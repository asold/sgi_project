{
  "title": "Exploring Multi-Task Multi-Lingual Learning of Transformer Models for Hate Speech and Offensive Speech Identification in Social Media",
  "url": "https://openalex.org/W3123044186",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2251593539",
      "name": "Sudhanshu Mishra",
      "affiliations": [
        "Indian Institute of Technology Kanpur",
        "University of Illinois Urbana-Champaign"
      ]
    },
    {
      "id": "https://openalex.org/A2614488936",
      "name": "Shivangi Prasad",
      "affiliations": [
        "University of Illinois Urbana-Champaign"
      ]
    },
    {
      "id": "https://openalex.org/A2192659826",
      "name": "Shubhanshu Mishra",
      "affiliations": [
        "University of Illinois Urbana-Champaign",
        "Indian Institute of Technology Kanpur"
      ]
    },
    {
      "id": "https://openalex.org/A2251593539",
      "name": "Sudhanshu Mishra",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2614488936",
      "name": "Shivangi Prasad",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2192659826",
      "name": "Shubhanshu Mishra",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2613977835",
    "https://openalex.org/W6815770799",
    "https://openalex.org/W2954226438",
    "https://openalex.org/W1871142974",
    "https://openalex.org/W2972735048",
    "https://openalex.org/W2595653137",
    "https://openalex.org/W3036074945",
    "https://openalex.org/W3009899658",
    "https://openalex.org/W2963626623",
    "https://openalex.org/W2563877105",
    "https://openalex.org/W3000571327",
    "https://openalex.org/W2974917466",
    "https://openalex.org/W3094215269",
    "https://openalex.org/W2083873466",
    "https://openalex.org/W2974387227",
    "https://openalex.org/W2729412353",
    "https://openalex.org/W2989817717",
    "https://openalex.org/W6773817926",
    "https://openalex.org/W3100941475",
    "https://openalex.org/W1527758775",
    "https://openalex.org/W2810732061",
    "https://openalex.org/W2740168486",
    "https://openalex.org/W2963216553",
    "https://openalex.org/W2516255829",
    "https://openalex.org/W2016799133",
    "https://openalex.org/W2973159684",
    "https://openalex.org/W2955358972",
    "https://openalex.org/W2963943967",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2972944582",
    "https://openalex.org/W2922580172"
  ],
  "abstract": null,
  "full_text": "Noname manuscript No.\n(will be inserted by the editor)\nExploring multi-task multi-lingual learning of\ntransformer models for hate speech and oﬀensive\nspeech identiﬁcation in social media\nSudhanshu Mishra · Shivangi Prasad ·\nShubhanshu Mishra∗\nReceived: date / Accepted: date\nAbstract Hate Speech has become a major content moderation issue for on-\nline social media platforms. Given the volume and velocity of online con-\ntent production, it is impossible to manually moderate hate speech related\ncontent on any platform. In this paper we utilize a multi-task and multi-\nlingual approach based on recently proposed Transformer Neural Networks\nto solve three sub-tasks for hate speech. These sub-tasks were part of the\n2019 shared task on hate speech and oﬀensive content (HASOC) identiﬁ-\ncation in Indo-European languages. We expand on our submission to that\ncompetition by utilizing multi-task models which are trained using three ap-\nproaches, a) multi-task learning with separate task heads, b) back-translation,\nand c) multi-lingual training. Finally, we investigate the performance of var-\nious models and identify instances where the Transformer based models per-\nform diﬀerently and better. We show that it is possible to to utilize diﬀerent\ncombined approaches to obtain models that can generalize easily on diﬀer-\nent languages and tasks, while trading oﬀ slight accuracy (in some cases)\nfor a much reduced inference time compute cost. We open source an up-\ndated version of our HASOC 2019 code with the new improvements at https:\n//github.com/socialmediaie/MTML_HateSpeech.\nKeywords Hate Speech ·Oﬀensive content ·Transformer Models ·BERT ·\nLanguage Models ·Neural Networks ·Multi-lingual ·Multi-Task Learning ·\nS. Mishra\nIndian Institute of Technology Kanpur, India\nE-mail: sdhanshu@iitk.ac.in\nS. Prasad\nUniversity of Illinois at Urbana-Champaign, USA\nE-mail: sprasad6@illinois.edu\nS. Mishra∗ [Corresponding Author]\nUniversity of Illinois at Urbana-Champaign, USA\nE-mail: mishra@shubhanshu.com\narXiv:2101.11155v1  [cs.CL]  27 Jan 2021\n2 Sudhanshu Mishra et al.\nSocial Media ·Natural Language Processing ·Machine Learning ·Deep\nLearning ·Open Source\n1 Introduction\nWith increased access to the internet, the number of people that are connected\nthrough social media is higher than ever (Perrin, 2015). Thus, social media\nplatforms are often held responsible for framing the views and opinions of\na large number of people (Duggan et al., 2017). However, this freedom to\nvoice our opinion has been challenged by the increase in the use of hate speech\n(Mondal et al., 2017). The anonymity of the internet grants people the power to\ncompletely change the context of a discussion and suppress a person’s personal\nopinion (Sticca and Perren, 2013). These hateful posts and comments not only\naﬀect the society at a micro scale but also at a global level by inﬂuencing\npeople’s views regarding important global events like elections, and protests\n(Duggan et al., 2017). Given the volume of online communication happening on\nvarious social media platforms and the need for more fruitful communication,\nthere is a growing need to automate the detection of hate speech. For the\nscope of this paper we adopt the deﬁnition of hate speech and oﬀensive speech\nas deﬁned in the Mandl et al. (2019) as “ insulting, hurtful, derogatory, or\nobscene content directed from one person to another person ” (quoted from\n(Mandl et al., 2019)).\nIn order to automate hate speech detection the Natural Language Pro-\ncessing (NLP) community has made signiﬁcant progress which has been ac-\ncelerated by organization of numerous shared tasks aimed at identifying hate\nspeech (Mandl et al., 2019; Kumar et al., 2020, 2018). Furthermore, there has\nbeen a proliferation of new methods for automated hate speech detection in\nsocial media text (Salminen et al., 2018; Mishra et al., 2020b; Mishra and\nMishra, 2019; Mishra, 2020a; Waseem et al., 2017; Struß et al., 2019; Mandl\net al., 2019; Mondal et al., 2017). However, working with social media text\nis diﬃcult (Eisenstein, 2013; Mishra and Diesner, 2016; Mishra et al., 2014;\nMishra and Diesner, 2019; Mishra, 2019, 2020b,a), as people use combinations\nof diﬀerent languages, spellings and words that one may never ﬁnd in any\ndictionary. A common pattern across many hate speech identiﬁcation tasks\nMandl et al. (2019); Kumar et al. (2020); Waseem et al. (2017); Zampieri\net al. (2019); Basile et al. (2019); Struß et al. (2019) is the identiﬁcation of\nvarious aspects of hate speech, e.g., in HASOC 2019 (Mandl et al., 2019), the\norganizers divided the task into three sub-tasks, which focused on identifying\nthe presence of hate speech; classiﬁcation of hate speech into oﬀensive, pro-\nfane, and hateful; and identifying if the hate speech is targeted towards an\nentity.\nMany researchers have tried to address these types of tiered hate speech\nclassiﬁcation tasks using separate models, one for each sub-task (see review of\nrecent shared tasks Zampieri et al. (2019); Kumar et al. (2018, 2020); Mandl\net al. (2019); Struß et al. (2019)). However, we consider this approach limited\nMulti-task multi-lingual hate speech identiﬁcation 3\nfor application to systems which consume large amounts of data, and are\ncomputationally constrained for eﬃciently ﬂagging hate speech. The limitation\nof existing approach is because of the requirement to run several models, one\nfor each language and sub-task.\nIn this work, we propose a uniﬁed modeling framework which identiﬁes\nthe relationship between all tasks across multiple languages. Our aim is to\nbe able to perform as good if not better than the best model for each task\nlanguage combination. Our approach is inspired from the promising results\nof multi-task learning on some of our recent works (Mishra, 2019, 2020b,a).\nAdditionally, while building a uniﬁed model which can perform well on all tasks\nis challenging, an important beneﬁt of these models is their computational\neﬃciency, achieved by reduced compute and maintenance costs, which can\nallow the system to trade-oﬀ slight accuracy for eﬃciency.\nIn this paper, we propose the development of such universal modelling\nframework, which can leverage recent advancements in machine learning to\nachieve competitive and in few cases state-of-the-art performance of a variety\nof hate speech identiﬁcation sub-tasks across multiple languages. Our frame-\nwork encompasses a variety of modelling architectures which can either train\non all tasks, all languages, or a combination of both. We extend the our prior\nwork in Mishra and Mishra (2019); Mishra et al. (2020b); Mishra (2020b,a,\n2019) to develop eﬃcient models for hate speech identiﬁcation and benchmark\nthem against the HASOC 2019 corpus, which consists of social media posts\nin three languages, namely, English, Hindi, and German. We open source our\nimplementation to allow its usage by the wider research community. Our main\ncontributions are as follows:\n1. Investigate more eﬃcient modeling architectures which use a) multi-task\nlearning with separate task heads, b) back-translation, and c) multi-lingual\ntraining. These architectures can generalize easily on diﬀerent languages\nand tasks, while trading oﬀ slight accuracy (in some cases) for a much\nreduced inference time compute cost.\n2. Investigate the performance of various models and identiﬁcation of in-\nstances where our new models diﬀer in their performance.\n3. Open source pre-trained models and model outputs at Mishra et al. (2020a)\nalong with the updated code for using these models at: https://github.\ncom/socialmediaie/MTML_HateSpeech\n2 Related Work\nPrior work (see Schmidt and Wiegand (2017) for a detailed review on prior\nmethods) in the area of hate speech identiﬁcation, focuses on diﬀerent aspects\nof hate speech identiﬁcation, namely analyzing what constitutes hate speech,\nhigh modality and other issues encountered when dealing with social media\ndata and ﬁnally, model architectures and developments in NLP, that are be-\ning used in identifying hate speech these days. There is also prior literature\n4 Sudhanshu Mishra et al.\nfocusing on the diﬀerent aspects of hateful speech and tackling the subjectiv-\nity that it imposes. There are many shared tasks Mandl et al. (2019); Kumar\net al. (2018, 2020); Struß et al. (2019); Basile et al. (2019) that tackle hate\nspeech detection by classifying it into diﬀerent categories. Each shared task\nfocuses on a diﬀerent aspect of hate speech. Waseem et al. (2017) proposed\na typology on the abusive nature of hate speech, classifying it into general-\nized, explicit and implicit abuse. Basile et al. (2019) focused on hateful and\naggressive posts targeted towards women and immigrants. Mandl et al. (2019)\nfocused on identifying targeted and un-targeted insults and classifying hate\nspeech into hateful, oﬀensive and profane content. Kumar et al. (2018, 2020)\ntackled aggression and misogynistic content identiﬁcation for trolling and cy-\nberbullying posts. Vidgen et al. (2019) identiﬁes that most of these shared\ntasks broadly fall into these three classes, individual directed abuse, identity\ndirected abuse and concept directed abuse. It also puts into context the various\nchallenges encountered in abusive content detection.\nUnlike other domains of information retrieval, there is a lack of large data-\nsets in this ﬁeld. Moreover, the data-sets available are highly skewed and focus\non a particular type of hate speech. For example, Davidson et al. (2017) models\nthe problem as a generic abusive content identiﬁcation challenge, however,\nthese posts are mostly related towards racism and sexism. Furthermore, in the\nreal world, hateful posts do not fall into to a single type of hate speech. There\nis a huge overlapping between diﬀerent hateful classes, making hate speech\nidentiﬁcation a multi label problem.\nA wide variety of system architectures, ranging from classical machine\nlearning to recent deep learning models, have been tried for various aspects\nof hate speech identiﬁcation. Facebook, YouTube, and Twitter are the major\nsources of data for most data-sets. Burnap and Williams (2015) used SVM\nand ensemble techniques on identifying hate speech in Twitter data. Razavi\net al. (2010) approach for abuse detection using an insulting and abusive lan-\nguage dictionary of words and phrases. Van Hee et al. (2015) used bag of\nwords n-gram features and trained an SVM model on a cyberbullying dataset.\nSalminen et al. (2018) achieved an F1-score of 0.79 on classiﬁcation of hateful\nYouTube and Facebook posts using a linear SVM model employing TF-IDF\nweighted n-grams.\nRecently, models based on deep learning techniques have also been ap-\nplied to the task of hate speech identiﬁcation. These models often rely on\ndistributed representations or embeddings, e.g., FastText embeddings (Joulin\net al. (2017), and paragraph2vec distributed representations (Le and Mikolov\n(2014). Badjatiya et al. (2017) employed an LSTM architecture to tune Glove\nword embeddings on the DATA-TWITTER-TWH data-set. Risch and Krestel\n(2018) used a neural network architecture using a GRU layer and ensemble\nmethods for the TRAC 2018 (Kumar et al., 2018) shared task on aggres-\nsion identiﬁcation. They also tried back-translation as a data augmentation\ntechnique to increase the data-set size. Wang (2018) illustrated the use of se-\nquentially combining CNNs with RNNs for abuse detection. They show that\nthis approach was better than using only the CNN architecture giving a 1%\nMulti-task multi-lingual hate speech identiﬁcation 5\nimprovement in the F1-score. One of the most recent developments in NLP\nare the transformer architecture introduced by Vaswani et al. (2017). Utilizing\nthe transformer architecture, Devlin et al. (2019) provide methods to pre-train\nmodels for language understanding (BERT) that have achieved state of the\nart results in many NLP tasks and are promising for hate speech detection as\nwell. BERT based models achieved competitive performance in HASOC 2019\nshared tasks. We Mishra and Mishra (2019) ﬁne tuned BERT base models for\nthe various HASOC shared tasks being the top performing model in some of the\nsub-tasks. A similar approach was also used for the TRAC 2020 shared tasks on\nAggression identiﬁcation by us Mishra et al. (2020b) still achieving competitive\nperformance with the other models without using an ensemble techniques. An\ninteresting approach was the use of multi-lingual models by joint training on\ndiﬀerent languages. This approach presents us with a uniﬁed model for diﬀer-\nent languages in abusive content detection. Ensemble techniques using BERT\nmodels (Risch and Krestel, 2020) was the top performing model in many of the\nshared tasks in TRAC 2020. Recently, multi-task learning has been used for\nimproving performance on NLP tasks (Liu et al., 2016; Søgaard and Goldberg,\n2016), especially social media information extraction tasks (Mishra, 2019), and\nmore simpler variants have been tried for hate speech identiﬁcation in our re-\ncent works (Mishra and Mishra, 2019; Mishra et al., 2020b). Florio et al. (2020)\ninvestigated the usage of AlBERTo on monitoring hate speech against Italian\non Twitter. Their results show that even though AlBERTo is sensitive to the\nﬁne tuning set, it’s performance increases given enough training time. Mozafari\net al. (2020) employ a transfer learning approach using BERT for hate speech\ndetection. Ranasinghe and Zampieri (2020) use cross-lingual embeddings to\nidentify oﬀensive content in multilingual setting. Our multi-lingual approach\nis similar in spirit to the method proposed in Plank (2017) which use the same\nmodel architecture and aligned word embedding to solve the tasks. There has\nalso been some work on developing solutions for multilingual toxic comments\nwhich can be related to hate speech.1 Recently, Mishra (2020c) also used a sin-\ngle model across various tasks which performed very well for event detection\ntasks for ﬁve Indian languages.\nThere have been numerous competitions dealing with hate speech evalua-\ntion. OﬀensEval Zampieri et al. (2019) is one of the popular shared tasks deal-\ning with oﬀensive language in social media, featuring three sub-tasks for dis-\ncriminating between oﬀensive and non-oﬀensive posts. Another popular shared\ntask in SemEval is the HateEval Basile et al. (2019) task on the detection of\nhate against women and immigrants. The 2019 version of HateEval consists\nof two sub-task for determination of hateful and aggressive posts. GermEval\nStruß et al. (2019) is another shared task quite similar to HASOC. It focused\non the Identiﬁcation of Oﬀensive Language in German Tweets. It features\ntwo sub-tasks following a binary and multi-class classiﬁcation of the German\ntweets.\n1 https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification\n6 Sudhanshu Mishra et al.\nAn important aspect of hate speech is that it is primarily multi-modal in\nnature. A large portion of the hateful content that is shared on social media\nis in the form of memes, which feature multiple modalities like audio, text,\nimages and videos in some cases as well. Yang et al. (2019) present diﬀerent\nfusion approaches to tackle multi-modal information for hate speech detection.\nGomez et al. (2020) explore multi-modal hate speech consisting of text and\nimage modalities. They propose various multi-modal architectures to jointly\nanalyze both the textual and visual information. Facebook recently released\nthe hateful memes data-set for the Hateful Memes challenge Kiela et al. (2020)\nto provide a complex data-set where it is diﬃcult for uni-modal models to\nachieve good performance.\n3 Methods\nFor this paper, we extend some of the techniques that we have used in TRAC\n2020 in Mishra et al. (2020b) as well as Mishra (2019, 2020a,b), and apply\nthem to the HASOC data-set Mandl et al. (2019). Furthermore, we extend\nthe work that we did as part of the HASOC 2019 shared task Mishra and\nMishra (2019) by experimenting with multi-lingual training, back-translation\nbased data-augmentation, and multi-task learning to tackle the data sparsity\nissue of the HASOC 2019 data-set.\nFig. 1: Task Description\n3.1 Task Deﬁnition and Data\nAll of the experiments reported hereafter have been done on the HASOC 2019\ndata-set (Mandl et al., 2019) consisting of posts in English (EN), Hindi (HI)\nand German (DE). The shared tasks of HASOC 2019 had three sub-tasks\n(A,B,C) for both English and Hindi languages and two sub-tasks (A,B) for\nthe German language. The description of each sub-task is as follows (see Figure\n1 for details):\nMulti-task multi-lingual hate speech identiﬁcation 7\n– Sub-Task A: Posts have to be classiﬁed into hate speech HOF and non-\noﬀensive content NOT.\n– Sub-Task B: A ﬁne grained classiﬁcation of the hateful posts in sub-\ntask A. Hate Speech posts have to be identiﬁed into the type of hate they\nrepresent, i.e containing hate speech content(HATE), containing oﬀensive\ncontent (OFFN) and those containing profane words (PRFN).\n– Sub-Task C: Another ﬁne grained classiﬁcation of the hateful posts in\nsub-tasks A. This sub-task required us to identify whether the hate speech\nwas targeted towards an individual or group TIN or whether it was un-\ntargeted UNT.\nTable 1: Distribution of number of tweets in diﬀerent data-sets and splits.\ntask DE EN HI\ntrain dev test train dev test train dev test\nA 3,819 794 850 5,852 505 1,153 4,665 136 1,318\nB 407 794 850 2,261 302 1,153 2,469 136 1,318\nC 2,261 299 1,153 2,469 72 1,318\nThe HASOC 2019 data-set consists of posts taken from Twitter and Face-\nbook. The data-set only consists of text and labels and does not include any\ncontextual information or meta-data of the original post e.g. time information.\nThe data distribution for each language and sub-task is mentioned in Table\n1. We can observe, that the sample size for each language is of the order of a\nfew thousand post, which is an order smaller to other datasets like OﬀenseEval\n(13,200 posts), HateEval (19,000 posts), and Kaggle Toxic Comments datasets\n(240,000 posts). This can pose a challenge for training deep learning models,\nwhich often consists of large number of parameters, from scratch. Class wise\ndata distribution for each language is available in the appendix .1 ﬁgures 4,\n5, and 6. These ﬁgures show that the label distribution is highly skewed for\ntask C, such as the label UNT, which is quite underrepresented. Similarly, for\nGerman the task A data is quite unbalanced. For more details on the dataset\nalong with the details on its creation and motivation we refer the reader to\nMandl et al. (2019). Mandl et al. (2019) reports that the inter-annotator agree-\nment is in the range of 60% to 70% for English and Hindi. Furthermore, the\ninter-annotator agreement is more than 86% for German.\n3.2 Fine-tuning transformer based models\nThe transformer based models especially BERT (Devlin et al., 2019), have\nproven to be successful in achieving very good results on a range of NLP tasks.\nUpon its release, BERT based models became state of the art for 11 NLP tasks\n(Devlin et al., 2019). This motivated us to try out BERT for hate speech de-\ntection. We had used multiple variants of the BERT model during HASOC\n8 Sudhanshu Mishra et al.\nFig. 2: An overview of various model architectures we used. Shaded task boxes\nrepresent that we ﬁrst compute a marginal representation of labels only be-\nlonging to that task before computing the loss.\n2019 shared tasks Mishra and Mishra (2019). We also experimented with other\ntransformer models and BERT during TRAC2020 Mishra et al. (2020b). How-\never, based on our experiments, we ﬁnd the original BERT models to be best\nperforming for most tasks. Hence, for this paper we only implement our mod-\nels on those. For our experiments we use the open source implementations of\nBERT provided by Wolf et al. (2019) 2. A common practice for using BERT\nbased models, is to ﬁne-tune an existing pre-trained model on data from a\nnew task. For ﬁne tuning the pre-trained BERT models we used the BERT\nfor Sequence Classiﬁcation paradigm present in the HuggingFace library. We\nﬁne tune BERT using various architectures. A visual description of these ar-\nchitectures is shown in Figure 2. These models are explained in detail in later\nsections.\nTo process the text, we ﬁrst use a pre-trained BERT tokenizer to convert\nthe input sentences into tokens. These tokens are then passed to the model\nwhich generate a BERT speciﬁc embeddings for each token. The special part\n2 https://github.com/huggingface/transformers\nMulti-task multi-lingual hate speech identiﬁcation 9\nabout BERT is that its decoder is supplied all the hidden states of the encoder\nunlike other transformer models before BERT. This helps it to capture better\ncontextual information even for larger sequences. Each sequence of tokens is\npadded with a [CLS] and [SEP] token. The pre-trained BERT model generates\nan output vector for each of the tokens. For sequence classiﬁcation tasks, the\nvector corresponding to the [CLS] token is used as it holds the contextual\ninformation about the complete sentence. Additional ﬁne-tuning is done on\nthis vector to generate the classiﬁcation for speciﬁc data-sets.\nTo keep our experiments consistent, the following hyper-parameters were\nkept constant for all our experiments. For training our models we used the\nstandard hyper-parameters as mentioned in the huggingface transformers doc-\numentation. We used the Adam optimizer (with ϵ= 1e−8) for 5 epochs, with\na training/eval batch size of 32. Maximum allowable length for each sequence\nwas kept as 128. We use a linearly decreasing learning rate with a starting\nvalue as 5e−5 with a weight decay of 0.0 and a max gradient norm of 1 .0. All\nmodels were trained using Google Colab’s 3 GPU runtimes. This limited us to\na model run-time of 12 hours with a GPU which constrained our batch size as\nwell as number of training epochs based on the GPU allocated by Colab.\nWe refer to models which ﬁne tune BERT on using data set from a single\nlanguage for a single task, as Single models with an indicator (S), this is\ndepicted in Figure 2 (1st row left). All other models types which we discuss\nlater are identiﬁed by their model types and naems in Figure 2.\n3.3 Training a model for all tasks\nOne of the techniques that we had used for our work in HASOC 2019 Mishra\nand Mishra (2019) was creating an additional sub-task D by combining the\nlabels for all of the sub-tasks. We refer to models which use this technique as\nJoint task models which an indicator (D) (see Figure 2 models marked with\nD). This allowed us to train a single model for all of the sub-tasks. This also\nhelps in overcoming the data sparsity issue for sub-tasks B and sub-tasks C\nfor which the no. of data points is very small. The same technique was also\nemployed in our submission to TRAC 2020 Mishra et al. (2020b) aggression\nand misogyny identiﬁcation tasks. Furthermore, when combining labels, we\nonly consider valid combination of labels, which allows us to reduce the possible\noutput space. For HASOC, the predicted output labels for the joint-training\nare as follows : NOT-NONE-NONE, HOF-HATE-TIN, HOF-HATE-\nUNT, HOF-OFFN-TIN, HOF-OFFN-UNT, HOF-PRFN-TIN, HOF-\nPRFN-UNT. The task speciﬁc labels can be easily extracted from the output\nlabels, using post-processing of predicted labels.\n3 https://colab.research.google.com/\n10 Sudhanshu Mishra et al.\n3.4 Multi-lingual training\nInspired from joint training of all tasks, as described above, we also implement\nthe training of a single model for all languages for a given sub-task. Similar\napproach was utilized in our prior submission to TRAC 2020 Mishra et al.\n(2020b). We refer to models which use this technique as All models with an\nindicator (ALL) (see Figure 2 models marked with ALL). In this method, we\ncombine the data-sets from all the languages and train a single multi-lingual\nmodel on this combined data-set. The multi-lingual model is able to learn\ndata from multiple languages thus providing us with a single uniﬁed model\nfor diﬀerent languages. A major motivation for taking this approach was that\nsocial media data often does not belong to one particular language. It is quite\ncommon to ﬁnd code-mixed posts on Twitter and Facebook. Thus, a multi-\nlingual model is the best choice in this scenario. During our TRAC 2020 work,\nwe had found out that this approach works really well and was one of our\ntop models in almost all of the shared tasks. From a deep learning point of\nview, this technique seems promising as doing this also increases the size of\nthe data-set available for training without adding new data points from other\ndata-sets or from data augmentation techniques.\nAs a natural extension of the above two approaches, we combine the multi-\nlingual training with the joint training approach to train a single model on all\ntasks for all languages. We refer to models which use this technique as All\njoint task models with an indicator (ALL) (D) (see Figure 2).\n3.5 Multi-task learning\nWhile the joint task setting, can be considered as a multi-task setting, it is\nnot, in the common sense, and hence our reservation in calling it multi-task.\nThe joint task training can be considered an instance of multi-class predic-\ntion, where the number of classes is based on the combination of tasks. This\napproach does not impose any sort of task speciﬁc structure on the model, or\ncomputes and combines task speciﬁc losses. The core idea of multi-task learn-\ning is to use similar tasks as regularizers for the model. This is done by simply\nadding the loss functions speciﬁc to each task in the ﬁnal loss function of the\nmodel. This way the model is forced to optimize for all of the diﬀerent tasks\nsimultaneously, thus producing a model that is able to generalize on multiple\ntasks on the data-set. However, this may not always prove to be beneﬁcial as\nit has been reported that when the tasks diﬀer signiﬁcantly the model fails\nto optimize on any of the tasks. This leads to signiﬁcantly worse performance\ncompared to single task approaches. However, sub-tasks in hate speech de-\ntection are often similar or overlapping in nature. Thus, this approach seems\npromising for hate speech detection.\nOur multi-task setup is inspired from the marginalized inference tech-\nnique which was used in Mishra et al. (2020b). In the marginalized infer-\nence, we post-process the probabilities of each label in the joint model, and\nMulti-task multi-lingual hate speech identiﬁcation 11\ncompute the task speciﬁc label probability by marginalizing the probability\nof across all the other tasks. This ensures that the probabilities of labels for\neach sub-task make a valid probability distribution and sum to one. For ex-\nample, p(HOF-HATE-TIN) > p(HOF-PRFN-TIN) does not guarantee\nthat p(HOF-HATE-UNT) > p(HOF-PRFN-UNT). As described above,\nwe can calculate the task speciﬁc probabilities by marginalizing the output\nprobabilities of that task. For example, p(HATE) = p(HOF-HATE-TIN)+\np(HOF-HATE-UNT). However, using this technique did not lead to a signif-\nicant improvement in the predictions and the evaluation performance. In some\ncases, it was even lower than the original method. A reason we suspect for this\nlow performance is that the model was not trained to directly optimize its loss\nfor this marginal inference. Next, we describe our multi-task setup inspired\nfrom this approach.\nFor our multi-task experiments, we ﬁrst use our joint training approach\n(sub-task D) to generate the logits for the diﬀerent class labels. These logits\nare then marginalized to generate task speciﬁc logits (marginalizing logits is\nsimpler than marginalizing the probability for each label, as we do not need\nto compute the partition function). For each task, we take a cross-entropy loss\nusing the new task speciﬁc logits. Finally we add the respective losses for each\nsub-task along with the sub-task D loss. This added up loss is the ﬁnal multi-\ntask loss function of our model. We then train our model to minimize this\nloss function. In this loss, each sub-task loss acts as a regularizer for the other\ntask losses. Since, we are computing the multi-task loss for each instance, we\ninclude a special label NONE for sub-tasks B and C, for the cases where the\nlabel of sub-task A is NOT. We refer to models which use this technique as\nMulti-task models with an indicator (MTL) (D) (see Figure 2).\nOne important point to note is that we restrict the output space of the\nmulti-task model by using the task 4 labels. This is an essential constraint that\nwe put on the model because of which there is no chance of any inconsistency\nin the prediction. By inconsistency we say that it is not possible for our multi-\ntask model to predict a data point that belongs to NOT for task A and to\nany label other than NONE for the tasks B and C. If we follow the general\nprocedure for training a multi-task model, we would have 2∗(3+1)∗(2+1) = 24\n, with +1 for the additional NONE label, combinations of outputs from our\nmodel, which would produce the inconsistencies mentioned above.\nLike the methods mentioned before, we extend multi-task learning to all\nlanguages, which results in Multi-task all model , which are indicated with an\nindicator (MTL) (ALL) (D) .\n3.6 Training with Back-Translated data\nOne approach for increasing the size of the training data-set, is to generate\nnew instances based on existing instances using data augmentation techniques.\nThese new instances are assigned the same label as the original instance. Train-\ning model with instances generated using data augmentation techniques as-\n12 Sudhanshu Mishra et al.\nsumes that the label remains same if the data augmentation does not change\nthe instance signiﬁcantly. We utilized a speciﬁc data augmentation technique\nused in NLP models, called Back-Translation (Koehn, 2005; Sennrich et al.,\n2016). Back-translation uses two machine translation models, one, to translate\na text from its original language to a target language; and another, to translate\nthe new text in target language back to the original language. This technique\nwas successfully used in the submission of Risch and Krestel (2018, 2020) dur-\ning TRAC 2018 and 2020. Data augmentation via back-translation assumes\nthat current machine translation systems when used in back-translation set-\ntings give a diﬀerent text which expresses a similar meaning as the original.\nThis assumption allows us to reuse the label of the original text for the back-\ntranslated text.\nWe used the Google translate API 4 to back-translate all the text in our\ndata-sets.\nFor each language in our data-set we use the following source →target →\nsource pairs:\n– EN: English →French →English\n– HI: Hindi →English →Hindi\n– DE: German →English →German\nTo keep track of the back-translated texts we added a ﬂag to the text id. In\nmany cases, there were minimal changes to the text. In some cases there were\nno changes to the back-translated texts. However the no. of such texts where\nthere was no change after back-translation was very low. For example, among\n4000 instances in the English training set around 100 instances did not have\nany changes. So while using the back-translated texts for our experiments, we\nsimply used all the back-translated texts whether they under-went a change\nor not. The data-set size doubled after using the back-translation data aug-\nmentation technique. An example of back-translated English text is as follows\n(changed text is emphasized):\n1. Original: @politico No. We should remember very clearly that #Indi-\nvidual1 just admitted to treason . #TrumpIsATraitor #McCainsAHero\n#JohnMcCainDay\n2. Back-translated: @politico No, we must not forget that very clear\n#Individual1 just admitted to treason. #TrumpIsATraitor #McCainsA-\nHero #JohnMcCainDay\n4 Results\nWe present our results for sub-tasks A, B and C in Table 2, 3, and 4 respec-\ntively. To keep the table concise we use the following convention.\n1. (ALL): A bert-base-multi-lingual-uncasedmodel was used with multi-lingual\njoint training.\n4 https://cloud.google.com/translate/docs\nMulti-task multi-lingual hate speech identiﬁcation 13\n2. (BT): The data-set used for this experiment is augmented using back-\ntranslation.\n3. (D): A joint training approach has been used.\n4. (MTL): The experiment is performed using a multi-task learning ap-\nproach.\n5. (S): This is the best model which was submitted to HASOC 2019 in Mishra\nand Mishra (2019).\nThe pre-trained BERT models which were ﬁne-tuned for each language in\na single language setting, are as follows:\n1. EN - bert-base-uncased\n2. HI - bert-base-multi-lingual-uncased\n3. DE - bert-base-multi-lingual-uncased\n4.1 Model performance\nWe evaluate our models against each other and also against the top performing\nmodels of HASOC 2019 for each task. We use the same benchmark scores,\nnamely, weighted F1-score and macro F1-score, as were used in Mandl\net al. (2019), with macro F1-score being the scores which were used for\noverall ranking in HASOC 2019.\n4.1.1 Sub-Task A\nThe best scores for sub-task A are mentioned in Table 2. The best scores for\nthis task belong to Wang et al. (2019), Bashar and Nayak (2020) and Saha\net al. (2019) for English, Hindi and German respectively. All the models that\nwe experimented with in sub-task A are very closely separated by the macro-\nF1 score. Hence, all of them give a similar performance for this task. The\ndiﬀerence between the macro F1-scores of these models is < 3% . For both\nEnglish and Hindi, the multi-task learning model performed the best while\nfor the German language, the model that was trained on the back-translated\ndata using the multi-lingual joint training approach and task D ( (ALL)\n(BT) (D) )worked best. However, it is interesting to see that the multi-task\nmodel gives competitive performance on all of the languages within the same\ncomputation budget. One thing to notice is that, the train macro-F1 scores of\nthe multi-task model are much lower than the other models. This suggests that\nthe (MTL) model, given additional training time might improve the results\neven further. We are unable to provide longer training time due to lack of\ncomputational resources available to us. The (ALL) (MTL)model also gives\na similar performance compared to the (MTL) model. This suggests that the\nadditional multi-lingual training comes with a trade oﬀ with a slightly lower\nmacro-F1 score. However, the diﬀerence between the scores of the two models\nis ∼1%. In order to address the additional training time the (MTL) models\nrequired, we trained the (ALL) (MTL) model for 15 epochs. However, this\n14 Sudhanshu Mishra et al.\nTable 2: Sub-task A results. Models in HASOC 2019 (Mandl et al., 2019) were\nranked based on Macro F1.\nWeighted F1 Macro F1\nlang model dev train test dev train test\nEN\n(ALL) 0.562 0.949 0.804 0.568 0.946 0.753\n(ALL) (D) 0.481 0.894 0.797 0.497 0.886 0.740\n(BT) 0.535 0.973 0.756 0.545 0.971 0.690\n(BT) (ALL) 0.493 0.986 0.803 0.509 0.985 0.747\n(BT) (ALL) (D) 0.474 0.981 0.806 0.492 0.980 0.750\n(MTL) (ALL) (D) 0.552 0.823 0.801 0.559 0.812 0.755\n(MTL) (D) 0.543 0.745 0.819 0.557 0.725 0.765\n(S) 0.606 0.966 0.790 0.610 0.964 0.740\n(S) (D) 0.596 0.908 0.801 0.603 0.902 0.747\nHASOC Best - - 0.840 - - 0.788\nHI\n(ALL) 0.786 0.976 0.793 0.785 0.976 0.793\n(ALL) (D) 0.815 0.959 0.811 0.815 0.959 0.810\n(BT) 0.654 0.967 0.746 0.654 0.967 0.744\n(BT) (ALL) 0.815 0.982 0.795 0.814 0.982 0.795\n(BT) (ALL) (D) 0.772 0.975 0.793 0.772 0.975 0.792\n(MTL) (ALL) (D) 0.860 0.921 0.808 0.860 0.921 0.807\n(MTL) (D) 0.748 0.893 0.814 0.749 0.893 0.814\n(S) 0.742 0.961 0.802 0.742 0.961 0.802\n(S) (D) 0.822 0.941 0.814 0.823 0.941 0.811\nHASOC Best - - 0.820 - - 0.815\nDE\n(ALL) 0.899 0.993 0.794 0.706 0.981 0.584\n(ALL) (D) 0.906 0.988 0.779 0.730 0.968 0.566\n(BT) 0.878 0.988 0.777 0.628 0.969 0.533\n(BT) (ALL) 0.908 0.999 0.800 0.742 0.998 0.612\n(BT) (ALL) (D) 0.902 0.998 0.783 0.712 0.994 0.584\n(MTL) (ALL) (D) 0.917 0.969 0.786 0.764 0.915 0.582\n(MTL) (D) 0.878 0.898 0.789 0.593 0.683 0.526\n(S) 0.606 0.966 0.789 0.610 0.964 0.577\nHASOC Best - - 0.792 - - 0.616\ntraining time was too large as the models over-ﬁtted the data. This ﬁnally\nresulted in a degradation in the performance of these models. A sweet spot for\nthe training time may be found for the (MTL) models which may result in an\nincrease in the performance of the model whilst avoiding over-ﬁtting. We were\nnot able to conduct more experiments to do the same due to time constraints.\nThis may be evaluated in the additional future work on these models. We,\nhowever, cannot compare the German (MTL) models with the (MTL) models\nof the other languages as the German data did not have not have sub-task C,\nso the (MTL) approach did not have sub-task C for German. As we will see in\nthe next section, the (MTL) models performed equally well in sub-task B. This\nmight be because both tasks A and B involve identifying hate and hence are in\na sense co-related. This co-relation is something that the (MTL) models can\nutilize for their advantage. It has been found in other multi-task approaches\nthat the models learn more eﬀectively when the diﬀerent tasks are co-related.\nMulti-task multi-lingual hate speech identiﬁcation 15\nHowever, their performance can degrade if the tasks are un-related. The lower\nperformance on the German data may be because of the unavailability of the\nsub-task C. However, the results are still competitive with the other models.\nFor German, the (ALL) (MTL) model performed better than our submission\nfor HASOC 2019. The (MTL) model for Hindi was able to match the best\nmodel for this task at HASOC 2019.\nThe (ALL) and (ALL) (D) training methods show an improvement from\nour single models submitted at HASOC. These models present us with an\ninteresting option for abuse detection tasks as they are able to work on all\nof the shared tasks at the same time, leveraging the multi-lingual abilities of\nthe model whilst still having a computation budget equivalent to that of a\nsingle model. These results show that these models give a competitive perfor-\nmance with the single models. They even outperform the single model, e.g.,\nthey outperform the bert-base-uncased single models that were used in En-\nglish sub-task A, which have been specially tuned for English tasks. While for\nGerman and Hindi, the single models themselves utilized a bert-base-uncased\nmodel, so they are better suited for analyzing the improvements by the multi-\nlingual joint training approach. On these languages we see, that the (ALL)\nand (ALL) (D) techniques do improve the macro-F1 scores on for this task.\nThe back-translation technique does not seem to improve the models much.\nThe approach had a mixed performance. For all the languages, back-translation\nalone does not improve the model and hints at over-ﬁtting, resulting in a de-\ncrease in test results. However, when it is combined with the (ALL) and (D)\ntraining methods we see an increase in the performance. The (ALL) and (D)\ntraining methods are able to leverage the data-augmentation applied in the\nback-translated data. Back-translation when used with (ALL) or (ALL) (D)\nare better than the single models that we submitted at HASOC 2019. The\n(BT) (ALL) model comes really close to the best model at HASOC, coming\nsecond according to the results in Mandl et al. (2019).\n4.1.2 Sub-Task B\nThe best scores for sub-task B are mentioned in Table 3. The best scores for\nthis task belong to Ruiter et al. (2019) for German. For English and Hindi\nsub-task B our submissions had performed the best at HASOC 2019. For sub-\ntask B, many of our models were able to signiﬁcantly outperform the best\nHASOC models. For English, the multi-task approach results in a new best\nmacro-F1 score of 0.600, a 6% increase from the previous best. For Hindi, our\n(BT) (ALL) results in a macro-F1 score of 0 .662 which is 8% more than the\nprevious best. For Germans, our (MTL) model has a macro-F1 score on the\ntest set of 0.416 which is almost 7% more than the previous best.\nFor the English task, even our (MTL) (ALL) and (BT) (ALL) models were\nable to beat the previous best. However, our results show that unlike sub-task\nA where our models had similar performances, in sub-task B there is huge\nvariation in their performance. Many outperform the best, however some of\nthem also show poor results. The (ALL) and (ALL) (D) perform poorly for\n16 Sudhanshu Mishra et al.\nTable 3: sub-task B results. Models in HASOC 2019 (Mandl et al., 2019) were\nranked based on Macro F1.\nWeighted F1 Macro F1\nlang model dev train test dev train test\nEN\n(ALL) 0.361 0.826 0.501 0.290 0.805 0.467\n(ALL) (D) 0.201 0.776 0.556 0.190 0.580 0.392\n(BT) 0.422 0.965 0.532 0.352 0.960 0.510\n(BT) (ALL) 0.396 0.962 0.626 0.375 0.957 0.591\n(BT) (ALL) (D) 0.201 0.950 0.576 0.153 0.708 0.408\n(MTL) (ALL) (D) 0.397 0.927 0.635 0.277 0.915 0.590\n(MTL) (D) 0.344 0.899 0.638 0.341 0.881 0.600\n(S) 0.349 0.867 0.728 0.314 0.846 0.545\n(S) (D) 0.401 0.875 0.698 0.332 0.839 0.537\nHASOC Best - - 0.728 - - 0.545\nHI\n(ALL) 0.494 0.832 0.500 0.340 0.802 0.494\n(ALL) (D) 0.678 0.792 0.564 0.293 0.566 0.415\n(BT) 0.231 0.807 0.507 0.160 0.767 0.501\n(BT) (ALL) 0.589 0.890 0.667 0.283 0.875 0.662\n(BT) (ALL) (D) 0.630 0.849 0.519 0.180 0.617 0.381\n(MTL) (ALL) (D) 0.819 0.883 0.647 0.499 0.864 0.641\n(MTL) (D) 0.553 0.802 0.602 0.348 0.764 0.593\n(S) 0.466 0.749 0.688 0.322 0.701 0.553\n(S) (D) 0.757 0.826 0.715 0.459 0.736 0.581\nHASOC Best - - 0.715 - - 0.581\nDE\n(ALL) 0.326 0.876 0.459 0.315 0.861 0.343\n(ALL) (D) 0.285 0.813 0.154 0.255 0.603 0.128\n(BT) 0.285 0.620 0.413 0.328 0.581 0.285\n(BT) (ALL) 0.478 0.985 0.495 0.484 0.984 0.397\n(BT) (ALL) (D) 0.179 0.945 0.242 0.153 0.707 0.177\n(MTL) (ALL) (D) 0.463 0.946 0.527 0.346 0.707 0.344\n(MTL) (D) 0.468 0.923 0.541 0.482 0.918 0.416\n(S) 0.112 0.367 0.756 0.140 0.247 0.249\n(S) (D) 0.865 0.918 0.778 0.282 0.409 0.276\nHASOC Best - - 0.775 - - 0.347\nthe three languages, except (ALL) in German, and show very small macro-F1\nscores even on the training set. Thus, training these models for longer may\nchange the results. The (MTL) models are able to give competitive perfor-\nmance in task-A and is able to outperform the previous best, thus showing\nit’s capability to leverage diﬀerent co-related tasks and generalize well on all\nof them.\nHere again we see that back-translation alone does not improve the macro-\nF1 scores. However, an interesting thing to notice is that the (ALL) and (BT)\nmodels which perform poorly individually, tend to give good results when\nused together. Outperforming the previous best HASOC models, in all the\nthree languages. This hints that data sparsity alone is not the major issue of\nthis task. This is also evident from the performance of the (MTL) model which\nonly utilizes the data-set of a single language, which is signiﬁcantly smaller\nMulti-task multi-lingual hate speech identiﬁcation 17\nthan the back-translated (twice the original data-set) and the multi-lingual\njoint model (sum of the sizes of the original model). But the (BT) (ALL) (D)\nmodel performed poorly in all of the three languages. Thus, the use of sub-task\n(D) with these models only degrades performance.\nThe results from this task conﬁrm that the information required to predict\ntask - A is important for task - B as well. This information is shared better by\nthe modiﬁed loss function of the (MTL) models rather than the loss function\nfor sub-task (D).\nThe (MTL) models build up on the sub-task (D) approach and do not\nutilize it explicitly. The sub-task (D) approach seems like a multi-task learning\nmethod, however, it is not complete and is not able to learn from the other\ntasks, thus does not oﬀer huge improvement. These (MTL) models do show\na variation in their performance but it is always on the higher side of the\nmacro-F1 scores.\n4.1.3 Sub-Task C\nThe best scores for sub-task C are mentioned in Table 4. The best scores for\nthis task belong to Mujadia et al. (2019) for Hindi while our submissions per-\nformed the best for English. The results for sub-task C also show appreciable\nvariation. Except the (ALL) (D) and (BT) (ALL) (D) models which also per-\nformed poorly in sub-task B, the variation in their performance, especially for\nEnglish, is not as signiﬁcant as that present in sub-task B. This may be due to\nthe fact that the two way ﬁne-grained classiﬁcation is a much easier task than\nthe three way classiﬁcation in sub-task B. One important point to note is that\nsub-task C focused on identifying the context of the hate speech, speciﬁcally\nit focused on ﬁnding out whether it is targeted or un-targeted, while sub-task\nA and sub-task B both focused on identifying the type of hate speech.\nThe (MTL) models do not perform as well as they did in the previous\ntwo tasks. They were still able to outperform the best models for English but\nperform poorly for Hindi. An important point to notice here is that the train\nmacro-F1 scores for the (MTL) models is signiﬁcantly low. This suggests that\nthe (MTL) model was not able learn well even for the training instances of\nthis task. This can be attributed to the point mentioned above that this task\nis inherently not as co-related to sub-task A and sub-task B as previously\nassumed. The task structure itself is not beneﬁcial for a (MTL) approach.\nThe main reason for this is that this task focuses on identifying targeted and\nun-targeted hate-speech. However, a non hate-speech text can also be an un-\ntargeted or targeted text. As the (MTL) model receives texts belonging to\nboth hate (HOF) and non-hate speech NOT, the information contained in\nthe texts belonging to this task are counter acted by those targeted and un-\ntargeted texts belong to the (NOT) class. Thus, a better description of this task\nis not a ﬁne-grain classiﬁcation of hate speech text, but that which involves\ntargeted and un-targeted labels for both (HOF) and (NOT) classes. In that\nsetting, we can fully utilize the advantage of the multi-task learning model\nand can expect better performance on this task as well.\n18 Sudhanshu Mishra et al.\nTable 4: sub-task C results. Models in HASOC 2019 (Mandl et al., 2019) were\nranked based on Macro F1.\nWeighted F1 Macro F1\nlang model dev train test dev train test\nEN\n(ALL) 0.842 0.986 0.737 0.524 0.958 0.547\n(ALL) (D) 0.380 0.792 0.658 0.141 0.328 0.292\n(BT) 0.836 0.991 0.771 0.465 0.974 0.543\n(BT) (ALL) 0.839 0.987 0.718 0.534 0.962 0.514\n(BT) (ALL) (D) 0.374 0.967 0.600 0.173 0.618 0.297\n(MTL) (ALL) (D) 0.839 0.704 0.658 0.311 0.465 0.518\n(MTL) (D) 0.844 0.747 0.692 0.470 0.506 0.538\n(S) 0.880 0.980 0.756 0.627 0.942 0.511\n(S) (D) 0.548 0.874 0.764 0.393 0.651 0.476\nHASOC Best - - 0.756 - - 0.511\nHI\n(ALL) 0.844 0.765 0.827 0.525 0.740 0.557\n(ALL) (D) 0.594 0.666 0.740 0.216 0.417 0.336\n(BT) 0.861 0.766 0.817 0.652 0.744 0.568\n(BT) (ALL) 0.797 0.941 0.775 0.517 0.937 0.527\n(BT) (ALL) (D) 0.682 0.779 0.673 0.288 0.507 0.317\n(MTL) (ALL) (D) 0.374 0.530 0.626 0.292 0.524 0.456\n(MTL) (D) 0.557 0.577 0.628 0.397 0.573 0.451\n(S) 0.800 0.877 0.727 0.550 0.866 0.565\n(S) (D) 0.769 0.724 0.758 0.537 0.622 0.550\nHASOC Best - - 0.736 - - 0.575\nThe (ALL) and (BT) models performed really well in sub-task C. The\n(ALL), (BT) and (ALL) (BT) models outperform the previous best for En-\nglish. The combination of these models with (D) still does not improve them\nand they continue to give poor performance. This provides more evidence to\nour previous inference that sub-task (D) alone does not improve the our per-\nformance.\nOverall most of our models, show an improvement from the single models\nsubmitted at HASOC.The sub-par performance of the back-translated models\nacross the sub-tasks suggest that data sparsity is not the central issue of this\nchallenge. To take advantage of the augmented-data additional methods have\nto be used. The sub-task (D) does not signiﬁcantly adds as an improvement\nto the models. It can be seen that it actually worsens the situation for sub-\ntasks B and sub-tasks C. This can be attributed to it changing the task to a\nmuch harder 7-class distribution task.The combined model approaches that we\nhave mentioned above oﬀer a resource eﬃcient way for hate speech detection.\nThe (ALL), (ALL) (MTL) and (MTL) models are able to generalize well for\nthe diﬀerent tasks and diﬀerent languages. They present themselves as good\ncandidates for a uniﬁed model for hate speech detection.\nMulti-task multi-lingual hate speech identiﬁcation 19\n/uni00000028/uni00000031/uni0000002b/uni0000002c/uni00000027/uni00000028\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000058/uni00000044/uni0000004a/uni00000048\n/uni00000013/uni00000011/uni00000015\n/uni00000013/uni00000011/uni00000017\n/uni00000013/uni00000011/uni00000019\n/uni00000013/uni00000011/uni0000001b\n/uni00000014/uni00000011/uni00000013/uni00000049/uni00000014/uni00000010/uni00000056/uni00000046/uni00000052/uni00000055/uni00000048\n/uni00000049/uni0000004c/uni0000004f/uni00000048/uni00000042/uni00000057/uni0000005c/uni00000053/uni00000048/uni00000003/uni00000020/uni00000003/uni00000047/uni00000048/uni00000059\n/uni00000028/uni00000031/uni0000002b/uni0000002c/uni00000027/uni00000028\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000058/uni00000044/uni0000004a/uni00000048\n/uni00000049/uni0000004c/uni0000004f/uni00000048/uni00000042/uni00000057/uni0000005c/uni00000053/uni00000048/uni00000003/uni00000020/uni00000003/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051\n/uni00000028/uni00000031/uni0000002b/uni0000002c/uni00000027/uni00000028\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000058/uni00000044/uni0000004a/uni00000048\n/uni00000049/uni0000004c/uni0000004f/uni00000048/uni00000042/uni00000057/uni0000005c/uni00000053/uni00000048/uni00000003/uni00000020/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n/uni0000004f/uni00000044/uni00000045/uni00000048/uni0000004f\n/uni00000031/uni00000032/uni00000037\n/uni0000002b/uni00000032/uni00000029\n(a) sub-task A\n/uni00000028/uni00000031/uni0000002b/uni0000002c/uni00000027/uni00000028\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000058/uni00000044/uni0000004a/uni00000048\n/uni00000013/uni00000011/uni00000013/uni00000013\n/uni00000013/uni00000011/uni00000015/uni00000018\n/uni00000013/uni00000011/uni00000018/uni00000013\n/uni00000013/uni00000011/uni0000001a/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000013/uni00000049/uni00000014/uni00000010/uni00000056/uni00000046/uni00000052/uni00000055/uni00000048\n/uni00000049/uni0000004c/uni0000004f/uni00000048/uni00000042/uni00000057/uni0000005c/uni00000053/uni00000048/uni00000003/uni00000020/uni00000003/uni00000047/uni00000048/uni00000059\n/uni00000028/uni00000031/uni0000002b/uni0000002c/uni00000027/uni00000028\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000058/uni00000044/uni0000004a/uni00000048\n/uni00000049/uni0000004c/uni0000004f/uni00000048/uni00000042/uni00000057/uni0000005c/uni00000053/uni00000048/uni00000003/uni00000020/uni00000003/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051\n/uni00000028/uni00000031/uni0000002b/uni0000002c/uni00000027/uni00000028\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000058/uni00000044/uni0000004a/uni00000048\n/uni00000049/uni0000004c/uni0000004f/uni00000048/uni00000042/uni00000057/uni0000005c/uni00000053/uni00000048/uni00000003/uni00000020/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n/uni0000004f/uni00000044/uni00000045/uni00000048/uni0000004f\n/uni0000002b/uni00000024/uni00000037/uni00000028\n/uni00000032/uni00000029/uni00000029/uni00000031\n/uni00000033/uni00000035/uni00000029/uni00000031\n(b) sub-task B\n/uni00000028/uni00000031/uni0000002b/uni0000002c/uni00000027/uni00000028\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000058/uni00000044/uni0000004a/uni00000048\n/uni00000013/uni00000011/uni00000013/uni00000013\n/uni00000013/uni00000011/uni00000015/uni00000018\n/uni00000013/uni00000011/uni00000018/uni00000013\n/uni00000013/uni00000011/uni0000001a/uni00000018\n/uni00000014/uni00000011/uni00000013/uni00000013/uni00000049/uni00000014/uni00000010/uni00000056/uni00000046/uni00000052/uni00000055/uni00000048\n/uni00000049/uni0000004c/uni0000004f/uni00000048/uni00000042/uni00000057/uni0000005c/uni00000053/uni00000048/uni00000003/uni00000020/uni00000003/uni00000047/uni00000048/uni00000059\n/uni00000028/uni00000031/uni0000002b/uni0000002c/uni00000027/uni00000028\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000058/uni00000044/uni0000004a/uni00000048\n/uni00000049/uni0000004c/uni0000004f/uni00000048/uni00000042/uni00000057/uni0000005c/uni00000053/uni00000048/uni00000003/uni00000020/uni00000003/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051\n/uni00000028/uni00000031/uni0000002b/uni0000002c/uni00000027/uni00000028\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000058/uni00000044/uni0000004a/uni00000048\n/uni00000049/uni0000004c/uni0000004f/uni00000048/uni00000042/uni00000057/uni0000005c/uni00000053/uni00000048/uni00000003/uni00000020/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n/uni0000004f/uni00000044/uni00000045/uni00000048/uni0000004f\n/uni00000037/uni0000002c/uni00000031\n/uni00000038/uni00000031/uni00000037\n(c) sub-task C\nFig. 3: Variation in label F1-scores for all sub-tasks across all models\n4.2 Error analysis\nAfter identifying the best model and the variation in evaluation scores for each\nmodel, we investigate the overall performance of these models for each label\nbelonging to each task. In Figure 3, we can observe how the various labels\nhave a high variance in their predictive performance.\n4.2.1 Sub-Task A\nFor English, the models show decent variation for both the labels on the train-\ning set. However, this variation is not as signiﬁcant for the dev and test sets\nfor the (NOT) label. There is an appreciable variation for (HOF) label on\nthe dev set, but it is not transferred to the test set. The scores for the train\nsets is very high compared to the dev and test sets. For Hindi, the predictions\nfor both the labels show minimum variation in the F1-score across the three\n20 Sudhanshu Mishra et al.\ndata-sets, with similar scores for each label. For German, the F1-scores for\nthe (NOT) class is quite high compared to that of (HOF) class. The models,\nhave a very low F1-score for the (HOF) label on the test set with appreciable\nvariation across the diﬀerent models.\n4.2.2 Sub-Task B\nFor English, the F1-scores for all the labels are quite high on the train set\nwith decent variation for the (OFFN) label. All of the labels show apprecia-\nble variance on the dev and test sets. The (OFFN) has the lowest F1-score\namongst the labels on both the dev and test sets with the other two labels\nhaving similar scores for the test set. For Hindi, the train F1-scores are similar\nfor all of the labels. The F1-scores are on the lower end for the (HATE) and\n(OFFN) labels on the dev set with appreciable variance across the models.\nThis may be due to the fact that the Hindi dev set contains very few samples\nfrom these two labels. For German, the variation among the F1-scores is high\nacross all the three sets. The (HATE) label and the (OFFN) label have a\nlarge variation in their F1-scores across the models on the dev and test set re-\nspectively. The F1-score for the (OFFN) label is much higher than the other\nlabels on the test set.\n4.2.3 Sub-Task C\nFor English, the (UNT) label has exceptionally high variance across the mod-\nels for the train set. This is due to the exceptionally low scores by the (BT)\n(ALL) (D) model. This label has extremely low F1-score on the dev set. Fur-\nthermore, there is also large variation in the (TIN) scores across the models\nin all the sets.\nFor Hindi, the (TIN) label has similar F1-scores with large variations\nacross the models on all of the three sets. However, the (UNT) label has\nsmall variance across the models on the dev and test sets.\n4.2.4 Back Translation\nWe also looked at the issue with back-translated results. In order to assess the\nback-translated data we looked at the new words added and removed from\na sentence after back-translation. Aggregating these words over all sentences\nwe ﬁnd that the top words which are often removed and introduced are stop\nwords, e.g. the, of, etc. In order to remove these stop words from our analysis\nand assess the salient words introduced and removed per label we remove the\noverall top 50 words from the introduced and removed list aggregated over\neach label. This highlights words which are often removed from oﬀensive and\nhateful labels are indeed oﬀensive words. A detailed list of words for English\nand German can be found in appendix .2 (we excluded results for Hindi because\nof Latex encoding issues).\nMulti-task multi-lingual hate speech identiﬁcation 21\n5 Discussion\n5.1 Computational beneﬁts\nFrom the results mentioned above, we can easily conclude that multi-task mod-\nels present us with robust models for hate speech detection that can generalize\nwell across diﬀerent languages and diﬀerent tasks for a given domain. Even the\ncombined models, present us with models that can be deployed easily and give\ncompetitive performance on diﬀerent languages with an eﬃcient computation\nbudget. Many of our models, perform better than the best scoring models of\nHASOC 2019 while maintaing a low inference cost.\n5.2 Additional evaluation\nOur current evaluation was limited to the HASOC dataset, additional evalua-\ntion needs to be done to assess out of domain and out of language capabilities\nof these techniques. Furthermore, the back-translation approach needs to be\nassessed even further using qualitative analysis of generated back-translations.\n5.3 Architectures and Training improvements\nThere are additional combination of architectures which we plan to try in\nfuture iterations of this work. Some of the combinations which we have not\nconsidered in this work are the (BT) (MTL) models and the (BT) (MTL)\n(ALL) models. We have seen that the (ALL) and (BT) models work well\nin unison and the (MTL) (ALL) models also give competitive performance\nwith the (MTL) model. Therefore, a (BT) (MTL) (ALL) model is expected to\nbring out the best of both worlds. The (MTL) models we have used can still\nbe tuned further, which may increase their results on the test sets. We trained\n(ALL) (MTL) model for 15 epochs instead of the usual 5, but it over-ﬁtted the\ntraining set. Further experiments have to be conducted to identify the ideal\ntraining time for these models.\n5.4 Real world usage\nEven though our models have performed really well on the HASOC dataset,\nyet the results are far from ideal. Given that HASOC dataset is quite small, our\nmodels may not generalize well outside of the domain of HASOC, however, our\nfocus was on assessing the improvements we get using our multi-task and multi-\nlingual techniques on this datasets. We also conducted similar experiments in\nour work for the TRAC 2020 dataset Mishra et al. (2020b). In order to make\nthese model more robust for general purpose hate-speech detection we need to\ntrain it on more-diverse and larger dataset. Furthermore, we also would like to\nhighlight that our models need to be further evaluated for demographic bias\n22 Sudhanshu Mishra et al.\nas it has been found in Davidson et al. (2019) that hate speech and abusive\nlanguage datasets exhibit racial bias towards African American English usage.\n6 Conclusion\nWe would like to conclude this paper by highlighting the promise shown by\nmulti-lingual and multi-task models on solving the hate and abusive speech\ndetection in a computationally eﬃcient way while maintaining comparable\naccuracy of single task models. We do highlight that our pre-trained models\nneed to be further evaluated before being used on large scale, however the\narchitecture and the training framework is something which can easily scale to\nlarge dataset without sacriﬁcing performance as was shown in Mishra (2020b,a,\n2019).\nCompliance with Ethical Standards\nConﬂict of Interest: The authors declare that they have no conﬂict of interest.\nReferences\nBadjatiya, P., Gupta, S., Gupta, M., and Varma, V. (2017). Deep learning\nfor hate speech detection in tweets. In Proceedings of the 26th International\nConference on World Wide Web Companion , WWW ’17 Companion, page\n759–760, Republic and Canton of Geneva, CHE. International World Wide\nWeb Conferences Steering Committee.\nBashar, M. A. and Nayak, R. (2020). Qutnocturnal@ hasoc’19: Cnn for hate\nspeech and oﬀensive content identiﬁcation in hindi language. arXiv preprint\narXiv:2008.12448.\nBasile, V., Bosco, C., Fersini, E., Nozza, D., Patti, V., Rangel Pardo, F. M.,\nRosso, P., and Sanguinetti, M. (2019). SemEval-2019 task 5: Multilingual\ndetection of hate speech against immigrants and women in twitter. In Pro-\nceedings of the 13th International Workshop on Semantic Evaluation , pages\n54–63, Minneapolis, Minnesota, USA. Association for Computational Lin-\nguistics.\nBurnap, P. and Williams, M. L. (2015). Cyber hate speech on twitter: An\napplication of machine classiﬁcation and statistical modeling for policy and\ndecision making. Policy & Internet , 7(2):223–242.\nDavidson, T., Bhattacharya, D., and Weber, I. (2019). Racial Bias in Hate\nSpeech and Abusive Language Detection Datasets. In Proceedings of the\nThird Workshop on Abusive Language Online , pages 25–35, Stroudsburg,\nPA, USA. Association for Computational Linguistics.\nDavidson, T., Warmsley, D., Macy, M. W., and Weber, I. (2017). Automated\nhate speech detection and the problem of oﬀensive language. In Proceedings\nof the International AAAI Conference on Web and Social Media 2017 .\nMulti-task multi-lingual hate speech identiﬁcation 23\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2019). BERT: Pre-\ntraining of deep bidirectional transformers for language understanding. In\nProceedings of the 2019 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technologies,\nVolume 1 (Long and Short Papers) , pages 4171–4186, Minneapolis, Min-\nnesota. Association for Computational Linguistics.\nDuggan, M., Smith, A., and Caiazza, T. (2017). Online Harassment 2017.\nTechnical report, Pew Research Center.\nEisenstein, J. (2013). What to do about bad language on the internet. In\nProceedings of the 2013 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technologies ,\npages 359–369, Atlanta, Georgia. Association for Computational Linguistics.\nFlorio, K., Basile, V., Polignano, M., Basile, P., and Patti, V. (2020). Time of\nyour hate: The challenge of time in hate speech detection on social media.\nApplied Sciences, 10(12):4180.\nGomez, R., Gibert, J., Gomez, L., and Karatzas, D. (2020). Exploring hate\nspeech detection in multimodal publications. In 2020 IEEE Winter Confer-\nence on Applications of Computer Vision (WACV) , pages 1459–1467.\nJoulin, A., Grave, E., Bojanowski, P., and Mikolov, T. (2017). Bag of tricks\nfor eﬃcient text classiﬁcation. In Proceedings of the 15th Conference of the\nEuropean Chapter of the Association for Computational Linguistics: Volume\n2, Short Papers , pages 427–431, Valencia, Spain. Association for Computa-\ntional Linguistics.\nKiela, D., Firooz, H., Mohan, A., Goswami, V., Singh, A., Ringshia, P., and\nTestuggine, D. (2020). The hateful memes challenge: Detecting hate speech\nin multimodal memes.\nKoehn, P. (2005). Europarl : A Parallel Corpus for Statistical Machine Trans-\nlation. MT Summit.\nKumar, R., Ojha, A. K., Malmasi, S., and Zampieri, M. (2018). Benchmarking\naggression identiﬁcation in social media. In Proceedings of the First Work-\nshop on Trolling, Aggression and Cyberbullying (TRAC-2018) , pages 1–11,\nSanta Fe, New Mexico, USA. Association for Computational Linguistics.\nKumar, R., Ojha, A. K., Malmasi, S., and Zampieri, M. (2020). Evaluating ag-\ngression identiﬁcation in social media. In Kumar, R., Ojha, A. K., Lahiri, B.,\nZampieri, M., Malmasi, S., Murdock, V., and Kadar, D., editors,Proceedings\nof the Second Workshop on Trolling, Aggression and Cyberbullying (TRAC-\n2020), Paris, France. European Language Resources Association (ELRA).\nLe, Q. V. and Mikolov, T. (2014). Distributed representations of sentences\nand documents. CoRR, abs/1405.4053.\nLiu, P., Qiu, X., and Huang, X. (2016). Deep Multi-Task Learning with Shared\nMemory for Text Classiﬁcation. In Proceedings of the 2016 Conference on\nEmpirical Methods in Natural Language Processing, pages 118–127, Strouds-\nburg, PA, USA. Association for Computational Linguistics.\nMandl, T., Modha, S., Majumder, P., Patel, D., Dave, M., Mandlia, C., and\nPatel, A. (2019). Overview of the hasoc track at ﬁre 2019: Hate speech and\noﬀensive content identiﬁcation in indo-european languages. In Proceedings\n24 Sudhanshu Mishra et al.\nof the 11th Forum for Information Retrieval Evaluation , FIRE ’19, page\n14–17, New York, NY, USA. Association for Computing Machinery.\nMishra, S. (2019). Multi-dataset-multi-task Neural Sequence Tagging for Infor-\nmation Extraction from Tweets. InProceedings of the 30th ACM Conference\non Hypertext and Social Media - HT ’19 , pages 283–284, New York, New\nYork, USA. ACM Press.\nMishra, S. (2020a). Information Extraction from Digital Social Trace Data\nwith Applications to Social Media and Scholarly Communication Data.\nACM SIGIR Forum, 54(1).\nMishra, S. (2020b). Information Extraction from Digital Social Trace Data\nwith Applications to Social Media and Scholarly Communication Data . PhD\nthesis, University of Illinois at Urbana-Champaign.\nMishra, S. (2020c). Non-neural Structured Prediction for Event Detection\nfrom News in Indian Languages. In Mehta, P., Mandl, T., Majumder, P.,\nand Mitra, M., editors, Working Notes of FIRE 2020 - Forum for Informa-\ntion Retrieval Evaluation, Hyderabad, India. CEUR Workshop Proceedings,\nCEUR-WS.org.\nMishra, S., Agarwal, S., Guo, J., Phelps, K., Picco, J., and Diesner, J. (2014).\nEnthusiasm and support: alternative sentiment classiﬁcation for social move-\nments on social media. In Proceedings of the 2014 ACM conference on Web\nscience - WebSci ’14 , pages 261–262, Bloomington, Indiana, USA. ACM\nPress.\nMishra, S. and Diesner, J. (2016). Semi-supervised Named Entity Recognition\nin noisy-text. In Proceedings of the 2nd Workshop on Noisy User-generated\nText (WNUT), pages 203–212, Osaka, Japan. The COLING 2016 Organizing\nCommittee.\nMishra, S. and Diesner, J. (2019). Capturing Signals of Enthusiasm and Sup-\nport Towards Social Issues from Twitter. In Proceedings of the 5th Inter-\nnational Workshop on Social Media World Sensors - SIdEWayS’19 , pages\n19–24, New York, New York, USA. ACM Press.\nMishra, S. and Mishra, S. (2019). 3Idiots at HASOC 2019: Fine-tuning Trans-\nformer Neural Networks for Hate Speech Identiﬁcation in Indo-European\nLanguages. In Proceedings of the 11th annual meeting of the Forum for\nInformation Retrieval Evaluation , pages 208–213, Kolkata, India.\nMishra, S., Prasad, S., and Mishra, S. (2020a). Model and predictions for\nmulti-task multi-lingual learning of transformer models for hate speech and\noﬀensive speech identiﬁcation in social media. Accessible at: https://doi.\norg/10.13012/B2IDB-3565123_V1.\nMishra, S., Prasad, S., and Mishra, S. (2020b). Multilingual Joint Fine-tuning\nof Transformer models for identifying Trolling,Aggression and Cyberbully-\ning at TRAC 2020. In Proceedings of the Second Workshop on Trolling,\nAggression and Cyberbullying (TRAC-2020) .\nMondal, M., Silva, L. A., and Benevenuto, F. (2017). A Measurement Study\nof Hate Speech in Social Media. In Proceedings of the 28th ACM Conference\non Hypertext and Social Media - HT ’17, pages 85–94, New York, New York,\nUSA. ACM Press.\nMulti-task multi-lingual hate speech identiﬁcation 25\nMozafari, M., Farahbakhsh, R., and Crespi, N. (2020). A bert-based transfer\nlearning approach for hate speech detection in online social media. In Cher-\niﬁ, H., Gaito, S., Mendes, J. F., Moro, E., and Rocha, L. M., editors, Com-\nplex Networks and Their Applications VIII , pages 928–940, Cham. Springer\nInternational Publishing.\nMujadia, V., Mishra, P., and Sharma, D. M. (2019). Iiit-hyderabad at hasoc\n2019: Hate speech detection.\nPerrin, A. (2015). Social Media Usage:2005-2015. Technical report, Pew Re-\nsearch Center.\nPlank, B. (2017). All-in-1 at IJCNLP-2017 task 4: Short text classiﬁcation\nwith one model for all languages. In Proceedings of the IJCNLP 2017,\nShared Tasks, pages 143–148, Taipei, Taiwan. Asian Federation of Natural\nLanguage Processing.\nRanasinghe, T. and Zampieri, M. (2020). Multilingual oﬀensive language iden-\ntiﬁcation with cross-lingual embeddings. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language Processing (EMNLP) ,\npages 5838–5844, Online. Association for Computational Linguistics.\nRazavi, A. H., Inkpen, D., Uritsky, S., and Matwin, S. (2010). Oﬀensive lan-\nguage detection using multi-level classiﬁcation. In Proceedings of the 23rd\nCanadian Conference on Advances in Artiﬁcial Intelligence , AI’10, page\n16–27, Berlin, Heidelberg. Springer-Verlag.\nRisch, J. and Krestel, R. (2018). Aggression identiﬁcation using deep learning\nand data augmentation. In Proceedings of the First Workshop on Trolling,\nAggression and Cyberbullying (co-located with COLING) , pages 150–158.\nRisch, J. and Krestel, R. (2020). Bagging bert models for robust aggression\nidentiﬁcation. In Proceedings of the Workshop on Trolling, Aggression and\nCyberbullying (TRAC@LREC).\nRuiter, D., Rahman, M. A., and Klakow, D. (2019). Lsv-uds at HASOC 2019:\nThe problem of deﬁning hate. In Mehta, P., Rosso, P., Majumder, P., and\nMitra, M., editors, Working Notes of FIRE 2019 - Forum for Information\nRetrieval Evaluation, Kolkata, India, December 12-15, 2019 , volume 2517\nof CEUR Workshop Proceedings, pages 263–270. CEUR-WS.org.\nSaha, P., Mathew, B., Goyal, P., and Mukherjee, A. (2019). Hatemonitors:\nLanguage agnostic abuse detection in social media.\nSalminen, J., Almerekhi, H., Milenkovi´ c, M., gyo Jung, S., An, J., Kwak, H.,\nand Jansen, B. (2018). Anatomy of online hate: Developing a taxonomy and\nmachine learning models for identifying and classifying hate in online news\nmedia.\nSchmidt, A. and Wiegand, M. (2017). A Survey on Hate Speech Detection\nusing Natural Language Processing. InProceedings of the Fifth International\nWorkshop on Natural Language Processing for Social Media , pages 1–10,\nStroudsburg, PA, USA. Association for Computational Linguistics.\nSennrich, R., Haddow, B., and Birch, A. (2016). Improving Neural Machine\nTranslation Models with Monolingual Data. In Proceedings of the 54th An-\nnual Meeting of the Association for Computational Linguistics (Volume 1:\nLong Papers), pages 86–96, Stroudsburg, PA, USA. Association for Compu-\n26 Sudhanshu Mishra et al.\ntational Linguistics.\nSøgaard, A. and Goldberg, Y. (2016). Deep multi-task learning with low level\ntasks supervised at lower layers. In Proceedings of the 54th Annual Meeting\nof the Association for Computational Linguistics (Volume 2: Short Papers) ,\npages 231–235. Association for Computational Linguistics.\nSticca, F. and Perren, S. (2013). Is Cyberbullying Worse than Traditional\nBullying? Examining the Diﬀerential Roles of Medium, Publicity, and\nAnonymity for the Perceived Severity of Bullying. Journal of Youth and\nAdolescence, 42(5):739–750.\nStruß, J., Siegel, M., Ruppenhofer, J., Wiegand, M., and Klenner, M. (2019).\nOverview of germeval task 2, 2019 shared task on the identiﬁcation of of-\nfensive language. In KONVENS.\nVan Hee, C., Lefever, E., Verhoeven, B., Mennes, J., Desmet, B., De Pauw, G.,\nDaelemans, W., and Hoste, V. (2015). Detection and ﬁne-grained classiﬁca-\ntion of cyberbullying events. In Angelova, G., Bontcheva, K., and Mitkov,\nR., editors, Proceedings of Recent Advances in Natural Language Processing,\nProceedings, pages 672–680.\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,\nKaiser,  L., and Polosukhin, I. (2017). Attention is all you need. InAdvances\nin neural information processing systems , pages 5998–6008.\nVidgen, B., Harris, A., Nguyen, D., Tromble, R., Hale, S., and Margetts, H.\n(2019). Challenges and frontiers in abusive content detection. InProceedings\nof the Third Workshop on Abusive Language Online , pages 80–93, Florence,\nItaly. Association for Computational Linguistics.\nWang, B., Ding, Y., Liu, S., and Zhou, X. (2019). Ynu wb at hasoc 2019: Or-\ndered neurons lstm with attention for identifying hate speech and oﬀensive\nlanguage.\nWang, C. (2018). Interpreting neural network hate speech classiﬁers. In Pro-\nceedings of the 2nd Workshop on Abusive Language Online (ALW2) , pages\n86–92, Brussels, Belgium. Association for Computational Linguistics.\nWaseem, Z., Davidson, T., Warmsley, D., and Weber, I. (2017). Understanding\nabuse: A typology of abusive language detection subtasks. In Proceedings of\nthe First Workshop on Abusive Language Online , pages 78–84, Vancouver,\nBC, Canada. Association for Computational Linguistics.\nWolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac,\nP., Rault, T., Louf, R., Funtowicz, M., and Brew, J. (2019). Huggingface’s\ntransformers: State-of-the-art natural language processing.\nYang, F., Peng, X., Ghosh, G., Shilon, R., Ma, H., Moore, E., and Predovic, G.\n(2019). Exploring deep multimodal fusion of text and photo for hate speech\nclassiﬁcation. In Proceedings of the Third Workshop on Abusive Language\nOnline, pages 11–18, Florence, Italy. Association for Computational Lin-\nguistics.\nZampieri, M., Malmasi, S., Nakov, P., Rosenthal, S., Farra, N., and Kumar,\nR. (2019). SemEval-2019 task 6: Identifying and categorizing oﬀensive lan-\nguage in social media (OﬀensEval). In Proceedings of the 13th International\nWorkshop on Semantic Evaluation , pages 75–86, Minneapolis, Minnesota,\nMulti-task multi-lingual hate speech identiﬁcation 27\nUSA. Association for Computational Linguistics.\nAppendix\n.1 Label Distribution\n/uni00000031/uni00000032/uni00000037/uni0000002b/uni00000032/uni00000029\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000024\n/uni00000013\n/uni00000018/uni00000013/uni00000013\n/uni00000014/uni00000013/uni00000013/uni00000013\n/uni00000014/uni00000018/uni00000013/uni00000013\n/uni00000015/uni00000013/uni00000013/uni00000013\n/uni00000015/uni00000018/uni00000013/uni00000013\n/uni00000016/uni00000013/uni00000013/uni00000013\n/uni00000016/uni00000018/uni00000013/uni00000013/uni0000004c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000056\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000028/uni00000031/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051\n/uni00000031/uni00000032/uni00000037/uni0000002b/uni00000032/uni00000029\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000024\n/uni00000013\n/uni00000018/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000018/uni00000013\n/uni00000015/uni00000013/uni00000013\n/uni00000015/uni00000018/uni00000013\n/uni00000016/uni00000013/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000028/uni00000031/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000047/uni00000048/uni00000059\n/uni00000031/uni00000032/uni00000037/uni0000002b/uni00000032/uni00000029\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000024\n/uni00000013\n/uni00000015/uni00000013/uni00000013\n/uni00000017/uni00000013/uni00000013\n/uni00000019/uni00000013/uni00000013\n/uni0000001b/uni00000013/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000028/uni00000031/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n/uni0000002b/uni00000024/uni00000037/uni00000028/uni00000033/uni00000035/uni00000029/uni00000031/uni00000032/uni00000029/uni00000029/uni00000031\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000025\n/uni00000013\n/uni00000015/uni00000013/uni00000013\n/uni00000017/uni00000013/uni00000013\n/uni00000019/uni00000013/uni00000013\n/uni0000001b/uni00000013/uni00000013\n/uni00000014/uni00000013/uni00000013/uni00000013\n/uni00000014/uni00000015/uni00000013/uni00000013/uni0000004c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000056\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000028/uni00000031/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051\n/uni0000002b/uni00000024/uni00000037/uni00000028/uni00000033/uni00000035/uni00000029/uni00000031/uni00000032/uni00000029/uni00000029/uni00000031\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000025\n/uni00000013\n/uni00000015/uni00000013\n/uni00000017/uni00000013\n/uni00000019/uni00000013\n/uni0000001b/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000015/uni00000013\n/uni00000014/uni00000017/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000028/uni00000031/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000047/uni00000048/uni00000059\n/uni0000002b/uni00000024/uni00000037/uni00000028/uni00000033/uni00000035/uni00000029/uni00000031/uni00000032/uni00000029/uni00000029/uni00000031\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000025\n/uni00000013\n/uni00000015/uni00000013\n/uni00000017/uni00000013\n/uni00000019/uni00000013\n/uni0000001b/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000015/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000028/uni00000031/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n/uni00000037/uni0000002c/uni00000031/uni00000038/uni00000031/uni00000037\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000026\n/uni00000013\n/uni00000015/uni00000018/uni00000013\n/uni00000018/uni00000013/uni00000013\n/uni0000001a/uni00000018/uni00000013\n/uni00000014/uni00000013/uni00000013/uni00000013\n/uni00000014/uni00000015/uni00000018/uni00000013\n/uni00000014/uni00000018/uni00000013/uni00000013\n/uni00000014/uni0000001a/uni00000018/uni00000013\n/uni00000015/uni00000013/uni00000013/uni00000013/uni0000004c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000056\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000028/uni00000031/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051\n/uni00000037/uni0000002c/uni00000031/uni00000038/uni00000031/uni00000037\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000026\n/uni00000013\n/uni00000018/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000018/uni00000013\n/uni00000015/uni00000013/uni00000013\n/uni00000015/uni00000018/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000028/uni00000031/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000047/uni00000048/uni00000059\n/uni00000037/uni0000002c/uni00000031/uni00000038/uni00000031/uni00000037\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000026\n/uni00000013\n/uni00000018/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000018/uni00000013\n/uni00000015/uni00000013/uni00000013\n/uni00000015/uni00000018/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000028/uni00000031/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\nFig. 4: English Data class wise distribution\n28 Sudhanshu Mishra et al.\n/uni00000031/uni00000032/uni00000037/uni0000002b/uni00000032/uni00000029\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000024\n/uni00000013\n/uni00000018/uni00000013/uni00000013\n/uni00000014/uni00000013/uni00000013/uni00000013\n/uni00000014/uni00000018/uni00000013/uni00000013\n/uni00000015/uni00000013/uni00000013/uni00000013\n/uni00000015/uni00000018/uni00000013/uni00000013\n/uni00000016/uni00000013/uni00000013/uni00000013\n/uni00000016/uni00000018/uni00000013/uni00000013/uni0000004c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000056\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000027/uni00000028/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051\n/uni00000031/uni00000032/uni00000037/uni0000002b/uni00000032/uni00000029\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000024\n/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni00000015/uni00000013/uni00000013\n/uni00000016/uni00000013/uni00000013\n/uni00000017/uni00000013/uni00000013\n/uni00000018/uni00000013/uni00000013\n/uni00000019/uni00000013/uni00000013\n/uni0000001a/uni00000013/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000027/uni00000028/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000047/uni00000048/uni00000059\n/uni00000031/uni00000032/uni00000037/uni0000002b/uni00000032/uni00000029\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000024\n/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni00000015/uni00000013/uni00000013\n/uni00000016/uni00000013/uni00000013\n/uni00000017/uni00000013/uni00000013\n/uni00000018/uni00000013/uni00000013\n/uni00000019/uni00000013/uni00000013\n/uni0000001a/uni00000013/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000027/uni00000028/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n/uni00000032/uni00000029/uni00000029/uni00000031/uni0000002b/uni00000024/uni00000037/uni00000028/uni00000033/uni00000035/uni00000029/uni00000031\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000025\n/uni00000013\n/uni00000015/uni00000018\n/uni00000018/uni00000013\n/uni0000001a/uni00000018\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000015/uni00000018\n/uni00000014/uni00000018/uni00000013\n/uni00000014/uni0000001a/uni00000018\n/uni00000015/uni00000013/uni00000013/uni0000004c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000056\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000027/uni00000028/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051\n/uni00000032/uni00000029/uni00000029/uni00000031/uni0000002b/uni00000024/uni00000037/uni00000028/uni00000033/uni00000035/uni00000029/uni00000031\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000025\n/uni00000013\n/uni00000018\n/uni00000014/uni00000013\n/uni00000014/uni00000018\n/uni00000015/uni00000013\n/uni00000015/uni00000018\n/uni00000016/uni00000013\n/uni00000016/uni00000018\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000027/uni00000028/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000047/uni00000048/uni00000059\n/uni00000032/uni00000029/uni00000029/uni00000031/uni0000002b/uni00000024/uni00000037/uni00000028/uni00000033/uni00000035/uni00000029/uni00000031\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000025\n/uni00000013\n/uni00000014/uni00000013\n/uni00000015/uni00000013\n/uni00000016/uni00000013\n/uni00000017/uni00000013\n/uni00000018/uni00000013\n/uni00000019/uni00000013\n/uni0000001a/uni00000013\n/uni0000001b/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni00000027/uni00000028/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\nFig. 5: German Data class wise distribution\n/uni0000002b/uni00000032/uni00000029/uni00000031/uni00000032/uni00000037\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000024\n/uni00000013\n/uni00000018/uni00000013/uni00000013\n/uni00000014/uni00000013/uni00000013/uni00000013\n/uni00000014/uni00000018/uni00000013/uni00000013\n/uni00000015/uni00000013/uni00000013/uni00000013\n/uni00000015/uni00000018/uni00000013/uni00000013/uni0000004c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000056\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni0000002b/uni0000002c/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051\n/uni0000002b/uni00000032/uni00000029/uni00000031/uni00000032/uni00000037\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000024\n/uni00000013\n/uni00000014/uni00000013\n/uni00000015/uni00000013\n/uni00000016/uni00000013\n/uni00000017/uni00000013\n/uni00000018/uni00000013\n/uni00000019/uni00000013\n/uni0000001a/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni0000002b/uni0000002c/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000047/uni00000048/uni00000059\n/uni0000002b/uni00000032/uni00000029/uni00000031/uni00000032/uni00000037\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000024\n/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni00000015/uni00000013/uni00000013\n/uni00000016/uni00000013/uni00000013\n/uni00000017/uni00000013/uni00000013\n/uni00000018/uni00000013/uni00000013\n/uni00000019/uni00000013/uni00000013\n/uni0000001a/uni00000013/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni0000002b/uni0000002c/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n/uni00000033/uni00000035/uni00000029/uni00000031/uni00000032/uni00000029/uni00000029/uni00000031/uni0000002b/uni00000024/uni00000037/uni00000028\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000025\n/uni00000013\n/uni00000015/uni00000013/uni00000013\n/uni00000017/uni00000013/uni00000013\n/uni00000019/uni00000013/uni00000013\n/uni0000001b/uni00000013/uni00000013\n/uni00000014/uni00000013/uni00000013/uni00000013\n/uni00000014/uni00000015/uni00000013/uni00000013/uni0000004c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000056\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni0000002b/uni0000002c/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051\n/uni00000033/uni00000035/uni00000029/uni00000031/uni00000032/uni00000029/uni00000029/uni00000031/uni0000002b/uni00000024/uni00000037/uni00000028\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000025\n/uni00000013\n/uni00000014/uni00000013\n/uni00000015/uni00000013\n/uni00000016/uni00000013\n/uni00000017/uni00000013\n/uni00000018/uni00000013\n/uni00000019/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni0000002b/uni0000002c/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000047/uni00000048/uni00000059\n/uni00000033/uni00000035/uni00000029/uni00000031/uni00000032/uni00000029/uni00000029/uni00000031/uni0000002b/uni00000024/uni00000037/uni00000028\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000025\n/uni00000013\n/uni00000018/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni00000014/uni00000018/uni00000013\n/uni00000015/uni00000013/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni0000002b/uni0000002c/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\n/uni00000037/uni0000002c/uni00000031/uni00000038/uni00000031/uni00000037\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000026\n/uni00000013\n/uni00000015/uni00000013/uni00000013\n/uni00000017/uni00000013/uni00000013\n/uni00000019/uni00000013/uni00000013\n/uni0000001b/uni00000013/uni00000013\n/uni00000014/uni00000013/uni00000013/uni00000013\n/uni00000014/uni00000015/uni00000013/uni00000013\n/uni00000014/uni00000017/uni00000013/uni00000013\n/uni00000014/uni00000019/uni00000013/uni00000013/uni0000004c/uni00000051/uni00000056/uni00000057/uni00000044/uni00000051/uni00000046/uni00000048/uni00000056\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni0000002b/uni0000002c/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051\n/uni00000037/uni0000002c/uni00000031/uni00000038/uni00000031/uni00000037\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000026\n/uni00000013\n/uni00000014/uni00000013\n/uni00000015/uni00000013\n/uni00000016/uni00000013\n/uni00000017/uni00000013\n/uni00000018/uni00000013\n/uni00000019/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni0000002b/uni0000002c/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000047/uni00000048/uni00000059\n/uni00000037/uni0000002c/uni00000031/uni00000038/uni00000031/uni00000037\n/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000042/uni00000026\n/uni00000013\n/uni00000014/uni00000013/uni00000013\n/uni00000015/uni00000013/uni00000013\n/uni00000016/uni00000013/uni00000013\n/uni00000017/uni00000013/uni00000013\n/uni00000018/uni00000013/uni00000013\n/uni0000004f/uni00000044/uni00000051/uni0000004a/uni00000003/uni00000020/uni00000003/uni0000002b/uni0000002c/uni00000003/uni0000005f/uni00000003/uni00000056/uni00000053/uni0000004f/uni0000004c/uni00000057/uni00000003/uni00000020/uni00000003/uni00000057/uni00000048/uni00000056/uni00000057\nFig. 6: Hindi Data class wise distribution\nMulti-task multi-lingual hate speech identiﬁcation 29\n.2 Back translation top changed words\nHere we list the top 5 words per label for each task obtained after removing the top 50\nwords which were either introduced or removed via back translation. We do not list the top\nwords for Hindi because of the encoding issue in Latex.\nListing 1: Changed words in English Training Data\n1 t a s k 1 introduced words\n2 HOF [ ( ’ asset ’ , 30) , (” you ’ re ” , 29) , ( ’ so ’ , 28) , (” i t ’ s ” , 26) , ( ’\nthere ’ , 25) ]\n3 NOT [ ( ’ worldcup2019 ’ , 47) , ( ’ at ’ , 41) , (” i ’m” , 40) , (” i t ’ s ” , 38) ,\n( ’ us ’ , 38) ]\n4 t a s k 1 removed words\n5 HOF [ ( ’ fuck ’ , 52) , ( ’ he ’ s ’ , 43) , ( ’ what ’ , 38) , ( ’ don ’ t ’ , 37) , ( ’\nthem ’ , 36) ]\n6 NOT [ ( ’ happy ’ , 49) , ( ’ than ’ , 47) , ( ’ being ’ , 45) , ( ’ every ’ , 45) , ( ’\nbeen ’ , 43) ]\n7 t a s k 2 introduced words\n8 HATE [ ( ’ there ’ , 17) , ( ’ worldcup2019 ’ , 16) , ( ’ so ’ , 14) , ( ’ because ’ ,\n14) , ( ’ dhoni ’ , 13) ]\n9 NONE [ ( ’ worldcup2019 ’ , 47) , ( ’ at ’ , 41) , (” i ’m” , 40) , (” i t ’ s ” , 38) ,\n( ’ us ’ , 38) ]\n10 OFFN [ ( ’ impeach45 ’ , 11) , ( ’ asset ’ , 11) , ( ’ now ’ , 8) , ( ’ l i e ’ , 6) , ( ’\ntrump2020 ’ , 6) ]\n11 PRFN [ ( ” i t ’ s ” , 16) , ( ’ fucking ’ , 16) , ( ’damn ’ , 14) , ( ’ f ’ , 14) , (”\nyou ’ re ” , 12) ]\n12 t a s k 2 removed words\n13 HATE [ ( ’ which ’ , 20) , ( ’ ground ’ , 20) , ( ’ such ’ , 18) , ( ’ i t s ’ , 18) , (”\ndoesn ’ t ” , 18) ]\n14 NONE [ ( ’ happy ’ , 49) , ( ’ than ’ , 47) , ( ’ being ’ , 45) , ( ’ every ’ , 45) ,\n( ’ been ’ , 43) ]\n15 OFFN [ ( ’ he ’ s ’ , 12) , ( ’ them ’ , 11) , (” he ’ s ” , 9) , ( ’ what ’ , 9) , ( ’ been\n’ , 9) ]\n16 PRFN [ ( ’ fuck ’ , 47) , ( ’ fucking ’ , 21) , ( ’ he ’ s ’ , 16) , ( ’ o f f ’ , 16) , ( ’\ndon ’ t ’ , 15) ]\n17 t a s k 3 introduced words\n18 NONE [ ( ’ worldcup2019 ’ , 47) , ( ’ at ’ , 41) , (” i ’m” , 40) , (” i t ’ s ” , 38) ,\n( ’ us ’ , 38) ]\n19 TIN [ ( ’ asset ’ , 30) , (” you ’ re ” , 27) , ( ’ so ’ , 25) , ( ’ which ’ , 25) , ( ’\nbecause ’ , 25) ]\n20 UNT [ ( ’ f ’ , 8) , ( ’nmy’ , 5) , ( ’ ∗ ∗ ∗’ , 5) , ( ’ there ’ , 4) , ( ’ these ’ , 4) ]\n21 t a s k 3 removed words\n22 NONE [ ( ’ happy ’ , 49) , ( ’ than ’ , 47) , ( ’ being ’ , 45) , ( ’ every ’ , 45) ,\n( ’ been ’ , 43) ]\n23 TIN [ ( ’ fuck ’ , 48) , ( ’ he ’ s ’ , 39) , ( ’ what ’ , 35) , ( ’ don ’ t ’ , 34) , (” he\n’ s ” , 34) ]\n24 UNT [ ( ’ them ’ , 7) , ( ’ f ∗∗∗ ’ , 6) , ( ’ being ’ , 5) , ( ’ such ’ , 5) , ( ’ does ’ ,\n5) ]\nListing 2: Changed words in German Training Data\n1 t a s k 1 introduced words\n2 HOF [ ( ’ ! ! ’ , 15) , ( ’ etwas ’ , 15) , ( ’ diese ’ , 12) , ( ’ sein ’ , 11) , ( ’\nwerden ’ , 11) ]\n3 NOT [ ( ’ einen ’ , 59) , ( ’ j e t z t ’ , 58) , ( ’ war ’ , 57) , ( ’ menschen ’ , 57) ,\n( ’ was ’ , 56) ]\n4 t a s k 1 removed words\n30 Sudhanshu Mishra et al.\n5 HOF [ ( ’ du ’ , 18) , ( ’ wohl ’ , 14) , ( ’ haben ’ , 12) , ( ’ eure ’ , 11) , ( ’ mir\n’ , 11) ]\n6 NOT [ ( ’ wieder ’ , 56) , ( ’ uber ’ , 55) , ( ’vom ’ , 52) , ( ’ haben ’ , 51) , ( ’\neinem ’ , 49) ]\n7 t a s k 2 introduced words\n8 HATE [ ( ’ diese ’ , 6) , ( ’ werden ’ , 5) , ( ’ grun ’ , 4) , ( ’ s o l l t e ’ , 4) , ( ’\nkonnen ’ , 3) ]\n9 NONE [ ( ’ einen ’ , 59) , ( ’ j e t z t ’ , 58) , ( ’ war ’ , 57) , ( ’ menschen ’ , 57) ,\n( ’ was ’ , 56) ]\n10 OFFN [ ( ’ ! ! ’ , 11) , ( ’ sein ’ , 8) , ( ’dumm’ , 8) , ( ’ etwas ’ , 8) , ( ’ sein\n, ’ , 7) ]\n11 PRFN [ ( ’ ich ’ , 6) , ( ’ scheibe ’ , 5) , ( ’ etwas ’ , 5) , ( ’ keine ’ , 5) , ( ’\na l l e ’ , 4) ]\n12 t a s k 2 removed words\n13 HATE [ ( ’ diesen ’ , 5) , ( ’ dass ’ , 5) , ( ’ kann ’ , 4) , ( ’ wohl ’ , 4) , ( ’ also\n’ , 4) ]\n14 NONE [ ( ’ wieder ’ , 56) , ( ’ uber ’ , 55) , ( ’vom ’ , 52) , ( ’ haben ’ , 51) , ( ’\neinem ’ , 49) ]\n15 OFFN [ ( ’ du ’ , 12) , ( ’ nur ’ , 8) , ( ’ muss ’ , 8) , ( ’ eure ’ , 8) , ( ’ haben ’ ,\n7) ]\n16 PRFN [ ( ’ bin ’ , 5) , ( ’ was ’ , 5) , ( ’ wohl ’ , 4) , ( ’ keine ’ , 4) , ( ’ f r e s s e n\n’ , 4) ]",
  "topic": null,
  "concepts": [],
  "institutions": [
    {
      "id": "https://openalex.org/I94234084",
      "name": "Indian Institute of Technology Kanpur",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I157725225",
      "name": "University of Illinois Urbana-Champaign",
      "country": "US"
    }
  ],
  "cited_by": 18
}