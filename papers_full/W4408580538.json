{
  "title": "Gender and content bias in Large Language Models: a case study on Google Gemini 2.0 Flash Experimental",
  "url": "https://openalex.org/W4408580538",
  "year": 2025,
  "authors": [
    {
      "id": null,
      "name": "Balestri, Roberto",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4393946427",
    "https://openalex.org/W4405030052",
    "https://openalex.org/W4287123711",
    "https://openalex.org/W1819662813",
    "https://openalex.org/W6746696776",
    "https://openalex.org/W6721933647",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4248898595",
    "https://openalex.org/W2893425640",
    "https://openalex.org/W4299627282",
    "https://openalex.org/W4220820301",
    "https://openalex.org/W4392011551",
    "https://openalex.org/W3041336306",
    "https://openalex.org/W6948089939",
    "https://openalex.org/W4319334192",
    "https://openalex.org/W2498119267",
    "https://openalex.org/W4386302153",
    "https://openalex.org/W4288408645",
    "https://openalex.org/W6872781554",
    "https://openalex.org/W4287813526",
    "https://openalex.org/W6784152822",
    "https://openalex.org/W4376643691",
    "https://openalex.org/W6876135988",
    "https://openalex.org/W4304183812",
    "https://openalex.org/W4405182693",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2020018978",
    "https://openalex.org/W6741969125",
    "https://openalex.org/W4408930118",
    "https://openalex.org/W3105882417",
    "https://openalex.org/W2764072425",
    "https://openalex.org/W4220752914",
    "https://openalex.org/W4406318333",
    "https://openalex.org/W4252266292"
  ],
  "abstract": "This study evaluates the biases in Gemini 2.0 Flash Experimental, a state-of-the-art large language model (LLM) developed by Google, focusing on content moderation and gender disparities. By comparing its performance to ChatGPT-4o, examined in a previous work of the author, the analysis highlights some differences in ethical moderation practices. Gemini 2.0 demonstrates reduced gender bias, notably with female-specific prompts achieving a substantial rise in acceptance rates compared to results obtained by ChatGPT-4o. It adopts a more permissive stance toward sexual content and maintains relatively high acceptance rates for violent prompts (including gender-specific cases). Despite these changes, whether they constitute an improvement is debatable. While gender bias has been reduced, this reduction comes at the cost of permitting more violent content toward both males and females, potentially normalizing violence rather than mitigating harm. Male-specific prompts still generally receive higher acceptance rates than female-specific ones. These findings underscore the complexities of aligning AI systems with ethical standards, highlighting progress in reducing certain biases while raising concerns about the broader implications of the model's permissiveness. Ongoing refinements are essential to achieve moderation practices that ensure transparency, fairness, and inclusivity without amplifying harmful content.",
  "full_text": null,
  "topic": "Moderation",
  "concepts": [
    {
      "name": "Moderation",
      "score": 0.7179574966430664
    },
    {
      "name": "Harm",
      "score": 0.5997021794319153
    },
    {
      "name": "Psychology",
      "score": 0.5285543203353882
    },
    {
      "name": "Transparency (behavior)",
      "score": 0.48933762311935425
    },
    {
      "name": "Social psychology",
      "score": 0.4658326506614685
    },
    {
      "name": "Computer science",
      "score": 0.2838151454925537
    },
    {
      "name": "Computer security",
      "score": 0.21961113810539246
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I9360294",
      "name": "University of Bologna",
      "country": "IT"
    }
  ]
}