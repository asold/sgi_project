{
    "title": "Combination of n-grams and Stochastic Context-Free Grammars for language modeling",
    "url": "https://openalex.org/W2000869250",
    "year": 2000,
    "authors": [
        {
            "id": "https://openalex.org/A5089241415",
            "name": "José-Miguel Benedí",
            "affiliations": [
                "Universitat Politècnica de València"
            ]
        },
        {
            "id": "https://openalex.org/A5061837815",
            "name": "Joan Andreu Sánchez",
            "affiliations": [
                "Universitat Politècnica de València"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2119907552",
        "https://openalex.org/W278158788",
        "https://openalex.org/W1547416962",
        "https://openalex.org/W1966812932",
        "https://openalex.org/W2949237929",
        "https://openalex.org/W84343910",
        "https://openalex.org/W2439178139",
        "https://openalex.org/W1632114991",
        "https://openalex.org/W17183103",
        "https://openalex.org/W1978470410",
        "https://openalex.org/W2124008567",
        "https://openalex.org/W2144158482",
        "https://openalex.org/W1508165687",
        "https://openalex.org/W1781314407",
        "https://openalex.org/W1512626953",
        "https://openalex.org/W3021713638"
    ],
    "abstract": "This paper describes a hybrid proposal to combine n-grams and Stochastic Context-Free Grammars (SCFGs) for language modeling. A classical n-gram model is used to capture the local relations between words, while a stochastic grammatical model is considered to represent the long-term relations between syntactical structures. In order to define this grammatical model, which will be used on large-vocabulary complex tasks, a category-based SCFG and a probabilistic model of word distribution in the categories have been proposed. Methods for learning these stochastic models for complex tasks are described, and algorithms for computing the word transition probabilities are also presented. Finally, experiments using the Penn Treebank corpus improved by 30% the test set perplexity with regard to the classical n-gram models.",
    "full_text": null
}