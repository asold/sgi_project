{
  "title": "Exploring the Student Perspective: Assessing Technology Readiness and Acceptance for Adopting Large Language Models in Higher Education",
  "url": "https://openalex.org/W4387819663",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2170871200",
      "name": "Claudia Lemke",
      "affiliations": [
        "Berlin School of Economics and Law"
      ]
    },
    {
      "id": "https://openalex.org/A2007835287",
      "name": "Kathrin Kirchner",
      "affiliations": [
        "Technical University of Denmark"
      ]
    },
    {
      "id": "https://openalex.org/A4309231308",
      "name": "Liadan Anandarajah",
      "affiliations": [
        "Humboldt-Universit√§t zu Berlin"
      ]
    },
    {
      "id": "https://openalex.org/A5093100701",
      "name": "Florian Herfurth",
      "affiliations": [
        "Berlin School of Economics and Law"
      ]
    },
    {
      "id": "https://openalex.org/A2170871200",
      "name": "Claudia Lemke",
      "affiliations": [
        "Berlin School of Economics and Law"
      ]
    },
    {
      "id": "https://openalex.org/A5093100701",
      "name": "Florian Herfurth",
      "affiliations": [
        "Berlin School of Economics and Law"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3107263672",
    "https://openalex.org/W4319793302",
    "https://openalex.org/W4367694193",
    "https://openalex.org/W4315874291",
    "https://openalex.org/W4323536358",
    "https://openalex.org/W1791587663",
    "https://openalex.org/W2033943395",
    "https://openalex.org/W4361204578",
    "https://openalex.org/W4220945916",
    "https://openalex.org/W7006481656",
    "https://openalex.org/W2162369966",
    "https://openalex.org/W4318464200",
    "https://openalex.org/W2571044048",
    "https://openalex.org/W3176951880",
    "https://openalex.org/W2036793060",
    "https://openalex.org/W2040467573",
    "https://openalex.org/W4381955194",
    "https://openalex.org/W3048075395",
    "https://openalex.org/W2124293473",
    "https://openalex.org/W4317910584",
    "https://openalex.org/W2059269918",
    "https://openalex.org/W4327874398",
    "https://openalex.org/W6847505539",
    "https://openalex.org/W4366489368",
    "https://openalex.org/W4327918021",
    "https://openalex.org/W6960172453",
    "https://openalex.org/W2112042732",
    "https://openalex.org/W1572210709",
    "https://openalex.org/W4226112058",
    "https://openalex.org/W6848857030",
    "https://openalex.org/W4385468994",
    "https://openalex.org/W4362472309",
    "https://openalex.org/W2094025128",
    "https://openalex.org/W4382653968",
    "https://openalex.org/W4256564441",
    "https://openalex.org/W4391215636",
    "https://openalex.org/W4367590697",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W4313564799",
    "https://openalex.org/W1835007222"
  ],
  "abstract": "Digital technologies are changing and will continue to change how we learn and teach today and in the future. With the latest developments in the field of generative artificial intelligence (AI), particularly large language models (LLMs), the question of using AI-based tools in academic education is ruling the current discussions about the transformative impact of AI in higher education (HE). These discussions range from banning these technologies for learning and teaching in HE to guided study support. This study avoids taking up these multifarious and partly controversial debates. Instead, we show how students perceive using AI-based tools for automated text generation for their studies. Drawing on a synthesis of two theories: the 'Technology Readiness Index' (TRI) and 'Technology Acceptance Model' (TAM). The model is validated based on survey data collected among undergraduate first-semester students (N=111) of a computer science-related study programme in Germany in winter 2022/23. The students had to evaluate their relationship to that new technology focusing on their readiness for technology adoption and acceptance. By analysing the collected data with a partial least squares model, we find that the optimism toward the new technology positively influences technology acceptance, while discomfort with the technology negatively influences perceived ease of use. The paper concludes with recommendations for action for adopting LLMs in HE. A proper investment in building AI skills in academic teaching plays a valuable role in fostering the students' positive attitude and innovativeness towards this new technology. Additionally, there is a need for more education about the risks and challenges of using this technology to reduce the impact of factors such as discomfort on ease of use. This requires a factual discourse, away from the current hype-induced exaggerated and hyperbolic statements, for instance, in developing formal guidance for universities.",
  "full_text": " \nExploring the Student Perspective: Assessing Technology Readiness \nand Acceptance for Adopting Large Language Models in Higher \nEducation \nClaudia Lemke1, Kathrin Kirchner2, Liadan Anandarajah3, Florian N. Herfurth1  \n1Business Information Systems, Berlin School of Economics and Law, Berlin, Germany \n2Department of Technology, Management and Economics, Technical University of Denmark, Lyngby, \nDenmark \n3Computer Science, Humboldt-Universit√§t zu Berlin, Berlin, Germany \nClaudia.lemke@hwr-berlin.de \nkakir@dtu.dk \nliadan.anandarajah@student.hu-berlin.de \ns_herfurth22@stud.hwr-berlin.de \nAbstract: Digital technologies are changing and will continue to change how we learn and teach today and in the future. \nWith the latest developments in the field of generative artificial intelligence (AI), particularly large language models (LLMs), \nthe question of using AI-based tools in academic education is ruling the current discussions about the transformative impact \nof AI in higher education (HE). \nThese discussions range from banning these technologies for learning and teaching in HE to guided study support. This study \navoids taking up these multifarious and partly controversial debates. Instead, we show how students perceive using AI-based \ntools for automated text generation for their studies. Drawing on a synthesis of two theories: the 'Technology Readiness \nIndex' (TRI) and 'Technology Acceptance Model' (TAM). The model is validated based on survey data collected among \nundergraduate first-semester students ( N=111) of a computer science -related study programme in Germany in winter \n2022/23. The students had to evaluate their relationship to that new technology focusing on their readiness for technology \nadoption and acceptance. By analysing the collected data with a partial least squares model, we find that the optimism \ntoward the new technology positively influences technology acceptance, while discomfort with the technology negatively \ninfluences perceived ease of use. The paper concludes with recommendations for action for adopting LLMs in HE. A proper \ninvestment in building AI skills in academic teaching plays a valuable role in fostering the students ' positive attitude and \ninnovativeness towards this new technology. Additionally, there is a need for more education about the risks and challenges \nof using this technology to reduce the impact of factors such as discomfort on ease of use. This requires a factual discourse, \naway from the current hype-induced exaggerated and hyperbolic statements, for instance, in developing formal guidance \nfor universities. \nKeywords: Student Perspective, Technology Readiness, Technology Acceptance, Large Language Models, Higher Education \n1. Introduction \nRecent breakthroughs in generative artificial intelligence (AI) have massively influenced the current AI hype and \nthe discussions about the impact of such a transformative digital technology like AI. Generative AI is an umbrella \nterm for general-purpose systems based on machine learning (ML) and natural language processing (NLP) for \ncreating new content, including text, audio, video, software code or simulations. Such systems use vast amounts \nof data to train their deep neural networks and conceptualise patterns of multimedia-related new content based \non their probabilistic nature, like art, images, movies, music, texts or software programs. A powerful \nrepresentative of these AI systems is the Large Language Models (LLMs). These systems represent \"generative \nmathematical models of statistical distribution of tokens \" (Shanahan, 2022. p. 2) as universal language \nprocessing tools. These pre-trained models are parameterised by a neural network that gets their training data \nfrom the massive amount of publicly available human-generated text. With their ability to provide a probabilistic \ndistribution of word sequences, they are modelling natural language texts based on statistics, information \ntheory, and machine learning (Li, 2022). This transformation process demonstrates the current potential of large \nlanguage models, which empower humans to ask the system questions in natural language (called prompts) and \nreceive answers. LLMs are a new technology, especi ally their usage in (higher) education for teachers and \nlearners. Even though tools already exist to support the writing process, this kind of technology, which might \ntake over the entire creative writing process, is entirely new and unique. This kind of interaction with the system \nleads us to believe that these systems are intelligent and that the results are justifiable. An important debate \nabout the results' trustworthiness, credibility and comprehensibility of generative AI is ongoing. It requires close \nattention and further research, not only in the (higher) education field  (Crawford, Cowling and Allen , 2023; \nBender et al, 2021; Weidinger et al, 2021).  \n156 \nProceedings of the 22nd European Conference on e-Learning, ECEL 2023\nClaudia Lemke et al \n \nOur paper sets a different focus by  investigating how students perceive this new technology, what beh aviour \nand what relationship they develop with this technology by measuring their readiness and acceptance. The long-\nestablished theories of TRI and TAM in information systems research (see Venkatesh, Davis and Moris , 2007) \nare particularly well suited for this investigation and are applied as a combined model for the first time in the \ncontext of LLMs. This paper contributes to making the current debate on the use of LLMs in HE more objective. \nIn particular, we examine  students' willingness to use  these technologies  by surveying 111 first -year \nundergraduate students in a German Higher Education Institution (HE) . The students' perception of LLMs for \ntheir daily study work might shape future action plans for handling the use of LLMs in HE. \n2. Related Work \nThe current hype around the potential uses of LLMs in HE has led to increased research. Kasneci et al (2023) or \nGimpel et al (2023) investigate the opportunities and challenges of LLMs for HE from a teacher's and student's \nperspectives. Farrokhnia et al (2023) or Su and Yang (2023) combine general aspects of generative AI with a \nclose focus on ChatGPT (a specific LLM product) and its adoption in HE. Lim et al (2023) demand attention to the \nparadoxes of generative AI and provide implicatio ns for the future of education from the perspective of \nmanagement educators. Other work is devoted to specific aspects of generative AI in HE, such as Rudolph, Tan \nand Tan (2023) or Savelka et al (2023) about assessments in HE. Further work, such as Chan a nd Hu (2023) or \nSullivan, Kelly and McLaughlan (2023), look mainly at the impact of using LLMs from the student's perspective.  \nMost papers show that generative AI in HE is an emerging technology, especially LLMs, with a broad scope of \nnew applications but also risks and limitations for students and lecturers, which needs further investigation. Our \npaper answers this need by examining how students are prepared to anticipate this new technology based on a \nquantitative survey. We know from information systems research that the user's willingness to interact with a \nnew technology influences the possibilities of technology adoption in an organisational setting. Therefore, our \npaper focusses on the students' behaviour, intentions, and treatment of this new technology. For this purpose, \nwe apply the theory of Technology Readiness Index (TRI) and combine it with the Technology Acceptance Model \n(TAM). These two theories stand as research paradigms to explain technology adoption and ac ceptance, \naccording to Porter and Donthu (2006).  \nWhile TAM predicts individual adoption and use of new technology (Venkatesh and Bala, 2008), TRI focuses on \nthe measurement of technology readiness as \"people‚Äôs propensity to embrace and use new technologie s for \naccomplishing goals in home life and work‚Äù (Parasuraman and Colby , 2015). These theories were initially \ndeveloped separately and used insights from psychology (Levina, 2021) and marketing research (Parasuraman, \n2000). Other works like Lin et al (2005), Lin, Shih and Sher (2007), Walczuch, Lemmink and Streukens (2007) or \nGodoe and Johanson (2012), Koivisto (2016) and Gao et al (2022) show how these two theories can be combined. \nThus, the factors influencing the readiness positively and negatively, according to TRI, compose the exogenous \nvariables that determine the perceived usefulness and ease of use of new technology in terms of TAM. We will \ncall such an integrated framework TRI-TAM. \nCurrent work that deals with the readiness of AI-based systems uses the findings from TRI combined with other \napproaches, especially from 'customer experience ‚Äô research (Alami et al, 2021 or Gao et al , 2022) or only \nfocusing on the investigation of technology acceptance and user experience (Mlekus, 2020). However, we see \nan advantage in applying an integrated model that measures the readiness of users and their influence on the \nacceptance of these new AI-based LLMs. Moreover, past research shows the usefulness of this integrated model. \nTherefore, we apply this approach as a theoretical framework for our study, specifically for the new technology \nof LLMs in HE.  \n3. Theoretical Framework and Hypotheses Development \nThe technology readiness for new technology is represented by positive and negative factors influencing the \nuser‚Äôs willingness to interact with this new technology. According to Parasuraman (2000) and Parasuraman and \nColby (2001, 2015), optimism and innovativeness are contributors that increase an individual‚Äôs readiness, while \ndiscomfort and insecurity as inhibitors show adverse effects on readiness. With a 36 -item scale, TRI measures \n‚Äúpeople‚Äôs propensity to embrace and use new technology for accomplishing goals in home life and at work‚Äù \n(Parasuraman 2000, p. 308).  \nTAM investigates how a technology‚Äôs attributes affe ct an individual ‚Äôs perception of technology (Porter and \nDonthu, 2006). These two primary predictors are perceived usefulness (PU) and perceived ease of use (PEOU) \n157 \nProceedings of the 22nd European Conference on e-Learning, ECEL 2023\nClaudia Lemke et al \n \n(Davis, 1989). According to Davis (1989, p.  320), PU is defined as ‚Äúthe degree to which a per son believes that \nusing a particular system would enhance his or her job performance‚Äù, while PEOU ‚Äúrefers to the degree to which \na person believes that using a particular system would be free of effort‚Äù.  Davis, Bagozzi and Warshaw (1989)  \nshow in the original TAM versions 1 and 2 the influence that PU and PEOU have on behavioural intentions, which \naffect the actual use of new technology. The different applications of the TRI-TAM framework recap this two-\nstage influence of technology acceptance to only one factor, mostly called actual use or use intention.  \nAccording to the different approaches of TRI-TAM, our research study will investigate only one contributor and \none inhibitor factor and their effects of PU and PEOU in terms of LLM adoption in HE. Here, optimism is defined \nas a positive view of new technology, while innovativeness primarily expresses the tendency to be able to take \non a pioneering role with the application of the technology. In contrast, discomfort expr esses a perceived lack \nof control over technology, and insecurity encompasses distrust of technology. (Parasuraman and Colby, 2001).  \nInitial study results on LLM adoption in HE show some main positive aspects: the personalisation of learning or \nadaptive learning (Zhai, 2022; Su and Yang, 2023; Kasneci et al, 2023), the direct support of the writing process \n(Wessels, 2022; Kasneci et al, 2023), dissolving writer‚Äôs blocks (Wessels, 2022) or improving critical thinking and \nproblem-solving (Kasneci , 2023). Furthermore, LLMs can work as tutors and mentors, analys e the learning \nprocess, identify specific learning or educational needs early on (Zhai, 2022; Kasneci et al, 2023), and making \nwork (Su and Yang, 2023). In contrast, the positive aspects of being innovative and taking on a pioneering role \nwith the use of such systems was hardly mentioned as a reason. Positive technology readiness refers to optimism \nor to students ‚Äô hope and confidence that LLMs wil l improve their study work.  The optimistic motives \npredominate the positive factors and therefore we subordinate the as pects of innovativeness to one positive \nfactor and name it Optimism (OP).  \nThe negative factors of TRI reinforce the user's tendency to avoid adopting this new technology. Here, previous \nstudies argue mainly from an ethical point of view ( Tuomi, 2023; Weidinger et al, 2021) and discuss systems \nbased on the functionality of ML and NLP (Chatterjee and Dethlefs, 2023). These include, for example, concerns \nabout the originality and plagiarism of academic work using LLM or, more generally, the dangers of AI-assisted \ncheating (Lim et al, 2023; Milano, McGrane and Leonelli, 2023). The lack of trustworthiness in these systems is \nnot a major issue that negatively influences the perceived usefulness and ease of use of LLMs, which might be \ndue to the current hype around these systems (Hu , 2023). For these reasons, we combine insecurity and \ndiscomfort as an inhibitor for readiness and define only one TRI-related negative factor Discomfort (DI). \n \nFigure 1: The integrated TRI-TAM framework for LLMs in HE (according to Lin et al. 2007; Godeo and \nJohanson 2012; Gao et al. 2022) \nThe TRI-TAM literature defines TRI- related factors as exogenous variables influencing  technology acceptance \n(Lin et al, 2005; Godoe and Johanson , 2012). I n our case, optimism and discomfort are the two exogenous \nvariables that affect the perceived usefulness and ease of use  of LLM adoption in HE. In particular, Gao et al \n(2022); their study of another AI-based new technology argues that a positive attitude towards this technology \nreinforces how, with what intensity and with what success it is used. On the other hand, a negative effect causes \nthe user to feel overwhelmed by the technology because it seems too complicated and complex. The behaviour \nin the use of this technology is thus negatively influenced. Thus, according to these arguments, the strength of \ntechnology acceptance depends essentially on a positively PU and PEOU. In addition, PU is further enhanced by \nthe effects of a PEOU.  Previous findings from TAM (Davis, 1989; Venkatesh and Bala, 2008 ) show that PU  \nrepresents the degree of AU, more so than PEOU. While PEOU tends to reflect experience and voluntariness, PU \ntends to show up in factors such as subjective norms, job relevance , or output quality (Venkatesh and Bala, \n158 \nProceedings of the 22nd European Conference on e-Learning, ECEL 2023\nClaudia Lemke et al \n \n2008). Our theoretical TRI-TAM framework contains two TRI-related factors, one positive, one negative, which \ndifferently influence  the technology acceptance typified as PU and PEOU with the corresponding hypotheses \n(see figure 2 in section 5 ). Based on the above -discussed literature, we pose the following five hypotheses to \ninvestigate the student‚Äôs readiness and acceptance of LLMs in HE (see figure 1):  \nH1. Optimism (OP) has a positive impact on perceived usefulness (PU). \nH2. Discomfort (DI) has a negative impact on perceived usefulness (PU). \nH3. Optimism (OP) has a positive impact on perceived ease of use (PEOU). \nH4: Discomfort (DI) has a negative impact on perceived ease of use (PEOU). \nH5: Perceived ease of use (PEOU) is positively related to perceived usefulness (PU). \n4. Data and methodology \nThe entire study embodied two phases. In the first phase, to get familiar with the tools, the students were asked \nto use LLMs to generate three different texts. In the second phase, which took place from the end of December \n2022 to the beginning of January 2023  and is the focus of this paper, each student must complete a \nquestionnaire. The survey consisted of  45 items taken from the TRI and TAM  literature. The items and their \nstructure closely follow the study design of the Godoe and Johanson (2012) survey and are based on the original \nframeworks by Paras uraman (2000) and Davis (1989). Our questionnaire contains 31 technology belief \nstatements, both positive and negative, related to our defined two readiness factors of OP and DI, our first two \nfactors. The two other factors, PU and PEOU, with a total of tw elve items , complement the questionnaire \nregarding technology acceptance. Each of the 45 items was measured either on a 5 -point or a 7 -point Likert-\nscale.  \n118 students from a bachelor‚Äôs programme in Business Information Systems at a German university of applied \nscience were asked about their attitudes and views on using AI -based automated text generation tools. The \nentire student group consisted of 15.3% women and 84.7% men with an average age of 19.67 years. After \ncleaning the not fully answered surveys f rom the collected data set, a usable sample of N=111 was available. \n77.8% of the students reported having no experience with LLMs prior to the study. They first came into contact \nwith the tools through this study and thus used them for the first time. Only  22.8% had already had their first \nexperience. At the time of data collection, all students used the GPT-3-based playground with a technical \ninterface which allowed tuning the language modelling algorithm and its outputs. The GPT-3 model (Generated \nPre-Trained Transformer 3), founded and operated by the US-American company OpenAI, was the best-known \nand most widely used model at the time of this study. \n \nFigure 2: Selected items for the final TRI-TAM scale according to its Cronbach‚Äôs alpha of the TRI-TAM \nframework for LLMs in HE \n159 \nProceedings of the 22nd European Conference on e-Learning, ECEL 2023\nClaudia Lemke et al \n \n5. Results and Discussion \nPartial Least Squares (PLS) analysis was used to validate the measurement and  structural properties of our \ntheoretical research model. PLS was applied as it tests the properties of the measured items while also analysing \nthe direction and strength of our hypotheses (Hair et al, 2022). The internal consistency was assessed through \nCronbach‚Äôs alpha (see figure 2), composite reliability and Average Variance Expected (AVE).  \n21 items were taken out because of low factor loadings . Only one Cronbach‚Äôs alpha was between 0.6 and 0.7, \nall others had values above 0.7. The relatively high number of excluded items due to low Cronbach alpha¬¥s was \na surprise as all questions were derived from verified scales. However, these scales were never used in \nconnection to LLMs and we asked the questions to a relatively homogeneous group of survey participants. \nThe evaluation of the structural model (inner model) showed that all VIF values were below 3, so no collinearity \nissues could be found. The Standardized Roo t Mean Square Residual (SRMR) index of our m odel is below the \nrecommended upper threshold of 0.1. The recommended criteria of 0.8 for the Normed Fit Index (NFI) has also \nbeen surpassed by our model. Results from the PLS analysis of the structural model, including path coefficients \nand their statistical significance, are illustrated in figure 3. Standard errors were computed by a bootstrapping \nprocedure with 500 re -samples. Our analysis substantiated the hypothesised relationships H1, H3 and H4  by \nempirical evidence. O O has a positive and significant effect on PU (\nùõΩ = 0.755; \tùëù ‚â§ 0.001)\tand PEOU (ùõΩ =\n0.337, ùëù ‚â§ 0.001). Furthermore, DI negatively and significantly influence s PEOU (ùõΩ = ‚àí0.271, ùëù ‚â§ 0.001). \nHowever, DI does not significantly influence PU, and PEOU does not significantly influence PU, so the hypotheses \nH2 and H5 do not hold as figure 3 shows. \n \nFigure 3: Research Model of TRI-TAM framework for LLMs in HE [sample N=111] \n5.1 Optimism and perceived use and perceived ease of use \nThe results from our study confirm the hypotheses that optimism positively influences PU and PEOU. Several \nstudies (Lin et al 2005, Godeo and Johanson, 2012 ) have already demonstrated this connection in examining \nvarious technologies that were new at that time.  \nThe examination of the reliability and validity of the data also showed a high Cronbach's alpha (0.808) for the \nfactor OP, so that only those items with a low factor loading were removed. These items were mainly related to \nstatements addressing motives of innovativeness. We suspect that the homogeneity of the student group with \na similar age and an assumed high affinity for technology through the field of study does not consider a \npioneering role relevant compared with the group's peers. Students prefer using these tools if it simplifies their \ndaily study routine, helps them to fulfil their writing tasks, and thus makes them more efficient. Consequently, \nthese motives strongly impact the perceived usefulness of the tools more than the perceived ease of use. These \ninsights also align with previous research findings (Gimpel et al, 2023; Sullivan, Kelly and McLaughlan, 2023) on \nthe impact of LLMs in HE. \n160 \nProceedings of the 22nd European Conference on e-Learning, ECEL 2023\nClaudia Lemke et al \n \n5.2 Discomfort and perceived use and perceived ease of use \nInterpreting the results regarding the inhibitor factor of DI and its influence on PU and PEOU is more \ncomplicated. In particular, it was necessary to remove items that contained statements about the distrust or \ndangers of such tools. The students' answers were too homogeneous (very high or very low mean). Contrary to \nour expectations, the test of our hypothesis did not reveal a strong negative influence of Discomfort on PU and \nPEOU. We only find a moderate ly negative relationship of DI and PEOU , although w e also hypothesised a \nnegative influence of DI on PU. This is in line with, for example, the findings of Godeo and Johanson (2012, p 41), \nwho argued that discomfort does not have a negative impact on PU because users ‚Äúsee the main value of a \nsystem, regardless of how they handle it‚Äù . We hypothesised negative impact on PU against the backdrop of \nexcessive media attention on LLMs, especially ChatGPT, at the time of conducting the survey. On the one hand, \nthe students used the technical interface of the GPT -3 playground model that helped them to influence the \nunderlying algorithms and understand partly how they are working. On the other hand, when they had to answer \nthe survey, the user-friendly interface for ChatGPT had just launched, causing the hype around LLMs, also in the \neducation field. In particular, the debate about the dangers, risks and the first bans at universities or even \ncountries might have negatively influenced the students. The results of the survey do not confirm this \nassumption. The students did not so much see the dangers or distrust the new technology, but motives such as \nthe concrete functioning or handling of the tool played a determining role in answering the items. Interestingly, \nthe students answered statements about the dangers or risks of these tools or the possibilities of being used by \ngovernments or states for manipulation without impacting their PU. These items also showed low factor loadings \nand were therefore removed. Thus, the assumption we made earlier that the students would be negatively \ninfluenced by adverse reporting and therefore assess the usefulness of such tools differently did not apply. \n5.3 Perceived ease of use and perceived usefulness \nPrior studies argue that perceived ease of use contributes to perceived usefulness (Godeo and Johanson, 2012; \nLin et al 2005). We also followed this assumption but couldn't confirm this hypothesis here. It is, above all, the \noverwhelming simplicity of using these tools that others also see as an argument for their widespread everyday \nuse (Milano, McGrane and Leonelli, 2023; Gimbel et al, 2023). While in past technology adoption there was often \na gap between the usefulness of a tool and its ease of use, it is precisely these new tools of the digital age that \nare enormously easy to use.  \n6. Conclusion \n6.1 Recommendations for Action \nLLMs are regarded as a learning tool from the students‚Äô perspective, serving as aids in simplifying their everyday \nstudies. This should be taken seriously by HE (UNESCO, 2023). In particular, the tools should be integrated into \neveryday teaching, given that students already exhibit high technology readiness and acceptance to use them. \nIt also means that academic writing skills must be integrated into all teaching areas, for example, as a tool to \nstrengthen critical thinking (Milano, McGrane and Leonelli, 2023). Overall, HE teachers should focus on enabling \nspecific AI skills so that students can evaluate the output of the tools. They should be better able to assess the \nlimitations and risks of these tools - as our study showed that students still need more awareness - and they \nshould better understand how these tools work. The origin of the results should become the focus of a more \nsubstantial examination of these tools.  \nOn the one hand, students need to understand that these systems mainly use freely accessible internet sources \nas data for their pre-training (Kasneci et al, 2023). Therefore, the prompt results may lack accuracy in areas with \nnecessary specific expertise or may verge into plagiarism (Lucchi, 2023). On the other hand, these tools tend to \ngenerate speculative content (Bang et al, 2023), emphasizing the urgency  to train students to check the \ncorrectness of content for meaningful everyday pedagogical practice. Additionally, LLMs have several potential \nethical violations like threats to privacy and security, and consequences of bi ases (Dwivedi et al, 2023) and \ndiscrimination, that students should be more aware of when using these tools. The positive attitudes to using \nthese tools are also increasingly reflected in the fact that students use them more and more for examinations, \nespecially for writing academic papers. Here, teachers and HEs are challenged to rethink the existing structures \nand paradigms of exams in academia and look for new innovative evaluation methodologies. All in all, it requires \nguidelines for using these tools so that the perceived positive attitude of the students leads to the reinforcement \n161 \nProceedings of the 22nd European Conference on e-Learning, ECEL 2023\nClaudia Lemke et al \n \nof individual and collective learning success  (Dwivedi et al, 2023) . These guidelines should also clarify the \ndirectives from the teachers' point of view and thus represent a fundamental new institutional document in HE.  \n6.2 Future Research \nFurther research should focus on some different facets. First, the teachers‚Äô perspective should also be examined. \nA comparative study could investigate the extent to which teachers are prepared to adapt to this new technology \nand the factors underpinning their readiness and acceptability.  Second, while our study specifically collected \ndata from information systems students with an inherent curiosity for new technologies, future work could \nencompass a more diverse spectrum of students, including other study subjects like social sciences. This would \nenrich the dataset and facilitate the control of demographic influences. Furthermore, we collected data during \nthe first launch of Large Language Models, where the general risks of these models were not yet seriously \ndiscussed. Future studies should examine the associated ethical challenges and risks more closely. \nOverall, the acceptance measurement of new  technology adoption also shows comparable patterns to \nnumerous past studies, e.g. Saber and Souiden (2010), Koivisto et al (2016), and Gao et al (2022). Optimism (and \ninnovativeness in general) promote a positive attitude towards new technology. At the same time, discomfort \nand uncertainty weaken this attitude and thus influence the usability of new technology and the awareness of \nease of use. Third, this study shows two significant changes requiring further and more extensive investigation, \nespecially in further developing TRI and TAM theories alongside their associated measurement scales. O n the \none hand, the fundamental change in technology use has changed behaviour and attitudes towards new \ntechnologies. Today, ubiquity and omnipresence touch all areas of life and work and thus demand new ways of \nhuman interaction with new technologies , which  generally create a higher level of technology acceptance  to \ndeal with new technologies. On the other hand,  the user-friendliness or usability of modern technologies has \nalso increased highly, so people are more open to using new technologies. These changes can impact how users \nperceive new technologies. These transformative dynamics necessitate reconsidering how users perceive and \nevaluate new technologies, thereby mandating a fundamental reevaluation of the underlying measurement \nscale structure.  \nReferences \nAlami, H., Lehoux, P., Denis, J.L. ... and Fortin, J. P. (2021) ‚ÄúOrganizational readiness for artificial intelligence in health care: \ninsights for decision-making and practice‚Äù, Journal of Health Organization and Management, Vol. 35, No. 1, pp 106‚Äì\n114. \nBang, Y., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., Lovenia, H., Ji, Z., Yu, T., Chung, W., Do, Q. V., Xu, Y., & Fung, P. \n(2023) ‚ÄúA Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity‚Äù. \nArXiv. /abs/2302.04023 \nBender, E. M., Gebru, T., McMillan-Major, A. and Mitchell, S. (2021) ‚ÄúOn the Dangers of Stochastic Parrots: Can Language \nModels Be Too Big?‚Äù, Proceedings of the 2021 ACM conference on fairness, accountability, and transparency, pp 610‚Äì\n623. \nChan, C.K.Y. and Hu, W. (2023). ‚ÄúStudents‚Äô Voices on Generative AI: Perceptions, Benefits, and Challenges in Higher \nEducation‚Äù, arXiv, [online], https://doi.org/10.48550/arxiv.2305.00290. \nChatterjee, J. and Dethlefs, N. (2023) ‚ÄúThis new conversational AI model can be your friend, philosopher, and guide ... and \neven your worst enemy‚Äù, Patterns (N. Y.), Vol. 4, No. 1, article no.: 100676. \nCrawford, J., Cowling, M. and Allen, K.-A. (2023) ‚ÄúLeadership is needed for ethical ChatGPT: Character, assessment, and \nlearning using artificial intelligence (AI)‚Äù, Journal of University Teaching & Learning Practice, Vol. 20, No. 3, Quarterly \nIssue 1, article 02, pp 1‚Äì19. \nDavis, F.D. (1989) ‚ÄúPerceived Usefulness, Perceived Ease of Use, and User Acceptance of Information Technology‚Äù, MIS \nQuarterly, Vol. 13, No. 3, pp 319‚Äì340. \nDavis, F.D., Bagozzi, R.P. and Warshaw, P.R. (1989) ‚ÄúUser Acceptance of Computer Technology: A Comparison of Two \nTheoretical Models‚Äù, Management Science, Vol. 35, No. 8, pp 982‚Äì1003. \nFarrokhnia, M., Banihashem, S.K., Noroozi, O., and Wals, A. (2023) ‚ÄúA SWOT analysis of ChatGPT: Implications for \neducational practice and research‚Äù, Innovations in Education and Teaching International, 2023, pp 1‚Äì15. \nDwivedi, Y. K., Kshetri, N., Hughes, L., Slade, E. L., Jeyaraj, A., Kar, A. K., ... & Wright, R. (2023) ‚Äú‚ÄôSo what if ChatGPT wrote \nit?‚Äô Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for \nresearch, practice and policy.‚Äù International Journal of Information Management, 71, 102642. \nGao, J., Ren, L., Yang, Y., Zhang, D. and Li, L. (2022) ‚ÄúThe impact of artificial intelligence technology stimuli on smart \ncustomer experience and the moderating effect of technology readiness‚Äù, International Journal of Emerging Markets, \nVol. 17, No. 4, pp 1123‚Äì1142. \n162 \nProceedings of the 22nd European Conference on e-Learning, ECEL 2023\nClaudia Lemke et al \n \nGimpel, H., Hall, K., Decker, S. ‚Ä¶ and Vandirk, S. (2023) ‚ÄúUnlocking the power of generative AI models and systems such as \nGPT-4 and ChatGPT for higher education: A Guide for Students and Lecturers‚Äù, Hohenheim Discussion Papers in \nBusiness, Economics and Social Sciences, Vol. 2023, No. 2, pp 1‚Äì46. \nGodoe, P. and Johansen, T. (2012) ‚ÄúUnderstanding adoption of new technologies: Technology readiness and technology \nacceptance as an integrated concept‚Äù, Journal of European psychology students, Vol. 3, No. 1, pp 38‚Äì52. \nHair, J.F., Hult, G.T.M., Ringle, C.M. and Sarstedt, M. (2022) A Primer on Partial Least Squares Structural Equation Modeling \n(PLS-SEM). 3rd ed. Sage Publishing. \nKasneci, E., Se√üler, K., K√ºchemann, S., Bannert, M., Dementieva, D., Fischer, F., ... and Kasneci, G. (2023) ‚ÄúChatGPT for \ngood? On opportunities and challenges of large language models for education‚Äù, Learning and Individual Differences, \nVol. 103, article no.: 102274. \nKoivisto, K., Makkonen, M., Frank, L. and Riekkinen, J. (2016) ‚ÄúExtending the Technology Acceptance Model with Personal \nInnovativeness and Technology Readiness: A Comparison of Three Models‚Äù, BLED 2016: Proceedings of the 29th Bled \neConference. Moderna organizacija, pp 113‚Äì128. \nLevina, N (2021) ‚ÄúAll Information Systems Theory is Grounded Theory‚Äù, MIS Quarterly, Vol. 45, No. 1, pp 489‚Äì494. \nLi, H. (2022) ‚ÄúLanguage models: past, present, and future‚Äù, Communications of the ACM, Vol. 65, No. 7 ,pp 56‚Äì63. \nLim, W.M., Gunasekara, A., Pallant, J.L., Pallant, J.I., Pechenkina, E. (2023) ‚ÄúGenerative AI and the future of education: \nRagnar√∂k or reformation? A paradoxical perspective from management educators‚Äù, The International Journal of \nManagement Education, Vol. 21, No. 2, article no.: 100790. \nLin, C.-H., Shih, H.-Y., Sher, P.J. and Wang, Y.-L. (2005) ‚ÄúConsumer adoption of e-service: integrating technology readiness \nwith the technology acceptance model‚Äù, Technology Management: A Unifying Discipline for Melting the Boundaries, \n2005, pp 483‚Äì488. \nLin, C.H., Shih, H.Y., and Sher, P.J. (2007) ‚ÄúIntegrating technology readiness into technology acceptance: The TRAM model‚Äù, \nPsychology & Marketing, Vol. 24, Issue 7, pp 641‚Äì657. \nMilano, S., McGrane, J.A. and Leonelli, S. (2023) ‚ÄúLarge language models challenge the future of higher education. Nature \nMachine Intelligence, Vol. 5, No. 4, pp 333‚Äì334. \nLucchi, N. (2023) ‚ÄúChatGPT: A Case Study on Copyright Challenges for Generative AI Systems‚Äù. European Journal of Risk \nRegulation, http://dx.doi.org/10.2139/ssrn.4483390 \nMlekus, L., Bentler, D., Paruzel, A., Kato-Beiderwieden, A.L., and Maier, G.W. (2020) ‚ÄûHow to raise technology acceptance: \nuser experience characteristics as technology-inherent determinants‚Äù, Gruppe. Interaktion. Organisation. Zeitschrift \nf√ºr Angewandte Organisationspsychologie (GIO), Vol. 51, No. 3, pp 273‚Äì283. \nParasuraman, A. (2000) ‚ÄúTechnology Readiness Index (TRI), A Multiple-Item Scale to Measure Readiness To Embrace New \nTechnologies‚Äù, Journal of Service Research, Vol. 2, No. 4, pp 307‚Äì320. \nParasuraman, A. and Colby, C.L. (2001) Techno-Ready Marketing. How and Why Your Customers Adopt Technology. The \nFree Press. \nParasuraman, A. and Colby, C.L. (2015) ‚ÄúAn Updated and Streamlined Technology Readiness Index: TRI 2.0‚Äù, Journal of \nService Research, Vol. 18, Issue 1, pp 59‚Äì74. \nPorter, C. E., and Donthu, N. (2006) ‚ÄúUsing the technology acceptance model to explain how attitudes determine Internet \nusage: The role of perceived access barriers and demographics‚Äù, Journal of business research, Vol. 59, No. 9, pp 999‚Äì\n1007. \nRudolph, J., Tan, S. and Tan, S. (2023) ‚ÄúChatGPT: Bullshit spewer or the end of traditional assessments in higher \neducation?‚Äù, Journal of Applied Learning and Teaching, Vol. 6, No. 1, pp 1‚Äì22. \nSaber, C., M., and Souiden, N. (2010) ‚ÄúRethinking the TAM model: time to consider fun.‚Äù Journal of Consumer Marketing, \n27(4), pp 336-344. \nSavelka, J., Agarwal, A., Bogart, C., Song, Y. and Sakr, M. (2023) ‚ÄúCan Generative Pre-trained Transformers (GPT) Pass \nAssessments in Higher Education Programming Courses?‚Äù, arXiv, [online], http://arxiv.org/abs/2303.09325. \nShanahan, M. (2023) ‚ÄúTalking About Large Language Models‚Äù, arXiv, [online], http://arxiv.org/abs/2212.03551. \nSu, J. and Yang, W. (2023) ‚ÄúUnlocking the Power of ChatGPT: A Framework for Applying Generative AI in Education‚Äù, ECNU \nReview of Education, Vol. 0, No. 0, pp 1‚Äì12. \nSullivan, M., Kelly, A. and McLaughlan, P. (2023) ‚ÄúChatGPT in higher education: Considerations for academic integrity and \nstudent learning‚Äù, Journal of Applied Learning and Teaching, Vol. 6, No. 1, pp 1‚Äì10. \nTuomi, I. (2023) ‚ÄúA Framework for Socio-Developmental Ethics in Educational AI‚Äù, Proceedings of the 56th Hawaii \nInternational Conference on System Sciences 2023, pp 6208‚Äì6217. \nUNESCO (2023), ‚ÄúUNESCO unveils new AI roadmap for classrooms‚Äù. United Nations, [online], \nhttps://news.un.org/en/story/2023/05/1137117.  \nVenkatesh, V. and Bala, H. (2008) ‚ÄúTechnology Acceptance Model 3 and a Research Agenda on Interventions‚Äù, Decision \nSciences, Vol. 39, No. 2, pp 273‚Äì315. \nVenkatesh, V., Davis, F. and Morris, M. (2007) ‚ÄúDead Or Alive? The Development, Trajectory And Future Of Technology \nAdoption Research‚Äù, AIS Educator Journal, Vol. 8, No. 4, pp 267‚Äì286. \nWalczuch, R., Lemmink, J. and Streukens, S. (2007) ‚ÄúThe Effect of Service Employees‚Äô Technology Readiness on Technology \nAcceptance‚Äù, Information & Management, Vol. 44, No. 2, pp 206‚Äì215. \nWeidinger, L., Mellor, J., Rauh, M. ‚Ä¶ and Gabriel I. (2021) ‚ÄúEthical and social risks of harm from Language Models‚Äù, arXiv, \n[online], https://arxiv.org/pdf/2112.04359.pdf.  \n163 \nProceedings of the 22nd European Conference on e-Learning, ECEL 2023\nClaudia Lemke et al \n \nWe√üels, D. (2022) ‚ÄûHochschullehre unter dem Einfluss des KI-gest√ºtzten Schreibens‚Äú. Hochschulforum Digitalisierung, \n[online], https://hochschulforumdigitalisierung.de/de/blog/Hochschullehre-KI-gestuetztes-Schreiben. \nZhai, X. (2022) ‚ÄúChatGPT User Experience: Implications for Education‚Äù, SSRN Electronic Journal, [online], \nhttps://ssrn.com/abstract=4312418. \n \n164 \nProceedings of the 22nd European Conference on e-Learning, ECEL 2023",
  "topic": "Perspective (graphical)",
  "concepts": [
    {
      "name": "Perspective (graphical)",
      "score": 0.7538777589797974
    },
    {
      "name": "Mathematics education",
      "score": 0.46879610419273376
    },
    {
      "name": "Technology acceptance model",
      "score": 0.45064079761505127
    },
    {
      "name": "Psychology",
      "score": 0.4184926748275757
    },
    {
      "name": "Computer science",
      "score": 0.4118630588054657
    },
    {
      "name": "Pedagogy",
      "score": 0.3590186536312103
    },
    {
      "name": "Sociology",
      "score": 0.32189178466796875
    },
    {
      "name": "Engineering ethics",
      "score": 0.3209763467311859
    },
    {
      "name": "Engineering",
      "score": 0.21901807188987732
    },
    {
      "name": "Human‚Äìcomputer interaction",
      "score": 0.17063456773757935
    },
    {
      "name": "Artificial intelligence",
      "score": 0.12467828392982483
    },
    {
      "name": "Usability",
      "score": 0.12346681952476501
    }
  ]
}