{
  "title": "Parallel Context Windows for Large Language Models",
  "url": "https://openalex.org/W4385570090",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4207264833",
      "name": "Nir Ratner",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2606741828",
      "name": "Yoav Levine",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2279044859",
      "name": "Yonatan Belinkov",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2917746027",
      "name": "Ori Ram",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4287893610",
      "name": "Inbal Magar",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A343093649",
      "name": "Omri Abend",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5050599602",
      "name": "Ehud Karpas",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A130468041",
      "name": "Amnon Shashua",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4257822710",
      "name": "Kevin Leyton-Brown",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2112924421",
      "name": "Yoav Shoham",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2170240176",
    "https://openalex.org/W2130158090",
    "https://openalex.org/W2963748441",
    "https://openalex.org/W2403947200",
    "https://openalex.org/W2251939518",
    "https://openalex.org/W4221152111",
    "https://openalex.org/W3045492832",
    "https://openalex.org/W2912924812",
    "https://openalex.org/W4287704453",
    "https://openalex.org/W4286953959",
    "https://openalex.org/W3099700870",
    "https://openalex.org/W4224306499",
    "https://openalex.org/W2070246124",
    "https://openalex.org/W2889787757",
    "https://openalex.org/W4287019748",
    "https://openalex.org/W3026404337",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4287207937",
    "https://openalex.org/W3105662186",
    "https://openalex.org/W2890894339",
    "https://openalex.org/W4287026929",
    "https://openalex.org/W3197876970",
    "https://openalex.org/W4252076394",
    "https://openalex.org/W3180230246",
    "https://openalex.org/W2921312604",
    "https://openalex.org/W3156789018",
    "https://openalex.org/W1964613733",
    "https://openalex.org/W2077302143",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2692059227",
    "https://openalex.org/W4385573804",
    "https://openalex.org/W4281401697",
    "https://openalex.org/W2949380545",
    "https://openalex.org/W4320087074",
    "https://openalex.org/W3172943453",
    "https://openalex.org/W3103682594",
    "https://openalex.org/W4311557185",
    "https://openalex.org/W4289598175"
  ],
  "abstract": "Nir Ratner, Yoav Levine, Yonatan Belinkov, Ori Ram, Inbal Magar, Omri Abend, Ehud Karpas, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023.",
  "full_text": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\nVolume 1: Long Papers, pages 6383–6402\nJuly 9-14, 2023 ©2023 Association for Computational Linguistics\nParallel Context Windows for Large Language Models\nNir Ratner Yoav Levine Yonatan Belinkov Ori Ram Inbal Magar Omri Abend\nEhud Karpas Amnon Shashua Kevin Leyton-Brown Yoav Shoham\nAI21 Labs\nnirr@ai21.com\nAbstract\nWhen applied to processing long text, Large\nLanguage Models (LLMs) are limited by their\ncontext window. Existing efforts to address\nthis limitation involve training specialized ar-\nchitectures, and cannot be easily applied to off-\nthe-shelf LLMs. We present Parallel Context\nWindows (PCW), a method that alleviates the\ncontext window restriction for any off-the-shelf\nLLM without further training . The key to the\napproach is to carve a long context into chunks\n(“windows”), restrict the attention mechanism\nto apply only within each window, and re-use\nthe positional embeddings across the windows.\nOur main results test the PCW approach on\nin-context learning with models that range in\nsize between 750 million and 178 billion pa-\nrameters, and show substantial improvements\nfor tasks with diverse input and output spaces.\nWe show additional beneﬁts in other settings\nwhere long context windows may be beneﬁcial:\nmulti-hop questions and retrieval-augmented\nquestion answering with multiple retrieved doc-\numents. Our results highlight Parallel Context\nWindows as a promising method for applying\noff-the-shelf LLMs in a range of settings that\nrequire long text sequences. We make our code\npublicly available at https://github.com/\nai21labs/parallel-context-windows.\n1 Introduction\nA key parameter of a Large Language Model\n(LLM) is its context window , the number of text\ntokens it can process in a forward pass. Cur-\nrent LLM architectures limit the context window\nsize—typically up to several thousand tokens— be-\ncause the global nature of the attention mechanism\nimposes computational costs quadratic in context\nlength. This presents an obstacle to use cases where\nthe LLM needs to process a lot of text, e.g., tack-\nling tasks that require long inputs ( Tay et al. , 2020;\nShaham et al. , 2022), considering large sets of re-\ntrieved documents for open-book question answer-\ning (Karpukhin et al. , 2020; Levine et al. , 2022a,b),\n100\n101\n102\nn-shot Training Examples\n10\n20\n30\n40\n50\n60\n70BANKING77 Accuracy(%)\nSingle Context Window ICL (Regular)\nParallel Context Windows ICL (Ours)\nFigure 1: In-context learning (ICL) accuracy against\nn-shot training examples for the BANKING77 intent\nclassiﬁcation dataset ( Casanueva et al. , 2020) using the\nmodel Jurassic-1-Grande (17B). The blue line shows\nthe improvement in performance as the context window\nis ﬁlled with examples; the orange line shows how our\nParallel Context Windows method, which adds up to\nfour times more training examples, provides a signiﬁ-\ncant boost in performance. The error bars represent the\nstandard deviation across multiple runs, as explained in\nSection 3.1.\nor performing in-context learning ( Brown et al. ,\n2020) when the desired input-output relationship\ncannot be adequately characterized within the con-\ntext window.\nPrevious work has addressed such obstacles\nby training dedicated architectures, e.g., training\nsparse attention mechanisms for long inputs ( Za-\nheer et al. , 2020; Guo et al. , 2021) and Fusion-in-\nDecoder readers for retrieved documents ( Izacard\nand Grave, 2020). However, these architectures are\noften tailored to speciﬁc use cases, and they are\noften constrained in terms of their size as a trade-\noff, in order to facilitate long text consumption. It\nremains an open problem to ﬁnd an effective way\nto allow off-the-shelf LLMs to process text longer\nthan its original context window, without dedicated\ntraining.\nIn this paper, we introduce Parallel Context Win-\n6383\ninput: Ar gen tina brings the cup home.   \nt opic: sports\ninput: Biden wins pr esidency.   \nt opic: politics\ninput: Ne w smart camer a r elea sed.   \nt opic:  t echnology\nSingle Con t e xt Windo w\nP ar allel Con t e xt Windo ws\ninput: W all Str ee t r eports dr ops.  \nt opic: _\nT es t e x ample\ninput: W all Str ee t r eports dr ops.  \nt opic: _\nT es t e x ample\ninput: Ar gen tina brings the cup home.   \nt opic: sports\nFigure 2: An illustration of Parallel Context Windows (PCW) approach, exposing the LLM to text within multiple\ncontext windows during generation. Tokens inside each window attend only to the previous tokens in their window .\nTest example tokens attend to the tokens of all context windows.\ndows (PCW), illustrated in Figure 2, a new ap-\nproach for addressing this problem in any decoder-\nbased LLM 1, and show its efﬁcacy in several se-\ntups. PCW involves splitting long text into multiple\nparallel contexts, each equally accessible during\noutput generation. Doing so consists of two sim-\nple post-hoc modiﬁcations to a pretrained LLM,\nneither of which requires any further training: (1)\nusing sparse masking to allow each context win-\ndow to attend only to itself, while still allowing\nthe generated text to attend to all contexts simul-\ntaneously; and (2) reusing the model’s learned po-\nsitional embeddings within each parallel context\nwindow, sidestepping the problem of extrapolating\npositional embeddings and signaling to the model\nthat each window is equally “close” to the gener-\nated tokens.\nWe conducted an in-depth investigation of the\nextent to which Parallel Context Windows can im-\nprove LLMs’ ability to perform in-context learning\n(Brown et al. , 2020): when a pretrained LLM is\ngiven an input sequence of concatenated “training”\ninput–output pairs representing a task, followed by\n1We will use LLM to refer to decoder-only language mod-\nels.\na single “test” input, it is able to supply the corre-\nsponding test output with high accuracy. Crucially,\nin the setting of in-context learning, the context\nwindow limitation inherently caps the number of\ntraining examples that can be inserted before the\ntest example. This signiﬁcantly limits the applica-\nbility of in-context learning for tasks with long or\nhighly diverse inputs or outputs.\nWe focus on these types of tasks, showing\nthat Parallel Context Windows signiﬁcantly aid in-\ncontext learning of two task families that tend to\nsuffer from low in-context learning performance:\nclassiﬁcation tasks that have many classes and ex-\ntractive question answering tasks. We experiment\nwith Jurassic-1 models ( Lieber et al. , 2021) having\nbetween 7B and 178B parameters and GPT2 mod-\nels ( Radford et al. , 2019) having between 750M\nand 1.5B parameters. Notably, using 3 Parallel\nContext Windows leads to average performance\ngains of 6.7, 7.3, and 7.9 points in the in-context\nlearning scores of classiﬁcation tasks with over 5\nclasses for Jurassic-1 models of sizes 7B, 17B, and\n178B, respectively (see example in Figure 1). Our\nresults show that Parallel Context Windows broad-\nens the scope of tasks that can be learned via the\n6384\nContext   \nWindow 1\nContext   \nWindow 2\nContext   \nWindow 3\nT ask T okens\np1, p2, ... , pC\np1, p2, ... , pC\npC + 1, ... , pC + T\nPCW Attention Mask & Position Embeddings\nFigure 3: Attention pattern and positional embeddings\nassignment in PCW. The (i, j) cell in the matrix is col-\nored iff the ith token can attend to the jth token. Each\ncontext window (in grey) attends to itself and is assigned\npositional embeddings ( ⃗ pi) independently, thus re-using\nthe positional vectors. Task tokens (in blue) attend to all\nthe windows. PCW makes the attention matrix sparser,\neffectively parallelizing the processing of multiple win-\ndows.\npopular setup of in-context learning, to tasks that\nrequire more training examples than permitted in\ncurrent context sizes.\nWe further explore the applicability of PCW to\ntwo other settings that may beneﬁt from the integra-\ntion of several documents. One is multi-hop ques-\ntion answering, where the different pieces of infor-\nmation are shown in different windows. We show\nthat in some cases parallel reading is beneﬁcial,\nthrough a test case on the HotpotQA benchmark\n(Yang et al. , 2018). The other setting is retrieval-\naugmented question answering, where we show\nthat reading several retrieved documents in parallel\nis advantageous, through a test case on the Natural\nQuestions benchmark ( Kwiatkowski et al. , 2019).\nOverall, we provide clear evidence that, with-\nout any further training, Parallel Context Windows\ncan make a large amount of text accessible to an\noff-the-shelf LLM during decoding. We thus see\npromise in further investigation of Parallel Context\nWindows for applying off-the-shelf LLMs in other\napplications that require such capabilities, such as\ntackling tasks with long inputs.\n2 Parallel Context Windows\nThis section provides the details of our Parallel\nContext Windows method. The high-level idea of\nPCW is to insert a long input sequence into multiple\nreplicas of the LLM’s original context window, and\nto allow for a small amount of tokens at the end of\nthe sequence to attend to all of the context windows\nsimultaneously. We design PCW so that the mod-\niﬁcations made to the off-the-shelf LLM are min-\nimal, such that processing long contexts remains\neffective even without further training of the LLM.\nA side advantage is that the LLM modiﬁcations\nrequired for PCW are quite simple to implement.\nSpeciﬁcally, PCW applies two modiﬁcations to two\nmechanisms in common autoregressive LLMs: the\npositional embeddings (Section 2.1) and the atten-\ntion mask (Section 2.2). Figure 3 illustrates both\nchanges.\n2.1 Positional Embeddings Modiﬁcation\nDenoting the LLM’s original context window size\nby N and the Transformer’s input representation\ndimension by d, Transformer-based LLMs receive\ninformation regarding the input text ordering via a\nset of N positional embeddings {⃗ pi ∈ Rd}N\ni=1, by\nadding ⃗ pi to the input token embedding in position\ni.\nWe conceptually divide the tokens at the input of\nthe LLM into context tokens and task tokens. The\ncontext tokens are inputs that assist the LLM with a\ngiven task, such as in-context examples, or relevant\nretrieved documents. Task tokens refer to the input\nof the test example, e.g., a sentence to be classiﬁed\nor a question.\nWhen considering a task that requires T task\ntokens to formulate, the fact that there are only\nN trained positional embeddings implies that ef-\nfectively only C = N − T input tokens can be\nprocessed as context. 2 In order to implement PCW,\nwe expand the number of processable context to-\nkens by a factor of B such that the overall input\nsequence can include B · C + T tokens. In order to\nallow LLMs to process this long sequence of text,\nwe assign one of N learned positional embedding\nvectors to location i ∈ {1, . . . , B· C + T} by the\n2In the case of absolute positional embeddings this is a\nhard restriction; for relative positional embeddings, processing\nmore tokens entails degradation ( Press et al. , 2021).\n6385\nfollowing mapping (depicted in Figure 3):\n⃗ pPCW\ni =\n{\n⃗ p(i−1 mod C)+1 1 ≤ i ≤ BC\n⃗ pi−(B−1)C BC < i≤ BC + T\n(1)\nIn words, via this mapping, the model effectively\nidentiﬁes B replicas of the ﬁrst C original posi-\ntional embeddings, and the T task tokens retain\nthe last T positional embeddings, now seeing these\nB replicas as context in their near past. We refer\nto these replicas of the positional embeddings as\ncontext window replicas . Notably, while the above\nre-use of the positional embeddings assigns mean-\ningful positions to all tokens within the longer in-\nput sequence, the memory cost of this expansion is\nquadratic, and moreover, the model was not trained\nto have two tokens in the same position attend to\neach other. To address these, we describe below a\nmodiﬁcation to the LLM’s attention mechanism.\n2.2 Attention Mask Modiﬁcation\nWe impose a restriction on the attention mecha-\nnism which implies that tokens within each context\nwindow replica perform autoregressive attention to\nother tokens in their context window replica, and\ndo not attend to tokens in other context window\nreplicas. In contrast, the task tokens attend to con-\ntext tokens within all context window replicas.\nIn the above setting of context window size\nN, we represent attention restrictions by atten-\ntion mask scores aii′ ∈ { 0, 1} for i, i′ ∈ [N] :=\n{1, . . . , N}. If aii′ = 0then for any Transformer\nlayer in the LLM, tokens in input location i cannot\nattend to tokens in input location i′, and if aii′ = 1\nthey can. In common autoregressive LLMs, a token\ncan only attend to tokens that precede it, which fol-\nlowing the above notation is translated into aii′ = 1\nif 1 ≤ i′ ≤ i ≤ N and aii′ = 0otherwise.\nFor the case of PCW, the B parallel context win-\ndows include tokens in positions i ∈ [C], and are\nidentiﬁed with an index b ∈ [B]. The T task tokens\nare not parallelized, and are located in positions\ni ∈ {C+1, . . . , C+T = N}. For completeness of\nthe notation, we will assign a dummy context win-\ndow index b = B+1 to the T task tokens. We add a\nsecond index to the attention scores: abb′\nii′ ∈ {0, 1}\nfor i, i′ ∈ [N] and b, b′ ∈ [B]. Similarly to the\nabove, if ab,b′\nii′ = 0then for any Transformer layer\nin the LLM, tokens in input location i and context\nwindow b cannot attend to tokens in input location\ni′ and context window b′, and if ab,b′\nii′ = 1they can.\nWith the above notation in place, the following\nrestriction implies that context tokens perform au-\ntoregressive attention within each context window\nreplica (illustrated in Figure 3):\nab,b′\nii′ =\n{\n1, if 1 ≤ i′ ≤ i ≤ C and b = b′\n0, otherwise (2)\nThe following implies that the T task tokens attend\nto all tokens in all B context windows (for i > C):\naB+1,b′\nii′ =\n{\n1, if 1 ≤ i′ ≤ i ≤ N, b ′ ∈ [B + 1]\n0, otherwise\n(3)\nThe above attention masks allow the model to\nattend to B times more context when decoding\nthe output, while keeping the computational cost\nlinear in the number of parallel contexts B. Overall,\nfor both the above PCW modiﬁcations, assigning\nB = 1corresponds to the vanilla LLM mechanism.\n3 PCW for In-Context Learning\n3.1 Experimental Setup\nWe apply the PCW method in the setting of in-\ncontext learning (ICL): we distribute the in-context\ntraining examples among the multiple context win-\ndow replicas, thus allowing the test example to\nattend to more training examples. For each ex-\nperiment, we report the performance with regular\nICL, using the maximum number of examples that\nﬁt in a model’s context window ( nmax). For our\nPCW method, given B parallel windows, we effec-\ntively use B × nmax training examples. The nmax\nused for each dataset and model can be found in\nTable 9. Unless stated otherwise, we report results\nwith B = 3 in the main paper, and discuss the\nchoice of B in Appendix C. Since training exam-\nples vary in length, we allocate in-context examples\ninto the parallel windows in a manner that balances\nthe windows’ lengths. 3 The test example (corre-\nsponding to the T task tokens in Section 2) receives\nthe positional embedding that immediately follows\nthe longest context window.\nTraining and test sets The performance of in-\ncontext learning was shown to signiﬁcantly vary\nwith the choice of training examples ( Zhao et al. ,\n2021). We followed past work ( Zhao et al. , 2021;\n3Within each window, positional embeddings are assigned\nsequentially starting from 1. See Appendix A for a discussion.\n6386\nLu et al. , 2021), randomly sampling 30 sets of train-\ning examples from the full training set. We report\nthe mean and standard deviation of performance\nmetrics across these samples. When comparing\nPCW method with standard ICL, statistically sig-\nniﬁcant differences according to a t-test (p-value\n< 0.05) are marked with *. To allow for an exten-\nsive set of experiments, we followed prior work\nand randomly subsampled the test sets to contain\nat most 250 examples ( Zhao et al. , 2021; Lu et al. ,\n2021; Han et al. , 2022).\nModels We experiment with 5 LMs of vary-\ning sizes: GPT2-Large (0.75B parameters) and\nGPT2-XL (1.5B) ( Radford et al. , 2019); and three\nJuarassic-1 (J1) models ( Lieber et al. , 2021): Large\n(7.5B), Grande (17B), and Jumbo (178B). Due to\nits massive size, we reduced the number of sampled\ntraining sets and the test set size for J1-Jumbo to\n15 and 125, respectively.\nDatasets Our main focus is classiﬁcation, and we\nexperiment with 15 different datasets in this cate-\ngory, listed in Appendix B. Many of these datasets\nare used in prior work on in-context learning ( Zhao\net al., 2021; Lu et al. , 2021; Han et al. , 2022). We\nadditionally experiment with several datasets with\na high number of output classes (up to 150), to ex-\namine how well our approach works in this setting.\nTo classify an example in the in-context learning\nsetup, we assign the label using restrictive greedy\ndecoding (see Appendix A). We also experiment\nwith another type of tasks, information extraction,\nand test 4 datasets with a subset of the models\n(J1-Large and J1-Grande). For these tasks we use\ngreedy decoding at temperature 0 (as in Zhao et al.\n(2021)). For further information about the decoding\nand formats used for the different types of datasets,\nsee Appendices A and B.\n3.2 Classiﬁcation Tasks Results\nPCW enables in-context learning with a large\nnumber of classes. Table 1 shows the results\non various classiﬁcation tasks, organized by the\nnumber of classes. With a small number of output\nclasses (≤ 5), we ﬁnd small or insigniﬁcant differ-\nences between PCW and vanilla ICL on J1-Large\n(7.5B), while with J1-Grande (17B) and J1-Jumbo\n(178B), PCW is superior in the majority of cases.\nHowever, many of these differences are not statisti-\ncally signiﬁcant.\nOur PCW method shines in classiﬁcation tasks\nwith a large number of output classes. With more\n101\n102\n# of Labels\n2.5\n0.0\n2.5\n5.0\n7.5\n10.0\n12.5\n15.0 Accuracy\nFigure 4: Average gains of PCW vs. the # of labels.\nEach data point represents the average gain across all\ndatasets and J1 models. There is a a strong positive\ncorrelation between the number of unique labels and the\ngains from PCW.\nthan 5 classes, PCW statistically signiﬁcantly out-\nperforms ICL in nearly all models and datasets.\nThe average improvement across these datasets is\n6.7, 7.3, and 7.9 for J1-Large, J1-Grande, and J1-\nJumbo. Evidently, the larger the model, the greater\nthe beneﬁt from our method . This positive scaling\nbehavior of PCW stands in contrast to prior work\nattempting to improve ICL ( Zhao et al. , 2021; Lu\net al., 2021; Han et al. , 2022), where improvements\nto 178B-scale models were smaller than improve-\nments observed in smaller models.\nIn Table 5 (Appendix D.1), we report results with\nGPT-2 models. Although they are smaller than J1\nmodels, we ﬁnd consistent statistically signiﬁcant\nimprovements with GPT2-XL (1.5B parameters)\nin almost all datasets. With GPT2-Large (0.75B),\nwe ﬁnd improvements in the majority of datasets.\nPCW improves with more classes. To examine\nthe relation between the number of output classes\nand the performance of PCW, we compute the dif-\nference between PCW and ICL in each experiment,\nand average over all datasets (and models) having\nthe same number of classes. As Figure 4 shows,\nthere is a strong positive correlation between the\nnumber of classes and the improvement brought\nabout by PCW (Pearson correlation r = 0.93 be-\ntween the log-number of classes and the average\nimprovement; the slope is 3.02). For datasets with\ndozens of unique labels—speciﬁcally Banking77\n(Casanueva et al. , 2020), NLU Intent ( Xingkun Liu\nand Rieser, 2019), and CLINIC150 ( Larson et al. ,\n2019)—we observe improvements of 10–15 points\nin most cases. Importantly, prior in-context learn-\n6387\nJ1- Large (7.5B) J1-Grande (17B) J1-Jumbo (178B)\nDataset # Labels ICL PCW ICL PCW ICL PCW\nSST-2 2 93.51.6 93.81.1 95.21.1 95.60.5 96.51.4 97.01.5\nCR 2 93.90.7 93.90.7 93.60.8 93.80.8 93.61.5 93.11.0\nRTE 2 58.33.8 58.13.7 61.25.1 62.23.0 63.95.0 66.04.1\nSubj 2 84.17.7∗ 79.17.2 93.02.5 95.31.2∗ 89.15.3 93.62.1∗\nCB 3 65.28.0 61.28.2 75.08.1 75.76.0 76.24.3 76.63.5\nAGNews 4 79.83.6 81.52.1∗ 81.43.0 82.72.1 82.53.8 85.91.7∗\nSST-5 5 45.53.9 47.42.9∗ 51.63.4 53.82.2∗ 55.42.8 55.13.9\nYELP 5 56.23.8 56.35.1 66.22.2 65.62.0 66.34.1 65.42.6\nTREC 6 87.04.5 89.43.2∗ 86.53.8 88.73.4∗ 87.15.7 90.43.1\nDBPedia 14 93.23.0 96.21.5∗ 92.53.3 97.31.6∗ 91.74.4 96.52.3∗\nNLU Scenario 18 81.92.2 84.21.5∗ 86.12.1 88.81.1∗ 85.42.9 87.81.6∗\nTREC Fine 50 60.56.9 68.83.4∗ 63.36.0 71.84.6∗ 71.45.7 78.73.6∗\nNLU Intent 68 69.73.3 79.71.9∗ 72.13.1 81.91.6∗ 74.33.4 81.62.9∗\nBANKING77 77 51.03.4 63.52.7∗ 55.23.3 69.12.2∗ 55.33.5 70.93.1∗\nCLINIC150 150 67.32.7 75.41.7∗ 68.92.5 78.61.8∗ 65.75.0 79.92.1∗\nTable 1: Accuracy results (in %) for J1-Large, J1-Grande, and J1-Jumbo models with regular ICL in comparison\nwith using PCW with B = 3prompts. The best results for each model and dataset are boldfaced, and ‘*’ is used to\nindicate that the boldfaced result is statistically better (t-test with p-value < 0.05).\ning work has not considered datasets with such a\nlarger number of classes, perhaps due to the stan-\ndard limitation of the context window size. 4 We\nnote that in GPT-2 models (Table 5, Appendix D.1)\nwe do not see a signiﬁcant correlation between\nPCW improvements and the number of classes, but\nthese smaller models tend to struggle with very\nlarge numbers of classes.\nComparing results for datasets with different\nnumbers of output classes may be confounded\nby other factors, such as differences in domain,\nstyle, or genre. To isolate such effects, we com-\npare results with two datasets, each having both\nﬁne-grained and coarse-grained labels: (1) The\nTREC dataset ( Li and Roth , 2002), which has 6\ncoarse-grained and 50 ﬁne-grained classes. (2)\nNLU (Xingkun Liu and Rieser , 2019),5 which has\n18 scenarios and 68 intents. From Table 1, we\nsee that PCW outperforms standard ICL by 2.6\nand 8.1 points on TREC coarse-grained and ﬁne-\ngrained classiﬁcation, respectively. Similarly, on\nNLU coarse- and ﬁne-grained classiﬁcation, we\nsee average improvements of 2.5 and 9.0 points,\nrespectively. We conclude that our approach shines\nespecially well when dealing with a large number\nof output classes.\n4An exception is Alex et al. (2021), who evaluated GPT3\non Banking77 in a limited setting, but obtained poor results.\n5Note that the NLU dataset is also misleadingly known as\nHWU64; see the Huggingface dataset page for more details.\nPCW makes in-context learning more stable.\nA known limitation of in-context learning is high\nvariance across examples and sensitivity to aspects\nlike the order of examples ( Lu et al. , 2021). Encour-\nagingly, we ﬁnd that PCW reduces such variance:\nWe observe average std values of 3.1, 2.3, and 2.6\nfor J1-Large, J1-Grande, and J1-Jumbo with PCW,\ncompared to 3.9, 3.4, and 3.9 in standard ICL.\n3.3 Information Extraction Results\nTable 2 shows the results of ICL and PCW on in-\nformation extraction datasets with tasks like air-\nline name extraction or extractive question answer-\ning. These tasks can be considered as classiﬁcation\ntasks with an extremely large number of classes, po-\ntentially the entire vocabulary or phrases from the\nvocabulary. Our approach consistently improves\nresults with both J1-Large and J1-Grande, resulting\nin statistically signiﬁcant improvements in almost\nall cases. We also observe smaller standard devia-\ntions with PCW compared to ICL.\nIt is worth noting that prior work has not experi-\nmented much with information extraction in an in-\ncontext learning setting. Zhao et al. (2021) reported\nresults with several datasets, but not with extractive\nquestion-answering. Our approach seems to allow\nin-context learning in such cases as well.\nFinally, we tested two multiple-choice QA tasks:\nOpenBookQA ( Mihaylov et al. , 2018) and Sto-\nryCloze ( Mostafazadeh et al. , 2017). With our\nlarger model, J1-Grande, PCW leads to a signiﬁ-\n6388\nJ1-Large (7.5B) J1-Grande (17B)\nDataset ICL PCW ICL PCW\nATIS 85.65.3 89.03.0∗ 88.04.6 91.73.1∗\nMIT Movies 67.92.7 70.32.5∗ 69.03.9 69.33.3\nSQuAD 79.22.1 80.51.4∗ 83.82.5 85.11.4∗\nadversarialQA43.02.2 44.61.5∗ 46.42.0 47.41.8\nTable 2: PCW improves information extraction (ATIS\nand MIT Movies are measured with EM, SQuAd and\nadversarialQA with F1).\ncant improvement in OpenBookQA and does not\nsigniﬁcantly improve or worsen over ICL in other\ncases. Details and results of the experiment can be\nfound in Appendix D.2.\n4 PCW for Question Answering\nIn this section, we explore potential usages of PCW\nin other settings than in-context learning. Specif-\nically, we examined two question-answering set-\ntings where PCW is expected to help aggregate\ninformation from multiple texts. Firstly, we con-\nsider the case of question answering based on re-\ntrieved documents. Secondly, we experiment with\nmulti-hop reasoning, where the model is required\nto utilize more than one text while answering a\nquestion. Importantly, while in Section 3 the par-\nallel context windows were used for processing\ntraining examples for ICL, in this section the win-\ndows are used for parallel processing of documents\nrelated to the test example.\n4.1 Retrieval Based Question Answering\nSetup We ﬁrst experiment with Natural Ques-\ntions (NQ, Kwiatkowski et al. , 2019) in an open-\nbook question-answering retrieval setting: Given\na question and a set of candidate documents, that\nmay or may not contain the evidence for the ques-\ntion, a model needs to generate a free-text answer.\nIn the single context window setting (the base-\nline), we followed the few-shot setup deﬁned by\nLazaridou et al. (2022): For each question, we re-\ntrieved evidence documents from Wikipedia, using\na BM25 sparse retriever ( Robertson et al. , 2009).\nWe then prompted the model with in-context train-\ning examples of the related task of extracting the an-\nswer from a gold evidence document, and concate-\nnated the test question and N ∈ { 1, 2, 4, 6, 8, 10}\nevidence documents6. To fully utilize the context\n6Notably, Lazaridou et al. (2022) used this apparatus only\nwith N = 1, while we experiment with different values of N.\n1 2 4 6 8 10\n# Documents per Window\n22\n23\n24\n25\n26\n27\n28\n29Exact Match (%)\nSingle Window (baseline)\n3 Parallel Windows (PCW)\nFigure 5: NQ results for J1 Grande—EM against num-\nber of documents in a single window.\nJ1-Large (7.5B) J1-Grande (17B)\nType Seq PCW Seq PCW\nComparison 15.3 21.5 20.9 28.7\nBridge 21.6 16.5 27.1 24.0\nTable 3: Zero-shot Exact Match (EM) results on Hot-\npotQA with Sequential and Parallel processing (PCW\napproach).\nwindow size, we “padded” the prompt with as much\nin-context training examples as possible.\nFor PCW, we followed the setup of a single win-\ndow while taking advantage of the method’s natural\nability of parallelization: We increased the number\nof retrieved documents per question, and divided\nthem between windows. E.g., for N = 1 and 3\nparallel context windows ( B = 3), PCW processes\nB × N = 3retrieved documents (1 per each win-\ndow), thus effectively increasing the chance that\nthe correct answer span will be shown to the model\nin one of the retrieved documents. The metric we\nused was the standard Exact Match (EM). We refer\nto Appendix A for more details.\nResults Figure 5 shows the results for J1-Grande,\nwhen using PCW compared to the baseline, as a\nfunction of the number of candidate documents in\na single window. In all cases, PCW performs bet-\nter than the baseline, demonstrating the beneﬁt of\nparallel processing of candidate documents. As we\nincrease the number of available retrieved docu-\nments, we see an increase in performance for both\napproaches. Similar trend can be seen for J1-Large\n(see Figure 6 in Appendix). Naturally, the perfor-\nmance of this task depends on the probability of\nretrieving the correct answer. The latter increases\nin PCW setting, when the number of processed\ndocuments is multiplied by B = 3.\n6389\n4.2 Multi-hop Question Answering\nSetup Finally, we experiment with HotpotQA\n(Yang et al. , 2018), which requires multi-hop rea-\nsoning. Given a question and 10 evidence docu-\nments (2 gold and 8 distractors), answering the\nquestion requires reasoning over both gold docu-\nments. HotpotQA includes two question types 7: (a)\nQuestions that refer to a bridge entity. For exam-\nple, to answer the question “when was the singer\nof Radiohead born?”, one needs to reason that the\nsinger is “Thom Yorke” (the bridge entity) and then\nﬁnd his birthday. (b) Questions that rely on a com-\nparison between two entities. For example: “Who\nhas played for more NBA teams, Michael Jordan\nor Kobe Bryant?”. As a baseline, we provide all\nof the evidences in a random, sequential manner.\nFor PCW, we use 5 windows, with 2 evidences in\neach window. Since the 10 evidences ﬁlled most\nof the context window of J1 models, we work in\na zero-shot setting. The evaluation metric is the\nstandard Exact Match (EM).\nResults Table 3 shows the results. We break\ndown the results according to the bridge and\ncomparison question types. Interestingly, PCW\nhelps with comparison questions, improving per-\nformance over the baseline in both J1-Large and\nJ1-Grande while degrading the performance on\nbridge questions. This disparate behavior can be\nexplained by the kind of processing required to an-\nswer the two types of questions. In comparison\nquestions, the model can extract the necessary in-\nformation from the two gold texts independently,\nmaking them suitable for PCW. For example, to\nknow who played for more NBA teams, the LM\nneeds to extract the number of NBA teams Jordan\nplayed for from one text, while extracting the num-\nber of NBA teams Bryant played for from another\nindependent text. In contrast, to answer a bridge\nquestion, the processing of each text is conditioned\non the other text: When reading a sentence about\nThom Yorke’s birthplace, we already need to know\nthat Yorke is the Radiohead singer, if we wish to\nthen be able to answer the above question. This\nmakes PCW less suitable for these types of tasks in\nits current form, and we leave it as an open direc-\ntion for how to encode sequential relation between\nwindows (perhaps by some further training).\n7Examples of questions taken from Yang et al. (2018)\n5 Related Work\n5.1 In-Context Learning\nIn-context learning has been the subject of exten-\nsive research since it was ﬁrst introduced by Brown\net al. (2020). For instance, Zhao et al. (2021)\nshowed that LMs are often miscalibrated. Zhao\net al. (2021) and Han et al. (2022) explored ways to\novercome this issue by different calibration meth-\nods. Lu et al. (2021) observed that few-shot perfor-\nmance varies signiﬁcantly depending on the order\nof examples in the prompt, and proposed a protocol\nfor ﬁnding better permutations. Min et al. (2021)\nproposed a noisy channel approach to boost few-\nshot performance. Our framework is orthogonal\nand thus complementary to these methods, as we\nare mainly focused on how to increase the number\nof examples shown to the model. Our approach is\nalso more general as it seamlessly supports genera-\ntive tasks as well.\n5.2 Expanding the Context Window\nThe issue of a limited context window has been\nthe focus of many studies that tried to alleviate\nthe memory footprint of self-attention. One line\nof work ( Zaheer et al. , 2020; Guo et al. , 2021, in-\nter alia ) suggested using sparse attention to over-\ncome this difﬁculty. Press et al. (2022) proposed\nto encode positional information via relative fac-\ntors added to attention weights, instead of absolute\npositional encoding. Despite the impressive ex-\ntrapolation abilities of Press et al. (2022), the self-\nattention cost of such models remains quadratic,\nmaking inference for longer prompts slow and\nexpensive. Ivgi et al. (2022) suggest SLED, an\nencoder–decoder model for long texts, which en-\ncodes short overlapping chunks of the input text,\nand fuses the information in the decoder, a-la\nFusion-in-Decoder (Izacard and Grave, 2020). Sim-\nilarly to our approach, both Izacard and Grave\n(2020) and Ivgi et al. (2022) employ off-the-shelf\narchitectures, but those methods require further\ntraining. Among all mentioned methods, our work\nis the ﬁrst that utilizes existing LLMs for longer\ninputs without any further training .\nIn concurrent work, Hao et al. (2022) suggest\nusing multiple context windows, while scaling the\ncontext tokens’ attention weights. We show that\nlarge gains can be made without scaling the atten-\ntion weights, and we demonstrate particularly large\ngains for tasks with diverse output spaces.\nMoreover, they focus on LLMs with non-learned\n6390\npositional encoding (sinusoidal, Vaswani et al.\n2017 and ALIBI, Press et al. 2022) and only show\nresults in the ICL setting. In contrast, we show\nthat PCW is effective for more common LLMs that\nhave learned positional embeddings, and show that\nPCW obtains gains both in ICL and in document\nretrieval settings.\n6 Conclusion and Future Work\nIn recent years, a multitude of successful\napproaches have been proposed for allowing\nTransformer-based language models to leverage\nlarge amounts of text during inference, leading to\na variety of dedicated architectures. In parallel,\nhowever, the mainstream LLM production line of\nnew models with “regular”—up to several thou-\nsand tokens—context window sizes enjoys faster\nprogress in the form of scaling, innovation, and\ndata updating.\nThis paper introduced Parallel Context Windows\n(PCW): A simple approach for allowing any off-\nthe-shelf LLM to broaden the scope of text it can\naccess during inference. We showed the effective-\nness of PCW in the framework of in-context learn-\ning, where access to a context that is larger by a\nfactor of B implies learning from B times more\ntraining examples. Our results show that PCW is\nmore effective than the vanilla single context win-\ndow approach for in-context learning over a broad\nset of multi-class classiﬁcation tasks, suggesting\nthat PCW could improve in-context learning in\ntasks with diverse input or output spaces. We also\nshowed promising signals for applying PCW for\nmultiple retrieved document reading.\nTwo key directions of future work strike us as\nparticularly promising. First, by demonstrating\nthat an off-the-shelf LLM can attend to substan-\ntially larger quantities of text via PCW, our results\nmotivate further investigation of the PCW method\nin other settings in which it would be desirable to\napply mainstream LLMs over long text sequences.\nSecond, though our results suggest that PCW is\neffective without further training, we believe that\nfurther (short) training of an LLM with parallel\ncontext windows could further enhance the abili-\nties demonstrated in this work.\nLimitations\nWe presented Parallel Context Windows (PCW),\na simple approach that alleviates context window\nrestrictions for any off-the-shelf LLM, without ad-\nditional training. We showed the potential of this\nmethod on a variety of models and datasets. With\nthat, our method does have some limitations.\nThe number of context windows has a limit, and\nneeds to be predetermined. Similarly to vanilla\nin-context learning, the number of examples to in-\nclude in the prompt must be selected beforehand.\nFor PCW, it is also required to select the number\nof context windows, B. In this paper, most of the\nresults are for B = 3. We experiment in Appendix\nC with the choice of B. The results are task de-\npendent, but at a high level we ﬁnd that there are\ndiminishing returns around B in the range of 5 to 7.\nWe leave further investigation of how to effectively\nbeneﬁt from more windows for future work.\nNot effective for all types of tasks. As discussed\nin Section 3, PCW shows impressive gains in ICL\nfor tasks such as multi-class tasks classiﬁcation as\nwell as information extraction. However, for some\ntasks, PCW does not improve performance. This\nmight indicate that some tasks are not suited for\nparallel processing. Section 4.2 demonstrated that\nPCW is more suitable for cases where the input\ntext could be divided into few independent inputs,\nbut it remains an open question as to whether tasks,\nsuch as long text generation, would beneﬁt from\nPCW.\n7 Acknowledgements\nWe thank our colleagues at AI21 Labs for their\nassistance and advice and the anonymous reviewers\nfor their useful suggestions.\nReferences\nNeel Alex, Eli Liﬂand, Lewis Tunstall, Abhishek\nThakur, Pegah Maham, C. Jess Riedel, Emmie\nHine, Carolyn Ashurst, Paul Sedille, Alexis Car-\nlier, Michael Noetel, and Andreas Stuhlmüller. 2021.\nRaft: A real-world few-shot text classiﬁcation bench-\nmark.\nMax Bartolo, Alastair Roberts, Johannes Welbl, Sebas-\ntian Riedel, and Pontus Stenetorp. 2020. Beat the ai:\nInvestigating adversarial human annotation for read-\ning comprehension. Transactions of the Association\nfor Computational Linguistics , 8:662–678.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\n6391\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners .\nIñigo Casanueva, Tadas Temcinas, Daniela Gerz,\nMatthew Henderson, and Ivan Vulic. 2020. Ef-\nﬁcient intent detection with dual sentence en-\ncoders. In Proceedings of the 2nd Workshop\non NLP for ConvAI - ACL 2020 . Data avail-\nable at https://github.com/PolyAI-LDN/task-speciﬁc-\ndatasets.\nIdo Dagan, Oren Glickman, and Bernardo Magnini.\n2006. The pascal recognising textual entailment chal-\nlenge. In Machine Learning Challenges. Evaluating\nPredictive Uncertainty, Visual Object Classiﬁcation,\nand Recognising Tectual Entailment , pages 177–190,\nBerlin, Heidelberg. Springer Berlin Heidelberg.\nMarie-Catherine de Marneffe, Mandy Simons, and Ju-\ndith Tonhauser. 2019. The commitmentbank: Investi-\ngating projection in naturally occurring discourse.\nXiaowen Ding, Bing Liu, and Philip Yu. 2008. A holis-\ntic lexicon-based approach to opinion mining . pages\n231–240.\nMandy Guo, Joshua Ainslie, David Uthus, Santiago On-\ntanon, Jianmo Ni, Yun-Hsuan Sung, and Yinfei Yang.\n2021. Longt5: Efﬁcient text-to-text transformer for\nlong sequences.\nZhixiong Han, Yaru Hao, Li Dong, Yutao Sun, and\nFuru Wei. 2022. Prototypical calibration for few-\nshot learning of language models .\nYaru Hao, Yutao Sun, Li Dong, Zhixiong Han, Yux-\nian Gu, and Furu Wei. 2022. Structured prompting:\nScaling in-context learning to 1,000 examples .\nCharles T. Hemphill, John J. Godfrey, and George R.\nDoddington. 1990. The ATIS spoken language sys-\ntems pilot corpus . In Speech and Natural Language:\nProceedings of a Workshop Held at Hidden Valley,\nPennsylvania, June 24-27,1990 .\nMaor Ivgi, Uri Shaham, and Jonathan Berant. 2022. Ef-\nﬁcient long-text understanding with short-text mod-\nels.\nGautier Izacard and Edouard Grave. 2020. Leverag-\ning passage retrieval with generative models for\nopen domain question answering. arXiv preprint\narXiv:2007.01282.\nVladimir Karpukhin, Barlas O ˘guz, Sewon Min, Patrick\nLewis, Ledell Wu, Sergey Edunov, Danqi Chen, and\nWen-tau Yih. 2020. Dense passage retrieval for\nopen-domain question answering. arXiv preprint\narXiv:2004.04906.\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\nﬁeld, Michael Collins, Ankur Parikh, Chris Alberti,\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\nton Lee, Kristina Toutanova, Llion Jones, Matthew\nKelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\nUszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-\nral questions: A benchmark for question answering\nresearch. Transactions of the Association for Compu-\ntational Linguistics, 7:452–466.\nStefan Larson, Anish Mahendran, Joseph J. Peper,\nChristopher Clarke, Andrew Lee, Parker Hill,\nJonathan K. Kummerfeld, Kevin Leach, Michael A.\nLaurenzano, Lingjia Tang, and Jason Mars. 2019. An\nevaluation dataset for intent classiﬁcation and out-of-\nscope prediction. In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP) .\nAngeliki Lazaridou, Elena Gribovskaya, Wojciech\nStokowiec, and Nikolai Grigorev. 2022. Internet-\naugmented language models through few-shot\nprompting for open-domain question answering .\nYoav Levine, Itay Dalmedigos, Ori Ram, Yoel Zeldes,\nDaniel Jannai, Dor Muhlgay, Yoni Osin, Opher\nLieber, Barak Lenz, Shai Shalev-Shwartz, et al.\n2022a. Standing on the shoulders of giant frozen\nlanguage models. arXiv preprint arXiv:2204.10019 .\nYoav Levine, Ori Ram, Daniel Jannai, Barak Lenz, Shai\nShalev-Shwartz, Amnon Shashua, Kevin Leyton-\nBrown, and Yoav Shoham. 2022b. Huge frozen lan-\nguage models as readers for open-domain question\nanswering. In ICML 2022 Workshop on Knowledge\nRetrieval and Language Models .\nQuentin Lhoest, Albert Villanova del Moral, Yacine\nJernite, Abhishek Thakur, Patrick von Platen, Suraj\nPatil, Julien Chaumond, Mariama Drame, Julien Plu,\nLewis Tunstall, Joe Davison, Mario Šaško, Gun-\njan Chhablani, Bhavitvya Malik, Simon Brandeis,\nTeven Le Scao, Victor Sanh, Canwen Xu, Nicolas\nPatry, Angelina McMillan-Major, Philipp Schmid,\nSylvain Gugger, Clément Delangue, Théo Matus-\nsière, Lysandre Debut, Stas Bekman, Pierric Cis-\ntac, Thibault Goehringer, Victor Mustar, François\nLagunas, Alexander Rush, and Thomas Wolf. 2021.\nDatasets: A community library for natural language\nprocessing. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Process-\ning: System Demonstrations , pages 175–184, Online\nand Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nXin Li and Dan Roth. 2002. Learning question clas-\nsiﬁers. In COLING 2002: The 19th International\nConference on Computational Linguistics .\nOpher Lieber, Or Sharir, Barak Lenz, and Yoav Shoham.\n2021. Jurassic-1: Technical details and evaluation.\nWhite Paper. AI21 Labs .\nJimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-\nHong Yang, Ronak Pradeep, and Rodrigo Nogueira.\n2021. Pyserini: A Python toolkit for reproducible\n6392\ninformation retrieval research with sparse and dense\nrepresentations. In Proceedings of the 44th Annual\nInternational ACM SIGIR Conference on Research\nand Development in Information Retrieval (SIGIR\n2021), pages 2356–2362.\nJingjing Liu, D. Scott Cyphers, Panupong Pasupat, Ian\nMcGraw, and James R. Glass. 2012. A conversa-\ntional movie search system based on conditional ran-\ndom ﬁelds. In Interspeech.\nYao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,\nand Pontus Stenetorp. 2021. Fantastically ordered\nprompts and where to ﬁnd them: Overcoming few-\nshot prompt order sensitivity .\nTodor Mihaylov, Peter Clark, Tushar Khot, and Ashish\nSabharwal. 2018. Can a suit of armor conduct elec-\ntricity? a new dataset for open book question answer-\ning. In EMNLP.\nSewon Min, Mike Lewis, Hannaneh Hajishirzi, and\nLuke Zettlemoyer. 2021. Noisy channel language\nmodel prompting for few-shot text classiﬁcation .\nNasrin Mostafazadeh, Michael Roth, Annie Louis,\nNathanael Chambers, and James Allen. 2017. Ls-\ndsem 2017 shared task: The story cloze test. In\nProceedings of the 2nd Workshop on Linking Models\nof Lexical, Sentential and Discourse-level Semantics ,\npages 46–51.\nBo Pang and Lillian Lee. 2004. A sentimental education:\nSentiment analysis using subjectivity summarization\nbased on minimum cuts . CoRR, cs.CL/0409058.\nOﬁr Press, Noah Smith, and Mike Lewis. 2022. Train\nshort, test long: Attention with linear biases enables\ninput length extrapolation . In International Confer-\nence on Learning Representations .\nOﬁr Press, Noah A Smith, and Mike Lewis. 2021.\nTrain short, test long: Attention with linear biases\nenables input length extrapolation. arXiv preprint\narXiv:2108.12409.\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016. SQuAD: 100,000+ Questions\nfor Machine Comprehension of Text . arXiv e-prints,\npage arXiv:1606.05250.\nStephen Robertson, Hugo Zaragoza, et al. 2009. The\nprobabilistic relevance framework: Bm25 and be-\nyond. Foundations and Trends® in Information Re-\ntrieval, 3(4):333–389.\nUri Shaham, Elad Segal, Maor Ivgi, Avia Efrat, Ori\nYoran, Adi Haviv, Ankit Gupta, Wenhan Xiong, Mor\nGeva, Jonathan Berant, et al. 2022. Scrolls: Stan-\ndardized comparison over long language sequences.\narXiv preprint arXiv:2201.03533 .\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D. Manning, Andrew Ng, and\nChristopher Potts. 2013. Recursive deep models for\nsemantic compositionality over a sentiment treebank .\nIn Proceedings of the 2013 Conference on Empiri-\ncal Methods in Natural Language Processing , pages\n1631–1642, Seattle, Washington, USA. Association\nfor Computational Linguistics.\nYi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen,\nDara Bahri, Philip Pham, Jinfeng Rao, Liu Yang,\nSebastian Ruder, and Donald Metzler. 2020. Long\nrange arena: A benchmark for efﬁcient transformers.\narXiv preprint arXiv:2011.04006 .\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. CoRR, abs/1706.03762.\nPawel Swietojanski Xingkun Liu, Arash Eshghi and Ver-\nena Rieser. 2019. Benchmarking natural language\nunderstanding services for building conversational\nagents. In Proceedings of the Tenth International\nWorkshop on Spoken Dialogue Systems Technology\n(IWSDS), pages xxx–xxx, Ortigia, Siracusa (SR),\nItaly. Springer.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\nWilliam Cohen, Ruslan Salakhutdinov, and Christo-\npher D. Manning. 2018. HotpotQA: A dataset for\ndiverse, explainable multi-hop question answering .\nIn Proceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing , pages\n2369–2380, Brussels, Belgium. Association for Com-\nputational Linguistics.\nManzil Zaheer, Guru Guruganesh, Avinava Dubey,\nJoshua Ainslie, Chris Alberti, Santiago Ontanon,\nPhilip Pham, Anirudh Ravula, Qifan Wang, Li Yang,\nand Amr Ahmed. 2020. Big bird: Transformers for\nlonger sequences.\nXiang Zhang, Junbo Zhao, and Yann LeCun. 2015a.\nCharacter-level convolutional networks for text clas-\nsiﬁcation. In Advances in Neural Information Pro-\ncessing Systems, volume 28. Curran Associates, Inc.\nXiang Zhang, Junbo Jake Zhao, and Yann LeCun. 2015b.\nCharacter-level convolutional networks for text clas-\nsiﬁcation. In NIPS.\nTony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and\nSameer Singh. 2021. Calibrate before use: Improv-\ning few-shot performance of language models .\nA Experimental Details\nA.1 PCW Implementation Details\nHandling context windows of various lengths\nSection 2 thoroughly describes PCW method for\ncases where each window has the same number of\ntokens. Throughout all our experiments, this was\nrarely the case. We considered two variations of\n6393\nPCW to handle these cases. The ﬁrst was whether\nto use left or right indentation of the windows,\nmeaning whether all of the windows should begin\nor end in the same position id. To avoid any discon-\ntinuity in the assignment of position ids, it is also\npossible to pad the windows with some dummy to-\nkens (e.g., new line). Left indentation was found to\nbe the most preferred option in ICL setting, while\npadding did not appear to be signiﬁcant. For that\nreason, and considering the simplicity of this so-\nlution, we chose to use left indentation in all of\nour experiments. It is important to note that in the\nPCW implementation, all the windows and the task\ntokens attend to a single shared BOS token. We\nfound that having multiple BOS tokens negatively\naffected our results.\nSplitting the inputs into windows For the ex-\nperiments described in Section 3, we assigned an\nequal number of nmax samples per window, and\nonly attempted to balance the lengths of the win-\ndows by greedily switching long and short samples\nbetween windows. nmax was calculated according\nto the following formula:\nnmax = ⌊N − Tmax\nD90\n⌋ (4)\nwhere N is the context window size, Tmax is the\nlength of longest test sample and D90 is the 90th\npercentile of the train samples’ lengths. To avoid\nunwanted effects due to outliers, we removed the\nlongest percentile of train and test samples.\nIn the experiments described in Section 4.1, we\ndivided the documents according to the retriever’s\nranking, so that the last document in each window\nwould have the highest ranking in the window. It\nshould be noted that the training examples were not\nparallelized. The same randomly chosen examples\nwere used for both baseline and PCW, and new\nexamples were drawn for each test sample. For the\nexperiment described in Section 4.2, the division\nbetween windows was random.\nA.2 Evaluation Details\nClassiﬁcation A common way to evaluate mod-\nels in the in-context learning setup is to iterate\nover all possible labels for each test sample and\ncheck which label receives the highest probability\naccording to the LM. This approach is problem-\natic where a large number of classes is present,\nespecially when some class names are split into\nmultiple tokens. To save computational costs, we\nimplemented constrained greedy decoding, at each\nstep allowing only tokens that could result in a\nvalid label. It is important to acknowledge that this\nevaluation method could result in slightly different\nperformance for both the ICL baseline and for the\nPCW approach. However, since most of the labels\nonly contained few tokens in both J1’s & GPT’s\ntokenizers, and the ﬁrst token is usually quite in-\ndicative to the nature of the label, this effect should\nbe minor.\nInformation extraction The LMs’ predictions\nfor the information extraction tasks were generated\nwith greedy decoding at temperature 0, similar to\nZhao et al. (2021). We used Exact Match (EM) or\nF1 as the metric of choice for the extraction tasks.\nComputational cost As discussed in the begin-\nning of this appendix, we used restrictive decoding\nfor the majority of the experiments in the paper.\nThis usage greatly reduced the computational cost\nof our experiments: Most classiﬁcation tasks were\npreformed in 1-4 GPU hours for all models (besides\nexperiments with J1-Jumbo, which lasted roughly\n10-50 GPU hours per experiment). The experi-\nments described in Section 3.3 and Section 4 took\nup to 20 GPU hours each.\nB Datasets Information\nB.1 Overview\nWe used 15 different datasets for our classiﬁca-\ntion experiments: SST-2 ( Socher et al. , 2013),\nCR (Ding et al. , 2008), RTE ( Dagan et al. , 2006),\nSubj ( Pang and Lee , 2004), CB ( de Marneffe\net al. , 2019), AGNews ( Zhang et al. , 2015b),\nSST-5 ( Socher et al. , 2013), YELP ( Zhang et al. ,\n2015a),TREC ( Li and Roth , 2002), DBPedia\n(Zhang et al. , 2015a), NLU ( Xingkun Liu and\nRieser, 2019), BANKING77 ( Casanueva et al. ,\n2020) and CLINIC150 ( Larson et al. , 2019). TREC\nand NLU datasets were used with both ﬁne and\ncoarse grained labels. The different formats used\nin all of tasks, as well as the values of nmax for\nboth J1 and GPT2 models, can be found in Table\n9. We have also used 6 more datasets from extrac-\ntion and multiple-choice domains, which were only\nevaluated with J1 models:\n• ATIS airlines ( Zhao et al. , 2021); nmax = 67.\n• MIT Movie Genre ( Zhao et al. , 2021);\nnmax = 54.\n6394\n• SQuAD (Rajpurkar et al. , 2016); nmax = 8.\n• adversarialQA(Bartolo et al. , 2020); nmax =\n8.\n• OpenBookQA ( Mihaylov et al. , 2018);\nnmax = 87.\n• StoryCloze(Mostafazadeh et al. , 2017);\nnmax = 44.\nFor Section 4 we used Natural Questions\n(Kwiatkowski et al. , 2019) and HotpotQA ( Yang\net al., 2018) datasets. All datasets were evaluated\nwith the standard test set or validation set in the ab-\nsence of a public test set. As described in Section 3,\nwe subsampled all test sets for the ICL experiments.\nIn Natural Questions dataset, we used half of the\ntest set (its original size was 3610 samples) to speed\nup evaluation. We used the full HotpotQA valida-\ntion set, containing 7405 samples. The datasets are\nall in English.\nThe majority of the datasets can be found in\nthe Huggingface Datasets package ( Lhoest et al. ,\n2021), apart from the information extraction tasks\nATIS airlines ( Hemphill et al. , 1990) and MIT\nmovie genre ( Liu et al. , 2012), which were taken\nfrom Zhao et al. (2021), and Natural Questions\n(Kwiatkowski et al. , 2019) which was loaded and\nincorporated with retrieved documents using Py-\nserini (Lin et al. , 2021). Since loading the training\nset via Pyserini is not currently a built-in option,\nwe used the validation set of Natural Questions\nas an effective train set. We found this decision\nreasonable since we only used the training set for\nfew-shot prompting, and we did not optimize any\nparameters using the validation set.\nWe have tried our best to track the licenses of the\ndatasets used in this work. The license information\nthat we have managed to ﬁnd is as follows: SST-2,\nRTE, SST-5, NLU Scenario, NLU Intent, BANK-\nING77 and SQuAD—CC-BY 4.0, adversarialQA—\nCC-BY-SA 4.0, DBPedia—CC-BY-SA 3.0.\nB.2 Preprocessing and Formatting\nIn all ICL experiments, we used only pairs of in-\nputs and expected outputs, without any instructions.\nFor the classiﬁcation datasets, we mainly used for-\nmats found in Lu et al. (2021) when applicable.\nFor extraction and multi-choice datasets, we used\nthe formats from Brown et al. (2020). We gener-\nated new formats for classiﬁcation datasets with\ndozens of labels, which are rarely used in few-shot\nsetting. The formats were based on wordings and\nlabels used in HuggingFace, with minor modiﬁca-\ntions to make the formats more similar to natural\nlanguage ( e.g., replacing ‘_’ with spaces in label\nnames). Details of the classiﬁcation prompts can be\nfound in Table 9. Experiments from Section 4 were\nformatted similarly to the work done by ( Lazaridou\net al., 2022). Their prompts formats are presented\nin Table 10.\nC The Effect of the Number of Context\nWindows on Performance\nWhen using PCW for ICL, the number of paral-\nlel context windows ( B) affects the number of in-\ncontext training examples. We used B = 2, 3, 4\nin preliminary experiments, and saw that for clas-\nsiﬁcation tasks, the optimal choice of B depends\non the number of unique labels in the task. We\nobserved that the performance for tasks with a\nhigh number of classes was improved when we\nincreased B, while the optimal choice of B for\ntasks with few classes tended to be 1 or 2 (See Ta-\nbles 6,7 and 8). For simplicity, We chose to display\nresults for B = 3in all of the main experiments.\nNevertheless, we were curious to see how far we\ncould push the number of parallel context windows\nbefore the model stopped beneﬁting from them. We\nused a representative subset of three datasets with\na varying number of classes, and increased B from\n1 to 8. The number of training sets and the size of\ntest set for those experiments were set on 15 and\n125 respectively.\nAs seen in Figure 7, when the number of context\nwindows is increased, datasets with a large number\nof classes, such as AGNews and DBPedia (with 4\nand 14 labels, respectively), continue to improve\n(with a convergence at around B = 6). Hence,\nPCW can achieve even greater improvements by\noptimizing B per dataset. Increasing the number\nof context windows, however, seemed to harm the\nperformance of SST-2.\nIdentifying which tasks beneﬁt from large paral-\nlel data processing would be an interesting research\ndirection in the future. For now, we recommend\nchoosing an optimal B on the development set (if\navailable) for best results. In the absence of a devel-\nopment set, a conservative choice, such as B = 3,\nmay be beneﬁcial. It is possible to investigate the\nbehaviour of PCW with a larger number of win-\ndows, but we ﬁnd it irrelevant for most practical\ncases of ICL, where an extremely large number of\n6395\n1 2 4 6 8 10\n# Documents per Window\n18\n20\n22\n24Exact Match (%)\nSingle Window (baseline)\n3 Parallel Windows (PCW)\nFigure 6: NQ results for J1 Large—EM against number\nof documents in a single window.\ntraining samples would allow ﬁnetuning a model.\nWe leave exploring this issue for future work.\nD Additional Results\nD.1 Replication Experiments with GPT2\nTable 5 presents replication of the results shown in\nTable 1 for GPT2-Large and GPT2-XL models. A\nqualitative inspection of errors in these experiments\nsuggested that vanilla ICL fails more in examples\nwhere the test label appears earlier in the prompt.\nSince PCW allows more context windows, it more\noften shows a training example with the test label\ntowards the end of one of the windows. We eval-\nuated GPT2-Large performance on the AGNews\ndataset and discovered that PCW shows a training\nexample with the test label in a closer location to\nthe test example 62% of the time. In those cases,\nPCW outperforms ICL by 19.4%, compared to a\nmargin of roughly 10% for the entire test set. This\nanalysis suggests that PCW provides a solution to\nthe recency bias noted by Zhao et al. (2021).\nD.2 Multiple-Choice QA\nIn addition to our in-depth investigation of PCW,\nwe have experimented with two multiple-choice\nQA datasets OpenBookQA ( Mihaylov et al. , 2018)\nand StoryCloze ( Mostafazadeh et al. , 2017) under\nICL setting. We formatted and evaluated the tasks\nas in Brown et al. (2020), by providing few-shot\nexamples with the correct completion followed by\nan example of context only, and comparing the av-\nerage per-token LM likelihood of each possible\ncompletion. We did not use the calibration from\nBrown et al. (2020). We used the same setup as\ndescribed in Section 3.1, with the exception of re-\nducing the number of sampled training sets and\nJ1-Large (7.5B) J1-Grande (17B)\nDataset ICL PCW ICL PCW\nOpenBookQA 46.01.5 46.61.0 51.62.2 54.2∗\n1.7\nStoryCloze 84.21.0 84.30.8 84.70.9 84.61.0\nTable 4: Results for J1-Large and J1-Grande models for\nMultiple Choice datasets.\nthe test set size used for J1-Grande in the Open-\nBookQA experiment to 15 and 125, respectively.\nThe results shown in Table 4 show that increas-\ning the number of examples of in-context training\nunder the PCW setting improved the performance\nof J1-Grande in the OpenBookQA task, but did not\nsigniﬁcantly affect the other scenarios. Based on\nthis observation, it seems that PCW has the poten-\ntial of providing gains for multiple-choice tasks in\nspeciﬁc scenarios, but further analysis should be\nmade based on more datasets to better understand\nit. We leave this for future work.\n6396\nGPT2-Large(0.75B) GPT2-XL(1.5B)\nDataset # Labels ICL PCW ICL PCW\nSST-2 2 80.511.4 85.55.7\n∗ 90.73.8 93.02.1\n∗\nCR 2 81.36.3 83.84.7 79.46.0 82.93.4\n∗\nRTE 2 53.02.5 53.51.9 55.42.7 55.52.0\nSubj 2 67.412.3 69.511.8 68.010.8 68.66.7\nCB 3 45.34.7 44.44.2 53.59.2 51.97.0\nAGNews 4 61.912.9 72.57.0\n∗ 68.012.4 80.03.5\n∗\nSST-5 5 41.14.6 44.74.4\n∗ 37.17.9 43.35.9\n∗\nTREC 6 55.68.3 57.74.9 48.44.7 48.62.6\nDBPedia 14 63.118.9 80.75.3\n∗ 77.210.5 87.33.9\n∗\nNLU Scenario 18 37.06.1\n∗ 31.43.7 47.58.0 52.96.1\n∗\nTREC Fine 50 30.37.8 33.64.0\n∗ 36.86.4 39.52.8\n∗\nNLU Intent 68 24.35.4 28.14.4\n∗ 30.25.2 38.94.5\n∗\nBANKING77 77 29.35.3 28.54.0 30.94.0 33.73.2\n∗\nCLINIC150 150 44.23.2 45.41.8 46.92.5 48.71.9\n∗\nTable 5: Accuracy results for GPT2-Large and GPT2-XL models with regular ICL in comparison with using PCW\nwith B = 3prompts. The results mirror the results found in Table 1 and use the same format, with the exception of\nYELP dataset that had nmax = 0for GPT2 models.\nDataset # Labels ICL PCW ( B = 2) PCW ( B = 3) PCW ( B = 4)\nSST-2 2 93.51.6 94.11.3 93.81.1 94.01.1\nCR 2 93.90.7 93.80.7 93.90.7 92.91.5\nRTE 2 58.33.8 59.43.9 58.13.7 57.94.3\nSubj 2 84.17.7 81.97.5 79.17.2 77.77.0\nCB 3 65.28.0 59.97.7 61.28.2 56.85.4\nAGNews 4 79.83.6 80.92.4 81.52.1 81.91.9\nSST-5 5 45.53.9 46.33.9 47.42.9 46.12.8\nYELP 5 56.23.8 56.83.4 56.35.1 54.83.1\nTREC 6 87.04.5 88.83.4 89.43.2 89.73.0\nDBPedia 14 93.23.0 95.12.3 96.21.5 96.41.3\nNLU Scenario 18 81.92.2 83.41.7 84.21.5 84.61.4\nTREC Fine 50 60.56.9 65.23.8 68.83.4 68.83.2\nNLU Intent 68 69.73.3 77.72.1 79.71.9 80.91.9\nBANKING77 77 51.03.4 58.73.3 63.52.7 65.82.5\nCLINIC150 150 67.32.7 74.42.5 75.41.7 78.12.1\nTable 6: Results for different choices of B for J1-Large model. The best result for each dataset is boldfaced.\nDataset # Labels ICL PCW ( B = 2) PCW ( B = 3) PCW ( B = 4)\nSST-2 2 95.21.1 95.40.7 95.60.5 95.60.3\nCR 2 93.60.8 93.90.9 93.80.8 93.90.7\nRTE 2 61.25.1 64.22.7 62.23.0 62.43.4\nSubj 2 93.02.5 94.61.3 95.31.2 95.71.0\nCB 3 75.08.1 74.78.3 75.76.0 73.05.6\nAGNews 4 81.43.0 82.12.4 82.72.1 82.62.0\nSST-5 5 51.63.4 53.62.9 53.82.2 53.92.0\nYELP 5 66.22.2 66.61.7 65.62.0 65.51.9\nTREC 6 86.53.8 88.14.0 88.73.4 89.24.5\nDBPedia 14 92.53.3 95.82.7 97.31.6 97.91.3\nNLU Scenario 18 86.12.1 88.41.4 88.81.1 89.21.2\nTREC Fine 50 63.36.0 67.74.3 71.84.6 71.24.8\nNLU Intent 68 72.13.1 79.72.4 81.91.6 83.31.6\nBANKING77 77 55.23.3 64.53.1 69.12.2 70.92.8\nCLINIC150 150 68.92.5 76.52.5 78.61.8 80.22.6\nTable 7: Results for different choices of B for J1-Grande model. The best result for each dataset is boldfaced.\n6397\nDataset # Labels ICL PCW ( B = 2) PCW ( B = 3)\nSST-2 2 96.51.4 97.80.9 97.01.5\nCR 2 93.61.5 93.91.0 93.11.0\nRTE 2 63.95.0 65.23.9 66.04.1\nSubj 2 89.15.3 91.63.0 93.62.1\nCB 3 76.24.3 76.27.1 76.63.5\nAGNews 4 82.53.8 84.91.7 85.91.7\nSST-5 5 55.42.8 55.63.2 55.13.9\nYELP 5 66.34.1 68.32.5 65.42.6\nTREC 6 87.15.7 89.13.0 90.43.1\nDBPedia 14 91.74.4 96.22.6 96.52.3\nNLU Scenario 18 85.42.9 87.11.8 87.81.6\nTREC Fine 50 71.45.7 77.52.4 78.73.6\nNLU Intent 68 74.33.4 80.32.5 81.62.9\nBANKING77 77 55.33.5 65.93.9 70.93.1\nCLINIC150 150 65.75.0 74.84.2 79.92.1\nTable 8: Results for different choices of B for J1-Jumbo model. The best result for each dataset is boldfaced. For\ncomputational considerations, we have only attempted to use B = 2and B = 3.\n85\n90\n95SST-2\nJ1-Large J1-Grande\n72.5\n75.0\n77.5\n80.0\n82.5\n85.0AGNews\n2 4 6 8\n90\n92\n94\n96\n98DBPedia\n2 4 6 8\n# of Parallel Context Windows (B)\nFigure 7: Multi-class tasks beneﬁt from increased context windows, but simpler tasks with fewer classes may suffer\nfrom a decrease in performance.\n6398\nDataset nmax\nJ1\nnmax\nGPT2\nPrompt Example Labels\nSST-2 68 27 Review: , the power of this movie is undeniable .\nSentiment: positive\n[negative, positive]\nCR 54 21 premise: Review: in fact , i liked it so much after\nusing it with my son who is now 2 years old , that\ni bought one for our new baby ’ s room\nSentiment: positive\n[negative, positive]\nRTE 17 5 premise: The 10-day-old \"test-tube\" baby ele-\nphant born at Colchester Zoo has found a name,\nthanks to the internet!\nhypothesis: baby elephant born\nprediction: True\n[True, False]\nSubj 42 18 Input: they follow him to las vegas , where he is\nostensibly doing “ research “ for the next season\n, but is actually pursuing a dream to become a\ndancer in a vegas show .\nType: objective\n[objective, subjective]\nCB 19 5 premise: Paula could not help herself. It was just\nthe way she was. Others might say they hated her\nand mean it.\nhypothesis: others hated Paula\nprediction: true\n[true, false, neither]\nAGNews 30 11 input: Citigroup faces regulatory probe The UK’s\nFinancial Services Authority launches a formal\ninvestigation into Citigroup’s \"unusual trading\nactivity\".\ntype: business\n[world, sports, business, technology]\nSST-5 51 20 Review: it ’s just a little too self-satisﬁed .\nSentiment: okay\n[terrible, bad, okay, good, great]\nYELP 5 0 review: Good modern atmosphere and delicious\ncupcakes.\nstars: 3\n[1, 2, 3, 4, 5]\nTREC 88 38 Question: When was the ﬁrst Barbie produced ?\nType: numeric\n[abbreviation, entity, description, human, loca-\ntion, numeric]\nDBPedia 21 7 input: The Bstanu River is a tributary of the Râul\nMare in Romania.\ntype: nature\n[company, school, artist, athlete, politics, trans-\nportation, building, nature, village, animal, plant,\nalbum, ﬁlm, book]\nNLU\nScenario\n112 43 utterance: you have got the answer right.\nscenario: general\n[lists, weather, general, cooking, email, alarm,\ndatetime, calendar, social, transport, iot, recom-\nmendation, takeaway, play, music, qa, news, au-\ndio]\nTREC\nFine\n84 37 Question: What dropped 1 , 313 feet in 1980 ?\nType: entity other\n[abbreviation abbreviation, abbreviation expan-\nsion, entity animal, entity body, entity color, en-\ntity creation, entity currency, entity disease, entity\nevent, entity food...\nNLU\nIntent\n101 43 utterance: please read out the tasks from the list\nfor today\nintent: lists query\n[alarm query, alarm remove, alarm set, audio\nvolume down, audio volume mute, audio volume\nother, audio volume up, calendar query, calendar\nremove, calendar set...\nBANK-\nING77\n77 27 query: Card payment didn’t go through.\nintent: declined card payment\n[activate my card, age limit, apple pay or google\npay, atm support, automatic top up, balance not\nupdated after bank transfer, balance not updated\nafter cheque or cash deposit...\nCLINIC150 101 39 utterance: i would like to look up my credit score\nplease\nintent: credit score\n[restaurant reviews, nutrition info, account\nblocked, oil change how, time, weather, redeem\nrewards, interest rate, gas type...\nTable 9: Table of classiﬁcation datasets with their used prompts and the nmax for both GPT2 and J1 tokenizers. For\nreadability, we truncated the list of labels for some of the multi-label tasks.\n6399\nTask Prompt\nNatural Questions (NQ) Title: We Bought a Zoo\nEvidence: We Bought a Zoo We Bought a Zoo is a 2011 American family... The ﬁlm also stars\nScarlett Johansson, Maggie Elizabeth Jones...\nQuestion: who is the little girl on we bought a zoo?\nAnswer: Maggie Elizabeth Jones\nTitle: Vaal River\nEvidence: ...The river ﬂows west into the Grootdraai Dam near Standerton, Mpumalanga. On its\ncourse to the Vaal Dam in Vereeniging...\nQuestion: where does the vaal dam get its water from?\nAnswer: Vaal River\n==\nTitle: San Juan River (Colorado River tributary)\nEvidence: in the San Juan Mountains has often been diminished by warming winter temperatures..\n==\nTitle: olorad\nEvidence: drained by the Colorado River. The South Park of Colorado is the region of the\nheadwaters of the South Platte River...\n==\nTitle: San Juan River (Colorado River tributary)\nEvidence: ...Colorado at the conﬂuence of its East and West Forks. Both forks originate above\nelevations of in the eastern San Juan Mountains in the San Juan National Forest...\n==\nQuestion: where are the san juan mountains in new mexico?\nAnswer:\nHotpotQA Evidences:\n==\nThe 2009 Singapore Grand Prix (formally the 2009 Formula 1 SingTel Singapore Grand Prix) was\na Formula One motor race held at the Marina Bay Street Circuit in Singapore on 27 September\n2009...\n==\nCatharina Felser (born October 2, 1982) is a German race car driver born in Siegburg...\n==\n...Sergio Pérez, the only other Mexican to ﬁnish on the podium, currently races with Sahara\nForce India F1 Team .\n==\nSergio Pérez Mendoza ( ; born 26 January 1990) also known as \"Checo\" Pérez, is a Mexican\nracing driver, currently driving for Force India.\n==\nQuestion: Which other Mexican Formula One race car driver has held the podium besides the\nForce India driver born in 1990?\nAnswer:\nTable 10: Prompt formats for Natural Questions (NQ) and HotpotQA. The prompts were manually shortened for\nreadability.\n6400\nACL 2023 Responsible NLP Checklist\nA For every submission:\n□\u0013 A1. Did you describe the limitations of your work?\nSection Limitations\n□\u0017 A2. Did you discuss any potential risks of your work?\nWe see no reasonable direct potential risk\n□\u0013 A3. Do the abstract and introduction summarize the paper’s main claims?\nSee abstract and section 1.\n□\u0017 A4. Have you used AI writing assistants when working on this paper?\nLeft blank.\nB □\u0013 Did you use or create scientiﬁc artifacts?\nSee sections 3-4.\n□\u0013 B1. Did you cite the creators of artifacts you used?\nSee sections 3,4 and appendix B.\n□\u0013 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\nSee appendix B.\n□\u0017 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\nAll the artifacts were used for research purposes, similarly to how they were used in many other\npapers.\n□\u0017 B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiﬁes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nThe datasets used are quite common and are publicly available.\n□\u0013 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\nSee appendix B\n□\u0013 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiﬁcant, while on small test sets they may not be.\nSee appendix B.\nC □\u0013 Did you run computational experiments?\nSee Sections 3-4 and appendices C-D.\n□\u0013 C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\nSee section 3 and appendix A.\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n6401\n□\u0013 C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\nSee sections 3,4 and appendices.\n□\u0013 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\nSee sections 3 and 4.\n□\u0013 C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\nSee appendix B.\nD □\u0017 Did you use human annotators (e.g., crowdworkers) or research with human participants?\nLeft blank.\n□ D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\nNo response.\n□ D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants’ demographic\n(e.g., country of residence)?\nNo response.\n□ D3. Did you discuss whether and how consent was obtained from people whose data you’re\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nNo response.\n□ D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\nNo response.\n□ D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nNo response.\n6402",
  "topic": "Context (archaeology)",
  "concepts": [
    {
      "name": "Context (archaeology)",
      "score": 0.6582342982292175
    },
    {
      "name": "Computer science",
      "score": 0.6173474788665771
    },
    {
      "name": "Computational linguistics",
      "score": 0.42884671688079834
    },
    {
      "name": "Programming language",
      "score": 0.39429640769958496
    },
    {
      "name": "Linguistics",
      "score": 0.3664143979549408
    },
    {
      "name": "Natural language processing",
      "score": 0.33351677656173706
    },
    {
      "name": "Computer graphics (images)",
      "score": 0.3270324468612671
    },
    {
      "name": "History",
      "score": 0.19422301650047302
    },
    {
      "name": "Philosophy",
      "score": 0.18661171197891235
    },
    {
      "name": "Archaeology",
      "score": 0.13720202445983887
    }
  ],
  "institutions": [],
  "cited_by": 33
}