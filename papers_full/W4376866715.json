{
    "title": "Large Language Models in Medical Education: Opportunities, Challenges, and Future Directions",
    "url": "https://openalex.org/W4376866715",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A5103070560",
            "name": "Alaa Abd‐Alrazaq",
            "affiliations": [
                "Weill Cornell Medical College in Qatar"
            ]
        },
        {
            "id": "https://openalex.org/A5016543807",
            "name": "Rawan AlSaad",
            "affiliations": [
                "Qatar Science and Technology Park",
                "Weill Cornell Medical College in Qatar"
            ]
        },
        {
            "id": "https://openalex.org/A5053540130",
            "name": "Dari Alhuwail",
            "affiliations": [
                "Kuwait University"
            ]
        },
        {
            "id": "https://openalex.org/A5001592898",
            "name": "Arfan Ahmed",
            "affiliations": [
                "Weill Cornell Medical College in Qatar"
            ]
        },
        {
            "id": "https://openalex.org/A5004416931",
            "name": "M Healy",
            "affiliations": [
                "Weill Cornell Medical College in Qatar"
            ]
        },
        {
            "id": "https://openalex.org/A5003060473",
            "name": "Syed Latifi",
            "affiliations": [
                "Weill Cornell Medical College in Qatar"
            ]
        },
        {
            "id": "https://openalex.org/A5056435145",
            "name": "Sarah Aziz",
            "affiliations": [
                "Weill Cornell Medical College in Qatar"
            ]
        },
        {
            "id": "https://openalex.org/A5079507190",
            "name": "Rafat Damseh",
            "affiliations": [
                "United Arab Emirates University"
            ]
        },
        {
            "id": "https://openalex.org/A5063175992",
            "name": "Sadam Alabed Alrazak",
            "affiliations": [
                "University of Toronto"
            ]
        },
        {
            "id": "https://openalex.org/A5045843215",
            "name": "Javaid I. Sheikh",
            "affiliations": [
                "Weill Cornell Medical College in Qatar"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3172942063",
        "https://openalex.org/W4363645798",
        "https://openalex.org/W4362716434",
        "https://openalex.org/W4361017283",
        "https://openalex.org/W4361296421",
        "https://openalex.org/W4320893927",
        "https://openalex.org/W4323038373",
        "https://openalex.org/W4319663047",
        "https://openalex.org/W4324020772",
        "https://openalex.org/W4327915219",
        "https://openalex.org/W4324130227",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W4319350602",
        "https://openalex.org/W4319299307",
        "https://openalex.org/W4362708482",
        "https://openalex.org/W4316671929",
        "https://openalex.org/W4320709689",
        "https://openalex.org/W4362734502",
        "https://openalex.org/W4323835279",
        "https://openalex.org/W4319460874",
        "https://openalex.org/W4322761615",
        "https://openalex.org/W4321446367",
        "https://openalex.org/W4321116084",
        "https://openalex.org/W4321351832",
        "https://openalex.org/W2044487099",
        "https://openalex.org/W4292088805",
        "https://openalex.org/W3094858067",
        "https://openalex.org/W4286493308",
        "https://openalex.org/W3162522014",
        "https://openalex.org/W4282916733",
        "https://openalex.org/W4318925155",
        "https://openalex.org/W4280602135",
        "https://openalex.org/W4323350039",
        "https://openalex.org/W4318931874",
        "https://openalex.org/W4320895630",
        "https://openalex.org/W4323347604",
        "https://openalex.org/W4319301505",
        "https://openalex.org/W4321435202",
        "https://openalex.org/W4321460183",
        "https://openalex.org/W4322743583",
        "https://openalex.org/W4324364344",
        "https://openalex.org/W4321499901",
        "https://openalex.org/W4376108655",
        "https://openalex.org/W4319334927",
        "https://openalex.org/W4319227726",
        "https://openalex.org/W4322723456",
        "https://openalex.org/W2003759405",
        "https://openalex.org/W4364378939",
        "https://openalex.org/W4313453502",
        "https://openalex.org/W4312083290",
        "https://openalex.org/W4313451803",
        "https://openalex.org/W4317910584",
        "https://openalex.org/W4210491685",
        "https://openalex.org/W4225907492",
        "https://openalex.org/W4284991798",
        "https://openalex.org/W4315498620"
    ],
    "abstract": "The integration of large language models (LLMs), such as those in the Generative Pre-trained Transformers (GPT) series, into medical education has the potential to transform learning experiences for students and elevate their knowledge, skills, and competence. Drawing on a wealth of professional and academic experience, we propose that LLMs hold promise for revolutionizing medical curriculum development, teaching methodologies, personalized study plans and learning materials, student assessments, and more. However, we also critically examine the challenges that such integration might pose by addressing issues of algorithmic bias, overreliance, plagiarism, misinformation, inequity, privacy, and copyright concerns in medical education. As we navigate the shift from an information-driven educational paradigm to an artificial intelligence (AI)–driven educational paradigm, we argue that it is paramount to understand both the potential and the pitfalls of LLMs in medical education. This paper thus offers our perspective on the opportunities and challenges of using LLMs in this context. We believe that the insights gleaned from this analysis will serve as a foundation for future recommendations and best practices in the field, fostering the responsible and effective use of AI technologies in medical education.",
    "full_text": "Viewpoint\nLarge Language Models in Medical Education: Opportunities,\nChallenges, and Future Directions\nAlaa Abd-alrazaq1, PhD; Rawan AlSaad1,2, PhD; Dari Alhuwail3, PhD; Arfan Ahmed1, PhD; Padraig Mark Healy4,\nMSc; Syed Latifi4, PhD; Sarah Aziz1, MSc; Rafat Damseh5, PhD; Sadam Alabed Alrazak6, BSc; Javaid Sheikh1, MD\n1AI Center for Precision Health, Weill Cornell Medicine-Qatar, Doha, Qatar\n2College of Computing and Information Technology, University of Doha for Science and Technology, Doha, Qatar\n3Information Science Department, College of Life Sciences, Kuwait University, Kuwait, Kuwait\n4Office of Educational Development, Division of Medical Education, Weill Cornell Medicine-Qatar, Doha, Qatar\n5Department of Computer Science and Software Engineering, United Arab Emirates University, Abu Dhabi, United Arab Emirates\n6Department of Mechanical & Industrial Engineering, Faculty of Applied Science and Engineering, University of Toronto, Toronto, ON, Canada\nCorresponding Author:\nAlaa Abd-alrazaq, PhD\nAI Center for Precision Health\nWeill Cornell Medicine-Qatar\nPO Box 5825, Doha Al Luqta St\nAr-Rayyan\nDoha, NA\nQatar\nPhone: 974 55708549\nEmail: alaa_alzoubi88@yahoo.com\nAbstract\nThe integration of large language models (LLMs), such as those in the Generative Pre-trained Transformers (GPT) series, into\nmedical education has the potential to transform learning experiences for students and elevate their knowledge, skills, and\ncompetence. Drawing on a wealth of professional and academic experience, we propose that LLMs hold promise for revolutionizing\nmedical curriculum development, teaching methodologies, personalized study plans and learning materials, student assessments,\nand more. However, we also critically examine the challenges that such integration might pose by addressing issues of algorithmic\nbias, overreliance, plagiarism, misinformation, inequity, privacy, and copyright concerns in medical education. As we navigate\nthe shift from an information-driven educational paradigm to an artificial intelligence (AI)–driven educational paradigm, we\nargue that it is paramount to understand both the potential and the pitfalls of LLMs in medical education. This paper thus offers\nour perspective on the opportunities and challenges of using LLMs in this context. We believe that the insights gleaned from this\nanalysis will serve as a foundation for future recommendations and best practices in the field, fostering the responsible and\neffective use of AI technologies in medical education.\n(JMIR Med Educ 2023;9:e48291) doi: 10.2196/48291\nKEYWORDS\nlarge language models; artificial intelligence; medical education; ChatGPT; GPT-4; generative AI; students; educators\nIntroduction\nWe are witnessing a significant paradigm shift in the field of\nartificial intelligence (AI) due to the emergence of large-scale\nself-supervised models that can be leveraged to automate a wide\nvariety of downstream tasks. These models are now referred to\nas foundation models, with many notable examples, such as\nOpenAI’s GPT-4 [1] and DALL-E [2], Meta’s SAM (Segment\nAnything Model) [3] and LLaMA [4], and Google’s LaMDA\n(Language Models for Dialog Applications) [5] and large-scale\nViT (Vision Transformer) [6]. These models are trained on\nmassive amounts of data and are capable of performing tasks\nrelated to natural language processing, computer vision, robotic\nmanipulation, and computer-human interaction. Language-based\nfoundation models, or large language models (LLMs), can\nunderstand and generate natural language text, allowing them\nto engage in human-like conversations, with coherent and\ncontextually appropriate responses to user prompts. Remarkably,\ndue to the advancement of these large-scale AI systems, they\nJMIR Med Educ 2023 | vol. 9 | e48291 | p. 1https://mededu.jmir.org/2023/1/e48291\n(page number not for citation purposes)\nAbd-alrazaq et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\nare now able to generate human-like content (eg, texts, images,\ncodes, audio, and videos).\nThe Generative Pre-trained Transformers (GPT) series models\nlaunched by OpenAI are examples of foundation models that\nare based on generative AI (ie, AI models used to generate new\ncontent, such as texts, images, codes, audio, and videos, based\non the training data they have been exposed to). OpenAI\nlaunched the first model of the GPT series (GPT-1) in 2018,\nfollowed by GPT-2 in 2019, GPT-3 in 2020, ChatGPT in 2022,\nand GPT-4 in 2023, with each iteration representing significant\nimprovements over the previous one. GPT-4 is one of the most\nadvanced AI-based chatbots available today. GPT-4 is an\nadvanced multimodal foundation model that has state-of-the-art\nperformance in generating human-like text based on user\nprompts [1]. Unlike previous GPT series models (eg, ChatGPT,\nGPT-3, and GPT-2), which accept only text inputs, GPT-4 can\nprocess image inputs, in addition to text inputs, to return textual\nresponses [1]. Furthermore, GPT-4 has a larger model size (more\nparameters); has been trained on a larger amount of data; and\ncan generate more detailed responses (more than 25,000 words),\nwith a high level of fidelity [7]. Based on rigorous\nexperimentation, GPT-4 capabilities demonstrate improved\nreasoning, creativity, safety, and alignment and the ability to\nprocess complex instructions [1]. As a result, GPT-4 is now\nactively used by millions of users for language translation,\nsentiment analysis, image captioning, text summarization,\nquestion-answering systems, named entity recognition, content\nmoderation, text paraphrasing, personalized recommendations,\ntext completion and prediction, programming code generation\nand debugging, and so forth.\nUndoubtedly, the versatility and capabilities of current\ngenerative AI and LLMs (eg, GPT-4) will revolutionize various\ndomains, with one of particular interest being medical education.\nThe integration of such technologies into medical education\noffers numerous opportunities for enhancing students’\nknowledge, skills, and competence. For instance, LLMs can be\nused to produce clinical case studies, act as virtual test subjects\nor virtual patients, facilitate and accelerate research outputs,\ndevelop course plans, and provide personalized feedback and\nassistance. However, their adoption in medical education\npresents serious challenges, such as plagiarism, misinformation,\noverreliance, inequity, privacy, and copyright issues. In order\nto shift medical education practices from being\ninformation-driven to being AI-driven through the use of LLMs,\nit is essential to acknowledge and address the concerns and\nchallenges associated with the adoption of LLMs. This is\nnecessary to ensure that students and educators understand how\nto use these tools effectively and appropriately to fully leverage\ntheir potential. To this end, the objective of this paper is to\nexplore the opportunities, challenges, and future directions of\nusing LLMs in medical education. This paper uses GPT-4 as a\ncase study to discuss these opportunities and challenges, as it\nis a state-of-the-art generative LLM that was available at the\ntime of writing.\nOpportunities\nOverview\nLLMs have the potential to significantly impact all phases of\nmedical education programs, offering numerous benefits in\nvarious aspects, including curriculum planning, delivery,\nassessments, programmatic enhancements, and research [8-30].\nThis section elucidates and illustrates the specific opportunities\nand applications of LLMs that can be leveraged to deliver a\nmore efficient, effective, personalized, and engaging medical\neducation system that is better equipped to prepare future health\ncare professionals. Figure 1 shows the main opportunities of\nLLMs in medical education.\nFigure 1. Opportunities of large language models in medical education.\nJMIR Med Educ 2023 | vol. 9 | e48291 | p. 2https://mededu.jmir.org/2023/1/e48291\n(page number not for citation purposes)\nAbd-alrazaq et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\nCurriculum Development\nMedical curriculum planning is a complex process that requires\ncareful consideration of various factors, including educational\nobjectives, teaching methodologies, assessment strategies, and\nresource allocation [31]. LLMs, like GPT-4, can play a\nsignificant role in enhancing this process by conducting needs\nassessments and analyses and providing expert-level knowledge\nand insights on various medical topics, helping educators\nidentify content gaps and ensure comprehensive coverage of\nessential subjects [8,17]. Additionally, GPT-4 can assist in\ndeveloping measurable learning objectives for each phase of a\nmedical program curriculum and customizing it to meet the\ndiverse needs of individual learners, fostering personalized and\nadaptive learning experiences. By analyzing students'\nperformance data, LLMs can suggest targeted interventions and\nrecommend specific resources to address learning gaps and\noptimize educational outcomes [16,17]. Furthermore, this\nintegration of LLMs and GPT-4 into medical curriculum\nplanning can support faculty in designing, updating, or\nmodifying a medical curriculum; LLMs can provide suggestions\nfor course content, learning objectives, and teaching\nmethodologies based on the emerging trends and best practices\nin medical education, freeing up more time for faculty to focus\non other teaching aspects [32-34].\nTeaching Methodologies\nLLMs, like GPT-4, can be used to augment existing teaching\nmethodologies in medical education programs, enhancing the\noverall learning experience for students. For example, LLMs\ncan supplement lecture content by providing real-time\nclarifications, additional resources, and context to complex\ntopics, ensuring a deeper understanding for students [35,36].\nFor small-group sessions, GPT-4 can facilitate discussions by\ngenerating thought-provoking questions, encouraging\npeer-to-peer interactions, and fostering an engaging and\ncollaborative learning environment. For virtual patient\nsimulations, LLMs can create realistic virtual patient scenarios,\nask questions, interpret responses, and provide feedback,\nallowing students to practice clinical reasoning,\ndecision-making, and communication skills in a safe and\ncontrolled setting. For interactive medical case studies, GPT-4\ncan generate case studies that are tailored to specific learning\nobjectives and guide students through the diagnostic process,\ntreatment options, and ethical considerations, thereby allowing\nstudents to interactively explore both common conditions and\nrare conditions, which can help to prepare them for real-world\nclinical practice [37]. An example of using ChatGPT (GPT-4)\nto create interactive case studies for medical students is included\nin Multimedia Appendix 1. For clinical rotations, as virtual\nmentors, LLMs can help students apply theoretical knowledge\nto real-world situations by offering instant feedback and\npersonalized guidance to reinforce learning and address\nmisconceptions.\nPersonalized Study Plans and Learning Materials\nBy leveraging the power of LLMs and generative AI tools,\nstudents can input information about their individual strengths,\nweaknesses, goals, and preferences to generate study plans that\nare tailored to their specific needs. This level of personalization\nensures that each student's unique learning style and pace are\ntaken into account, leading to more efficient and effective\nlearning [38]. Moreover, LLMs, like GPT-4, can also generate\npersonalized learning materials, including concise summaries,\nflash cards, and practice questions, that target specific areas\nwhere a student needs improvement. An example of using an\nLLM, like ChatGPT, to provide personalized explanations of\nmedical terminology (ie, aphthous stomatitis) to students at\ndifferent levels (premedical students, year 2 medical students,\nand year 4 medical students) is presented in Multimedia\nAppendix 2. Tailored resources can help students focus on the\nmost relevant content, optimizing their study time and enhancing\nknowledge retention. Furthermore, an iterative feedback loop\ncould be established wherein students use LLM-generated\nmaterials and provide feedback, which is then used to fine-tune\nthe LLM's outputs. Over time, this could lead to increasingly\naccurate and effective personalized learning materials.\nAssessment and Evaluation\nLLMs and GPT-4 can play a significant role in designing\ncomprehensive assessment plans and enhancing the evaluation\nprocess in medical education [14,18,26]. They can be utilized\nto (1) develop comprehensive, well-rounded assessment plans\nthat incorporate formative and summative evaluations,\ncompetency-based assessments, and effective feedback\nmechanisms; (2) align assessment methods with learning\nobjectives by analyzing learning objectives and suggesting\nappropriate assessment methods that accurately measure\nstudents' progress toward achieving the desired competencies;\nand (3) provide prompt feedback and rubrics by automating the\nprocess of providing timely and actionable feedback to students,\nidentifying areas of strength and weakness, and offering targeted\nsuggestions for improvement. Additionally, GPT-4 can assist\nin the creation of transparent and consistent grading rubrics,\nensuring that students understand the expectations and criteria\nfor success.\nMedical Writing Assistance\nLLMs have become valuable tools in medical writing, offering\na range of benefits to medical students and medical researchers\n[37,39-43]. LLMs, like GPT-4, can assist medical students and\neducators in selecting appropriate language, terminology, and\nphrases for use in their writing, ensuring accuracy and\nreadability for their intended audience. Furthermore, LLMs can\nprovide guidance on writing style and formatting, helping\nstudents to improve the clarity and coherence of their work. By\nleveraging these chatbots' capabilities, medical students can\nstreamline their writing process and produce high-quality work,\nresulting in time that can be reallocated to other aspects of their\nstudies.\nMedical Research and Literature Review\nLLMs are valuable tools for medical research and literature\nreviews, providing a faster, more efficient, and more accurate\nmeans of gathering and analyzing data [26,28,44-46]. With the\nability to access, extract, and summarize relevant information\nfrom scientific literature, electronic medical records, and other\nsources, these chatbots enable medical students and researchers\nto quickly and efficiently gather the information they need for\nJMIR Med Educ 2023 | vol. 9 | e48291 | p. 3https://mededu.jmir.org/2023/1/e48291\n(page number not for citation purposes)\nAbd-alrazaq et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\ntheir reports, papers, and research articles. By leveraging the\ndata extraction capabilities of LLMs, medical students and\nresearchers can more easily access and analyze the vast amounts\nof information available to them (Multimedia Appendix 3). This\nensures that their research is grounded in accurate and reliable\ndata, allows them to make well-informed conclusions based on\ntheir findings, and frees up valuable time and resources that can\nbe directed toward other important aspects of the research\nprocess. Moreover, when writing research papers, medical\nstudents can use LLMs for help with generating outlines and\ndrafting introductions or conclusions; LLMs can also suggest\npossible ways to discuss and analyze results (Multimedia\nAppendix 4).\nProgram Monitoring and Review\nLLMs and generative AI tools, when integrated into curriculum\nmanagement systems, have enormous potential to transform the\nmonitoring and review of medical education programs. By\nanalyzing data collected through various sources, including\nstudent feedback, testing results, and program delivery data,\nLLMs like GPT-4 can provide program leaders with valuable\ninsights into the efficacy of their programs. LLMs can identify\nareas of improvement, monitor trends in student performance,\nand provide benchmarks against which program performance\ncan be evaluated. LLMs can also analyze national health\npriorities and community needs to help programs adapt and\nadjust their objectives and allocation of resources accordingly.\nBy leveraging these tools, program leaders can gain insights\nand make data-driven decisions that enhance the quality and\neffectiveness of medical education programs.\nChallenges\nOverview\nDespite the abovementioned opportunities that LLMs and\ngenerative AI tools can provide, they have limitations in medical\neducation. These challenges and limitations are discussed in\nthe following subsections. Figure 2 shows the main challenges\nof LLMs in medical education.\nFigure 2. Challenges of large language models in medical education.\nAcademic Dishonesty\nThe ability of LLMs to respond to short-answer and\nmultiple-choice exam questions can be exploited for cheating\npurposes [47]. As mentioned earlier, LLMs can write medical\nessays that are difficult to distinguish from human-generated\nessays, which may increase plagiarism. Although several tools\n(eg, GPTZero, Originality.AI, OpenAI AI Text Classifier, and\nTurnitin AI Writing Detector) have been developed to detect\nAI-generated text, students may still be able to make their\nAI-generated essays undetectable to such tools. Specifically, a\nstudy demonstrated that adding 1 word (“amazing”) to an\nAI-generated text reduced the fake level (ie, generated by AI)\ndetected by a tool from 99% to 24% [48]. Although this is just\n1 example, it still increases and highlights apprehensions\nregarding the effectiveness of such tools in detecting and\npreventing plagiarism.\nMisinformation and Lack of Reliability\nAlthough recent LLMs (eg, GPT-4) have significantly reduced\nhallucinations in comparison with earlier models [1], due to\ninaccurate training data, recent LLMs still generate incorrect\nor inaccurate information that is convincingly written. Given\nthe authoritative writing style generated by these systems,\nstudents may find it challenging to differentiate between genuine\nknowledge and unverified information. As a result, they may\nnot scrutinize the validity of information and end up believing\ninaccurate or deceptive information [49]. Further, such\nmisinformation may make LLMs untrustworthy among users\nand thus may decrease the adoption of LLMs. As an example\nof misinformation, studies showed that LLMs, such as GPT-4,\neither include citations that do not exist in generated articles or\ninclude citations that are irrelevant to the topic [41,50-52]. This\nraises the question of how to guarantee that generative AI tools\nand LLMs remain assistive technologies and not propagators\nof false or misleading health information.\nLack of Consistency\nRecent LLMs and generative AI tools generate different outputs\nfor the same prompt. Although this feature may be helpful in\nsome cases, it has several disadvantages [53]. First, generating\ndifferent responses to the same prompt may prevent educators\nJMIR Med Educ 2023 | vol. 9 | e48291 | p. 4https://mededu.jmir.org/2023/1/e48291\n(page number not for citation purposes)\nAbd-alrazaq et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\nfrom detecting whether the text was generated by AI. Second,\nthis feature may produce contradicting responses on the same\ntopic. Finally, this feature may generate responses with different\nqualities. For example, in a study [48], 3 researchers at the same\nlocation asked an LLM-based chatbot the exact same question\nat the same time, but they received 3 different responses of\ndifferent quality. Specifically, the first researcher received a\nmore up-to-date, complete, and organized response compared\nto the responses that the second and third researchers received\n[48]. Accordingly, one may inquire about the methods to\nguarantee fair access, for all users (students and educators), to\nidentical, up-to-date, and high-quality learning materials.\nAlgorithmic Bias\nGiven that recent LLMs (eg, GPT-4) are trained on a large\ncorpus of text data from the internet (eg, websites, books, news\narticles, scientific papers, and movie subtitles), it is likely that\nthey are trained on biased or unrepresentative data. OpenAI has\nacknowledged that GPT-4 may still generate biased responses\nlike earlier GPT models, thereby reinforcing social biases and\nstereotypes [1]. For example, if an LLM was trained on data\nrelated to disease among a certain ethnic group, then it is likely\nthat it generates responses (eg, essays, exams, and clinical case\nscenarios) that are biased toward that group. According to a\nstudy [54], an LLM that was trained on a vast corpus of internet\ntext demonstrated gender bias in its output.\nOverreliance\nAs mentioned earlier, recent generative AI tools (eg, GPT-4)\nhave a tendency to make up facts and present incorrect\ninformation in more convincing and believable ways [1]. This\nmay cause users to excessively trust generative AI tools, thereby\nincreasing the risk of overreliance. Therefore, the use of\ngenerative AI tools may hinder the development of new skills\nor even lead to the loss of skills that are foundational to medical\nstudent development, such as critical thinking, problem-solving,\nand communication. In other words, the ease with which\ngenerative AI tools can provide answers could lead to a decrease\nin students’ motivation to conduct independent investigations\nand arrive at their own conclusions or solutions. This raises the\nquestion of how generative AI tools can be used to improve\nrather than reduce critical thinking and problem-solving in\nstudents.\nLack of Human Interaction and Emotions\nCurrent LLMs are unable to deliver the same degree of human\ninteraction as an actual educator or tutor. This is because, at\npresent, (1) their capabilities are restricted to a textual interface,\n(2) they are incapable of recognizing the physical gestures or\nmovements of students and educators, and (3) they cannot reveal\nany emotions. The absence of human interaction can negatively\naffect students who prefer a personal connection with their\neducator. According to a study conducted by D'Mello and\ncolleagues [55], students who engaged with a virtual tutor that\nimitated human-like emotional behavior demonstrated superior\nlearning outcomes compared to those who engaged with a virtual\ntutor that lacked such behavior. Hence, it is worth considering\nways to humanize generative AI tools not just in their ability\nto think and provide responses but also in terms of exhibiting\nemotions and possessing a distinctive personality.\nLimited Knowledge\nLLMs, like GPT-4, depend on the data used for training, which\ncover a wide range of general information but might not always\nencompass the latest or most specialized medical knowledge.\nThis constraint impacts the reliability and precision of the\ninformation generated by LLMs in medical education\nenvironments, where accuracy and expertise are essential [26].\nMoreover, the knowledge base of most LLMs is presently static,\nwhich means that they cannot learn and adjust in real time as\nnew medical information emerges. However, the field of\nmedicine is constantly evolving, with novel research findings,\nguidelines, and treatment protocols being regularly introduced\n[56]. Additionally, the restricted knowledge of current LLMs\nin medical education could result in a superficial understanding\nof complex medical concepts, lacking the necessary depth and\ncontext for effective learning. For instance, while GPT-4 can\nproduce text that seems coherent and factually correct at first\nglance, it may not always capture the subtleties and complexities\nof medical knowledge, thus falling short in providing\ncomprehensive and accurate guidance for medical students and\neducators.\nInequity in Access\nGenerative AI tools and LLMs may increase the inequity among\nstudents and educators, given that these tools are not equally\naccessible to all of them. For example, although most generative\nAI tools can communicate in several languages, in addition to\nEnglish, and outperform earlier chatbots in this aspect, their\nproficiency in each language varies based on the amount and\nquality of training data available for each language [1]; thus,\nstudents and educators who are not proficient in English are\nless likely to use them. Further, generative AI tools may be less\naccessible to (1) those who are not familiar with using\ntechnologies or AI tools; (2) those who do not have access to\nthe necessary technology (eg, internet and computers); (3) those\nwho cannot afford subscription fees (eg, US $20/month for\nGPT-4); and (4) those with disabilities, such as blindness or\nmotor impairment.\nPrivacy\nWhen communicating with LLMs, students and educators may\nreveal their personal information (eg, name, email, phone\nnumber, prompts, uploaded images, and generated images).\nOpenAI acknowledges that it may use users’ personal\ninformation for several purposes, such as analyzing, maintaining,\nand improving its services; conducting research; preventing\nfraud, criminal activity, or misuse of its services; and complying\nwith legal obligations and legal processes [57]. Moreover,\nOpenAI may share users’personal information with third parties\nwithout further notice to users or users’ consent [57]. A recent\nreflection of these concerns is Italy's data protection group\ndiscontinuing access to ChatGPT while it conducts an\ninvestigation around data use and collection practices, in\nalignment with requirements of the General Data Protection\nRegulation [58]. In addition, LLM use during clerkship clinical\nrotations for patient care (eg, SOAP [Subjective, Objective,\nJMIR Med Educ 2023 | vol. 9 | e48291 | p. 5https://mededu.jmir.org/2023/1/e48291\n(page number not for citation purposes)\nAbd-alrazaq et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\nAssessment, and Plan] note generation) could result in\nunintended patient privacy breaches. Questions surrounding\nhow to safeguard student and patient data should be central in\ncurricular discussions.\nCopyright\nLLMs may be trained on copyrighted materials (eg, books,\nscientific articles, and images), thereby potentially producing\ntext that bears similarity to or even directly copies content\nprotected by copyright, which could potentially impact\ndownstream uses. Such a situation brings up apprehensions\nregarding the utilization of content created by generative AI\ntools (eg, educational materials, presentations, course syllabi,\nquizzes, and scientific papers) without appropriate\nacknowledgment and authorization from the copyright holder.\nThere are ongoing discussions related to authorship rights for\narticles that are written by using LLMs. Although various\npublishers and editors do not accept listing such tools as\ncoauthors (eg, those of Nature, Jinan Journal, and eLife), others\ndo (eg, those of Oncoscience [59], Nurse Education in Practice\n[60], and medRxiv [61]). As this is an area likely to evolve, it\nraises questions regarding how students and educators should\nacknowledge the use of these systems while complying with\nprofessional and regulatory expectations.\nFuture Directions\nOverview\nConsidering the opportunities and challenges presented by the\nuse of LLMs and generative AI tools in medical education, we\ndiscuss future directions, targeting academic institutions,\neducators, students, developers, and researchers. We argue that\nthose who embrace the use of the technology, including LLMs,\nwill challenge the status quo and will likely be better positioned\nand higher performing than those who do not. Therefore, the\nfollowing recommendations and future directions can be useful\nto all of the previously mentioned stakeholders and many others.\nAcademic Institutions\nWith the rise of generative AI tools and LLMs, there is a fear\nthat in the future, these technologies may make the human brain\ndormant in nearly all tasks, including some of the basic ones.\nNow more than ever, medical schools and academic institutions\nneed to consider the appropriate strategies to incorporate the\nuse of LLMs into medical education. One possibility is to\ndevelop guidelines or best practices for the use of AI tools in\ntheir assignments. These guidelines should explain to students\nhow to properly disclose or cite any content generated by LLMs\nwhen writing essays, research papers, and assignments.\nAcademic institutions may also subscribe to tools that can detect\nAI-generated text, such as Turnitin, ZeroGPT, and\nOriginality.AI. Academic institutions should provide training\nsessions and workshops to teach students and educators how to\neffectively and ethically use such tools in medical education.\nUltimately, academic institutions should favor student-centered\npedagogy that nurtures building trusting relationships that focus\non assessment for learning and do not entirely focus on\nassessment of learning [62].\nEducators\nGiven the rapid, explosive advances driven by the expected use\nGPT-4 and other LLMs, medical educators are encouraged to\nembrace these technologies rather than stay away from them.\nWith AI’s rapid evolution, it is paramount for medical educators\nto upskill their competencies in utilizing generative AI tools\neffectively within medical curricula. Current medical curricula\ndo not include education on the proper use of AI. Content\ncovering such technologies and their application to medicine\n(eg, disease discovery) should be included. Medical educators\nshould consider how LLMs can be integrated into medical\neducation, thus requiring them to reconsider the teaching and\nlearning process. This can be done through updating course\nsyllabi to set and clarify the objectives of the use of LLMs (eg,\nGPT-4), as well as by reflecting on their use in practice and\ntheir impact on the profession.\nAssignments will also have to be reconsidered, and educators\nshould strive to assign multimodal activities that require\nhigh-order thinking, creativity, and teamwork. For example,\neducators could use oral exams and presentations, hands-on\nactivities, and group projects to assess their students’ analytical\nand critical reasoning, the soundness and precision of their\narguments, and their persuasive capabilities. Educators may\nconsider involving students in peer evaluations and exercise\n“teach-back.”\nBecause health care is complex and often involves high stakes,\nit is paramount that educators also explain to their medical\nstudents the abovementioned limitations of LLMs. For example,\neducators should highlight the importance of proper citation\nand attribution in medical school, as well as how to avoid\npotential user privacy and copyright issues, misinformation,\nand biases. We recommend that educators discourage reliance\nthat can lead to reduced clinical reasoning skills. Instead,\neducators should encourage students to check, critique, and\nimprove responses generated by LLMs. Educators should\nemphasize that these technological tools should be continually\nmonitored by human experts and that they should be used with\nguidance and critical thinking before acting on any of their\nrecommendations.\nAlthough LLMs, like GPT-4, are powerful tools capable of\ngenerating detailed, personalized study plans and learning\nmaterials, they are not infallible. They are as good as the data\nthat they have been trained on, and there is always a risk of\ninaccuracies or misinterpretations, particularly when dealing\nwith complex, nuanced fields, such as medical education.\nTherefore, we believe that it is crucial to incorporate human\ninput or expert-reviewed content into the process of developing\nsuch tools. For instance, subject matter experts, such as\nexperienced medical educators or practitioners, could review\nand validate the content generated by an LLM. They could\nprovide the correct context, ensure that the material aligns with\ncurrent medical standards and guidelines, and verify the content's\nrelevance to students’ specific learning needs.\nStudents\nStudents should ethically and safely use these tools and\ntechnologies in a constructive manner to thrive outside of the\nJMIR Med Educ 2023 | vol. 9 | e48291 | p. 6https://mededu.jmir.org/2023/1/e48291\n(page number not for citation purposes)\nAbd-alrazaq et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\nclassroom, in a world that is rapidly being dominated by AI.\nSimilar to educators, medical students also need to elevate their\nskills and competencies in effectively leveraging and utilizing\ngenerative AI tools and LLMs in their practices. It is paramount\nthat students acknowledge the use of LLMs in their medical\nand academic work and, at the same time, do so ethically and\nresponsibly.\nDevelopers\nDevelopers of generative AI tools bear the responsibility of\nmeticulously developing generative AI tools while taking into\naccount prevalent constraints, such as inequality, privacy,\nimpartiality, contextual understanding, human engagement, and\nmisinformation. Although recent generative AI technologies,\nlike GPT-4 and ChatGPT, possess the ability to communicate\nin various languages, their performance is notably more effective\nin English compared to their performance in other languages.\nThis could be attributed to the lack of data sets and corpora in\nlanguages other than English (eg, Arabic) [63]. Developers and\nresearchers should collaborate to build large data sets and\ncorpora in other languages to improve the performance of LLMs\nwhen using such languages [63,64]. To tackle the challenges\nof fairness and equity, developers need to create generative AI\ntechnologies that can accommodate the varied requirements and\nbackgrounds of users, particularly for underprivileged or\nmarginalized students and educators. For example, developers\nought to equip generative AI tools with the capability to interact\nwith students and educators through voice, visuals, and videos,\nas well as text, to make them more humanized and accessible\nto those with disabilities (eg, blindness).\nWith some generative AI tools creating or “faking” certain\narticles or information, it is essential for developers to clearly\nstate and discern facts from fiction in the outputs. Additionally,\ndevelopers should also make an effort to develop more\nhumanized LLMs that consider the virtual relationship that has\nbeen developed between humans and machines. The\ndevelopment of generative AI tools should rely on various\ntheories that consider relationship formation among humans,\nsuch as social exchange theory. When developing generative\nAI technologies, it is also essential to adhere to user-focused\ndesign principles while taking into account the social, emotional,\ncognitive, and pedagogical dimensions [65]. We recommend\nthat developers create responsible generative AI tools that\ncorrespond with core human principles and comply with our\nlegal system.\nDevelopers play a crucial role in integrating ChatGPT into\nmedical education platforms, drawing inspiration from its use\nin popular educational platforms, such as Duolingo and Khan\nAcademy. By examining these examples, they can design and\ndevelop innovative learning experiences for medical students\nwho use LLMs. Duolingo and Khan Academy use ChatGPT to\nprovide personalized learning experiences based on the\nindividual needs and progress of each student. This approach\ncan be adopted in medical education to create tailored study\nplans and learning materials that cater to the unique strengths,\nweaknesses, and learning styles of medical students. Both\nDuolingo and Khan Academy use ChatGPT to offer real-time\nfeedback and guidance to learners as they engage with the\nplatform. In the context of medical education, ChatGPT could\nbe integrated into learning management systems or virtual\npatient simulations to provide instant feedback on students'\nperformance, diagnostic decisions, or treatment plans. By giving\nstudents immediate access to targeted guidance and correction,\nChatGPT can facilitate continuous improvement and foster a\ndeeper understanding of medical principles. Duolingo utilizes\nChatGPT to create interactive, conversation-based lessons that\nhelp learners practice their language skills in a more engaging\nand natural manner. Similarly, ChatGPT can be used in medical\neducation to develop interactive learning modules that allow\nstudents to practice clinical communication skills, such as taking\npatient histories, explaining diagnoses, or discussing treatment\noptions. Khan Academy leverages ChatGPT to facilitate\npeer-to-peer interactions and support, enabling students to learn\nfrom each other and collaborate on problem-solving tasks. In\nmedical education, ChatGPT could be used to create virtual\nstudy groups, in which students can discuss clinical cases, share\ninsights, and work together to solve complex medical problems.\nResearchers\nThere is an urgent need to conduct more empirical and\nevidence-based human-computer interaction and user interface\ndesign research for the use of LLMs in medical education.\nResearchers should explore ways to strike a balance between\nusing these technologies and maintaining the essential human\ninteraction and feedback in education to enhance learning and\nteaching experiences and outcomes [48]. Further, research is\nrequired to investigate the impact of LLMs on students’learning\nprocesses and outcomes. Lastly, there is a need to delve deeper\ninto the possible consequences of overdependence on LLMs in\nmedical education [48].\nConclusion\nIn conclusion, LLMs are double-edged swords. Specifically,\nLLMs have the potential to revolutionize medical education,\nenhance the learning experience, and improve the overall quality\nof medical education by offering a wide range of applications,\nsuch as acting as a virtual patient and medical tutor, generating\nmedical case studies, and developing personalized study plans.\nHowever, LLMs do not come without challenges. Academic\ndishonesty, misinformation, privacy concerns, copyright issues,\noverreliance on AI, algorithmic bias, lack of consistency and\nhuman interaction, and inequity in access are some of the major\nhurdles that need to be addressed.\nTo overcome these challenges, a collaborative effort is required\nfrom educators, students, academic institutions, researchers,\nand developers of generative AI tools and LLMs. Rather than\nbanning them, medical schools and academic institutions should\nembrace generative AI tools and develop clear guidelines and\nrules for the use of these technologies for academic activities.\nInstitutional efforts may be required to help students and\neducators develop the skills necessary to incorporate the ethical\nuse of AI into medical training. Educators should use new\nteaching philosophies and redesign assessments and assignments\nto allow students to use such technologies. Students should\nethically and safely use these technologies in a constructive\nmanner. Developers have a duty to carefully design such\nJMIR Med Educ 2023 | vol. 9 | e48291 | p. 7https://mededu.jmir.org/2023/1/e48291\n(page number not for citation purposes)\nAbd-alrazaq et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\ntechnologies while considering common limitations, such as\ninequity, privacy, unbiased responses, lack of context and human\ninteraction, and misinformation.\nConflicts of Interest\nA Abd-alrazaq is an Associate Editor of JMIR Nursing at the time of this publication. The other authors have no conflicts of\ninterest to declare.\nMultimedia Appendix 1\nExample of using ChatGPT (GPT-4) to create interactive case studies for medical students.\n[DOCX File , 2248 KB-Multimedia Appendix 1]\nMultimedia Appendix 2\nExample of using ChatGPT (GPT-4) to provide personalized explanations of medical terminology to students at different levels.\n[DOCX File , 1794 KB-Multimedia Appendix 2]\nMultimedia Appendix 3\nExample of using large language models (Petal) for document analysis.\n[DOCX File , 677 KB-Multimedia Appendix 3]\nMultimedia Appendix 4\nExample of using ChatGPT (GPT-4) to provide an outline and references for research papers.\n[DOCX File , 2362 KB-Multimedia Appendix 4]\nReferences\n1. OpenAI. GPT-4 technical report. arXiv Preprint posted online on March 27, 2023. [FREE Full text]\n2. Ramesh A, Pavlov M, Goh G, Gray S, Voss C, Radford A, et al. Zero-shot text-to-image generation. In: Proc Mach Learn\nRes. 2021 Presented at: 38th International Conference on Machine Learning; July 18-24, 2021; Virtual p. 8821-8831.\n3. Kirillov A, Mintun E, Ravi N, Mao H, Rolland C, Gustafson L, et al. Segment anything. arXiv Preprint posted online on\nApril 5, 2023. [FREE Full text]\n4. Touvron H, Lavril T, Izacard G, Martinet X, Lachaux MA, Lacroix T, et al. LLaMA: Open and efficient foundation language\nmodels. arXiv Preprint posted online on February 27, 2023. [FREE Full text]\n5. Thoppilan R, De Freitas D, Hall J, Shazeer N, Kulshreshtha A, Cheng HT, et al. LaMDA: Language models for dialog\napplications. arXiv Preprint posted online on February 10, 2022. [FREE Full text]\n6. Zhai X, Kolesnikov A, Houlsby N, Beyer L. Scaling vision transformers. 2022 Presented at: 2022 IEEE/CVF Conference\non Computer Vision and Pattern Recognition (CVPR); June 18-24, 2022; New Orleans, Louisiana p. 12104-12113. [doi:\n10.1109/cvpr52688.2022.01179]\n7. OpenAI. GPT-4 is OpenAI’s most advanced system, producing safer and more useful responses. OpenAI. URL: https:/\n/openai.com/product/gpt-4 [accessed 2023-03-20]\n8. Wang LKP, Paidisetty PS, Cano AM. The next paradigm shift? ChatGPT, artificial intelligence, and medical education.\nMed Teach. Epub ahead of print 2023 Apr 10. [doi: 10.1080/0142159X.2023.2198663] [Medline: 37036176]\n9. Temsah O, Khan SA, Chaiah Y, Senjab A, Alhasan K, Jamal A, et al. Overview of early ChatGPT's presence in medical\nliterature: Insights from a hybrid literature review by ChatGPT and human experts. Cureus 2023 Apr 08;15(4):e37281\n[FREE Full text] [doi: 10.7759/cureus.37281] [Medline: 37038381]\n10. Subramani M, Jaleel I, Mohan SK. Evaluating the performance of ChatGPT in medical physiology university examination\nof phase I MBBS. Adv Physiol Educ 2023 Jun 01;47(2):270-271 [FREE Full text] [doi: 10.1152/advan.00036.2023]\n[Medline: 36971685]\n11. Strong E, DiGiammarino A, Weng Y, Basaviah P, Hosamani P, Kumar A, et al. Performance of ChatGPT on free-response,\nclinical reasoning exams. medRxiv Preprint posted online on March 29, 2023. [FREE Full text] [doi:\n10.1101/2023.03.24.23287731] [Medline: 37034742]\n12. Sallam M, Salim NA, Al-Tammemi AB, Barakat M, Fayyad D, Hallit S, et al. ChatGPT output regarding compulsory\nvaccination and COVID-19 vaccine conspiracy: A descriptive study at the outset of a paradigm shift in online search for\ninformation. Cureus 2023 Feb 15;15(2):e35029 [FREE Full text] [doi: 10.7759/cureus.35029] [Medline: 36819954]\n13. Abdel-Messih MS, Boulos MNK. ChatGPT in clinical toxicology. JMIR Med Educ 2023 Mar 08;9:e46876 [FREE Full\ntext] [doi: 10.2196/46876] [Medline: 36867743]\nJMIR Med Educ 2023 | vol. 9 | e48291 | p. 8https://mededu.jmir.org/2023/1/e48291\n(page number not for citation purposes)\nAbd-alrazaq et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\n14. Mbakwe AB, Lourentzou I, Celi LA, Mechanic OJ, Dagan A. ChatGPT passing USMLE shines a spotlight on the flaws\nof medical education. PLOS Digit Health 2023 Feb 09;2(2):e0000205 [FREE Full text] [doi: 10.1371/journal.pdig.0000205]\n[Medline: 36812618]\n15. Masters K. Ethical use of artificial intelligence in health professions education: AMEE guide No. 158. Med Teach 2023\nJun;45(6):574-584. [doi: 10.1080/0142159X.2023.2186203] [Medline: 36912253]\n16. Masters K. Response to: Aye, AI! ChatGPT passes multiple-choice family medicine exam. Med Teach 2023 Jun;45(6):666.\n[doi: 10.1080/0142159X.2023.2190476] [Medline: 36940462]\n17. Lee H. The rise of ChatGPT: Exploring its potential in medical education. Anat Sci Educ. Epub ahead of print 2023 Mar\n14. [doi: 10.1002/ase.2270] [Medline: 36916887]\n18. Kung TH, Cheatham M, Medenilla A, Sillos C, De Leon L, Elepaño C, et al. Performance of ChatGPT on USMLE: Potential\nfor AI-assisted medical education using large language models. PLOS Digit Health 2023 Feb 09;2(2):e0000198 [FREE\nFull text] [doi: 10.1371/journal.pdig.0000198] [Medline: 36812645]\n19. Khan RA, Jawaid M, Khan AR, Sajjad M. ChatGPT - Reshaping medical education and clinical management. Pak J Med\nSci 2023;39(2):605-607 [FREE Full text] [doi: 10.12669/pjms.39.2.7653] [Medline: 36950398]\n20. Karkra R, Jain R, Shivaswamy RP. Recurrent strokes in a patient with metastatic lung cancer. Cureus 2023 Feb\n06;15(2):e34699 [FREE Full text] [doi: 10.7759/cureus.34699] [Medline: 36909080]\n21. Ide K, Hawke P, Nakayama T. Can ChatGPT be considered an author of a medical article? J Epidemiol. Epub ahead of\nprint 2023 Apr 08 [FREE Full text] [doi: 10.2188/jea.JE20230030] [Medline: 37032109]\n22. Huh S. Are ChatGPT’s knowledge and interpretation ability comparable to those of medical students in Korea for taking\na parasitology examination?: a descriptive study. J Educ Eval Health Prof 2023;20:1 [FREE Full text] [doi:\n10.3352/jeehp.2023.20.1] [Medline: 36627845]\n23. Hallsworth JE, Udaondo Z, Pedrós-Alió C, Höfer J, Benison KC, Lloyd KG, et al. Scientific novelty beyond the experiment.\nMicrob Biotechnol. Epub ahead of print 2023 Feb 14 [FREE Full text] [doi: 10.1111/1751-7915.14222] [Medline: 36786388]\n24. Guo AA, Li J. Harnessing the power of ChatGPT in medical education. Med Teach. Epub ahead of print 2023 Apr 10. [doi:\n10.1080/0142159X.2023.2198094] [Medline: 37036161]\n25. Goodman RS, Patrinely JRJ, Osterman T, Wheless L, Johnson DB. On the cusp: Considering the impact of artificial\nintelligence language models in healthcare. Med 2023 Mar 10;4(3):139-140. [doi: 10.1016/j.medj.2023.02.008] [Medline:\n36905924]\n26. Gilson A, Safranek CW, Huang T, Socrates V, Chi L, Taylor RA, et al. How does ChatGPT perform on the United States\nMedical Licensing Examination? The implications of large language models for medical education and knowledge assessment.\nJMIR Med Educ 2023 Feb 08;9:e45312 [FREE Full text] [doi: 10.2196/45312] [Medline: 36753318]\n27. Eysenbach G. The role of ChatGPT, generative language models, and artificial intelligence in medical education: A\nconversation with ChatGPT and a call for papers. JMIR Med Educ 2023 Mar 06;9:e46885 [FREE Full text] [doi:\n10.2196/46885] [Medline: 36863937]\n28. Arif TB, Munaf U, Ul-Haque I. The future of medical education and research: Is ChatGPT a blessing or blight in disguise?\nMed Educ Online 2023 Dec;28(1):2181052 [FREE Full text] [doi: 10.1080/10872981.2023.2181052] [Medline: 36809073]\n29. Anderson N, Belavy DL, Perle SM, Hendricks S, Hespanhol L, Verhagen E, et al. AI did not write this manuscript, or did\nit? Can we trick the AI text detector into generated texts? The potential future of ChatGPT and AI in sports & exercise\nMedicine manuscript generation. BMJ Open Sport Exerc Med 2023 Feb 16;9(1):e001568 [FREE Full text] [doi:\n10.1136/bmjsem-2023-001568] [Medline: 36816423]\n30. Alkaissi H, McFarlane SI. Artificial hallucinations in ChatGPT: Implications in scientific writing. Cureus 2023 Feb\n19;15(2):e35179 [FREE Full text] [doi: 10.7759/cureus.35179] [Medline: 36811129]\n31. Davis MH, Harden RM. Planning and implementing an undergraduate medical curriculum: the lessons learned. Med Teach\n2003 Nov;25(6):596-608. [doi: 10.1080/0142159032000144383] [Medline: 15369907]\n32. Ngo B, Nguyen D, vanSonnenberg E. The cases for and against artificial intelligence in the medical school curriculum.\nRadiol Artif Intell 2022 Aug 17;4(5):e220074 [FREE Full text] [doi: 10.1148/ryai.220074] [Medline: 36204540]\n33. Dumić-Čule I, Orešković T, Brkljačić B, Tiljak MK, Orešković S. The importance of introducing artificial intelligence to\nthe medical curriculum - assessing practitioners' perspectives. Croat Med J 2020 Oct 31;61(5):457-464 [FREE Full text]\n[doi: 10.3325/cmj.2020.61.457] [Medline: 33150764]\n34. Çalışkan SA, Demir K, Karaca O. Artificial intelligence in medical education curriculum: An e-Delphi study for competencies.\nPLoS One 2022 Jul 21;17(7):e0271872 [FREE Full text] [doi: 10.1371/journal.pone.0271872] [Medline: 35862401]\n35. Maini B, Maini E. Artificial intelligence in medical education. Indian Pediatr 2021 May 15;58(5):496-497 [FREE Full text]\n[Medline: 33980744]\n36. Grunhut J, Marques O, Wyatt ATM. Needs, challenges, and applications of artificial intelligence in medical education\ncurriculum. JMIR Med Educ 2022 Jun 07;8(2):e35587 [FREE Full text] [doi: 10.2196/35587] [Medline: 35671077]\n37. Kitamura FC. ChatGPT is shaping the future of medical writing but still requires human judgment. Radiology 2023\nApr;307(2):e230171. [doi: 10.1148/radiol.230171] [Medline: 36728749]\nJMIR Med Educ 2023 | vol. 9 | e48291 | p. 9https://mededu.jmir.org/2023/1/e48291\n(page number not for citation purposes)\nAbd-alrazaq et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\n38. Frommeyer TC, Fursmidt RM, Gilbert MM, Bett ES. The desire of medical students to integrate artificial intelligence into\nmedical education: An opinion article. Front Digit Health 2022 May 13;4:831123 [FREE Full text] [doi:\n10.3389/fdgth.2022.831123] [Medline: 35633734]\n39. Ali SR, Dobbs TD, Hutchings HA, Whitaker IS. Using ChatGPT to write patient clinic letters. Lancet Digit Health 2023\nApr;5(4):e179-e181 [FREE Full text] [doi: 10.1016/S2589-7500(23)00048-1] [Medline: 36894409]\n40. Biswas S. ChatGPT and the future of medical writing. Radiology 2023 Apr;307(2):e223312. [doi: 10.1148/radiol.223312]\n[Medline: 36728748]\n41. Chen TJ. ChatGPT and other artificial intelligence applications speed up scientific writing. J Chin Med Assoc 2023 Apr\n01;86(4):351-353. [doi: 10.1097/JCMA.0000000000000900] [Medline: 36791246]\n42. Koo M. The importance of proper use of ChatGPT in medical writing. Radiology 2023 May;307(3):e230312. [doi:\n10.1148/radiol.230312] [Medline: 36880946]\n43. Patel SB, Lam K. ChatGPT: the future of discharge summaries? Lancet Digit Health 2023 Mar;5(3):e107-e108 [FREE Full\ntext] [doi: 10.1016/S2589-7500(23)00021-3] [Medline: 36754724]\n44. Dahmen J, Kayaalp ME, Ollivier M, Pareek A, Hirschmann MT, Karlsson J, et al. Artificial intelligence bot ChatGPT in\nmedical research: the potential game changer as a double-edged sword. Knee Surg Sports Traumatol Arthrosc 2023\nApr;31(4):1187-1189. [doi: 10.1007/s00167-023-07355-6] [Medline: 36809511]\n45. Graf A, Bernardi RE. ChatGPT in research: Balancing ethics, transparency and advancement. Neuroscience 2023 Apr\n01;515:71-73. [doi: 10.1016/j.neuroscience.2023.02.008] [Medline: 36813155]\n46. Hill-Yardin EL, Hutchinson MR, Laycock R, Spencer SJ. A Chat(GPT) about the future of scientific publishing. Brain\nBehav Immun 2023 May;110:152-154. [doi: 10.1016/j.bbi.2023.02.022] [Medline: 36868432]\n47. Choi EPH, Lee JJ, Ho MH, Kwok JYY, Lok KYW. Chatting or cheating? The impacts of ChatGPT and other artificial\nintelligence language models on nurse education. Nurse Educ Today 2023 Jun;125:105796. [doi: 10.1016/j.nedt.2023.105796]\n[Medline: 36934624]\n48. Tlili A, Shehata B, Adarkwah MA, Bozkurt A, Hickey DT, Huang R, et al. What if the devil is my guardian angel: ChatGPT\nas a case study of using chatbots in education. Smart Learning Environments 2023 Feb 22;10(15):1-24 [FREE Full text]\n[doi: 10.1186/s40561-023-00237-x]\n49. Bair H, Norden J. Large language models and their implications on medical education. Acad Med. Epub ahead of print\n2023 May 10. [doi: 10.1097/ACM.0000000000005265] [Medline: 37162220]\n50. Akhter HM, Cooper JS. Acute pulmonary edema after hyperbaric oxygen treatment: A case report written with ChatGPT\nassistance. Cureus 2023 Feb 07;15(2):e34752 [FREE Full text] [doi: 10.7759/cureus.34752] [Medline: 36909067]\n51. Manohar N, Prasad SS. Use of ChatGPT in academic publishing: A rare case of seronegative systemic lupus erythematosus\nin a patient with HIV infection. Cureus 2023 Feb 04;15(2):e34616 [FREE Full text] [doi: 10.7759/cureus.34616] [Medline:\n36895547]\n52. Trust T. ChatGPT & education. University of Massachusetts Amherst. 2023. URL: https://docs.google.com/presentation/\nd/1Vo9w4ftPx-rizdWyaYoB-pQ3DzK1n325OgDgXsnt0X0/edit#slide=id.p [accessed 2023-05-23]\n53. Ahn S. The impending impacts of large language models on medical education. Korean J Med Educ 2023 Mar;35(1):103-107\n[FREE Full text] [doi: 10.3946/kjme.2023.253] [Medline: 36858381]\n54. Bolukbasi K, Chang KW, Zou J, Saligrama V, Kalai A. Man is to computer programmer as woman is to homemaker?\nDebiasing word embeddings. 2016 Presented at: 30th Conference on Neural Information Processing Systems (NIPS 2016);\nDecember 5-10, 2016; Barcelona, Spain URL: https://proceedings.neurips.cc/paper_files/paper/2016/file/\na486cd07e4ac3d270571622f4f316ec5-Paper.pdf\n55. D’Mello S, Lehman B, Pekrun R, Graesser A. Confusion can be beneficial for learning. Learn Instr 2014 Feb;29:153-170\n[FREE Full text] [doi: 10.1016/j.learninstruc.2012.05.003]\n56. Thirunavukarasu AJ, Hassan R, Mahmood S, Sanghera R, Barzangi K, El Mukashfi M, et al. Trialling a large language\nmodel (ChatGPT) in general practice with the applied knowledge test: Observational study demonstrating opportunities\nand limitations in primary care. JMIR Med Educ 2023 Apr 21;9:e46599 [FREE Full text] [doi: 10.2196/46599] [Medline:\n37083633]\n57. Markovski Y. Data usage for consumer services FAQ. OpenAI. URL: https://help.openai.com/en/articles/\n7039943-data-usage-for-consumer-services-faq [accessed 2023-03-19]\n58. McCallum S. ChatGPT banned in Italy over privacy concerns. BBC. 2023 Apr 01. URL: https://www.bbc.com/news/\ntechnology-65139406 [accessed 2023-04-03]\n59. ChatGPT Generative Pre-trained Transformer, Zhavoronkov A. Rapamycin in the context of Pascal's Wager: generative\npre-trained transformer perspective. Oncoscience 2022 Dec 21;9:82-84 [FREE Full text] [doi: 10.18632/oncoscience.571]\n[Medline: 36589923]\n60. O'Connor S. Open artificial intelligence platforms in nursing education: Tools for academic progress or abuse? Nurse Educ\nPract 2023 Jan;66:103537. [doi: 10.1016/j.nepr.2022.103537] [Medline: 36549229]\n61. Kung TH, Cheatham M, ChatGPT, Medenilla A, Sillos C, De Leon L, et al. Performance of ChatGPT on USMLE: Potential\nfor AI-assisted medical education using large language models. medRxiv Preprint posted online on December 21, 2022.\n[FREE Full text] [doi: 10.1101/2022.12.19.22283643]\nJMIR Med Educ 2023 | vol. 9 | e48291 | p. 10https://mededu.jmir.org/2023/1/e48291\n(page number not for citation purposes)\nAbd-alrazaq et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX\n62. Rudolph J, Tan S, Tan S. ChatGPT: Bullshit spewer or the end of traditional assessments in higher education? Journal of\nApplied Learning and Teaching 2023;6(1):1-22 [FREE Full text] [doi: 10.37074/jalt.2023.6.1.9]\n63. Ahmed A, Ali N, Alzubaidi M, Zaghouani W, Abd-alrazaq AA, Househ M. Freely available Arabic corpora: A scoping\nreview. Comput Methods Programs Biomed Update 2022;2:100049 [FREE Full text] [doi: 10.1016/j.cmpbup.2022.100049]\n64. Ahmed A, Ali N, Alzubaidi M, Zaghouani W, Abd-alrazaq A, Househ M. Arabic chatbot technologies: A scoping review.\nComput Methods Programs Biomed Update 2022;2:100057 [FREE Full text] [doi: 10.1016/j.cmpbup.2022.100057]\n65. Kuhail MA, Alturki N, Alramlawi S, Alhejori K. Interacting with educational chatbots: A systematic review. Educ Inf\nTechnol (Dordr) 2022 Jul 09;28:973-1018 [FREE Full text] [doi: 10.1007/s10639-022-11177-3]\nAbbreviations\nAI: artificial intelligence\nGPT: Generative Pre-trained Transformers\nLaMDA: Language Models for Dialog Applications\nLLM: large language model\nSAM: Segment Anything Model\nSOAP: Subjective, Objective, Assessment, and Plan\nViT: Vision Transformer\nEdited by K Venkatesh; submitted 19.04.23; peer-reviewed by B Chaves, A Thirunavukarasu, K Masters; comments to author 05.05.23;\nrevised version received 15.05.23; accepted 17.05.23; published 01.06.23\nPlease cite as:\nAbd-alrazaq A, AlSaad R, Alhuwail D, Ahmed A, Healy PM, Latifi S, Aziz S, Damseh R, Alabed Alrazak S, Sheikh J\nLarge Language Models in Medical Education: Opportunities, Challenges, and Future Directions\nJMIR Med Educ 2023;9:e48291\nURL: https://mededu.jmir.org/2023/1/e48291\ndoi: 10.2196/48291\nPMID:\n©Alaa Abd-alrazaq, Rawan AlSaad, Dari Alhuwail, Arfan Ahmed, Padraig Mark Healy, Syed Latifi, Sarah Aziz, Rafat Damseh,\nSadam Alabed Alrazak, Javaid Sheikh. Originally published in JMIR Medical Education (https://mededu.jmir.org), 01.06.2023.\nThis is an open-access article distributed under the terms of the Creative Commons Attribution License\n(https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium,\nprovided the original work, first published in JMIR Medical Education, is properly cited. The complete bibliographic information,\na link to the original publication on https://mededu.jmir.org/, as well as this copyright and license information must be included.\nJMIR Med Educ 2023 | vol. 9 | e48291 | p. 11https://mededu.jmir.org/2023/1/e48291\n(page number not for citation purposes)\nAbd-alrazaq et alJMIR MEDICAL EDUCATION\nXSL•FO\nRenderX"
}