{
    "title": "Shadows of wisdom: Classifying meta-cognitive and morally-grounded narrative content via Large Language Models",
    "url": "https://openalex.org/W4386724574",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2523581180",
            "name": "Alexander Stavropoulos",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2797543170",
            "name": "Damien Crone",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1971519950",
            "name": "Igor Grossmann",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W3102638056",
        "https://openalex.org/W2016874080",
        "https://openalex.org/W2897197068",
        "https://openalex.org/W2889287254",
        "https://openalex.org/W632139601",
        "https://openalex.org/W2759309028",
        "https://openalex.org/W4247053316",
        "https://openalex.org/W4287867774",
        "https://openalex.org/W4224035554",
        "https://openalex.org/W2131975628",
        "https://openalex.org/W4385521225",
        "https://openalex.org/W2113128227",
        "https://openalex.org/W3128376221",
        "https://openalex.org/W2767106145",
        "https://openalex.org/W4386081032",
        "https://openalex.org/W4377098551",
        "https://openalex.org/W2794174306",
        "https://openalex.org/W2024509488",
        "https://openalex.org/W4361230739",
        "https://openalex.org/W4385430086",
        "https://openalex.org/W1963683764",
        "https://openalex.org/W2051659537",
        "https://openalex.org/W4220778766",
        "https://openalex.org/W4239888143",
        "https://openalex.org/W3124836788",
        "https://openalex.org/W2520322692",
        "https://openalex.org/W3172399575",
        "https://openalex.org/W4390513007",
        "https://openalex.org/W3001279689",
        "https://openalex.org/W2975256032",
        "https://openalex.org/W2164777277",
        "https://openalex.org/W3026735396",
        "https://openalex.org/W2747680751",
        "https://openalex.org/W4283168218",
        "https://openalex.org/W4283391121",
        "https://openalex.org/W4387617694",
        "https://openalex.org/W4283578200",
        "https://openalex.org/W1990090942",
        "https://openalex.org/W4298222310",
        "https://openalex.org/W4232317699",
        "https://openalex.org/W3128773437",
        "https://openalex.org/W4308244910",
        "https://openalex.org/W3092858700",
        "https://openalex.org/W2153222072",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W4241478906",
        "https://openalex.org/W63592799",
        "https://openalex.org/W2139736795",
        "https://openalex.org/W4386369375",
        "https://openalex.org/W4309666046",
        "https://openalex.org/W2119595472",
        "https://openalex.org/W2916945592",
        "https://openalex.org/W4389636360",
        "https://openalex.org/W4385622263",
        "https://openalex.org/W4392504765",
        "https://openalex.org/W2053154970",
        "https://openalex.org/W4380763235",
        "https://openalex.org/W1546047689",
        "https://openalex.org/W3165259048",
        "https://openalex.org/W3166550823",
        "https://openalex.org/W2160554939",
        "https://openalex.org/W2593799161"
    ],
    "abstract": "We investigated Large Language Models' (LLMs) efficacy in classifying complex psychological constructs like intellectual humility, perspective-taking, open-mindedness, and search for a compromise in narratives of 347 Canadian and American adults reflecting on a workplace conflict. Using state-of-the-art models like GPT-4 across few-shot and zero-shot paradigms and RoB-ELoC (RoBERTa -fine-tuned-on-Emotion-with-Logistic-Regression-Classifier), we compared their performance with expert human coders. Results showed robust classification by LLMs, with over 80% agreement and F1 scores above 0.85, and high human-model reliability (Cohen’s κ Md across top models = .80). RoB-ELoC and few-shot GPT-4 were standout classifiers, although somewhat less effective in categorizing intellectual humility. We offer example workflows for easy integration into research. Our proof-of-concept findings indicate the viability of both open-source and commercial LLMs in automating the coding of complex constructs, potentially transforming social science research.",
    "full_text": null
}