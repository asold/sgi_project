{
  "title": "The performance of large language models in dentomaxillofacial radiology: a systematic review",
  "url": "https://openalex.org/W4413110542",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2940463754",
      "name": "Ze-Kai Liu",
      "affiliations": [
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A4223236515",
      "name": "Andrew Nalley",
      "affiliations": [
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2059146434",
      "name": "Jing Hao",
      "affiliations": [
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A3178814296",
      "name": "Qi-Yong H Ai",
      "affiliations": [
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2313323784",
      "name": "Andy Wai Kan Yeung",
      "affiliations": [
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2128328912",
      "name": "Ray Tanaka",
      "affiliations": [
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2122570768",
      "name": "Kuo‚ÄêFeng Hung",
      "affiliations": [
        "University of Hong Kong"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4385227045",
    "https://openalex.org/W3126541881",
    "https://openalex.org/W4391650958",
    "https://openalex.org/W4396722287",
    "https://openalex.org/W4321605784",
    "https://openalex.org/W4320920036",
    "https://openalex.org/W4387356888",
    "https://openalex.org/W4394843589",
    "https://openalex.org/W2005501262",
    "https://openalex.org/W4406152263",
    "https://openalex.org/W4402452705",
    "https://openalex.org/W4406282496",
    "https://openalex.org/W4399423680",
    "https://openalex.org/W4391578733",
    "https://openalex.org/W4390116001",
    "https://openalex.org/W4390645866",
    "https://openalex.org/W4407058940",
    "https://openalex.org/W4391540306",
    "https://openalex.org/W4409374353",
    "https://openalex.org/W4410583412",
    "https://openalex.org/W4391930138",
    "https://openalex.org/W4406051568",
    "https://openalex.org/W4409289609",
    "https://openalex.org/W4392764290",
    "https://openalex.org/W4394964267",
    "https://openalex.org/W4408522596",
    "https://openalex.org/W4392082336",
    "https://openalex.org/W4384824783",
    "https://openalex.org/W4401281718",
    "https://openalex.org/W4407750099",
    "https://openalex.org/W4403609252",
    "https://openalex.org/W4408190450",
    "https://openalex.org/W4402557035"
  ],
  "abstract": "Abstract Objectives This study aimed to systematically review the current performance of large language models (LLMs) in dento-maxillofacial radiology (DMFR). Methods Five electronic databases were used to identify studies that developed, fine-tuned, or evaluated LLMs for DMFR-related tasks. Data extracted included study purpose, LLM type, images/text source, applied language, dataset characteristics, input and output, performance outcomes, evaluation methods, and reference standards. Customized assessment criteria adapted from the TRIPOD-LLM reporting guideline were used to evaluate the risk-of-bias in the included studies specifically regarding the clarity of dataset origin, the robustness of performance evaluation methods, and the validity of the reference standards. Results The initial search yielded 1621 titles, and 19 studies were included. These studies investigated the use of LLMs for tasks including the production and answering of DMFR-related qualification exams and educational questions (n = 8), diagnosis and treatment recommendations (n = 7), and radiology report generation and patient communication (n = 4). LLMs demonstrated varied performance in diagnosing dental conditions, with accuracy ranging from 37% to 92.5% and expert ratings for differential diagnosis and treatment planning between 3.6 and 4.7 on a 5-point scale. For DMFR-related qualification exams and board-style questions, LLMs achieved correctness rates between 33.3% and 86.1%. Automated radiology report generation showed moderate performance with accuracy ranging from 70.4% to 81.3%. Conclusions LLMs demonstrate promising potential in DMFR, particularly for diagnostic, educational, and report generation tasks. However, their current accuracy, completeness, and consistency remain variable. Further development, validation, and standardization are needed before LLMs can be reliably integrated as supportive tools in clinical workflows and educational settings.",
  "full_text": null,
  "topic": "Medicine",
  "concepts": [
    {
      "name": "Medicine",
      "score": 0.5273143649101257
    },
    {
      "name": "English language",
      "score": 0.43202757835388184
    },
    {
      "name": "Medical physics",
      "score": 0.4255495071411133
    },
    {
      "name": "Radiology",
      "score": 0.39000067114830017
    },
    {
      "name": "Psychology",
      "score": 0.23691827058792114
    },
    {
      "name": "Mathematics education",
      "score": 0.061569541692733765
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I889458895",
      "name": "University of Hong Kong",
      "country": "HK"
    },
    {
      "id": "https://openalex.org/I177725633",
      "name": "Chinese University of Hong Kong",
      "country": "HK"
    }
  ],
  "cited_by": 1
}