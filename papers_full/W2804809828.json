{
  "title": "A Melody-Conditioned Lyrics Language Model",
  "url": "https://openalex.org/W2804809828",
  "year": 2018,
  "authors": [
    {
      "id": "https://openalex.org/A2100223352",
      "name": "Kento Watanabe",
      "affiliations": [
        "Tohoku University"
      ]
    },
    {
      "id": "https://openalex.org/A1993312045",
      "name": "Yuichiroh Matsubayashi",
      "affiliations": [
        "Tohoku University"
      ]
    },
    {
      "id": "https://openalex.org/A2058627656",
      "name": "Satoru Fukayama",
      "affiliations": [
        "National Institute of Advanced Industrial Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2140422315",
      "name": "Masataka Goto",
      "affiliations": [
        "National Institute of Advanced Industrial Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2084773436",
      "name": "Kentaro Inui",
      "affiliations": [
        "Tohoku University",
        "RIKEN Center for Advanced Intelligence Project"
      ]
    },
    {
      "id": "https://openalex.org/A2109871063",
      "name": "Tomoyasu Nakano",
      "affiliations": [
        "National Institute of Advanced Industrial Science and Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1836465849",
    "https://openalex.org/W1519655822",
    "https://openalex.org/W165283731",
    "https://openalex.org/W2074231493",
    "https://openalex.org/W47006904",
    "https://openalex.org/W116271097",
    "https://openalex.org/W179875071",
    "https://openalex.org/W2964121744",
    "https://openalex.org/W2295159313",
    "https://openalex.org/W2135498578",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2100690397",
    "https://openalex.org/W2553169610",
    "https://openalex.org/W2540286278",
    "https://openalex.org/W2135801767",
    "https://openalex.org/W2251065004",
    "https://openalex.org/W2250842199",
    "https://openalex.org/W2593469111",
    "https://openalex.org/W2574634960",
    "https://openalex.org/W1522301498"
  ],
  "abstract": "Kento Watanabe, Yuichiroh Matsubayashi, Satoru Fukayama, Masataka Goto, Kentaro Inui, Tomoyasu Nakano. Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). 2018.",
  "full_text": "Proceedings of NAACL-HLT 2018, pages 163‚Äì172\nNew Orleans, Louisiana, June 1 - 6, 2018.c‚Éù2018 Association for Computational Linguistics\nA Melody-conditioned Lyrics Language Model\nKento Watanabe1, Yuichiroh Matsubayashi1,\nSatoru Fukayama2, Masataka Goto2, Kentaro Inui1,3, Tomoyasu Nakano2\n1Graduate School of Information Sciences, Tohoku University,\n2National Institute of Advanced Industrial Science and Technology (AIST),\n3RIKEN Center for Advanced Intelligence Project\n{kento.w, y-matsu, inui}@ecei.tohoku.ac.jp,\n{s.fukayama, m.goto, t.nakano}@aist.go.jp\nAbstract\nThis paper presents a novel, data-driven lan-\nguage model that produces entire lyrics for a\ngiven input melody. Previously proposed mod-\nels for lyrics generation suffer from the in-\nability of capturing the relationship between\nlyrics and melody partly due to the unavail-\nability of lyrics-melody aligned data. In\nthis study, we Ô¨Årst propose a new practi-\ncal method for creating a large collection of\nlyrics-melody aligned data and then create a\ncollection of 1,000 lyrics-melody pairs aug-\nmented with precise syllable-note alignments\nand word/sentence/paragraph boundaries. We\nthen provide a quantitative analysis of the\ncorrelation between word/sentence/paragraph\nboundaries in lyrics and melodies. We then\npropose an RNN-based lyrics language model\nconditioned on a featurized melody. Experi-\nmental results show that the proposed model\ngenerates Ô¨Çuent lyrics while maintaining the\ncompatibility between boundaries of lyrics\nand melody structures.\n1 Introduction\nWriting lyrics for a given melody is a challenging\ntask. Unlike prose text, writing lyrics requires both\nknowledge and consideration of music-speciÔ¨Åc\nproperties such as the structure of melody, rhythms,\netc. (Austin et al., 2010; Ueda, 2010). A simple ex-\nample is the correlation between word boundaries\nin lyrics and the rests in a melody. As shown in\nFigure 1, a single word spanning beyond a long\nmelody rest can sound unnatural. When writing\nlyrics, a lyricist must consider such constraints in\ncontent and lexical selection, which can impose\nextra cognitive loads.\nThis consideration when writing lyrics has mo-\ntivated a wide-range of studies for the task of\ncomputer-assisted lyrics writing (Barbieri et al.,\n2012; Abe and Ito, 2012; Potash et al., 2015; Watan-\nabe et al., 2017). Such studies aim to model the\n‚ÅÑ@@Flute1 ,-2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl5 ,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl9 ,- 2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl13,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl17, -7))))) 7)!.) #) )) ) -7))))) (‚ÅÑFl21, ) ) )) ) -7))!#))) ) -7))!))) '‚ÅÑFl25 )!)))) #)) )!))))! - )!)))7)!.))‚ÅÑFl29)!))#))) )!)))) #)) )!)))) -7) )!#)))) -7)‚ÅÑFl33)!))))! - )! 7) ( ) , )! ))) )! 7) ) ))‚ÅÑFl37( , )) (! - 7) )!#)))) )) '‚ÅÑFl41\n‚ÅÑFl45\n‚ÅÑFl49\n‚ÅÑ@@Flute1 ,-2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl5 ,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl9 ,- 2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl13,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl17, -7))))) 7)!.) #) )) ) -7))))) (‚ÅÑFl21, ) ) )) ) -7))!#))) ) -7))!))) '‚ÅÑFl25 )!)))) #)) )!))))! - )!)))7)!.))‚ÅÑFl29)!))#))) )!)))) #)) )!)))) -7) )!#)))) -7)‚ÅÑFl33)!))))! - )! 7) ( ) , )! ))) )! 7) ) ))‚ÅÑFl37( , )) (! - 7) )!#)))) )) '‚ÅÑFl41\n‚ÅÑFl45\n‚ÅÑFl49\nma-da\n„Åæ„Å†\nRest\nRest\nExample of awkward lyrics.\nExample of natural lyrics.\n(Proceed to an unknown tomorrow)\n(I walked alone... This road)\nÁü•„Çâ „Å™„ÅÑ ÊòéÊó• „Å∏ Ë°å„Åè\n(yet) (know) (not) (tomorrow) (to) (go)\nshi- ra na- i a- shi- „Éª ta e yu-ku\nhi-to-ri\n‰∏Ä‰∫∫\n(alone)\nde\n„Åß\n(FUNC)\na- ru- i- ta\nÊ≠©„ÅÑ„Åü\n(walked)\nko-no\n„Åì„ÅÆ\n(this)\nmi-chi\nÈÅì\n(road)\nFigure 1: Examples of awkward and natural lyrics.\nFUNC indicates a function word. The song is\nfrom the RWC Music Database (RWC-MDB-P-2001\nNo.20) (Goto et al., 2002).\nlanguage in lyrics and to design a computer sys-\ntem for assisting lyricists in writing. They propose\nto constrain their models to generate only lyrics\nthat satisfy given conditions on syllable counts,\nrhyme positions, etc. However, such constraints\nare assumed to be manually provided by a human\nuser, which requires the user to interpret a source\nmelody and transform their interpretation to a set\nof constraints. To assist users with transforming a\nmelody to constraints, a language model that auto-\nmatically captures the relationship between lyrics\nand melody is required.\nSome studies (Oliveira et al., 2007; Oliveira,\n2015; Nichols et al., 2009) have quantitatively ana-\nlyzed the correlations between melody and phono-\nlogical aspects of lyrics (e.g., the relationship be-\ntween a beat and a syllable stress). However, these\nstudies do not address the relationship between\nmelody and thediscourse structureof lyrics. Lyrics\nare not just a sequence of syllables but a meaningful\nsequence of words. Therefore, it is desirable that\nthe sentence/paragraph boundaries are determined\nbased on both melody rests and context words.\nConsidering such line/paragraph structure of\nlyrics, we present a novel language model that gen-\n163\nerates lyrics whose word, sentence, and paragraph\nboundaries are appropriate for a given melody,\nwithout manually transforming the melody to syl-\nlable constraints. This direction of research has\nreceived less attention because it requires a large\ndataset consisting of aligned pairs of melody and\nsegment boundaries of lyrics which has yet to exist.\nTo address this issue, we leverage a publicly-\navailable collection of digital music scores and cre-\nate a dataset of digital music scores each of which\nspeciÔ¨Åcs a melody score augmented with syllable\ninformation for each melody note. We collected\n1,000 Japanese songs from an online forum where\nmany amateur music composers upload their music\nscores. We then automatically aligned each music\nscore with the raw text data of the corresponding\nlyrics in order to augment it with the word, sen-\ntence, and paragraph boundaries.\nThe availability of such aligned, parallel data\nopens a new area of research where one can con-\nduct a broad range of data-oriented research for\ninvestigating and modeling correlations between\nmelodies and discourse structure of lyrics. In this\npaper, with our melody-lyrics aligned songs, we in-\nvestigate the phenomena that (i) words, sentences,\nand paragraphs rarely span beyond a long melody\nrest and (ii) the boundaries of larger components\n(i.e., paragraphs) tend to coincide more with longer\nrests. To the best of our knowledge, there is no\nprevious work that provides any quantitative analy-\nsis of this phenomenon with this size of data (see\nSection 7).\nFollowing this analysis, we build a novel, data-\ndriven language model that generates Ô¨Çuent lyrics\nwhose sentence and paragraph boundaries Ô¨Åt an\ninput melody. We extend a Recurrent Neural Net-\nwork Language Model (RNNLM) (Mikolov et al.,\n2010) so that its output can be conditioned on a\nfeaturized melody. Both our quantitative and qual-\nitative evaluations show that our model captures\nthe consistency between melody and boundaries of\nlyrics while maintaining word Ô¨Çuency.\n2 Melody-lyric alignment data\nOur goal is to create a melody-conditioned lan-\nguage model that captures the correlations between\nmelody patterns and discourse segments of lyrics.\nThe data we need for this purpose is a collec-\ntion of melody-lyrics pairs where the melody and\nlyrics are aligned at the level of not only note-\nsyllable alignment but also discourse components\n‚ÅÑ@@1,-2))))) ) ) ) )) )! -))#)) (! ,‚ÅÑ5,-2))))) ) ) ) )) ) , )))) (! ,‚ÅÑ9,-2))))) ) ) ) )) )! -))#)) (! ,‚ÅÑ13,-2))))) ) ) ) )) ) , )))) (! ,‚ÅÑ17, -7))))) 7)!.) #) )) ) -7))))) (‚ÅÑ21, ) ) )) ) -7))!#))) ) -7))!))) '‚ÅÑ25 )!)))) #)) )!))))! - )!)))7)!.))‚ÅÑ29)!))#))) )!)))) #)) )!)))) -7) )!#))))-7)‚ÅÑ33)!))))! - )! 7) ( ) , )! ))) )! 7) ) ))‚ÅÑ37( , )) (! - 7) )!#)))) )) '‚ÅÑ41\n‚ÅÑ45\n‚ÅÑ49\n‚ÅÑ@@1,-2))))) ) ) ) )) )! -))#)) (! ,‚ÅÑ5,-2))))) ) ) ) )) ) , )))) (! ,‚ÅÑ9,-2))))) ) ) ) )) )! -))#)) (! ,‚ÅÑ13,-2))))) ) ) ) )) ) , )))) (! ,‚ÅÑ17, -7))))) 7)!.) #) )) ) -7))))) (‚ÅÑ21, ) ) )) ) -7))!#))) ) -7))!))) '‚ÅÑ25 )!)))) #)) )!))))! - )!)))7)!.))‚ÅÑ29)!))#))) )!)))) #)) )!)))) -7) )!#))))-7)‚ÅÑ33)!))))! - )! 7) ( ) , )! ))) )! 7) ) ))‚ÅÑ37( , )) (! - 7) )!#)))) )) '‚ÅÑ41\n‚ÅÑ45\n‚ÅÑ49\nna ni ka ta           ri na i to                  o mo o  ta\n‰Ωï „Åã Ë∂≥„Çä „Å™„ÅÑ „Å® ÊÄù„Å£ „Åü\nMelody\nSyllable\nDigital musical score data with syllables\n[na-ni]   [ka]   [ta-ri]   [na-i]   [to]   [o-mo]   [ta]Syllable\nWord „ÄàBOL„Äâ\nLyric text data \nwith syllable and \nboundary\nRest\n‰Ωï „Åã Ë∂≥„Çä „Å™„ÅÑ „Å® ÊÄù„Å£ „Åü\nMelody\nSyllable\nMelody-Lyric alignment data\nWord\nRest\nNeedleman-Wunsch alignment algorithm\nna-ni ka ta- ri na- i to             o-mo ta\nRest\nRest\nNULLNULL NULL\nNULL\n(some- (FUNC)(enough)      (not)     (FUNC)               (think)    (FUNC)   \n(I thought that something was missing)\nthing)\n„ÄàBOL„Äâ\nFigure 2: Melody-lyrics alignment using the Needle-\nman Wunsch algorithm. BOL denotes a line boundary.\n(i.e., word/sentence/paragraph boundaries) of a\nlyric, as illustrated in the bottom of Figure 2. We\ncreate such a dataset by automatically combining\ntwo types of data available from online forum sites:\ndigital music score data (the top of Figure 2) and\nraw lyrics data (the middle).\nA digital music score speciÔ¨Åes a melody score\naugmented with syllable information for each\nmelody note (see the top of Figure 2). Score data\naugmented in this way is sufÔ¨Åcient for analyzing\nthe relationship between the phonological aspects\nof lyrics and melody, but it is insufÔ¨Åcient for our\ngoal since the structural information of the lyrics\nis not included. We thus augment score data fur-\nther with boundaries of sentences, and paragraphs,\nwhere we assume that sentences and paragraphs\nof lyrics are approximately captured by lines and\nblocks,1 respectively, of the lyrics in the raw text.\nThe integration of music scores and raw lyrics\nis achieved by (1) applying a morphological an-\nalyzer2 to raw lyrics for word segmentation and\nChinese character pronunciation prediction and (2)\naligning music score with raw lyrics at the sylla-\nble level as illustrated in Figure 2. For this align-\nment, we employ the Needleman-Wunsch algo-\nrithm (Needleman and Wunsch, 1970). This align-\nment process is reasonably accurate because it fails\nin principle only when the morphological analysis\nfails in Chinese character pronunciation prediction,\nwhich occurs for only less than 1% of the words in\nthe data set.\nWith this procedure, we obtained 54,181\nJapanese raw lyrics and 1,000 digital musical\n1Blocks are assumed to be segmented by empty lines.\n2To extract word boundaries and syllable information for\nJapanese lyrics, we apply MeCab parser (Kudo et al., 2004).\n164\n‚ÅÑ@@Flute1 ,-2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl5 ,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl9 ,- 2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl13,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl17, -7))))) 7)!.) #) )) ) -7))))) (‚ÅÑFl21, ) ) )) ) -7))!#))) ) -7))!))) '‚ÅÑFl25 )!)))) #)) )!))))! - )!)))7)!.))‚ÅÑFl29)!))#))) )!)))) #)) )!)))) -7) )!#)))) -7)‚ÅÑFl33)!))))! - )! 7) ( ) , )! ))) )! 7) ) ))‚ÅÑFl37( , )) (! - 7) )!#)))) )) '‚ÅÑFl41\n‚ÅÑFl45\n‚ÅÑFl49\n‚ÅÑ@@Flute1 ,-2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl5 ,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl9 ,- 2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl13,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl17, -7))))) 7)!.) #) )) ) -7))))) (‚ÅÑFl21, ) ) )) ) -7))!#))) ) -7))!))) '‚ÅÑFl25 )!)))) #)) )!))))! - )!)))7)!.))‚ÅÑFl29)!))#))) )!)))) #)) )!)))) -7) )!#)))) -7)‚ÅÑFl33)!))))! - )! 7) ( ) , )! ))) )! 7) ) ))‚ÅÑFl37( , )) (! - 7) )!#)))) )) '‚ÅÑFl41\n‚ÅÑFl45\n‚ÅÑFl49\n‚ÅÑ@@Flute1 ,-2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl5 ,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl9 ,- 2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl13,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl17, -7))))) 7)!.) #) )) ) -7))))) (‚ÅÑFl21, ) ) )) ) -7))!#))) ) -7))!))) '‚ÅÑFl25 )!)))) #)) )!))))! - )!)))7)!.))‚ÅÑFl29)!))#))) )!)))) #)) )!)))) -7) )!#)))) -7)‚ÅÑFl33)!))))! - )! 7) ( ) , )! ))) )! 7) ) ))‚ÅÑFl37( , )) (! - 7) )!#)))) )) '‚ÅÑFl41\n‚ÅÑFl45\n‚ÅÑFl49\n[te- ra-shi][te]      [ku-re][ta] [to- ki]     [ka-n-ji] [ta]   [no]\n[ha-ji- me-te] [ki-zu- i][ta]  [hi][no]    [a-na-ta] [no] \n<BOB>\n<BOL> Word boundary\nWord boundary\nWord boundary\n(light) (FUNC)  (FUNC)(FUNC)(when) (feel)   (FUNC)(FUNC)\n(first)   (notice)(FUNC)(time)(FUNC)  (you) (FUNC)\n(I felt when you warmly lit the gap in my heart)\n(The first time I noticed your lovely smile)\nRest#2\nRest#4 Rest#5\nRest#3Rest#1\n‚ÅÑ@@Flute1 ,-2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl5 ,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl9 ,- 2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl13,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl17, -7))))) 7)!.) #) )) ) -7))))) (‚ÅÑFl21, ) ) )) ) -7))!#))) ) -7))!))) '‚ÅÑFl25 )!)))) #)) )!))))! - )!)))7)!.))‚ÅÑFl29)!))#))) )!)))) #)) )!)))) -7) )!#)))) -7)‚ÅÑFl33)!))))! - )! 7) ( ) , )! ))) )! 7) ) ))‚ÅÑFl37( , )) (! - 7) )!#)))) )) '‚ÅÑFl41\n‚ÅÑFl45\n‚ÅÑFl49\n‚ÅÑ@@Flute1 ,-2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl5 ,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl9 ,- 2))))) ) ) ) )) )! - ))#)) (! ,‚ÅÑFl13,- 2))))) ) ) ) )) ) , )))) (! ,‚ÅÑFl17, -7))))) 7)!.) #) )) ) -7))))) (‚ÅÑFl21, ) ) )) ) -7))!#))) ) -7))!))) '‚ÅÑFl25 )!)))) #)) )!))))! - )!)))7)!.))‚ÅÑFl29)!))#))) )!)))) #)) )!)))) -7) )!#)))) -7)‚ÅÑFl33)!))))! - )! 7) ( ) , )! ))) )! 7) ) ))‚ÅÑFl37( , )) (! - 7) )!#)))) )) '‚ÅÑFl41\n‚ÅÑFl45\n‚ÅÑFl49\nFigure 3: Example boundaries appearing immediately\nafter a rest. BOB indicates a block boundary.\n(MIDI Tick)\nFigure 4: Distribution of the number of boundaries in\nthe melody-lyrics alignment data.\nscores from online forum sites 3; we thus created\n1,000 melody-lyrics pairs. We refer to these 1,000\nmelody-lyrics pairs as a melody-lyrics alignment\ndata4 and refer to the remaining 53,181 lyrics with-\nout melody as a raw lyrics data.\nWe randomly split the 1,000 melody-lyrics align-\nments into two sets: 90% for analyzing/training\nand the remaining 10% for testing. From those,\nwe use 20,000 of the most frequent words whose\nsyllable counts are equal to or less than 10, and\nconverted others to a special symbol ‚ü®unknown‚ü©.\nAll of the digital music score data we collected\nwere distributed in the UST format, a common Ô¨Åle\nformat designed speciÔ¨Åcally for recently emerging\ncomputer vocal synthesizers. While we focus on\nJapanese music in this study, our method for data\ncreation is general enough to be applied to other\nlanguage formats such as MusicXML and ABC,\nbecause transferring such data formats to UST is\nstraightforward.\n3For selecting the 1,000 songs, we chose only frequently\ndownloaded or highly popular songs to ensure the quality of\nthe resulting dataset.\n4We publicly release all source URLs of the 1,000 songs\n(https://github.com/KentoW/melody-lyrics).\n3 Correlations between melody and lyric\nIn this section, we examine two phenomena re-\nlated to boundaries of lyrics: (1) the positions of\nlyrics segment boundaries are biased to melody\nrest positions, and (2) the probability of boundary\noccurrence depends on the duration of a rest, i.e.,\na shorter rest tends to be a word boundary and a\nlonger rest tends to be a block boundary, as shown\nin Figure 3. All analyses were performed on the\ntraining split of the melody-lyrics alignment data,\nwhich is described in Section 2.\nFor the Ô¨Årst phenomenon, we Ô¨Årst calculated\nthe distribution of boundary appearances at the po-\nsitions of melody notes and rests. Here, by the\nboundary of a line (or block), we refer to the po-\nsition of the beginning of the line (or block). 5 In\nFigure 3, we say, for example, that the boundary\nof the Ô¨Årst block beginning ‚Äúte-ra-shi te‚Äù coincides\nwith Rest#1. The result, shown at the top of Fig-\nure 4, indicates that line and block boundaries are\nstrongly biased to rest positions and are far less\nlikely to appear at note positions. Words, lines, and\nblocks rarely span beyond a long melody rest.\nThe bottom of Figure 4 shows the detailed dis-\ntributions of boundary occurrences for different\ndurations of melody rests, where durations of 480\nand 1920 correspond to a quarter rest and a whole\nrest, respectively. The results exhibit a clear, strong\ntendency that the boundaries of larger segments\ntend to coincide more with longer rests. To the\nbest of our knowledge, this is the Ô¨Årst study that\nhas ever provided such strong empirical evidence\nfor the phenomena related to the correlations be-\ntween lyrics segments and melody rests. It is also\nimportant to note that the choice of segment bound-\naries looks like a probabilistic process (i.e., there\nis a long rest without a block boundary). This ob-\nservation suggests the difÔ¨Åculty of describing the\ncorrelations of lyrics and melody in a rule-based\nfashion and motivates our probabilistic approach\nas we present in the next section.\n4 Melody-conditioned language model\nOur goal is to build a language model that generates\nÔ¨Çuent lyrics whose discourse segment Ô¨Åt a given\nmelody in the sense that generated segment bound-\naries follow the distribution observed in Section 3.\nWe propose to pursue this goal by conditioning a\n5The beginning of a line/block and the end of a line/block\nare equivalent since there is no melody between the end and\nbeginning of a line/block.\n165\n‚ÅÑ@@1,-2)))))))))) )! -))#))(! ,‚ÅÑ5,-2)))))))))) ),)))) (! ,‚ÅÑ9,-2)))))))))) )! -))#))(! ,‚ÅÑ13,-2)))))))))) ),)))) (! ,‚ÅÑ17,-7)))))7)!.)#))))-7)))))(‚ÅÑ21,)))))-7))!#))))-7))!)))'‚ÅÑ25 )!))))#)))!))))! - )!)))7)!.))‚ÅÑ29)!))#))) )!))))#)))!))))-7))!#))))-7)‚ÅÑ33)!))))! -)! 7)( ),)!))))! 7))))‚ÅÑ37( ,))(! -7) )!#))))))'‚ÅÑ41\n‚ÅÑ45\n‚ÅÑ49\n‚ÅÑ@@1,-2)))))))))) )! -))#))(! ,‚ÅÑ5,-2)))))))))) ),)))) (! ,‚ÅÑ9,-2)))))))))) )! -))#))(! ,‚ÅÑ13,-2)))))))))) ),)))) (! ,‚ÅÑ17,-7)))))7)!.)#))))-7)))))(‚ÅÑ21,)))))-7))!#))))-7))!)))'‚ÅÑ25 )!))))#)))!))))! - )!)))7)!.))‚ÅÑ29)!))#))) )!))))#)))!))))-7))!#))))-7)‚ÅÑ33)!))))! -)! 7)( ),)!))))! 7))))‚ÅÑ37( ,))(! -7) )!#))))))'‚ÅÑ41\n‚ÅÑ45\n‚ÅÑ49\nsa-ru\n(away) <BOL> 023\nùê≤\"#$% ùê≤&#$%\nùê±(#$%\nùê≤\"# ùê≤&#\nùê±(#\nùê≤\"#$) ùê≤&#$)\nùêØ(ùë§#$-) ùê±(#$)\nùêß#$)\nsa-ru\nùë§#$)\nOutput\nWord\nùëö1(#)\nTAR G ET\nNOTE\nContext\nMelody\nRepresen-\ntation\nLSTM\nùë§#$%\nùêß#$% ùêß#\nùêØ(ùë§#$)) ùêØ(ùë§#$%)\nùë†#$) ùë†#$% ùë†#ùë§#\nùë§#$%\n‚Ä¶\nSyllable\nCount\n(away)\nsa-ru\n(away)\nka-ra\n(from)\n‚Ä¶\nùëö1 # 3%4ùëö1 # $%4\nWord\nEmbedd-\ning\nùë§#$- ùë§#$) ùë§#$%\nContext Melody Vector\n‚Ä¶‚Ä¶\nùëö1(#$%)\nTAR G ET\nNOTE\nùëö1 #$% 3%4ùëö1 #$% $%4\nùëö1 # $- ùëö1 # 3-ùëö1 #$% 3-\nha-shi-ri\n(run)\nha-shi-ri\n(run)\nha- shi- ri\nùë§#$)\n(run)\nha- shi- ri\nùë§#$)\n(run)\nùëö1 #$% $-\nFigure 5: Melody-conditioned RNNLM.\nstandard RNNLM with a featurized input melody.\nWe call this model a Melody-conditioned RNNLM.\nThe network structure of the model is illustrated\nin Figure 5. Formally, we are given a melody\nm = m1,...,mi,...,mI that is a sequence of notes\nand rests, where m includes a pitch and a dura-\ntion information. Our model generates lyrics w =\nw1,...,wt,...,wT that is a sequence of words and\nsegment boundary symbols: ‚ü®BOL‚ü©and ‚ü®BOB‚ü©,\nspecial symbols denoting a line and a block bound-\nary, respectively. For each time step t, the model\noutputs a single word or boundary symbol taking a\npair of the previously generated word wt‚àí1 and the\nmusical feature vector nt for the current word posi-\ntion which includes context window-based features\nthat we describe in the following section. In this\nmodel, we assume that the syllables of the gener-\nated words and the notes in the input melody have\na one-to-one correspondence. Therefore, the posi-\ntion of the incoming note/rest for a word position\nt (referred to as a target note for t) is uniquely de-\ntermined by the syllable counts of the previously\ngenerated words.6 The target note for t is denoted\nas mi(t) by deÔ¨Åning a function i(¬∑) which maps\ntime step t to the index of the next note in t.\nHere, the challenging issue with this model is\ntraining. Generally, language models require a\nlarge amount of text data to learn well. Moreover,\nthis is also the case for learning correlation between\nrest positions and syllable counts. As shown in Fig-\nure 4, most words are supposed to not overlap a\n6Note that our melody-lyrics alignment data used in train-\ning does not make this assumption, but we can still uniquely\nidentify the positions of target notes based on the obtained\nmelody-word alignment.\nlong rest. This means, for example, that when the\nincoming melody sequence for a next word posi-\ntion is note, note, (long) rest, note, note , as the\nsequence following to mi(t‚àí1) in Figure 5, it is de-\nsirable to select a word whose syllable count is two\nor less so that the generated word does not overlap\nthe long rest. If there is sufÔ¨Åcient data available,\nthis tendency may be learned directly from the cor-\nrelation between rests and words without explicitly\nconsidering the syllable count of a word. However,\nour melody-lyrics alignments for 1,000 songs are\ninsufÔ¨Åcient for this purpose.\nWe take two approaches to address this data spar-\nsity problem. First, we propose two training strate-\ngies that increase the number of training examples\nusing raw lyrics that can be obtained in greater\nquantities. Second, we construct a model that pre-\ndicts the number of syllables in each word, as well\nas words themselves, to explicitly supervise the\ncorrespondence between rest positions and syllable\ncounts.\nIn the following sections, we Ô¨Årst describe the\ndetails of the proposed model and then present the\ntraining strategies used to obtain better models with\nour melody-lyrics alignment data.\n4.1 Model construction\nThe proposed model is based on a standard\nRNNLM (Mikolov et al., 2010):\nP(w) =‚àèT\nt=1P(wt|w0, ..., wt‚àí1), (1)\nwhere context words are encoded using\nLSTM (Hochreiter and Schmidhuber, 1997)\nand the probabilities over words are calculated\nby a softmax function. w0 = ‚ü®B‚ü©is a symbol\ndenoting the beginning of lyrics. We extend this\nmodel such that each output is conditioned by\nthe context melody vectors n1, ...,nt, as well as\nprevious words:\nP(w|m) =‚àèT\nt=1P(wt|w0, ..., wt‚àí1,n1, ...,nt). (2)\nThe model simultaneously predicts the sylla-\nble counts of words by sharing the parameters\nof LSTM with the above word prediction model\nin order to learn the correspondence between the\nmelody segments and syllable counts:\nP(s|m) =‚àèT\nt=1P(st|w0, ..., wt‚àí1,n1, ...,nt), (3)\nwhere s = s1, ..., sT is a sequence of syllable\ncounts, which corresponds to w.\n166\nFor each time step t, the model outputs a word\ndistribution yt\nw ‚ààRV and a distribution of syllable\ncount yt\ns ‚ààRS using a softmax function:\nyt\nw = softmax(BN(Wwzt)), (4)\nyt\ns = softmax(BN(Wszt)), (5)\nwhere zt is the output of the LSTM for each time\nstep. V is the vocabulary size and S is the syllable\ncount threshold.7 Ww and Ws are weight matri-\nces. BN denotes batch normalization (Ioffe and\nSzegedy, 2015).\nThe input to the LSTM in each time step t is a\nconcatenation of the embedding vector of the pre-\nvious word v(wt‚àí1) and the context melody repre-\nsentation xt\nn, which is a nonlinear transformation\nof the context melody vector nt:\nxt = [ v(wt‚àí1), xt\nn], (6)\nxt\nn = ReLU( Wnnt + bn), (7)\nwhere Wn is a weight matrix and bn is a bias.\nTo generate lyrics, the model searches for the\nword sequence with the greatest probability (Eq.\n2) using beam search. The model stops generating\nlyrics when the syllable count of the lyrics reaches\nthe number of notes in the input melody.\nNote that our model is not speciÔ¨Åc to the lan-\nguage of lyrics. The model only requires the se-\nquences of melody, words, and syllable counts and\ndoes not use any language-speciÔ¨Åc features.\n4.2 Context melody vector\nIn Section 3, we indicated that the positions of\nrests and their durations are important factors for\nmodeling boundaries of lyrics. Thus, we collect\na sequence of notes and rests around the current\nword position (i.e., time step t) and encode their\ninformation into context melody vector nt (see the\nbottom of Figure 5).\nThe context melody vector nt is a binary fea-\nture vector that includes a musical notation type\n(i.e., note or rest), a duration8, and a pitch for each\nnote/rest in the context window. We collect notes\nand rests around the target note mi(t) for the cur-\nrent word position t with a window size of 10 (i.e.,\nmi(t)‚àí10, ..., mi(t), ..., mi(t)+10).\nFor pitch information, we use a gap (pitch inter-\nval) between a target note mi(t) and its previous\n7The syllable counts of the ‚ü®BOL‚ü©and ‚ü®BOB‚ü©are zero.\n8We rounded each duration to one of the values 60, 120,\n240, 360, 480, 720, 960, 1200, 1440, 1680, 1920, and 3840\nand use one-hot encoding for each rounded duration.\nAlgorithm 1Pseudo melody generation\n1: for eachsyllable in the input-lyrics do\n2: b ‚Üêget boundary type next to the syllable\n3: sample note pitch p ‚àºP(pi|pi‚àí2, pi‚àí1)\n4: sample note duration dnote ‚àºP(dnote|b)\n5: assign note with (p, dnote) to the syllable\n6: sample binary variable r ‚àºP(r|b)\n7: if r = 1then\n8: insert rest with duration drest ‚àºP(drest|b)\n9: end if\n10: end for\n(MIDI Tick)\nFigure 6: Distribution of the number of boundaries in\npseudo-data.\nnote mi(t‚àí1). Here, the pitch is represented by a\nMIDI note number in the range 0 to 127. For ex-\nample, the target and its previous notes are 68 and\n65, respectively, and the gap is +3.\n4.3 Training strategies\nPretraining The size of our melody-lyrics align-\nment data is limited. However, we can obtain a\nlarge amount of raw lyrics. We, therefore, pretrain\nthe model with 53,181 raw lyrics and then Ô¨Åne-\ntune it with the melody-lyrics alignment data. In\npretraining, all context melody vectors nt are zero\nvectors. We refer to these pretrained and Ô¨Åne-tuned\nmodels as Lyrics-only and Fine-tuned models, re-\nspectively.\nLearning with pseudo-melody We propose a\nmethod to increase the melody-lyrics alignment\ndata by attaching pseudo melodies to the obtained\n53,181 raw lyrics. We refer to the model that uses\nthis data as the Pseudo-melody model.\nAlgorithm 1 shows the details of pseudo-melody\ngeneration. For each syllable in the lyrics, we Ô¨Årst\nassign a note to the syllable by sampling the proba-\nbility distributions. The pitch of each note is gener-\nated based on the trigram probability. Then, we de-\ntermine whether to generate a rest next to it. Since\nwe established the correlations between rests and\nboundaries of lyrics in Section 3, the probability for\na rest and its duration is conditioned by a boundary\n167\ntype next to the target syllable. All probabilities are\ncalculated using the training split of the melody-\nlyrics alignment data.\nFigure 6 shows the distributions of the number\nof boundaries in the pseudo data. The distributions\nclosely resemble those of gold data in Figure 4.\n5 Quantitative evaluation\nWe evaluate the proposed Melody-conditioned\nRNNLMs quantitatively based on two evaluation\nmetrics: (1) a test set perplexity for measuring the\nÔ¨Çuency; (2) a line/block boundary replication task\nfor measuring the consistency between the melody\nand boundaries in the generated lyrics.\n5.1 Experimental setup\nIn our model, we chose the dimensions of the word\nembedding vectors and context melody representa-\ntion vectors to 512 and 256, respectively, and the\ndimension of the LSTM hidden state was 768. We\nused a categorical cross-entropy loss for outputs\nyt\nw and yt\ns, Adam (Kingma and Ba, 2014) with an\ninitial learning rate of 0.001 for parameter opti-\nmization, and a mini-batch size of 32. We applied\nan early-stopping strategy with a maximum epoch\nnumber of 100, and training was terminated after\nÔ¨Åve epochs of unimproved loss on the validation\nset. For lyrics generation, we used a beam search\nwith a width of 10. An example of the generated\nlyrics is shown in the supplemental material.\n5.2 Evaluation metrics\nPerplexity Test-set perplexity (PPL) is a stan-\ndard evaluation measure for language models. PPL\nmeasures the predictability of wording in orig-\ninal lyrics, where a lower PPL value indicates\nthat the model can generate Ô¨Çuent lyrics. We\nused PPL and its variant PPL-W, which excludes\nline/block boundaries, to investigate the predictabil-\nity of words.\nAccuracy of boundary replication Under the\nassumption that the line and block boundaries of\nthe original lyrics are placed at appropriate po-\nsitions in the melody, we evaluated consistency\nbetween the melody and boundaries in the gener-\nated lyrics by measuring the reproducibility of the\nboundaries in the original lyrics. Here the metric\nwe used was F1-measure of the boundary positions.\nWe also asked a person to place line and block\nboundaries at plausible positions for randomly se-\nlected 10 input melodies that the evaluator has\nPerplexity F1-measure\nModel PPL PPL-W BOB BOL UB\nLyrics-only 138.0 225.0 0.121 0.061 0.106\nFull-data 135.9 222.1 0.122 0.063 0.108\nAlignment-only 173.3 314.8 0.298 0.287 0.477\nHeuristic 175.8 284.7 0.373 0.239 0.402\nFine-tuned 152.2 275.5 0.260 0.302 0.479\nPseudo-melody 115.7 197.5 0.318 0.241 0.406\n(w/oys)\nFine-tuned 155.1 278.1 0.318 0.241 0.366\nPseudo-melody 118.0 201.5 0.312 0.250 0.406\nHuman - - 0.717 0.671 0.751\nTable 1: Results of the quantitative evaluation. ‚ÄúUB‚Äù\ndenotes the score for unlabeled matching of line/block\nboundaries. ‚Äúw/o ys‚Äù denotes the exclusion of the\nsyllable-count output layer.\nnever heard. This person is not a professional mu-\nsician but an experienced performer educated on\nmusicology. The bottom part of Table 1 represents\nthe human performance.\n5.3 Effect of Melody-conditioned RNNLM\nTo investigate the effect of our language models,\nwe compared the following six models. The Ô¨Årst\none is (1) a Lyrics-only model, a standard RNNLM\ntrained with 54,081 song lyrics without melody in-\nformation. The second and third ones are baseline\nMelody-conditioned RNNLMs where the proposed\ntraining strategies are not applied: (2) a Full-data\nmodel trained with mixed data (54,081 song lyrics\nand 900 melody-lyrics alignments of those), and\n(3) an Alignment-only model trained with only 900\nmelody-lyrics alignment data. The fourth one is a\nstrong baseline to evaluate the performance of the\nproposed approaches: (4) a Heuristic model that\n(i) assigns a line/block boundary to a rest based on\nits duration with the same probability, as reported\nin Figure 4, and (ii) Ô¨Ålls the space between any\ntwo boundaries with lyrics of the appropriate syl-\nlable counts. This Heuristic model computes the\nfollowing word probability:\nP(wt|w0, ..., wt‚àí1,m) = (8)\nÔ£±Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£≤\nÔ£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£¥Ô£≥\nQ(‚ü®BOB‚ü©|mi(t+1)) (if wt =‚ü®BOB‚ü©)\nQ(‚ü®BOL‚ü©|mi(t+1)) (if wt =‚ü®BOL‚ü©)\n(1‚àíQ(‚ü®BOB‚ü©|mi(t+1))‚àíQ(‚ü®BOL‚ü©|mi(t+1)))√ó\nPLSTM(wt|w0,...,wt‚àí1)\n1‚àíPLSTM(‚ü®BOL‚ü©|w0,...,wt‚àí1)‚àíPLSTM(‚ü®BOB‚ü©|w0,...,wt‚àí1)\n(otherwise)\nwhere Q is the same probability as reported in Fig-\nure 4. PLSTM is the word probability calculated by\na standard LSTM language model. The remaining\ntwo are Melody-conditioned RNNLMs with the\nproposed learning strategies: (5) Fine-tuned and\n(6) Pseudo-melody models.\n168\nLyrics in test set Lyrics generated by Pseudo-melody modelLyrics generated by Heuristic model\n(MIDI Tick) (MIDI Tick)(MIDI Tick)\nFigure 7: Distribution of the number of boundaries in the test set and lyrics generated by theHeuristic and Pseudo-\nmelody models.\nThe top part of Table 1 summarizes the perfor-\nmance of these models. Regarding the boundary\nreplication, the Heuristic, Alignment-only, Fine-\ntuned, and Pseudo-melody models achieved higher\nperformance than the Lyrics-only model for unla-\nbeled matching of line/block boundaries (i.e., UB).\nThis result indicates that our Melody-conditioned\nRNNLMs successfully capture the consistency be-\ntween melody and boundaries of lyrics. The re-\nsults of the Full-data model is low (as expected)\nbecause the size of the melody-lyrics alignment\ndata is far smaller than that of the raw lyrics data\nand this harms the learning process of the depen-\ndency between melody and lyrics. For the block\nboundary, the Heuristic model achieved the best\nperformances. For the line boundary, the Fine-\ntuned model achieved the best performances.\nRegarding PPL and PPL-W, the Lyrics-only,\nFull-data, and Pseudo-melody models show bet-\nter results than the other models. The Fine-tuned\nmodel shows reduced performance compared with\nthe Lyrics-only model because Ô¨Åne-tuning with\na small amount of data causes overÔ¨Åtting in the\nlanguage model. Also, the training size of the\nAlignment-only model is insufÔ¨Åcient for learning a\nlanguage model of lyrics. Interestingly, thePseudo-\nmelody model achieved better performance than the\nFull-data model and overall achieved the best score.\nThis result indicates that the Pseudo-melody model\nuses the information of a given melody to make a\nbetter prediction of its lyrics word sequence. On\nthe other hand, the Heuristic model had the worst\nperformance, despite training with a large amount\nof raw lyrics. We analyze the reason for such per-\nformance and describe our results in Section 5.5.\nIt is not necessarily clear which to choose, either\nthe Fine-tuned or Pseudo-melody model, which\nmay depend also on the size and diversity of the\ntraining and test data. However, one can conclude\nat least that combining a limited-scale collection\nof melody-lyrics alignment data with a far larger\ncollection of lyrics-alone data boosts the model‚Äôs\ncapability of generating a Ô¨Çuent lyrics which struc-\nturally Ô¨Åts well the input melody.\n5.4 Effect of predicting syllable-counts\nTo investigate the effect of predicting syllable-\ncounts, we compared the performance of the pro-\nposed models to models that exclude the syllable-\ncount output layer ys. The middle part of Table 1\nsummarizes the results. For the pretraining strat-\negy, the use of ys successfully alleviates data spar-\nsity when learning the correlation between syllable\ncounts and melodies from only words themselves.\nAs can be seen, the model without ys shows re-\nduced performance relative to both PPLs and the\nboundary replication. On the other hand, for the\npseudo-melody strategy, the two models are com-\npetitive in both measures. This means that the\nPseudo-melody model obtained a sufÔ¨Åcient amount\nof word-melody input pairs to learn the correlation.\n5.5 Analysis of melody and generated lyrics\nTo examine whether the models can capture corre-\nlations between rests and boundaries of lyrics, we\ncalculate the proportion of the word, line, and block\nboundaries in the original lyrics and in the lyrics\ngenerated by the Heuristic and Pseudo-melody\nmodel for the test set (Figure 7). The proportion\nof ‚ü®BOL‚ü©and ‚ü®BOB‚ü©generated by the Heuristic\nmodel are almost equivalent to those of the original\nlyrics. On the other hand, for the Pseudo-melody\nmodel, the proportion of line/block boundary types\nfor the longer rests are smaller than that of the\noriginal lyrics.\nAlthough the Heuristic model reproduces the\nproportion of the original line/block boundaries,\nthe model had a low performance in terms of PPL,\n169\n0\n5\n10\n15\n20\n25\n30\n0 50 100 150 200\nNumber of blocks\nSyllable counts per block\n0\n100\n200\n300\n400\n500\n600\n0 10 20 30 40 50\nNumber of lines\nSyllable counts per line\nJS-divergence: 0.075\nJS-divergence: 0.172\nJS-divergence: 0.144\nJS-divergence: 0.190\n0\n5\n10\n15\n20\n25\n30\n0 50 100 150 200\nNumber of blocks\nSyllable counts per block\n0\n100\n200\n300\n400\n500\n600\n0 10 20 30 40 50\nNumber of lines\nSyllable counts per line\n0\n5\n10\n15\n20\n25\n30\n0 50 100 150 200\nNumber of blocks\nSyllable counts per block\n0\n100\n200\n300\n400\n500\n600\n0 10 20 30 40 50\nNumber of lines\nSyllable counts per line\n0\n100\n200\n300\n400\n500\n600\n0 5 10 15 20 25 30 35 40 45 50\nNumber\tof\tlines\nSyllable\tcounts\tper\tline\nLyrics in test set Lyrics generated by Heuristic model Lyrics generated by Pseudo-melody model\nFigure 8: Distribution of the syllable count of the generated lines/blocks\nHeuristic Lyrics-only Fine-tuned Pseudo-melody Human(Upper-bound)\nMeasureMeans¬±SD MedianMeans¬±SD MedianMeans¬±SD MedianMeans¬±SD Median Means¬±SD Median\nL 2.06¬±1.08 2 2.33¬±1.23 2 2.85¬±1.20 3 2.93¬±1.14 3 3.56¬±1.33 4\nG 2.28¬±1.07 2 2.81¬±1.16 3 2.79¬±1.06 3 2.97¬±1.08 3 3.50¬±1.25 4\nLM 2.34¬±1.07 2 2.91¬±1.15 3 2.70¬±1.13 3 2.96¬±1.09 3 3.49¬±1.35 4\nDM 2.33¬±1.10 2 2.80¬±1.06 3 2.59¬±1.11 3 2.89¬±1.07 3 3.49¬±1.30 4\nOQ 2.01¬±1.01 2 2.59¬±1.15 3 2.42¬±1.08 2 2.65¬±1.01 3 3.32¬±1.19 4\nTable 2: Results of the qualitative evaluation.\nas shown in Section 5.3. By investigating the lyrics\ngenerated by theHeuristic model, we found that the\nmodel tends to generate line/block boundaries after\nthe melody rest, even if the two rests are quite close.\nFigure 8 shows the distributions of the syllable\nper line / block frequency and the distributions of\nthe Jensen-Shannon divergence. While the Heuris-\ntic model tends to generate short lines/blocks, our\nmodel generates the lyrics so that lines/blocks do\nnot become too short. This result supports that (i)\nour model is trained using melody and lyric con-\ntexts and (ii) the heuristic approach, which simply\ngenerates line/block boundaries based on the dis-\ntribution in Figure 4, cannot generate Ô¨Çuent lyrics\nwith well-formed line/block lengths.\n6 Qualitative evaluation\nTo asses the quality of the generated lyrics, inspired\nby (Oliveira, 2015), we asked 50 Yahoo crowd-\nsourcing workers to answer the following Ô¨Åve ques-\ntions using a Ô¨Åve-point Likert scale:\nListenability (L)When listening to melody and\nlyrics, are the positions of words, lines, and seg-\nments natural? (1=Poor to 5=Perfect)\nGrammaticality (G)Are the lyrics grammatically\ncorrect? (1=Poor to 5=Perfect)\nLine-level meaning (LM)Is each line in the lyrics\nmeaningful? (1=Unclear to 5=Clear)\nDocument-level meaning (DM) Are the entire\nlyrics meaningful? (1=Unclear to 5=Clear)\nOverall quality (OQ)What is the overall quality\nof the lyrics? (1=Terrible to 5=Great)\nFor the evaluation sets, we randomly se-\nlected four melodies from the RWC Music\nDatabase (Goto et al., 2002). For each melody,\nwe prepared four lyrics generated by the Heuristic,\nLyrics-only, Fine-tuned, and Pseudo-melody mod-\nels. Moreover, to obtain an upper bound for this\nevaluation, we used the lyrics created by amateur\nwriters: we asked four native Japanese speakers to\nwrite lyrics on the evaluation melody. One writer\nwas a junior high school teacher of music who had\nexperience in music composition and writing lyrics.\nThree writers were graduate students with different\nlevels of musical expertise. Two of the three writers\nhad experience with music composition, but none\nof them had experience with writing lyrics.9 As a\nresult, we obtained 50 (workers) √ó4 (melodies) √ó\n5 (lyrics) samples in total. We note that workers did\nnot know whether lyrics were created by a human\nor generated by a computer.\nTable 2 shows the average scores, standard devia-\ntions, and medians for each measure. Regarding the\n‚ÄúListenability‚Äù evaluation, workers gave high scores\nto the Fine-tuned and Pseudo-melody models that\nare trained using both the melody and lyrics. This\nresult is consistent with the perplexity evaluation\nresult. On the other hand, regarding the ‚ÄúGrammat-\nicality‚Äù and ‚ÄúMeaning‚Äù evaluation, workers gave\nhigh scores to the Lyrics-only and Pseudo-melody\nmodels that are well-trained on a large amount of\ntext data. This result is consistent with the result of\n9We release lyrics and audio Ô¨Åles used in the quali-\ntative evaluation on the Web ( https://github.com/\nKentoW/deep-lyrics-examples).\n170\nthe boundary replication task. Regarding the ‚ÄúOver-\nall quality‚Äù evaluation, the Pseudo-melody model\noutperformed all other models. These results indi-\ncate our pseudo data learning strategy contributes\nto generating high-quality lyrics. However, the\nquality of lyrics automatically generated is still\nworse than the quality of lyrics that humans pro-\nduce, and it still remains an open challenge for\nfuture research to develop computational models\nthat generate high-quality lyrics.\n7 Related work\nIn the literature, a broad range of research efforts\nhas been reported for computationally modeling\nlyrics-speciÔ¨Åc properties such as meter, rhythm,\nrhyme, stress, and accent Greene et al. (2010);\nReddy and Knight (2011); Watanabe et al. (2014,\n2016). While these studies provide insightful Ô¨Ånd-\nings on the properties of lyrics, none of those takes\nthe approach of using melody-lyrics parallel data\nfor modeling correlations of lyrics and melody\nstructures. One exception is the work of Nichols\net al. (2009), who used melody-lyrics parallel data\nto investigate, for example, the correlation between\nsyllable stress and pitch; however, their exploration\ncovers only correlations at the prosody level but\nnot structural correlations.\nThe same trend can be seen also in the literature\nof automatic lyrics generation, where most stud-\nies utilize only lyrics data. Barbieri et al. (2012)\nand Abe and Ito (2012) propose a model for gen-\nerating lyrics under a range of constraints pro-\nvided in terms of rhyme, rhythm, part-of-speech,\netc. Potash et al. (2015) proposes an RNNLM\nthat generates rhymed lyrics under the assump-\ntion that rhymes tend to coincide with the end of\nlines. In those studies, the melody is considered\nonly indirectly; namely, input prosodic/linguistic\nconstraints/preferences on lyrics are assumed to\nbe manually provided by a human user because\nthe proposed models are not capable of inter-\npreting and transforming a given melody to con-\nstraints/preferences.\nFor generating lyrics for a given melody, we\nhave so far found in the literature two studies\nwhich propose a method. Oliveira et al. (2007)\nand Oliveira (2015) manually analyze correlations\namong melodies, beats, and syllables using 42 Por-\ntuguese songs and propose a set of heuristic rules\nfor lyrics generation. Ramakrishnan A et al. (2009)\nattempt to induce a statistical model for generating\nmelodic Tamil lyrics from melody-lyrics parallel\ndata using only ten songs. However, the former cap-\ntures only phonological aspects of melody-lyrics\ncorrelations and can generate a small fragment of\nlyrics (not an entire lyrics) for a given piece of\nmelody. The latter suffers from the severe shortage\nof data and fails to conduct empirical experiments.\n8 Conclusion and future work\nThis paper has presented a novel data-driven ap-\nproach for building a melody-conditioned lyrics\nlanguage model. We created a 1,000-song melody-\nlyrics alignment dataset and conducted a quanti-\ntative investigation into the correlations between\nmelodies and segment boundaries of lyrics. No\nprior work has ever conducted such a quantitative\nanalysis of melody-lyrics correlations with this size\nof data. We have also proposed a RNN-based,\nmelody-conditioned language model that gener-\nates Ô¨Çuent lyrics whose word/line/block boundaries\nÔ¨Åt a given input melody. Our experimental re-\nsults have shown that: (1) our Melody-conditioned\nRNNLMs capture the consistency between melody\nand boundaries of lyrics while maintaining word\nÔ¨Çuency; (2) combining a limited-scale collection of\nmelody-lyrics alignment data with a far larger col-\nlection of lyrics-alone data for training the model\nboosts the model‚Äôs competence; (3) we have also\nproduced positive empirical evidence for the effect\nof applying a multi-task learning schema where\nthe model is trained for syllable count prediction as\nwell as for word prediction; and (4) the human judg-\nments collected via crowdsourcing showed that our\nmodel improves the quality of generated lyrics.\nFor future directions, we plan to further extend\nthe proposed model for capturing other aspects of\nlyrics/melody discourse structure such as repeti-\ntions, verse-bridge-chorus structure, and topical\ncoherence of discourse segment. The proposed\nmethod for creating melody-lyrics alignment data\nenables us to explore such a broad range of aspects\nof melody-lyrics correlations.\nAcknowledgments\nThis study utilized the RWC Music Database (Pop-\nular Music). This work was partially supported\nby a Grant-in-Aid for JSPS Research Fellow Grant\nNumber JP16J05945, JSPS KAKENHI Grant Num-\nbers JP15H01702, and JST ACCEL Grant Number\nJPMJAC1602. The authors would like to thank Dr.\nPaul Reisert for the English language review.\n171\nReferences\nChihiro Abe and Akinori Ito. 2012. A Japanese lyrics\nwriting support system for amateur songwriters. In\nProceedings of Asia-PaciÔ¨Åc Signal & Information\nProcessing Association Annual Summit and Confer-\nence 2012 (APSIPA ASC 2012). pages 1‚Äì4.\nDave Austin, Jim Peterik, and Cathy Lynn Austin.\n2010. Songwriting for Dummies. Wileys.\nGabriele Barbieri, Franc ¬∏ois Pachet, Pierre Roy, and\nMirko Degli Esposti. 2012. Markov constraints for\ngenerating lyrics with style. In Proceedings of the\n20th European Conference on ArtiÔ¨Åcial Intelligence\n(ECAI 2012). pages 115‚Äì120.\nMasataka Goto, Hiroki Hashiguchi, Takuichi\nNishimura, and Ryuichi Oka. 2002. RWC Mu-\nsic Database: Popular, classical and jazz music\ndatabases. In Proceedings of the 3rd International\nConference on Music Information Retrieval (ISMIR\n2002). volume 2, pages 287‚Äì288.\nErica Greene, Tugba Bodrumlu, and Kevin Knight.\n2010. Automatic analysis of rhythmic poetry with\napplications to generation and translation. In Pro-\nceedings of the 2010 Conference on Empirical Meth-\nods in Natural Language Processing (EMNLP 2010).\npages 524‚Äì533.\nSepp Hochreiter and J¬®urgen Schmidhuber. 1997. Long\nshort-term memory. Neural computation 9(8):1735‚Äì\n1780.\nSergey Ioffe and Christian Szegedy. 2015. Batch nor-\nmalization: Accelerating deep network training by\nreducing internal covariate shift. In Proceedings\nof the 32nd International Conference on Machine\nLearning (ICML 2015). volume 37, pages 448‚Äì456.\nDiederik P. Kingma and Jimmy Ba. 2014. Adam: A\nmethod for stochastic optimization. arXiv preprint\narXiv:1412.6980.\nTaku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.\n2004. Applying conditional random Ô¨Åelds to\nJapanese morphological analysis. In Proceedings of\nthe 2004 Conference on Empirical Methods in Nat-\nural Language Processing (EMNLP 2004) . pages\n230‚Äì237.\nTomas Mikolov, Martin KaraÔ¨Å ¬¥at, Lukas Burget, Jan\nCernock`y, and Sanjeev Khudanpur. 2010. Recurrent\nneural network based language model. In Proceed-\nings of Interspeech 2010. pages 1045‚Äì1048.\nSaul B. Needleman and Christian D. Wunsch. 1970.\nA general method applicable to the search for sim-\nilarities in the amino acid sequence of two proteins.\nJournal of Molecular Biology 48(3):443‚Äì453.\nEric Nichols, Dan Morris, Sumit Basu, and Christo-\npher Raphael. 2009. Relationships between lyrics\nand melody in popular music. In Proceedings of the\n10th International Society for Music Information Re-\ntrieval Conference (ISMIR 2009). pages 471‚Äì476.\nHugo Gonc ¬∏alo Oliveira. 2015. Tra-la-lyrics 2.0: Au-\ntomatic generation of song lyrics on a semantic do-\nmain. Journal of ArtiÔ¨Åcial General Intelligence\n6(1):87‚Äì110.\nHugo R. Gonc ¬∏alo Oliveira, F. Amialcar Cardoso, and\nFrancisco C. Pereira. 2007. Tra-la-lyrics: An ap-\nproach to generate text based on rhythm. In Pro-\nceedings of the 4th International Joint Workshop on\nComputational Creativity. pages 47‚Äì55.\nPeter Potash, Alexey Romanov, and Anna Rumshisky.\n2015. GhostWriter: Using an LSTM for auto-\nmatic Rap lyric generation. In Proceedings of the\n2015 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP 2015) . pages 1919‚Äì\n1924.\nAnanth Ramakrishnan A, Sankar Kuppan, and\nSobha Lalitha Devi. 2009. Automatic generation\nof Tamil lyrics for melodies. In Proceedings of the\nWorkshop on Computational Approaches to Linguis-\ntic Creativity. pages 40‚Äì46.\nSravana Reddy and Kevin Knight. 2011. Unsupervised\ndiscovery of rhyme schemes. In Proceedings of the\n52nd Annual Meeting of the Association for Compu-\ntational Linguistics (ACL 2011). pages 77‚Äì82.\nTatsuji Ueda. 2010. „Çà„Åè„Çè„Åã„Çã‰ΩúË©û„ÅÆÊïôÁßëÊõ∏ The\nwriting lyrics textbook which is easy to understand\n(in Japanese). Y AMAHA music media corporation.\nKento Watanabe, Yuichiroh Matsubayashi, Kentaro\nInui, and Masataka Goto. 2014. Modeling structural\ntopic transitions for automatic lyrics generation. In\nProceedings of the 28th PaciÔ¨Åc Asia Conference on\nLanguage, Information and Computation (PACLIC\n2014). pages 422‚Äì431.\nKento Watanabe, Yuichiroh Matsubayashi, Kentaro\nInui, Tomoyasu Nakano, Satoru Fukayama, and\nMasataka Goto. 2017. LyriSys: An Interactive sup-\nport system for writing lyrics based on topic tran-\nsition. In Proceedings of the 22nd International\nConference on Intelligent User Interfaces (ACM IUI\n2017). pages 559‚Äì563.\nKento Watanabe, Yuichiroh Matsubayashi, Naho Orita,\nNaoaki Okazaki, Kentaro Inui, Satoru Fukayama,\nTomoyasu Nakano, Jordan Smith, and Masataka\nGoto. 2016. Modeling discourse segments in lyrics\nusing repeated patterns. In Proceedings of the 26th\nInternational Conference on Computational Linguis-\ntics (COLING 2016). pages 1959‚Äì1969.\n172",
  "topic": "Lyrics",
  "concepts": [
    {
      "name": "Lyrics",
      "score": 0.7687262296676636
    },
    {
      "name": "Computer science",
      "score": 0.5699256062507629
    },
    {
      "name": "Linguistics",
      "score": 0.5047999620437622
    },
    {
      "name": "Language model",
      "score": 0.4778170883655548
    },
    {
      "name": "Human language",
      "score": 0.42565909028053284
    },
    {
      "name": "Natural language processing",
      "score": 0.3853455185890198
    },
    {
      "name": "Speech recognition",
      "score": 0.3684232234954834
    },
    {
      "name": "Artificial intelligence",
      "score": 0.34680137038230896
    },
    {
      "name": "Art",
      "score": 0.16793209314346313
    },
    {
      "name": "Philosophy",
      "score": 0.1419181525707245
    },
    {
      "name": "Literature",
      "score": 0.10479432344436646
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I201537933",
      "name": "Tohoku University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I73613424",
      "name": "National Institute of Advanced Industrial Science and Technology",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I4210126580",
      "name": "RIKEN Center for Advanced Intelligence Project",
      "country": "JP"
    }
  ]
}