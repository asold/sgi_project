{
  "title": "Leveraging Readability and Sentiment in Spam Review Filtering Using Transformer Models",
  "url": "https://openalex.org/W4308419420",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5110945413",
      "name": "Sujithra Kanmani",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5002474708",
      "name": "B. Surendiran",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4247954696",
    "https://openalex.org/W3124524575",
    "https://openalex.org/W2086289305",
    "https://openalex.org/W2130071626",
    "https://openalex.org/W1488483520",
    "https://openalex.org/W2084103650",
    "https://openalex.org/W2346875348",
    "https://openalex.org/W2140156190",
    "https://openalex.org/W2514892918",
    "https://openalex.org/W6761705167",
    "https://openalex.org/W6758644424",
    "https://openalex.org/W6739226397",
    "https://openalex.org/W3163571239",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W6769997294",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2914120296",
    "https://openalex.org/W3170547996",
    "https://openalex.org/W3119860226",
    "https://openalex.org/W1517997934",
    "https://openalex.org/W2131774270",
    "https://openalex.org/W2792916349",
    "https://openalex.org/W2962933419",
    "https://openalex.org/W2806643775",
    "https://openalex.org/W6742418442",
    "https://openalex.org/W3009481995",
    "https://openalex.org/W6682989926",
    "https://openalex.org/W6751273497",
    "https://openalex.org/W6603261821",
    "https://openalex.org/W3083950266",
    "https://openalex.org/W2905232447",
    "https://openalex.org/W3007065191",
    "https://openalex.org/W3017367042",
    "https://openalex.org/W6645173153",
    "https://openalex.org/W6752950752",
    "https://openalex.org/W6747819751",
    "https://openalex.org/W2161283199",
    "https://openalex.org/W2921297172",
    "https://openalex.org/W3112028611",
    "https://openalex.org/W1484930183",
    "https://openalex.org/W3119467012",
    "https://openalex.org/W2923978210",
    "https://openalex.org/W6763701032",
    "https://openalex.org/W3212921332",
    "https://openalex.org/W2970597249"
  ],
  "abstract": "&lt;p&gt; Leveraging Readability and Sentiment in Spam Review Filtering Using Transformer Models &lt;/p&gt;",
  "full_text": "Leveraging Readability and Sentiment in Spam Review Filtering Using\nTransformer Models\nSujithra Kanmani* and Surendiran Balasubramanian\nDepartment of Computer Science and Engineering, National Institute of Technology Puducherry, Karaikal, India\n*Corresponding Author: Sujithra Kanmani. Email: sujithrakanmani@gmail.com\nReceived: 15 March 2022; Accepted: 30 May 2022\nAbstract: Online reviews signiﬁcantly inﬂuence decision-making in many aspects\nof society. The integrity of internet evaluations is crucial for both consumers and\nvendors. This concern necessitates the development of effective fake review\ndetection techniques. The goal of this study is to identify fraudulent text reviews.\nA comparison is made on shill reviewsvs. genuine reviews over sentiment and\nreadability features using semi-supervised language processing methods with a\nlabeled and balanced Deceptive Opinion dataset. We analyze textual features\naccessible in internet reviews by merging sentiment mining approaches with read-\nability. Overall, the research improves fake review screening by using various\ntransformer models such as Bidirectional Encoder Representation from Transfor-\nmers (BERT), Robustly Optimized BERT (Roberta), XLNET (Transformer-XL)\nand XLM-Roberta (Cross-lingual Language model – Roberta). This proposed\nresearch extracts and classiﬁes features from product reviews to increase the effec-\ntiveness of reviewﬁltering. As evidenced by the investigation, the application of\ntransformer models improves the performance of spam review ﬁltering when\nrelated to existing machine learning and deep learning models.\nKeywords: Fraudulent; sentiment; readability; BERT; XLNET; roberta; XLM-\nroberta\n1 Introduction\nPeople’s signiﬁcant way of expressing themselves is now through the use of websites. Using e-\ncommerce sites, forums and blogs, people can readily exchange their opinions on items and services.\nMost customers examine product and service reviews before purchasing them. Everyone on the internet\nincreasingly recognizes the value of these online evaluations for other consumers and suppliers combined.\nVendors can even build extra marketing tactics [1]. Customers found it difﬁcult to distinguish a slanted\nreview from an honest review written by a zealous consumer simply by looking at the review’s rating\nbecause all skewed evaluations were released by unknown entities or tricksters who took a customer’s\nname. Furthermore, [2,3] rely solely on numerical ratings to identify the presence of online review\nmanipulation, neglecting the rich linguistic content of online reviews. We evaluate the language content\nof reviews and use a readability approach to detect items with altered evaluations in this research, which\nThis work is licensed under a Creative Commons Attribution 4.0 International License, which\npermits unrestricted use, distribution, and reproduction in any medium, provided the original\nwork is properly cited.\nComputer Systems Science & Engineering\nDOI: 10.32604/csse.2023.029953\nArticle\nechT PressScience\ngoes beyond rating analysis. Although distinguishing between false and authentic reviews is complex, the\nwriting style typically reveals speciﬁc insights that help us to discern between the both.\nThe problem could not be solved by physically assessing the linguistic content of a single review. Some\nfeatures of the modiﬁed review were similar to another [4] to identify between honest and faked reviews. It\nwas nearly complicated for unwitting customers to identify the manipulation of product ratings expressed in a\nreview. Individual consumer reviews frequently reﬂect a personal perspective on their product experience. As\na result, their writing styles should be distinct. Such distinctions represent the diversity of their culture,\neducation, career, etc. Fake reviews are frequently more dramatic or exaggerated, whereas honest\nevaluations are straightforward and well-written [5]. Shill reviews are less readable than honest reviews [6,7].\nFake reviews elicit more positive or negative feelings than authentic reviews [8]. Thus sentiment\nanalysis is also necessary in the case of feature selection forﬁltering the fake reviews. A review often\nreceives several comments. We expect most of the comments to have similar feelings for genuine,\nauthentic reviews. However, in the case of spam reviews, most consumers will likely reject the reviewer’s\npoint of view. As a result, the majority of the comments may express opposing opinions in the form of\nreviews.\nAs the inﬂuence of false reviews rises, recognizing them has become a signiﬁcant issue, and ongoing\nstudy is required to handle this concerning situation. Researchers have suggested the holistic model\n[9,10], supervised and unsupervised machine-learning approaches [10,11] and deep-learning techniques\n[12,13] in recent years for identifying bogus reviews. Our study focused mostly on review text features\nsuch as readability and sentiment features. Both may be modiﬁed to produce the desired outcome. As a\nresult, we’ve developed a reliable method for detecting spam reviews. We present an exposure approach\nthat includes bag of words (BOW) test analysis, tokenization, padding and transformers models such as\nBERT, Roberta, XLNET and XLM_Roberta. The transformer models are evaluated using a single labeled\nand balanced dataset (Deceptive Opinion) where XLM_Roberta outperforms with 96% accuracy. Besides,\nwe also tested deep-learning models mainly the Bidirectional Long Short Term Memory (Bi_LSTM)\nmodel, Convolutional Neural Network (CNN)-2D + Bi_LSTM model, CNN + LSTM (Long Short Term\nMemory) model, CNN + GRU (Gated Recurrent Unit) model. The CNN + LSTM model outperformed\nall others with the highest accuracy, 84% and minimum data loss. Our study tested machine learning\nmodels for comparison of performance with the deep-learning models, such as Logistic regression (LR),\nMultinomial Naïve Bayes (MNB), Support Vector Machine (SVM) and Random Forest (RF) Classiﬁer.\nThe most important contributions of this analysis are\n/C15 We developed a novel method for extracting and categorizing features included in reviews to\ndemonstrate that readability can also be used as an effective shill review identiﬁcation component.\n/C15 We conducted a careful benchmark analysis on the problem of misinformation, utilizing multiple\ntransformers models and compared the outcomes to the State Of The Art (SOTA) models.\n/C15 We also addressed the weaknesses in the present study by using the deceptive opinion dataset and\ngave future directions for enhancing spam reviewﬁltering.\nThe rest of the paper is organized as follows; Section 2 summarizes the related works. Section 3 contains\nthe data, methods and techniques used in this study as well as an analysis of the recommended model’s\nstructures. Section 4 goes over the experiments and their results. Finally, Section 5 concludes the study\nand suggests some future research directions.\n2 Related Work\nThis section examines previous efforts to identify fake reviews using various detection algorithms. The\nextant literature may be classiﬁed into three categories as given below.\n1440 CSSE, 2023, vol.45, no.2\n2.1 Transformer Based Detection Models\nWhen a pre-trained model is used to retain contextual information concealed in raw data, the model may\nbetter understand the meaning of a letter, word, or sentence in context. BERT leverages Masking Modelling\nLanguage as a ground-breaking language model, enabling self-supervised training on massive text datasets\n[14]. BERT has shown SOTA performance in a diversity of NLP applications [15], with toxic comment\nidentiﬁcation [16]. Liu et al. [ 17] demonstrate that BERT is under-tuned and provide Roberta, an\nimproved version of BERT, by carefully selecting the training parameters and pushing the SOTA on\nmultiple tasks. XLM [18] improves Roberta by including Time Lapse Monitoring (TLM) in the pre-\ntraining. The XLM authors now propose XLM-R, a pre-trained model trained on big datasets in\n100 languages. XLM-R achieves SOTA performance in cross-lingual detection, sequence labeling, and\nquestion answering. Several recent research [19,20] have also used XLM-R for negative text analysis and\ngot SOTA performance.\n2.2 Deep Learning Detection Models\nOver the last decade, LSTM models have been acknowledged as effective models that can learn from\nsequence data. The capacity that makes LSTM useful is its ability to grasp long-range correlations and\nlearn quickly from sequences of varying durations. Fraudulent card transactions have also been examined\nusing LSTM models [21]. Bi-LSTM is a sort of recurrent neural network which is built with two hidden\nlayers that allow bidirectional processing of the data. This is the main source of contention with LSTM.\nIn natural language processing, Bi-LSTM has shown encouraging results [ 22]. Several studies\ndemonstrate that CNN + LSTM provides a much more robust model than both CNN and LSTM\nseparately [23]. The great performance of the CNN-LSTM model is due to the amalgamation of short and\nlong-term feature interactions. CNN + BiLSTM model provides results over extended texts [24,25]. To\nefﬁciently create both global and local textual semantics, a CNN + GRN model may also be used to\nclassify text. The Gate Recurrent Network may be used to evaluate user browsing history in a variety of\nways [26]. As a result, the model’s convergence rate can be purposely sped up [27].\n2.3 Machine Learning Detection Models\nTraditional machine learning algorithms for example, Support Vector Machine (SVM) [28], Random\nForest [29], Multinomial Naive Bayes (MNB) [30,31] and Logistic Regression (LR) [32] rely on human\nfeature engineering and are incapable of collecting contextual data in the toxic comment. Despite the fact\nthat deep learning models have grown in popularity, classical models have not disappeared. Several\nresearch [33,34], suggest that LR works better in low-resource settings, whereas deep learning’s potential\ncan only be completely unleashed with enough annotated training data. Furthermore, traditional feature-\nbased approaches maintain a model’s interpretability to some extent, while most deep learning models do\nnot. For identifying fake opinions, stylometric characteristics were applied using machine learning\nclassiﬁers, namely Support Vector Machine (SVM) with Sequential Minimal Optimization (SMO) and\nNaive Bayes. According to trials using existing hotel reviews, exhausting stylometric traits is a promising\nway to detect fraudulent opinions [35]. Reference [36] combines behavioral and semantic factors in order\nto identify bogus reviews. It is categorized using a variety of classiﬁers, including Logistic Regression\n(LR), K-Nearest Neighbor (KNN), Multinomial Naive Bayes (MNB), and Support Vector Machine\n(SVM). And the LR performs admirably in all assessment metrics [37] analyses reviewer and review-\ncentric attributes for false review identiﬁcation. It made use of the Yelp ground truth dataset, which\nincluded both actual and fraudulent review collections. Random Forests have been utilized to examine\nboth known and unexpected traits, and the results are encouraging. Thus the leveraging of the deep\nneural network is taken into consideration in this work and a detailed comparative analysis is being\nprovided in this paper, along with the expansion of future direction.\nCSSE, 2023, vol.45, no.2 1441\n3 Materials and Methods\n3.1 Dataset Description\nThe Kaggle Deceptive Opinion dataset is used to test the proposed analysis. This dataset contains\n1600 recordings withﬁve attributes. It’s a collection of 20 real and fake hotel reviews from Chicago. The\ndescriptions ofﬁve ﬁelds are listed inTab. 1below\n3.2 Proposed Framework for Analysis\nThe proposed framework for analysis expands on the existing research by incorporating Deep neural\nnetwork model (Transformer models) approaches with the distinct linguistic feature of readability and\nsentiment mining, sets to categorize reviews from untruthful domains, thereby increasing the credibility\nof user-generated content available online as shown inFig. 1 below and various phases involved in the\nanalysis are\n3.2.1 Data Acquisition\nThere are a few databases that contain both excellent quality real reviews and deceptive ones. Inquiring\nabout past efforts based on the references given in Section 2, we discovered that a single labeled dataset was\ngenerally employed. The labeled dataset is obtained from Ott et al. [38]. The deceptive opinion dataset, also\nknown as the Ott dataset, is utilized in our analysis.\n3.2.2 Data Preprocessing\nIn this study, a series of preprocessing techniques were utilized to prepare the raw review data from the\ndeceptive opinion dataset for computational activity. They are Tokenization, Stop words removal and\nLemmatization. Tokenization divides raw text into words and phrases known as tokens. Tokenization aids\nin determining the meaning of the text by evaluating the word sequence. Stop words are the words which\nlacks meaning (e.g.,“a”, “an”). Any human language has an abundance of stop words. We eliminate the\nlow-level information from our text by deleting these terms, allowing us to focus on the crucial\ninformation. In this study, all data is cleansed of stop words before proceeding with the fake review\nidentiﬁcation technique. The technique of collecting together the many inﬂected forms of a word so that\nthey may be studied as a single item is known as lemmatization. Lemmatization is similar to stemming in\nthat it adds context to words. As a result, it connects words with similar meanings to a single term. Thus\nthe raw data goes through these three preprocessing stages.\n3.2.3 Feature Selection and Extraction\nThis part shows a key role in the analysis phase as the feature selection decides the accuracy of the\nclassiﬁers involved. This examination of the literature found two key features of distinct approaches, such\nas readability and sentiment for fake review detection. The extraction of the feature is based on the\nTable 1: Description of theﬁelds present in the deceptive opinion dataset\nFields Description\nDeceptive There are two sorts of reviews:“truthful” and “deceptive.”\nHotel It contains the hotel ’s name.\nPolarity It expresses the review ’s emotions like positive and negative\nSource It identi ﬁes the source of the review, which comes from three sources: TripAdvisor, Mturk,\nand the web.\nText It includes the reviews.\n1442 CSSE, 2023, vol.45, no.2\nreview dataset and the accuracy of review spam detection is dependent on the feature engineering strategy\nused. As a consequence, these components must be considered in tandem for the efﬁcient deployment of the\nfake review detection model and enhanced accuracy [39]. We employed the usual vector space representation\ntechniques with TF-IDF (Term Frequency-Inverse Document Frequency) weighting [40], as well as custom\ntokenizers of common transformer models (BERT, Roberta and XLNet tokenizer). The major features\nutilized for the study is discussed as follows,\nFigure 1: The proposed analysis framework\nCSSE, 2023, vol.45, no.2 1443\nReadability Feature\nIn addition to the criteria listed above, we suggest an additional set of features extracted based on\nreadability tests [ 41]. It is an intriguing subject of Natural Language Processing that deals with\ndetermining a document’s readability. These exams determine how dif ﬁcult a book is to read and\ncomprehend. The signiﬁcant cause that disturbs the authenticity of the review is the readability feature.\nThe readability of a review’s language is determined by its structural elements and captures how simple it\nis to interpret. The most existing system acquires low accuracy of fake reviews detection as they just use\na single feature and lack the labeled experimental data. we are utilizing the key feature (i.e.,) readability\nas it has a hypothesis stating Shill reviews are harder to read than regular reviews [6]. We will use the\nfollowing readability tests (https://readabilityformulas.com/coleman-liau-readability-formula.php) in our\nresearch dataset to analyze the importance of this feature in fake review detection and they are listed below\nFlesch Reading Ease(FRE):It calculates the readability of a text on a scale of 1 to 100. When the score\nlevel goes low, the information becomes difﬁcult to read. The mathematical formula used for calculating the\nreadability score is shown in theEq. (1):\nFRE ¼ 206:835 /C0ð 1:015 /C3 ASLÞ/C0ð 84:6 /C3 ASWÞ (1)\nwhere RE stands for Readability Ease, ASL stands for“Average Sentence Length” (i.e., the number of words\ndivided by the number of sentences), ASW stands for Average Syllable Weighted (i.e., the number of\nsyllables divided by the number of words).Tab. 2shows the various score levels and their meanings.\nThe Coleman–Liau Index:This formula assesses the reading level of a text. It uses phrases and letters as\nvariables. According to Coleman,“Letter length is a stronger predictor of readability than word length in\nsyllables.” This readability score is calculated using the mathematical procedure described inEq. (2):\nCLI ¼ 0:0588L /C0 0:296S /C0 15:8 (2)\nwhere L denotes the average number of letters per 100 words and S the average number of sentences per\n100 words, respectively.\nSMOG: It is an abbreviation for‘Simple Measure of Gobbledygook. It is a foundation for readability. It\ncalculates how many years of schooling the typical individual needs to comprehend a text. It works well for\ntexts of at least 30 sentences. This was the length of text sampled during the formula’s development. SMOG\ndetermines how many years of schooling an average person needs to grasp any piece of writing. This is\nreferred to as the SMOG Grade. McLaughlin proposed calculating this using a piece of 30 phrases or\nmore and completing the following: There are a total of 30 sentences if you count the 10 sentences at the\nTable 2: Flesch reading ease scores and interpretation\nScore School level Notes\n90–100 Grade 5 Very easy\n80–90 Grade 6 Easy\n70–80 Grade 7 Fairly easy\n60–70 Grade 8 Plain english\n50–60 Grade 10 –12 Fairly dif ﬁcult\n30–50 College Dif ﬁcult\n0–30 College graduate Very dif ﬁcult\n1444 CSSE, 2023, vol.45, no.2\nbeginning, 10 in the middle and 10 at the end. Every word with three syllables or more is counted. Taking the\nsquare root of the integer and rounding it to the nearest ten adding three to this number. The mathematical\nformula used for calculating the SMOG readability score is shown in theEq. (3):\nSMOG grade¼ 3 þ Square Root of Polysyllable Count (3)\nDale Chall:This formula assesses word difﬁculty using a count of‘hard’ phrases. It uses the length of\nthe sentence and the number of ‘difﬁcult’ phrases to identify a text sample’s US grade level. The\nmathematical formula used for calculating the Dale chall readability raw score is as shown in theEq. (4):\nR score ¼ 0:1579 /C3ð PÞþ 0:0496 /C3 L (4)\nwhere R_Score = Raw Score, R_Score is the reading grade of a reader who can comprehend your text. P\nstands for Difﬁcult Words Percentage and L stands for Average Sentence Length in words. If P is more\nthan 5%, then Adjusted Score will be computed as, Adjusted Score = R_Score + 3.6365; otherwise\nAdjusted Score = R_Score. With the adjusted score value the grade level of the reader is decided. These\nreadability tests were conducted on the deceptive opinion dataset and the results are shown inFig. 2.\nFig. 2 contains the Average values of Truthful and deceptive reviews, where the values of the Deceptive\nreviews fall under the category of less readable, having a little difﬁculty in reading factor compared to the\ntruthful reviews. For example, considering the Flesch reading test, the truthful reviews lie in the range of\n70–80, which is fairly easy to read, but the deceptive reviews lie in the category of 60–70, which will\ncontain Plain English making it less readable.\nThus by exploiting these readability tests over the deceptive opinion dataset, we can able to analyze that\nthe fake reviews have more complexity of readability than compared to the truthful reviews, as depicted in\nthe aboveFig. 2.\nSentiment Feature\nThe second feature which is considered for the study is the sentiment feature, as the sentiment plays a\nmajor role in terms of classiﬁcation and the V ADER (Valence Aware Dictionary for Sentiment Reasoning)\ndoes the extraction of the sentiment from the review. The V ADER library makes use of the polarity feature,\nwhich categorizes sentiment as positive, negative, or neutral. The compound score is calculated by summing\nthe valence ratings of each word in the lexicon, then normalizing between extreme negative and positive. The\ncompound score is computed usingEq. (5):\ncs ¼\nsﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃ\ns2 þ b\np (5)\nsweiveRfoerocSytilibadaeR\nReadability Test Involved\nREVIEW SCORES IN READABILITY TEST \nFigure 2: Reviews score in readability test\nCSSE, 2023, vol.45, no.2 1445\nwhere CS represents the computed compound score, s is the sum of all word polarity scores andb is the\ndefault value of 15. Normalization function is used such that using this hyper parameterb the maximum\nexpected value is approximated. As stated inEqs. (6)–(8) below, the following compound range criteria\nare used to classify positive, negative and neutral moods.\ncs /C21 0:05 for sentiment ¼ positive (6)\ncs /C20/C0 0:05 for sentiment ¼ negative (7)\nðcs . /C0 0:05Þ& ðcs , /C0 0:05Þ for sentiment ¼ neutral (8)\nReviewing evaluations to determine if they are positive, negative, or neutral. It entails predicting\nwhether the reviews will be decent or negative based on the text’s words, emoji’s and review scores,\namong other factors. Fake reviews, according to comparable research [ 6], evoke more favorable or\nnegative responses than genuine evaluations. This is because bogus evaluations are used to sway people’s\nopinions and it’s more vital to communicate ideas than it is to just give facts.\n3.2.4 Transformer Models\nIn recent decades, transformer models have shown greater classiﬁcation performance. As it employs a\npre-trained model for training, the computational time is decreased and since pre-trained models are widely\navailable as open-source, the cost of environmental setup is also lowered. This section addresses the\nnumerous transformer models used in this investigation, which are listed below.\nBidirectional Encoder Representation from Transformers (BERT)\nBERT is a deep learning language processing model with sophisticated features. By a large margin,\nBERT beats all previous language models. In all tiers, it operates on the collaborative left and right\ncontext phenomena. BERT is a basic yet effective tool. It shows promise in a variety of machine learning\ntasks. For each new model to execute a range of functions, aﬁne-tuned BERT model just has to add one\nadditional layer. A veiled language model is used. MLM (Masked Language Model) is based on the\nphenomenon of masking random words from input and then predicting the ID of those words based on\ntheir context. MLM employs both left and right contexts, allowing for bidirectional model training. In\ncontrast to previous language models, BERT can learn the contextual representation from both ends of the\nsentence. For tokenization, BERT used a 30 K vocabulary of character level Byte-Pair Encoding. The\ninput sequence is used to produce tokens and a positional embedding. [CLS] and [SEP], two unique\ntokens, are added to the beginning and end of a sequence, respectively. Text categorization techniques\nsuch as Next Sentence Prediction use the [CLS] token. A separator is provided by the [SEP] token. As a\nresult, we employed BERTBASE in our work. It isn’t suitable for tasks involving ambiguous data mining\nor text mining. It was employed in the identiﬁcation of bogus news in reference [42]. BERT was used to\ndo sentiment analysis in reference [43] and it functioned admirably.\nRoBERTa Model\nThe Transformers’ Bidirectional Encoder Representation is abbreviated into the RoBERTa model [\n44].\nThe Transformers family, which includes the BERT and RoBERTa, was intended to address the long-range\ndependencies problem in sequence-to-sequence modeling. With a bigger vocabulary set of 50 K sub-word\nunits, RoBERTa used byte-level Byte-Pair Encoding. Aside from that, the RoBERTa model improves on\nthe BERT model by training on more data and longer sequences. The RoBERTa tokenizer includes\nvarious unique tokens, such as tokens, which denote the beginning and end of a sentence. The token is\nused to pad the text to achieve the maximum length of the word vector. The RoBERTa tokenizer encodes\nthe raw text with input ids and an attention mask. The input ids represent the token indices and numerical\n1446 CSSE, 2023, vol.45, no.2\nrepresentation of the token. On the other hand, the attention mask is used to group the sequence together as an\noptional input. The attention mask indicates which tokens should be looked at and which should not.\nThe goal of the RoBERTa base layers is to offer a meaningful word embedding as the feature\nrepresentation so that succeeding layers may readily extract useful information from it.\nXLNet Model\nXLNet is a BERT-based autoregressive language model that overcomes the problem of concurrently\ngenerated forecasts using BERT [45]. BERT learns by anticipating disguised words at the same time. The\nrelationships between these predictions are not learned by predicting words simultaneously. XLNet\novercame this by incorporating a permutational language model while retaining BERT’s bi-directionality.\nIt learns to anticipate words by attempting every variation of the words in a sequence. Thus, XLNet\nlearns in a random sequence, yet in a sequential and autoregressive manner. As a result, it consistently\noutperforms BERT on the GLUE benchmark by 2–13 percent. Similar tokens [CLS] and [SEP] are used\nfor classiﬁcation and separation in XLNet.\nXLM-RoBERTa Model\nThe transformer-based multilingual masked language model XLM-RoBERTa has been pre-trained on\ntext in 100 languages and delivers cutting-edge performance in cross-lingual classiﬁcation, sequence\nlabeling and question answering [46]. XLM-RoBERTa improves on BERT by training on a larger dataset,\ndynamically masking tokens instead of static masking by combining a well-known preprocessing\ntechnique (Byte-Pair-Encoding) and a dual-language training mechanism with BERT to learn better\nrelationships between words in different languages. Thus, the transformer models were utilized to boost\nthe accuracy of spam review ﬁltering. It is evident from the experimental results that the usage of\ntransformer models along with readability and sentiment features gives a better future direction towards\nachieving the credibility of the user-generated content like reviews.\n4 Experimental Analysis and Results\nThis section describes the experiment and the outcomes of several machine learning, deep learning, and\ntransformer models. The tables and graphs are supplied to allow for a comparison of the models ’\nperformance.\n4.1 Experimental Setup\nThe experiments are written in Python 3.6.9 in Google Colab to make use of the GPU’s computing\ncapabilities. Numpy 1.18.5 and Huggingface 3.5.1 are used for data preparation and tokenization.\nHuggingface 3.5.1 is also used to implement the pre-trained transformers. Scikit-learn 0.23.2 is used to\nimplement the Machine learning model. Pytorch 1.7.0 or Tensorﬂow 2.3.0 are used to create deep\nlearning models. Matplotlib 3.2.2 is used to create the graphs.\n4.2 Experimental Evaluation of Machine Learning Models\nThe reviews are categorized as fake or non-fake using several Machine learning classiﬁers and assessed\nfor accuracy. Logistic regression classiﬁers excel in accuracy, whereas Support Vector Machine and\nMultinomial Naive Bayes outperform the other classiﬁers. The dataset is alienated into multiple train and\ntest sections, and the accuracy is reported as given inTab. 3. The results of various classiﬁers involved in\nthe fake and truthful reviews and their performance score are being tabulated as shown inTab. 4.\nCSSE, 2023, vol.45, no.2 1447\nThus this paper studied various machine learning classiﬁers for classifying the fake and truthful reviews.\nLogistic regression excels in accuracy among the classiﬁers. Multinomial Naïve Bayes (MNB) and Support\nVector Machine performed better than other classiﬁers.\n4.3 Experimental Evaluation of Deep Learning Models\nThe Deceptive opinion dataset was used in the experiment. Compared to traditional models like LSTM,\nBI-LSTM, CNN + Bi-LSTM and CNN + GRU, the proposed combinational recommended model CNN and\nLSTM with sentiment intensity value offer superior results. Furthermore, the ﬁndings of this hybrid\ntechnique surpass the sentiment intensity values-based model. The proposed hybrid (CNN-LSTM) model\noutperforms existing methods in terms of accuracy. The loss function of the recommended model\noutperformed other models in terms of performance measures. Figs. 3–7 [47] show the correlation\naccuracy estimations of multiple models for the misleading opinion dataset and the results are\nsummarized inTab. 5.\nFig. 3 depicts the LSTM model with an accuracy value of 80.5 percent.Fig. 4 depicts the Bi-LSTM\nmodel with an accuracy of 82.5 percent. The CNN-BiLSTM model has a 59 percent accuracy, as seen in\nFig. 5. On the deceptive opinion dataset, this combination has the lowest accuracy percentage.Fig. 6\ndepicts the CNN-GRU model with a 66 percent accuracy. The suggested CNN-LSTM combinational\nmodel is presented inFig. 7 and it outperforms the current models in terms of accuracy by 87.7 percent\ninvolving readability and sentiment features. The ﬁrst ﬁfty review sentences from the testing set are\nTable 3: Accuracy evaluation details for classiﬁers involving readability and sentiment features\nClassiﬁers involved Training and testing ratio (%) for classi ﬁcation accuracy\n60:40 ratio (%) 70:30 ratio (%) 80:20 ratio (%) 90:10 ratio (%)\nSupport vector machine 85.9 83.9 86.2 86.2\nRandom forest 78.4 74.5 74 78\nDecision tree 65.3 67.5 64 68\nLogistic regression 86.5 85.6 87 87.7\nAda-boost 79.2 80 78 80\nMultinomial naïve bayes 81.8 83.3 83.1 85\nTable 4: Performance score of classiﬁers\nClassiﬁers Truthful reviews Fake reviews\nPrecision\n(%)\nRecall\n(%)\nF-score\n(%)\nPrecision\n(%)\nRecall\n(%)\nF-score\n(%)\nSupport vector machine 85 81 83 82 86 84\nRandom forest 73 81 77 79 71 75\nDecision tree 67 67 67 67 67 67\nLogistic regression 86 84 85 84 86 85\nAda-boost 71 85 81 83 75 79\nMultinomial naïve bayes 91 76 83 80 93 86\n1448 CSSE, 2023, vol.45, no.2\nutilized as input and the deception of these phrases is predicted using the model we provide. The model’s\naccuracy is then compared against the accuracy of several inspired deep learning models. The anticipated\npercentages of accuracy and deception are being computed.\nFigure 3: LSTM model with loss and accuracy values\nFigure 4: Bi-LSTM model with loss and accuracy values\nFigure 5: CNN + Bi-LSTM model with loss and accuracy values\nCSSE, 2023, vol.45, no.2 1449\nThis article investigated the use of deep learning models,ﬁnding that a hybrid mix of CNN and LSTM\nwith readability and sentiment features outperforms other deep learning models such as LSTM, Bi-LSTM,\nCNN + Bi-LSTM and CNN + GRU in terms of accuracy.\n4.4 Experimental Evaluation of Transformer Models\nThe study aims to exploit the transformer models over the deceptive opinion dataset. A range of learning\nrates between 1e− 3 and 5e− 5 will be examined, along with batch sizes ranging from 16 to 32. The models\nwill be trained using Adam optimization and cross-entropy as a loss function. The following settings will be\nFigure 6: CNN + GRU model with loss and accuracy values\nFigure 7: CNN + LSTM model with accuracy and loss curves\nTable 5:Accuracy evaluation details for deep learning models involving readability and sentiment features\nDeep learning model Accuracy percentage involving\nsentiment features only [47]\nAccuracy percentage involving\nreadability and sentiment features\nLSTM 80.5 80.5\nBi-LSTM 82.5 82.5\nCNN + Bi-LSTM 49 59\nCNN + GRU 42 66\nCNN + LSTM 83.7 87.7\n1450 CSSE, 2023, vol.45, no.2\nﬁne-tuned: Number of batches: [16,32] and Rate of learning: [1e− 3, 5e− 3, 1e− 4, 5e− 4, 1e− 5, 5e− 5].\nBelow Tab. 6 shows the results of transformer models on the deception dataset. Again the models were\nevaluated on the accuracy, recall, precision and f1-score as it is given inFig. 8. All models were run on\nﬁve different train-test splits.\n4.5 Findings and Contribution\nThe study’s goal was to investigate how we can employ pre-trained transformers to detect spam reviews.\nTo begin, we experimentally investigated the best combination of machine learning and deep learning\nmodels. Next, we demonstrated that combining transformer-based classi ﬁers improves performance\nagainst spam review ﬁltering. BERT, RoBERTa, XLNet pre-trained language models were used.\nRoBERTa and XLNet were able to classify false reviews more effectively. Overall, RoBERTa-based\ncombination models outperformed all others. In machine learning, logistic regression gave better\nexcellence, and in the case of deep learning, the CNN-LSTM combination outperformed the other models.\n5 Conclusion and Future Direction\nThis study looked into how different pre-trained transformers may be used to identify online spam\nreviews. Furthermore, this study added to current research by assembling the best models utilizing\nreadability and sentiment features for spam review identiﬁcation. In conjunction with all classiﬁcation\nmodels, RoBERTa and the combination of RoBERTa with XLM outperformed BERT in detecting spam\nreviews. These transformers are more sophisticated and as a result, can better convey the review ’s\ncontent. Additionally, the transformer model outperformed the machine learning and deep learning\nmodels. Thus transformers in depth might be quite valuable for natural language processing as it saves\ntime with the pre-trained models by achieving excellence of efﬁciency. The Future direction is towards\nworking on the unavailability of the labeled dataset where the behavioral features will be taken for\nTable 6: Performance details for transformer models\nModels Accuracy Precision Recall F-score Epoch\nBERT 91.2 93 89 91 5\nXLNET 94.3 94.7 94 94.3 5\nRoBERTa 97.13 98 96.4 97 5\nXLM-RoBERTa 98.2 97.8 98.6 98.2 5\nPerformance Percentage\nMetrics Involved\nPerformance of Transformer models\nFigure 8: Performance of transformer models\nCSSE, 2023, vol.45, no.2 1451\nconsidering the fake reviewﬁltering. As the reviews are of user-generated content, they may consist of\nmultilingual categories, and thus multilingual review spam detection will be explored.\nFunding Statement:The authors received no speciﬁc funding for this study\nConﬂicts of Interest:The authors declare that they have no conﬂicts of interest to report regarding the\npresent study.\nReferences\n[1] H. Xue, F. Li, H. Seo and R. Pluretti,“Trust-aware review spam detection,” 2015 IEEE Trustcom/BigDataSE/\nISP A, Helsinki, Finland, vol. 1, pp. 726–733, 2015.\n[2] N. Hu, L. Liu and V. Sambamurthy,“Fraud detection in online consumer reviews,” Decision Support Systems, vol.\n50, no. 3, pp. 614–626, 2011.\n[3] N. Hu, I. Bose, Y. Gao and L. Liu,“Manipulation in digital word-of-mouth: A reality check for book reviews,”\nDecision Support Systems, vol. 50, no. 3, pp. 627–635, 2011.\n[4] M. K. P. Orlow, H. A. Taylor and F. L. Brancati,“Readability standards for informed-consent forms as compared\nwith actual readability,” The New England Journal of Medicine, vol. 348, no. 8, pp. 721–726, 2003.\n[5] L. Zhou, J. K. Burgoon, D. P. Twitchell, T. Qin and J. F. Nunamaker,“A comparison of classiﬁcation methods for\npredicting deception in computer-mediated communication,” Journal of Management Information Systems, vol.\n20, no. 4, pp. 139–166, 2004.\n[6] A. Vartapetiance and L. Gillam,“I don’t know where he is not: Does deception research yet offer a basis for\ndeception detectives?” in Proc. of the Workshop on Computational Approaches to Deception Detection ,\nAvignon, France, pp. 5–14, 2012.\n[7] T. Ong, M. Mannino and D. Gregg,“Linguistic characteristics of shill reviews,” Electronic Commerce Research\nand Applications, vol. 13, no. 2, pp. 69–78, 2014.\n[8] M. Chakraborty, S. Pal, R. Pramanik and C. R. Chowdary,“Recent developments in social spam detection and\ncombating techniques: A survey,” Information Processing & Management, vol. 52, pp. 1053–1073, 2016.\n[9] Y . Li, Z. Qin, W. Xu and J. Guo,“A holistic model of mining product aspects and associated sentiments from\nonline review,” Multimedia Tools and Applications, vol. 74, no. 23, pp. 10177– 94, 2015.\n[10] J. K. Rout, S. Singh, S. K. Jena and S. Bakshi,“Deceptive review detection using labeled and unlabeled data,”\nMultimedia Tools and Applications, vol. 76, no. 3, pp. 3187–211, 2017.\n[11] R. Hassan and M. R. Islam,“Detection of fake online reviews using semi supervised and supervised learning,” in\n2019 Int. Conf. on Electrical, Computer and Communication Engineering, Cox's Bazar, Bangladesh, pp. 1–5,\n2019.\n[12] S. Girgis, E. Amer and M. Gadallah,“Deep learning algorithms for detecting fake news in online text,” in 2018\n13th Int. Conf. on Computer Engineering and Systems, Cairo, Egypt, pp. 93–7, 2018.\n[13] A. Hassan and A. Mahmood,“Deep learning approach for sentiment analysis of short texts,” in 2017 3rd Int.\nConf. on Control, Automation and Robotics, Nagoya, Japan, pp. 705–10, 2017.\n[14] G. Song, D. Huang and Z. Xiao,“A study of multilingual toxic text detection approaches under imbalanced\nsample distribution,” Information, vol. 12, no. 5, pp. 205, 2021.\n[15] D. Jacob, C. Ming-Wei and L. Kristina,“Bert: Pre-training of deep bidirectional transformers for language\nunderstanding,” in Proc. of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, Minneapolis, Minnesota, vol. 1, pp. 4171–4186, 2019.\n[16] M. Mozafari, R. Farah bakhsh and N. Crespi,“A Bert-based transfer learning approach for hate speech detection\nin online social media,” in Int. Conf. on Complex Networks and Their Applications, Springer, Switzerland, pp.\n928–940, 2019.\n[17] Y . Liu, M. Ott, N. Goyal, J. Du, M. Joshiet al.,“Roberta: A robustly optimized bert pretraining approach,” arXiv\npreprint arXiv:1907.11692, 2019.\n[18] G. Lample and A. Conneau,“Cross-lingual language model pretraining,” arXiv:1901.07291, 2019.\n1452 CSSE, 2023, vol.45, no.2\n[19] T. Ranasinghe, M. Zampieri and M. MUDES, “Multilingual detection of offensive spans, ” arXiv,\narXiv:2102.09665, 2021.\n[20] Roy, S. Gosh, U. Narayan, T. Raha, Z. Abidet al., “Leveraging multilingual transformers for hate speech\ndetection,” arXiv:2101.03207, 2021.\n[21] B. Wiese and C. Omlin,“Credit card transactions, fraud detection, and machine learning: Modelling time with\nlstm recurrent neural networks,” in Innovations in Neural Information Paradigms and Applications, Berlin,\nHeidelberg: Springer, pp. 231–268, 2009.\n[22] M. Schuster and K. K. Paliwal, “Bidirectional recurrent neural networks,” IEEE Transactions on Signal\nProcessing, vol. 45, pp. 2673–2681, 1997.\n[23] Y . A. Amrani, M. Lazaar and K. E. E. Kadiri,“Random forest and support based hybrid on vector intelligent\nmachine approach to sentiment analysis,” Procedia Computer Science, vol. 127, pp. 511–520, 2018.\n[24] M. Rhanoui, M. Mikram, S. Yousﬁ and S. Barzali,“A cnn-bilstm model for document-level sentiment analysis,”\nMachine Learning and Knowledge Extraction, vol. 1, no. 3, pp. 832–847, 2019.\n[25] L. Zhang and F. Xiang,“Relation classiﬁcation via bilstm-cnn,” Data Mining and Big Data, no. 10, pp. 373–382,\n2018.\n[26] S. Okura, Y. Tagami, S. Ono and A. Tajima,“Embedding-based news recommendation for millions of users,” in\nProc. of the 23rd ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining, Halifax, NS, Canada, pp.\n1933–1942, 2017.\n[27] B. Liu, Y . Zhou and W. Sun,“Character-level text classiﬁcation via convolutional neural network and gated\nrecurrent unit,” International Journal of Machine Learning and Cybernetics, vol. 11, no. 8, pp. 1939–1949, 2020.\n[28] E. Greevy and A. F. Smeaton,“Classifying racist texts using a support vector machine,” in Proc. of the 27th\nAnnual Int. ACM SIGIR Conf. on Research and Development in Information Retrieval,S h e fﬁeld, UK, vol. 25,\nno. 29, pp. 468–469, 2004.\n[29] I. Alﬁna, R. Mulia, M. I. Fanany and Y. Ekanata,“Hate speech detection in the Indonesian language: A dataset and\npreliminary study,” in 2017 Int. Conf. on Advanced Computer Science and Information Systems (ICACSIS),\nIndonesia, pp. 233–238, 2017.\n[30] I. Kwok and Y. Wang,“Locate the hate: Detecting tweets against blacks,” in Twenty-Seventh AAAI Conf. on\nArtiﬁcial Intelligence, USA, vol. 27, pp. 1621–1622, 2013.\n[31] L. Chen, L. Hong and J. Liu,“Analysis and prediction of new media information dissemination of police\nmicroblog,” Journal of New Media, vol. 2, no. 2, pp. 91–98, 2020.\n[32] M. A. Saif, A. N. Medvedev, M. A. Medvedev and T. Atanasova,“Classiﬁcation of online toxic comments using\nthe logistic regression and neural networks models,” in AIP Conf. Proc., New York, NY, USA, vol. 2048, pp.\n060011–060014, 2018.\n[33] X. Huang, L. Xing, F. Dernoncourt and M. J. Paul,“Multilingual twitter corpus and baselines for evaluating\ndemographic bias in hate speech recognition,” arXiv preprint arXiv:2002.10361, 2020.\n[34] S. S. Aluru, B. Mathew, P. Saha and A. Mukherjee,“Deep learning models for multilingual hate speech\ndetection,” arXiv:2004.06465, 2020.\n[35] S. Shojaee, M. A. A. Muradt, A. B. Azman, N. M. Sharef and S. Nadali,“Detecting deceptive reviews using\nlexical and syntactic features,” in 2013 13th Int. Conf. on Intelligent Systems Design and Applications ,\nSalangor, Malaysia, pp. 53–58, 2013.\n[36] X. Wang, X. Zhang, C. Jiang and H. Liu,“Identiﬁcation of fake reviews using semantic and behavioral features,”\nin 2018 4th Int. Conf. on Information Management (ICIM), Oxford, UK, pp. 92–97, 2018.\n[37] J. Fontanarava, G. Pasi and M. Viviani, “Feature analysis for fake review detection through supervised\nclassiﬁcation.” in 2017 IEEE Int. Conf. on Data Science and Advanced Analytics (DSAA), Tokyo, Japan,\npp. 658–666, 2017.\n[38] M. Ott, Y. Choi, C. Cardie and J. T. Hancock,“Finding deceptive opinion spam by any stretch of the imagination,”\narXiv preprint arXiv:1107.4557, 2011.\nCSSE, 2023, vol.45, no.2 1453\n[39] N. Hussain, H. T. Mirza, G. Rasool, I. Hussain and M. Kaleem,“Spam review detection techniques: A systematic\nliterature review,” Applied Science, vol. 9, no. 987, pp. 1–26, 2019.\n[40] V . Maslej, M. Sarnovský, P. Butka and K. Machová,“Comparison of deep learning models and various text pre-\nprocessing techniques for the toxic comments classiﬁcation,” Applied Science, vol. 10, no. 8631, pp. 1–26, 2020.\n[41] M. P. O’Mahony and B. Smyth,“Using readability tests to predict helpful product reviews,” in RIAO 2010 the\n9th Int. Conf. on Adaptivity, Personalization and Fusion of Heterogeneous Information , Paris, France,\npp. 164–167, 2010.\n[42] R. K. Kaliyar, A. Goswami and P. Narang,“Fakebert: Fake news detection in social media with a bert-based deep\nlearning approach,” Multimedia Tools and Applications, vol. 80, no. 8, pp. 11765–11788, 2021.\n[43] C. Sun, L. Huang and X. Qiu,“Utilizing bert for aspect based sentiment analysis via constructing auxiliary\nsentence,” arXiv preprint arXiv:1903.09588, 2019.\n[44] H. Al-Jarrah, R. Al-Hamouri and A. S. Mohammad,“The impact of roberta transformer for evaluation common\nsense understanding,” in Proc. of the Fourteenth Workshop on Semantic Evaluation, Barcelona (online), pp. 521–\n526, 2020.\n[45] Z. Yang, Z. Dai, Y . Yang, J. Carbonell, R. R. Salakhutdinovet al.,“Xlnet: Generalized autoregressive pretraining\nfor language understanding,” Advances in Neural Information Processing Systems, vol. 32, pp. 5753–5763, 2019.\n[46] A. Conneau, K. Khandelwal, N. Goyal, V. Chaudhary, G. Wenzek et al., “Unsupervised cross-lingual\nrepresentationl learning at scale,” in Proc. of the 58th Annual Meeting of the Association for Computational\nLinguistics, ACL (online), pp. 8440–8451, 2020.\n[47] R. S. Kanmani and B. Surendiran, “Boosting credibility of a recommender system using deep learning\ntechniques-an empirical study,” International Journal of Engineering Trends and Technology, vol. 69, no. 10,\npp. 235–243, 2021.\n1454 CSSE, 2023, vol.45, no.2",
  "topic": "Readability",
  "concepts": [
    {
      "name": "Readability",
      "score": 0.9137438535690308
    },
    {
      "name": "Transformer",
      "score": 0.7768305540084839
    },
    {
      "name": "Computer science",
      "score": 0.7765563726425171
    },
    {
      "name": "Encoder",
      "score": 0.6425285935401917
    },
    {
      "name": "Sentiment analysis",
      "score": 0.5782793164253235
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5605183839797974
    },
    {
      "name": "Language model",
      "score": 0.48564043641090393
    },
    {
      "name": "Machine learning",
      "score": 0.4659368097782135
    },
    {
      "name": "Deep learning",
      "score": 0.4445200264453888
    },
    {
      "name": "The Internet",
      "score": 0.44181129336357117
    },
    {
      "name": "Data science",
      "score": 0.3780733346939087
    },
    {
      "name": "Natural language processing",
      "score": 0.37384703755378723
    },
    {
      "name": "World Wide Web",
      "score": 0.20941871404647827
    },
    {
      "name": "Engineering",
      "score": 0.11273682117462158
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 9
}