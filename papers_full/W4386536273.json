{
  "title": "Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in Decentralized Finance",
  "url": "https://openalex.org/W4386536273",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2890545031",
      "name": "Ahyun Song",
      "affiliations": [
        "Sungkyunkwan University"
      ]
    },
    {
      "id": "https://openalex.org/A2145671926",
      "name": "Eui-Seong Seo",
      "affiliations": [
        "Kyonggi University"
      ]
    },
    {
      "id": "https://openalex.org/A2126650939",
      "name": "Hee-Youl Kim",
      "affiliations": [
        "Sungkyunkwan University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4200629745",
    "https://openalex.org/W2944302975",
    "https://openalex.org/W2987821246",
    "https://openalex.org/W2768800090",
    "https://openalex.org/W4214575999",
    "https://openalex.org/W4289533854",
    "https://openalex.org/W6686453509",
    "https://openalex.org/W3177318507",
    "https://openalex.org/W6756753118",
    "https://openalex.org/W4323322022",
    "https://openalex.org/W6803671390",
    "https://openalex.org/W6784869275",
    "https://openalex.org/W3170937175",
    "https://openalex.org/W3128634608",
    "https://openalex.org/W3179573039",
    "https://openalex.org/W2968035976",
    "https://openalex.org/W2962831337",
    "https://openalex.org/W2789063661",
    "https://openalex.org/W4382203122",
    "https://openalex.org/W4382998627",
    "https://openalex.org/W2963610939",
    "https://openalex.org/W2906498146",
    "https://openalex.org/W3081497074",
    "https://openalex.org/W2981650061",
    "https://openalex.org/W2599354622",
    "https://openalex.org/W2622370560",
    "https://openalex.org/W4205388843",
    "https://openalex.org/W6715501732",
    "https://openalex.org/W2963523189",
    "https://openalex.org/W3015959599",
    "https://openalex.org/W4210263262",
    "https://openalex.org/W2963166639",
    "https://openalex.org/W3198381997",
    "https://openalex.org/W3040266635",
    "https://openalex.org/W3184127157",
    "https://openalex.org/W6802061597",
    "https://openalex.org/W2962736999",
    "https://openalex.org/W2962791923",
    "https://openalex.org/W2808771744",
    "https://openalex.org/W2963795951",
    "https://openalex.org/W2960737790",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6640963894",
    "https://openalex.org/W3155567600",
    "https://openalex.org/W2122646361",
    "https://openalex.org/W4288057688",
    "https://openalex.org/W2949500778",
    "https://openalex.org/W3035699237",
    "https://openalex.org/W3006668450",
    "https://openalex.org/W6793954727",
    "https://openalex.org/W3162783690",
    "https://openalex.org/W2991581693",
    "https://openalex.org/W2921674422",
    "https://openalex.org/W2784213583",
    "https://openalex.org/W2998523344",
    "https://openalex.org/W3014078607",
    "https://openalex.org/W3045256896",
    "https://openalex.org/W3002238338",
    "https://openalex.org/W1959608418",
    "https://openalex.org/W2902455138",
    "https://openalex.org/W3156551120",
    "https://openalex.org/W4308606797",
    "https://openalex.org/W4295720041",
    "https://openalex.org/W4294568686",
    "https://openalex.org/W3204263062",
    "https://openalex.org/W3099971460",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3135550350"
  ],
  "abstract": "DeFi, a decentralized financial service based on blockchain, not only provides innovative financial services, but also poses various risks, such as the Terra Luna crash. Therefore, anomaly detection in DeFi is necessary to ensure the safety and reliability of the DeFi ecosystem. However, this is very difficult because of the complex protocol, interaction among smart contracts, and high market volatility. In this study, we propose a novel method to effectively detect anomalies in DeFi. To the best of our knowledge, this is the first study that utilizes deep learning to detect anomalies in DeFi. We propose a deep learning model, anomaly VAE-Transformer, which combines the variational autoencoder to extract local information in the short term, and the transformer, to identify dependencies between data in the long term. Based on a deep understanding of DeFi protocols, the proposed model collects and analyzes various on-chain data of Olympus DAO, a representative DeFi protocol, for extracting features suitable for anomaly detection. Then, we demonstrate the superiority of the proposed model by analyzing four anomaly cases detected successfully by the proposed model in Olympus DAO. A malicious attack attempt and structural changes in DeFi protocols can be identified quickly using the proposed method; this is expected to help protect the assets of DeFi users and improve the safety, reliability, and transparency of the DeFi market. The dataset and codes are available at <uri>https://github.com/fialle/Anomaly-VAE-Transformer</uri>",
  "full_text": "Received 27 August 2023, accepted 4 September 2023, date of publication 8 September 2023,\ndate of current version 13 September 2023.\nDigital Object Identifier 10.1 109/ACCESS.2023.3313448\nAnomaly VAE-Transformer: A Deep Learning\nApproach for Anomaly Detection in Decentralized\nFinance\nAHYUN SONG\n1, EUISEONG SEO\n 1, (Member, IEEE), AND HEEYOUL KIM\n 2\n1Department of Computer Science and Engineering, Sungkyunkwan University, Seoul 03063, South Korea\n2Division of Computer Science and Engineering, Kyonggi University, Suwon 16227, South Korea\nCorresponding author: Heeyoul Kim (heeyoul.kim@kyonggi.ac.kr)\nThis work was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the\nMinistry of Education under Grant 2020R1A6A1A03040583.\nABSTRACT DeFi, a decentralized financial service based on blockchain, not only provides innovative\nfinancial services, but also poses various risks, such as the Terra Luna crash. Therefore, anomaly detection\nin DeFi is necessary to ensure the safety and reliability of the DeFi ecosystem. However, this is very difficult\nbecause of the complex protocol, interaction among smart contracts, and high market volatility. In this\nstudy, we propose a novel method to effectively detect anomalies in DeFi. To the best of our knowledge,\nthis is the first study that utilizes deep learning to detect anomalies in DeFi. We propose a deep learning\nmodel, anomaly V AE-Transformer, which combines the variational autoencoder to extract local information\nin the short term, and the transformer, to identify dependencies between data in the long term. Based on a\ndeep understanding of DeFi protocols, the proposed model collects and analyzes various on-chain data of\nOlympus DAO, a representative DeFi protocol, for extracting features suitable for anomaly detection. Then,\nwe demonstrate the superiority of the proposed model by analyzing four anomaly cases detected successfully\nby the proposed model in Olympus DAO. A malicious attack attempt and structural changes in DeFi protocols\ncan be identified quickly using the proposed method; this is expected to help protect the assets of DeFi users\nand improve the safety, reliability, and transparency of the DeFi market. The dataset and codes are available\nat https://github.com/fialle/Anomaly-VAE-Transformer\nINDEX TERMS Anomaly detection, blockchain, deep learning, DeFi, Olympus DAO.\nI. INTRODUCTION\nDecentralized finance (DeFi) is a distributed finance service\nimplemented through smart contracts on a blockchain net-\nwork without using centralized financial institutions. DeFi\novercomes the limitations of traditional finance, such as\ninformation asymmetry between users and institutions, high\ntransaction fees, and delayed transactions, while heightening\nthe transparency and accessibility of financial services and\ninducing various financial innovations. According to DeFi\nLlarma [1], the total value locked (TVL) deposited in DeFi\nprotocols peaked at approximately $180 billion at the end of\n2021, 12 times higher than that compared to $15 billion at the\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Rajeeb Dey\n.\nend of 2020. The DeFi market has been stagnant in addition to\nthe overall decline of the cryptocurrency market that started\nin the first half of 2022; the TVL of DeFi protocols is around\n$46 billion as of May 2023.\nThe DeFi ecosystem is innovative and consistently grow-\ning through various financial services; however, there are also\nrisks of abnormal transactions and fraudulent practices such\nas:\nFlash loan attack on bZx protocol in 2020: The attacker\nutilized a flash loan to manipulate the market price of wBTC\nby exploiting a bug in bZx.\nTrue Seigniorage Dollar (TSD) attack in 2021: The\nattacker abused the principles of DAO, amassing TSD tokens\nto gain voting power, then induced the DAO to upgrade the\nsmart contract with malicious code.\nVOLUME 11, 2023\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.\nFor more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/ 98115\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nTerra LUNA crash in 2022: This crash resulted from a\nrapid UST sell-off, causing oversupply of Luna and a signif-\nicant price drop. The primary cause was the vulnerability in\nthe algorithm designed to maintain the price of UST.\nSmart contract attack on Yearn Finance in 2023: The\nattacker exploited a hardcoded misconfiguration in Yearn\nFinance’s smart contract code.\nTherefore, anomaly detection in DeFi is extremely impor-\ntant and necessary to protect users and improve the safety and\nreliability of the DeFi ecosystem.\nAnomaly detection refers to the process of detecting\nan anomaly or outlier, which is a type of data represent-\ning patterns deviating from the normal category. In recent\nyears, notable advancements in deep learning technology\nhave been achieved in various fields including computer\nvision, natural language processing, and voice recognition,\nand therefore, numerous studies have focused on utiliz-\ning deep learning technology in the anomaly detection\nfield [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12].\nHowever, there remain numerous challenges to realizing\nanomaly detection because of its distinctive characteristics.\nUnlike general problems, an anomaly occurs very rarely and\ncannot be predicted. In addition, it is defined differently based\non the domain, ranging from finance and medical to smart\nmanufacturing. Thus, a general anomaly detection model\ncannot be easily applied to different domains.\nRecently, the blockchain technology has been under the\nspotlight over the past few years. Yet, the technology has\nnot fully matured and there is a completely different techno-\nlogical difficulty stemming from the nature of decentralized\npeer-to-peer networks. Thus, research on anomaly detection\nusing deep learning technology in a blockchain network is\nstill in the early stages [13], [14], [15]. Past research focused\non the detection of a Ponzi scheme, which is a specific type of\nfraud with a narrower scope than anomalies in a blockchain\nnetwork [16], [17], [18], [19], [20], [21], [22], [23], [24], [25],\n[26], [27], [28], [29].\nThus, there is lack of research on anomaly detection in\nDeFi, which is a new type of a distributed financial ser-\nvice implemented on a blockchain network. DeFi has the\ntechnological burden of a complex structure where various\nprotocols and tokens interact based on blockchain and smart\ncontract technologies. Therefore, a thorough understanding\nof the operation principle of a blockchain and the on-chain\ndata structure is required to analyze data related to DeFi.\nIn addition, the market volatility of DeFi is extremely high\nbecause it is a financial ecosystem that is still in the early\nstages, which causes normal transaction patterns to change\nvery rapidly or the line between abnormal and normal trans-\nactions to become unclear. Given these abovementioned rea-\nsons, detecting anomaly in DeFi is an extremely difficult\nand unique challenge requiring active research to obtain a\nsolution.\nIn this paper, we propose an anomaly variational autoen-\ncoder (V AE)-Transformer, which is a new deep learning\nmodel for anomaly detection in DeFi. The proposed model\ncombines a V AE for extracting local information in the short\nterm [30] and a transformer for identifying the dependency\nbetween data in the long term [31]. The V AE encoder encodes\ntime series daily data into low-dimensional embedding and\nsends it to the transformer. The transformer receives the\nembedding sequence and generates contextualized embed-\ndings; the output is sent to a V AE decoder, which inputs\nthe output of the transformer and reconstructs the daily data.\nThe proposed model uses the difference between original\nand reconstructed data for anomaly detection. To the best of\nour knowledge, our research is the first study utilizing deep\nlearning for anomaly detection in DeFi.\nFor evaluation, we applied the proposed model to Olym-\npus decentralized autonomous organization (DAO), which\nis one of the largest DeFi at this moment. To this end,\nwe collected and analyzed the transactions of Olympus DAO\nusers related to staking, unstaking, bond creation, and bond\nredemption activity, the internal transactions between smart\ncontracts invoked accordingly, and the event logs generated\nas execution results. Based on the analyzed on-chain data,\n12 features are extracted for use in the anomaly detection\nmodel. This is unlike previous studies that detect fraud and\nPonzi schemes in a blockchain using only simple transac-\ntions. Further, we calculate anomaly scores using the trained\nanomaly V AE-Transformer and detect anomalies in Olympus\nDAO. Moreover, we thoroughly analyze the four detected\nanomaly cases of Olympus DAO. The analysis results con-\nfirm that the proposed anomaly V AE-Transformer model can\nsuccessfully detect different abnormal patterns and is suitable\nfor anomaly detection in Olympus DAO.\nThe major contributions of this study are summarized\nbelow.\n• To the best of our knowledge, this is the first study on\nanomaly detection in DeFi using deep learning technol-\nogy.\n• With a deep understanding of the DeFi protocol, the pro-\nposed model extracts features appropriate for anomaly\ndetection by collecting and analyzing transactions and\nrelated various on-chain data.\n• We propose the anomaly V AE-Transformer model that\ncombines a V AE for extracting local information in the\nshort term and a transformer for identifying dependency\nbetween data in the long term for anomaly detection in\nDeFi.\n• The actual dataset of Olympus DAO is used. The\nexcellence of the proposed model is proved by care-\nfully analyzing the four cases in which the anomaly\nV AE-Transformer model successfully detects anomalies\nin Olympus DAO.\nThe remainder of this manuscript is organized as follows:\nIn Section II, DeFi and Olympus DAO are examined in\ndetail and previous studies on anomaly detection using deep\nlearning are reviewed. In Section III, data collection and\nfeature extraction for anomaly detection in DeFi are ana-\nlyzed, and the proposed anomaly V AE-Transformer model\n98116 VOLUME 11, 2023\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nis explained. Section IV explains the implementation of the\nproposed model and the experiment on anomaly detection\nin Olympus DAO, and the results of anomaly detection are\nanalyzed in detail. Finally, Section V concludes the findings\nof this research.\nII. RELATED WORK\nA. DEFI AND OLYMPUS DAO\nDeFi, or decentralized finance, is a distributed finance ser-\nvice implemented through smart contracts without using\ncentralized financial institutions on a blockchain network.\nBlockchain is a type of distributed ledger technology where\nanyone can read data but not manipulate it because the block\ndata are stored in a decentralized peer-to-peer storage sys-\ntem. All nodes participating in a blockchain share the same\nrecords, requiring agreement among all nodes. Therefore,\nalthough a higher number of nodes in a blockchain results\nin inefficiency, the essential nature of decentralization is\nheightened because data are shared by more nodes. Thus,\na blockchain has the potential to offer diverse services that\ndiffer from conventional centralized services because of the\ndecentralization of data, server, and decision making.\nIn traditional finance, centralized financial companies\nmanage and control the overall processes of financial ser-\nvices. That is, financial companies plan financial services,\ndetermine the terms of the offered products, and explain the\ndetails of the services to customers. Then, financial services\nare provided to customers by implementing the matters speci-\nfied in terms and conditions. All processes are executed by the\nindependent systems of each financial company using which\nall information including transaction history is recorded and\nmanaged. Consequently, customers can only obtain very lim-\nited information compared to that accessible to financial\ncompanies, and they end up paying high financial charges to\nthese companies. Further, the safety of financial companies,\nwhere all information related to financial services is stored,\nis directly related to the safety of financial services.\nIn contrast, DeFi enables direct financial transac-\ntions among users without the need for a centralized\nagency by using blockchain and smart contract technology.\nA blockchain network plays the role of a platform in DeFi; on\nthis network, anyone can create financial services with their\nown rules, and other uses who agree with such rules can freely\nuse the relevant service without the permission of the person\nwho created the services. All information related to DeFi\nincluding financial transactions is transparently recorded in\nthe nodes of the blockchain network, and the DeFi service\nis executed through smart contracts for which the rules of\nthe service are programmed. DeFi has been gaining consid-\nerable research interest as an alternative to traditional finance\nentailing structural issues such as information asymmetry\nbetween users and financial companies, high transaction fees,\nand delayed transactions.\nThe DeFi ecosystem provides traditional financial services\nsuch as deposits, loans, trade, insurance, asset management,\nand derivatives. Further, the DeFi ecosystem provides cre-\native, innovative, and converged services by freely connect-\ning and utilizing other DeFi services. Some notable DeFi\nservices include MakerDAO, Compound, and Aave in the\ncredit/lending field, Uniswap in the decentralized exchange\n(DEX) field, Yield and Synthetix in the derivatives field, and\nNexus Mutual in the insurance field.\nAmong the various DeFi services, Olympus DAO, which\nis a representative service of DeFi 2.0, is examined in detail\nin this study. Olympus DAO is an Ethereum-based decen-\ntralized reserve currency protocol launched in March 2021,\nand it first proposed protocol owned liquidity (POL), which\ndifferentiates it from conventional DeFi services. Further,\nOlympus DAO has recently received increasing attention as\nan approach that can provide a higher yield than that of\ntraditional financial services, guarantee a minimum value\nof OHM token as treasury owned assets, and participate in\ndecision making through a DAO.\nThe minimum value of an OHM token issued by Olympus\nDAO is guaranteed by the assets deposited in the treasury.\nIn other words, the treasury of Olympus DAO is used to pro-\nvide liquidity and guarantee the values of the OHM tokens.\nThe Olympus DAO treasury is operated by a DAO, and it\nis safely managed against hacking attempts by applying the\nmultisignature wallet technology. The assets in the Olympus\nDAO treasury can increase in value through certain activities\nsuch as receiving rewards by providing liquidity when OHM\ntoken transactions increase within DEX or by transferring\nthe difference between the sales and issuance prices of bonds\nthrough bonding sales.\nStaking and bonding are two core mechanisms of Olym-\npus DAO. The Olympus DAO participants can earn interest\nthrough staking and purchase OHM tokens at a discounted\nprice through bonding. Further, the Olympus DAO protocol\ncan secure safety by directly owning liquidity and treasury\nassets through staking and bonding.\nBonding plays an important role in increasing the assets\nowned by the treasury. Bonders (bonding participants) can\npurchase an OHM token at a discounted price from the market\nprice. Further, bonders can participate in staking by owing\nOHM tokens or earn profits by selling the token after a\ncertain period (five days by default). The protocol receives\nassets from bonders and transfers them to the treasury assets.\nStakers stake OHM tokens in a protocol and receive the\nrebase rewards. Olympus DAO provides a high yield to stak-\ners, thereby inducing the demands for OHM tokens. Stakers\nreceive sOHM once they stake OHM tokens, and the number\nof sOHM tokens increases according to APY , which is a yield\ngiven by a smart contract. Finally, stakers receive the same\namount of OHM tokens as sOHM when they unstake at a later\ntime.\nB. ANOMALY DETECTION USING DEEP LEARNING\nAnomaly detection refers to the process of detecting an\nanomaly or outlier, which is a type of data representing\npatterns deviating from the normal category. Anomaly detec-\ntion has been actively researched over the past few decades\nVOLUME 11, 2023 98117\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nin several fields including the detection and monitoring of\nfinancial misdeeds such as the fraudulent use of credit cards,\nfinancial transaction fraud, market manipulation, cyber secu-\nrity, quality management, medical and healthcare risks, and\nsmart manufacturing [2], [3].\nAn anomaly can be categorized into various types such\nas point, conditional, and group anomalies [4], [32], [33].\nA point anomaly is an individual data point or sequence hav-\ning unusual values compared to other data. Examples include\nan excessively high financial transactions or abnormal health\nindicators of a patient’s health. A conditional anomaly refers\nto an individual data point or sequence having unusual values\nin a specific context. For example, a sharp decline in tem-\nperature during the summer in seasonal temperature data is\na conditional anomaly. A group anomaly refers to a group\nof data demonstrating unusual patterns compared to other\ngroups of data. Here, an individual data point belonging to\ngroup anomaly can be normal. Examples of group anomaly\ninclude transactions demonstrating strange patterns in con-\ntinuous financial transactions or repetitions of normal system\nlogs at specific times.\nDeep learning technology is being applied in numerous\nfields because of the rapid developments in the artificial\nintelligence field. Anomaly detection is an important issue\nthat is actively researched in various domains, and there-\nfore, many studies have focused on using deep learning\ntechnology in the anomaly detection domain. For exam-\nple, in [3], deep anomaly detection is categorized into the\nfollowing three types: (1) deep learning for feature extrac-\ntion, (2) end-to-end anomaly score learning, and (3) learn-\ning feature representations of normality. In (1) deep learn-\ning and anomaly detection are separated completely where\ndeep learning is used only for feature extraction. Research\nbelonging to this type utilizes deep learning technology\nfor extracting low-dimensional feature representations from\nhigh-dimensional data. These studies applied and imple-\nmented pre-trained deep learning models; however, com-\npletely separating feature extraction and anomaly scoring can\ninterfere with deducing optimal results [34], [35], [36]. In (2),\ndeep learning and anomaly scoring module are integrated\ncompletely, wherein a neural network that learns anomaly\nscores in an end-to-end method is used. Research in this type\nfocuses on simultaneously learning feature representation\nand anomaly scores. Because previous anomaly measures\nare not used, loss functions with excellent performance must\nbe designed for anomaly score learning [37], [38], [39].\nIn (3), deep learning and anomaly scoring module are not\ncompletely separated, and thus, it aims to learn normality\neffectively. Studies on autoencoders [8], [40], [41], genera-\ntive adversarial networks [42], [43], [44], and predictability\nmodeling [45], [46], [47] belong to this category.\nTime-series anomaly detection refers to detecting abnor-\nmal data, or anomaly (point anomaly, conditional anomaly,\nand group anomaly), in time-series data arranged in a chrono-\nlogical order among various types of data. Data are con-\nstantly generated in real time in many application fields; thus,\ndetecting and responding to anomaly in early stages by mon-\nitoring the time-series data are significant for heightening\nthe efficiency and safety of a relevant domain. Therefore,\ntime-series anomaly detection is extensively researched in\na variety of domains including finance, medical, environ-\nment, and manufacturing process. Most studies on time-series\nanomaly detection using deep learning technology belong to\nlearning feature representations of normality among the dif-\nferent categories of deep anomaly detection. With respect to\nanomaly detection methods, research on time-series anomaly\ndetection can be categorized into reconstruction, forecasting,\nand dissimilarity methods [2], [3], [4], [5].\nReconstruction methods involve reconstructing data and\ndetecting anomalies using the difference between original\nand reconstructed data. Autoencoder (AE) [40], [48], [49],\nV AE[8], [9], [10], [11], [12], [50], and transformer based\nmodels [5], [6], [7], [51], [52] use such reconstruction errors.\nIn [50], a semi-supervised framework is introduced, employ-\ning a V AE and a one-class support vector machine for the\ndetection of structural anomalies. In [51], a transformer-\nbased generative adversarial network(GAN) framework is\npresented for time series anomaly detection. Reference [52]\nproposes an adversarial transformer model designed for\ndetecting anomalies in multivariate time series data. Forecast-\ning methods involve predicting the future state based on past\nand present states and detecting anomaly using the difference\nbetween the predicted and observed values [45], [53], [54].\nDissimilarity methods detect an anomaly by measuring the\ndissimilarity of data distribution or the distance from clusters\nwhere similar data are clustered [55], [56], [57].\nV AE-LSTM [8] uses both a V AE module for identify-\ning local features of a short window and an LSTM mod-\nule for estimating the general correlation in the long term.\nAn encoder in the V AE module generates low-dimensional\nembedding for a short window, the LSTM receives the gener-\nated embedding as an input and predicts the next embedding,\nand the decoder receives the predicted embedding as an input\nand reconstructs the original window. The reconstruction\nerror is the anomaly detection score of V AE-LSTM. Anomaly\ntransformer [5] presents a new anomaly attention module\nthat simultaneously calculates prior association focusing on\nnearby data and series association that identifies association\nfrom the perspective of entire data. Prior association applies\nthe learnable Gaussian kernel, while series association func-\ntions similar to the self-attention of a general transformer.\nIn addition, the anomaly transformer amplifies the difference\nbetween normal and abnormal data by applying minimax\nassociation learning.\nAnomaly detection still has numerous challenges to over-\ncome because of its distinctive characteristics. Unlike other\ncommon problems, anomaly detection occurs very rarely and\ncannot be predicted [3]. Most datasets have a significantly\ngreater amount of normal data and extremely small amounts\nof anomalies. Due to this class imbalance, it is challenging\n98118 VOLUME 11, 2023\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nor even impossible to obtain labeled data. Further, normal\ndata can be misrecognized as anomaly due to noise, which\nis a type of error that can irregularly occur in the process\nof collecting and processing data. In addition, anomaly is\nfrequently associated with factors that cannot be known in\nadvance such as financial fraud or cyberattacks. Anomaly is\ndefined differently and has varying characteristics for each\ndomain, and therefore, a general anomaly detection model\ncannot be applied identically to different domains.\nThe blockchain technology has recently been under the\nspotlight; however, this technology has not matured and there\nis a completely different technological difficulty arising from\nthe nature of a decentralized peer-to-peer network. Thus,\nresearch on anomaly detection in a blockchain network using\ndeep learning technology is still in its early stages [1], [2],\n[3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15].\nFor blockchain networks, research is more actively con-\nducted on a specific type of fraud, or a Ponzi scheme, which\nhas narrower scope than anomaly detection [16], [17], [18],\n[19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29].\nA Ponzi scheme is a traditional financial investment fraud\nthat lures users by guaranteeing high profits. A Ponzi scheme\non a blockchain network can induce more serious damages\nbecause of the anonymity of a blockchain and the unchange-\nable and unstoppable execution characteristics of a smart\ncontract [16], [17].\nIn [16], smart contracts having the features of a Ponzi\nscheme were detected and analyzed to examine the dataset\nof 184 Ponzi schemes. The results of analyzing inflow and\noutflow transaction, life span, volume of payment, and pay-\nment inequality of 184 Ponzi schemes are presented. In [18],\nfeatures were extracted from the opcode of user accounts\nand smart contracts, and then, a Ponzi scheme was detected\nusing data mining and machine learning methods. In [21],\n172 Ponzi schemes and 3,203 non-Ponzi smart contracts were\nused as a dataset, and a Ponzi detection model based on data\nmining to which opcode feature and behavior-based features\nare applied was proposed.\nIn [23], exploit transactions and attacker EOAs were ana-\nlyzed for understanding attacks toward decentralized appli-\ncations (Dapps) on Ethereum, and DEFIER, which is a tool\nfor investigating new Dapps attacks, was proposed. In [24],\nseveral features such as the time difference between the first\nand last transactions, entire Ether balance, and minimum\nvalue of the received Ether were used, and a model was\nproposed to detect illicit accounts on the Ethereum network\nbased on transaction history.\nDeFi is growing continuously as it continues to provide\ninnovative financial services based on a blockchain. DeFi is\novercoming the limitations of traditional financial systems\nand substantially contributing to heightening the accessibility\nand transparency of financial services. However, abnormal\ntransactions and fraudulent practices are present in the DeFi\necosystem, and there is a lack of research on anomaly detec-\ntion in DeFi, whereas research on the overall security of\nDeFi is still in the rudimentary stages. Thus, research on\nFIGURE 1. Overall process of anomaly detection in Olympus DAO.\nanomaly detection in DeFi is inevitable for protecting users\nand enhancing the safety and reliability of the DeFi ecosys-\ntem.\nIII. PROPOSED MODEL\nThis study proposes an anomaly V AE-Transformer model\nthat is newly designed for anomaly detection in DeFi. This\nstudy targeted Olympus DAO, which is a popular DeFi pro-\ntocol, and the proposed model can be applied to other DeFi\nprotocols through minor modifications. Fig. 1 shows the\nprocess of anomaly detection in Olympus DAO. Data related\nto Olympus DAO are collected from on-chain data saved\nin the Ethereum blockchain, and then, they are analyzed to\nextract appropriate features. In the subsequent step, such data\nare used to train the proposed anomaly V AE-Transformer\nmodel. Finally, the trained model is used to detect anomaly\nin Olympus DAO, and the detection results are analyzed.\nIn the time-series data analysis, data are aggregated by the\nspecific time interval (minute, hour, day, etc.) to be used.\nHourly data are the most appropriate for Defi analyses. The\nfrequency of data generation is insufficient to conduct the\nanalysis on a minute basis considering the time required for\nthe blockchain consensus or the transaction period of users.\nDaily data cannot properly reflect the high volatility of the\nDeFi market, and therefore, large fluctuations that occur for\na day can be missed. The proposed model utilizes the hourly\ndata for anomaly detection; the method for collecting the\nappropriate data based on understanding Olympus DAO and\nextracting appropriate features to constitute hourly data is\nexplained in Section III-A.\nFor performing anomaly detection in DeFi, various types\nof data must be analyzed and high-dimensional data need to\nbe examined because of the complexity of DeFi. Although\nhourly data are examined in this study, fairly long time\nsequence (e.g., one month) data need to be inspected instead\nof the data of a few hours to capture long-term dependency\nbetween data and to increate detection accuracy. Considering\nthese circumstances, we propose an approach to combine\nthe V AE and the transformer. Unlike traditional RNNs such\nas LSTM, the transformer has an outstanding capability to\nprocess long-term dependency in long-sequence data because\nof the self-attention mechanism. However, the transformer\nentails a high computational cost when utilizing extremely\nlong sequences or high-dimensional data because it requires\nquadratic computational complexity. Further, V AE reduces\nthe complexity of high-dimensional data and projects data\nonto a low-dimensional latent space for better representation.\nVOLUME 11, 2023 98119\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nThe proposed anomaly V AE-Transformer model detects\nanomaly in a high-dimensional long data sequence based\non the integration between the V AE and the transformer.\nThe proposed model uses V AE to encode the sequence into\nlow-dimensional embedding and the transformer to capture\nlong-term dependency among embeddings in the embedding\nsequences. The proposed model uses reconstructions errors\nof both the V AE and the transformer for anomaly detection.\nThe reconstruction error of the transformer reflects the extent\nof data anomaly from the long-term perspective, whereas\nthe reconstruction error of V AE reflects the extent of data\nanomaly from the short-term perspective. The detailed archi-\ntecture of the proposed method as well as the training and\nanomaly detection methods are provided in Section III-B.\nA. DATA COLLECTION AND FEATURE EXTRACTION\nUsing diverse types of data plays a crucial role in anomaly\ndetection and improving detection accuracy. This principle\napplies to anomaly detection targeting Olympus DAO. Data\ndiversity helps detect anomalies in different scenarios or\npatterns; however, using an excessive amount of different\ndata types can also lead to problems. Excessive data diver-\nsity causes overfitting of the detection model and lowers\nthe detection accuracy for new data. High-dimensional data\ninduce the curse of dimensionality, which increases the com-\nputational amount and reduces the performance of the model.\nIf data types are too diverse, the quality of a specific data\ntype may be too poor or inconsistent, and this will lower\nthe accuracy of a model. Thus, an appropriate level of data\ndiversity should be maintained by selecting highly relevant\ndata for anomaly detection.\nThe types of data related to Olympus DAO include treasury\nbalance, OHM price, yield (APY), and OHM market capi-\ntalization. We focused on the flow of OHM tokens coming\ninto Olympus DAO from outside or those taken out externally\nas indicated by the solid red lines in Fig. 2. The proposed\nmodel monitors the following events and detects anoma-\nlies in Olympus DAO: an event where an external OHM\ntoken comes into Olympus DAO because of a user’s staking,\nan event where an OHM token owned by Olympus is taken\nout externally because of unstaking, an event where a new\nOHM token is minted because of bond creation, and an event\nwhere the OHM token is sent to external users because of\nbond redemption.\nTreasury balance and OHM market capitalization are\nclosely related to staking and bonding activities, and APY\nis changed based on the pre-determined policy according to\nthe total OHM supply. Therefore, closely observing the flow\nof OHM tokens enables changes in the Olympus DAO state\nto be identified, which in return, help detect anomalies. The\nOHM price is associated with the status of Olympus DAO;\nhowever, it is insufficient to detect an anomaly in Olympus\nDAO because the OHM price is highly volatile depending on\nthe overall cryptocurrency market atmosphere. Transactions\nand transfer activities between OHM token holders are not\nrelated to anomalies in Olympus DAO.\nFIGURE 2. Flow of OHM tokens based on user activity (solid red lines).\nIn addition to the simplified architecture of Olympus DAO, the flow of\nincoming/outgoing OHM tokens attributed to staking, unstaking, bond\ncreation, and bond redemption is shown in this figure. In the case of\nbond creation, a new OHM token is minted internally.\nWe collected the users’ staking, unstaking, bond cre-\nation, and bond redemption activities; these activities are\nperformed when transactions generated and propagated by\nusers are triggered. These transactions can be collected easily\nthrough transparency and integrity, which are advantages of a\nblockchain. However, unlike previous research on fraud and\nPonzi schemes in Bitcoin and Ethereum, it is difficult to grasp\nthe specific meaning of activities for DeFi such as Olympus\nDAO based only on the information of collected transac-\ntions. A user’s transaction becomes a starting point in DeFi\nprotocols. However, numerous complicated smart contracts\ninteract simultaneously, which requires a deep understanding\nof the relevant DeFi protocol. Furthermore, DeFi platforms\ngenerate and use their own custom tokens such as OHM\ntokens, and the transfer information of these tokens is not\nspecified in transactions unlike how the amount of trans-\nferred ETH is specified in the transactions. Therefore, the\nusers’ transactions, internal transactions among smart con-\ntracts invoked accordingly, and event logs generated as the\nresult were collected and analyzed to identify the specific\nmeaning of each action.\nTable 1 summarizes the number of transactions collected\nand analyzed by activity and number of related smart con-\ntracts. Olympus DAO has a relatively shorter active period;\nhowever, the several occurrences of updates and changes\ntook place during which new smart contracts were generated\nand used. Therefore, there are 3 versions of smart contracts\nfor staking, and 18 types of smart contracts for bonding.\nWe analyzed smart contract codes and the transactions sent to\nthese contracts for obtaining the OHM tokens transferred by\neach transaction. In this process, the list of transactions was\nobtained with the help of Etherscan, which is an Ethereum\nblock explorer, and Infura was used to obtain the details\nof transactions and corresponding receipts to be analyzed.\nAlgorithm 1 shows the pseudocode for obtaining redemption\nactivity information of OHM / DAI Bond V4. A total of\n98120 VOLUME 11, 2023\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nTABLE 1. Summary of collected and analyzed transactions.\nAlgorithm 1 Obtaining Redemption Activity Information of\nOHM/DAI Bond V4\nInput: addr ▷ contract address of OHM/DAI Bond V4\nOutput: R ▷ set of (transaction, OHM amount) pairs\n1: / * get transactions of the contract from Etherscan */\n2: TxList ← GetTxsFromAddress (addr )\n3: R ← ∅\n4: for all tx ∈ TxList do\n5: if tx.s tatus= error then continue\n6: end if\n7: if tx.m ethod is redeem then\n8: /∗ get receipt of tx via Infura * /\n9: receipt ← GetTxReceipt (tx )\n10: for all event ∈ receipt.logs do\n11: if event.name is BondRedeemed then\n12: / ∗ get OHM token amount inevent ∗ /\n13: amount ← GetOHMAmount (event)\n14: R ← R ∪ {(tx, amount)}\n15: end if\n16: end for\n17: end if\n18: end for\n19: return R\n459,451 transactions were analyzed, and the detailed infor-\nmation is provided in Appendix.\nWe collected and analyzed the data generated from March\n2021 to December 2022. Among them, the data from April\n2021 were used for anomaly detection because the Olympus\nDAO was started in March 2021 and the activity patterns\nin the very beginning differed from the normal patterns of\na later time. Only data up to April 2022 were used for the\nanomaly detection because bonding, which is one of the core\nideas of Olympus DAO, was terminated at the end of April\n2022 after its last transaction. Then, inverse bonding with an\nopposite concept of previous bonding was introduced, and\nit demonstrated completely different patterns from previous\nbonding activities. Therefore, we decided to exclude the data\nafter May 2022.\nThese time-series data were resampled by hour to extract\nfeatures to be used in the anomaly detection model. The\nfollowing features were extracted every hour for each staking,\nunstaking, bond creation, and bond redemption activity, and\na total of 12 features were obtained.\n• Amount of transferred OHM tokens: The amount of\nOHM tokens transferred from Olympus DAO to out-\nside or from outside into Olympus DAO in an hour.\n• Number of transactions: The number of transactions\ngenerated and normally executed by users’ activities in\nan hour.\n• Number of active users: The number of active users\nwho submitted new transactions in an hour is obtained\nby the number of unique addresses of the senders of\ntransactions generated during this period.\nB. ANOMALY VAE-TRANSFORMER\n1) OVERALL ARCHITECTURE\nThe proposed anomaly V AE-Transformer model combines\nV AE for extracting local information in the short term and\na transformer for identifying the dependency between data\nin the long term. Fig. 3 shows the overall architecture of the\nproposed model. The V AE model consists of an encoder and\na decoder. The V AE encoder encodes daily data (sequence\nof hourly data of 24 hours) among time series data into\nlow-dimensional embedding, and the V AE decoder receives\nthe output of the transformer as an input to reconstruct the\ndaily data. The transformer was designed by referring to the\nstandard transformer suggested in [31] and the informer sug-\ngested in [58]; it consists of three encoders which use stacked\nattention and feed-forward layers. The transformer receives\nthe encoding value of q non-overlapping daily data, and it\ngenerates q contextualized embeddings as an output, which\nis then transferred to the V AE decoder. The proposed model\ncalculates the anomaly score using the difference between the\noriginal and reconstructed data, and it is determined as an\nanomaly if the anomaly score exceeds the threshold.\nFor time series X = {x1, x2, . . . ,xN }, xt ∈ Rm repre-\nsents m-dimensional data observed at time t. In this study, xt\nrepresents hourly data at time t for m features of the DeFi\nprotocol extracted in Section III-A. Fig. 4 shows that this\nstudy applies the overlapped sliding window technique to\ntime-series X and generates daily data, or the sequence of\nhourly data of 24 h (window size p = 24), to be used as an\ninput. A total of (N − p + 1) daily data are generated from N\nhourly data, and the daily data at time t is expressed as dt =[\nxt , xt+1, . . . ,xt+p−1\n]\n. Therefore, xi, which is the hourly data\nat time i, is overlapped with p number of daily data, which\nneeds to be considered when calculating the anomaly score at\ntime i. (However, for xi where 1 ≤ i < por (N − p) < i ≤ N,\nthe number of overlapped daily data is less than p.)\n2) TRAINING THE ANOMALY VAE-TRANSFORMER\nThe proposed anomaly V AE-Transformer model is trained\nin an unsupervised method in which V AE is trained first\nfollowed by the transformer, which is trained using the pre-\nviously trained V AE.\nVOLUME 11, 2023 98121\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nFIGURE 3. Overall architecture of anomaly VAE-Transformer model.\nFIGURE 4. Generating daily data from the sequence of hourly data.\nFor training the V AE, the V AE encoder receives dt =[\nxt ,xt+1, . . . ,xt+p−1\n]\nwhere d t ∈ Rp×m, which is the daily\ndata at time t, and it encodes this data into low-dimensional\nembedding et .\net = VAE_Encoder(dt ), (1)\nwhere et ∈ Rk and k represents the latent space dimension.\nThe V AE decoder receives the V AE encoder’s output et as an\ninput, and it decodes this into reconstructed daily data ˆdt .\nˆdt = VAE_Decoder(et ), (2)\nwhere ˆdt ∈ Rp×m. For minimizing the reconstruction error or\nthe difference between the original daily data dt and recon-\nstructed daily data ˆdt , V AE is optimized using ELBO loss.\nFor V AE training, (N − p + 1) number of overlapped daily\ndata generated by time-series X = {x1, x2, . . . ,xN } are used.\nFor training, the transformer takes Et which is the value\nencoded from q non-overlapping daily data Dt by the V AE\nencoder as an input, and it generates q number of contextual-\nized embeddings as output Zt .\nDt =\n[\ndt , dt+p, dt+p×2, . . . ,dt+p×(q−1)\n]\n, (3)\nEt =\n[\net , et+p, et+p×2, . . . ,et+p×(q−1)\n]\n, (4)\nZt = Transformer (Et )\n=\n[\nzt\nt , zt\nt+p, zt\nt+p×2, . . . ,zt\nt+p×(q−1)\n]\n, (5)\nwhere Dt ∈ Rq×p×m, Et ∈ Rq×k , zt\ni ∈ Rk , Zt ∈ Rq×k , and\nthe transformer is optimized to minimize the reconstruction\nloss of Et and Zt . In this training, all sequences of the q non-\noverlapped daily data generated from time-series X are used.\n3) ANOMALY SCORE\nAfter training, the proposed model can detect anomalies.\nWhen time-series X = {x1, x2, . . . ,xN } where xt ∈ Rm is\ngiven, the anomaly score Si for xi at time t is calculated, and\nit is detected as an anomaly if this value exceeds the threshold\nθ.\nFor the given time-series X, the daily data at time t is\nexpressed as dt =\n[\nxt ,xt+1, . . . ,xt+p−1\n]\n, dt ∈ Rp×m. In our\nmodel, Dt , the sequence of q non-overlapping daily data\nstarting at time t is taken as an input.\nDt =\n[\ndt , dt+p, dt+p×2, . . . ,dt+p×(q−1)\n]\n, (6)\nwhere Dt ∈ Rq×p×m. The V AE encoder encodes q non-\noverlapping daily data separately, and delivers Et , which is\n98122 VOLUME 11, 2023\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\na set of q low-dimensional embeddings to the transformer.\net = VAE_Encoder(dt ), (7)\nEt =\n[\net , et+p, et+p×2, . . . ,et+p×(q−1)\n]\n, (8)\nwhere et ∈ Rk , Et ∈ Rq×k .\nThe transformer receives Et as an input and generates q\ncontextualized embeddings as a set of output Zt , which is then\ndelivered to the V AE decoder.\nZt = Transformer (Et )\n=\n[\nzt\nt , zt\nt+p, zt\nt+p×2, . . . ,zt\nt+p×(q−1)\n]\n, (9)\nwhere Zt ∈ Rq×k , zt\ni ∈ Rk .\nThe V AE decoder receives the transformer output Zt as an\ninput, and decodes q number of zt\ni separately; as a result, Ot ,\na set of q reconstructed daily data are generated.\not\ni = VAE_Decoder\n(\nzt\ni\n)\n=\n[\nˆxt\ni , ˆxt\ni+1, . . . ,ˆxt\ni+p−1\n]\n, (10)\nOt =\n[\not\nt , ot\nt+p, ot\nt+p×2, . . . ,ot\nt+p×(q−1)\n]\n, (11)\nwhere ot\ni ∈ Rp×m, Ot ∈ Rq×p×m. Here, ot\ni rep-\nresents the reconstructed daily data of di, which is\nthe daily data at time i among the sequence Dt =[\ndt , dt+p, dt+p×2, . . . ,dt+p×(q−1)\n]\n, which started at time t. ˆxt\ni\nrepresents the reconstructed hourly data at time i.\nLossHt\ni is calculated using the mean squared error (MSE)\nof the original hourly data xi and reconstructed hourly data\nˆxt\ni .\nLossHt\ni = MSE\n(\nxi, ˆxt\ni\n)\n. (12)\nAs explained above, since each hourly data xi is duplicated\nin the p daily data, the anomaly score Si at time i is obtained by\ncalculating the average of LossHt\ni where (i − p + 1) ≤ t ≤ i.\nSi = Average\n(\nLossHt\ni\n)\n= 1\np\n∑ i\nt=i−p+1 LossHt\ni . (13)\nFig. 5 shows the process of calculating the anomaly score;\nif this score exceeds a certain threshold, xi is judged as\nan anomaly. All steps of finding anomalies are depicted in\nAlgorithm 2.\nIV. EXPERIMENTS AND RESULTS\nA. IMPLEMENTATION AND EXPERIMENTS\nThe dataset used in the experiment and analysis was gen-\nerated through data collection and feature extraction, and it\nconsists of hourly data from 00:00 on April 1, 2021 to 24:00\non April 30, 2022. Each data has 12 features, and the total\nnumber of data is 9,480. This dataset was divided into two\ndatasets; the first one with 3,600 data until 24:00 on August\n28, 2021 was used for training, while the remaining 5,880\ndata were used for inference and analysis.\nUnsupervised learning is generally applied for anomaly\ndetection. Abnormal data are extremely rare compared to\nthe number of normal data, and therefore, it is extremely\nFIGURE 5. Process of computing the anomaly score from the output of\nthe anomaly VAE-Transformer.\nAlgorithm 2 Finding Anomaly in Time Series\nInput: X ▷ time series X = {x1, x2, · · ·, xN }\nOutput: Anomaly ▷ set of detected anomalies\n1: Anomaly ← ∅\n2: for t = 1 to N − pq + 1 do\n3: /* compose a sequence of daily data\n4: where dt =\n[\nxt , xt+1, · · ·, xt+p−1\n]\n*/\n5: Dt ←\n[\ndt , dt+p, · · ·, dt+p×(q−1)\n]\n6: /* get V AE embedding*/\n7: Et ← V AE_Encoder(Dt )\n8: /* get Transformer output*/\n9: Zt ← Transformer (Et )\n10: /* get reconstructed sequence of daily data\n11: Ot =\n[\not\nt , ot\nt+p, · · ·, ot\nt+p×(q−1)\n]\n12: where ot\ni =\n[\nˆxt\ni , ˆxt\ni+1, · · ·, ˆxt\ni+p−1\n]\n*/\n13: Ot ← V AE_Decoder(Zt )\n14: /* calluilate reconnstruction error */\n15: LossHt\ni ← MSE\n(\nxi, ˆxt\ni\n)\n∀i, t ≤ i < t + pq\n16: end for\n17: for i = 1 to N do\n18: /* calculate anomaly score at timei*/\n19: Si ← 1\np\n∑i\nt=i−p+1 Loss Ht\ni\n20: if Si > threshold then\n21: Anomaly ← Anomaly ∪{xi}\n22: end if\n23: end for\n24: return Anomaly\nchallenging to obtain enough labeled abnormal data. Fur-\nthermore, the patterns of anomaly vary significantly, and\nit is difficult to identify future patterns from the past pat-\nterns. Thus, unsupervised learning is suitable for learning\nthe patterns of normal data and for detecting the patterns of\nVOLUME 11, 2023 98123\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nFIGURE 6. Training loss and validation loss of VAE (dimension of latent\nspace = 64, size of hidden layers = [512, 512]).\nanomaly. We adopted unsupervised learning, and the training\nprocess of the proposed anomaly V AE-Transformer model\nwas divided into 1) V AE training and 2) transformer training\nusing the trained V AE.\nV AE is a generative model that can infer the generation\nfactors of training data and provide excellent anomaly detec-\ntion results for data within a short window. The V AE of the\nproposed model is implemented using the base version of\nTimeV AE [11], which is appropriate for handling the time-\nseries data. We used the V AE to encode the sequence of\nhourly data of a day (24 h) into low-dimensional embedding,\nand we performed decoding to reconstruct the data of one\nday from the transformer output into daily data. The training\nmethod of V AE is as follows.\nThe window size is set to 24 and 3,577 input windows\nare generated from 3,600 training data using the sliding\nwindow technique. After shuffling these windows, 20% of\nthe windows are used for validation, and the windows are\noptimized using the ELBO loss. Grid search is employed to\nfind the optimized values for the dimension of a latent space\nand the number of hidden layers in V AE. The grid for the\ndimension of a latent space is defined as [2, 4, 8, 16, 32,\n64, 128, 256, 512], and the grid for the number of layers is\ndefined as [1], [2], and [3]. Subsequently, after generating\nall possible combinations of these values, each combination\nis applied to train the model, and the results are evaluated.\nThe experiment is conducted by varying the dimension of\na latent space and the number of hidden layers in V AE;\nspecifically, the most outstanding performance is obtained\nwhen the dimension of the latent space is 64 and the number\nof hidden layers is 2. Fig. 6 shows the relevant losses, and\nFig. 7 shows the visualization result of arbitrarily selecting\nthree input windows and inputting them in the trained V AE\nto generate reconstructed output. The reconstructed output is\nhighly similar to the original data.\nThe transformer can help sequential data processing, and\nit has been widely useful for finding the long-range temporal\nFIGURE 7. Visualized comparison between the original and\nVAE-reconstructed data. Three arbitrary data are selected where the\nreconstructed data (bottom) is highly similar to the original data (top).\nTABLE 2. Hyperparameters of proposed Anomaly VAE-Transformer.\ndependency of time-series data. The transformer part of the\nproposed model is implemented based on the informer [58]\nand anomaly transformer [5] using the standard transformer\nprovided by PyTorch. In the proposed model, the data of\n28 days (approx. one month) are input in the transformer, and\nthe input data are composed of embeddings in the unit of days\ngenerated by the pre-trained V AE encoder. The transformer\nreconstructs the data of 28 days from this input and delivers\nthe data to the subsequent step.\nWe proceeded with the training as explained below to\nensure that the transformer adequately reconstructs the input.\nA total of 2,929 windows with a size of 672 were generated\nusing the sliding window technique from 3,600 training data.\nWindows with a size of 28 were newly generated by gathering\nembeddings created by inputting in the V AE encoder for\nevery 24 data in each window. 80% of the windows in the\nfront were used for training, while 20% the back were used for\nvalidation. Training was performed to minimize the MSE of\ninput data and reconstruct the data using Adam optimization.\nThe training process is stopped within 100 epochs with a\nbatch size of 16. Table 2 presents the hyperparameters used\nin the experiment.\n98124 VOLUME 11, 2023\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nTABLE 3. Elapsed time of each process in Anomaly VAE-Transformer.\nFIGURE 8. Anomaly score calculated for each time period (from 00:00 on\nAugust 29, 2021 to 24:00 on April 30, 2022; threshold = 32.3).\nThe experiments were conducted on a machine equipped\nwith Intel Core i7-12700F CPU and NVIDIA GeForce\nRTX 3060 GPU and 32GB DDR4 RAM. We measured the\ntime required for training both V AE and transformer, as well\nas the time taken for calculating anomaly scores using the\ntrained model. The results of system performance are sum-\nmarized in Table 3.\nB. ANALYSIS\nSometimes data without accurate labels or ground truth are\nanalyzed in the studies on anomaly detection. In such cases,\nit is difficult to use traditional performance indicators such\nas F1 score or confusion matrix. This limitation becomes\nmore prominent during anomaly detection in DeFi. In this\ncase, the detection performance of a model is proved through\nvarious case studies to determine the suitability of the model.\nTo the best of our knowledge, no anomaly detection case has\nbeen officially reported for Olympus DAO. Thus, this study\naims to prove through case studies that the proposed anomaly\nV AE-Transformer can successfully detect various abnormal\npatterns in the Olympus DAO.\nFor anomaly detection, the anomaly score is calculated for\nevery hour from 00:00 on August 29, 2021 to 24:00 on April\n30, 2022 using the trained anomaly V AE-Transformer. Fig. 8\nshows the anomaly score of each period, while Fig. 9 shows\nthe log scale of the distribution of anomaly score values.\nTABLE 4. Detected anomalies (in descending order of anomaly score).\nFIGURE 9. Log scale distribution of anomaly scores. Most normal data are\nclearly distinguished from certain anomaly data, and the threshold is 32.3.\nMost periods have low scores; however, certain periods have\nabnormal scores, which indicate that an anomaly has occurred\nin those periods. We set the threshold θ for distinguishing\nbetween normal and abnormal scores as 32.3 to allow the\nperiods with the top 0.1% scores to become an anomaly.\nTable 4 presents the detected anomaly periods. If the con-\ntinuous periods are combined (#1 and #6, #3 and #4), there\nare a total of five periods; the top four cases are analyzed to\nverify whether anomaly detection is properly executed.\nCase 1: Sudden increase in user activity (2022-04-20\n23:00–2022-04-21 01:00)\nFig. 10 shows the results of visualizing the changes in\n12 features in the detected (marked with red) and adjacent\nperiods. As shown in the figure, the staking, unstaking, and\nredemption activity of the OHM tokens varied significantly\nin the red-colored periods. In the case of staking and unstak-\ning, the numbers of active users and transactions suddenly\nincreased, which led to a significant increase in the token\namount. In terms of bond redemption, only one transaction\noccurred in the period; however, a substantially large trans-\naction amount of 59,000 OHM tokens was involved in the\nredemption process, which is very likely to be an abnor-\nmal transaction. Similarly, seven features showed significant\nchanges from adjacent values, and thus, this period received\nhigh anomaly score and it was detected as anomaly. Unfor-\ntunately, the reason for such an abnormal activity in this\nperiod remains unknown; however, this period was a few days\nVOLUME 11, 2023 98125\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nFIGURE 10. (Case 1) Graphs of 12 features in the detected anomaly period (2022-04-20 23:00∼2022-04-21 01:00) and adjacent periods. Red\nparts indicate anomaly. Features related to staking, unstaking, and bond redemption activities sharply increased.\nFIGURE 11. (Case 2) Graphs of 12 features in the detected anomaly period (2022-01-26 11:00 - 12:00) and adjacent periods. Red parts indicate\nanomaly. The amount of staked OHM tokens and unstaked OHM tokens significantly increased, but no noticeable changes occurred in other\nfeatures.\nbefore the inverse bond started, which is a notable change in\nOlympus DAO. The anticipation and anxiety stemming from\nrecent price drop and introduction of new inverse bond are\nassumed to have caused the anomaly.\n98126 VOLUME 11, 2023\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nFIGURE 12. (Case 3) Graphs of 12 features in the detected anomaly period (2022-10-15 04:00–06:00) and adjacent periods. Red parts\nindicate anomaly. Staking and unstaking activities sharply increased in which the number of transactions and unique addresses\n(number of active users) is particularly high. In contrast, bond creation and redemption activities are extremely low.\nFIGURE 13. (Case 4) Graphs of 12 features in the detected anomaly period (2022-04-28 09:00–10:00) and the adjacent periods. Red\nparts indicate an anomaly. User activity is extremely low.\nCase 2: Abnormal activity of a specific user (2022-01-26\n11:00–12:00)\nFig. 11 shows that other features did not fluctuate sig-\nnificantly in this period; however, the amounts of staked\nOHM tokens and unstaked OHM tokens increased consid-\nerably compared to the adjacent values. Despite a large\nincrease in the amount, the number of transactions and\nactive users did not vary noticeably, and therefore, it can be\ninferred that a small number of users executed staking and\nunstaking for OHM tokens on a large scale in this period.\nVOLUME 11, 2023 98127\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nTABLE 5. Description of Olympus DAO transactions collected.\nWe thoroughly investigated staking and unstaking transac-\ntions that occurred in this period, and we discovered one\nsuspicious transaction. A user with the Ethereum address 0 ×\n41339.9825963515 e5705df8d3b0ea98105ebb1c unstaked a\nlarge amount of 79844 OHM tokens and then immediately\nstaked them again. After a few minutes, the same amount of\nOHM tokens was unstaked and immediately staked again.\nRepeatedly executing unstaking and staking within a short\nperiod of time does not allow users to gain any benefit and\nonly causes losses from transaction fees, which raised sus-\npicion behind their actions. Such an action may be part of a\nmore complicated attack on DeFi which could be analyzed\nwith the timestamp attack model in [59], or an attempt to\nfind the vulnerability of the staking code, or a simple mistake\nof the user. The proposed model cannot identify the purpose\nof this action; however, it can detect the period in which\n98128 VOLUME 11, 2023\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nthis action has a high probability of abnormal transactions.\nThe effectiveness of this model was confirmed because the\ndetection result induces further investigation for preventing\nmore serious incidents.\nCase 3: Structural changes in Olympus DAO (2021-10-\n15 04:00–06:00)\nIn this period, activities related to staking and unstaking\nsignificantly increased, while those related to bond creation\nand redemption greatly decreased, as shown in Fig. 12.\nA notable aspect is that the number of staking and unstaking\ntransactions is extremely high; the value is the highest in the\nentire analysis dataset. This result indicates that the anomaly\nin this period was caused by a large number of normal users\naffected by a specific incident rather than by a small number\nof certain individuals. In this period, the Olympus DAO V2\nto which new governance and bonding policy are applied was\nannounced officially. The anticipation and anxiety for the new\nversion and a sudden increase in the OHM price caused active\nstaking and unstaking activities among normal users. Fur-\nthermore, previous bonding related activities were subsided\nbecause the significant changes in bonding were forecasted.\nAs shown here, the proposed model can adequately detect\nsudden anomalies of normal users arising from changes in\nthe Olympus DAO itself.\nCase 4: Extremely low user activity (2022-04-28 09:00–\n10:00)\nAs shown in Fig. 13, this period has very low activities\ncompared to those in other periods. The amount and trans-\naction number of staking and unstaking activities were both\nlower than those of the adjacent values. For bond creation,\nno new bonding activities were observed since 43 h before\nthis period. Unlike previous periods of active participation,\nlow activities increased the anomaly score in this period. Fur-\nther, one transaction with a noticeable amount of redemption\nraised the anomality of this period. This period experienced\na transition where the existing bond mechanism ended and a\nnew inverse bond mechanism started. Uncertainty about the\nfuture led users to restrain from participating in new activities.\nThe redemption of existing tokens occurred in preparation for\nterminating existing bond service, and new bonding activities\nwere not observed.\nThe analysis results showed that all four cases had a\nperiod in which an anomaly occurred, ultimately proving that\nthe proposed model can accurately detect anomaly periods.\nIn case 1, an anomaly period was successfully detected where\nmultiple features demonstrated sudden changes; in case 2, the\nanomaly of a specific user caused by malicious activities or\nmistakes was detected. In case 3, anomaly was detected when\nnumerous normal users intensively participated in activities\nbecause of the changes in the Olympus DAO. In contrast,\nin case 4, the anomaly of a stagnant state was detected in\nwhich the activities of normal users were decreased sub-\nstantially. These analysis results confirmed that the proposed\nanomaly V AE-Transformer model successfully detected var-\nious anomaly patterns, and it is a suitable model for anomaly\ndetection in the Olympus DAO.\nV. CONCLUSION\nThis study proposed a new methodology for anomaly detec-\ntion in DeFi. First, on-chain data of Olympus DAO, which is a\npopular DeFi protocol, were collected and analyzed to extract\n12 features that can identify the flow of OHM tokens. In addi-\ntion, we proposed a new deep learning model, the anomaly\nV AE-Transformer model, which consists of a transformer\nthat captures dependency between data in the long term, and\nV AE, which extracts local information in the short term. This\nmodel was used to perform anomaly detection in the Olympus\nDAO based on an actual dataset, and the four anomaly cases\nwith the highest anomaly scores in the detection results were\nanalyzed further to prove the effectiveness of the proposed\nmodel.\nDeFi has high technological complexity because of a com-\nplex protocol structure, interactions among various smart\ncontracts, and diverse token transactions, which has been\ncausing difficulty in performing anomaly detection. In partic-\nular, DeFi protocols such as Olympus DAO have extremely\nhigh volatility, which makes it difficult to monitor and man-\nage potential risks. The proposed method overcomes such\nlimitations and enables anomaly detection to be conducted\neffectively. The proposed method helps not only the gover-\nnance of DeFi but also general users participating in DeFi.\nFrom the perspective of DeFi governance, anomaly detec-\ntion can be considered an opportunity to find errors or the\nvulnerability of the DeFi protocol and to identify malicious\nattack attempts of an attacker. From the perspective of gen-\neral users, anomaly detection can help promptly recognize\nimportant structural changes of the DeFi protocol they are\nparticipating in, changes in user trends, and sudden issues.\nThese advantages can help the stakeholders make decisions\nbased on relevant information. In addition, anomaly detection\nusing the proposed method protects users’ assets, raises the\ntransparency of the DeFi market, and provides trust required\nfor new investors and enterprises to participate in the DeFi\necosystem. Thus, this study is expected to contribute to pro-\nmoting the development of the DeFi market.\nThe suggested method is applicable to Olympus DAO, but\nit can also be applied to other DeFi protocols through slight\nmodifications. However, the expansion and application of\nthe proposed method cannot be easily automated and require\nassistance of experts. The data collection and extraction of\nappropriate features is the most difficult to automate because\nDeFi protocols have their own unique concept and architec-\nture. In future studies, latest machine learning techniques will\nbe researched to overcome the abovementioned limitations,\nand new methods will be explored to easily automate the\nproposed method for various DeFi protocols.\nAPPENDIX\nCOLLECTED TRANSACTION DATA\nIn our study, we collected transaction data pertaining to user\nactivities such as staking, unstaking, bond creation, and bond\nredemption to train and analyze the anomaly detection model.\nAs can be observed in Table 5, these transactions amounted\nVOLUME 11, 2023 98129\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\nto a total of 459,451 instances across 21 smart contracts. The\nfragmentation, as a result of supporting bonding with vari-\nous cryptocurrencies like DAI, necessitated numerous smart\ncontracts. Further, with every upgrade, due to the inherent\nnature of blockchain technology, new versions of smart con-\ntracts were deployed for use. Utilizing block explorers like\nEtherscan, transactions related to the specific smart contract\naddresses mentioned in Table 5 can be observed.\nREFERENCES\n[1] DeFiLlama. DeFi Total Value Locked(TVL). Accessed: May 20, 2023.\n[Online]. Available: https://defillama.com/\n[2] S. Schmidl, P. Wenig, and T. Papenbrock, ‘‘Anomaly detection in time\nseries: A comprehensive evaluation,’’ Proc. VLDB Endowment, vol. 15,\nno. 9, pp. 1779–1797, May 2022.\n[3] G. Pang, C. Shen, L. Cao, and A. V . D. Hengel, ‘‘Deep learning for anomaly\ndetection: A review,’’ ACM Comput. Surv., vol. 54, no. 2, pp. 1–38,\nMar. 2021.\n[4] K. Choi, J. Yi, C. Park, and S. Yoon, ‘‘Deep learning for anomaly detection\nin time-series data: Review, analysis, and guidelines,’’ IEEE Access, vol. 9,\npp. 120043–120065, 2021.\n[5] J. Xu, H. Wu, J. Wang, and M. Long, ‘‘Anomaly transformer:\nTime series anomaly detection with association discrepancy,’’ 2021,\narXiv:2110.02642.\n[6] Z. Chen, D. Chen, X. Zhang, Z. Yuan, and X. Cheng, ‘‘Learning graph\nstructures with transformer for multivariate time-series anomaly detection\nin IoT,’’IEEE Internet Things J., vol. 9, no. 12, pp. 9179–9189, Jun. 2021.\n[7] X. Wang, D. Pi, X. Zhang, H. Liu, and C. Guo, ‘‘Variational transformer-\nbased anomaly detection approach for multivariate time series,’’ Measure-\nment, vol. 191, Mar. 2022, Art. no. 110791.\n[8] S. Lin, R. Clark, R. Birke, S. Schönborn, N. Trigoni, and S. Roberts,\n‘‘Anomaly detection for time series using V AE-LSTM hybrid model,’’\nin Proc. IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP),\nMay 2020, pp. 4322–4326.\n[9] D. Park, Y . Hoshi, and C. C. Kemp, ‘‘A multimodal anomaly detector\nfor robot-assisted feeding using an LSTM-based variational autoencoder,’’\nIEEE Robot. Autom. Lett., vol. 3, no. 3, pp. 1544–1551, Jul. 2018.\n[10] Z. Li, Y . Zhao, J. Han, Y . Su, R. Jiao, X. Wen, and D. Pei, ‘‘Multivariate\ntime series anomaly detection and interpretation using hierarchical inter-\nmetric and temporal embedding,’’ in Proc. 27th ACM SIGKDD Conf.\nKnowl. Discovery Data Mining, Aug. 2021, pp. 3220–3230.\n[11] A. Desai, C. Freeman, Z. Wang, and I. Beaver, ‘‘TimeV AE: A vari-\national auto-encoder for multivariate time series generation,’’ 2021,\narXiv:2111.08095.\n[12] X. Wang, Y . Du, S. Lin, P. Cui, Y . Shen, and Y . Yang, ‘‘adV AE: A self-\nadversarial variational autoencoder with Gaussian anomaly prior knowl-\nedge for anomaly detection,’’ Knowl.-Based Syst., vol. 190, Feb. 2020,\nArt. no. 105187.\n[13] M. U. Hassan, M. H. Rehmani, and J. Chen, ‘‘Anomaly detection in\nblockchain networks: A comprehensive survey,’’ IEEE Commun. Surveys\nTuts., vol. 25, no. 1, pp. 289–318, 1st Quart., 2023.\n[14] T. Pham and S. Lee, ‘‘Anomaly detection in Bitcoin network using unsu-\npervised learning methods,’’ 2016, arXiv:1611.03941.\n[15] C. Yan, C. Zhang, Z. Lu, Z. Wang, Y . Liu, and B. Liu, ‘‘Blockchain\nabnormal behavior awareness methods: A survey,’’ Cybersecurity, vol. 5,\nno. 1, p. 5, Dec. 2022.\n[16] M. Bartoletti, S. Carta, T. Cimoli, and R. Saia, ‘‘Dissecting Ponzi schemes\non Ethereum: Identification, analysis, and impact,’’ Future Gener. Comput.\nSyst., vol. 102, pp. 259–277, Jan. 2020.\n[17] Y . Zhang, W. Yu, Z. Li, S. Raza, and H. Cao, ‘‘Detecting Ethereum\nPonzi schemes based on improved LightGBM algorithm,’’ IEEE Trans.\nComputat. Social Syst., vol. 9, no. 2, pp. 624–637, Apr. 2022.\n[18] W. Chen, Z. Zheng, J. Cui, E. Ngai, P. Zheng, and Y . Zhou, ‘‘Detecting\nPonzi schemes on Ethereum: Towards healthier blockchain technology,’’\nin Proc. World Wide Web Conf., 2018, pp. 1409–1418.\n[19] M. Bartoletti, B. Pes, and S. Serusi, ‘‘Data mining for detecting Bit-\ncoin Ponzi schemes,’’ in Proc. Crypto Valley Conf. Blockchain Technol.\n(CVCBT), Jun. 2018, pp. 75–84.\n[20] W. Chen, Z. Zheng, E. C.-H. Ngai, P. Zheng, and Y . Zhou, ‘‘Exploit-\ning blockchain data to detect smart Ponzi schemes on Ethereum,’’ IEEE\nAccess, vol. 7, pp. 37575–37586, 2019.\n[21] E. Jung, M. Le Tilly, A. Gehani, and Y . Ge, ‘‘Data mining-based Ethereum\nfraud detection,’’ in Proc. IEEE Int. Conf. Blockchain (Blockchain),\nJul. 2019, pp. 266–273.\n[22] K. Toyoda, T. Ohtsuki, and P. T. Mathiopoulos, ‘‘Identification of high\nyielding investment programs in Bitcoin via transactions pattern analysis,’’\nin Proc. IEEE Global Commun. Conf., Dec. 2017, pp. 1–6.\n[23] L. Su, X. Shen, X. Liao, X. F. Wang, and L. Xing, ‘‘Evil under the\nsun: Understanding and discovering attacks on Ethereum decentralized\napplications,’’ in Proc. USENIX Secur. Symp., 2021, pp. 1307–1324.\n[24] S. Farrugia, J. Ellul, and G. Azzopardi, ‘‘Detection of illicit accounts\nover the Ethereum blockchain,’’ Exp. Syst. Appl., vol. 150, Jul. 2020,\nArt. no. 113318.\n[25] M. Ostapowicz and K. Żbikowski, ‘‘Detecting fraudulent accounts\non blockchain: A supervised approach,’’ in Web Information Systems\nEngineering—WISE 2019. Hong Kong: Springer, Jan. 2019, pp. 18–31.\n[26] M. Bhowmik, T. S. S. Chandana, and B. Rudra, ‘‘Comparative study of\nmachine learning algorithms for fraud detection in blockchain,’’ in Proc.\n5th Int. Conf. Comput. Methodologies Commun. (ICCMC) , Apr. 2021,\npp. 539–541.\n[27] P. N. Sureshbhai, P. Bhattacharya, and S. Tanwar, ‘‘KaRuNa: A blockchain-\nbased sentiment analysis framework for fraud cryptocurrency schemes,’’ in\nProc. IEEE Int. Conf. Commun. Workshops (ICC Workshops), Jun. 2020,\npp. 1–6.\n[28] N. Dhieb, H. Ghazzai, H. Besbes, and Y . Massoud, ‘‘A secure AI-driven\narchitecture for automated insurance systems: Fraud detection and risk\nmeasurement,’’IEEE Access, vol. 8, pp. 58546–58558, 2020.\n[29] C. Lee, S. Maharjan, K. Ko, and J. W.-K. Hong, ‘‘Toward detect-\ning illegal transactions on Bitcoin using machine-learning methods,’’\nin Blockchain and Trustworthy Systems. Guangzhou, China: Springer,\nDec. 2020, pp. 520–533.\n[30] D. P. Kingma and M. Welling, ‘‘Auto-encoding variational Bayes,’’ 2013,\narXiv:1312.6114.\n[31] A. Vaswani, N. Shazeer, N. Parmar, and J. Uszkoreit, ‘‘Attention is all you\nneed,’’ in Proc. Adv. Neural Inf. Process. Syst., vol. 30, 2017, pp. 1–11.\n[32] V . Chandola, A. Banerjee, and V . Kumar, ‘‘Anomaly detection: A survey,’’\nACM Comput. Surv., vol. 41, no. 3, pp. 1–58, Jul. 2009.\n[33] A. Blázquez-García, A. Conde, U. Mori, and J. A. Lozano, ‘‘A review\non outlier/anomaly detection in time series data,’’ ACM Comput. Surveys,\nvol. 54, no. 3, pp. 1–33, Apr. 2022.\n[34] W. Yu, W. Cheng, C. C. Aggarwal, K. Zhang, H. Chen, and W. Wang,\n‘‘NetWalk: A flexible deep embedding approach for anomaly detection\nin dynamic networks,’’ in Proc. 24th ACM SIGKDD Int. Conf. Knowl.\nDiscovery Data Mining, Jul. 2018, pp. 2672–2681.\n[35] D. Xu, E. Ricci, Y . Yan, J. Song, and N. Sebe, ‘‘Learning deep represen-\ntations of appearance and motion for anomalous event detection,’’ 2015,\narXiv:1510.01553.\n[36] R. T. Ionescu, F. S. Khan, M.-I. Georgescu, and L. Shao, ‘‘Object-centric\nauto-encoders and dummy anomalies for abnormal event detection in\nvideo,’’ in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR),\nJun. 2019, pp. 7834–7843.\n[37] W. Sultani, C. Chen, and M. Shah, ‘‘Real-world anomaly detection in\nsurveillance videos,’’ in Proc. IEEE/CVF Conf. Comput. Vis. Pattern\nRecognit., Jun. 2018, pp. 6479–6488.\n[38] G. Pang, C. Yan, C. Shen, A. van den Hengel, and X. Bai, ‘‘Self-trained\ndeep ordinal regression for end-to-end video anomaly detection,’’ in Proc.\nIEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2020,\npp. 12170–12179.\n[39] M.-H. Oh and G. Iyengar, ‘‘Sequential anomaly detection using inverse\nreinforcement learning,’’ in Proc. 25th ACM SIGKDD Int. Conf. Knowl.\nDiscovery Data Mining, Jul. 2019, pp. 1480–1490.\n[40] C. Zhang, ‘‘A deep neural network for unsupervised anomaly detection and\ndiagnosis in multivariate time series data,’’ in Proc. AAAI. Artif. Intell.,\nvol. 33, no. 1, 2019, pp. 1409–1416.\n[41] W. Lu, Y . Cheng, C. Xiao, S. Chang, S. Huang, B. Liang, and T. Huang,\n‘‘Unsupervised sequential outlier detection with deep architectures,’’ IEEE\nTrans. Image Process., vol. 26, no. 9, pp. 4321–4330, Sep. 2017.\n[42] T. Schlegl, P. Seeböck, S. M. Waldstein, U. Schmidt-Erfurth, and G. Langs,\n‘‘Unsupervised anomaly detection with generative adversarial networks to\nguide marker discovery,’’ in Information Processing in Medical Imaging.\nBoone, NC, USA: Springer, Jun. 2017, pp. 146–157.\n98130 VOLUME 11, 2023\nA. Song et al.: Anomaly VAE-Transformer: A Deep Learning Approach for Anomaly Detection in DeFi\n[43] J. Donahue, P. Krähenbühl, and T. Darrell, ‘‘Adversarial feature learning,’’\n2016, arXiv:1605.09782.\n[44] X. Xia, X. Pan, N. Li, X. He, L. Ma, X. Zhang, and N. Ding, ‘‘GAN-based\nanomaly detection: A review,’’ Neurocomputing, vol. 493, pp. 497–535,\nJul. 2022.\n[45] M. Munir, S. A. Siddiqui, A. Dengel, and S. Ahmed, ‘‘DeepAnT: A deep\nlearning approach for unsupervised anomaly detection in time series,’’\nIEEE Access, vol. 7, pp. 1991–2005, 2019.\n[46] W. Liu, W. Luo, D. Lian, and S. Gao, ‘‘Future frame prediction for\nanomaly detection—A new baseline,’’ in Proc. IEEE/CVF Conf. Comput.\nVis. Pattern Recognit., Jun. 2018, pp. 6536–6545.\n[47] M. Ye, X. Peng, W. Gan, W. Wu, and Y . Qiao, ‘‘AnoPCN: Video anomaly\ndetection via deep predictive coding network,’’ in Proc. 27th ACM Int.\nConf. Multimedia, Oct. 2019, pp. 1805–1813.\n[48] J. Audibert, P. Michiardi, F. Guyard, S. Marti, and M. A. Zuluaga, ‘‘USAD:\nUnsupervised anomaly detection on multivariate time series,’’ in Proc.\n26th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2020,\npp. 3395–3404.\n[49] P. Zheng, S. Yuan, X. Wu, J. Li, and A. Lu, ‘‘One-class adversarial nets\nfor fraud detection,’’ in Proc. AAAI Conf. Artif. Intell., vol. 33, no. 1, 2019,\npp. 1286–1293.\n[50] A. Pollastro, G. Testa, A. Bilotta, and R. Prevete, ‘‘Semi-supervised detec-\ntion of structural damage using variational autoencoder and a one-class\nsupport vector machine,’’ IEEE Access, vol. 11, pp. 67098–67112, 2023.\n[51] A.-H. Shin, S. T. Kim, and G.-M. Park, ‘‘Time series anomaly detection\nusing transformer-based GAN with two-step masking,’’ IEEE Access,\nvol. 11, pp. 74035–74047, 2023.\n[52] F. Zeng, M. Chen, C. Qian, Y . Wang, Y . Zhou, and W. Tang, ‘‘Multivari-\nate time series anomaly detection with adversarial transformer architec-\nture in the Internet of Things,’’ Future Gener. Comput. Syst., vol. 144,\npp. 244–255, Jul. 2023.\n[53] P. Malhotra, L. Vig, G. Shroff, and P. Agarwal, ‘‘Long short term memory\nnetworks for anomaly detection in time series,’’ in Proc. ESANN, 2015,\np. 89.\n[54] H. Zhao, Y . Wang, J. Duan, C. Huang, D. Cao, Y . Tong, B. Xu, J. Bai,\nJ. Tong, and Q. Zhang, ‘‘Multivariate time-series anomaly detection via\ngraph attention network,’’ in Proc. IEEE Int. Conf. Data Mining (ICDM),\nNov. 2020, pp. 841–850.\n[55] L. Shen, L. Zhuocong, and J. Kwok, ‘‘Timeseries anomaly detection\nusing temporal hierarchical one-class network,’’ in Proc. Adv. Neural Inf.\nProcess. Syst., vol. 33, 2020, pp. 13016–13026.\n[56] H. Song, Z. Jiang, A. Men, and B. Yang, ‘‘A hybrid semi-supervised\nanomaly detection model for high-dimensional data,’’ Comput. Intell. Neu-\nrosci., vol. 2017, pp. 1–9, Mar. 2017.\n[57] J. Liu, H. Zhu, Y . Liu, H. Wu, Y . Lan, and X. Zhang, ‘‘Anomaly detec-\ntion for time series using temporal convolutional networks and Gaus-\nsian mixture model,’’ J. Phys., Conf. Ser., vol. 1187, no. 4, Apr. 2019,\nArt. no. 042111.\n[58] H. Zhou, S. Zhang, J. Peng, S. Zhang, J. Li, H. Xiong, and W. Zhang,\n‘‘Informer: Beyond efficient transformer for long sequence time-series\nforecasting,’’ in Proc. AAAI Conf. Artif. Intell., vol. 35, no. 12, 2021,\npp. 11106–11115.\n[59] X. Yang, S. Wang, F. Li, Y . Zhang, W. Yan, F. Gai, B. Yu, L. Feng, Q. Gao,\nand Y . Li, ‘‘Ubiquitous verification in centralized ledger database,’’ in\nProc. IEEE 38th Int. Conf. Data Eng. (ICDE), May 2022, pp. 1808–1821.\nAHYUN SONG received the M.S. degree in\ncomputer science from KAIST, South Korea,\nin 2005. She is currently pursuing the Ph.D.\ndegree in computer science and engineering with\nSungkyunkwan University. From 2005 to 2015,\nshe was the Manager with the Korea Finan-\ncial Telecommunications and Clearings Institute.\nSince 2015, she has been a Senior Manager\nwith the Financial Security Institute, South Korea.\nHer major research interests include security,\nblockchain, and DeFi.\nEUISEONG SEO (Member, IEEE) received the\nB.S., M.S., and Ph.D. degrees in computer sci-\nence from the Korea Advanced Institute of Sci-\nence and Technology (KAIST), in 2000, 2002,\nand 2007, respectively. He is currently a Pro-\nfessor with the Department of Computer Sci-\nence and Engineering, Sungkyunkwan University,\nSouth Korea. Before joining Sungkyunkwan Uni-\nversity in 2012, he was an Assistant Professor with\nthe Ulsan National Institute of Science and Tech-\nnology (UNIST), South Korea, from 2009 to 2012, and a Research Associate\nwith Pennsylvania State University, from 2007 to 2009. His research interests\nare system software, embedded systems, and cloud computing.\nHEEYOUL KIM received the B.E., M.S., and\nPh.D. degrees in computer science from KAIST,\nSouth Korea, in 2000, 2002, and 2007, respec-\ntively. From 2007 to 2008, he was with Samsung\nElectronics as a Senior Engineer. Since 2009,\nhe has been a Faculty Member with the Depart-\nment of Computer Science, Kyonggi University.\nHis major research interests include cryptography,\nsecurity, and blockchain.\nVOLUME 11, 2023 98131",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7307920455932617
    },
    {
      "name": "Autoencoder",
      "score": 0.7214943170547485
    },
    {
      "name": "Anomaly detection",
      "score": 0.7126883268356323
    },
    {
      "name": "Deep learning",
      "score": 0.6365203857421875
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5364686846733093
    },
    {
      "name": "Anomaly (physics)",
      "score": 0.5011827945709229
    },
    {
      "name": "Machine learning",
      "score": 0.42287886142730713
    },
    {
      "name": "Transformer",
      "score": 0.41812950372695923
    },
    {
      "name": "Data mining",
      "score": 0.36338144540786743
    },
    {
      "name": "Engineering",
      "score": 0.09558737277984619
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Condensed matter physics",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I848706",
      "name": "Sungkyunkwan University",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I28615091",
      "name": "Kyonggi University",
      "country": "KR"
    }
  ],
  "cited_by": 22
}