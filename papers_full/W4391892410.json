{
  "title": "Toward Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal Cross- and Self-Attention Large Language Model Approach",
  "url": "https://openalex.org/W4391892410",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2395601999",
      "name": "Jingda Yang",
      "affiliations": [
        "Stevens Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2095887118",
      "name": "Ying Wang",
      "affiliations": [
        "Stevens Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4312357424",
    "https://openalex.org/W2029693536",
    "https://openalex.org/W6605984345",
    "https://openalex.org/W4393137439",
    "https://openalex.org/W4390603514",
    "https://openalex.org/W6853837529",
    "https://openalex.org/W4384521943",
    "https://openalex.org/W6855873652",
    "https://openalex.org/W6855688163",
    "https://openalex.org/W6691329670",
    "https://openalex.org/W2963794306",
    "https://openalex.org/W2964223283",
    "https://openalex.org/W6839151939",
    "https://openalex.org/W6846626714",
    "https://openalex.org/W6852775702",
    "https://openalex.org/W4388886073",
    "https://openalex.org/W6855355790",
    "https://openalex.org/W4385572722",
    "https://openalex.org/W4301020594",
    "https://openalex.org/W4200248513",
    "https://openalex.org/W6854490134",
    "https://openalex.org/W6854517035",
    "https://openalex.org/W4384157987",
    "https://openalex.org/W1514607493",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4281663895",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4385681252",
    "https://openalex.org/W4394628733",
    "https://openalex.org/W4386875652",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4392122658",
    "https://openalex.org/W4382320007",
    "https://openalex.org/W4378473878",
    "https://openalex.org/W4384263581",
    "https://openalex.org/W4302305823"
  ],
  "abstract": "This paper introduces Auto-modeling of Formal Verification with Real-world Prompting for 5G and NextG protocols (AVRE), a novel system designed for the formal verification of Next Generation (NextG) communication protocols, addressing the increasing complexity and scalability challenges in network protocol design and verification. Utilizing Large Language Models (LLMs), AVRE transforms protocol descriptions into dependency graphs and formal models, efficiently resolving ambiguities and capturing design intent. The system integrates a transformer model with LLMs to autonomously establish quantifiable dependency relationships through cross- and self-attention mechanisms. Enhanced by iterative feedback from the HyFuzz experimental platform, AVRE significantly advances the accuracy and relevance of formal verification in complex communication protocols, offering a groundbreaking approach to validating sophisticated communication systems. We compare CAL&#x2019;s performance with state-of-the-art LLM-based models and traditional time sequence models, demonstrating its superiority in accuracy and robustness, achieving an accuracy of 95.94&#x0025; and an AUC of 0.98. This NLP-based approach enables, for the first time, the creation of exploits directly from design documents, making remarkable progress in scalable system verification and validation.",
  "full_text": "Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.\nDigital Object Identifier 10.1 109/ACCESS.2023.0322000\nTowards Auto-Modeling of Formal Verification\nfor NextG Protocols: A Multimodal cross- and\nself-attention Large Language Model Approach\nJINGDA YANG1, (Student Member,IEEE), and YING WANG2, (Member,IEEE)\n1School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, USA (e-mail: jyang76@stevens.edu)\n2School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, USA (e-mail: ywang6@stevens.edu)\nCorresponding author: Ying Wang (e-mail: ywang6@stevens.edu).\nThis effort was sponsored by the Defense Advanced Research Project Agency (DARPA) under grant no. D22AP00144. The views and\nconclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or\nendorsements, either expressed or implied, of DARPA or the U.S. Government.\nABSTRACT\nThis paper introduces Auto-modeling of Formal Verification with Real-world Prompting for 5G and\nNextG protocols (A VRE), a novel system designed for the formal verification of Next Generation (NextG)\ncommunication protocols, addressing the increasing complexity and scalability challenges in network\nprotocol design and verification. Utilizing Large Language Models (LLMs), A VRE transforms protocol\ndescriptions into dependency graphs and formal models, efficiently resolving ambiguities and capturing\ndesign intent. The system integrates a transformer model with LLMs to autonomously establish quantifiable\ndependency relationships through cross- and self-attention mechanisms. Enhanced by iterative feedback\nfrom the HyFuzz experimental platform, A VRE significantly advances the accuracy and relevance of\nformal verification in complex communication protocols, offering a groundbreaking approach to validating\nsophisticated communication systems. We compare CAL’s performance with state-of-the-art LLM-based\nmodels and traditional time sequence models, demonstrating its superiority in accuracy and robustness,\nachieving an accuracy of 95.94% and an AUC of 0.98. This NLP-based approach enables, for the first time,\nthe creation of exploits directly from design documents, making remarkable progress in scalable system\nverification and validation.\nINDEX TERMS Formal verification, cross-attention, self-attention, natural language protocol, formal flow\ngraph\nI. INTRODUCTION\nThe third generation partnership project (3GPP) published its\nRelease 17 (Rel-17) specifications at the end of the first quar-\nter of 2022 [1]. Since then, parallel and subsequent releases\nhave been rolled out to enhance and address new and unful-\nfilled requirements from previous releases. It ensures ongoing\ninnovation and improvement in mobile communication tech-\nnologies, aligning with the evolving needs and advancements\nin the field. 3GPP protocols consist of a multitude of technical\nspecifications and documents that cover various aspects of\nmobile communication networks, including radio access, core\nnetwork, and service capabilities. Encompassing a wide array\nof technical specifications, 3GPP protocols are extensive,\nwith documents like the Radio Resource Control (RRC) in\nRelease 17 spanning over a thousand pages [2]. The extensive\nnature of these documents, coupled with their distributed\nsecurity protocols, renders manual verification and testing\nboth time-intensive and susceptible to error. This complexity\nescalates in future network generations, exacerbating the risk\nof zero-day vulnerabilities.\nFurthermore, the incorporation of O-RAN and network\nfunction virtualization introduces additional layers of com-\nplexity and potential attack vectors through cloud APIs into\n5G and future G infrastructure [3]. These advancements offer\nenhanced functionality but expose operators to novel security\nchallenges, especially in the relatively uncharted territory\nof cloud security. This complexity, compounded by the in-\nvolvement of various entities in development, heightens the\nrisk of security breaches, particularly through misconfigured\ncontainers and exposed APIs.\nThus, in 5G and future G systems and networks, logical\nattacks exploiting protocol logic errors represent a significant\nVOLUME 11, 2023 1\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3366803\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJ. Yanget al.: Towards Auto-Modeling of Formal Verification for NextG Protocols\nvulnerability category. These attacks are challenging to detect\ndue to the scale and complexity of the network systems.\nFormal verification encompasses a broad range of techniques\nused to prove or disprove the correctness of algorithms, pro-\ntocols, systems, or software with respect to certain formal\nspecifications. It also involves mathematical analysis to en-\nsure that a system behaves as intended. Utilizing the Dolev-\nYao (DY) formal attack model [4], [5], one of the widely\nadopted methodologies, formal verification has demonstrated\nits effectiveness in identifying flaws in infrastructure and\ncommunication protocols. However, this approach is limited\nto abstract specifications, and, as of now, the full automation\nof protocol verification and validation of their implementa-\ntions remains beyond the reach of current technologies [6],\n[7].\nWith the recent advancements in Large Language Models\n(LLMs), an intriguing question emerges: Can LLMs con-\ntribute to accelerating the design and verification of large-\nscale protocols, and can they be effectively integrated with\nsystem validation processes that involve existing implemen-\ntations?\nTo answer this question, two crucial conditions must be\naddressed: clarifying ambiguities and capturing design inten-\ntions. The first condition involves resolving the conflict be-\ntween the ambiguity inherent in natural language processing\nand the need for explicitness in formal verification modeling.\nResolving this conflict is essential to demonstrate the poten-\ntial to provide measurable and verifiable trustworthiness. The\nsecond condition requires differentiating intentional relation-\nships or dependencies from unintentional ones identified by\nLLMs in targeting protocol designs. The differentiation is\ncrucial in transforming the design-intended relationships into\nmathematical and logical expressions in formal verification.\nIn the past several months, both academic and industry sec-\ntors have increasingly focused on applying LLMs in the realm\nof formal verification. Two major areas of this application\nare using prompt engineering and LLMs for hardware asser-\ntion [8]–[10] and software system Bounded Model Check-\ning (BMC) [8], [9]. To our knowledge, no published work\nyet explores the use of LLMs in verifying communication-\nrelated protocols and specifications, especially for the large\nand complex protocols of 3GPP releases. One of the reasons\nis due to a common challenge in existing research is capturing\ntrustworthy design intent in a set of assertions for use in\nformal verification or testing-based checking. This challenge\nintensifies as system distribution and complexity increase in\nthe case of 5G and the future G, particularly when intertwined\nwith a broad spectrum of various usage scenarios and verti-\ncals. The iterative prompts to the LLMs has limitations due\nto the complex and broad dependencies among identifiers,\ncommands, and properties.\nFurther more, our previous work on non-LLM-based\nNLP approach for 5G and other communication protocols\n[11] marked a significant shift from manual to automated,\naccuracy-focused analysis in translating natural language ori-\nented protocols into formal models. While it revealed limita-\ntions in handling complex semantic relationships with strong\ncontextual control, it also highlighted the potential and di-\nrection for LLM-based NLP in formal modeling. We found\nthis approach becomes particularly promising in detecting\ndesign intentions with greater intelligence and enhancing\ntrustworthiness through its connection to learn from real-\nworld experiments [12].\nIn this paper, we introduce a novel approach, named Auto-\nmodeling of Formal Verification with Real-world Prompting\nfor 5G and NextG protocols (A VRE), which addresses the\nneed for scalable formal verification in the domains of 5G and\nNextG. A VRE uses LLMs to clarify ambiguities and capture\ndesign intent, transforming protocol descriptions into depen-\ndency graphs and formal models. Our method differs from\nexisting techniques by integrating a transformer model with\nthe LLM, allowing quantifiable dependency relationships to\nbe generated under supervision and enabling transformative\nlearning without human involvement. This system, enhanced\nby iterative feedback from an experimental platform: Hy-\nFuzz [12], fills a research gap by combining experience-based\nand logical dependency analyses in protocol documentation,\nthereby significantly improving the accuracy and relevance of\nformal verification in complex communication protocols.\nA. RELATED WORK\nConverting Informal Natural Language System Designs\nand Protocols to Formal Description : Approaches to trans-\nforming natural language descriptions into formal mod-\nels have seen considerable advancements, evolving through\nthe introduction of diverse methodologies over the years.\nA decade ago, Drechsler et al. [13] proposed a paradigm\nthat incorporated the Formal Specification Level (FSL),\nadeptly bridging the gap between informal textbook speci-\nfications and formal Electronic System Level (ESL) inter-\npretations. Subsequently, Banarescu et al. [14] proposed a\nhybrid methodology that converted linguistic expressions into\nformal paradigms by merging symbolic and statistical tech-\nniques. With the advent of deep learning, Dong and Lapata\n[15] employed neural networks to convert natural language\ninstructions into executable codes. This work was further en-\nhanced by the contributions of Reddy et al. [16] in 2019, who\nfocused on semantic parsing, utilizing denotations to trans-\nform complex linguistic structures into formalized notations.\nMeanwhile, the application of regular expressions has been\nidentified as a viable means to extract formal specifications\nfrom natural language narratives, providing advanced com-\nponents in deep learning frameworks [17]. Despite these de-\nvelopments, models based on these previous methodologies\nhave achieved an accuracy threshold of approximately 90%,\nwhich is inadequate for ensuring complete recall. This poses\na challenge in the precise conversion of natural language\nprotocols into formal formulations.\nLLMs Based Formal Verification : LLMs have demon-\nstrated impressive reasoning and assertion capabilities for\nformal verification [9], [18], [19]. Research in [8], [9] has\nexplored using LLMs to generate temporal logic specifi-\n2 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3366803\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJ. Yanget al.: Towards Auto-Modeling of Formal Verification for NextG Protocols\ncations and assertions from unstructured natural languages.\nMeanwhile, studies in [20], [21] focus on leveraging LLMs\nto enhance BMC for identifying software vulnerabilities and\nderiving counterexamples. In [10], the authors trained GPT-4\nto generate correct SystemVerilog Assertions (SV A) through\niterative prompt refinement with rules. However, it remains\nunclear how these models derive answers and whether they\nrely on simple heuristics rather than a generated chain-of-\nthought [18]. The current state of the art prioritizes produc-\ning formal specifications and properties quickly, albeit with\nslight inaccuracies, over generating perfect specifications or\ncorrectness statements [19]. The non-transparency related to\nLLM heuristics leads to a large number of irrelevant depen-\ndencies, resulting in low precision in dependency classifica-\ntion. To address this, our experimental platform connects to\nguide and refine the dependency graph range.\nPrompting Limitations in LLM Enabled Formal Ver-\nification: Furthermore, the majority of existing work relies\non prompt engineering. LLM-integrated applications blur the\nline between data and instructions [22]. LLMs can produce\nnon-deterministic outputs, potentially yielding different re-\nsults for the same prompt. This variability poses a poten-\ntial threat to the validity of scientific conclusions unless\nresearchers adapt their methods to account for it in their\nempirical analyses [23]. The adoption of prompting methods\nintroduces challenges in iterative formal verification without\nhuman involvement. The randomness in LLMs is influenced\nby the sampling methods used during text generation, such as\ntop-k sampling or nucleus sampling [24], limiting its appli-\ncation in classifiers or deterministic types of applications. To\naddress the non-determinism and iterative formal verification,\ndistinct from current formal verification methods that uti-\nlize prompt engineering, we designed an open-access LLM,\nintegrated with a transformer model, to achieve supervised\ndependency.\"\nDigital Engineering Aided Formal Guided System Val-\nidation: In the field of integrated Design Validation, there\nhas been recent research progress in combining formal ver-\nification with simulation, resulting in a practical validation\nengine with reasonable run-time [25]. Experimental work\nin the context of 5G has gained significant attention over\nthe past few years, shifting from the simulation-driven re-\nsearch used in previous mobile network generations to system\nimplementation prototyping [26]. In our previous work, we\nexplored a Formal-guided Fuzzing testing approach [27],\n[28] to bridge design verification and system validation. This\napproach complements the scalability limitations of formal\nverification and addresses the impacts of detected vulnera-\nbilities. We have introduced a fuzzing digital twin [29] to\nprovide an open and automated platform for systematically\nthat enables an autonomous detection of vulnerabilities and\nunintended emergent behaviors in 5G infrastructures. How-\never, a constraint of this initial approach is heavy reliance on\nexpert insights to identify and articulate formal relationships.\nB. CONTRIBUTION\nThe main original contributions of this work are summarised\nas follows:\n• The research introduces a novel approach that utilizes\nLLMs to address critical challenges in formal verifica-\ntion, specifically in clarifying ambiguities and captur-\ning design intent. This approach combines experience-\nbased prior-probability distribution with logical depen-\ndency analysis in protocol documentation, and leverage\nexperimental-based posterior-probability to enhances\nthe accuracy and relevance of the dependency graph by\nthe cross-attention-based LLM (CAL) model.\n• The paper presents a new systematic solution named\nA VRE, which equipped with CAL, a continuously-\nlearning, cross-attention-based LLMs. CAL is desined\nto interpret and transform protocol descriptions into de-\npendency graphs, which can then be converted into for-\nmal models. CAL is enhanced by incorporating iterative\nfeedback from an experimental platform, HyFuzz, to fo-\ncuse on refining the capture of intentions and resolution\nof ambiguities.\n• In CAL, we introduce a novel multi-session detection\nmethod that bypasses traditional token count barriers. By\nsegmenting comprehensive protocols into manageable\nsections and concurrently processing them, it can output\ndetailed and quality analysis without token constraints.\nCAL incorporates refined cross-attention mechanisms\ninstead of prompting based scheme, achieves high effi-\nciency to identify and interpret complex formal relation-\nships with enhanced accuracy and insight.\n• We have developed a scalable cross sessions dependency\ngraph that supports the hierarchy of formal analysis,\nfacilitating the revelation of in-depth relationships em-\nbedded within protocols to systematically pinpoint and\ncounteract vulnerabilities.\nThe rest of our paper is organized as follows. Section I-A\nlisted the existing literature in the field of LLMs, dependency\ngraph, formal verification, and experimental based validation.\nWe introduce our proposed EVRA and show the architecture\nof the system in Section II, followed by the the detailed\ndescription of the system in Section III and Section IV. We\nprovide the performance analysis and in Section V. Lastly, we\nconcluse our work with future research directions in Section\nVI.\nII. SYSTEM OVERVIEW\nIn addressing the critical need for scalable formal verification\nin the rapidly evolving domains of 5G and NextG protocols\nand specifications, in this paper, we present a pioneering\napproach that utilizes LLMs to overcome key challenges\nof clarifying ambiguities and capturing design intent. We\npresent a novel systematic solution A VER as shown in Fig.\n1 : Auto-modeling of Formal Verification with Real-world\nPrompting for 5G and NextG protocols.\nAt the heart of A VRE is a continuously-learning, CAL\ndesigned to interpret and transform protocol descriptions into\nVOLUME 11, 2023 3\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3366803\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJ. Yanget al.: Towards Auto-Modeling of Formal Verification for NextG Protocols\nFIGURE 1. System Overview of Auto-Modeling and Trustworthy for Formal Verification and Validation in 5G and NextG Security Protocols. Red line shows\nthe process from informal system protocols to dependency graph and formal expression, and green line shows the formal guided fuzz testing feedback to\nthe CAL and refine the results\ndependency graphs, which are subsequently converted into\nformal models. Differing from the current state of the art in\nusing LLM prompting for formal verification, our approach\nintegrates the transformer model with the LLM model, en-\nabling it to generate a quantifiable dependency relationship\nunder supervision. This facilitates the transformative learning\nof the LLM without human involvement, meeting the require-\nments for formal explicitness. This system is further enhanced\nby incorporating iterative feedback from our experimental\nplatform: HyFuzz [12], aimed at refining intention capture\nand ambiguity resolution.\nCAL is trained on labeled identifiers (step 1 and step 2) and\nformal properties, designed to predict formal properties (step\n3) with a more controlled environments. The design of cross-\nattention mechanisms utilization the LLM model improve the\ncapability of the model in complex protocol.\nThe experimental platform serves as two purpose: intention\nand the trustworthy. As shown in step 4 and step 5 in Fig. II, it\nprovides relevancy and design intention information , which\nis used with the dependency relationships detected by CAL\ntogether to form the dependency graph. For trustworthy, as\nshown in step 6 and step 7, the low confident prediction is\nset to the experimental platform to return evidence that could\nbe added to ground truth dependence database. With multiple\niterations, a robust dependency graph will be generated to sent\nto formal method verification. The detected vulnerability will\nbe further used in protocol fortification.\nThe design of the system A VRE uniquely fills a gap in the\nexisting research landscape by integrating experience-based\nprior-probability distribution with logical dependency anal-\nysis in protocol documentation using LLMs. Moreover, by\nleveraging experimental-based posterior-probability through\nreal-world prompting, A VRE establishes an iterative learning\nloop, significantly enhancing the accuracy and relevance of\nthe intention of the CAL model. This advancement marks a\npivotal contribution to the field, offering new directions in the\nformal verification of complex communication protocols.\nIII. PROTOCOL ANALYSIS AND DATA PRE-PROCESS AND\nANNOTATION\nA. PROTOCOL ANALYSIS AND FORMAL PROPERTIES\nDEFINITION\nIn this paper, we use 3GPP Release 17 Radio Resource Con-\ntrol [30] as an example to illustrate A VRE. We identify two\nfundamental elements: procedures and identifiers. Procedures\nare defined as sequences of actions and interactions among\ndifferent entities. Identifiers in the protocols are specific la-\nbels or names used to uniquely recognize various elements\nwithin mobile telecommunications networks. For instance,\nIMSI (International Mobile Subscriber Identity) is a unique\nnumber associated with all cellular networks, used primarily\nfor identifying individual subscribers for billing and iden-\ntification purposes. IMEI (International Mobile Equipment\nIdentity) is defined as a unique number to identify mobile\ndevices, primarily used for identifying the device itself, rather\nthan the subscriber [30]. The procedures define the structure\nof a set of identifiers that are connected dependently. The\ndependent relationship between the identifiers, framed by\nthe structure defined in the procedures, generates the depen-\ndency graph, which is then converted for formal analysis.\nAs shown in Table. 1, while the extraction of entities from\nprotocol identifiers is straightforward, the classification of\ntheir dependency is a problem that CAL targets. However,\nthe procedures include intricate interactions and designs, with\nunspecified space for various vendors to implement based on\ntheir existing infrastructures and devices. In this paper, we\ninnovatively connect to real-world or simulated experimental\nplatforms to aid in procedure formulation.\nTABLE 1. RRCSetupRequest-IEs field descriptions\nIdentifier Description\nestablishmentCause Provides the establishment cause for the\nRRCSetupRequest in accordance with\nthe information received from upper lay-\ners. gNB is not expected to reject an\nRRCSetupRequest due to unknown cause\nvalue being used by the UE.\nue-Identity UE identity included to facilitate contention\nresolution by lower layers.\nConsidering confidentiality, integrity, and availability\n4 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3366803\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJ. Yanget al.: Towards Auto-Modeling of Formal Verification for NextG Protocols\n(CIA) triad which is widely accepted security model, along\nwith the Dolev-Yao model for communication protol formal\nverification, we have proposed four essential properties to de-\nscribe the dependency among identifiers [27]. These proper-\nties, each addressing a distinct facet of security augmentation\nwithin the specifications, are defined as follows:\n1) Confidentiality: the capability of source to prevent pri-\nvate information from leakage of the destination. The\nsource should be the selected encryption algorithm or the\nkey of encryption algorithm, and the destination should\nbe command or specific identifier, which are confiden-\ntiality protected by source.\n2) Integrity : the capability of source to keep the destina-\ntion information unmodified. Similar to confidentiality,\nthe source should be the selected integrity algorithm\nor the key of integrity algorithm, and the destination\nshould be the command or specific identifier, which are\nintegrity protected by source.\n3) Authentication: the ability of source to help User\nEquipment (UE) or gNodeB (gNB) to identify where\nand when the destination was sent from. The source\nshould be the distinctive identifier, which can uniquely\nrepresent a entity (like gNB) or a communication session\n(like UE id).\n4) Accounting: the source of accounting relationship is\nthe counting identifier which can sequentially track and\ndistinguish each transmitted command. The destination\nshould be the sequence-protected command.\n5) Include: the destination identifier is included in the\nsource identifier.\n6) Generate: the destination identifier is generated by the\nsource identifier.\nB. DATA PREPARATION\nIn our study, we annotated dependencies (formal properties)\nof identifiers in the 5G Radio Resource Control (RRC) pro-\ntocol [30], focusing on Sections 5.3.1 to 5.3.5. From these\nsections, approximately 16,428 samples were annotated, in-\ncluding source, destination, and dependency relationships.\nOut of these, 1,218 samples were identified by domain ex-\nperts who analyzed the documents to determine relationships.\nThe remaining samples consist of source and destination\npairs lacking a dependency relationship. In our proposed\nmodel, we treat this as a classification problem for all poten-\ntial source-destination pairs, encompassing both relevant and\nnon-relevant ones. Consequently, the large number of source\nand destination pairs results in highly imbalanced data.\nIn our analysis of the annotated data samples, we have\nidentified an imbalance in the distribution between positive\nand negative samples. To address this issue and improve\nthe model’s performance, we propose employing a weight-\nbalanced binary cross-entropy loss. Fig. 2 illustrates the size\nof each property type and the intersection sizes among them.\nIt is clear from Fig. 2 that ’include’ has the largest number\nof detections. Furthermore, the intersections of ’include’ with\n’account’ and ’integrity’ represent the two largest intersection\ncounts, indicating a strong correlation between these proper-\nties. It is also important to note the significant presence of\n’integrity’ in multiple intersections, which is consistent with\nthe importance of integrity in RRC protocols 3GPP in release\n17.\nIV. METHODOLOGY\nA. BUILDING MULTIMODAL CROSS- AND\nSELF-ATTENTION LARGE LANGUAGE MODEL\nIn this work, we proposed CAL, an LLM embedded with\ncross- and self-attention model, as delineated in Fig. 3, con-\nsidering both the contextual information from the original\nprotocols and learns the defined dependency relationships\namong identifiers. CAL model employs a pretrained LLM\n(GPT-2), which consists of N transformer layers, to extract\nhidden insights from protocol descriptions. Here, considering\nthe scalability of training and the performance accuracy, we\nselect N = 12.\nWe incorporate cross-attention mechanisms to discern the\nrelationships between the extracted latent information and\nquery entities [31]. To further enrich the contextual under-\nstanding, we deploy self-attention frameworks that evaluate\ninter-relations among all positions from the preceding stage,\nguided by weighted considerations. In the final stage of the\npresented model, a linear classifier is implemented to infer\nprobabilities associated with distinct formal attributes.\nSelf-attention generates contextual representations for a\nsingle sequence by computing weighted averages of all to-\nkens, while cross-attention evaluates interdependent contex-\ntual relationships between the query sequence and the context\nsequence in transformer models [32]–[34]. In the proposed\nCAL model for converting complex contextual protocols into\nexplicit dependency graphs, self-attention serves as the mech-\nanism to understand the context within the protocols, while\ncross-attention understands and recognizes the relationships\nacross the identifier sequences.\nSelf-attention calculates a weighted average of feature\nrepresentations, where the weight represents the similarity\nscore between pairs of feature representations. As defined\nin [32], an input sequence of n tokens of dimensions d,\nX ∈ Rn×d , is extracted by three projection matrices WQ ∈\nRd×dq , WK ∈ Rd×dk and WV ∈ Rd×dv (dq = dk ). The input\nconsists of queries and keys with dimension dk , and values\nwith dimension dv. Three different feature representations\nQ = XWQ, K = XWK , and V = XWV , where Q ∈ Rn×dq ,\nK ∈ Rn×dk and V ∈ Rn×dv . Intuitively, Q, K and V are\nseparately regarded as query, key and value. Normalized dot-\nproduct of query and key is used to represent the attention\nscore A ∈ Rn×n of each query and paired keys as:\nA = softmax(QKT\npdq\n) (1)\nwhere division by pdq normalizes the dot-product of Q and\nKT , ensuring that the distribution of the dot-product aligns\nVOLUME 11, 2023 5\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3366803\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJ. Yanget al.: Towards Auto-Modeling of Formal Verification for NextG Protocols\nFIGURE 2. Formal Properties Statistical Counts and Intersections\nClassifier\nSlef-attention\nMulti-Head \nAttention\nInput \nEmbedding\nInput1:\nProtocol\nPositional\nEncoding\nFeed \nForward\nN\n(12)\nx\nPretrained \nGPT2\nCorss-attention\nMulti-Head \nAttention\nFeed \nForward\nInput \nEmbedding\nInput2:\nQuery \nEntities\n6x\nSelf-attention\nMulti-Head \nAttention\nAdd \n& \nNorm\nFeed \nForward\nAdd \n& \nNorm\nLinear\nAdd \n& \nNorm\nAdd \n& \nNorm\nAdd \n& \nNorm\nAdd \n& \nNorm\n6x\nSoftmax\nOutput\nFormal \nRelationship \nProbabilities\nQ\nK\nV\nQ\nK\nV\nQ\nK\nV\nFIGURE 3. Attention Driven Formal Identifier and Property Abstraction\nModel\nwith expectation E = 0and variance Var = 1. Ultimately,\nattention value is calculated as follow,\nSelf-attention(Q, K, V ) =softmax(QKT\npdq\n)V = AV (2)\nwhere output Self-attention(Q, K, V ) ∈ Rn×dv is the weighted\naverage of extracted features. Normally, a residual linear feed\nforward layer is incorporated to further distill the acquired\nknowledge represented by the weighted average features.\nUtilizing the self-attention mechanism, cross-attention\ntakes two input sequences with different sequence length\nX1 ∈ Rn1×d and X2 ∈ Rn2×d as inputs. Subsequently,\nQ = X1WQ, K = X2WK , and V = X2WV are derived from\nX1 and X2 respectively and the dimension of attention value\ncan be succinctly expressed as Rn1×dv .\nB. BALANCED LOSS FUNCTION\nIn Section III-B, we observed the imbalance in the data\ndistribution of relationships amongst entities, and is evident\nin Table 2. In response to this challenge, we adopt a weight-\nbalanced binary cross-entropy loss, articulated in Equation 3.\nIn this equation, N signifies the total number of cases, yi\nrepresents the ground truth, p(yi) is the predicted probability,\nand n(yi) denotes the proportion of class yi within all cases.\nUtilizing the inverse class ratio amplifies the impact of the\nunderrepresented class while tempering the dominance of the\nmajority class, offering a balanced approach to mitigate the\nskewed data distribution.\nTABLE 2. Imbalanced Nature of Formal Property Data\nRelationship Class Count Relationship Class Count\nConfidentiality 0 16421 Accounting 0 16399\nConfidentiality 1 7 Accounting 1 29\nIntegrity 0 16408 Include 0 16329\nIntegrity 1 20 Include 1 99\nAuthentication 0 16417 Generate 0 16389\nAuthentication 1 11 Generate 1 39\n6 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3366803\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJ. Yanget al.: Towards Auto-Modeling of Formal Verification for NextG Protocols\nFIGURE 4. Virtual and Over the Air (OTA) Mode Experimental of HyFuzz\n[12]\nLi = −[yi · log(p(yi)) + (1− yi) · log(1 − p(yi))]\nL = 1\nN\nNX\ni=1\nLi · (1 − n(yi)\nN ) (3)\nC. CONNECTION TO EXPERIMENTAL PLATFORM\nInspired by the iterative prompting to the LLM, the experi-\nmental platform serves as the prompting server in real world.\nIn order to clarify the ambiguity in the LLM model, the coun-\nterpart experiments configuration could be auto-generated\nand performed, in which the results generated is feedback\nto the LLM to improve the trustworthiness. Through the\ndigital engineering module, which facilitates connections to\navailable real-world execution platforms or digital twins, the\nprocess effectively bridges the gap between design intentions\nand real-world operations for mission-critical infrastructures.\nThe experimental platform, HyFuzz, employs a hybrid\nsystem model [12] that incorporates two distinct platforms:\na ZeroMQ virtual model and an Over the Air (OTA) physical\nmodel. In addition to running 5G tests in various scenarios,\nthe uniqueness of the HyFuzz platform is its ability to serve\nas relay nodes to perform various fuzzing tests. The relay\nnode is capable of modifying and permutating commands and\naccessing messages exchanged between the UE and the gNB.\nHyFuzz facilitates multi-step Man-In-The-Middle (MITM)\nattacks, enabling the identification and analysis of vulner-\nabilities and the detection of various prompts due to the\nuncertainty of CAL model outputs and providing an accurate\nreal-world ground truth. An overview of the HyFuzz is shown\nin Fig. 4.\nAs illustrated in Fig. II, the experimental platform is seam-\nlessly integrated with the CAL model, supporting it from two\nkey aspects: design intention and trustworthiness. Regarding\ndesign intention, the platform supplies relevant information\nand design intents to the CAL model, enabling it to continue\nTABLE 3. Configuration of Model\nParameter Value\nGPT-2’s Embedding Size 768\nGPT-2’s Sequentce Length 104\nGPT-2’s Layers 12\nGPT-2’s Attention Head 12\nCross-attention Layer 6\nCross-attention Attention Head 6\nSelf-attention Layer 6\nSelf-attention Attention Head 6\nLearning Rate 1e−7\nEpoch 100\ndropout rate 0.1\nTrain/Validation Ratio 9 : 1\ntraining based on novel evidence of dependency relationships,\nthus effectively constructing an accurate dependency graph.\nIn terms of trustworthiness, low-confidence predictions are\nreferred back to the experimental platform for further vali-\ndation, potentially contributing new data to the ground truth\ndependency database. This iterative process aims to create a\nrobust dependency graph, which will be utilized for formal\nmethod verification. Detected vulnerabilities will then be\nleveraged in protocol fortification.\"\nV. SYSTEM PERFORMANCE ASSESSMENT\nA. CAL EXPERIMENT SETTING\nConsidering the openness and accessibility of the LLMs, in\nthis paper, we select the pre-trained GPT-2 model with 12\ntransformer layers and 12 attention heads as embedded pre-\ntrained LLM included in CAL. The GPT-2’s embedding size\nis set to 768, and the sequence length is configured to 1024, al-\nlowing for the effective extraction of hidden information from\nthe extended protocols. Subsequent to the application of the\nLLM, the extracted hidden information is processed through\n6 layers of self-attention with 6 attention heads and 6 layers\nof cross-attention with 6 attention heads. This structure aids\nin recognizing and processing the comprehensive relation-\nships between the protocols and the associated query entities.\nFurther details of the model’s configuration are presented in\nTable 3.\nB. CAL EXPERIMENT RESULT ANALYSIS\nAs depicted in Fig. 5, the consistent trends in both training\nand validation accuracy of CAL underscore the model’s profi-\nciency in extracting the dependency relationship information\nfrom the examined protocols and entities. In our experiment\nsetting, formal properties are designated as positive, while\ntheir absence is categorized as negative. As presented in\nTable4, our model performs stable accuracy of 95.94%, and\nachieves 100% accuracy in recall, indicating the high and\nstable performance in formal property prediction and the\ntrustworthiness of the model.\nWe further compared our model with other state of art\nmodel performance. Table 4 leads to an explicit conclusion\nthat the CAL significantly outperforms all other models de-\nlineated in Section V-A. Fig. 6 reveals that only the LSTM\nVOLUME 11, 2023 7\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3366803\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJ. Yanget al.: Towards Auto-Modeling of Formal Verification for NextG Protocols\n0 20 40 60 80 100\nEpoch\n0.0005\n0.0010\n0.0015\n0.0020\n0.0025\n0.0030\n0.0035\n0.0040Training loss\nCAL\nLLM with LSTM\nLSTM\nFIGURE 5. Training Loss: the training loss indicate the incapability of\ntraditional models like LSTM in processing complex dependency and text.\n0 20 40 60 80 100\nEpoch\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0Accuracy\nCAL Validation\nCAL Train\nLLM with LSTM Validation\nLLM with LSTM Train\nLSTM Validation\nLSTM Train\nFIGURE 6. Training Result: Suboptimal models, such as those utilizing\nLLM with LSTM and standalone LSTM, often get trapped in local minima\ndue to Class Imbalance and Specially Designed Loss.\nmodel and the hybrid LLMs with LSTM model exhibit a\ndeficiency in the efficient extraction of information during\nthe training phase, resulting in trapping in local optima. The\nresult also indicates the necessity of LLMs in processing\ncomplex protocols and standards.\nTo compare the performance of transformer-based models\nwith traditional non-transformer models, the LSTM, known\nfor effectively capturing long-range dependencies and typi-\ncally performs better than CNN and RNN, is chosen to replace\nthe cross-attention and self-attention. To ensure consistency\nof experimentation, the LSTM is set with a hidden state size of\n768 and 6 recurrent layers. Additionally, the LSTM alone was\nused to directly process natural language to predict formal\nproperties, also with a hidden state size of 768 and 6 layers.\nThe Area Under the Curve (AUC) is commonly described\nas a statistical measure used to evaluate the performance of a\nclassification model. As shown in Fig.7, we can see that via\nTABLE 4. Accuracy of Different Models\nModel Accuracy\nCAL 95.94%\nLLM with LSTM 66.76%\nLSTM 50.21%\n0.0 0.2 0.4 0.6 0.8 1.0\nFalse Positive Rate\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0True Positive Rate\nCAL (AUC = 0.98)\nFIGURE 7. Receiver Operating Characteristic (ROC) curve of CAL Model\nthe True Positive Rate (TPR) against the False Positive Rate\n(FPR), CAL has an AUC value of 0.98, indicating excellent\nperformance.\nThen, we further analyze the AUC for each type of de-\npendency, as shown in Fig. 8. Confidentiality: This curve\nappears to be the closest to the top-left corner, suggesting it\nhas the best performance among the four criteria. Integrity,\nAuthentication, Accounting: These curves are further from\nthe top-left corner compared to Confidentiality. While they\nstill demonstrate good performance, they are not as effective\nas the Confidentiality curve.\nTo better visualize the interactions between relevant en-\ntities and protocol procedure descriptions, we utilize the\nActions related to the transmission of ‘‘RRCSetupRequest’’\nmessage as an example. This verification process aims to\ndetermine whether our model can effectively extract valuable\ninformation from the human-written protocol procedure de-\n0.0 0.2 0.4 0.6 0.8 1.0\nFalse Positive Rate\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0True Positive Rate\nAll (AUC = 0.98)\nConfidentiality(AUC = 0.98)\nIntegrity(AUC = 0.97)\nAuthentication(AUC = 1.00)\nAccounting(AUC = 0.99)\nInclude(AUC = 0.96)\nGenerate(AUC = 0.98)\nFIGURE 8. Dependency Relations Specific ROC curve of CAL Model\n8 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3366803\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJ. Yanget al.: Towards Auto-Modeling of Formal Verification for NextG Protocols\nscriptions.\nIn transformer-based models, each transformer layer has\nthe capability to extract distinct information through different\nattention scores. In this study, we leverage the average score\nof cross-attention layers to visualize the interactions between\nrelevant entities and protocol procedure descriptions. Tak-\ning the entities ‘‘establishmentCause’’ and ‘‘RRCSetupRe-\nquest’’, along with their corresponding procedure as an exam-\nple, we generate an attention map (Fig. 9). The attention map\nclearly reveals that these two entities place more emphasis\non specific terminologies, such as ‘‘establishmentCause’’,\n‘‘mps-PriorityAccess’’, and ‘‘RRC’’, as well as the levels of\nindentation, such as ‘‘1 >’’ and ‘‘2:’’. This observation high-\nlights the cross-attention component’s ability to effectively\nfocus on and extract essential information from key terms\nwithin the input text.\nProtocol \nTokens\nInterested \nEntities\nFIGURE 9. Attention Map Depicting Average Attention Scores Across\nLayers: Lighter Shades Indicate Higher Attention; Darker Shades Signify\nReduced Attention.\nC. CASE STUDY OF DESIGN INTENTION CAPTURING AND\nTRUSTWORTHY ENHANCEMENT VIA THE CONNECTION\nTO REAL-WORLD TESTBED\nCase 1: Design Intention With the CAL model, the generated\ndependencies include both intended and unintended ones.\nCompared to extraction from human expertise, a portion of\nunintended dependency relationships is also detected. These\nunintended dependencies can be filtered out via connection\nto a real-world experimental platform.\nWe took the example of ‘‘RRC_setup_request’’ and ‘‘Se-\ncurity_mode_command’’, as shown in Fig. 10. Figure 10(a)\nillustrates the raw dependency relationships detected by CAL,\nwhile Figure 10(b) shows the experimentally filtered, design-\nintended dependency graph. Using the information flow from\nthe experiment platform, as shown in Fig.11, we can derive\nthe design-intended dependency graph presented in Fig. 10(b)\nand Fig. 10(d). Figures 10(c) and 10(e) are equivalent to\nFigures 10(b) and 10(d) respectively, offering a more user-\nfriendly visualization.\nCase 2: Trustworthy For dependencies predicted by CAL\nwith low confidence, the uncertain dependency can be con-\nverted into test scripts and sent to an experimental platform\nto generate evidence. This evidence can be used to confirm\nor refute the existence of the dependency. As shown in Fig.\n12, the dependency between KRRCenc and CipherAlgorithm\nshows low confidence in the detected ‘‘Integrity’’. This is\nautomatically converted into fuzzing scripts to generate ev-\nidence, proving that there is no dependency between them, as\nindicated in the parsed information from the log file 13.\nD. FORMAL VERIFICATION AND ATTACK MODEL\nBased on the predicted relationship between entities, our next\nobjective is to perform the formal verification, as shown in\nFig. 14 and Fig. 15. The interconnected sections and commu-\nnicated commands consisting of identifiers. We can first fill\nup the interconnected sections and communicated commands,\nwhich is depicted in natural language protocols, shown in\nFig. 16 to Fig. 19. And from the command table in natural\nlanguage protocols, we can easily identify which identifiers\nare included in the commands.\nUtilizing the identified formal properties, we construct\na comprehensive dependency graph, which facilitates the\nderivation of formal dependencies through this graph.\nWe consider the RRC connection establishment procedure\nas an example. Nodes were manually extracted from the\nnatural language protocol, as depicted in Figs. 16 and 17.\nThe visual representation employs boxes to signify ‘‘Include’’\nand uses various arrow types to delineate distinct formal\nproperties. Leveraging our predicted formal properties, we\ngenerated the RRC connection dependency graph (see Fig.\n??). Remarkably, this aligns perfectly with the ground truth of\nthe RRC connection dependency graph. However, during the\nSecurity Mode procedure, there were discrepancies between\nthe predicted formal properties (as presented in Fig. 18) and\nthe ground truth (see Fig. 19). Therefore, subsequent manual\nverification is advisable. Notably, while there may be the\ninclusion of extraneous formal properties, none are omitted.\nBuilding on previous related work [27], this dependency\ngraph can be transformed into Proverif code, enabling formal\nverification. Compared to solely manual labeling of formal\nproperties, our proposed model streamlines the process by\nnarrowing down the entirety of natural language protocols\nto the task of parsing redundant formal properties from the\ncrafted formal dependency graph.\nVOLUME 11, 2023 9\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3366803\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJ. Yanget al.: Towards Auto-Modeling of Formal Verification for NextG Protocols\n(a) \nmodel \ndetected \nrelations  \n= \ndesign \nintended \n+ \ndesign \nunintended \nrelations\n(b) \ndesign \nintended \nfor \nRRC \nSetup \nRequet\n(d) \ndesign \nintended \nfor \nSecuirty \nMode \nCommand\n(c) \nuser \nfriendly \nvisulaization \nof \n(b) \n(e) \nuser \nfriendly \nvisulaization \nof \n(d) \nFIGURE 10. Design Intention: (a) is the raw dependency relationships that detected by CAL, and (b) is the experiments filtered design intended\ndependency graph.\nFIGURE 11. Information Flow-graph detected in Experiment Platform\nFIGURE 12. Information Flow-graph detected in Experiment Platform\nVI. CONCLUSION\nIn conclusion, we present A VRE, a novel system for the\nformal verification of NextG protocols, leveraging LLMs\nto transform protocol descriptions into dependency graphs\nand formal models. Enhanced by the HyFuzz experimental\nplatform, A VRE demonstrates significant advances in the\naccuracy and relevance of formal verification in complex\ncommunication protocols. The research underscores the ef-\nficiency of CAL, a continuously-learning, cross-attention-\nFIGURE 13. Fuzzing Log File to Parse Evidence Information\nUE\nNetwork\nRRCSetupRequest\nRRCSetup\nRRCSetupComplete\nFIGURE 14. RRC Connection Flow Graph\nUE\nNetwork\nSecurityModeCommand\nSecurityModeComplete\nFIGURE 15. Security Mode Command Flow Graph\nbased LLM, in extracting formal properties and dependen-\ncies, outperforming traditional methods. The study empha-\n10 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3366803\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJ. Yanget al.: Towards Auto-Modeling of Formal Verification for NextG Protocols\nRRCSetupComplete\nRRCSetupRequest\nUE-identity\nestablish-\nmentCause\nradioResource\nConfogDedocated\ndedicatedNAS-\nMessage\n \nselectedPLMN\n-Identity\nng-5G-S-\nTMSI-V\nFIGURE 16. Ground Truth RRC Connection Dependency Graph\nRRCSetupComplete\nRRCSetupRequest\nUE-identity\nestablish-\nmentCause\nradioResource\nConfogDedocated\ndedicatedNAS-\nMessage\n \nselectedPLMN\n-Identity\nng-5G-S-\nTMSI-V\nConfidentiality\nIntegrity\nAuthentication\nAccounting\nGenerate\nLegend\nInclude\nFIGURE 17. Predicted Security Mode Command Dependency Graph\nSecurityModeCommand\nSecurityModeComplete\nciphering\nAlgorithm\nKRRCint\nKRRCenc\nKUPenc\nintegrity\nProtAlgorithm\nFIGURE 18. Ground Truth Security Mode Command Dependency Graph\nsizes the potential of LLMs in enhancing trustworthiness\nand clarifying ambiguities in protocol verification, marking\na significant contribution to the field. By reducing reliance\non manual labeling and associated human errors, our method\noffers a more efficient approach, focusing only on the most\npertinent formal relationships. Our work in extracting formal\nrelationships from natural language protocols enhances the\nclarity and understanding of these protocols, ensuring a more\nrobust, reliable, and efficient approach for protocol verifica-\ntion and system validation in large-scale, complex systems.\nSecurityModeCommand\nSecurityModeComplete\nciphering\nAlgorithm\nKRRCint\nKRRCenc\nKUPenc\nintegrity\nProtAlgorithm\nFIGURE 19. Comparison between Predicted and Ground Truth\nDependency Graph\nREFERENCES\n[1] 3GPP, ‘‘5g evolution toward 5g advanced: An overview of 3gpp releases\n17 and 18,’’ IEEE Xplore, 2022.\n[2] ‘‘Nr; radio resource control (rrc); protocol specification,’’ 3rd Generation\nPartnership Project (3GPP), Technical Specification (TS) 38.331, 2021,\navailable: 3GPP website. [Online]. Available: https://www.3gpp.org\n[3] ‘‘Open ran – 5g hacking just got a lot more interesting,’’ Karsten Nohl,\nSecurity Research Labs, Tech. Rep., 2022.\n[4] D. Dolev and A. Yao, ‘‘On the security of public key protocols,’’ IEEE\nTransactions on information theory , vol. 29, no. 2, pp. 198–208, 1983.\n[5] I. Cervesato, ‘‘The dolev-yao intruder is the most powerful attacker,’’ in\n16th Annual Symposium on Logic in Computer Science—LICS , vol. 1.\nCiteseer, 2001, pp. 1–2.\n[6] M. Ammann, L. Hirschi, and S. Kremer, ‘‘Dy fuzzing: Formal dolev-yao\nmodels meet cryptographic protocol fuzz testing,’’ in 45th IEEE Sympo-\nsium on Security and Privacy , 2024.\n[7] I. Rakotonirina, G. Barthe, and C. Schneidewind, ‘‘Decision and com-\nplexity of dolev-yao hyperproperties (technical report),’’ in Symposium on\nPrinciples of Programming Languages (POPL) , 2024.\n[8] R. Kande, H. Pearce, B. Tan, B. Dolan-Gavitt, S. Thakur, R. Karri, and\nJ. Rajendran, ‘‘Llm-assisted generation of hardware assertions,’’ arXiv\npreprint arXiv:2306.14027, 2023.\n[9] M. Cosler, C. Hahn, D. Mendoza, F. Schmitt, and C. Trippel, ‘‘nl2spec:\nInteractively translating unstructured natural language to temporal logics\nwith large language models,’’ arXiv preprint arXiv:2303.04864 , 2023.\n[10] M. Orenes-Vera, M. Martonosi, and D. Wentzlaff, ‘‘Using llms to facilitate\nformal verification of rtl,’’ arXiv e-prints, pp. arXiv–2309, 2023.\n[11] S. Yuan, J. Yang, S. Arya, C. Lipizzi, and Y . Wang, ‘‘From ambiguity to\nexplicitness: Nlp-assisted 5g specification abstraction for formal analysis,’’\narXiv preprint arXiv:2308.03277 , 2023.\n[12] J. Yang and Y . Wang, ‘‘A nextg hybrid testing platform for multi-step deep\nfuzzing and performance assessment from virtualization to over-the-air,’’\nin IEEE Cloudnet, 2023.\n[13] R. Drechsler, M. Soeken, and R. Wille, ‘‘Formal specification level: To-\nwards verification-driven design based on natural language processing,’’\nin Proceeding of the 2012 Forum on Specification and Design Languages .\nIEEE, 2012, pp. 53–58.\n[14] L. Banarescu, C. Bonial, S. Cai, M. Georgescu, K. Griffitt, U. Hermjakob,\nK. Knight, P. Koehn, M. Palmer, and N. Schneider, ‘‘Abstract meaning\nrepresentation for sembanking,’’ in Proceedings of the 7th linguistic anno-\ntation workshop and interoperability with discourse , 2013, pp. 178–186.\n[15] L. Dong and M. Lapata, ‘‘Language to logical form with neural attention,’’\narXiv preprint arXiv:1601.01280 , 2016.\n[16] S. Reddy, D. Chen, and C. D. Manning, ‘‘Coqa: A conversational question\nanswering challenge,’’ Transactions of the Association for Computational\nLinguistics, vol. 7, pp. 249–266, 2019.\n[17] C. Hahn, F. Schmitt, J. J. Tillman, N. Metzger, J. Siber, and\nB. Finkbeiner, ‘‘Formal specifications from natural language,’’ arXiv\npreprint arXiv:2206.01962, 2022.\n[18] A. Saparov and H. He, ‘‘Language models are greedy reasoners:\nA systematic formal analysis of chain-of-thought,’’ arXiv preprint\narXiv:2210.01240, 2022.\nVOLUME 11, 2023 11\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3366803\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJ. Yanget al.: Towards Auto-Modeling of Formal Verification for NextG Protocols\n[19] P. Srikumar, ‘‘Fast and wrong: The case for formally specifying hardware\nwith llms,’’ in Proceedings of the International Conference on Architec-\ntural Support for Programming Languages and Operating Systems (ASP-\nLOS). ACM. ACM Press , 2023.\n[20] N. Tihanyi, T. Bisztray, R. Jain, M. A. Ferrag, L. C. Cordeiro, and\nV . Mavroeidis, ‘‘The formai dataset: Generative ai in so ware security\nthrough the lens of formal verification,’’ PROMISE’23, p. 33, 2023.\n[21] Y . Charalambous, N. Tihanyi, R. Jain, Y . Sun, M. A. Ferrag, and L. C.\nCordeiro, ‘‘A new era in software security: Towards self-healing soft-\nware via large language models and formal verification,’’ arXiv preprint\narXiv:2305.14752, 2023.\n[22] S. Abdelnabi, K. Greshake, S. Mishra, C. Endres, T. Holz, and M. Fritz,\n‘‘Not what you’ve signed up for: Compromising real-world llm-integrated\napplications with indirect prompt injection,’’ in Proceedings of the 16th\nACM Workshop on Artificial Intelligence and Security , 2023, pp. 79–90.\n[23] S. Ouyang, J. M. Zhang, M. Harman, and M. Wang, ‘‘Llm is like a box\nof chocolates: the non-determinism of chatgpt in code generation,’’ arXiv\npreprint arXiv:2308.02828, 2023.\n[24] K. Krishna, Y . Chang, J. Wieting, and M. Iyyer, ‘‘Rankgen: Improving text\ngeneration with large ranking models,’’ arXiv preprint arXiv:2205.09726 ,\n2022.\n[25] L. Li and M. Thornton, Digital system verification: A combined formal\nmethods and simulation framework . Springer Nature, 2022.\n[26] Y . Wang, A. Gorski, and A. P. da Silva, ‘‘Development of a data-driven\nmobile 5g testbed: Platform for experimental research,’’ in 2021 IEEE\nInternational Mediterranean Conference on Communications and Net-\nworking (MeditCom). IEEE, 2021, pp. 324–329.\n[27] J. Yang, S. Arya, and Y . Wang, ‘‘Formal-guided fuzz testing: Targeting se-\ncurity assurance from specification to implementation for 5g and beyond,’’\narXiv preprint arXiv:2307.11247 , 2023.\n[28] J. Yang and Y . Wang, ‘‘Formal and fuzzing amplification: Targeting vul-\nnerability detection in 5g and beyond,’’ arXiv preprint arXiv:2307.05758 ,\n2023.\n[29] D. Dauphinais, M. Zylka, H. Spahic, F. Shaik, J. Yang, I. Cruz, J. Gibson,\nand Y . Wang, ‘‘Automated vulnerability testing and detection digital twin\nframework for 5g systems,’’ in 2023 IEEE 9th International Conference on\nNetwork Softwarization (NetSoft) . IEEE, 2023, pp. 308–310.\n[30] ‘‘3gpp ts 38.331: Radio resource control (rrc),’’ 3GPP, Report, 2022.\n[31] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL. Kaiser, and I. Polosukhin, ‘‘Attention is all you need,’’ 2017. [Online].\nAvailable: https://arxiv.org/pdf/1706.03762.pdf\n[32] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nŁ. Kaiser, and I. Polosukhin, ‘‘Attention is all you need,’’ Advances in\nneural information processing systems , vol. 30, 2017.\n[33] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‘‘Bert: Pre-training\nof deep bidirectional transformers for language understanding,’’ arXiv\npreprint arXiv:1810.04805, 2018.\n[34] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal,\nA. Neelakantan, P. Shyam, G. Sastry, A. Askell et al. , ‘‘Language models\nare few-shot learners,’’ arXiv preprint arXiv:2005.14165 , 2020.\nJINGDA YANG (Graduate Student Member,\nIEEE) received the B.E. degree in software engi-\nneering from Shandong University and the M.Sc.\ndegree in computer science from The George\nWashington University. He is currently a Ph.D.\nstudent in the School of System and Enterprises\nat Stevens Institute of Technology. His research\ninterests are formal verification and vulnerability\ndetection of wireless protocol in 5G.\nYING WANG(Member, IEEE) received the B.E.\ndegree in information engineering at Beijing Uni-\nversity of Posts and Telecommunications, M.S.\ndegree in electrical engineering from University of\nCincinnati and the Ph.D. degree in electrical en-\ngineering from Virginia Polytechnic Institute and\nState University. She is an associate professor in\nthe School of System and Enterprises at Stevens\nInstitute of Technology. Her research areas include\ncybersecurity, wireless AI, edge computing, health\ninformatics, and software engineering.\n12 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3366803\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8061816096305847
    },
    {
      "name": "Formal verification",
      "score": 0.4436686933040619
    },
    {
      "name": "Modeling language",
      "score": 0.43537747859954834
    },
    {
      "name": "Natural language processing",
      "score": 0.3583223819732666
    },
    {
      "name": "Programming language",
      "score": 0.22356587648391724
    },
    {
      "name": "Software",
      "score": 0.08281755447387695
    }
  ]
}