{
  "title": "Pseudo-labeling with transformers for improving Question Answering systems",
  "url": "https://openalex.org/W3203734430",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A5026394183",
      "name": "Karolina Kuligowska",
      "affiliations": [
        "University of Warsaw"
      ]
    },
    {
      "id": "https://openalex.org/A5097551882",
      "name": "Bart≈Çomiej Kowalczuk",
      "affiliations": [
        "University of Warsaw"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2398730997",
    "https://openalex.org/W3098371839",
    "https://openalex.org/W92894758",
    "https://openalex.org/W2962925243",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W4205671217",
    "https://openalex.org/W6638523607",
    "https://openalex.org/W2979805229",
    "https://openalex.org/W2038069320",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W6637298292",
    "https://openalex.org/W6779528875",
    "https://openalex.org/W2903885543",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W2924902521",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6727690538",
    "https://openalex.org/W3035160371",
    "https://openalex.org/W2525778437",
    "https://openalex.org/W1821462560",
    "https://openalex.org/W3035406246",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W1682403713"
  ],
  "abstract": "Advances in neural networks contributed to the fast development of Natural Language Processing systems. As a result, Question Answering systems have evolved and can classify and answer questions in an intuitive yet communicative way. However, the lack of large volumes of labeled data prevents large-scale training and development of Question Answering systems, confirming the need for further research. This paper aims to handle this real-world problem of lack of labeled datasets by applying a pseudo-labeling technique relying on a neural network transformer model DistilBERT. In order to evaluate our contribution, we examined the performance of a text classification transformer model that was fine-tuned on the data subject to prior pseudo-labeling. Research has shown the usefulness of the applied pseudo-labeling technique on a neural network text classification transformer model DistilBERT. The results of our analysis indicated that the model with additional pseudo-labeled data achieved the best results among other compared neural network architectures. Based on that result, Question Answering systems may be directly improved by enriching their training steps with additional data acquired cost-effectively.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8864692449569702
    },
    {
      "name": "Question answering",
      "score": 0.8538512587547302
    },
    {
      "name": "Transformer",
      "score": 0.7992244958877563
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6470197439193726
    },
    {
      "name": "Artificial neural network",
      "score": 0.6407976150512695
    },
    {
      "name": "Labeled data",
      "score": 0.5221348404884338
    },
    {
      "name": "Training set",
      "score": 0.5008025169372559
    },
    {
      "name": "Machine learning",
      "score": 0.4976377785205841
    },
    {
      "name": "Natural language",
      "score": 0.45901528000831604
    },
    {
      "name": "Language model",
      "score": 0.4388889968395233
    },
    {
      "name": "Natural language processing",
      "score": 0.38565412163734436
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ]
}