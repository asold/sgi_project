{
  "title": "CLGT: A Graph Transformer for Student Performance Prediction in Collaborative Learning",
  "url": "https://openalex.org/W4382318164",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2030549355",
      "name": "Tianhao Peng",
      "affiliations": [
        "Beihang University"
      ]
    },
    {
      "id": "https://openalex.org/A2095698136",
      "name": "Yu Liang",
      "affiliations": [
        "Beijing University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2096479677",
      "name": "Wenjun Wu",
      "affiliations": [
        "Beihang University"
      ]
    },
    {
      "id": "https://openalex.org/A2095648138",
      "name": "Jian Ren",
      "affiliations": [
        "Beihang University"
      ]
    },
    {
      "id": "https://openalex.org/A2755059475",
      "name": "Zhao Pengrui",
      "affiliations": [
        "Beihang University"
      ]
    },
    {
      "id": "https://openalex.org/A2553776962",
      "name": "Yanjun Pu",
      "affiliations": [
        "Beihang University"
      ]
    },
    {
      "id": "https://openalex.org/A2030549355",
      "name": "Tianhao Peng",
      "affiliations": [
        "Beihang University"
      ]
    },
    {
      "id": "https://openalex.org/A2095698136",
      "name": "Yu Liang",
      "affiliations": [
        "Beijing University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2096479677",
      "name": "Wenjun Wu",
      "affiliations": [
        "Institute of Art",
        "Beihang University"
      ]
    },
    {
      "id": "https://openalex.org/A2095648138",
      "name": "Jian Ren",
      "affiliations": [
        "Beihang University"
      ]
    },
    {
      "id": "https://openalex.org/A2755059475",
      "name": "Zhao Pengrui",
      "affiliations": [
        "Beihang University"
      ]
    },
    {
      "id": "https://openalex.org/A2553776962",
      "name": "Yanjun Pu",
      "affiliations": [
        "Beihang University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2725879830",
    "https://openalex.org/W3010160222",
    "https://openalex.org/W2015040676",
    "https://openalex.org/W6787995345",
    "https://openalex.org/W3081035802",
    "https://openalex.org/W1988790447",
    "https://openalex.org/W3169515383",
    "https://openalex.org/W3210132809",
    "https://openalex.org/W2300733940",
    "https://openalex.org/W2922172590",
    "https://openalex.org/W6756040250",
    "https://openalex.org/W6675354045",
    "https://openalex.org/W6621483976",
    "https://openalex.org/W2964952717",
    "https://openalex.org/W3093206758",
    "https://openalex.org/W6807384801",
    "https://openalex.org/W2571990848",
    "https://openalex.org/W2578528541",
    "https://openalex.org/W6767098714",
    "https://openalex.org/W4287642280",
    "https://openalex.org/W2899771611",
    "https://openalex.org/W2302890201",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W4221166193",
    "https://openalex.org/W650350307",
    "https://openalex.org/W2604314403",
    "https://openalex.org/W2338508252",
    "https://openalex.org/W4210257598",
    "https://openalex.org/W3113177135",
    "https://openalex.org/W1997273776",
    "https://openalex.org/W2970066309",
    "https://openalex.org/W4220885120"
  ],
  "abstract": "Modeling and predicting the performance of students in collaborative learning paradigms is an important task. Most of the research presented in literature regarding collaborative learning focuses on the discussion forums and social learning networks. There are only a few works that investigate how students interact with each other in team projects and how such interactions affect their academic performance. In order to bridge this gap, we choose a software engineering course as the study subject. The students who participate in a software engineering course are required to team up and complete a software project together. In this work, we construct an interaction graph based on the activities of students grouped in various teams. Based on this student interaction graph, we present an extended graph transformer framework for collaborative learning (CLGT) for evaluating and predicting the performance of students. Moreover, the proposed CLGT contains an interpretation module that explains the prediction results and visualizes the student interaction patterns. The experimental results confirm that the proposed CLGT outperforms the baseline models in terms of performing predictions based on the real-world datasets. Moreover, the proposed CLGT differentiates the students with poor performance in the collaborative learning paradigm and gives teachers early warnings, so that appropriate assistance can be provided.",
  "full_text": "CLGT: A Graph Transformer for Student Performance Prediction\nin Collaborative Learning\nTianhao Peng1,2, Yu Liang3*, Wenjun Wu1,4, Jian Ren1,2, Zhao Pengrui1,2, Yanjun Pu1,2\n1State Key Laboratory of Software Development Environment, Beihang University\n2School of Computer Science and Engineering, Beihang University\n3Beijing Engineering Research Center for IoT Software and Systems, Beijing University of Technology\n4Institute of Artificial Intelligence, Beihang University\n{pengtianhao,wwj09315,renjian,zhaopengrui,buaapyj}@buaa.edu.cn, yuliang@bjut.edu.cn\nAbstract\nModeling and predicting the performance of students in col-\nlaborative learning paradigms is an important task. Most of\nthe research presented in literature regarding collaborative\nlearning focuses on the discussion forums and social learning\nnetworks. There are only a few works that investigate how\nstudents interact with each other in team projects and how\nsuch interactions affect their academic performance. In order\nto bridge this gap, we choose a software engineering course\nas the study subject. The students who participate in a soft-\nware engineering course are required to team up and complete\na software project together. In this work, we construct an in-\nteraction graph based on the activities of students grouped in\nvarious teams. Based on this student interaction graph, we\npresent an extended graph transformer framework for col-\nlaborative learning (CLGT) for evaluating and predicting the\nperformance of students. Moreover, the proposed CLGT con-\ntains an interpretation module that explains the prediction re-\nsults and visualizes the student interaction patterns. The ex-\nperimental results confirm that the proposed CLGT outper-\nforms the baseline models in terms of performing predictions\nbased on the real-world datasets. Moreover, the proposed\nCLGT differentiates the students with poor performance in\nthe collaborative learning paradigm and gives teachers early\nwarnings, so that appropriate assistance can be provided.\nIntroduction\nIn modern world, the collaborative learning (CL) is a preva-\nlent learning method. In a CL environment, the students\nof different calibers and intellectual levels work together in\nteams and engage in a common task (Laal and Laal 2012).\nThe process of modeling and predicting the performance of\nstudents is an important task in CL. Software engineering\n(SE) is an educational program that combines theory and\npractice. The practical teaching forms the core of SE pro-\ngram. As the practical teaching includes considerable CL,\nwe choose SE as the subject in this work.\nThe SE courses often incorporate team-based collabora-\ntive projects that are designed to mimic the professional\nsoftware development tasks. These tasks are often more\n*Corresponding author\nCopyright ¬© 2023, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\ncomplex as compared to individual coding exercises imple-\nmented in other programming classes. In these tasks, each\nstudent in the study group needs to participate and work\ntogether on a medium scale software project following the\nclassic life cycle of SE, following requirement specifica-\ntions, architectural design, and coding. The final score of\neach student depends on their contribution in the project and\nthe quality of the final software artifacts delivered by the\nteam. In order to accurately and efficiently evaluate the aca-\ndemic performance of each student in a team project, the\ninstructor needs an intelligent educational tool for analyzing\nthe process of every project by mining the students‚Äô behavior\ndata, especially the interaction behaviors.\nHowever, it remains a challenge for the instructors in the\nfield of SE to score the team members by considering their\nindividual contributions in the projects. This is mainly due\nto the difficulty in capturing and quantifying the amount\nof individual effort and work (Parizi, Spoletini, and Singh\n2018). A typical solution is to adopt either peer evalua-\ntion or assessing the team as a whole. However, both ap-\nproaches can be inaccurate and prejudiced, resulting in an\nunfair assessment. Currently, with the introduction of on-\nline CL platforms, such as GitHub and GitLab, it is possi-\nble to collect the behavioral data of students, such as source\ncode submissions and review postings. The availability of\nonline behavior data enables the researchers to apply the\nmachine-learning algorithms for CL (Olsen, Aleven, and\nRummel 2015; Yee-King, Grimalt-Reynes, and d‚ÄôInverno\n2016; Ekuban et al. 2020; Yee-King and d‚ÄôInverno 2016).\nHowever, these methods are mostly developed based on the\nclassic machine learning models that choose the activity fre-\nquency of students as input features. Such coarse-granular\nfeatures are unable to capture the rich spatial and temporal\ninformation embedded in the interaction of different team\nmembers, thus only presenting a limited value to the instruc-\ntors.\nThe CL data contains interactive activities with the graph\nstructured features, where the nodes represent the students\nand the edges between two students represent the interac-\ntions between them. There are often different kinds of in-\nteractions among the students, such as submitting docu-\nments and source codes, as well as posting reviews and\nissues. Each kind of edge has multiple attributes and has\nThe Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23)\n15947\na potential impact on the final grade of students. Thus,\nthe graph-structured interactive behaviors are formulated as\na weighted heterogeneous graph, which contains not only\nmultiple types of edges, but also the additional informa-\ntion features regarding each type of edge. In order to effec-\ntively exploit the rich edge feature information, in this work,\nwe propose a method for processing the CL data and an\nextended G\nraph T ransformer framework for C ollaborative\nLearning (CLGT). We implement the proposed model and\ncompare its performance with Ada Boost (Freund and\nSchapire 1997), relational graph convolutional network (R-\nGCN) (Schlichtkrull et al. 2018), graph transformer network\n(GTN) (Yun et al. 2019) and Graph Trans (Dwivedi and\nBresson 2020) based on the same dataset for predicting the\nperformance of the students. The experimental results show\nthat the proposed model outperforms four other models.\nIn addition to performance prediction, an instructor also\nneeds intelligent tutoring tools to infer the latent impact\nof student interactions on the process of collaborative soft-\nware development. For instance, the online questioning-\nanswering and code submissions are recorded on the CL\nplatform, however, the implicit activities, such as getting in-\nspiration from reading other‚Äôs documents and codes is dif-\nficult to measure. Moreover, it is noteworthy that most of\nthe deep learning models are inherently designed as black\nboxes, which are not able to provide good explanations re-\ngarding their reasoning mechanisms. Both factors, including\nthe unobserved activities and the nature of the model makes\nit difficult to present the explainable prediction results to the\ninstructors of SE courses. Therefore, in this work, we build\nan interpretation model inspired by PGM-Explainer (Vu and\nThai 2020) to explain the prediction results of the proposed\nCLGT model. Based on the results of the interpretation\nmodel, we are able to analyze whether the students influence\ntheir peers during the learning process and to what extent.\nThe major contributions of this work are summarized be-\nlow.\n1. In this work, we extend the graph transformer model to\ndevelop the CLGT model for accurately predicting and\nassessing the performance of students in a project-based\nCL environment.\n2. We build an interpretation module for explaining that\nwhich part of the graph structure data is responsible for\nthe prediction results of the proposed CLGT framework.\n3. To facilitate further research, we publish our dataset of\nstudents CL activities generated from an online project-\nbased SE course. The relevant code and dataset are pub-\nlicly available in the code repository 1.\nRelated Works\nThere are some works presented in literature for measur-\ning the contribution of each individual in the projects re-\nlated to software engineering courses. The log data and ac-\ntivity records available in version control systems are used\nin collaborative software development (Arcelli Fontana and\nRaibulet 2017; Loeliger and McCullough 2012; Clifton,\n1https://github.com/Tianhao-Peng/CLGT/\nKaczmarczyk, and Mrozek 2007; Reid and Wilson 2005),\nthus enabling the researchers to gather data regarding the\ncomputing contribution metrics. Most of the methods pre-\nsented in literature (Parizi, Spoletini, and Singh 2018; Buf-\nfardi 2020) utilize classic statistics and regression algo-\nrithms for assessing the contribution of a member based on\nthe activity ratio among the metrics of team members, in-\ncluding the number of commits, pull requests, and the lines\nof code changed by this member. However, these methods\nfail to consider and reflect the interactive activities that oc-\ncur during the software development process. Fu et al. (Fu\net al. 2021) constructed a developer interaction graph based\non the data obtained from GitHub (a git repository man-\nager) for identifying the key developers bridging messages\nacross the GitHub communities. This method only studies\nthe structural properties of large-scale interaction networks\nin the professional software development communities with-\nout any attention to the topics of small- or medium-sized stu-\ndent interaction networks in collaborative learning. To the\nbest of our knowledge, the proposed work is a first attempt\nthat focuses on predicting the performance of students based\non their interactive graph in software engineering courses.\nIt is noteworthy that most of the research efforts regard-\ning the learning outcome prediction have focused on model-\ning the performance of students based on individual learn-\ning process (Corbett and Anderson 1994; Pavlik Jr, Cen,\nand Koedinger 2009; Piech et al. 2015; Pu et al. 2019;\nLiang et al. 2022). However, the individual analytic mod-\nels cannot be applied directly in collaborative learning en-\nvironments since they do not consider the influence of the\nstudents within a team or between different teams. There\nare few works that make an effort to extend the models\ndesigned specifically for individual learning to team-based\nlearning scenarios. Olsen et al. (Olsen, Aleven, and Rummel\n2015) extended the additive factors model (Pavlik Jr, Cen,\nand Koedinger 2009) by using cooperative features to pre-\ndict the performance of students in a collaborative learning\nenvironment. Yee-King et al. (Yee-King, Grimalt-Reynes,\nand d‚ÄôInverno 2016) employed K-nearest neighbour (KNN)\nmodel to make predictions on the grades of students in a\ncollaborative learning environment. Ekuban et al. (Ekuban\net al. 2020) evaluated multiple machine learning models, in-\ncluding decision tree, random forest, extra trees, Ada Boost,\nand gradient boosting to predict the performance of students\nworking in a team based on student interactions. However,\nthe models discussed above are shallow and have a limited\nperformance in terms of handling large scale datasets and\nmodeling complex graph-structured data based on spatio-\ntemporal features.\nThe graph neural network (GNN) is a suitable frame-\nwork for modeling complex interactions. The applications\nof GNN are widespread, ranging from image classifica-\ntion and video processing to speech recognition and natu-\nral language processing (Wu et al. 2020). However, there\nare few research works that use GNN for modeling stu-\ndent interactions in a collaborative learning environment.\nThe R-GCN (Schlichtkrull et al. 2018) proposes relation-\nspecific transformation in the message passing steps to deal\nwith various relations in edges. GTN (Yun et al. 2019) pro-\n15948\nWriting documents within teams\nWeek 1\nReviewing projects of other teams\nWeek 3\nWriting codes within teams\nWeek 2\nReviewing projects of other teams\nWeek 16\nFigure 1: The flowchart of the three cycle phases of the SE course. During the documentation and coding phase, the students\ninteract with other members of their teams, and during the reviewing phase, the integration occurs between the teams as well.\nAs shown in the figure, the interaction graphs within and between the teams may change on weekly basis.\nposes a novel graph transformer layer to identify the con-\nnections between unconnected nodes that are closely related.\nGraph Trans (Dwivedi and Bresson 2020) proposes an ele-\ngant positional encoding strategy based on the eigenvectors\nof the graph Laplacian to apply attention to neighbouring\nnodes. However, these models cannot fully and efficiently\nutilize the extra edge information of weighted heterogeneous\ngraphs in some datasets which contain not only multiple\ntypes of edges, but also additional information features of\neach type of edge.\nMoreover, there has been little work devoted to explain-\ning collaborative learning activities with explainable mod-\nels. Without reasoning the underlying mechanisms behind\nthe predictions, deep models cannot be fully used in col-\nlaborative learning. PGM-Explainer (Vu and Thai 2020) is\nan explanation method that explains the predictions of any\nGNN in an interpretable manner. It has great performance in\ninterpreting graph-structured data, including node prediction\ntasks.\nProblem Statement\nIn this work, we aim to model the performance of students\nduring the implementation of SE projects for exploring their\ninteractions with each other team members, and the influ-\nence of these interactions on the academic performance of\nstudents in a CL environment.\nThe goal of any software engineering course is to en-\nable the students to master a variety of software engineer-\ning skills. The learning activities designed to achieve these\nlearning goals are divided into a three-phase cycle, includ-\ning writing documents, coding, and reviewing projects of\nother teams, as presented in Fig. 1. During the documenta-\ntion phase, the students are required to submit various files.\nEach change in these files can be tracked by using a ver-\nsion control system. During the coding phase, the students\ncommit code on the course website. Finally, during the re-\nviewing phase, the students review the documents and codes\nof other teams and point out the problems by raising issues\non the course website. Each problem raised by students has\na degree rating, which indicates the severity of that problem.\nWhen students commit the revised documents or code in the\nrepository, the rest of the team can view these changes and\ncontinue their development by considering these changes.\nTherefore, we assume that the commit behavior affects all\nthe other members of the team. When a student raises a prob-\nlem on a project of another team by creating an issue, all the\nmembers of that team have to work together to fix the project\nbased on the raised issue. Therefore, we believe that the be-\nhavior of issue affects all the members of the team.\nAs presented in Fig. 1, the collaborative learning activ-\nities have peculiar spatial and temporal characteristics. In\nterms of spatial characteristics, the interaction activities re-\nflect the structural influence relationships among the stu-\ndents in the course. In terms of temporal characteristics, the\ninteraction graph keeps changing as the course progresses.\nThe machine learning models, such as Ada Boost, KNN,\nand decision trees, currently used in collaborative learn-\ning research (Olsen, Aleven, and Rummel 2015; Pavlik Jr,\nCen, and Koedinger 2009; Yee-King, Grimalt-Reynes, and\nd‚ÄôInverno 2016; Ekuban et al. 2020) are unable to deal with\nsuch complex spatio-temporal data. The GNNs are deep\nlearning models that have the ability to capture the graph de-\npendencies based on message passing between graph nodes.\nThe transformers have the ability to forecast time series\ndata (Min et al. 2022). In this work, we combine GNN and\nTransformer models to make full use of the spatio-temporal\nfeatures available in the data. We propose a new model\nCLGT based on Graph Trans (Dwivedi and Bresson 2020)\nfor modeling the interactions between the students partici-\npating in any software engineering course.\nInteraction Graph Generation\nIt is necessary to convert the data collected from the version\ncontrol system into a format that is usable by the neural net-\nworks. The students use a CL platform as a repository for\ncode and document projects. The CL platform records the\ndetails regarding each change a student makes in any file.\nTherefore, the nature and place of the change are known.\nThe data type of the interaction graph can be generated\nbased on the recorded information. In this work, we require a\ndefinition that can validate if a construct is an instance of an\ninteraction graph. We identify three necessary and sufficient\nconditions for interaction graphs.\n1. An interaction graph is described by a graph G = (V, E),\nwhere V denotes a set of vertices and E denotes a set of\nedges such that E ‚àà V √ó V. All the edges are directed\nfrom one vertex to another. This indicates that one vertex\ninteracts with other vertices.\n2. Each vertex V represents a student, and each student is\n15949\nùíóùíä\nùíç{ùíÜùíäùíã\nùíç }{ùíòùíäùíã\nùíç }\nùëΩùíå,ùíçùë¨ùíå,ùíçùë¨ùíòùíÜùíäùíàùíâùíï\nùíå,ùíç ùë∏ùíå,ùíç ùë≤ùíå,ùíç\nLinear projection layer\nScaling\nProduct\nSum\nConcat\nNorm & Residual\nùíâùíäùíã\nùíå,ùíç\n‡∑°ùíâùíäùíã\nùíå,ùíç\n{ùíòùíäùíã\nùíç+ùüè} {ùíÜùíäùíã\nùíç+ùüè} ùíóùíä\nùíç+ùüè\nsoftmax\n√ó K\nheads\n√ó L\nlayers\n{ùíóùíã\nùíç}\nData Generation\nVariable Selection\nStructure Learning\nPerturbed \nGraph\nPrediction \nGraph\nExplanation\nFigure 2: The architecture for the CLGT framework, including the prediction module (Left) and the explainer module (Right).\nthe part of a team.\n3. Edges E represents the interactions between different\nvertexes V. There are two types of edges, including inter-\nactions between students within the same team and inter-\nactions between different teams. Additionally, each edge\ntype has different weights, depicting the degree of influ-\nence of the interaction activity.\nSince there are multiple types of edges in an interaction\ngraph and each edge type has multiple types of attributes, an\ninteraction graph is a weighted heterogeneous graph.\nInteraction Degree Definitions\nIn order to accurately depict the interaction activities be-\ntween the students, we consider the revised lines in the docu-\nments and the codes. The issue depict the degree of influence\nof an interaction activity. The definition of the interaction\ndegree of documents, codes, and issues is as follows.\n1. For the interaction activities of document revision adoc,\nthe version control system record the number of lines\nadded or deleted in the documentnumdoc, which indicates\nthe degree of influence of the revision activity. Since the\ndocument revision activity is available to the students\nwithin the same team, we normalize the number of lines\nnumdoc between all commits performed in one week, as\nfollows:\nI(ai\ndoc) =\nnumi\ndoc\nPn\nk=0 numk\ndoc\nwhere I(ai\ndoc) indicates the influence of the document re-\nvision activity ai\ndoc.\n2. As the interaction activities regarding code revision acode\nare available to the students within the same team, we\nprocess the data similar to the previous step. We normal-\nize the number of lines numcode between all the commits\nperformed in one week, as follows:\nI(ai\ncode) =\nnumi\ncode\nPn\nk=0 numk\ncode\nwhere I(ai\ncode) denotes the influence of the code revision\nactivity ai\ncode.\n3. For the interaction activities regarding the creation of is-\nsues aissue , each issue records the severity of the problems\nraised in the issue. We normalize the severity of the issues\nnumissue between all issues incorporated in one week, as\nfollows:\nI(ai\nissue ) = numi\nissue\nPn\nk=0 numk\nissue\nwhere I(ai\nissue ) denotes the influence of the code revision\nactivity ai\nissue .\nBased on the normalized data of the document revision,\ncode revision, and issue related activities, we generate the\ninteraction matrix, which is used as the input of the model.\nInteraction Matrix Generation\nOnce an interaction graph is generated based on the col-\nlected commit records and issue data, it can be converted\ninto an interaction matrix. For a simple graph with vertex\nset V = v1, ¬∑ ¬∑ ¬∑, vn, the interaction matrix A is a square ma-\ntrix of dimension n √ó n. The value of Ai j represents whether\n15950\nvertex vi interacts with vj. Zero denotes that there is no in-\nteraction, while a positive number indicates the influence of\nthe interaction. Since the interaction graph is directed, the\ninteraction matrix is asymmetric. Especially, the diagonal el-\nements of a matrix are zero, as the edges (cycles) from the\nvertices pointing towards themselves are not allowed in the\ninteraction graphs.\nPrediction Module\nThe proposed prediction module of CLGT framework is in-\nspired by the Graph Trans (Dwivedi and Bresson 2020).It is\ndesigned to effectively utilize the rich edge feature informa-\ntion in collaborative learning. It is notable that original graph\ntrans model only considers heterogeneous graphs that con-\ntain multiple types of edges and does not consider the case\nwhere the weighted heterogeneous graph contains additional\ninformation features regarding the type of each edge. For in-\nstance, in our software engineering course dataset, the edges\nrepresent different interactions, and each interaction activity\nhas a varying degree of influence. In order to address this\nproblem, we add a pipeline for the weighted edge features\nbased on the original model for making full use of edge\ninformation available in the graph. Fig. 2 (Left) illustrates\nthe prediction module of CLGT framework. The prediction\nmodule comprises an extra edge feature pipeline and an ex-\ntra weighted edge feature pipeline to effectively utilize the\navailable edge information.\nGiven the interaction graph G = (V, E), we pass the input\nnode vi for each node i, edge features ei j and weighted edge\nfeatures wi j for each edge between node i and node j via a\nlinear projection layer to embed these tod‚àídimensional hid-\nden features v0\ni , e0\ni j and w0\ni j. After the input layer, the pipeline\npropagates edge attributes from one layer to another, and the\nlayer update equations are as follows.\nhk,‚Ñì\ni j =\nÔ£´Ô£¨Ô£¨Ô£¨\nÔ£¨Ô£¨Ô£≠\nQk,‚Ñìv‚Ñì\ni ¬∑ Kk,‚Ñìv‚Ñì\nj\n‚àödk\nÔ£∂Ô£∑Ô£∑Ô£∑\nÔ£∑Ô£∑Ô£∏ ¬∑ Ek,‚Ñìe‚Ñì\ni j ¬∑ Ek,‚Ñì\nweightw‚Ñì\ni j (1)\nÀÜhk,‚Ñì\ni j =\nX\nj‚ààNi\nso f tmax(hk,‚Ñì\ni j )Vk,‚Ñìv‚Ñì\nj (2)\nwhere Qk,‚Ñì, Kk,‚Ñì, Vk,‚Ñì ‚àà Rdk√ód are trainable parameter ma-\ntrices, k denotes the number of attention heads, Ni denotes\nthe neighbors of node i. The outputs of hk,‚Ñì\ni j and ÀÜhk,‚Ñì\ni j in at-\ntention heads are then concatenated and passed via residual\nconnection layers as follows.\nv‚Ñì+1\ni = Fr(Fc(ÀÜhk,‚Ñì\ni j ) + v‚Ñì\ni ) (3)\ne‚Ñì+1\ni = Fr(Fc(hk,‚Ñì\ni j ) + e‚Ñì\ni ) (4)\nw‚Ñì+1\ni = Fr(Fc(hk,‚Ñì\ni j ) + w‚Ñì\ni ) (5)\nwhere v‚Ñì+1\ni , e‚Ñì+1\ni , w‚Ñì+1\ni denotes the output of‚Ñì layer and the\ninput of ‚Ñì + 1 layer, Fc denotes the concat operation, Fr de-\nnotes the normalization and residual connection operation.\nThe task of the model is node classification, e‚Ñì\ni , w‚Ñì\ni repre-\nsent the intermediate results, and v‚Ñì\ni in each layer is passed\nto a fully connected layer to compute the prediction scores.\nExplainer Module\nIn order to understand the underlying mechanisms behind\nthe predictions, and present the explainable prediction re-\nsults, we build an explainer module for the prediction\nmodule. This explainer module is inspired by the PGM-\nExplainer (Vu and Thai 2020) and elaborates the process\nbased on which the proposed CLGT makes predictions.\nMoreover, it also shows the part of the graph structure data\nthat is responsible for the prediction results.\nAs presented in Fig. 2 (Right), the workflow of the ex-\nplainer module can be roughly divided into three stages.\n1. Data Generation The explainer module repeatedly per-\nturbs the nodes in the original graph data and feeds the\nperturbed graph data to the proposed CLGT for obtaining\nthe sampled data. This sample data contains node infor-\nmation and prediction results.\n2. Variable Selection Based on the sampled data, a pair-\nwise dependency test is used to form an approximate\nMarkov blanket for the target node to reduce the com-\nputational overhead and obtain all the potential statistics\nof the target node.\n3. Structure Learning The explainer module uses a hill-\nclimbing algorithm for maximizing the Bayesian infor-\nmation criterion (BIC) score in order to obtain an ex-\nplanatory Bayesian network. The explainer module gen-\nerates a weighted graph with the same number of nodes\nas the original input graph. The edge shows the influence\nof one node on the prediction result of the other node.\nExperiments\nDataset\nThe object of this work include teams of students from a\nsoftware engineering graduate course conducted in Spring\n2021. In this course, a GitLab-based website 2 is selected\nto implement the CL platform. We aim to study the inter-\nactions of students, when performing software engineering\nprojects assigned in a semester to explore the ways students\ninteract with each other in team projects and the effect of\nsuch interactions on the academic performance of students\nin a CL environment. The software engineering course lasted\n16 weeks and comprised three different sessions, including\nwriting documents, writing code, and reviewing projects of\nother teams. We acquire all the commits and issues avail-\nable within the GitLab during the 16-week course. We obtain\n4,903 commit records and 862 issues. Each commit records\nthe number of lines added or deleted from the documents\nand code. Each issue records the severity of the problems\nraised in the issue. Each week, the teacher classified stu-\ndents‚Äô grades into three categories (A, B, C) based on the\nquality and quantity of documentation and code contributed\nin the software engineering project.\nData Process\nBased on the proposed method, the interaction graphs and\ninteraction matrices are easily generated. As the course\n2https://gitlab.com/\n15951\n(a) Visualization of the output of the explainer module\n (b) Subgraph of Fig. 3(a)\nFigure 3: (a) presents the visualization of the output of the explainer module. The nodes represent the students, and the edges\nrepresent the influence of students on each other. Different teams are denoted by different colors. The student 58 of team 9 is\nspecially marked with ‚ú∞, which is further analyzed in (b). (b) presents the visualization of part of the Fig. 3(a). Different colors\nin the inner circle represent different teams, and the outer circular sector represents different students of the corresponding\nteams. The proportion of the sector indicates the degree of influence of a team and its members on the middle student. The\nlarger the proportion, the greater the influence.\nlasted for 16 weeks and the teacher graded each student\nweekly, we divide the acquired data into 16 sections. In each\nsection, we generate an interaction graph and three corre-\nsponding matrices, namely addition, deletion, and issue ma-\ntrices. The addition matrix (or the deletion matrix) considers\nthe members of the same team only and depict the influence\nof adding (or deleting) documents and codes on the mem-\nbers of the same team. The issue matrix considers the mem-\nbers of different teams and represents the influence of issues\nraised by one team on the members of other teams. Since the\nnumber of lines of code and documentation in each commit\nvary considerably, and there is a need for quantifying the\nseverity of raised issues, we divide them into three levels,\ni.e., minor, moderate, and severe levels. After division, we\nobtain 48 matrices, i.e., three matrices per week. Now, each\nmatrix consists of three types of elements, representing the\ninfluence from one vertex to another.\nThe purpose of the proposed CLGT is node classification.\nThe labels of each node include the weekly and final grades\nof the students in the published dataset. The weekly and final\ngrades of students are assigned by the teacher based on the\nquality and quantity of documentation and code contributed\nin the software engineering project.\nBaselines and Experimental Setup\nIn the experiments, we compare the proposed CLGT with\nAda Boost and three state-of-the-art graph neural networks.\nThe CLGT, Ada Boost, R-GCN, GTN and Graph Trans are\nconstructed using Pytorch (Paszke et al. 2017) and scikit-\nlearn (Pedregosa et al. 2011). For Ada Boost model, we\nuse sklearn.ensemble.AdaBoostClassifier with 100 week es-\ntimators given the cumulative average number of GitLab\npushes per week, and the total number of lines of docu-\nmentation and code added, deleted, and modified per week.\nIn the case of R-GCN and GTN models, the Adam opti-\nmizer is used and the hyperparameters, including learning\nrate, weight decay etc. are selected appropriately so that each\nbaseline yields its best performance. For the original graph\ntrans model and the proposed CLGT model, we use 10 graph\ntransformer layers, where each layer comprises 8 attention\nheads and arbitrary hidden dimensions. Therefore, the total\nnumber of trainable parameters is in the range of 588k and\n855k. We use the learning rate decay strategy for training\nthe models. The training process is stopped when the learn-\ning rate reaches a value of 1 √ó 10‚àí6.\nResults and Discussion\nPrediction Results\nThe experimental results are presented in Table 1. For the\nsake of comparison, we implement the proposed CLGT\nmodel, R-GCN, GTN, Graph Trans model and Ada Boost\non the same dataset we collected. In this work, the accuracy\n(ACC), the F1-score and the average and standard deviation\nof the area under the ROC curve (AUC) are used as eval-\nuation metrics. The larger the AUC, F1-score or ACC, the\nbetter the model‚Äôs prediction performance.\nExperimental results show that CLGT model performs\nbetter as compared to Ada Boost, R-GCN, GTN, and Graph\nTrans model in terms of ACC, F1-score, and AUC. The out-\nstanding performance of the proposed model shows better\nutilization of rich edge and weighted edge feature informa-\ntion as compared to the baseline models. The proposed ar-\nchitecture specifically ensures better utilization of datasets\nthat not only contain multiple types of edges, but also addi-\ntional information features regarding the type of each edge.\n15952\nteam 1 team 2 team 3 team 4 team 5 team 6 team 7 team 8 team 9 team 10 team 11\nstu1-6 stu7-13 stu14-19 stu20-27 stu42-48 stu49-55 stu56-61 stu62-69stu28-34 stu35-41 stu70-75\nweek16week1\nFigure 4: The horizontal axis represents all the 75 students in the course. The vertical axis represents the 16 weeks during which\nthe course is conducted. The shades of color represent the activeness of students in the course, with darker colors representing\nmore active students. Additionally, 75 students are divided into 11 teams, with each block in the figure representing a team.\nMethod ACC F1-score AUC\nAda Boost 41.53¬±1.30 29.36¬±1.82 48.81¬±1.05\nR-GCN 64.81¬±2.13 52.64¬±1.83 76.54¬±2.60\nGTN 73.37¬±2.32 62.79¬±2.25 78.84¬±1.12\nGraph Trans 72.46¬±2.08 59.04¬±1.84 86.21¬±1.73\nCLGT(ours) 73.92¬±1.78 66.75¬±2.15 90.57¬±1.88\nTable 1: The prediction performances of the proposed\nCLGT, Ada Boost, R-GCN, GTN, and Graph Trans model\nbased on the same dataset. The best results are highlighted.\nCase Study and Visualization\nIn order to explore the explainability of the predicted results\nobtained using the proposed CLGT model, we build an ex-\nplainer module that generates a weighted graph. The edges\nof this weighted graph represent the influence of students on\neach other. The output of the weighted graph is visualized\n(as presented in Fig. 3(a)) for performing intuitive analysis.\n1. After considering a specific student, we explore which\nstudents have the greatest influence on him or her. In\nmost cases, the teammates have a greater influence on the\nstudents as compared to other team members. However,\nwe can also infer some information from the interpreta-\ntion results that is not reflected directly in the original\ninteraction graph. We process and visualize the subgraph\nof Fig. 3(a) in Fig. 3(b). The student 58 (in team 9) does\nnot interact with student 22 (in team 4). However, that\nstudent indirectly affects student 58 through the interac-\ntion with students in team 10 (there are direct interactions\nbetween team 4 and team 10). This shows that we can ex-\nplore potential relationships among different students to\nfurther analyze the role of student behavior.\n2. We explore how the influence of each student changes\nduring the course of 16 weeks. We process the data of\n16-week course in order to visualize the influence of all\nstudents in each week presented in Fig. 4. We find a high\ncorrelation between the students‚Äô influence and the teams\nthey belong to. Although some teams, e.g., team 10, do\nnot achieve the best grades, their overall influence is sig-\nnificantly bigger. On the contrary, other teams, e.g., team\n3, achieve better grades; however, their influence is not as\nhigh as their grades. We think this may reflect the under-\nlying characteristics of different teams, such as team 10\nbeing more active, but the overall quality of the project\ncode is poor. On the other hand, team 3 showcases the\nexactly opposite characteristics. These results enable the\ncourse instructors to build better student profiles and per-\nform accurate assessment based on the performance of\nstudents working in teams.\nConclusions\nIn this work, we investigate how students interact with each\nother in team projects and how such interactions affect the\nacademic performance of these students in the collabora-\ntive learning paradigm. We choose one-semester software\nengineering course to investigate and assess the collabora-\ntive learning activities of students. We propose a method\nfor extracting the activity data from an in-house Gitlab plat-\nform and constructing the interaction graph. Moreover, we\nalso introduce an extended graph transformer model named\nCLGT for accurately predicting the performance of students.\nWe also build an interpretation model for explaining the pre-\ndiction results of the proposed CLGT model and analyze the\ninfluence of each student on the teammates during the course\nproject. The experimental results confirm that the proposed\nCLGT model outperforms the state-of-art models and pro-\nvides good insights for the instructors to assess the learning\nprogress of students. Moreover, the proposed CLGT differ-\nentiates the students with poor performance in collaborative\nlearning and gives the teachers early warnings, so that ap-\npropriate assistance can be provided.\nAcknowledgments\nThis work is supported in part by the Science and Tech-\nnology Innovation 2030‚Äî‚ÄúNew Generation Artificial Intel-\nligence‚Äù Major Project (2018AAA0102300) and the State\nKey Laboratory of Software Development Environment\n(SKLSDE-2020ZX-01/2022KF-08/2022KF-10).\n15953\nReferences\nArcelli Fontana, F.; and Raibulet, C. 2017. Students‚Äô feed-\nback in using GitHub in a project development for a software\nengineering course. In Proceedings of the 2017 ACM Con-\nference on Innovation and Technology in Computer Science\nEducation, 380‚Äì380.\nBuffardi, K. 2020. Assessing individual contributions to\nsoftware engineering projects with git logs and user stories.\nIn Proceedings of the 51st ACM Technical Symposium on\nComputer Science Education, 650‚Äì656.\nClifton, C.; Kaczmarczyk, L. C.; and Mrozek, M. 2007. Sub-\nverting the fundamentals sequence: using version control to\nenhance course management. ACM SIGCSE Bulletin, 39(1):\n86‚Äì90.\nCorbett, A. T.; and Anderson, J. R. 1994. Knowledge\ntracing: Modeling the acquisition of procedural knowledge.\nUser modeling and user-adapted interaction, 4(4): 253‚Äì278.\nDwivedi, V . P.; and Bresson, X. 2020. A Generalization of\nTransformer Networks to Graphs. CoRR, abs/2012.09699.\nEkuban, A. B.; Mikroyannidis, A.; Third, A.; and\nDomingue, J. 2020. Using GitLab Interactions to Predict\nStudent Success When Working as Part of a Team. In Inter-\nnational Conference on Interactive Collaborative Learning,\n127‚Äì138. Springer.\nFreund, Y .; and Schapire, R. E. 1997. A Decision-Theoretic\nGeneralization of On-Line Learning and an Application to\nBoosting. J. Comput. Syst. Sci., 55(1): 119‚Äì139.\nFu, E.; Zhuang, Y .; Zhang, J.; Zhang, J.; and Chen, Y . 2021.\nUnderstanding the User Interactions on GitHub: A Social\nNetwork Perspective. In 2021 IEEE 24th International Con-\nference on Computer Supported Cooperative Work in De-\nsign (CSCWD), 1148‚Äì1153. IEEE.\nLaal, M.; and Laal, M. 2012. Collaborative learning: what is\nit? Procedia-Social and Behavioral Sciences, 31: 491‚Äì495.\nLiang, Y .; Peng, T.; Pu, Y .; and Wu, W. 2022. HELP-DKT:\nan interpretable cognitive model of how students learn pro-\ngramming based on deep knowledge tracing. Scientific Re-\nports, 12(1): 1‚Äì11.\nLoeliger, J.; and McCullough, M. 2012. Version Control\nwith Git: Powerful tools and techniques for collaborative\nsoftware development. ‚Äù O‚ÄôReilly Media, Inc.‚Äù.\nMin, E.; Chen, R.; Bian, Y .; Xu, T.; Zhao, K.; Huang, W.;\nZhao, P.; Huang, J.; Ananiadou, S.; and Rong, Y . 2022.\nTransformer for Graphs: An Overview from Architecture\nPerspective. arXiv preprint arXiv:2202.08455.\nOlsen, J. K.; Aleven, V .; and Rummel, N. 2015. Predicting\nStudent Performance in a Collaborative Learning Environ-\nment. International Educational Data Mining Society.\nParizi, R. M.; Spoletini, P.; and Singh, A. 2018. Measur-\ning team members‚Äô contributions in software engineering\nprojects using git-driven technology. In 2018 IEEE Fron-\ntiers in Education Conference (FIE), 1‚Äì5. IEEE.\nPaszke, A.; Gross, S.; Chintala, S.; Chanan, G.; Yang, E.;\nDeVito, Z.; Lin, Z.; Desmaison, A.; Antiga, L.; and Lerer,\nA. 2017. Automatic differentiation in pytorch. NeurIPS.\nPavlik Jr, P. I.; Cen, H.; and Koedinger, K. R. 2009. Perfor-\nmance Factors Analysis‚ÄìA New Alternative to Knowledge\nTracing. Online Submission.\nPedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V .;\nThirion, B.; Grisel, O.; Blondel, M.; Prettenhofer, P.; Weiss,\nR.; Dubourg, V .; Vanderplas, J.; Passos, A.; Cournapeau, D.;\nBrucher, M.; Perrot, M.; and Duchesnay, E. 2011. Scikit-\nlearn: Machine Learning in Python. Journal of Machine\nLearning Research, 12: 2825‚Äì2830.\nPiech, C.; Bassen, J.; Huang, J.; Ganguli, S.; Sahami, M.;\nGuibas, L. J.; and Sohl-Dickstein, J. 2015. Deep knowledge\ntracing. In Advances in neural information processing sys-\ntems, 505‚Äì513.\nPu, Y .; Wu, W.; Jiang, T.; Desmarais, M.; Lynch, C.; Mer-\nceron, A.; and Nkambou, R. 2019. ATC Framework: A fully\nAutomatic Cognitive Tracing Model for Student and Educa-\ntional Contents. In EDM.\nReid, K. L.; and Wilson, G. V . 2005. Learning by doing:\nintroducing version control as a way to manage student as-\nsignments. In Proceedings of the 36th SIGCSE technical\nsymposium on Computer science education, 272‚Äì276.\nSchlichtkrull, M.; Kipf, T. N.; Bloem, P.; Berg, R. v. d.;\nTitov, I.; and Welling, M. 2018. Modeling relational data\nwith graph convolutional networks. In European semantic\nweb conference, 593‚Äì607. Springer.\nVu, M.; and Thai, M. T. 2020. Pgm-explainer: Proba-\nbilistic graphical model explanations for graph neural net-\nworks. Advances in neural information processing systems,\n33: 12225‚Äì12235.\nWu, Z.; Pan, S.; Chen, F.; Long, G.; Zhang, C.; and Philip,\nS. Y . 2020. A comprehensive survey on graph neural net-\nworks. IEEE transactions on neural networks and learning\nsystems, 32(1): 4‚Äì24.\nYee-King, M.; and d‚ÄôInverno, M. 2016. Stimulating collab-\norative activity in online social learning environments with\nMarkov decision processes. In EDM, 652‚Äì653.\nYee-King, M.; Grimalt-Reynes, A.; and d‚ÄôInverno, M. 2016.\nPredicting student grades from online, collaborative social\nlearning metrics using K-NN. In EDM, 654‚Äì655.\nYun, S.; Jeong, M.; Kim, R.; Kang, J.; and Kim, H. J. 2019.\nGraph transformer networks. Advances in neural informa-\ntion processing systems, 32.\n15954",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.732776403427124
    },
    {
      "name": "Collaborative learning",
      "score": 0.5327850580215454
    },
    {
      "name": "Graph",
      "score": 0.5295670628547668
    },
    {
      "name": "Transformer",
      "score": 0.47982048988342285
    },
    {
      "name": "Software",
      "score": 0.46344566345214844
    },
    {
      "name": "Feature engineering",
      "score": 0.4301868677139282
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3586190938949585
    },
    {
      "name": "Mathematics education",
      "score": 0.3523787260055542
    },
    {
      "name": "Knowledge management",
      "score": 0.2562517523765564
    },
    {
      "name": "Deep learning",
      "score": 0.15992054343223572
    },
    {
      "name": "Theoretical computer science",
      "score": 0.13565579056739807
    },
    {
      "name": "Engineering",
      "score": 0.13226643204689026
    },
    {
      "name": "Psychology",
      "score": 0.08803483843803406
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ]
}