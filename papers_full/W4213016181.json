{
    "title": "Transformer Vibration Detection Based on YOLOv4 and Optical Flow in Background of High Proportion of Renewable Energy Access",
    "url": "https://openalex.org/W4213016181",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2104077544",
            "name": "Lei Su",
            "affiliations": [
                "Shanghai Electric (China)"
            ]
        },
        {
            "id": "https://openalex.org/A2096083575",
            "name": "Hua Huang",
            "affiliations": [
                "Shanghai Electric (China)"
            ]
        },
        {
            "id": "https://openalex.org/A2144853565",
            "name": "Lunming Qin",
            "affiliations": [
                "Shanghai University of Electric Power"
            ]
        },
        {
            "id": "https://openalex.org/A2105599710",
            "name": "Wenbin Zhao",
            "affiliations": [
                "Shanghai University of Electric Power"
            ]
        },
        {
            "id": "https://openalex.org/A2104077544",
            "name": "Lei Su",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2096083575",
            "name": "Hua Huang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2144853565",
            "name": "Lunming Qin",
            "affiliations": [
                "Shanghai University of Electric Power"
            ]
        },
        {
            "id": "https://openalex.org/A2105599710",
            "name": "Wenbin Zhao",
            "affiliations": [
                "Shanghai University of Electric Power"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2766476911",
        "https://openalex.org/W6680915801",
        "https://openalex.org/W3044841828",
        "https://openalex.org/W2149782216",
        "https://openalex.org/W2069616380",
        "https://openalex.org/W2028660383",
        "https://openalex.org/W2889626208",
        "https://openalex.org/W2531502724",
        "https://openalex.org/W1637731468",
        "https://openalex.org/W2560132615",
        "https://openalex.org/W1978073390",
        "https://openalex.org/W2127392509",
        "https://openalex.org/W2950907016",
        "https://openalex.org/W2004775482",
        "https://openalex.org/W1578285471",
        "https://openalex.org/W2894857097",
        "https://openalex.org/W6677605622",
        "https://openalex.org/W3037479016",
        "https://openalex.org/W6684350556",
        "https://openalex.org/W2986873299",
        "https://openalex.org/W2090469993",
        "https://openalex.org/W2794286598",
        "https://openalex.org/W1980627595",
        "https://openalex.org/W2509359033",
        "https://openalex.org/W2765375793",
        "https://openalex.org/W2566335221",
        "https://openalex.org/W3004063228",
        "https://openalex.org/W2599781079",
        "https://openalex.org/W2336212902",
        "https://openalex.org/W2914414110",
        "https://openalex.org/W3026588890",
        "https://openalex.org/W2572220918",
        "https://openalex.org/W2140238868",
        "https://openalex.org/W2163665416",
        "https://openalex.org/W3101541083",
        "https://openalex.org/W2116510919"
    ],
    "abstract": "In recent years, large-scale renewable energy access to substations has brought overload, harmonic, short circuit and other problems, which has led to an increase in the failure rate and shortening the service life of important power equipment such as transformers. Transformer is one of the key equipment in power system, and its operation status has an important impact on the safe and stable operation of power grid. In order to realize the real-time state evaluation of transformer, a real-time vibration signal detection method based on video is proposed in this paper. Firstly, YOLOv4 is used to detect the transformer object, and then the pyramid Lucas-Kanade optical flow method and Otsu method are used to calculate the transformer vibration vector. Experimental results show that the transformer vibration vector can be calculated in real time and accurately by using the proposed algorithm, so as to realize the real-time reliable analysis of the transformer state.",
    "full_text": "Transformer Vibration Detection\nBased on YOLOv4 and Optical Flow in\nBackground of High Proportion of\nRenewable Energy Access\nLei Su1, Hua Huang1, Lunming Qin2* and Wenbin Zhao3\n1State Grid Shanghai Electric Power Research Institute, Shanghai, China,2College of Electronic and Information Engineering,\nShanghai University of Electric Power, Shanghai, China,3College of Electric Power Engineering, Shanghai University of Electric\nPower, Shanghai, China\nIn recent years, large-scale renewable energy access to substations has brought overload,\nharmonic, short circuit and other problems, which has led to an increase in the failure rate\nand shortening the service life of important power equipment such as transformers.\nTransformer is one of the key equipment in power system, and its operation status has an\nimportant impact on the safe and stable operation of power grid. In order to realize the real-\ntime state evaluation of transformer, a real-time vibration signal detection method based\non video is proposed in this paper. Firstly, YOLOv4 is used to detect the transformer\nobject, and then the pyramid Lucas-Kanade optical ﬂow method and Otsu method\nare used to calculate the transformer vibration vector. Experimental results show that\nthe transformer vibration vector can be calculated in real time and accurately by using\nthe proposed algorithm, so as to realize the real-time reliable analysis of the\ntransformer state.\nKeywords: high proportion of renewable energy access, energy infrastructure, power transformer, vibration\ndetection, YOLOv4 model, pyramid lucas-kanade opticalﬂow, otsu algorithm\nINTRODUCTION\nIn response to the call of the state to vigorously develop new energy power generation, more and\nmore photovoltaic power stations and wind farms are connected to the power grid, which alleviates\nenergy shortage and environmental pollution, but also brings many threats to the power grid. In\nparticular, in order to save costs, some new energy power stations require direct access to the low-\nvoltage side of the substation and transmit electric energy to a higher voltage level through the\nsubstation. In this way, the adverse impact of new energy on the power grid will be directly applied to\nthe power transformer in the substation. As the upstream key equipment of the power system, the\ntransformer is not only expensive, but also undertakes tasks such as voltage conversion, power\ndistribution and transmission, and its operational reliability affects the operational safety of the\npower grid. Once the transformer fails, it may cause a large-scale blackout, which will cause huge\ndirect and indirect economic losses (Munir and Smit, 2011). Therefore, the research on early fault\ndetection and health status evaluation of power transformer is of great signiﬁcance to improve the\nreliability of power transformer and ensure the safe and stable operation of power grid.\nWith the advancement of intelligent technology (Zhao et al., 2020; Zhao et al., 2017), for\ntransformer maintenance, condition based maintenance is gradually adopted to replace the\ntraditional regular maintenance and post-accident maintenance. The condition based\nEdited by:\nMuhammad Wakil Shahzad,\nNorthumbria University,\nUnited Kingdom\nReviewed by:\nMuhammad Ahmad Jamil,\nNorthumbria University,\nUnited Kingdom\nNeeraj Dhanraj Bokde,\nAarhus University, Denmark\n*Correspondence:\nLunming Qin\nlunming.qin@Shiep.edu.cn\nSpecialty section:\nThis article was submitted to\nProcess and Energy Systems\nEngineering,\na section of the journal\nFrontiers in Energy Research\nReceived: 26 August 2021\nAccepted: 18 January 2022\nPublished: 14 February 2022\nCitation:\nSu L, Huang H, Qin L and Zhao W\n(2022) Transformer Vibration Detection\nBased on YOLOv4 and Optical Flow in\nBackground of High Proportion of\nRenewable Energy Access.\nFront. Energy Res. 10:764903.\ndoi: 10.3389/fenrg.2022.764903\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 7649031\nMETHODS\npublished: 14 February 2022\ndoi: 10.3389/fenrg.2022.764903\nmaintenance method mainly determines the maintenance\nstrategy based on the monitoring results of transformer\noperation status, so as to reduce the cost of equipment\nmaintenance, reduce shutdown loss and effectively prevent the\noccurrence of failures (Berler et al., 2000). Currently, transformer\ncondition assessment methods are mainly divided into two\ncategories: online monitoring and of ﬂine detection. On-line\nmonitoring can make the transformer need not be out of\noperation, can save manpower and material resources, and has\nits own obvious advantages. Commonly used online monitoring\nmethods of power transformers mainly include low-voltage pulse\nmethod, frequency response analysis method, gas\nchromatography analysis method of dissolved gas in\ntransformer oil, online monitoring method of transformer\npartial discharge and vibration analysis method of power\ntransformer (Judd et al., 2002 ). A major advantage of the\nvibration analysis method is that the detection system does\nnot have any form of electrical connection with the\ntransformer under test, which will not affect the normal\noperation of the power grid, fully guarantee the safety of\nonline monitoring and overcome the method of frequency\nresponse analysis, the method of short-circuit reactance, etc.\ncan only monitor the insufﬁciency of transformer mechanical\nfailure ofﬂine.\nResearch Status of Transformer Vibration\nAnalysis\nThe vibration analysis method uses the vibration sensor to\nmeasure the vibration signal on the surface of the transformer\noil tank, and then extracts the time-frequency domain\ncharacteristics contained to realize the on-line condition\nmonitoring of the transformer, which belongs to the external\ndetection and analysis method. In the mid to late 1990s, the idea\nof online monitoring of transformer operating status based on the\nvibration method was proposed. Although only Russia has used\nthis method in theﬁeld, the results have proved that the vibration\nmethod can be used for any type of transformer, and the accuracy\nrate is relatively high. Due to the lack of in-depth research on the\nvibration characteristics of windings and iron cores and lack of\nFIGURE 1 |YOLOv4 model structure.\nFIGURE 2 | (A)I represents the intensity of a pixel, and its related parameters are spatial position(x, y) and timet,t h a ti sI(x, y, t). (B) In the next frame, the pixel\nmoves the distance of(dx, dy), and the interval time isdt.\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 7649032\nSu et al. Transformer Vibration Detection\nexperience, there are still great limitations in monitoring winding\nand iron core faults (Borucki, 2012; Cao et al., 2013).\nWith the advancing of time, the research on the transformer\nvibration method is also intensiﬁed. Berler et al. (2000)conducted\na no-load and load control test on the transformer, and obtained\nthe transformer box vibration when the iron core and the winding\nacted separately, and the experiment Laboratory research has\ntaken a big step forward.Garcia et al. (2006a)and Garcia et al.\n(2006b) studied the relationship between vibration amplitude and\nphase and operating voltage, load current and temperature,\nestablished a mathematical model of fundamental frequency\namplitude and operating voltage, load current and\ntemperature, and obtained the fundamental frequency of\nwinding and core vibration. The amplitude is proportional to\nthe square of the load current and the operating voltage. This\nconclusion has played an important guiding role in subsequent\ntransformer research.\nResearch Status of Vibration Signal\nDetection\nThe detection of transformer vibration signal is an important\npremise for analyzing and evaluating transformer operation state\nand fault diagnosis. At present, vibration signal detection is\nwidely used in various engineering applications such as\nmachinery, vehicles, construction, aerospace, etc., and has\nbecome an important research direction in the ﬁeld of\nengineering measurement ( Wadhwa et al., 2016 ). The\ndetection methods of vibration signals can be roughly divided\ninto two categories: contact vibration measurement and non-\ncontact vibration measurement. The traditional contact vibration\nmeasurement mainly adopts the method of installing sensors on\nsite, which has many defects. Since the contact sensor needs to be\narranged point by point, the measurement range is limited. In\naddition, it is necessary to ﬁnd a ﬁxed reference object or\nreference point when performing displacement monitoring. At\npresent, the commonly used non-contact vibration measurement\nis mainly divided into two categories: laser vibration\nmeasurement and visual vibration measurement methods\nbased on video images. The laser vibration measurement\nmethod is mainly based on the principle of light interference,\nwhich has the advantages of extremely high accuracy and\nsensitivity, long measurement distance, and high measurement\nfrequency. The current prices of laser vibration measurement\nrelated equipment are very expensive and the requirements for\nthe professionalism of the operators are also high, which greatly\nrestricts its large-scale promotion and application, and is\ncurrently often used in theﬁelds of aerospace and machinery\nmanufacturing.\nAs an emerging vibration measurement method, vision-based\nvibration detection has received extensive attention from scholars\nat home and abroad (Hati and Nelson, 2019; Feng et al., 2017;\nChen et al., 2015; Wadhwa et al., 2017; Sarraﬁ et al., 2018; Choi\nand Han, 2018; Peng et al., 2020; Aoyama et al., 2018; Moya-\nAlbor et al., 2020; Zhang et al., 2019). Visual vibration detection\ntechniques can be divided into two categories according to\nwhether optical targets are needed. Digital image correlation\n(DIC), marker tracking, and point tracking are typical\ntechnologies that need to manually set markers on test objects\nas optical targets for computer vision processing. Different from\ntraditional measurement techniques based on contact sensor,\nDIC has been successfully applied to two-dimensional and\nthree-dimensional vibration measurement, so as to provide\nfull-ﬁeld synchronous vibration information ( Yu and Pan,\n2017; Helfrick et al., 2011 ). Mark tracking uses computer\nvision methods to determine the coordinates of marks printed,\nprojected or mounted on test objects, and also provides good\nresults for vibration measurement (Feng et al., 2015; Long and\nPan, 2016).\nThe target-less method uniﬁes the internal features of test\nobjects for computer vision processing without manually setting\noptical objects on test objects. Therefore, the target-less method is\nsuitable for objects that are difﬁcult to access or on which optical\ntargets cannot be installed or printed (Long and Pan, 2016).\nPoudel et al. (2005)extracted time-history signals of displacement\nby using subpixel edge detection method to analyze the dynamic\ncharacteristics of test objects. However, the process of sub-pixel\nedge detection is complex, and the extraction of vibration time\nhistory needs a lot of pre-processing.Son et al. (2015)used non-\ncontact target-free visual method to measure the vibration\nfrequency and other characteristics of cylindrical objects in\ndangerous areas that are inaccessible to humans. However, this\nmethod is susceptible to the interference of brightness change.\nHuang et al. (2018)proposed a vibration measurement method\nnamed VVM based on computer vision, which is used to measure\ndynamic characteristics such as wind-induced dynamic\ndisplacement and acceleration responses. However, VVM uses\ntemplate matching to obtain the motion information of all pixels\nin the whole ROI, which increases the running time of the\nalgorithm. Yang et al. (2020) proposed a video-output-only\nmethod to extract the full- ﬁeld motion of a structure and\nseparate or reconstruct micro deformation mode and large\nobject motion. However, this method is also difﬁcult to adapt\nto harsh environment (different light intensity) and camera\nmeasurement angle. Optical ﬂow method has been the focus\nof computer vision research since its beginning. This technology\ndetermines the instantaneous velocity of speciﬁc pixels in an\nFIGURE 3 |Lucas-Kanade method: estimate the opticalﬂow of black\npixels.\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 7649033\nSu et al. Transformer Vibration Detection\nimage sequence and is widely used in motion tracking and\nestimation (Horn and Schunck, 1981). However, the accuracy\nassessment work shows that the relatively new optical ﬂow\ntechnology still faces a major obstacle in practical vibration\nmeasurement applications, that is, the optimal selection of\nactive feature points ( Diamond et al., 2017 ). Overall, video\nimage monitoring is a non-contact monitoring method that\ncan not only perform static measurements such as\ndisplacement and strain, but also suitable for dynamic\ncharacteristics measurement. It has the advantages of simple\noperation, non-contact, non-destructive, no additional quality,\nand can realize long-distance, large-scale multi-point monitoring,\netc., but there are also shortcomings such as the need to set\nobjects, the optimal selection of active feature points, and high\nrequirements for ambient light and background.\nMain Contributions\nTo solve the above problems, this paper proposes a novel vision-\nbased vibration detection method to realize the real-time state\nevaluation of transformer in the case of high proportion\nrenewable energy access. Speciﬁcally, our main contributions\nare summarized as follows.\n1) Based on the video signal of the transformer, this paperﬁrst\nuses transfer learning and YOLOv4 algorithm to detect the\ntransformer as the region of interest, so as to avoid setting the\ntarget manually.\n2) In this paper, Shi-Tomasi method is used to extract the feature\npoints in the region of interest to calculate the transformer\nvibration vector, so as to avoid the interference of ambient\nlight and background factors.\n3) In this paper, Otsu algorithm is used to select the optimal\nactive feature points, so as to improve the calculation accuracy\nof transformer vibration vector. Firstly, the vibration vectors\nof all feature points in the region of interest are calculated by\nthe pyramid Lucas-Kanade (LK) sparse opticalﬂow method.\nThen Otsu method is used toﬁnd the threshold of vibration\nvectors toﬁlter out the vibration vector with small modulus.\nFinally, the remaining vibration vectors are summed and\naveraged, and the obtained mean is the transformer\nvibration vector.\nThe remainder of the paper is organized as follows.\nBackground Section reviews the YOLOv4 model and the\npyramid LK opticalﬂow method. InProposed Method Section,\nthe proposed vision-based vibration detection method is\nintroduced in detail. The performance of the proposed\nvibration detection method is examined in Experimental\nResults and Analysis Section and the conclusion is given in\nConclusion Section.\nBACKGROUND\nYOLOv4 Model\nYOLOv4 is an efﬁcient and powerful object detection algorithm\nwhich combines a large number of existing technologies and\nmakes innovation to achieve a perfect balance between detection\nspeed and accuracy. The YOLOv4 model includes four parts:\ninput, the feature extraction network BackBone, the feature\nenhancement network Neck and Prediction network, and its\nstructure is shown inFigure 1.\nThe BackBone of YOLOv4 is CSPDarknet53, which combines\nDarknet53 with CSPNet (Cross Stage Partial Network). CSPNet\nintegrates gradient changes into feature maps in order to solve the\nproblem of gradient information repetition and reduce the\nnumber of model parameters. Neck collects feature maps from\nthe BackBone and enhance their expression ability. The Neck of\nYOLOv4 uses SPP (Spatial Pyramid Pooling) structure to increase\nthe receptiveﬁeld. PAN (Path Aggregation Network) is used for\nFIGURE 4 |Lucas Kanade method: estimate the opticalﬂow of black pixels. The pyramid method starts from the highest level of the pyramid (with the least details)\nto the lowest level of the pyramid (with rich details).\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 7649034\nSu et al. Transformer Vibration Detection\nparameter aggregation instead of FPN (Feature Pyramid\nNetwork) to adapt to different levels of object detection.\nFinally, three feature layers are extracted and predicted by\nPrediction network. In addition, Mosaic data augmentation,\nLabel Smoothing, DropBlock regularization, CIoU loss, cosine\nannealing learning rate and so on are used to improve the model\nperformance.\nPyramid LK Optical Flow\nBasic Assumptions\nThe opticalﬂow method studies the displacement of an object in\ncontinuous images, for which a link between two frames is\nrequired. The implementation of the optical ﬂow method\nrequires two basic assumptions as prerequisites. First, the\nimage intensity does not change. In this paper, the image is\nconverted to grayscale processing, so it can be understood as that\nthe grayscale value of a pixel at a point on the object does not\nchange when it is displaced on the image. Second, the object\nmotion is small. That is, the object position does not change\ndramatically on the image between two adjacent frames. Based on\nthese two assumptions the same object between two frames can be\nlinked.\nConstraint Equation\nThe basic problems studied by optical ﬂow method can be\nrepresented by Figure 2 as follows.\nBased on theﬁrst assumption that the intensity of the pixel\nremains unchanged after the displacement occurs, the following\nequation can be established.\nI(x, y, t)/equals I(x + dx, y+ dy, t+ dt) (1)\nwhere I(x, y, t) represents the intensity of a pixel, (x, y)\nrepresents spatial position, t represents time, (dx, dy)\nrepresents the moving distance of the pixel,dt represents the\ninterval time. To remove the common terms, a Taylor expansion\nof Eq. 1 is performed, then addEq. 1 to the Taylor expansion\nequation as follows:\nI(x + dx, y+ dy, t+ dt)/equals I(x, y, t)+ zI\nzx dx + zI\nzy dy + zI\nzt dt + ...\n0zI\nzx dx + zI\nzy dy + zI\nzt dt /equals 0\n(2)\nDividing Eq. 2 by dt gives:\nzI\nzx u + zI\nzy v + zI\nzt /equals 0( 3 )\nwhere u /equals dx\ndt and v /equals dy\ndt are two unknown variables to be solved.\nzI\nzx, zI\nzy, and zI\nzt are the partial derivatives of the gray values of the\npixels in the image along x and y directions and time t,\nrespectively, which can be calculated according to the actual\nimage data. Since it is not feasible to solve two unknown\nvariables through an optical ﬂow Eq. 3, it is necessary to\nintroduce some methods such as the Lucas-Kanade method to\nsolve this problem.\nLK Optical Flow Method\nThe mainstream opticalﬂow algorithms can be broadly classiﬁed\ninto dense opticalﬂow method and sparse opticalﬂow method.\nThe dense opticalﬂow method will match each point pixel on the\nFIGURE 5 |Flow chart of the proposed method.\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 7649035\nSu et al. Transformer Vibration Detection\nimage and calculate its offset, which has a higher accuracy for\nmatching moving objects, but is more computationally intensive.\nThe Lucas-Kanade (LK) opticalﬂow method used in this paper is\na typical algorithm in the sparse opticalﬂow method. Compared\nwith the dense optical ﬂow method, this algorithm does not\ncompute all pixel points point by point, but tracks a relatively\nsmall number of feature points, which are usually given by some\nspeciﬁc corner detection algorithms (e.g., Shi-Tomasi algorithm),\nand uses them to represent the overall object motion.\nThe LK opticalﬂow method adds the assumption of“spatial\nconsistency” to the two basic assumptions of the original optical\nﬂow method, i.e., neighboring pixels in a certain area have similar\nvariations. Based on this assumption, a small window ofN × N\ncan be drawn around the feature points and it is determined that\nall pixel points within the small window have the same\nmovement, as shown inFigure 3.\nThe above method can be described by the following\nequations:\nI\nx(q1)Vx + Iy(q1)Vy /equals− It(q1)\nIx(q2)Vx + Iy(q2)Vy /equals− It(q2)\n...\nIx(qn)Vx + Iy(qn)Vy /equals− It(qn)\n(4)\nwhere q1, q2, ... , qn are the pixels inside the small window.Ix(qi),\nIy(qi), and It(qi) represent the partial derivatives of the gray\nvalue of pixelqi in imageI along x and y directions and timet,\nrespectively. Vx /equals u /equals dx\ndt denotes the velocity of movement inx\nFIGURE 6 | (A,B)Two transformer images in transformer detection data set.\nFIGURE 7 |AP curve of transformer test set.\nFIGURE 8 |Single image detection result of YOLOv4 model.\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 7649036\nSu et al. Transformer Vibration Detection\ndirection, Vy /equals v /equals dy\ndt denotes the velocity of movement iny\ndirection.\nThe system of Eq. 4 can be expressed in the form of the\nfollowing matrices:\n⎡⎢⎢⎢⎢⎢⎢\n⎢⎢⎢\n⎢⎢⎢\n⎢⎢⎢\n⎢⎢⎢\n⎢⎢⎢\n⎢⎣\nI\nx(q1) Ix(q1)\nIx(q2) Ix(q2)\n... ...\nIx(qn) Ix(qn)\n⎤⎥⎥⎥⎥⎥⎥\n⎥⎥⎥\n⎥⎥⎥\n⎥⎥⎥\n⎥⎥⎥\n⎥⎥⎥\n⎥⎦\n[ V\nx\nVy\n] /equals\n⎡⎢⎢⎢⎢⎢⎢\n⎢⎢⎢\n⎢⎢⎢\n⎢⎢⎢\n⎢⎢⎢\n⎢⎢⎢\n⎢⎣\n−I\nt(q1)\n−It(q2)\n...\n−It(qn)\n⎤⎥⎥⎥⎥⎥⎥\n⎥⎥⎥\n⎥⎥⎥\n⎥⎥⎥\n⎥⎥⎥\n⎥⎥⎥\n⎥⎦\n(5)\nFor the basic opticalﬂow method, two unknown variables\ncannot be solved because there is only one optical ﬂow\nequation. In contrast, there are n equations ( n > 2) in the\nLK optical ﬂow method, which is overdetermined, and this\nsystem of equations can be solved by ordinary least squares as\nfollows:\n[ V\nx\nVy\n] /equals ⎡⎣\n∑\ni\nIx(qi)\n2\n∑\ni\nIx(qi)Iy(qi)\n∑\ni\nIy(qi)Ix(qi) ∑\ni\nIy(qi)\n2 ⎤⎦\n−1\n⎡⎣\n−∑\ni\nIx(qi)It(qi)\n−∑\ni\nIy(qi)It(qi)\n⎤⎦\n(6)\nPyramid LK Optical Flow Method\nThe LK opticalﬂow method is based on the assumption that the\nmagnitude of object motion is small, so only theﬁrst-order term\nis retained when the Taylor expansion is performed during the\ncalculation of the constraint equations above, and large errors\nmay occur when the magnitude of object motion is large. To solve\nthis problem, the LK opticalﬂow method can be improved by\nusing the pyramid method.\nAs demonstrated inFigure 4, by downsampling the image, the\npyramid LK optical ﬂow method can reduce the larger\ndisplacements in the higher-level pyramid image to obtain a\nmore accurate opticalﬂow vector at that scale, and then scale up\nthe higher-level vector as an initial guide for the next layer when\nsolving layer by layer from the top down. At this time, the object\nposition guided by the opticalﬂow vector from the upper level\nzoomed in and the actual object position of the current layer will\nhave errors, but the error is usually consistent with the scale of\nsmall movements, so it can be calculated on this basis to obtain\nthe optical ﬂow vector of the current layer, and repeated\ndownward in turn to the original map of the bottom layer to\nobtain a more accurate optical ﬂow vector under large\nmovements.\nPROPOSED METHOD\nTransformer Detection\nFirstly, the transformer vibration video is read, and the speciﬁc\nposition of the transformer is obtained in theﬁrst frame image,\nso as to detect the vibration in the region of interest. This paper\ncombines transfer learning and YOLOv4 object detection model\nfor transformer detection. Due to the limited number of\ntransformer images, if YOLOv4 model is trained directly, the\nperformance of the model on the test set is poor due to over\nﬁtting. In this paper, we use the idea of transfer learning for\nreference, use large data sets to pre-train the model, transfer the\nweights of the trained model, and establish YOLOv4\ntransformer learning model. The model is used to detect the\ntransformer in the ﬁrst image and get the transformer\nlocation area.\nFIGURE 9 |The feature points in the whole image area are represented\nby green dots. The peripheral feature points of the transformer will interfere\nwith the calculation of the transformer vibration vector.\nFIGURE 10 |The feature points in the region of interest are represented\nby green dots, which can more accurately calculate the transformer vibration\nvector compared with the feature points inFigure 9.\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 7649037\nSu et al. Transformer Vibration Detection\nFeature Points Detection\nIn this paper, the Shi-Tomasi method is used to calculate the\nfeature points. Because the characteristic points of the edge\nand peripheral area of the transformer have nothing to do\nwith the vibration of the transformer, the introduction of\nthese characteristic points is easy to cause interference, so it is\nnecessary to set ROI (region of interest) as the feature point\ndetection range. The ﬁrst frame is converted to gray image,\nand the transformer position and its center point are obtained\naccording to the prediction results of YOLOv4 model. In this\npaper, a region in the center of the transformer is set as the\nfeature point detection range according to the proportion, and\nthe transformer feature points in theﬁrst frame are calculated\nas the initial feature points. In addition, the number and\nquality of the generated feature points can be controlled by\nsetting those maximum number, those quality level, the\nminimum distance between adjacent feature points, the size\nof those operation area and other parameters.\nTransformer Vibration Detection\nUsing pyramid LK sparse opticalﬂow method, the displacement\nvector of the feature points between theﬁrst frame and the next\nframe is calculated. Due to the inevitable error in the calculation\nprocess, it is not easy to take the displacement vector of one of the\nfeature points to represent the overall displacement vector of the\ntransformer. Usually, several feature points are calculated on a\ncertain object, and the transformer can be regarded as a rigid\nobject, that is, each feature point on the transformer will have an\napproximate displacement.\nIn this paper, ﬁrstly, the displacement vectors of all the\nfeature points in the speci ﬁcr e g i o no ft h et r a n s f o r m e ra r e\ncalculated by the LK sparse optical ﬂow method. Then the\nmodulus of all vectors is calculated, and Otsu method is used\nto get the threshold value of vector modulus to remove the\ndisplacement vector with smaller modulus value. Finally, sum\nand average the remaining displacement vectors, and the\naverage value is the displacement vector of the transformer\nin the image. By combining the transformer displacement and\ntime interval between every two frames, the vibration velocity\nof the transformer can be calculated. Furthermore, the\nvibration data of transformer in three-dimensional space\ncan be calculated by binocular vision. Figure 5 shows the\nﬂow chart of the proposed method.\nEXPERIMENTAL RESULTS AND ANALYSIS\nTransformer Detection Experiments\nExperimental Environment\nThe experimental environment for building YOLOv4 object\ndetection model is windows 10 64 bit operating system, the\nCPU is 32-core Intel Xeon e5-2695 V3, the memory capacity\nis 32GB, the GPU is NVIDIA grid p40-24q, the NVIDIA driver\nversion is 441.66, and the video memory size is 24 g. The deep\nlearning framework used is tensorﬂow GPU 2.2, CUDA version is\n10.1, cudnn version is 7.6.5.32.\nTABLE 1 |Comparison between the transformer vibration vectors calculated by the proposed algorithm and the vibration vectors which are assigned artiﬁcially.\nTransformer vibration vectors which\nare assigned artiﬁcially\nTransformer vibration vectors\ncalculated by the proposed algorithm\nTransformer vibration vectors\ncalculated by method without object\ndetection\nx direction\n(pixel)\ny direction\n(pixel)\nx direction\n(pixel)\ny direction\n(pixel)\nx direction\n(pixel)\ny direction\n(pixel)\n1 0 1.0016 −0.0020 0.0580 0.0017\n1 0 1.0063 0.0231 0.0574 0.0003\n−10 −1.0207 −0.0085 −0.0578 −0.0033\n−10 −1.0002 −0.0086 −0.0582 0.0022\n0 1 0.0131 1.0003 0.0046 0.0746\n01 −0.0023 0.9948 0.0059 0.0878\n10 10 10.0089 10.0051 1.6643 1.4486\n10 10 9.9913 9.9812 2.3282 1.0817\nFIGURE 11 |Generator synthesis video.\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 7649038\nSu et al. Transformer Vibration Detection\nData Set Construction\nTransformer images are screened and sorted, and labels are made\nto construct transformer detection data set. The data set contains\n489 transformer images of different types, different angles and\ndifferent environments, as shown inFigure 6. The data set is\nrandomly divided into training, validation and test set, with 396\nimages in the training set, 44 pictures in the validation set and 49\npictures in the test set. In the process of model training, random\ndata enhancement is carried out on the training set data,\nincluding scaling, length-width distortion, ﬂipping, gamut\ndistortion and other operations.\nYOLOv4 Model Performance and Transformer\nDetection Results\nThe concept of transfer learning is introduced into the model training\nprocess and YOLOv4 pre-trained model is used to help training. The\nmodel is iterated for 100 times, which is divided into freeze training\nand thaw training two stages. In theﬁrst 50 iterations, the weights of\nthe ﬁrst 249 layers are frozen, the batch size is set to 2, and the initial\nlearning rate is set to 0.001. If the validation loss dose not decrease for\nt h r e ee p o c h s ,t h el e a r n i n gr a t ew o u l db ea u t o m a t i c a l l yr e d u c e db y\nhalf. If the validation loss dose not decrease for 10 epochs, the training\nprocess would be stopped in advance. In the second 50 iterations, the\nweights of theﬁrst 249 layers are thawed and the batch size is set to 2.\nThe initial learning rate is 0.0001, and the methods of learning rate\nd e c l i n ea n de a r l ys t o pa r et h es a m ea st h o s eo ft h eﬁrst stage. The AP\ncurve of transformer test set is shown inFigure 7as follows.\nThe AP of the transformer is 99.77%, indicating that YOLOv4\nmodel can accurately detect the transformer. The detection result\nof a single transformer image is shown inFigure 8, where the area\nin the red box is the detected transformer area of interest.\nTransformer Vibration Detection\nExperiments\nIn this paper, the synthetic transformer vibration video is used as\nthe test data, and the transformer image is embedded into the\nbackground image as the foreground. The displacement vector of\nthe transformer in each frame is manually set, which is compared\nwith the vibration vector detection results of the proposed\nalgorithm to evaluate the algorithm performance. The running\nenvironment of vibration vector detection algorithm is windows\n10 64 bit operating system, the CPU is g4600, the GPU is gtx1050,\nthe memory size is 8G, and the image size of the input video is\n666 × 666.\n1) Vibration Vector Measurement Results and Analysis\nIn order to reduce interference, this paper does not calculate the\nfeature points in the whole image area (as shown inFigure 9), but\ndetects the transformer position through the YOLOv4 model, and\nselects a region in the center of the transformer as the feature\npoint region of interest (as shown inFigure 10). In comparison,\nthe feature points calculated in this region are more\nrepresentative of the transformer itself, and it is more accurate\nto use these feature points to calculate the vibration vector of the\ntransformer. Next, the pyramid LK sparse opticalﬂow method is\nused to calculate the vibration displacement vector of these\nfeature points between two adjacent frames. Then, we use\nOtsu algorithm to obtain a threshold of the modulus of these\nvibration vectors, and remove the vibration vectors whose\nmodulus are less than the threshold to reduce the\ncomputational interference. Finally, the average value of all\nremaining vibration vectors is calculated as the vibration\nvector of the transformer.\nTABLE 3 |Calculation error of vibration vector under different videos.\nVibrating objects NRMSE (%) RMSE MAE MAPE (%) PCV\nTransformer (x-direction) 0.229 0.0045 0.0040 0.0206 0.0007\nGenerator (x-direction) 0.078 0.0015 0.0043 0.0348 0.0003\nTransformer (y-direction) 0.065 0.0013 0.0010 0.1063 0.0006\nGenerator (y-direction) 0.087 0.0017 0.0014 0.0004 0.00008\nTABLE 2 |Comparison between the generator vibration vectors calculated by the proposed algorithm and the vibration vectors which are assigned artiﬁcially.\nGenerator vibration vectors which are\nassigned artiﬁcially\nGenerator vibration vectors calculated\nby the proposed algorithm\nGenerator vibration vectors calculated\nby method without object detection\nx direction\n(pixel)\ny direction\n(pixel)\nx direction\n(pixel)\ny direction\n(pixel)\nx direction\n(pixel)\ny direction\n(pixel)\n1 −1 0.9956 −1.0006 0.3380 −0.3294\n1 −1 1.0002 −1.0025 0.3381 −0.3318\n1 −1 1.0047 −1.0009 0.3457 −0.3291\n1 −1 0.9934 −1.0011 0.3460 −0.3307\n−11 −0.9977 1.0013 −0.3590 0.3414\n−11 −1.0059 0.9998 −0.3541 0.3371\n−11 −0.9942 0.9989 −0.3470 0.3375\n−11 −1.0000 1.0014 −0.3454 0.3354\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 7649039\nSu et al. Transformer Vibration Detection\nFIGURE 13 |Three real videos.(A) Tuning Fork (B) Low B String(C) Chime.\nFIGURE 12 |The vibration frequencies of four feature points, and comparison of four feature points spectra calculated by the artiﬁcially set vibration vectors and the\nproposed method. (A) frequency and spectrum of transformer vibration.(B) frequency and spectrum of generator vibration.\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 76490310\nSu et al. Transformer Vibration Detection\nFIGURE 14 | (A–C) are frequencies and spectra calculated by taking the motion coordinate sequences of four feature points in Tuning Fork, Low B String, and\nChime videos, respectively.(A) frequency and spectrum of tuning fork vibration.(B) frequency and spectrum of low B string vibration.(C) frequency and spectrum of\nchime vibration.\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 76490311\nSu et al. Transformer Vibration Detection\nThe video synthesized in this paper restores the vibration\npattern of the transformer in reality as much as possible, and the\ntransformer image is manipulated by swinging back and forth,\nand also tested under different motion amplitudes, and some of\nthe test data are recorded inTable 1.\nIt can be seen from the data in Table 1 that the error\nbetween the transformer displacement vector calculated by\nthe proposed method and the artiﬁcially set data is small, and\nthe accuracy is high, with signiﬁcant advantages over methods\nwithout object detection. No matter in the state of low\ndisplacement or high displacement, the accurate results are\nobtained. In the real environment, the vibration data of\ntransformer can also be obtained according to the proposed\nmethod, so as to analyze the vibration of transformer reliably.\nExcept for theﬁrst frame, the processing time of single frame\nis about 11 m, which fully ensures the real-time performance\nof the algorithm.\nTo ensure the practicality of the method in this paper,\nexperiments are conducted on other synthetic videos and the\nerror rate is calculated to evaluate the performance of the\nalgorithm in different scenarios.\nThe vibration vector is measured from the generator synthesis\nvideo shows inFigure 11, and the comparison of the calculated\nresults with the set amount is presented in the followingTable 2.\nIt can be seen that the proposed method still maintains excellent\nperformance on different synthesis videos.\nNormalized root-mean-square error (NRMSE), root mean square\nerror (RMSE), mean absolute error (MAE), mean absolute\npercentage error (MAPE), percentage change in variance (PCV)\nwere introduced to calculate the error rate (Zhang et al., 2016;\nBokde et al., 2020). The error metrics are deﬁned as follows:\nNRMSE /equals\n/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext\n1\nn∑ n\ni/equals 1(ai − bi)2\n√\nbmax − bmin\n× 100% (7 )\nRMSE /equals\n/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext\n1\nn∑\nn\ni/equals 1(ai − bi)2\n√\n(8)\nMAE /equals 1\nn∑\nn\ni/equals 1\n⏐⏐⏐⏐⏐\n⏐⏐a\ni − bi\n⏐⏐⏐⏐⏐\n⏐⏐ (9)\nMAPE /equals\n1\nn∑\nn\ni/equals 1\n|ai − bi|\nbi\n× 100% (10 )\nPCV /equals\n⏐⏐⏐⏐⏐\n1\nn∑ n\ni/equals 1(bi − /C22b)\n2\n− 1\nn∑ n\ni/equals 1(ai − /C22a)2\n⏐⏐⏐⏐⏐\n1\nn∑ n\ni/equals 1(ai − /C22a)2 (11)\nwhere ai and bi are the observed and forecasted data at time t,\nrespectively. n is the number of data for forecast evaluation.\nThe vibration vectors of individual feature points in the two\nsynthesized videos are calculated separately for each frame, and\nthe calculation results are evaluated in comparison with the set\nstandard value calculation errors usingEqs 7–11, and the results\nare shown inTable 3. It can be seen that the proposed method can\nmaintain its accuracy on different synthesized videos and has\nsome practicality.\n2) Vibration Frequency Test Results and Analysis\nThe vibration vector calculated by the method in this paper is\nused to predict the pixel coordinates of the feature points in each\nframe, and the spectrogram of the feature point motion can be\nobtained by collecting these coordinates into a series and then\nperforming FFT calculation, and the accuracy performance of the\nmethod can be analyzed according to the spectrogram. As shown\nin Figure 12,the blue curve is the theoretical spectrum calculated\nbased on the predeﬁned values of the synthesized video, and the\nred curve is the spectrum calculated by the method of this paper.\nIt can be seen that the proposed method maintains a good\nstability and accuracy.\nThe following real videos as shown in Figure 13 are\nintroduced to evaluate the methodology of this paper.\nAs can be seen inFigure 14, the motion spectrum of the\nfour feature points in the same video is more consistent, which\nproves the anti-interference property of the method in\nthis paper.\nThe object vibration frequencies are obtained based on the motion\nspectra of the feature points calculated under the synthetic video and\nvarious real videos, and compared with the real frequency calculation\nerrors usingEqs 9–11 to evaluate the algorithm performance. As can\nbe seen fromTable 4, the error of the calculation results of the\nvibration frequencies of objects in different videos by the method in\nthis paper is very small, all within an acceptable range, which ensures\nits practicality.\nCONCLUSION\nThis paper presents a real-time transformer vibration signal detection\nmethod based on video. Firstly, the precise positioning of power\nt r a n s f o r m e ri sr e a l i z e db yY O L O v 4m o d e l .S e c o n d l y ,t h e\ndisplacement vector of feature points is calculated by pyramid LK\nopticalﬂow method within the range of interested transformer. Then,\nthe interference term of displacement vector isﬁltered by Otsu\nalgorithm. Finally, the vibration vector of transformer is calculated\nby vector average. Experimentalresults show that the proposed\nalgorithm can accurately calculate the vibration vector and\nfrequency, which provides an important basis for the real-time state\nevaluation of the power equipment.\nDATA AVAILABILITY STATEMENT\nThe original contributions presented in the study are included in\nthe article/Supplementary material, further inquiries can be\ndirected to the corresponding author.\nTABLE 4 |Frequency calculation error under different videos.\nVibrating objects MAE MAPE (%)\nTransformer 0.22 0.5867\nGenerator 0.19 1.013\nTuning Fork 0.54 0.1929\nLow B String 1.07 1.621\nChime 0.88 0.2\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 76490312\nSu et al. Transformer Vibration Detection\nAUTHOR CONTRIBUTIONS\nLS and HH contributed to conception and design of the study. LQ\nand WZ collected 489 images of different types of transformers. LQ\nand WZ synthesized the transformer and generator vibration video.\nLQ and WZ implemented the programming of the proposed\nvibration detection algorithm. LS wrote the ﬁrst draft of the\nmanuscript. All authors wrote sections of the manuscript. All\nauthors contributed to manuscript revision, read, and approved\nthe submitted version.\nACKNOWLEDGMENTS\nThis work was supported by the science and technology project of\nState Grid Corporation of China (Project No.: B3094020000B).\nREFERENCES\nAoyama, T., Chikaraishi, M., Fujiwara, A . ,L i ,L . ,J i a n g ,M . ,I n o u e ,K . ,e ta l .\n(2018). Vibration Sensing of a Bridge Model Using a Multithread Active\nVision System. IEEE/ASME Trans. Mechatron. 23, 179–189. doi:10.1109/\ntmech.2017.2764504\nB e r l e r ,Z . ,G o l u b e v ,A . ,R u s o v ,V . ,T s v e t k o v ,V . ,a n dP a t t e r s o n ,C .( 2 0 0 0 ) .\n“Vibro-acoustic Method of Transformer Clamping Pressure\nMonitoring, ” in IEEE International Symposium on Electrical\nInsulation, Anaheim, CA, USA, 5-5 April 2000, 263 –266. doi:10.1109/\nELINSL.2000.845503\nBokde, N. D., Yaseen, Z. M., and Andersen, G. B. (2020). ForecastTB-An R\nPackage as a Test-Bench for Time Series Forecasting-Application of Wind\nSpeed and Solar Radiation Modeling. Energies 13, 2578. doi:10.3390/\nen13102578\nBorucki, S. (2012). Diagnosis of Technical Condition of Power Transformers Based\non the Analysis of Vibroacoustic Signals Measured in Transient Operating\nConditions. IEEE Trans. Power Deliv.27, 670–676. doi:10.1109/TPWRD.2012.\n2185955\nC a o ,H . ,L e i ,Y . ,a n dH e ,Z .( 2 0 1 3 ) .C h a t t e rI d e n t iﬁcation in End Milling\nProcess Using Wavelet Packets and Hilbert-Huang Transform. Int.\nJ. Machine Tools Manufacture 69, 11 –19. doi:10.1016/j.ijmachtools.\n2013.02.007\nChen, J. G., Wadhwa, N., Cha, Y.-J., Durand, F., Freeman, W. T., and Buyukozturk,\nO. (2015). Modal Identiﬁcation of Simple Structures with High-Speed Video\nUsing Motion Magniﬁcation. J. Sound Vibration345, 58–71. doi:10.1016/j.jsv.\n2015.01.024\nChoi, A. J., and Han, J.-H. (2018). Frequency-based Damage Detection in\nCantilever Beam Using Vision-Based Monitoring System with Motion\nMagniﬁcation Technique. J. Intell. Mater. Syst. Structures 29, 3923–3936.\ndoi:10.1177/1045389X18799961\nDiamond, D. H., Heyns, P. S., and Oberholster, A. J. (2017). Accuracy Evaluation of\nSub-pixel Structural Vibration Measurements through Optical Flow Analysis of\na Video Sequence.Measurement 95, 166–172. doi:10.1016/j.measurement.2016.\n10.021\nFeng, D., Feng, M., Ozer, E., and Fukuda, Y. (2015). A Vision-Based Sensor for\nNoncontact Structural Displacement Measurement.Sensors 15, 16557–16575.\ndoi:10.3390/s150716557\nFeng, D., Scarangello, T., Feng, M. Q., and Ye, Q. (2017). Cable Tension Force\nEstimate Using Novel Noncontact Vision-Based Sensor. Measurement 99,\n44–52. doi:10.1016/j.measurement.2016.12.020\nGarcia, B., Burgos, J. C., and Alonso, A. M. (2006b). Transformer Tank Vibration\nModeling as a Method of Detecting Winding Deformations-Part II:\nExperimental Veriﬁcation. IEEE Trans. Power Deliv. 21, 164–169. doi:10.\n1109/TPWRD.2005.852275\nGarcia, B., Burgos, J. C., and Alonso, A. (2006a). Transformer Tank Vibration\nModeling as a Method of Detecting Winding Deformations-Part I: Theoretical\nFoundation. IEEE Trans. Power Deliv.21, 157–163. doi:10.1109/TPWRD.2005.\n852280\nHati, A., and Nelson, C. W. (2019). $W$ -Band Vibrometer for Noncontact\nThermoacoustic Imaging. IEEE Trans. Ultrason. Ferroelect., Freq. Contr.66,\n1536–1539. doi:10.1109/TUFFC.2019.2923909\nH e l f r i c k ,M .N . ,N i e z r e c k i ,C . ,A v i t a b i l e ,P . ,a n dS c h m i d t ,T .( 2 0 1 1 ) .3 D\nDigital Image Correlation Methods for Full-Field Vibration\nMeasurement. Mech. Syst. Signal Process. 25, 917 –927. doi:10.1016/j.\nymssp.2010.08.013\nH o r n ,B .K .P . ,a n dS c h u n c k ,B .G .( 1 9 8 1 ) .D e t e r m i n i n gO p t i c a lF l o w .Artif.\nIntelligence 17, 185–203. doi:10.1016/0004-3702(81)90024-2\nH u a n g ,M . ,Z h a n g ,B . ,a n dL o u ,W .( 2 0 1 8 ) .AC o m p u t e rV i s i o n - B a s e d\nVibration Measurement Method fo r Wind Tunnel Tests of High-Rise\nBuildings. J. Wind Eng. Ind. Aerodynamics 182, 222–234. doi:10.1016/j.\njweia.2018.09.022\nJudd, M. D., Cleary, G. P., Bennoch, C. J.,Pearson, J. S., and Breckenridge, T.\n(2002). “Power Transformer Monitoring Using UHF Sensors: Site Trials,”\nin IEEE International Symposium on Electrical Insulation, Boston, MA,\nUSA, 7-10 April 2002, 145–149. doi:10.1109/ELINSL.2002.995899\nMoya-Albor, E., Brieva, J., Ponce, H., and Martinez-Villasenor, L. (2020). A Non-\ncontact Heart Rate Estimation Method Using Video Magniﬁcation and Neural\nNetworks. IEEE Instrum. Meas. Mag. 23, 56–62. doi:10.1109/MIM.2020.\n9126072\nMunir, B. S., and Smit, J. J. (2011).“Evaluation of Various Transformations to\nExtract Characteristic Parameters from Vibration Signal Monitoring of Power\nTransformer,” in Electrical Insulation Conference (EIC), Annapolis, MD, USA,\n5-8 June 2011, 289–293. doi:10.1109/EIC.2011.5996164\nPeng, C., Zeng, C., and Wang, Y. (2020). Camera-based Micro-vibration\nMeasurement for Lightweight Structure Using an Improved Phase-Based\nMotion Extraction. IEEE Sensors J. 20, 2590–2599. doi:10.1109/JSEN.2019.\n2951128\nPoudel, U. P., Fu, G., and Ye, J. (2005). Structural Damage Detection Using Digital\nVideo Imaging Technique and Wavelet Transformation.J. Sound Vibration\n286, 869–895. doi:10.1016/j.jsv.2004.10.043\nSarraﬁ, A., Mao, Z., Niezrecki, C., and Poozesh, P. (2018). Vibration-based Damage\nDetection in Wind Turbine Blades Using Phase-Based Motion Estimation and\nMotion Magniﬁcation. J. Sound Vibration421, 300–318. doi:10.1016/j.jsv.2018.\n01.050\nSon, K.-S., Jeon, H.-S., Park, J.-H., and Park, J. W. (2015). Vibration Displacement\nMeasurement Technology for Cylindrical Structures Using Camera Images.\nNucl. Eng. Tech.47, 488–499. doi:10.1016/j.net.2015.01.011\nTian, L., and Pan, B. (2016). Remote Bridge Deﬂection Measurement Using an\nAdvanced Video Deﬂectometer and Actively Illuminated LED Targets.Sensors\n16, 1344. doi:10.3390/s16091344\nW a d h w a ,N . ,C h e n ,J .G . ,S e l l o n ,J .B . ,W e i ,D . ,R u b i n s t e i n ,M . ,G h a f f a r i ,R . ,\net al. (2017). Motion Microscopy for Visualizing and Quantifying Small\nMotions. Proc. Natl. Acad. Sci. USA114, 11639–11644. doi:10.1073/pnas.\n1703715114\nWadhwa, N., Wu, H.-Y., Davis, A., Rubinstein, M., Shih, E., Mysore, G. J., et al.\n(2016). Eulerian Video Magniﬁcation and Analysis.Commun. ACM60, 87–95.\ndoi:10.1145/3015573\nYang, Y., Dorn, C., Farrar, C., and Mascareñas, D. (2020). Blind, Simultaneous\nIdentiﬁcation of Full-Field Vibration Modes and Large Rigid-Body Motion of\nOutput-Only Structures from Digital Video Measurements.Eng. Structures207,\n110183. doi:10.1016/j.engstruct.2020.110183\nYu, L., and Pan, B. (2017). Single-camera High-Speed Stereo-Digital Image\nCorrelation for Full-Field Vibration Measurement. Mech. Syst. Signal\nProcess. 94, 374–383. doi:10.1016/j.ymssp.2017.03.008\nZhang, D., Guo, J., Lei, X., and Zhu, C. (2016). A High-Speed Vision-Based Sensor\nfor Dynamic Vibration Analysis Using Fast Motion Extraction Algorithms.\nSensors 16, 572. doi:10.3390/s16040572\nZ h a n g ,D . ,T i a n ,B . ,W e i ,Y . ,H o u ,W . ,a n dG u o ,J .( 2 0 1 9 ) .S t r u c t u r a lD y n a m i c\nResponse Analysis Using Deviations from Idealized Edge Proﬁles in High-\nSpeed Video. Opt. Eng. 58, 1–9. doi:10.1117/1.OE.58.1.014106\nZ h a o ,J . ,L i ,L . ,X u ,Z . ,W a n g ,X . ,W a n g ,H . ,a n dS h a o ,X .( 2 0 2 0 ) .F u l l - s c a l e\nDistribution System Topology Identi ﬁcation Using Markov Random\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 76490313\nSu et al. Transformer Vibration Detection\nField. IEEE Trans. Smart Grid 11, 4714 –4726. doi:10.1109/tsg.2020.\n2995164\nZhao, J., Wang, J., Xu, Z., Wang, C., Wan, C., and Chen, C. (2017). Distribution\nNetwork Electric Vehicle Hosting Capacity Maximization: a Chargeable Region\nOptimization Model. IEEE Trans. Power Syst. 32, 4119–4130. doi:10.1109/\nTPWRS.2017.2652485\nConﬂict of Interest: LS and HH were employed by the company State Grid\nShanghai Electric Power Research Institute.\nThe remaining authors declare that the research was conducted in the absence of\nany commercial orﬁnancial relationships that could be construed as a potential\nconﬂict of interest.\nPublisher’s Note:All claims expressed in this article are solely those of the authors\nand do not necessarily represent those of their afﬁliated organizations, or those of\nthe publisher, the editors and the reviewers. Any product that may be evaluated in\nthis article, or claim that may be made by its manufacturer, is not guaranteed or\nendorsed by the publisher.\nCopyright © 2022 Su, Huang, Qin and Zhao. This is an open-access article\ndistributed under the terms of the Creative Commons Attribution License (CC\nBY). The use, distribution or reproduction in other forums is permitted, provided the\noriginal author(s) and the copyright owner(s) are credited and that the original\npublication in this journal is cited, in accordance with accepted academic practice.\nNo use, distribution or reproduction is permitted which does not comply with\nthese terms.\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 76490314\nSu et al. Transformer Vibration Detection"
}