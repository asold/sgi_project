{
  "title": "Mitigative Strategies for Recovering From Large Language Model Trust Violations",
  "url": "https://openalex.org/W4405031054",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2767315852",
      "name": "Max J. Martell",
      "affiliations": [
        "Pacific Northwest National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2913428144",
      "name": "Jessica A Baweja",
      "affiliations": [
        "Pacific Northwest National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A5098977245",
      "name": "Brandon D. Dreslin",
      "affiliations": [
        "Pacific Northwest National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2767315852",
      "name": "Max J. Martell",
      "affiliations": [
        "Pacific Northwest National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2913428144",
      "name": "Jessica A Baweja",
      "affiliations": [
        "Pacific Northwest National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A5098977245",
      "name": "Brandon D. Dreslin",
      "affiliations": [
        "Pacific Northwest National Laboratory"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3206793843",
    "https://openalex.org/W2984353433",
    "https://openalex.org/W3159250634",
    "https://openalex.org/W2981686111",
    "https://openalex.org/W4327860966",
    "https://openalex.org/W3158836591",
    "https://openalex.org/W2098119579",
    "https://openalex.org/W4360980141",
    "https://openalex.org/W4366989525",
    "https://openalex.org/W2793000014",
    "https://openalex.org/W3125633690",
    "https://openalex.org/W3121705224",
    "https://openalex.org/W1977714815",
    "https://openalex.org/W2010158189",
    "https://openalex.org/W3013998503",
    "https://openalex.org/W2888580379",
    "https://openalex.org/W2143074722",
    "https://openalex.org/W4404534210",
    "https://openalex.org/W3153990350",
    "https://openalex.org/W3016099278",
    "https://openalex.org/W3121787084",
    "https://openalex.org/W2113687834",
    "https://openalex.org/W3130167372",
    "https://openalex.org/W3084211362",
    "https://openalex.org/W3206297794",
    "https://openalex.org/W4242672582",
    "https://openalex.org/W2007567868",
    "https://openalex.org/W1978271112",
    "https://openalex.org/W2110171129",
    "https://openalex.org/W4200546216",
    "https://openalex.org/W4248588746",
    "https://openalex.org/W2034344216",
    "https://openalex.org/W2156702351",
    "https://openalex.org/W1973213502",
    "https://openalex.org/W2130087774",
    "https://openalex.org/W2282821441",
    "https://openalex.org/W2398251251",
    "https://openalex.org/W2095628489",
    "https://openalex.org/W3081297476",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W1967906317",
    "https://openalex.org/W3004158152",
    "https://openalex.org/W3095444354",
    "https://openalex.org/W3009578469",
    "https://openalex.org/W2942157335",
    "https://openalex.org/W2918027211",
    "https://openalex.org/W4213426744",
    "https://openalex.org/W2999637955",
    "https://openalex.org/W3103751997",
    "https://openalex.org/W3155739706",
    "https://openalex.org/W2911747006"
  ],
  "abstract": "In this study, we investigated strategies to address trust issues arising from errors in large language models (LLMs). The study examined the impact of confidence scores, system capability explanations, and user feedback on trust restoration post-error. 68 participants viewed the responses of an LLM to 20 general trivia questions, with an error introduced on the third trial. Each participant was presented with one mitigation strategy. Participants rated their overall trust in the model and the reliability of the answer. Results showed an immediate drop in trust after the error; however, there were no differences across the three strategies in trust recovery. All conditions had a logarithmic trend in trust recovery following error. Differences in overall trust were predicted by perceived reliability of the answer, suggesting that participants were evaluating results critically and using that to inform their trust in the model. Qualitative data supported this finding; participants expressed lasting distrust despite the LLMâ€™s later accuracy. Results showcase the need to prioritize accuracy in LLM deployment, because early errors may irrevocably damage user trust calibration and later adoption.",
  "full_text": null,
  "topic": "Distrust",
  "concepts": [
    {
      "name": "Distrust",
      "score": 0.9403215646743774
    },
    {
      "name": "Reliability (semiconductor)",
      "score": 0.6572267413139343
    },
    {
      "name": "Software deployment",
      "score": 0.5364174842834473
    },
    {
      "name": "Computer science",
      "score": 0.5169636607170105
    },
    {
      "name": "Psychology",
      "score": 0.45512980222702026
    },
    {
      "name": "Social psychology",
      "score": 0.3782861828804016
    },
    {
      "name": "Applied psychology",
      "score": 0.3782285153865814
    },
    {
      "name": "Computer security",
      "score": 0.35622113943099976
    },
    {
      "name": "Power (physics)",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Psychotherapist",
      "score": 0.0
    }
  ]
}