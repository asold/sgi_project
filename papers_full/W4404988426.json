{
  "title": "TabulaX: Leveraging Large Language Models for Multi-Class Table Transformations",
  "url": "https://openalex.org/W4404988426",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2742132143",
      "name": "Arash Dargahi Nobari",
      "affiliations": [
        "University of Alberta"
      ]
    },
    {
      "id": "https://openalex.org/A272765103",
      "name": "Davood Rafiei",
      "affiliations": [
        "University of Alberta"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2427822648",
    "https://openalex.org/W2554492429",
    "https://openalex.org/W4391136507",
    "https://openalex.org/W2001700730",
    "https://openalex.org/W4205922070",
    "https://openalex.org/W4237412827",
    "https://openalex.org/W1981578383",
    "https://openalex.org/W2481573984",
    "https://openalex.org/W2884499287",
    "https://openalex.org/W2260484439",
    "https://openalex.org/W2798578675",
    "https://openalex.org/W3026997957",
    "https://openalex.org/W4321448337",
    "https://openalex.org/W3170190513",
    "https://openalex.org/W4399175313",
    "https://openalex.org/W3014705052",
    "https://openalex.org/W2889003264",
    "https://openalex.org/W3098495697",
    "https://openalex.org/W4366660144",
    "https://openalex.org/W2496170334",
    "https://openalex.org/W4392366650",
    "https://openalex.org/W3165814564",
    "https://openalex.org/W3148437589",
    "https://openalex.org/W4391377904",
    "https://openalex.org/W2611988335",
    "https://openalex.org/W3035231859",
    "https://openalex.org/W2616147950"
  ],
  "abstract": "The integration of tabular data from diverse sources is often hindered by inconsistencies in formatting and representation, posing significant challenges for data analysts and personal digital assistants. Existing methods for automating tabular data transformations are limited in scope, often focusing on specific types of transformations or lacking interpretability. In this paper, we introduce TabulaX, a novel framework that leverages Large Language Models (LLMs) for multi-class column-level tabular transformations. TabulaX first classifies input columns into four transformation typesâ€”string-based, numerical, algorithmic, and generalâ€”and then applies tailored methods to generate human-interpretable transformation functions, such as numeric formulas or programming code. This approach enhances transparency and allows users to understand and modify the mappings. Through extensive experiments on real-world datasets from various domains, we demonstrate that TabulaX outperforms existing state-of-the-art approaches in terms of accuracy, supports a broader class of transformations, and generates interpretable transformations that can be efficiently applied.",
  "full_text": "TabulaX: Leveraging Large Language Models for Multi-Class\nTable Transformations\nArash Dargahi Nobari\ndargahi@ualberta.ca\nUniversity of Alberta\nEdmonton, AB, Canada\nDavood Rafiei\ndrafiei@ualberta.ca\nUniversity of Alberta\nEdmonton, AB, Canada\nABSTRACT\nThe integration of tabular data from diverse sources is often hin-\ndered by inconsistencies in formatting and representation, posing\nsignificant challenges for data analysts and personal digital assis-\ntants. Existing methods for automating tabular data transformations\nare limited in scope, often focusing on specific types of transfor-\nmations or lacking interpretability. In this paper, we introduce\nTabulaX, a novel framework that leverages Large Language Models\n(LLMs) for multi-class column-level tabular transformations. Tabu-\nlaX first classifies input columns into four transformation typesâ€”\nstring-based, numerical, algorithmic, and generalâ€”and then applies\ntailored methods to generate human-interpretable transformation\nfunctions, such as numeric formulas or programming code. This\napproach enhances transparency and allows users to understand\nand modify the mappings. Through extensive experiments on real-\nworld datasets from various domains, we demonstrate that TabulaX\noutperforms existing state-of-the-art approaches in terms of accu-\nracy, supports a broader class of transformations, and generates\ninterpretable transformations that can be efficiently applied.\nKEYWORDS\nLarge Language Models, Heterogeneous Table Join, Data Integra-\ntion, Data Transformation, Data Cleaning and Transformation\nPVLDB Reference Format:\nArash Dargahi Nobari and Davood Rafiei. TabulaX: Leveraging Large\nLanguage Models for Multi-Class Table Transformations. PVLDB, 18(11): ,\n2025.\n1 INTRODUCTION\nThe rapid growth of publicly available data and increased reliance\non third-party sources have underscored the need for efficient meth-\nods to combine and transform data from diverse sources. This is cru-\ncial for a wide range of users, including data analysts, scientists, and\npersonal digital assistants. However, significant challenges arise due\nto variations in formatting and presentation across these sources.\nThis work is licensed under the Creative Commons BY-NC-ND 4.0 International\nLicense. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of\nthis license. For any use beyond those covered by this license, obtain permission by\nemailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights\nlicensed to the VLDB Endowment.\nProceedings of the VLDB Endowment, Vol. 18, No. 11 ISSN 2150-8097.\ndoi:ArXiv Version\nTable 1: Performance of SOTA models on KBWT dataset\nGPT-4o DTT [8] GXJoin [34] AFJ [25]\nF1-Score 0.510 0.254 0.083 0.093\nExplainable N N Y N\nEven within a single organization, data such as names, addresses,\nand financial records may exist in multiple inconsistent formats. Tar-\nget tables may be stored in formats such as spreadsheets, relational\ndatabases, web tables, and comma-separated filesâ€”common across\norganizations, the web, and public government datasets [8, 31].\nThere has been a wide array of studies on automating the trans-\nformation of tabular data and ensuring consistency across diverse\ndata sources [1, 8, 18, 34], yet significant challenges remain. Table 1\nreports the performance, in terms of F1-score, of four state-of-the-\nart (SOTA) methods on KBWT [ 1], a dataset comprising tables\nextracted from a knowledge base (Â§5.1). Clearly, all SOTA models\nstruggle and only GXJoin generates explainable transformations,\nwhile the others produce either an output string or a match decision,\nboth of which lack interpretability. Figure 1 illustrates examples of\nsource and target tables. In the first table pair, where individuals\nare identified by name in the source and username in the target, all\nSOTA models perform well. However, for the second pair, involving\nweight conversions between pounds and kilograms, and the third\npair, linking company names with their CEOs, the models fail to\nproduce meaningful results. While GPT-4o often produces correct\noutputs, reflected in its relatively high F1-Score in Table 1, it does\nnot yield transformations that are scalable to large datasets.\nThe problem can be formulated as given a small set of matched\nrows between source and target tables, we want to identify map-\npings that transform source values into target values, enabling an\nequi-join between the two tables. This paper explores two key re-\nsearch questions in this context: (1) Can higher performance be\nachieved in transforming tables that exhibit a wide range of syn-\ntactic and semantic patterns (as illustrated in Figure 1)? (2) Can the\ntransformation process be made explainable? Aligned with prior\nwork in the literature [8, 14, 34, 53], this work primarily focuses\non transformations applied to key or join columns. However, the\nproposed approach has the potential to be extended to include\nadditional columns or more complex settings.\nChallenges. There are a few critical challenges that must be\naddressed to tackle the problem. One major challenge is the vast\nmulti-class search space due to the diverse nature of mismatches,\nas illustrated in Figure 1. These mismatches can range from string\ntransformations, such as converting full names to usernames, to\nnumeric conversions, like pounds to kilograms. In more complex\narXiv:2411.17110v2  [cs.DB]  18 Aug 2025\nSource Table Target Table\n(1)\n(2)\n(3)\nFull Name ...\nNadia Ralph Allen â€“\nSean Morse â€“\nDena Christopher Griffith â€“\nBrandy Constable â€“\nWeight in Pounds ...\n2 â€“\n51.5 â€“\n73 â€“\nCompany ...\nMicrosoft â€“\nPepsiCo â€“\nToyota â€“\nUsername ...\nn.r.allen â€“\ns.morse â€“\nd.c.griffith â€“\nb.constable â€“\nWeight in Kg ...\n0.9 â€“\n23.4 â€“\n33.1 â€“\nCEO ...\nSatya Nadella â€“\nRamon Laguarta â€“\nKoji Sato â€“\nFigure 1: Example input tables with formatting mismatch\ncases, transformations may even require external knowledge bases\n(for example, linking a company name to its CEO). An effective so-\nlution must not only handle all of these classes but also navigate the\nvast search space of potential transformations within each class to\nidentify the most appropriate mappings. Another challenge arises\nfrom the limited coverage of individual transformations . A single\ntransformation may only be applicable to a subset of the rows, as\ndemonstrated in the first table in Figure 1, where entries containing\nmiddle names are transformed differently than those without. A\ncomprehensive framework must identify multiple transformations\nand develop rules to apply the appropriate transformation based\non observed data patterns. Additionally, interpretability is a crucial\nrequirement for many application areas, particularly those involv-\ning sensitive or high-stakes data. Users need to understand and\nverify the logic behind each transformation to ensure it meets their\nrequirements. Furthermore, the ability to adjust or refine these map-\npings fosters trust and transparency in data integration processes.\nLimitations of existing approaches. Existing methods for\naddressing table transformations can be broadly categorized into\n(1) methods that learn a matching function for a given pair of\nvalues or records, and (2) methods that generate mapping rules\nbetween source and target tables [7, 8, 14, 34, 53]. The first group\nincludes techniques focused on learning similarity functions [9, 25]\nor mapping functions [ 19, 46], as well as approaches for match-\ning entity records that refer to the same real-world objects but\ndiffer in format or representation [ 2, 27, 52]. These approaches\ntypically rely on machine learning models or (semi-)manually de-\nfined similarity metrics to rank and select the best candidate for\neach corresponding value. While effective for addressing format-\nting mismatches in joining tabular data, they lack the ability to\ngenerate explicit mappings to transform the source formatting into\nthe target. This limits their flexibility in modifying transformations,\nmay lead to non-interpretable functions, and restricts their use\nprimarily to fuzzy joins. The second group of approaches focuses\non generating mapping rules. Many of these studies are limited to\nstring-based transformations and rely on an exhaustive search of\nthe parameter space to find the appropriate mapping. Some meth-\nods are constrained to using a single transformation function per\ntable [14, 15, 40, 53], while others depend entirely on retrieving\nfunctions from external sources [18, 20]. Also, some approaches\nemploy pretrained language models, which return mappings that\nare not interpretable [8].\nOur approach. We introduce TabulaX, a novel data integra-\ntion framework that leverages Large Language Models (LLMs) for\nmulti-class column-level tabular transformations. Similar to exist-\ning approaches, TabulaX transforms the entity or join column in\nthe source table to its corresponding representation in the target.\nHowever, the mapping functions generated by our framework cover\na much broader range of transformations, including textual, nu-\nmeric, algorithmic, and those requiring external knowledge. A key\nfeature of TabulaX lies in the interpretability and usability of its\ntransformations, which are generated as numeric functions or pro-\ngramming language code, unlike some approaches in the literature\nthat rely on their own domain specific languages [14, 15, 40]. Our\nexperimental evaluation reveals that TabulaX outperforms exist-\ning state-of-the-art approaches in terms of accuracy, supports a\nbroader class of transformations, and delivers mappings that can\nbe efficiently applied to large-scale tables and datasets.\nContributions. Our contributions can be summarized as fol-\nlows: (1) We propose TabulaX, a new framework for Multi-class\nTabular Transformations, capable of handling a broad range of\ntransformationsâ€”including textual, numeric, algorithmic, and those\nrequiring external knowledge. (2) We introduce a classification\nmechanism that enables TabulaX to effectively apply tailored trans-\nformation strategies to diverse types of data mismatches. (3) We de-\nvelop methods for generating human-interpretable transformation\nfunctions, such as numeric formulas and executable code, which\nimprove transparency and allow users to understand, verify, and\nmodify the mappings. (4) Through extensive experiments on real-\nworld datasets from various domains, we demonstrate that TabulaX\noutperforms existing state-of-the-art approaches in terms of ac-\ncuracy and supports a broader class of transformations. (5) We\npublicly release the TabulaX framework, source code, and datasets\nto support reproducability and foster further research1.\n2 RELATED WORKS\nWe organize related work into three main areas: (1) example-driven\ntable transformations, (2) the use of large language models for\ntabular data, and (3) techniques for integrating tabular datasets.\n2.1 Example-Driven Table Transformations\nThis line of work, closely aligns with ours and has been an active\narea of research in recent years [7, 8, 14, 15, 40, 53]. Early approaches\nsuch as FlashFill [14] and BlinkFill [40] targeted spreadsheet data\nusing substring-based transformations derived from user examples.\nAuto-join [53] improves robustness by employing predefined string\ntransformation units and a recursive backtracking algorithm to\npartition and transform noisy input. CST [ 7] builds on this by\n1https://github.com/arashdn/TabulaX\n2\nextracting common text fragments as transformation skeletons,\napplying row-level transformations, and ranking them by coverage.\nGXJoin [34] generalizes these transformation units, improving both\ncoverage and noise tolerance.\nWhile CST and GXJoin improve efficiency and noise handling,\nthey remain limited to a narrow set of predefined substring-based\noperations and require long textual overlaps. To address these\nconstraints, DTT [8] introduces a fine-tuned language model for\nexample-driven transformations. This approach eliminates the need\nfor predefined functions or pruning-based searches but relies on\nsynthetic training data and produces transformations in a non-\ninterpretable latent space. Our work addresses these problems by\nintroducing a novel class-aware LLM-based framework capable of\ngenerating interpretable, human-readable transformation functions,\nbridging expressiveness, generalization, and transparency.\nSome structural transformation methods, such as Foofah [ 22]\nand Explain-Da-V [ 39], focus on reshaping entire tables. While\nthey target cell- and grid-level alignment for schema matching,\nour column-level mappings can complement these approaches by\nhandling diverse value-level mismatches in integration tasks.\n2.2 Large Language Models for Tabular Data\nEarly pretrained models such as T5 [36], BERT [11], and GPT-3 [4]\nhave inspired the development of tabular-specific LLMs such as\nTaBERT [50], TURL [10], and TABBIE [21]. These encoder-based\nmodels are better suited for discriminative tasks like entity match-\ning [2, 28] and QA [ 6, 21, 50], while models like RPT [ 42] and\nByT5 [48] support generative tasks such as data to text [23, 35, 43].\nTabular LMs typically have less than 500M parameters and rely on\nfine-tuning for task adaptation. DTT [8], for instance, is built on\nfine-tuned ByT5 [48] for table joinability.\nRecent advances in LLMs such as ChatGPT2, Gemini3, and Llama\n3 [13] have enabled prompt-based methods that require minimal\nor no fine-tuning. Techniques such as self-consistency [ 45] and\nchain-of-thought prompting [47] improve LLM reasoning and per-\nformance by guiding generation through structured prompts. Some\nstudies apply LLMs to tabular tasks using supervised fine-tuning [26,\n51] and prompt-based approaches [41], emphasizing the importance\nof table serialization [8, 32, 41]. These approaches are complemen-\ntary to ours, improving how LLMs process and reason about tabular\ndata.\n2.3 Tabular Data Integration\nResearch focused on linking and integrating structured datasets is\nclosely related to our goals. A comprehensive overview of foun-\ndational methods is provided by Doan et al. [ 12], while more re-\ncent developments, particularly in the context of data lakes and\nopen data integration, are reviewed by Miller et al. [30] and Khati-\nwada et al. [ 24]. Our work also connects with efforts to detect\nlinkage points across datasets [16]. Notably, when schema elements\n(e.g., dbpedia:stockSymbol and dbpedia:stockTicker) are inter-\npreted as cell values, their alignment can be viewed as a form of\ncell-level transformation. This perspective supports the idea that\n2https://chatgpt.com\n3https://gemini.google.com\nschema-level and value-level integration can be unified under a sin-\ngle transformation framework, which our method aims to achieve\nthrough class-aware, interpretable mappings.\n3 MULTI-CLASS TRANSFORMATION\nDISCOVERY\nIn this section, we provide a detailed formulation of the problem, a\ndiscussion of our assumptions and observations, and a classification\nof transformations based on their functions.\nOur aim is to transform the values in a source table column\ninto their corresponding values in a target column, guided by a\nsmall set of provided examples. We assume that both the source\nvalues to be transformed and user-provided examples are available,\nwhich helps narrow the scope to concentrate specifically on data\ntransformation tasks [7, 8]. When such examples are not provided\nby users, methods such as unequal joining [ 19, 25, 46] or token-\nbased example generation [7, 53] can be employed to produce a set\nof examples, with the caveat that these automatically generated\nexamples may include noise or invalid matches.\nLet ğ‘† = {ğ‘ 1,ğ‘ 2,... }denote a set of values in the source table, and\nğ‘‡ = {ğ‘¡1,ğ‘¡2,... }represent the corresponding values in the target,\nwhich may be partially or completely unavailable. For a small subset\nğ‘†â€² âŠ‚ğ‘†, let ğ¸ = {(ğ‘ ğ‘–,ğ‘¡ğ‘— )|ğ‘ ğ‘– âˆˆğ‘†â€²}denote a set of examples where\ntarget values are provided to guide the transformation process. We\nwant to find a transformation function ğ‘“ such that:\nğ‘“ : ğ‘† â†’ğ‘‡|âˆ€ğ‘ ğ‘— âˆˆğ‘†â€²((ğ‘ ğ‘—,ğ‘“ (ğ‘ ğ‘— )âˆˆ ğ¸. (1)\nIdeally, the function learned from ğ‘†â€²should be applicable to any\nvalue in ğ‘†, rather than being restricted only to ğ‘†â€². The function\nis expected to be human-interpretable, meaning that its output\nshould be generated in a manner supported by transparent patterns.\nAdditionally, it should be implementable using commonly utilized\nprogramming languages in organizational settings. Moreover, given\nthat many data lakes and tables sourced from third parties often\nlack schema information, we operate under the assumption that\nno metadata or schema is available for the framework to benefit.\nAccordingly, transformations will be extracted only using the values\nin the individual cells.\nAs an example, consider the middle row in Figure 1, where\nS = {2, 51.5, 73} and T = {0.9, 23.4, 33.1} . We provide\nthe set of guiding examples as E = {(2, 0.9), (51.5, 23.4)}.\nThe aim is to find a transformation function that maps 2 to 0.9,\nand 51.5 to 23.4, thereby identifying a pattern. For instance, the\nfunction ğ‘“(ğ‘¥)= round(0.453 Ã—ğ‘¥)can transform any source value\nin ğ¸into its corresponding target and is generalizable to all inputs\nin ğ‘†.\nAs shown in Figure 1, different input tables require distinct\nclasses of transformations. For example, the top table can be trans-\nformed using a sequence of string manipulation functions, such as\nsubstring and split, while the middle table relies on a numerical\ntransformation (specifically, a linear function). Transformation of\nthe last table is not possible without external knowledge that is not\npresent in either the source or target.\nMost existing approaches in the literature limit their scope when\naddressing this problem. Some methods focus only on string-based\ntransformations [8, 14, 53], others only handle entity matching [28,\n3\nClassifier\nNumeric Function Fitting\nString-based\nRelationship Tagging\nNumberStringAlgorithmic\nNumeric\nAlgorithmic\nLookup Table\nDownstream TaskColumn Type DetectionGeneral Transformation Function\ns4 t4s5 t5s6 t6\nFunction Generator\ns1 t1s2 t2s3 t3\nExamples\ns4s5s6\nSource rowsChain-of-Thought Prompting\nFigure 2: The architecture of our framework\n52], and some retrieve mapping functions from large code reposi-\ntories [18, 20]. One may argue that recent commercially available\nLLMs, such as GPT and Gemini, could address these challenges. To\nevaluate the performance of LLMs in this context, we conducted\nan experiment using the GPT model4 on our benchmark consisting\nof diverse real-world tables. However, the out-of-the-box model\nstruggled to recognize many textual patterns, and frequently pro-\nduced hallucinated or irrelevant outputs in cases requiring external\nknowledge. Moreover, LLMs are not expected to handle numerical\ndata well [5], and our experiments also confirmed that the model\nwas unable to perform numerical transformations effectively.\nTo address this issue, we propose a framework that first classifies\nthe input mappings. Based on the identified class, appropriate ac-\ntions and methods are then selected to facilitate the transformation\nof the tables. We define four distinct classes of input transforma-\ntions:\nâ€¢ String-based: This class includes input columns that can\nbe transformed using a series of string manipulation func-\ntions commonly available in programming frameworks,\nsuch as substring, concatenation, split, case conversion (up-\nper/lowercase), etc. An example of this class is shown in\nthe top row in Figure 1.\nâ€¢ Numerical: This class encompasses input tables where\nboth source and target values are rational numbers and ex-\nhibit an underlying mathematical relationship. An example\nis the conversion from pounds to kilograms illustrated in\nFigure 1. It is important to note that nominal numbers, such\nas postal codes or ISBNs, do not fall in this category.\nâ€¢ Algorithmic: This class includes input tables where an al-\ngorithm exists to transform source values into target values,\nbut the transformation goes beyond numerical functions\nor sequences of string operations. Examples include trans-\nformation such as Gregorian to Hijri dates, characters to\nASCII codes, or binary to hexadecimal numbers.\nâ€¢ General: This class includes any table transformations that\nrequire external knowledge sources or do not fit into the\n4We used the gpt-4o-2024-05-13 model from the OpenAI API for this experiment\nprevious three categories. Examples include mapping a com-\npany name to its CEO, converting area codes to countries,\nor translating English words to French.\nIn the following sections, we will discuss the classification pro-\ncess and the specific actions required for each class of input tables.\n4 APPROACH\nFigure 2 depicts the architecture of TabulaX, our proposed frame-\nwork for tabular data transformation and join. The first component\nis a classifier that assigns a transformation class from the afore-\nmentioned set of classes. Once classified, the tables are routed to\nthe corresponding mapping modules, which generate the appro-\npriate transformation functions. These transformations are then\nutilized by the downstream task component to produce end-to-end\nresults. While this study focuses on unequal joins as the down-\nstream task, the generated transformations can also support other\napplications, such as detecting anomalies or outliers by identifying\ndeviations from the defined mappings, imputing missing values,\netc. The remainder of this section details each component of the\nframework.\n4.1 Input Data and Serialization\nMultiple components in our approach interact with LLMs, and most\nLLMs accept input only as a sequence of tokens, hence a critical\nstep is serializing the input tables into a linear sequence of text.\nThis sequence is then tokenized and processed by the LLM. Most\nLLMs are trained on vast, diverse datasets from web pages and\nare familiar with common notations used to represent sets and\npairs in mathematics and computer science. Leveraging this, we\nserialize the example pairs in a way that closely aligns with these\nconventions.\nSpecifically, each example is serialized as(\"s\" -> \"t\"), where s\nand t represent the source and target values, respectively. To ensure\ngenerality and with the assumption that schema and metadata\nmay not be available, all values are enclosed in quotation marks,\nregardless of their cell or column data types. We use the -> token\nto indicate the direction from source to target, instead of a comma,\n4\nwhich is more commonly used for separating elements in pairs or\ntuples. This decision is supported by our observations that when a\ncomma is used to separate tuple elements, LLMs, particularly GPT-\n4o, may fail to recognize the directionality from source to target,\nleading to erroneous predictions. Finally, the serialized examples\nare concatenated using commas to form the complete serialized\nlist.\nFor instance, consider the first two rows from the bottom row in\nFigure 1 as the set of provided examples. This set will be serialized\nas:\n(\"Microsoft\" -> \"Satya Nadella\"),( \"PepsiCo\" -> \"Ramon\nLaguarta\").\nThis serialization will be utilized throughout the framework when-\never an LLM needs to process the example set. Since many LLMs\nimpose a limit on input length, if the size of the example set ex-\nceeds the modelâ€™s context window, a sampling step is applied during\nserialization to reduce the input length.\n4.2 Classifier\nOur experiments with various LLMs indicate that even large, widely-\nused commercial models such as GPT-4o struggle to effectively\ntransform numeric values, recognize all textual patterns, and gen-\nerate lookup tables without prompts that are tailored for each class.\nTo address this, the first component of our framework is a classifier\nthat determines the subsequent components to which the input\ntables will be directed. To achieve this, we use a general-purpose\nLLM. LLMs, trained on vast and diverse datasets, can handle a\nwide range of tasks by utilizing one or a few training examples\n(i.e., shots) [4, 38] in their prompts, known as in-context learning.\nInspired by this idea, we developed a prompt template for clas-\nsifying input types. The structure of the prompt and the given\nexamples (shots) may significantly affect the quality of the classifi-\ncation, which led us to try 3-5 prompts before selecting one. Our\nclassifierâ€™s LLM prompt5 starts by defining the task, followed by a\nlist of possible classes. Each class is then explained in detail, and\nrepresentative examples are provided at the end.\nOnce the input class is identified, we propose a tailored method\nthat best suits the transformation of values in that class. Recognizing\nthat LLMs face challenges with numerical mappings, our framework\navoids relying on LLMs for this class. It also uses Chain-of-Thought\nprompting [47] for advanced algorithmic and general classes to\nenhance the modelâ€™s reasoning capabilities. In what follows, we\nwill describe how transformations are generated for each class in\nmore detail.\n4.3 Numerical Transformations\nWhen the input table is labeled as numerical, it is passed to the\nNumerical Function Fitting component, which is responsible for\nfitting a numerical function ğ‘“ğ‘› (i.e., curve fitting) based on the input\nexamples. The framework attempts to fit curves using the following\ntypes of functions:\nâ€¢ Linear: ğ‘“(ğ‘¥)= ğ‘ğ‘¥+ğ‘,\nâ€¢ Polynomial: ğ‘“(ğ‘¥)= ğ‘ğ‘¥2 +ğ‘ğ‘¥ +ğ‘,\nâ€¢ Exponential: ğ‘“(ğ‘¥)= ğ‘ğ‘’ğ‘¥ğ‘ (ğ‘ğ‘¥),\n5The prompt template, along with all other prompting techniques and templates used\nin this study, are available in our publicly-available code repository.\nâ€¢ Rational: ğ‘“(ğ‘¥)= ğ‘ğ‘¥+ğ‘\nğ‘¥+ğ‘ .\nThe parameters ğ‘, ğ‘, and ğ‘ are estimated during the curve fitting\nprocess using the Levenbergâ€“Marquardt algorithm [37]. The frame-\nwork then calculates the Mean Square Error (MSE) between the\npredicted and actual target values in the provided examples, and the\nfunction with the lowest MSE is selected as the mapping function,\ndenoted as ğ‘“ğ‘› (ğ‘¥). The list of functions is not limited to those men-\ntioned above; any function supported by the curve fitting algorithm\ncan be used.\nOnce the best-fitting function ğ‘“ğ‘› (ğ‘¥)is selected, it is passed to\nthe Numerical Function Generator component, which generates\nthe corresponding transformation as a function in a programming\nlanguageâ€”specifically Python, in our setup.\n4.4 String-Based Transformations\nTable transformations using string primitives and regular expres-\nsions have been widely studied in the literature [7, 14, 34, 40, 53],\noften using a Programming-By-Example (PBE) approach. While\nany of these methods could be incorporated as our String-Based\nFunction Generator, we propose a novel approach by leveraging\nLLMs, which outperform state-of-the-art techniques. Recent stud-\nies suggest that LLMs perform well in code generation [29, 33, 44],\nand our approach also utilizes LLMs to generate transformation\nfunctions for string-based inputs.\nSpecifically, the model is prompted to create a Python function\nthat takes a string as input and reformats it to produce the expected\noutput. In this case, the input examples are not presented using\nthe set-like notation from Section 4.1. Instead, we format them\nas test cases: Input: ğ‘ ğ‘– , Expected output: ğ‘¡ğ‘– , where ğ‘ ğ‘– and ğ‘¡ğ‘–\nrepresent arbitrary source and target samples, respectively. This\nformat is common on websites and forums, which are primary\nsources for common LLMs training data. As a result, LLMs better\nunderstand the task using this format, as demonstrated in our ex-\nperiments, leading to improved code generation compared to the\nset-like notation.\nAdditionally, the model is instructed not to use any external\nlibrary calls but is free to utilize any functions available in the\nstandard Python library. This approach covers a broader range\nof string-based transformations compared to methods that rely\non a limited set of predefined functions [7, 34, 53] or those using\nsubstring extraction via regular expressions [ 14, 15, 40]. Finally,\nthe generated function is verified by a syntax checker before being\nused as the transformation function.\n4.5 Algorithmic Transformations\nAlgorithmic transformations are more complex compared to numer-\nical and string-based transformations. Our experiments indicate\nthat applying the same approach used for string-based transfor-\nmations is ineffective here, mainly due to the limitations of LLMs\nin handling complex reasoning. In many cases, the model fails to\nidentify the correct transformation pattern and may hallucinate\nand generate code that does not align with the given examples.\nStudies suggests that complex reasoning in LLMs can be im-\nproved through intermediate reasoning steps [47, 49], known as\nChain-of-Thought (CoT) reasoning. Leveraging this approach, we\nbreak down the task of generating algorithmic transformations into\n5\ntwo simpler steps: (1) Relationship Tagging , which identifies the\nconversion type or the relationship between the source and target,\nand (2) Algorithmic Function Generator , which produces a Python\nfunction to execute the transformation based on the identified rela-\ntionship.\nFor tables requiring algorithmic transformations, the input is\nfirst processed by the relationship extractor, where the LLM is\nprompted to identify the relationship between the source and tar-\nget columns. The relationship is formatted as [type of source\ncolumn] to [type of target column]. For example, given the\ninput (\"2024/09/05\" -> \"1403/06/16\"), (\"1886/06/27\" ->\n\"1265/04/06\"), the model is expected to return Gregorian date\nto Jalali (Solar Hijri) date. This transformation is included\nin the training examples provided for in-context learning, along-\nside others, such as email to domain transformation. The detected\nrelationship and input tables are then passed to the algorithmic\nfunction generator component, which is structured similarly to the\nstring-based function generator. In this step, the model generates\na Python function based on the identified relationship, using the\nsame format and verification as the string-based component.\n4.6 General Transformations\nGeneral transformations are the most complex task, as they often\nrequire external knowledge not present in the provided examples.\nWe adopt a similar approach to the one used for algorithmic trans-\nformations, supported by Chain-of-Thought prompting, and break\nthe problem into two subtasks. The first step is similar to the rela-\ntionship tagging component in the algorithmic transformer, where\nthe types of source and target columns are detected. The second\nstep generates a transformation by leveraging a lookup table (i.e., a\nstructured mapping between source and target values) as a bridge.\nThere are multiple ways to obtain this table. One approach is to\nretrieve it from external repositories (e.g., structured databases,\nweb tables, or open knowledge graphs), which requires extensive\nindexing and specialized retrieval algorithms [18â€“20]. In this work,\nhowever, we leverage LLMs to dynamically construct the lookup\ntable, allowing for greater flexibility and adaptability.\nWhen input tables are labeled for general transformation, they\nare passed to the Column Type Detection component, where the\nLLM is prompted to identify the type of the source and target\ncolumns, formatted as [type of source column] to [type\nof target column]. While the task shares some similarities with\nalgorithmic transformer, the two training examples used in this\ncontext are selected to better match the general transformation sce-\nnario. For instance, given Data: (\"AGC\" -> \"United States\"),\n(\"YYZ\" -> \"Canada\"),the expected relationship isAirport Code\nto Country and for Data: (\"gallon\" -> \"liter\"), (\"inch\"\n-> \"centimeter\"), the relationship will be Imperial Units to\nMetric Unit.\nAs demonstrated in these examples, developing a deterministic\nalgorithm for such cases is infeasible, as the transformations rely on\nexternal knowledge. Consequently, we leverage the LLMâ€™s learned\nknowledge to generate a lookup function that directly prompts the\nmodel to predict the target value for a given source value, based on\nthe extracted column types and input examples.\nLimitations of general transformations. While our task break-\ndown and other steps significantly improve the modelâ€™s perfor-\nmance compared to state-of-the-art baselines, there are certain\nlimitations. First, the external knowledge used by the model is\ninherently constrained by its training data. Despite the extensive\ntraining of modern LLMs on large datasets from web pages and pub-\nlic knowledge bases, they may still lack domain-specific knowledge,\nparticularly in private sectors where similar data is not publicly\navailable. Additionally, the transformation function in this cate-\ngory primarily relies on LLM predictions, which are not human-\ninterpretable. Unlike other transformation types where the mapping\nfunction is generated based on a single prompt using a small set\nof example rowsâ€”independent of the source column sizeâ€”general\ntransformations may require an LLM call for each row, particularly\nif no batching strategy is applied. While this may raise scalability\nconcerns, it is worth noting that these LLM calls are independent\nand can be executed in parallel to deal with performance bottle-\nnecks.\nMoreover, LLMs are susceptible to hallucinations, and unlike\nthe numeric, string, or algorithmic transformers, where the out-\nput is an explicit algorithm that can be automatically or manually\nverified, hallucinations in this case may occur and remain unde-\ntected. In sensitive environments, one solution is to implement\nguardrails that verify the modelâ€™s output using domain knowl-\nedge or compare it against available target values. This component\ncould also be replaced with a retrieval-based approach to access\nrelevant information from public knowledge bases or private data\nsources. For example, the system could be integrated with a ta-\nble retrieval method that retrieves a bridge or cross table between\nthe source and target [1, 19, 46], or by employing entity matching\ntechniques [2, 27, 52]. These areas remain open for future works.\n4.7 Example Walkthrough: Generating a\nTransformation\nFigure 3 illustrates an end-to-end example of the framework in\naction. In this scenario, the source values represent Unicode code\npoints of certain characters, while the target values correspond to\ntheir ASCII decimal representations. Four examples are provided to\nguide the transformation generation process. The examples are first\npassed to the classifier, which identifies the input type as an algo-\nrithmic transformation. Based on this classification, the framework\ninvokes the algorithmic transformation process, beginning with the\nrelationship tagging component. The model extracts the relation-\nship as \"Unicode code point to ASCII decimal value, \" which is then\npassed, along with the input examples, to the function generator\ncomponent. The output of this step is a transformation expressed\nas human-interpretable Python code. This code is subsequently ex-\necuted on the source rows to generate the predicted target values.\n4.8 Integration with Downstream Tasks\nThe transformation functions generated by TabulaX can be directly\napplied to data analysis or used to support downstream tasks. Tabu-\nlar transformations have been used for a variety of tasks, including\nauto-completion and auto-filling of spreadsheets [14, 40], predict-\ning missing values, error correction [17], and joining tables [34, 53].\n6\nUnicodeU+0057U+005AU+0059U+0044\nASCII087090089068\nClassifier Relationship Tagging\nAlgorithmic Algorithmic Function Generator\nUnicode code point to ASCII decimal value\nInput Examples\nTransformer\nSource Rows\nUnicodeU+0042U+0055U+0054U+0041\nASCII066085084065Predicted Target\nComponent Selector\nFigure 3: The steps of processing an arbitrary input table\nIn this section, we focus specifically on the task of joining heteroge-\nneous tables, while the generalization of this framework for other\ndownstream applications are left for future works.\nConsider a scenario where a source table ğ‘† and a target table ğ‘‡\nmust be joined on semantically equivalent columns, guided by a set\nof examples mappings ğ¸. While these columns may differ in format,\nthey represent the same real-world entities or concepts. TabulaX\nleverages ğ¸to learn a transformation function, which is applied to\neach entry ğ‘ ğ‘– âˆˆğ‘† to produce a transformed value Ë†ğ‘¡ğ‘– . This results\nin a candidate set Ë†ğ‘‡, aligned with the format of ğ‘‡. Treating Ë†ğ‘‡ as\nan intermediate column, an equality join with ğ‘‡ can be used to\ncomplete the operation.\nHowever, strict equality joins are sensitive to minor discrep-\nancies between predicted and actual values. Unlike tasks such as\nauto-completion, where exact matches are essential, join operations\ncan often tolerate minor mismatches. When a one-to-one relation-\nship is expected (e.g., in primary-foreign key joins), the join can\ninstead be performed by selecting the closest match in ğ‘‡ for each\nË†ğ‘¡ğ‘– , using string similarity metrics such as edit distance. Formally,\nthe best match ğ‘œğ‘– for a source value ğ‘ ğ‘– is given by:\nğ‘œğ‘– = argmin\nğ‘¡ğ‘— âˆˆğ‘‡\nğ‘’ğ‘‘ğ‘–ğ‘¡_ğ‘‘ğ‘–ğ‘ ğ‘¡(Ë†ğ‘¡ğ‘–,ğ‘¡ğ‘— ). (2)\nThis method can be generalized to handle one-to-many or many-\nto-many joins by defining upper and lower bounds on allowable\nedit distances. Edit-distance-based matching offers a transparent\nand targeted solution for handling small inconsistencies, though it\nis not intended as a full fuzzy matching algorithm.\nFor numeric transformations, edit distance is not appropriate.\nInstead, we use absolute numerical differences to measure prox-\nimity between predicted and actual values. This maintains consis-\ntency with the goal of interpretable and context-sensitive alignment\nwhile accounting for datatype-specific variation. Edit-distance-\nbased matching is a simple yet effective technique, specifically\nused to address minor discrepancies between the predicted and\ntarget values, while maintaining transparency. It is not intended to\nperform a comprehensive fuzzy join but rather serves as a targeted\napproach to enhance matching accuracy in the presence of slight in-\nconsistencies. Unlike the other classes, however, edit-distance-based\nmatching is not applicable on numeric transformations; instead, we\nemploy absolute numerical distance to assess the closeness of the\ntransformed values to their targets.\n5 EXPERIMENTS AND ANALYSIS\nThis section presents a comprehensive evaluation of our frame-\nwork, examining its performance across different configurations\nand benchmarking it against established baselines.\n5.1 Benchmark Datasets\nTo evaluate the performance of our proposed method and compare\nit with current state-of-the-art baselines, we employ four real-world\ndatasets encompassing various input classes. Detailed descriptions\nof each dataset are provided below.\nWeb Tables Dataset (WT): Initially introduced by Zhu et al. [53]\nand subsequently utilized as a benchmark by Nobari et al. [ 7, 8],\nthis dataset consists of 31 pairs of tables spanning 17 distinct topics.\nEach table averages 92.13 rows with an input length of approxi-\nmately 31 characters. The tables were extracted from Google Fusion\nTables by selecting those that appeared in the same query results\nbut had different formats. This benchmark involves string-based\ntransformations and includes natural noise and inconsistencies. Not\nall entities can be transformed using traditional primitive string-\nbased transformations, making this dataset relatively challenging\nstring-based input [7, 8].\nSpreadsheet Dataset (SS): This dataset comprises 108 pairs of\ntables sourced from the Microsoft Excel product team and user\nhelp forums, focusing on usersâ€™ data cleaning issues. The tables\nrepresent spreadsheet pages that convey the same information in\ndifferent formats. It includes public benchmarks from FlashFill [14]\nand BlinkFill [ 40], and was featured in the 2016 Syntax-Guided\nSynthesis Competition (SyGuS-Comp) [3]. On average, each table\ncontains 34.43 rows and has an input source length of 19 characters.\nCompared to the WT dataset, while SS dataset is also string-based,\nit features considerably less noise and inconsistency.\nTable Transformation (TT): Introduced by He et al [ 18], this\ndataset was developed to support the task of retrieving data trans-\nformations from public code bases. It contains 230 pairs of tables,\neach averaging 8 rows, and covers a wide range of transformation\ntypes, including 102 algorithmic, 57 numeric, 68 string-based, and\n3 general transformations. Compared to the WT and SS datasets,\nTT features more complex transformation logic, often involving\nnumerical computations and algorithmic operations in addition to\nadvanced string manipulations.\n7\nKnowledge Base Web Tables (KBWT): Introduced by Abed-\njan et al. [1], this dataset primarily consists of tables extracted from\na Knowledge Base (KB), requiring semantic transformations and\nadditional KB information. For our evaluation, we selected single-\ncolumn tasks from this dataset, totaling 81 pairs of tables. Each\ntable averages 113 rows with an input source length of 13 charac-\nters. This dataset differs notably from the WT and SS benchmarks,\nwhich focus mainly on textual transformations. Among the tables\nin the KBWT benchmark, three are numeric, four are algorithmic,\nand the rest are general transformations.\n5.2 Experimental Setup and Evaluation Metrics\nOur framework, TabulaX, follows an example-driven approach,\ntaking ğ‘›input examples to guide the transformation process. Tab-\nulaX is designed to allow any general-purpose LLM to serve as\nthe inference model within the framework. We experiment with\nvarious numbers of input examples and multiple LLMs to provide\na detailed analysis of our frameworkâ€™s performance. Where the\nvalue of ğ‘›is not explicitly mentioned, it is set to 5 for the WT, SS,\nand KBWT datasets. For the TT dataset, ğ‘› is set to 3 due to the\nrelatively small number of rows in most of its tables. The default\nLLM used in the framework is OpenAI GPT-4o model, specifically,\ngpt-4o-2024-05-13 version.\nFor each transformation class, we tested 3â€“5 prompt variants\nand selected the best-performing one for our experiments. In the\nstring-based and algorithmic transformations, where the output\ndomain is relatively constrained and the final task is code genera-\ntion, we observed that changes in prompt had only a subtle effect\non performance. In contrast, general transformations involve more\ndiverse domains, and prompt variations had a somewhat greater\nimpact. For this class, we selected the most general prompt that\nyielded the best overall results. Overall, performance remained\nstable across prompts that followed the guidelines described in\nSection 4, especially for larger models like GPT-4o.\nThe focus of this study is the heterogeneous join as the down-\nstream task, and as described in Section 4.8, the prediction is ob-\ntained by calculating the edit distance between the predicted and\ntarget values. While this is the default approach in our framework,\nwe also conduct some experiments using exact matching to show-\ncase our modelâ€™s generalizability to other downstream tasks where\ntarget values may be unavailable or edit distance may not be pre-\nferred.\nJoin performance is evaluated based on precision, recall, and F1-\nscore, where precision measures the fraction of correct predictions\nthat join with the target, recall represents the fraction of source rows\nthat are correctly mapped, and F1-score is calculated by taking the\nharmonic mean of precision and recall. It is important to recognize\nthat not all source rows may be mapped to a target value for reasons\nsuch as generating an invalid function, returning empty output,\nor runtime exception. In addition to those metrics, we also report\nthe Average Edit Distance (AED) and Average Normalized Edit\nDistance (ANED), which indicates how much a prediction deviates\nfrom its target. ANED is normalized by the target length, facilitating\ncomparisons between datasets and tables with different lengths.\nEach datasetâ€™s reported metrics are averaged across all tables within\nthat dataset.\n5.3 Performance of classification\nTable 2 presents the performance of our classification module using\nthree different LLMs: GPT-4o, GPT-4o-mini, and LLaMA 3.1 8B. In\nthis table, support refers to the number of tables in each transforma-\ntion class. To measure performance, we use common classification\nmetrics: precision (P), recall (R), and F1-score (F). These metrics\nare calculated across four transformation classes: String, Numbers,\nAlgorithmic, and General. The macro average is calculated as the\nsimple average of the metrics across all classes, regardless of their\nsupport, while the micro average takes into account the weight of\neach class by considering the total number of instances. The goal\nis to assess how effectively each model can categorize input tables\ninto the correct transformation class, which is crucial for directing\nthem to the appropriate mapping components in our framework.\nWhile the benchmark datasets provide source and target table\npairs for evaluation, they do not include transformation type labels\nrequired for the classification task. To support this component, the\ntransformation classes for all benchmark instances were manually\nannotated by the authors. During the annotation process, a conflict\nrate of approximately 8% was observed, primarily in distinguish-\ning between algorithmic and string-based transformations. These\ndisagreements were resolved through discussion and consensus to\nensure consistency and accuracy in the labels.\nAs expected, GPT-4o outperforms the other models across all\nclasses, achieving the highest macro and micro average scores. This\nsuperior performance can be attributed to its larger size and its\ntraining focused more on understanding complex tasks. All models\nachieve perfect recall for the numerical class, indicating that they\nreliably detect numerical transformations. However, GPT-4o still\noutperforms the others in precision, suggesting fewer misclassi-\nfications, such as incorrectly labeling nominal numbers (like zip\ncodes) as numerical transformations or failing to recognize when\nonly one side of the transformation involves numerical data. As a\nresult, they achieve high recall, while their precision is not perfect.\nAnother important observation is the tendency of the models\nto misclassify certain String transformations as General or Algo-\nrithmic. This misclassification often occurs in cases requiring ex-\ntensive edit operations or the addition of literal text. For example,\nwhen transforming usernames into email addresses by appending a\ndomain name, these models sometimes label the task as General in-\nstead of String. They assume that adding a domain requires external\nknowledge rather than recognizing it as a fixed literal addition. This\nsuggests that LLMS, especially the smaller ones, may struggle with\nmore complex textual transformations that involve fixed patterns\nor extensive edits.\nOverall, GPT-4o demonstrates sufficient capability for our clas-\nsification tasks, emphasizing the importance of choosing a model\ncomplex enough to prevent misclassifications that could impact\nthe subsequent mapping components in our framework. In certain\ndomains, the transformation classes may already be established or\ncan be determined by domain experts, eliminating the need for this\nclassification component altogether.\n5.4 Performance Compared to baseline models\nIn this section, we evaluate the performance of our framework,\nTabulaX, on the end-to-end task of heterogeneous or unequal table\n8\nTable 2: Classification performance of various LLMs across transformation classes\nGPT-4o GPT-4o-mini LLaMA 3.1\nClass Support P R F P R F P R F\nString 207 0.92 0.85 0.88 0.89 0.74 0.81 0.72 0.91 0.80\nNumbers 60 0.78 1.00 0.88 0.67 1.00 0.81 0.65 1.00 0.79\nAlgorithmic 105 0.84 0.70 0.76 0.88 0.56 0.69 0.88 0.20 0.33\nGeneral 76 0.78 0.96 0.86 0.59 0.92 0.72 0.53 0.49 0.51\nMacro avg 448 0.83 0.88 0.84 0.76 0.81 0.75 0.69 0.65 0.61\nMicro avg 448 0.86 0.85 0.85 0.81 0.77 0.76 0.71 0.68 0.64\njoins. This task simulates a common scenario where source and\ntarget columns reside in different tables that need to be joined, but\nthe values in these columns are formatted differently.\nTo benchmark our approach, we compare TabulaX against four\nstate-of-the-art baselines: Deep Tabular Transformer (DTT) [ 8],\nGXJoin [34], Auto-FuzzyJoin (AFJ) [ 25], and Explain-Da-V [ 39].\nDTT leverages language models to generate outputs directly from\nprovided examples, focusing on string transformations. GXJoin\nextends the CST method [7] and exhaustively searches for general\ntextual string-based transformations to facilitate table joinability.\nAFJ employs similarity functions to identify the most probable\nrows to join without generating explicit transformation functions.\nExplain-Da-V performs example-driven structural transformations\nby exploring a graph of intermediate table states with an A*-based\nheuristic search and type-aware operators, aiming to reshape source\ntables so they align with the target structure.\nTable 3 summarizes the performance of our framework, TabulaX,\nand the baselines. As shown, TabulaX consistently achieves higher\nor comparable F1-scores across all datasets compared to these base-\nlines. On datasets dominated by string-based transformations, such\nas WT and SS, the performance gap between TabulaX and DTT is\nrelatively small, with DTT being the best-performing baseline in our\nsetup. Specifically, TabulaX achieves an F1-score of 0.983 on the WT\ndataset, only marginally higher than DTTâ€™s 0.950. On the SS dataset,\nboth methods perform almost identically, with F1-scores of 0.952.\nThis similarity is expected since both models handle string trans-\nformations effectively, though TabulaX offers the added advantage\nof generating interpretable transformation functions. In contrast,\nDTT directly outputs target values without transparency, which\ncan be a limitation in sensitive environments and scenarios requir-\ning interpretability. The performance gap between TabulaX and the\nbaselines increases on datasets involving more complex transfor-\nmations. On the TT dataset, which includes a mix of string-based,\nnumerical, and algorithmic transformations, TabulaX achieves an\nF1-score of 0.918, compared to 0.643 for DTT, 0.223 for GXJoin,\nand 0.219 for Explain-Da-V. The TDE approach [18] was proposed\nin the same work that introduced the TT dataset and reports a\ncoverage of 72% on it, whereas our method achieves a recall of\n92% on this benchmark. On the KBWT dataset, which contains a\nhigher proportion of general transformations requiring external\nknowledge, TabulaX reaches an F1-score of 0.567, whereas DTT\nscores only 0.254. The gap highlights TabulaXâ€™s versatility and its\nability to generalize across diverse data types, a feature not shared\nby the string-based baselines. Additionally, TabulaXâ€™s interpretable\ntransformations are valuable in understanding and verifying the\nmappings, unlike DTTâ€™s black-box approach.\nGXJoin, performs an exhaustive search in the string-based trans-\nformation space to generate interpretable transformations and is\nthe best-performing state-of-the-art approach generating an in-\nterpretable mapping in our experiments. This large search space\nallows GXJoin to achieve high precision on all datasets, as it applies\ntransformations without relying on edit distance-based matching.\nHowever, the recall is noticeably lower, indicating that it fails to\ntransform a significant portion of the data. In contrast, TabulaX\nmaintains a high recall by utilizing a broader set of transforma-\ntion units and providing a clear mapping between input rows and\ntransformations. Similar to other baselines, GXJoin is only limited\nto string-based transformations and is significantly outperformed\nby TabulaX and DTT on TT and KBWT datasets. Even without\nemploying edit distance matching, as indicated in Table 4, TabulaX\noutperforms GXJoin due to its ability to handle a wider variety of\ntransformations and its use of LLMs to interpret and apply complex\npatterns. GXJoinâ€™s exhaustive search methodology, while thorough,\ncan lead to scalability issues. Moreover, while TabulaX provides a\nclear mapping between input rows and the applied transformations,\nGXJoinâ€™s exhaustive search does not offer such mapping, and it\nmay apply multiple transformations without a straightforward way\nto trace back the exact steps for each row.\nIn terms of runtime, for a table with ğ‘›rows, TabulaX requires\nonly a single LLM call to generate transformations for string-based\ntables, two LLM calls (one for relationship tagging and another for\ntransformation generation) for algorithmic tables, and ğ‘›+1 LLM\ncalls for general tables when lookups rely on LLM calls. Costs can\nbe reduced if bridge tables are accessible from alternative sources.\nIn contrast, DTT, while effective primarily for string-based tables,\nrequires ğ‘˜ Ã—ğ‘›LLM calls, where ğ‘˜ represents the number of self-\nconsistency trials (set to 5 in the experiments). Both TabulaX (in\nthe worst case) and DTT have a linear growth in the LLM calls\nwith respect to input size, and their LLM calls can be executed in\nparallel if resources allow. On the other hand, GXJoin has quadratic\ngrowth in runtime due to its exhaustive search methodology. This\napproach also has more constraints on parallel execution, making\nGXJoin less scalable compared to TabulaX for larger datasets.\nAFJ relies on similarity functions to identify matching rows and\ndoes not generate explicit transformation functions, which limits\nits applicability in scenarios where understanding the transforma-\ntion process is essential. Explain-Da-V, while capable of producing\ninterpretable transformations, is primarily optimized for structural\n9\nTable 3: Performance compared to the baselines\nTabulaX DTT GXJoin AFJ Explain-Da-V\nDataset P R F P R F P R F P R F P R F\nWT 0.985 0.980 0.983 0.951 0.950 0.950 0.953 0.754 0.777 0.935 0.672 0.708 0.161 0.161 0.161\nSS 0.955 0.949 0.952 0.954 0.952 0.952 0.997 0.787 0.810 0.943 0.662 0.691 0.163 0.163 0.163\nTT 0.919 0.918 0.918 0.644 0.643 0.643 0.983 0.202 0.223 0.591 0.223 0.251 0.219 0.219 0.219\nKBWT 0.722 0.532 0.567 0.276 0.248 0.254 0.962 0.081 0.083 0.749 0.067 0.093 0.038 0.038 0.038\ntable reshaping. Its support for value-level transformations is lim-\nited, which hinders its performance in our setup. As a result, both\nmethods underperform compared to TabulaX across all datasets,\nwith particularly poor results on more complex benchmarks such\nas TT and KBWT.\nOverall, our results demonstrate that TabulaX not only outper-\nforms baselines on complex datasets but also provides interpretable\ntransformation functions, making it a superior choice for heteroge-\nneous joins across a wide range of tables.\n5.5 Impact of Matching Strategies\nTable 4 presents a detailed comparison of the frameworkâ€™s perfor-\nmance under two different matching scenarios: edit-distance-based\nmatching (left panel) and exact matching (right panel). The former\nmatching strategy is more suited for applications where a set of\ntarget values is available, such as in unequal table joins, where\nsmall variations between the generated and expected values can\nbe tolerated. The latter, exact matching, is more appropriate for\ntasks like missing data imputation, where precise outputs are re-\nquired. The top panel of the table reflects results when using the\nLLM-based classification model (GPT-4o in this set of experiments),\nwhile the bottom panel provides performance metrics when using\nthe ground truth classification, referred to as the â€œGoldenâ€ classifier.\nThis comparison allows us to assess the impact of the classification\non the overall performance of the framework.\nAn interesting observation is that the model performance on\ndatasets consisting of string-based transformations (Web Tables and\nSpreadsheet) is slightly better when the classification is done via the\nLLM-based model compared to the golden classifier. For instance, on\nthe Web Tables dataset using edit-distance matching, the F1-score\nwith LLM-based classification is 0.983, marginally higher than the\n0.973 achieved with the golden classifier. This counterintuitive per-\nformance can be attributed to the LLM-based classifier occasionally\nmislabeling some difficult string-based transformations as general\ntransformations. In these challenging cases, treating them as gen-\neral transformations allows the model to generate the target values\ndirectly by leveraging the LLMâ€™s generative capabilities, without\nbeing constrained to produce a specific transformation function\ncovering all input rows. While this approach can lead to better tar-\nget predictions and higher recall, it sacrifices interpretability since\nthe general transformations are not explicitly defined. In contrast,\nthe golden classifier strictly labels these cases as string-based trans-\nformations, requiring the model to generate explicit transformation\nfunctions, which may be more difficult for complex patterns.\nMoreover, when exact matching is employed (right panel of the\ntable), the modelâ€™s precision increases to nearly perfect levels across\nall datasets and classification methods. This increase is expected,\nas outputs are only accepted if they exactly match the expected\ntargets, significantly decreasing the possibility of false matches.\nHowever, this strict criterion leads to a reduction in recall, as the\nmodel misses rows where there are even minor discrepancies be-\ntween the generated and expected values, such as differences in\ncapitalization, punctuation, or minor formatting variations. In con-\ntrast, using edit-distance-based matching (left panel) allows minor\ndifferences between the predicted and target values, thereby consid-\nerably increasing recall and overall F1-score across all datasets. The\ndecrease in precision with edit-distance matching is minimal com-\npared to the considerable increase in recall, resulting in a substantial\nboost in F1-score, which is a consistent trend across all datasets.\nConsequently, edit-distance matching emerges as a better choice\nwhen target values are available, as it enhances the modelâ€™s overall\nperformance by providing a better trade-off between precision and\nrecall.\nThis performance increase is more noticeable on string-based\ndatasets, where minor inconsistencies are common. Specifically,\non the Web Tables dataset under LLM-based classification, the\nF1-score improves from 0.816 with exact matching to 0.983 with\nedit-distance matching, representing a substantial increase of ap-\nproximately 20.5%. This demonstrates that allowing for slight vari-\nations in matching can significantly enhance the modelâ€™s ability to\ncorrectly map source to target values in real-world, noisy datasets\nwith inherent inconsistencies. On the other hand, on the TT and\nKBWT datasets, which include more algorithmic and general trans-\nformations and may rely on external knowledge, the improvement\nin F1-score when using edit-distance matching is less pronounced.\nFor example, on the KBWT dataset, the F1-score under LLM-based\nclassification improves from 0.512 with exact matching to 0.567\nwith edit-distance matching, an increase of approximately 10.7%.\nThis indicates that for general transformations, minor discrepancies\nare less probable to occur when the model is not constrained to a\nstring-based transformation to cover all rows.\n5.6 Class-Wise Performance and Error Analysis\nIn this section, we analyze the modelâ€™s performance across each\ntransformation class and highlight specific challenges encountered\nin some cases. This evaluation helps identify patterns in model\nperformance and limitations that may inform future improvements.\nTable 5 provides an overview of the results for each class, with\nsupport indicating the number of tables in each category.\nIn the string transformation class, the framework demonstrates\nstrong performance. When edit-distance matching is applied, only\na few cases are missed, primarily due to noisy data or substantial\n10\nTable 4: The framework performance under various classification and matching methods\nClassification Dataset\nEdit Distance Matching Exact Matching\nP R F1 AED ANED P R F1 AED ANED\nLLM\nWeb Tables (WT) 0.985 0.980 0.983 1.501 0.068 1.000 0.729 0.816 5.497 0.269\nSpreadSheet (SS) 0.955 0.949 0.952 1.944 0.094 1.000 0.818 0.828 4.879 0.180\nTable Transformation (TT) 0.904 0.895 0.898 2.678 0.219 0.966 0.736 0.756 4.252 0.340\nKBWT 0.722 0.532 0.567 7.203 0.398 0.975 0.435 0.512 7.139 0.387\nGolden\nWeb Tables (WT) 0.975 0.971 0.973 2.223 0.094 1.000 0.690 0.770 6.362 0.308\nSpreadSheet (SS) 0.953 0.949 0.951 2.132 0.104 1.000 0.798 0.809 5.270 0.202\nTable Transformation (TT) 0.919 0.918 0.918 2.466 0.219 0.992 0.733 0.756 3.915 0.344\nKBWT 0.722 0.545 0.580 7.139 0.387 0.975 0.445 0.523 7.674 0.516\nTable 5: Performance Metrics per Transformation Class\nClass Support\nEdit Distance Matching Exact Matching\nP R F1 AED ANED P R F1 AED ANED\nString 207 0.957 0.953 0.955 1.795 0.120 1.000 0.775 0.802 4.144 0.223\nNumbers 60 0.971 0.971 0.971 - - 0.971 0.971 0.971 - -\nAlgorithmic 105 0.874 0.865 0.865 3.342 0.263 1.000 0.577 0.604 5.488 0.422\nGeneral 76 0.702 0.530 0.567 6.926 0.365 0.974 0.419 0.507 7.564 0.506\nvariations in formatting that were not adequately represented in\nthe provided examples. Edit-distance matching allows for minor\ndiscrepancies, improving recall, though it occasionally results in\nmissed rows when format variations exceed the threshold for an\napproximate match. When exact matching is employed, the modelâ€™s\nrecall decreases in the string class. This drop is expected, as exact\nmatching is more stringent and does not allow for minor discrep-\nancies or transformations that partially transform the source into\ntarget. For instance, in a dataset containing information about state\ngovernors formatted asName; (birth date - death date)in the\nsource and Name - (in office years) in the target, the model\nsuccessfully maps names but the date transformation is not feasible\nvia string operations, which will adversely affect the performance\nwhen exact matching is employed.\nMoreover, in cases where provided examples are not sufficiently\nrepresentative the model may generate a transformation function\nthat fails to generalize. Consider top row in Figure 1 as an example,\nif the examples only include names without middle names, the\nmodel might generate a transformation that concatenates the first\nletter of the first name with the last name, failing to account for\nmiddle names when they appear. This indicates the limitations of\nrandom sample selector used in our experiments and highlights the\nneed for a more strategic approach to example selection, which is\nan area for future improvement.\nFor numeric transformations, the model performs exception-\nally well across all tables, achieving near-perfect precision and\nrecall. This success can be attributed to the straightforward nature\nof numeric relationships, where mathematical functions can pre-\ncisely capture the transformation patterns. The few cases where the\nmodel did not perform well were mostly outliers or instances where\nno meaningful relationship existed between the input and output\nvalues. In the algorithmic transformation class, while the overall\nperformance remains strong, we observe a slight drop in both pre-\ncision and recall. The primary challenge here is the complexity of\ncertain algorithms. For example, transforming Gregorian dates to\nHijri dates involves a sophisticated algorithm that the model par-\ntially captures. While it correctly identifies the relationship among\nsource and target, the generated code may is incomplete, leading\nto some missed transformations.\nIn the general transformation class, although the model signifi-\ncantly outperforms the baseline, the performance metrics are lower\ncompared to the other classes. This transformation class is the most\ncomplex, as it heavily relies on the LLMâ€™s knowledge to produce ac-\ncurate mappings, introducing several limitations. In some cases, the\nmodel has difficulty accurately identifying the types of the source\nand target columns. For instance, when the source is a U.S. Patent\nID and the target is the patent name, the model may misinterpret\nthe data, resulting in incorrect or nonsensical outputs. Even when\nthe model correctly determines the column types, certain trans-\nformations in this class demand external knowledge beyond the\nmodelâ€™s pre-trained data. When tasked with mapping SWIFT codes\nto bank names, the model correctly recognizes the column types\nbut often produces inaccurate or hallucinated outputs, indicating a\nlimitation in knowledge availability.\nAnother common issue arises in one-to-many and many-to-many\nrelationships, where multiple valid mappings exist for each source\nitem. For example, in tables linking movies to their casts, a single\nmovie may have numerous associated actors, and the model may\ngenerate a correct output that does not match the target, which\nis considered incorrect. These cases are not rare and contribute\nnotably to the lower performance in the general class. Addressing\n11\nTable 6: Performance of the framework with Smaller and Open Source LLMs\nModel Dataset\nEdit Distance Matching Exact Matching\nP R F1 AED ANED P R F1 AED ANED\nGPT-4o\nWeb Tables (WT) 0.975 0.971 0.973 2.223 0.094 1.000 0.690 0.770 6.362 0.308\nSpreadSheet (SS) 0.953 0.949 0.951 2.132 0.104 1.000 0.798 0.809 5.270 0.202\nTable Transformation (TT) 0.919 0.918 0.918 2.466 0.219 0.992 0.733 0.756 3.915 0.344\nKBWT 0.722 0.545 0.580 7.139 0.387 0.975 0.445 0.523 7.674 0.516\nGPT-4o.m\nWeb Tables (WT) 0.924 0.920 0.922 3.752 0.142 0.983 0.626 0.685 8.214 0.372\nSpreadSheet (SS) 0.979 0.976 0.977 1.763 0.072 1.000 0.802 0.806 4.730 0.198\nTable Transformation (TT) 0.906 0.904 0.905 5.325 0.273 0.990 0.671 0.695 5.002 0.423\nKBWT 0.659 0.483 0.519 7.534 0.451 0.939 0.373 0.440 8.430 0.591\nLLaMA\nWeb Tables (WT) 0.822 0.820 0.821 6.837 0.275 0.994 0.437 0.491 11.298 0.568\nSpreadSheet (SS) 0.915 0.912 0.913 3.551 0.235 0.981 0.389 0.398 8.942 0.611\nTable Transformation (TT) 0.815 0.811 0.812 7.422 0.505 0.992 0.452 0.465 7.531 0.717\nKBWT 0.546 0.317 0.358 9.288 0.597 0.856 0.222 0.278 9.423 0.751\nthese complex mappings effectively remains a challenge and is kept\nfor future work.\n5.7 Evaluation of Different Model Sizes and\nOpen-Source Alternatives\nTo evaluate how the size and type of language models affect our\nframeworkâ€™s performance, we experimented with different commer-\ncial and open-source models of varying sizes. Table 6 summarizes\nthe results of these experiments. In this table, GPT-4o refers to\nthe gpt-4o-2024-05-13 model, one of the leading state-of-the-art\ncommercial models. GPT-4o.m denotes the smaller and more cost-\neffective gpt-4o-mini-2024-07-18 model. The LLaMA model rep-\nresents the Llama-3.1-8B-Instruct, an open-source model with\n8 billion parameters executable on a single GPU.\nAs anticipated, the largest model, GPT-4o, generally outperforms\nthe smaller models in terms of precision, recall, and F1-score, due\nto its advanced architecture and larger parameter count, especially\nwhen exact matching is used. However, for smaller models, edit-\ndistance-based matching significantly mitigates performance gaps.\nThis method accommodates minor variations in output, helping\nsmaller models perform competitively. Notably, the gap between\nF1-scores using edit-distance versus exact matching grows as model\nsize decreases. For instance, on the WT dataset, this difference is\napproximately 0.20 for GPT-4o, 0.24 for GPT-4o-mini, and 0.33 for\nLLaMA 3.1. The benefit of edit-distance matching even allows the\nGPT-4o-mini model to outperform GPT-4o on the SS dataset, under-\nscoring its value in compensating for smaller modelsâ€™ limitations.\nInterestingly, the smallest model tested, LLaMA 3.1, demon-\nstrates baseline-comparable or superior performance across datasets\nwith edit-distance matching. Although there is a noticeable per-\nformance drop compared to the GPT models, the gap is not sub-\nstantial in the Spreadsheet dataset. This outcome implies that for\nless complex tasks or in scenarios where computational resources\nare limited, smaller open-source models like LLaMA can be a vi-\nable alternative. However, on more complex datasets like KBWT,\nwhich require handling intricate transformations and may depend\non external knowledge, the larger GPT-4o model maintains a clear\nadvantage. Additionally, when exact matching is necessaryâ€”such\nas in applications requiring high accuracy without tolerance for\nerrorsâ€”the larger models demonstrate superior performance.\n6 CONCLUSION AND FUTURE WORKS\nIn this paper, we introduced TabulaX, a novel framework that\nleverages LLMs for Multi-class Table Transformations. TabulaX\naddresses the challenges of integrating a wide range of heteroge-\nneous tables with mismatched formats by classifying input data\ninto distinct transformation classesâ€”string-based, numerical, algo-\nrithmic, and generalâ€”and applying appropriate methods tailored to\neach class. Our approach generates human-interpretable transfor-\nmation functions in the form of numeric formulas and programming\ncode, enhancing transparency and allowing users to understand and\nmodify the mappings as needed. Through extensive experiments on\nreal-world datasets from various domains, we demonstrated that\nTabulaX outperforms existing state-of-the-art approaches in terms\nof accuracy and supports a broader class of transformations.\nAs possible future work, one direction is improving the han-\ndling of general transformations that require external knowledge;\nretrieval-based methods or domain-specific knowledge bases could\nbe integrated to access additional information not present in the\ninput data. Refinements to the classification mechanism could also\nbe explored, potentially using more advanced models or leveraging\nmetadata when available, to increase the accuracy of class detection.\nAdditionally, extensions to support multi-column transformations,\nhandling complex relational mappings, and further evaluations on\ndownstream tasks such as anomaly detection, data imputation, and\nentity matching are among other potential future directions.\nACKNOWLEDGMENTS\nThis research was partially supported by the Natural Sciences and\nEngineering Research Council of Canada.\n12\nREFERENCES\n[1] Ziawasch Abedjan, John Morcos, Ihab F. Ilyas, Mourad Ouzzani, Paolo Papotti,\nand Michael Stonebraker. 2016. DataXFormer: A robust transformation discovery\nsystem. In 2016 IEEE 32nd International Conference on Data Engineering (ICDE) .\n1134â€“1145.\n[2] Mehdi Akbarian Rastaghi, Ehsan Kamalloo, and Davood Rafiei. 2022. Probing the\nRobustness of Pre-trained Language Models for Entity Matching. InProceedings of\nthe 31st ACM International Conference on Information & Knowledge Management .\n3786â€“3790.\n[3] Rajeev Alur, Dana Fisman, Rishabh Singh, and Armando Solar-Lezama. 2016.\nSyGuS-Comp 2016: Results and Analysis. Electronic Proceedings in Theoretical\nComputer Science 229 (Nov 2016), 178â€“202.\n[4] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,\nRewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris\nHesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and\nDario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in\nNeural Information Processing Systems , H. Larochelle, M. Ranzato, R. Hadsell, M.F.\nBalcan, and H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 1877â€“1901.\n[5] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao\nChen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang,\nPhilip S. Yu, Qiang Yang, and Xing Xie. 2024. A Survey on Evaluation of Large\nLanguage Models. ACM Trans. Intell. Syst. Technol. 15, 3, Article 39 (March 2024),\n45 pages.\n[6] Wenhu Chen, Ming-Wei Chang, Eva Schlinger, William Wang, and William W\nCohen. 2020. Open question answering over tables and text. arXiv preprint\narXiv:2010.10439 (2020).\n[7] Arash Dargahi Nobari and Davood Rafiei. 2022. Efficiently Transforming Tables\nfor Joinability. In 2022 IEEE 38th International Conference on Data Engineering\n(ICDE). IEEE, 1649â€“1661.\n[8] Arash Dargahi Nobari and Davood Rafiei. 2024. DTT: An Example-Driven\nTabular Transformer for Joinability by Leveraging Large Language Models. Proc.\nACM Manag. Data (SIGMOD) 2, 1, Article 24 (March 2024), 24 pages.\n[9] Dong Deng, Guoliang Li, Shuang Hao, Jiannan Wang, and Jianhua Feng. 2014.\nMassJoin: A mapreduce-based method for scalable string similarity joins. In2014\nIEEE 30th International Conference on Data Engineering . 340â€“351.\n[10] Xiang Deng, Huan Sun, Alyssa Lees, You Wu, and Cong Yu. 2020. TURL: Table\nUnderstanding through Representation Learning. Proc. VLDB Endow. 14, 3 (2020),\n307â€“319.\n[11] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:\nPre-training of Deep Bidirectional Transformers for Language Understanding.\nIn Proceedings of the 2019 Conference of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Language Technologies, NAACL-HLT .\nAssociation for Computational Linguistics, 4171â€“4186.\n[12] AnHai Doan, Alon Halevy, and Zachary Ives. 2012. Principles of data integration .\nElsevier.\n[13] Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad\nAl-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan,\net al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783 (2024).\n[14] Sumit Gulwani. 2011. Automating String Processing in Spreadsheets Using\nInput-Output Examples. InProceedings of the 38th Annual ACM SIGPLAN-SIGACT\nSymposium on Principles of Programming Languages (Austin, Texas, USA)(POPL\nâ€™11). Association for Computing Machinery, New York, NY, USA, 317â€“330.\n[15] Sumit Gulwani, William R. Harris, and Rishabh Singh. 2012. Spreadsheet Data\nManipulation Using Examples. Commun. ACM 55, 8 (Aug. 2012), 97â€“105.\n[16] Oktie Hassanzadeh, Ken Q. Pu, Soheil Hassas Yeganeh, RenÃ©e J. Miller, Lucian\nPopa, Mauricio A. HernÃ¡ndez, and Howard Ho. 2013. Discovering linkage points\nover web data. Proc. VLDB Endow. 6, 6 (April 2013), 445â€“456.\n[17] Jian He, Enzo Veltri, Donatello Santoro, Guoliang Li, Giansalvatore Mecca, Paolo\nPapotti, and Nan Tang. 2016. Interactive and deterministic data cleaning. In\nProceedings of the 2016 International Conference on Management of Data . 893â€“907.\n[18] Yeye He, Xu Chu, Kris Ganjam, Yudian Zheng, Vivek Narasayya, and Surajit\nChaudhuri. 2018. Transform-data-by-example (TDE): an extensible search engine\nfor data transformations. Proc. VLDB Endow. 11, 10 (2018), 1165â€“1177.\n[19] Yeye He, Kris Ganjam, and Xu Chu. 2015. SEMA-JOIN: Joining Semantically-\nRelated Tables Using Big Table Corpora. Proc. VLDB Endow. 8, 12 (Aug. 2015),\n1358â€“1369.\n[20] Yeye He, Kris Ganjam, Kukjin Lee, Yue Wang, Vivek Narasayya, Surajit Chaud-\nhuri, Xu Chu, and Yudian Zheng. 2018. Transform-Data-by-Example (TDE):\nExtensible Data Transformation in Excel. In Proceedings of the 2018 Interna-\ntional Conference on Management of Data (Houston, TX, USA) (SIGMOD â€™18) .\nAssociation for Computing Machinery, New York, NY, USA, 1785â€“1788.\n[21] Hiroshi Iida, Dung Thai, Varun Manjunatha, and Mohit Iyyer. 2021. TABBIE: Pre-\ntrained Representations of Tabular Data. In Proceedings of the 2021 Conference of\nthe North American Chapter of the Association for Computational Linguistics: Hu-\nman Language Technologies . Association for Computational Linguistics, Online,\n3446â€“3456.\n[22] Zhongjun Jin, Michael R. Anderson, Michael Cafarella, and H. V. Jagadish. 2017.\nFoofah: Transforming Data By Example. In Proceedings of the 2017 ACM Interna-\ntional Conference on Management of Data (Chicago, Illinois, USA) (SIGMOD â€™17) .\nAssociation for Computing Machinery, New York, NY, USA, 683â€“698.\n[23] Mihir Kale and Abhinav Rastogi. 2020. Text-to-Text Pre-Training for Data-to-Text\nTasks. In Proceedings of the 13th International Conference on Natural Language\nGeneration. Association for Computational Linguistics, Dublin, Ireland, 97â€“102.\nhttps://aclanthology.org/2020.inlg-1.14\n[24] Aamod Khatiwada, Roee Shraga, Wolfgang Gatterbauer, and RenÃ©e J Miller. 2022.\nIntegrating data lake tables. Proceedings of the VLDB Endowment 16, 4 (2022),\n932â€“945.\n[25] Peng Li, Xiang Cheng, Xu Chu, Yeye He, and Surajit Chaudhuri. 2021. Auto-\nFuzzyJoin: Auto-Program Fuzzy Similarity Joins Without Labeled Examples. In\nProceedings of the 2021 International Conference on Management of Data (Virtual\nEvent, China) (SIGMOD/PODS â€™21) . Association for Computing Machinery, New\nYork, NY, USA, 1064â€“1076.\n[26] Peng Li, Yeye He, Dror Yashar, Weiwei Cui, Song Ge, Haidong Zhang, Danielle\nRifinski Fainman, Dongmei Zhang, and Surajit Chaudhuri. 2024. Table-GPT:\nTable Fine-tuned GPT for Diverse Table Tasks. Proc. ACM Manag. Data 2, 3,\nArticle 176 (May 2024), 28 pages.\n[27] Yuliang Li, Jinfeng Li, Yoshihiko Suhara, AnHai Doan, and Wang-Chiew Tan.\n2020. Deep Entity Matching with Pre-Trained Language Models. Proc. VLDB\nEndow. 14, 1 (sep 2020), 50â€“60.\n[28] Yuliang Li, Jinfeng Li, Yoshihiko Suhara, AnHai Doan, and Wang-Chiew Tan.\n2020. Deep Entity Matching with Pre-Trained Language Models. Proc. VLDB\nEndow. 14, 1 (oct 2020), 50â€“60. https://doi.org/10.14778/3421424.3421431\n[29] Mingxing Liu, Junfeng Wang, Tao Lin, Quan Ma, Zhiyang Fang, and Yanqun Wu.\n2024. An Empirical Study of the Code Generation of Safety-Critical Software\nUsing LLMs. Applied Sciences 14, 3 (2024).\n[30] RenÃ©e J Miller. 2018. Open data integration. Proceedings of the VLDB Endowment\n11, 12 (2018), 2130â€“2139.\n[31] RenÃ©e J Miller, Fatemeh Nargesian, Erkang Zhu, Christina Christodoulakis, Ken Q\nPu, and Periklis Andritsos. 2018. Making Open Data Transparent: Data Discovery\non Open Data. IEEE Data Eng. Bull. 41, 2 (2018).\n[32] Md Mahadi Hasan Nahid and Davood Rafiei. 2024. NormTab: Improving Sym-\nbolic Reasoning in LLMs Through Tabular Data Normalization. arXiv preprint\narXiv:2406.17961 (2024).\n[33] Mohamed Nejjar, Luca Zacharias, Fabian Stiehle, and Ingo Weber. 2023. LLMs\nfor science: Usage for code generation and data analysis. Journal of Software:\nEvolution and Process (2023), e2723.\n[34] Soroush Omidvartehrani, Arash Dargahi Nobari, and Davood Rafiei. 2024.\nGXJoin: Generalized Cell Transformations for Explainable Joinability. In Ad-\nvances in Databases and Information Systems . Springer Nature Switzerland, Cham,\n123â€“137.\n[35] Ankur Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan\nDhingra, Diyi Yang, and Dipanjan Das. 2020. ToTTo: A Controlled Table-To-Text\nGeneration Dataset. In Proceedings of the 2020 Conference on Empirical Methods in\nNatural Language Processing (EMNLP) . Association for Computational Linguistics,\nOnline, 1173â€“1186. https://doi.org/10.18653/v1/2020.emnlp-main.89\n[36] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,\nMichael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the\nLimits of Transfer Learning with a Unified Text-to-Text Transformer.Journal of\nMachine Learning Research 21 (2020), 140:1â€“140:67.\n[37] Ananth Ranganathan. 2004. The levenberg-marquardt algorithm. Tutoral on LM\nalgorithm 11, 1 (2004), 101â€“110.\n[38] Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Vinija Jain, Samrat Mondal,\nand Aman Chadha. 2024. A systematic survey of prompt engineering in large\nlanguage models: Techniques and applications. arXiv preprint arXiv:2402.07927\n(2024).\n[39] Roee Shraga and RenÃ©e J Miller. 2023. Explaining dataset changes for semantic\ndata versioning with explain-da-v. Proc. VLDB Endow. 16, 6 (2023).\n[40] Rishabh Singh. 2016. BlinkFill: Semi-Supervised Programming by Example for\nSyntactic String Transformations. Proc. VLDB Endow. 9, 10 (June 2016), 816â€“827.\n[41] Yuan Sui, Mengyu Zhou, Mingjie Zhou, Shi Han, and Dongmei Zhang. 2024.\nTable Meets LLM: Can Large Language Models Understand Structured Table\nData? A Benchmark and Empirical Study. In Proceedings of the 17th ACM Inter-\nnational Conference on Web Search and Data Mining (Merida, Mexico) (WSDM\nâ€™24). Association for Computing Machinery, New York, NY, USA, 645â€“654.\n[42] Nan Tang, Ju Fan, Fangyi Li, Jianhong Tu, Xiaoyong Du, Guoliang Li, Sam\nMadden, and Mourad Ouzzani. 2021. RPT: Relational Pre-Trained Transformer\nis Almost All You Need towards Democratizing Data Preparation. Proc. VLDB\nEndow. 14, 8 (2021), 1254â€“1261.\n[43] James Thorne, Majid Yazdani, Marzieh Saeidi, Fabrizio Silvestri, Sebastian Riedel,\nand Alon Halevy. 2021. From natural language processing to neural databases.\nIn Proc. VLDB Endow. , Vol. 14. VLDB Endowment, 1033â€“1039.\n13\n[44] Jianxun Wang and Yixiang Chen. 2023. A Review on Code Generation with LLMs:\nApplication and Evaluation. In 2023 IEEE International Conference on Medical\nArtificial Intelligence (MedAI) . 284â€“289.\n[45] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang,\nAakanksha Chowdhery, and Denny Zhou. 2022. Self-consistency improves chain\nof thought reasoning in language models. arXiv preprint arXiv:2203.11171 (2022).\n[46] Yue Wang and Yeye He. 2017. Synthesizing Mapping Relationships Using Table\nCorpus. In Proceedings of the 2017 ACM International Conference on Manage-\nment of Data (Chicago, Illinois, USA) (SIGMOD â€™17) . Association for Computing\nMachinery, New York, NY, USA, 1117â€“1132.\n[47] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei\nXia, Ed Chi, Quoc V Le, and Denny Zhou. 2022. Chain-of-Thought Prompting\nElicits Reasoning in Large Language Models. In Advances in Neural Information\nProcessing Systems , Vol. 35. Curran Associates, Inc., 24824â€“24837.\n[48] Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir\nKale, Adam Roberts, and Colin Raffel. 2022. ByT5: Towards a Token-Free Fu-\nture with Pre-trained Byte-to-Byte Models. Transactions of the Association for\nComputational Linguistics 10 (03 2022), 291â€“306.\n[49] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and\nKarthik Narasimhan. 2023. Tree of Thoughts: Deliberate Problem Solving with\nLarge Language Models. In Advances in Neural Information Processing Systems ,\nVol. 36. Curran Associates, Inc., 11809â€“11822.\n[50] Pengcheng Yin, Graham Neubig, Wen-tau Yih, and Sebastian Riedel. 2020.\nTaBERT: Pretraining for Joint Understanding of Textual and Tabular Data. In\nProceedings of the 58th Annual Meeting of the Association for Computational\nLinguistics. Association for Computational Linguistics, Online, 8413â€“8426.\n[51] Tianshu Zhang, Xiang Yue, Yifei Li, and Huan Sun. 2023. Tablellama: Towards\nopen large generalist models for tables. arXiv preprint arXiv:2311.09206 (2023).\n[52] Chen Zhao and Yeye He. 2019. Auto-EM: End-to-End Fuzzy Entity-Matching\nUsing Pre-Trained Deep Models and Transfer Learning. In The World Wide Web\nConference (San Francisco, CA, USA) (WWW â€™19) . Association for Computing\nMachinery, New York, NY, USA, 2413â€“2424.\n[53] Erkang Zhu, Yeye He, and Surajit Chaudhuri. 2017. Auto-join: Joining tables by\nleveraging transformations. Proc. VLDB Endow. 10, 10 (2017), 1034â€“1045.\n14",
  "topic": "Table (database)",
  "concepts": [
    {
      "name": "Table (database)",
      "score": 0.7271854877471924
    },
    {
      "name": "Class (philosophy)",
      "score": 0.7106004357337952
    },
    {
      "name": "Computer science",
      "score": 0.6541168689727783
    },
    {
      "name": "Programming language",
      "score": 0.37552890181541443
    },
    {
      "name": "Natural language processing",
      "score": 0.3399549722671509
    },
    {
      "name": "Theoretical computer science",
      "score": 0.325700044631958
    },
    {
      "name": "Artificial intelligence",
      "score": 0.28396812081336975
    },
    {
      "name": "Database",
      "score": 0.09727418422698975
    }
  ],
  "institutions": []
}