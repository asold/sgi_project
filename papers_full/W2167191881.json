{
    "title": "The development of a critical appraisal tool for use in systematic reviews addressing questions of prevalence",
    "url": "https://openalex.org/W2167191881",
    "year": 2014,
    "authors": [
        {
            "id": "https://openalex.org/A2023216196",
            "name": "Zachary Munn",
            "affiliations": [
                "University of Adelaide"
            ]
        },
        {
            "id": "https://openalex.org/A1976896143",
            "name": "Sandeep Moola",
            "affiliations": [
                "University of Adelaide"
            ]
        },
        {
            "id": "https://openalex.org/A2037491981",
            "name": "Dagmara Riitano",
            "affiliations": [
                "University of Adelaide"
            ]
        },
        {
            "id": "https://openalex.org/A2309828383",
            "name": "Karolina Lisy",
            "affiliations": [
                "University of Adelaide"
            ]
        },
        {
            "id": "https://openalex.org/A2023216196",
            "name": "Zachary Munn",
            "affiliations": [
                "University of Adelaide"
            ]
        },
        {
            "id": "https://openalex.org/A1976896143",
            "name": "Sandeep Moola",
            "affiliations": [
                "University of Adelaide"
            ]
        },
        {
            "id": "https://openalex.org/A2037491981",
            "name": "Dagmara Riitano",
            "affiliations": [
                "University of Adelaide"
            ]
        },
        {
            "id": "https://openalex.org/A2309828383",
            "name": "Karolina Lisy",
            "affiliations": [
                "University of Adelaide"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2127468653",
        "https://openalex.org/W2085076230",
        "https://openalex.org/W2103859942",
        "https://openalex.org/W163425073",
        "https://openalex.org/W2042916741",
        "https://openalex.org/W2064317905",
        "https://openalex.org/W2062374656",
        "https://openalex.org/W2166384797",
        "https://openalex.org/W2047875943",
        "https://openalex.org/W2165999166",
        "https://openalex.org/W4392145873",
        "https://openalex.org/W2063277639",
        "https://openalex.org/W2042312051",
        "https://openalex.org/W1582290513",
        "https://openalex.org/W1607441804",
        "https://openalex.org/W1600798082",
        "https://openalex.org/W2475469026",
        "https://openalex.org/W1992637165",
        "https://openalex.org/W2316748172",
        "https://openalex.org/W2811157820",
        "https://openalex.org/W4300627763",
        "https://openalex.org/W2116810060",
        "https://openalex.org/W2054069489",
        "https://openalex.org/W4239301040"
    ],
    "abstract": "The results of this pilot study found that this tool was well-accepted by users and further refinements have been made to the tool based on their feedback. We now put forward this tool for use by authors conducting prevalence systematic reviews.",
    "full_text": "The development of a critical appraisal tool for use in systematic \nreviews addressing questions of prevalence\nZachary Munn*, Sandeep Moola, Dagmara Riitano, Karolina Lisy\nAbstract\nBackground: Recently there has been a significant increase in the number of systematic reviews addressing \nquestions of prevalence. Key features of a systematic review include the creation of an a priori protocol, clear \ninclusion criteria, a structured and systematic search process, critical appraisal of studies, and a formal process \nof data extraction followed by methods to synthesize, or combine, this data. Currently there exists no standard \nmethod for conducting critical appraisal of studies in systematic reviews of prevalence data.\nMethods: A working group was created to assess current critical appraisal tools for studies reporting prevalence \ndata and develop a new tool for these studies in systematic reviews of prevalence. Following the development of \nthis tool it was piloted amongst an experienced group of sixteen healthcare researchers. \nResults: The results of the pilot found that this tool was a valid approach to assessing the methodological \nquality of studies reporting prevalence data to be included in systematic reviews. Participants found the tool \nacceptable and easy to use. Some comments were provided which helped refine the criteria.\nConclusion: The results of this pilot study found that this tool was well-accepted by users and further \nrefinements have been made to the tool based on their feedback. We now put forward this tool for use by \nauthors conducting prevalence systematic reviews.\nKeywords: Prevalence, Survey, Critical Appraisal, Systematic Review\nCopyright: © 2014 by Kerman University of Medical Sciences\nCitation: Munn Z, Moola S, Riitano D, Lisy K. The development of a critical appraisal tool for use in \nsystematic reviews addressing questions of prevalence . Int J Health Policy Manag 2014; 3: 123–128.  \ndoi: 10.15171/ijhpm.2014.71\n*Correspondence to:\nZachary Munn \nEmail: zachary.munn@adelaide.edu.au\nArticle History:\nReceived: 18 June 2014\nAccepted: 11 August 2014\nePublished: 13 August 2014\nOriginal Article\nThe Joanna Briggs Institute, Faculty of Health Sciences, University of Adelaide, Adelaide, Australia\nhttp://ijhpm.com\nInt J Health Policy Manag 2014, 3(3), 123–128 doi 10.15171/ijhpm.2014.71\nIntroduction\nThe prevalence of a disease indicates the number of people \nin a population that have the disease at a given point in time \n(1). The accurate measurement of disease burden among \npopulations, whether at a local, national, or global level, \nis of critical importance for governments, policy-makers, \nhealth professionals and the general population to inform the \ndevelopment, delivery and use of health services. For example, \naccurate information regarding measures of disease can assist \nin planning management of disease services (by ensuring \nsufficient resources are available to cope with the burden of \ndisease), set priorities regarding public health initiatives, and \nevaluate changes and trends in diseases over time. However, \npolicy-makers are often faced with conflicting reports of \ndisease prevalence in the literature. \nThe systematic review of evidence has been proposed and \nis now well-accepted as the ideal method to summarize the \nliterature relating to a certain social or healthcare topic (2,3). \nThe systematic review can provide a reliable summary of the \nliterature to inform decision-makers in a timely fashion. Key \nfeatures of a systematic review include the creation of an a \npriori protocol, clear inclusion criteria, a comprehensive and \nsystematic search process, the critical appraisal of studies, and \na formal process of data extraction followed by methods to \nsynthesize, or combine, this data (4). In this way, systematic \nreviews extend beyond the subjective, narrative reporting \ncharacteristics of a traditional literature review to provide a \ncomprehensive, rigorous, and transparent synthesis of the \nliterature on a certain topic.\nHistorically, systematic reviews have predominantly focused \non the synthesis of quantitative evidence to establish the \neffects of interventions. In the last five years, there has been \na substantial increase in the number of systematic reviews \naddressing questions of prevalence ( Figure 1 ). However, \ncurrently there does not appear to be any formal guidance \nfor authors wishing to conduct a review of prevalence. \nConsequently, there is significant variability in the methods \nused to conduct these reviews. \nThe Joanna Briggs Institute (JBI) and the Cochrane \nCollaboration are evidence-based organizations that were \nformed to develop methodologies and guidance on the \nprocess of conducting systematic reviews (2,5–8). In 2012, a \nworking group was formed within the Joanna Briggs Institute \nto evaluate systematic reviews of prevalence and develop \nguidance for researchers wishing to conduct such reviews. \nThe group identified that the major area where prevalence \nreviews were disparate was in their conduct of critical \nappraisal or quality assessment of included studies. For \nexample, whilst some reviews used instruments that were \nappropriate for reviews of prevalence data (9,10), others used \ninstruments or criteria not designed to critically appraise  \nstudies reporting prevalence (such as reporting guidelines, \nstudy design specific tools, or self-developed criteria for their \nreview question) (11–13), or refrained from conducting a \nMunn et al.\nInternational Journal of Health Policy and Management, 2014, 3(3), 123–128\n124\nformal quality assessment altogether (14,15). Therefore, the \nworking group sought to address this gap by developing and \ntesting a critical appraisal form that could be used for studies \nincluded in systematic reviews of prevalence data.  \nMaterials and methods\nDeveloping the Tool \nThe working party began by conducting a search for \nsystematic reviews of prevalence data to determine how the \nmethodological quality of studies included in these reviews \nwere assessed. The group then searched for critical appraisal \ntools that have been used to assess studies reporting on \nprevalence data. A number of tools were identified including \nthe Joanna Briggs Institute’s Descriptive/Case series critical \nappraisal tool. A non-exhaustive list is shown in Table 1 . \nCritical appraisal tools from the Cochrane Collaboration \nand the Critical Appraisal Skills Program (CASP) were \nalso identified. \nAlthough many of these checklists identified important \ncriteria, it was felt by the group that none of these tools were \ncomplete and ideal for use during assessment of quality \nduring the systematic review process. Based on a review \nof these criteria and our own knowledge and research we \ndeveloped a tool specifically for use in systematic reviews of \nprevalence data. This tool was initially trialed by the working \ngroup and refined until it was deemed ready for further \nexternal review. Details on how to answer each question in \nthe tool are available in Appendix 1 and the Joanna Briggs \nInstitute guidance on conducting prevalence and incidence \nreviews  ( Table 2) (21).\nPilot testing \nA pilot of the tool was conducted during the 2013 Joanna \nBriggs Institute convention in Adelaide during October of \nthat year. A workshop was held on systematic reviews of \nprevalence and incidence where attendees were given a cross-\nsectional study (22) to appraise with the new tool, along with \na short survey that was developed to establish the face validity, \nease of use, acceptability and timeliness (i.e. time taken to \ncomplete) of the tool, and feedback on areas for improvement \n(23). The questions asked and how they were measured is \nreported in Table 3.\nResults\nSixteen workshop participants completed the critical appraisal \ntask and survey. Of the 16, 13 participants stated they had \nan academic/research background, 2 said they had a health \nbackground, and one said they had both. The average time \nspent working in research was 11 years, with the minimum \nbeing 2.5 years and the maximum experience being 30 years. \nFor ease of use of the critical appraisal tool, the mean score on \nthe 5-point Likert Scale was 3.63, with the majority (75%) of \nTable 1. Existing critical appraisal tools\nName Number of Criteria Comments\nJBI (3) Descriptive/Case series studies appraisal tool 9 Targeted towards specific study designs\nCentre for Evidence-Based Management Critical Appraisal of a Survey (16) 12 Targeted towards a specific study design\nLoney et al. Critical Appraisal tool for prevalence (17) 8 Designed specifically for studies assessing prevalence \nStrengthening the Reporting of Observational Studies in Epidemiology \n(STROBE) Checklist (18) 22 Targeted towards reporting\nNational Collaborating Centre for Environmental Health Critical Appraisal \nof Cross-Sectional Studies (19) 11 Addresses external and internal validity as well as \nreporting standards\nHoy et al.’s risk of bias tool (20) 10 Addresses external and internal validity\nFigure 1. Number of systematic reviews of prevalence by year of publication identified in a PubMed search\n\nMunn et al.\nInternational Journal of Health Policy and Management, 2014, 3(3), 123–128\n125\nTable 2. The Joanna Briggs Institute Prevalence Critical Appraisal Tool\nCriteria Yes No Unclear Not applicable\n1.\t Was the sample representative of the target population?\n2.\t Were study participants recruited in an appropriate way?\n3.\t Was the sample size adequate?\n4.\t Were the study subjects and the setting described in detail?\n5.\t Was the data analysis conducted with sufficient coverage of the identified sample? \n6.\t Were objective, standard criteria used for the measurement of the condition? \n7.\t Was the condition measured reliably? \n8.\t Was there appropriate statistical analysis? \n9.\t Are all important confounding factors/subgroups/differences identified and accounted for? \n10.\t Were subpopulations identified using objective criteria? \nparticipants providing a rating of 4, corresponding to ‘easy’ . \nFor the acceptability of the tool, the mean score was 4.33, with \nall participants giving either a ranking of 4 (acceptable) or 5 \n(very acceptable). For timeliness, the mean score was 3.94, \nwith 88% providing a score of 4 (acceptable). Out of all the \nparticipants, all except 1 viewed the tool as a valid quality \nappraisal checklist for prevalence data ( Table 4). \nThere were a number of suggestions provided for refinement \nand improvement of the tool. These comments resulted in \nsome changes in the order of the questions of the tool and \nthe supporting information used to assist in judging criteria, \nalthough no changes were made to the individual questions.\nDiscussion\nSystematic reviews of prevalence and incidence data are \nbecoming increasingly important as decision makers realize \ntheir usefulness in informing policy and practice. These \nreviews have the potential to better support healthcare \nprofessionals, policy-makers, and consumers in making \nevidence-based decisions that effectively target and address \nburden of disease issues both now and in to the future.\nThe conduct of a systematic review is a scientific exercise \nthat produces results which may influence healthcare \ndecisions. As such, reviews are required to have the same \nrigor expected of all research. The quality of a review, and \nany recommendations for practice that may arise, depends on \nthe extent to which scientific review methods are followed to \nminimize the risk of error and bias. The explicit and rigorous \nmethods of the process distinguish systematic reviews from \ntraditional reviews of the literature  ( 2). \nSystematic reviews normally rely on the use of critical appraisal \nchecklists that are tailored to assess the quality of a particular \nstudy design. For example, there may be separate checklists \nused to appraise randomized controlled trials, cohort studies, \ncross-sectional studies and so on. Prevalence data can be \nsourced from various study designs, even randomized \ncontrolled trials (11); however, critical appraisal tools directed \nat assessing the risk of bias of randomized controlled trials are \naimed at assessing biases related to causal effects and hence \nare not appropriate for reviews examining the prevalence \nTable 3. Survey pilot tool\nQuestion Measurement\nEase of use of the tool 5-point Likert scale (1 very difficult, 5 very easy)\nIs this a valid tool for prevalence data? Yes/No\nTimeliness 5-point Likert Scale (1 very unacceptable, 5 very acceptable)\nAcceptability 5-point Likert Scale (1 very unacceptable, 5 very acceptable)\nRedundant questions Free text\nComments for improvement Free text \nTable 4. Results from the survey\nExperience Ease of tool use Acceptability Time\nNumber of cases 15 16 15 16\nMinimum 2.50 2.00 4.00 2.00\nMaximum 30.00 4.00 5.00 5.00\nArithmetic mean 11.37 3.63 4.33 3.94\n95.00% lower confidence limit 6.94 3.24 4.06 3.63\n95.00% upper confidence limit 15.80 4.00 4.60 4.24\nStandard deviation 8.00 0.72 0.49 0.57\nMunn et al.\nInternational Journal of Health Policy and Management, 2014, 3(3), 123–128\n126\nof a condition. For example, criteria regarding the use of an \nintention-to-treat analysis as often seen in critical appraisal \nchecklists for randomized controlled trials are not a true \nquality indicator for questions of prevalence.\nDue to this, a new tool assessing validity and quality \nindicators specific to issues of prevalence has been developed. \nThis checklist addresses critical issues of internal and external \nvalidity that must be considered when assessing validity of \nprevalence data that can be used across different study designs \n(not just cross-sectional studies but all studies that might \nreport prevalence data). The criteria address the following \nissues:\n• Ensuring a representative sample.\n• Ensuring appropriate recruitment.\n• Ensuring an adequate sample size.\n• Ensuring appropriate description and reporting of study \nsubjects and setting.\n• Ensuring data coverage of the identified sample is \nadequate.\n• Ensuring the condition was measured reliably and \nobjectively.\n• Ensuring appropriate statistical analysis.\n• Ensuring confounding factors/subgroups/differences are \nidentified and accounted for. \nA pilot test of this tool amongst a group of experienced \nhealthcare professionals and researchers found that this tool \nhad face validity and high levels of acceptability, ease of use and \ntimeliness to complete. The initial results of this pilot testing \nare encouraging. This tool now needs to be tested further in \na larger scale study to assess its other clinimetric properties, \nparticularly its construct validity and inter-rater reliability.  \nWe have developed this tool as we did not feel that any of \nthe current checklists identified from our search sufficiently \naddressed important quality issues in prevalence studies. \nSome of the tools [most notably the tool refined by Hoy et \nal. (20)] contain similar questions to our tool but there are \nimportant differences. For example, we provide a criteria \nregarding sample size which is not included in the Hoy et al. \nchecklist. Our tool also has the advantage of being simple, \neasy and quick as shown during the pilot testing. This tool \nwill now be incorporated into the next version of the Joanna \nBriggs Institute’s systematic review package.  \nConclusion\nCritical appraisal is a pivotal step in the process of systematic \nreviews. As reviews of questions addressing prevalence \nbecome more well-known, critical appraisal tools addressing \nstudies reporting prevalence data are needed. Following a \nsearch of the literature a new tool has been proposed that can \nbe used for studies reporting prevalence data, developed by a \nworking party within the Joanna Briggs Institute. The results \nof this pilot study found that this tool was well-accepted by \nusers and further refinements have been made to the tool \nbased on their feedback. We now put forward this tool for use \nby authors conducting prevalence systematic reviews.\nAcknowledgements \nThe authors would like to acknowledge the participants of the \nworkshop and the wider staff of the Joanna Briggs Institute \nand its collaboration for their feedback.\nEthical issues \nNo ethical issues are raised.\nCompeting interests \nThe authors declare that they have no competing interests. \nAuthors’ contributions \nZM lead the methodological group and drafted the paper. SM, DR, and KL were \nmembers of the working group and provided substantial input regarding its \ndevelopment and testing. \nReferences \n1. Webb P, Bain C, Pirozzo S. Essential epidemiology: an \nintroduction for students and health professionals . New York: \nCambridge University Press; 2005.\n2. Munn Z, Tufanaru C, Aromataris E. Data extraction and \nsynthesis in systematic reviews. Am J Nurs  2014; 114: 49–54. \ndoi: 10.1097/01.naj.0000451683.66447.89\n3. The Joanna Briggs Institute. Reviewer’s Manual. Australia: The \nJoanna Briggs Institute; 2014.\n4. Pearson A, Robertson-Malt S, Rittenmeyer L. Synthesizing \nQualitative Evidence. Philadelphia: Lippincott Williams & Wilkins; \n2011. \n5. Noyes J, Popay J, Pearson A, Hannes K, Booth A. Qualitative \nresearch and Cochrane reviews. In: Higgins J, Green S, editors. \nCochrane Handbook for Systematic Reviews of Interventions. \nVersion 5.1.0 [updated March 2011]. The Cochrane Collaboration; \n2011.\n6. Pearson A. Balancing the evidence: incorporating the synthesis \nof qualitative data into systematic reviews. JBI Reports 2004; 2: \n45–64. doi: 10.1111/j.1479-6988.2004.00008.x\n7. Pearson A, Jordan Z, Munn Z. Translational science \nand evidence-based healthcare: a clarification and \nreconceptualization of how knowledge is generated and used in \nhealthcare. Nursing Research and Practice 2012; 2012: 792519.  \ndoi: 10.1155/2012/792519\n8. The Joanna Briggs Institute. Joanna Briggs Institute Reviewers’ \nManual: 2011 edition . Adelaide: The Joanna Briggs Institute; \n2011.\n9. Sawyer A, Ayers S, Smith H. Pre- and postnatal psychological \nwellbeing in Africa: a systematic review. J Affect Disord  2010; \n123: 17–29. doi: 10.1016/j.jad.2009.06.027\n10. Mirza I, Jenkins R. Risk factors, prevalence, and treatment of \nanxiety and depressive disorders in Pakistan: systematic review. \nBMJ 2004; 328: 794. doi: 10.1136/bmj.328.7443.794\n11. Van Lancker A, Velghe A, Van Hecke A, Verbrugghe M, Van \nDen Noortgate N, Grypdonck M, et al. Prevalence of symptoms \nin older cancer patients receiving palliative care: a systematic \nreview and meta-analysis. J Pain Symptom Manage 2014; 47: \n90–104. doi: 10.1016/j.jpainsymman.2013.02.016\n12. Klaassen KM, Dulak MG, van de Kerkhof PC, Pasch MC. The \nprevalence of onychomycosis in psoriatic patients: a systematic \nreview. J Eur Acad Dermatol Venereol  2014; 28: 533–41.  doi: \n10.1111/jdv.12239\n13. McGrath J, Saha S, Welham J, El Saadi O, MacCauley C, \nChant D. A systematic review of the incidence of schizophrenia: \nthe distribution of rates and the influence of sex, urbanicity, \nmigrant status and methodology. BMC Med  2004; 2:13. doi: \n10.1186/1741-7015-2-13\n14. Goto A, Goto M, Noda M, Tsugane S. Incidence of type 2 \ndiabetes in Japan: a systematic review and meta-analysis. PloS \nMunn et al.\nInternational Journal of Health Policy and Management, 2014, 3(3), 123–128\n127\nOne 2013; 8: e74699.  doi: 10.1371/journal.pone.0074699\n15. Bahekar AA, Singh S, Saha S, Molnar J, Arora R. The prevalence \nand incidence of coronary heart disease is significantly increased \nin periodontitis: a meta-analysis. Am Heart J 2007; 154: 830–7. \ndoi: 10.1016/j.ahj.2007.06.037\n16. Centre for Evidence-Based Management. Critical appraisal of \na survey. [updated 2014 June 5]. Available from: http://www.\ncebma.org/wp-content/uploads/Critical-Appraisal-Questions-for-\na-Survey.pdf \n17. Loney PL, Chambers LW, Bennett KJ, Roberts JG, Stratford PW. \nCritical appraisal of the health research literature: prevalence or \nincidence of a health problem. Chronic Dis Can 1998; 19: 170–6.\n18. Vandenbroucke JP, von Elm E, Altman DG, Gøtzsche PC, \nMulrow CD, Pocock SJ, et al . Strengthening the Reporting of \nObservational Studies in Epidemiology (STROBE): explanation \nand elaboration. PLoS Med 2007; 4: e297. doi: 10.1371/journal.\npmed.0040297\n19. National Collaborating Centre for Environmental Health \n(NCCEH). A Primer for Evaluating the Quality of Studies on \nEnvironmental Health Critical Appraisal of Cross-Sectional \nStudies. [updated 2014 June 5]. Available from:  http://www.\nncceh.ca/sites/default/files/Critical_Appraisal_Cross-Sectional_\nStudies_Aug_2011.pdf\n20. Hoy D, Brooks P, Woolf A, Blyth F, March L, Bain C, et al . \nAssessing risk of bias in prevalence studies: modification of \nan existing tool and evidence of interrater agreement. J clin \nepidemiol 2012; 65: 934–9. doi: 10.1016/j.jclinepi.2011.11.014\n21. Munn Z, Moola S, Lisy K, Riitano D. The Systematic Review \nof Prevalence and Incidence Data The Joanna Briggs Institute \nReviewer’s Manual 2014. Australia: The Joanna Briggs Institute; \n2014.\n22. Lim ES, Ko YK, Ban KO. Prevalence and risk factors of \nmetabolic syndrome in the Korean population--Korean National \nHealth Insurance Corporation Survey 2008. J Adv Nurs  2013; \n69: 1549–61. doi: 10.1111/jan.12013\n23. Verhagen AP, de Vet HC, de Bie RA, Boers M, van den Brandt \nPA. The art of quality assessment of RCTs included in systematic \nreviews. J Clin Epidemiol 2001; 54: 651–4. doi: 10.1016/s0895-\n4356(00)00360-7\n24. Naing L, Winn T, Rusli BN. Practical issues in calculating the \nsample size for prevalence studies. Archives of Orofacial \nSciences 2006; 1: 9–14.\n25. Daniel WW. Biostatistics:  A  Foundation for  Analysis  in  the  \nHealth  Sciences. 7th ed. New York: John Wiley & Sons; 1999.\nImplications for policy makers\n•\t Until now there has been substantial variability in how \nstudies reporting prevalence data are critically appraised. \nThe tool proposed within this paper can be considered \nas a valid option for researchers and policy-makers when \nconducting systematic reviews of prevalence. \n•\t This tool guides the assessment of internal and external \nvalidity of studies reporting prevalence data.\nImplications for public\nSystematic reviews are of great importance to provide a \ncritical summary of the research and inform evidence-\nbased practice. Prevalence systematic reviews are \nbecoming increasingly popular within the research \ncommunity. This article proposes a new tool that can \nbe used during the conduct of these types of systematic \nreviews to critically appraise studies to ensure that their \nresults are valid. \nKey Messages \nAppendix 1\nPrevalence Critical Appraisal Instrument \nThe 10 criteria used to assess the methodological quality of \nstudies reporting prevalence data and an explanation are \ndescribed below. These questions can be answered either with \na yes, no, unclear, or not applicable. \nAnswers: Y es, No, Unclear or Not/Applicable \n1. Was the sample representative of the target population? \nThis  question  relies  upon  knowledge  of  the  broader  \ncharacteristics  of  the  population  of interest. If the study \nis of women with breast cancer, knowledge of at least the \ncharacteristics, demographics, and medical history is needed. \nThe term “target population” should not be taken to  infer  \nevery  individual  from  everywhere  or  with  similar  disease  \nor  exposure  characteristics. Instead,  give  consideration  to  \nspecific  population  characteristics  in  the  study,  including  \nage range, gender, morbidities, medications, and other \npotentially influential factors. For example, a sample may not \nbe representative of the target population if a certain group \nhas been used (such as those working for one organisation, \nor one profession) and the results then inferred to the target \npopulation (i.e. working adults). \n2. Were study participants recruited in an appropriate way? \nRecruitment is the calling or advertising strategy for gaining \ninterest in the study, and is not the same as sampling. Studies \nmay report random sampling from a population, and the \nmethods section should report how sampling was performed. \nWhat source of data were study participants recruited from?  \nWas the sampling frame appropriate?  For example, census \ndata is a  good example of appropriate recruitment as a good \ncensus will identify everybody. Was everybody included who \nshould have been included?  Were any groups  of  persons  \nexcluded?  Was the whole population of interest surveyed? \nIf not, was random sampling from a defined subset of the \npopulation employed? Was stratified random sampling with \neligibility criteria used to ensure the sample was representative \nof the population that the researchers were generalizing to?\n3. Was the sample size adequate?\nAn adequate sample size is important to ensure good \nprecision of the final estimate. Ideally we are looking for \nevidence that the authors conducted a sample size calculation \nMunn et al.\nInternational Journal of Health Policy and Management, 2014, 3(3), 123–128\n128\nto determine an adequate sample size.  This will estimate how \nmany subjects are needed to produce a reliable estimate of the \nmeasure(s) of interest. For conditions with a low prevalence, \na larger sample size is needed. Also consider sample sizes for \nsubgroup (or characteristics) analyses, and whether these are \nappropriate. Sometimes, the study will be large enough (as \nin large national surveys) whereby a sample size calculation \nis not required. In these cases, sample size can be considered \nadequate.  \nWhen there is no sample size calculation and it is not a large \nnational survey, the reviewers may consider conducting their \nown sample size analysis using the following formula (24,25):\n2\n2\n(1 )ZP Pn d\n−=\nWhere:\nn= sample size\nZ= Z statistic for a level of confidence\nP= Expected prevalence or proportion (in proportion of one; \nif 20%, P= 0.2)\nd= precision (in proportion of one; if 5%, d= 0.05)\n4. Were the study subjects and setting described in detail? \nCertain  diseases  or  conditions  vary  in  prevalence  across  \ndifferent  geographic  regions  and populations  (e.g.  women  \nvs.  men,  socio-demographic  variables  between  countries).  \nHas  the study sample been described in sufficient detail so \nthat other researchers can determine if it is comparable to the \npopulation of interest to them?\n5. Is the data analysis conducted with sufficient coverage of the \nidentified sample?\nA large number of dropouts, refusals or “not founds” amongst \nselected subjects may diminish a study’s validity, as can low \nresponse rates for survey studies.\n- Did the authors describe the reasons for non-response \nand compare persons in the study to those not in the \nstudy, particularly with regards to their socio-demographic \ncharacteristics?\n-  Could  the  not-responders  have  led  to  an  underestimate  of  \nprevalence  of  the  disease  or condition under investigation?\n- If  reasons  for  non-response  appear  to  be  unrelated  to  the  \noutcome  measured  and  the characteristics of non-responders \nare comparable to those in the study, the researchers may be \nable to justify a more modest response rate. \n-  Did  the  means  of  assessment  or  measurement  negatively  \naffect  the  response  rate (measurement should be easily \naccessible, conveniently timed for participants, acceptable in \nlength, and suitable in content). \n6. Were objective, standard criteria used for measurement of \nthe condition?\nHere  we  are  looking  for  measurement  or  classification  \nbias.  Many  health  problems  are  not easily diagnosed or \ndefined and some measures may not be capable of including \nor excluding appropriate levels or stages of the health problem. \nIf the outcomes were assessed based on existing definitions or \ndiagnostic criteria, then the answer to this question is likely to \nbe yes. If the outcomes were assessed using observer reported, \nor self-reported scales, the risk of over- or under-reporting \nis increased, and objectivity is compromised. Importantly, \ndetermine if the measurement tools used were validated \ninstruments as this has a significant impact on outcome \nassessment validity.\n7. Was the condition measured reliably?\nConsiderable judgment is required to determine the presence \nof some health outcomes. Having established the objectivity \nof the outcome measurement instrument (see item 6 of this \nscale), it  is  important  to  establish  how  the  measurement  \nwas  conducted.  Were  those  involved  in collecting data \ntrained or educated in the use of the instrument/s? If there \nwas more than one data collector, were they similar in terms \nof level of education, clinical or research experience, or level \nof responsibility in the piece of research being appraised?\n-  Has the researcher justified the methods chosen?\n- Has the researcher made the methods explicit? (For \ninterview method, how were interviews conducted?) \n8. Was there appropriate statistical analysis?\nAs with any consideration of statistical analysis, consideration \nshould be given to whether there was a more appropriate \nalternate statistical method that could have been used. The \nmethods section should be detailed enough for reviewers \nto identify the analytical technique used and how specific \nvariables were measured. Additionally, it is also important to \nassess the appropriateness of the analytical strategy in terms \nof the assumptions associated with the approach as differing \nmethods of analysis are based on differing assumptions about \nthe data and how it will respond. Prevalence rates found in \nstudies only provide estimates of the true prevalence of a \nproblem in the larger population. Since some \nsubgroups are very small, 95% confidence intervals are \nusually given. \n9. Are all important confounding factors/ subgroups/differences \nidentified and accounted for?\nIncidence and prevalence studies often draw or report findings \nregarding the differences between groups. It is important that \nauthors of these studies identify all important confounding \nfactors, subgroups and differences and account for these. \n10. Were subpopulations identified using objective criteria?\nObjective criteria should also be used where possible to \nidentify subgroups (refer to question 6)."
}