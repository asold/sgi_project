{
  "title": "Guiding Generative Language Models for Data Augmentation in Few-Shot Text Classification",
  "url": "https://openalex.org/W3212218375",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5012792921",
      "name": "Aleksandra Edwards",
      "affiliations": [
        "Cardiff University"
      ]
    },
    {
      "id": "https://openalex.org/A5060273715",
      "name": "Asahi Ushio",
      "affiliations": [
        "Cardiff University"
      ]
    },
    {
      "id": "https://openalex.org/A5086289154",
      "name": "José Camacho-Collados",
      "affiliations": [
        "Cardiff University"
      ]
    },
    {
      "id": "https://openalex.org/A5033592980",
      "name": "Hélène de Ribaupierre",
      "affiliations": [
        "Cardiff University"
      ]
    },
    {
      "id": "https://openalex.org/A5005253980",
      "name": "Alun Preece",
      "affiliations": [
        "Cardiff University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3014025313",
    "https://openalex.org/W2971296908",
    "https://openalex.org/W2143017621",
    "https://openalex.org/W2407080277",
    "https://openalex.org/W3089105501",
    "https://openalex.org/W3105604018",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2982399380",
    "https://openalex.org/W2245473182",
    "https://openalex.org/W2038721957",
    "https://openalex.org/W2980257913",
    "https://openalex.org/W2996287690",
    "https://openalex.org/W3098341425",
    "https://openalex.org/W2984284833",
    "https://openalex.org/W2114535528",
    "https://openalex.org/W2905266130",
    "https://openalex.org/W3033544963",
    "https://openalex.org/W3026805444",
    "https://openalex.org/W2097117768",
    "https://openalex.org/W2594590228",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W203446342",
    "https://openalex.org/W2963809228",
    "https://openalex.org/W2618530766",
    "https://openalex.org/W3109974350",
    "https://openalex.org/W3113542424",
    "https://openalex.org/W2074466695",
    "https://openalex.org/W2996749617",
    "https://openalex.org/W2998184481",
    "https://openalex.org/W3197544723",
    "https://openalex.org/W1493526108",
    "https://openalex.org/W1979651826",
    "https://openalex.org/W3117527017",
    "https://openalex.org/W3010293452",
    "https://openalex.org/W3139403840",
    "https://openalex.org/W2963216553",
    "https://openalex.org/W3030772833",
    "https://openalex.org/W2921386177",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3103417625",
    "https://openalex.org/W3011920570",
    "https://openalex.org/W2946433668",
    "https://openalex.org/W2963626623"
  ],
  "abstract": "Data augmentation techniques are widely used for enhancing the performance of machine learning models by tackling class imbalance issues and data sparsity. State-of-the-art generative language models have been shown to provide significant gains across different NLP tasks. However, their applicability to data augmentation for text classification tasks in few-shot settings have not been fully explored, especially for specialised domains. In this paper, we leverage GPT-2 (Radford A et al, 2019) for generating artificial training instances in order to improve classification performance. Our aim is to analyse the impact the selection process of seed training examples have over the quality of GPT-generated samples and consequently the classifier performance. We perform experiments with several seed selection strategies that, among others, exploit class hierarchical structures and domain expert selection. Our results show that fine-tuning GPT-2 in a handful of label instances leads to consistent classification improvements and outperform competitive baselines. Finally, we show that guiding this process through domain expert selection can lead to further improvements, which opens up interesting research avenues for combining generative models and active learning.",
  "full_text": "Guiding Generative Language Models for\nData Augmentation in Few-Shot Text Classiﬁcation\nAleksandra Edwards† Asahi Ushio† Jose Camacho-Collados†\nHélène de Ribaupierre† Alun Preece‡\n†School of Computer Science and Informatics, Cardiff University, United Kingdom\n‡Crime and Security Research Institute, Cardiff University, United Kingdom\n{edwardsai,ushioa,camachocolladosj,deribaupierreh,preecead}@cardiff.ac.uk\nAbstract\nData augmentation techniques are widely used\nfor enhancing the performance of machine\nlearning models by tackling class imbalance\nissues and data sparsity. State-of-the-art gen-\nerative language models have been shown to\nprovide signiﬁcant gains across different NLP\ntasks. However, their applicability to data aug-\nmentation for text classiﬁcation tasks in few-\nshot settings have not been fully explored, es-\npecially for specialised domains. In this pa-\nper, we leverage GPT-2 (Radford et al., 2019)\nfor generating artiﬁcial training instances in or-\nder to improve classiﬁcation performance. Our\naim is to analyse the impact the selection pro-\ncess of seed training examples has over the\nquality of GPT-generated samples and conse-\nquently the classiﬁer performance. We pro-\npose a human-in-the-loop approach for select-\ning seed samples. Further, we compare the ap-\nproach to other seed selection strategies that\nexploit the characteristics of specialised do-\nmains such as human-created class hierarchi-\ncal structure and the presence of noun phrases.\nOur results show that ﬁne-tuning GPT-2 in\na handful of label instances leads to consis-\ntent classiﬁcation improvements and outper-\nform competitive baselines. The seed selec-\ntion strategies developed in this work lead to\nsigniﬁcant improvements over random seed\nselection for specialised domains. We show\nthat guiding text generation through domain\nexpert selection can lead to further improve-\nments, which opens up interesting research av-\nenues for combining generative models and ac-\ntive learning.\n1 Introduction\nData sparsity and class imbalance are common\nproblems in text classiﬁcation tasks (Türker et al.,\n2019; Zhang and Wu, 2015; Shams, 2014; Kumar\net al., 2020), especially when the text to be labelled\nis from a highly-specialised domain where only\nscarce domain experts can perform the labelling\ntask (Türker et al., 2019; Ali, 2019; Lu et al., 2021).\nData Augmentation (DA) is a widely used method\nfor tackling such issues (Anaby-Tavor et al., 2020;\nKumar et al., 2020; Papanikolaou and Pierleoni,\n2019). However, the well-established DA methods\nin domains such as computer vision and speech\nrecognition (Anaby-Tavor et al., 2020; Giridhara\net al., 2019; Krizhevsky et al., 2017; Cui et al.,\n2015; Ko et al., 2015; Szegedy et al., 2015), rely-\ning on simple transformations of existing samples,\ncannot be easily transferred to textual data as they\ncan lead to syntactic and semantic distortions to\ntext (Giridhara et al., 2019; Anaby-Tavor et al.,\n2020).\nRecent advances in text generation models, such\nas GPT and subsequent releases (Radford et al.,\n2018), have led to the development of new DA ap-\nproaches which generate additional training data\nfrom original samples, rather than perform only\nlocal changes to the text. Related studies use\ntext generation models for improving relation ex-\ntraction (Papanikolaou and Pierleoni, 2019; Ku-\nmar et al., 2020), tackle class imbalance prob-\nlems for extreme multi-label classiﬁcation tasks\n(Zhang et al., 2020), and augment domain-speciﬁc\ndatasets in order to improve performance in various\ndomain-speciﬁc classiﬁcation tasks (Amin-Nejad\net al., 2020). Speciﬁcally, Kumar et al. (2020) and\nAnaby-Tavor et al. (2020) explore different ﬁne-\ntuning approaches for pre-trained models for data\naugmentation in order to preserve class-label infor-\nmation. Results showed the potential of generative\nmodels such as GPT-2 (Radford et al., 2019) and\nBART (Lewis et al., 2019) to augment small col-\nlections of labelled data. Further, an important\nproblem with text generation techniques is the pos-\nsibility of generating noise which decreases the\nperformance of classiﬁcation models rather than\nimproving it (Yang et al., 2020). However, this\nproblem is ignored in the aforementioned studies.\nThe most similar study to ours is that of Yang\narXiv:2111.09064v2  [cs.CL]  9 Jan 2023\net al. (2020) in the context of commonsense reason-\ning. They proposed an approach based on the use\nof inﬂuence functions and heuristics for selecting\nthe most diverse and informative artiﬁcial samples\nfrom an already-generated artiﬁcial dataset. In-\nstead, we focus on the previous step of selecting\nthe most informative samples (or seeds) from the\noriginal data. We show that a careful selection of\nclass representative samples from the original data\nin the ﬁrst place can already lead to improvements\nand has an important efﬁciency advantage, as it\nprevents an unnecessary waste of resources and\ntime of generating unused generated documents,\nespecially considering how resource expensive gen-\nerative language models are (Strubell et al., 2019;\nSchwartz et al., 2019). Finally, there is no research\non exploiting the use of experts knowledge for im-\nproving the performance of generative language\nmodels for specialised domains.\nTherefore, our aim is to improve the quality of\ngenerated artiﬁcial instances used for text classiﬁca-\ntion training by developing seed selection strategies\nto guide the generation process. Speciﬁcally, we\npropose three DA methods in order to improve few-\nshot text classiﬁcation performance using GPT-2 —\n1) a human-in-the-loop method that involves a do-\nmain expert choosing class representative samples;\n2) a method that leverages the expert-generated\nclassiﬁcation hierarchy of a dataset in order to im-\nprove the classiﬁcation of the top hierarchy classes;\n3) a method that selects the seeds with the maxi-\nmum occurrence of nouns. We chose these seed\nselection strategies because they exploit character-\nistics associated with specialised domains such as\nhigh number of terms, annotation performed by ex-\nperts, and hierarchical class structure (common for\nsocial science and medical domains which require\nthematic analysis).\nOur contributions are summarised as follows.\n• We advocate an important but not-well-\nstudied problem of exploring how the qual-\nity of generated data and consequently few-\nshot classiﬁcation can be improved using text\ngeneration-based DA strategies. We perform\nanalysis for more specialised domain requir-\ning domain experts for annotation.\n• We propose novel seed selection strategies\nand analyse their impact on the performance\nof text generation-based data augmentation\nmethods for few-shot text classiﬁcation —\nWe show that classiﬁcation performance can\nbe improved signiﬁcantly for specialised do-\nmains with limited labelled data using seed se-\nlection strategies and label preservation tech-\nniques. The human-in-the-loop seed selection\nproved to be the most suitable method for im-\nproving the quality of the generated data for\nspecialised domains.\n• We analyse how different approaches of ﬁne-\ntuning GPT-2 model affect the quality of gen-\nerated data and consequently the classiﬁcation\nperformance.\n2 Methodology\nWe experiment with two ﬁne-tuning techniques for\nGPT in order to identify optimal ways for adapting\nGPT-2 model for DA for classiﬁcation. Further, our\nanalysis focus on few-shot classiﬁcation because of\nthe demand for approaches which can perform well\nfor only a handful of training instances especially in\nspecialised domains where experts are sparse and\ndata access is limited. However, our methodology\ncan be easily extended for classiﬁcation problems\nwith more labelled data and it can also be used to\ngenerate more artiﬁcial training data.\n2.1 Seed Selection Strategies\nWe implement four seed selection strategies, which\nwe describe below.\nHuman-in-the-loop Seed Selection. The highly\nspecialised nature of some domains where the man-\nual annotation of documents is performed by ex-\nperts show that identifying class representative sam-\nples might require more implicit knowledge that\nis hard to be captured by statistical approaches.\nTherefore, we conducted a study asking experts\nto select the class representative samples from the\noriginal training data. The chosen seeds are then\nused to generate additional training data. We ex-\nplain the approach in Section 3.5.\nMaximum Nouns-guided Seed Selection.\nMany specialised domains are rich of domain-\nspeciﬁc terminology and thus we believe that\nnoun-rich instances might be more indicative for\nthe classes compared to the other training samples.\nTherefore, we use this strategy to select the seeds\nwith the maximum occurrence of nouns. We\nidentify single word nouns and compound nouns\nwithin data using NLTK (Bird and Loper, 2004).\nSubclass-guided Seed Selection. In this strat-\negy, we leverage the human-generated classiﬁca-\ntion hierarchy of a dataset in order to improve the\nclassiﬁcation of the top classes. Speciﬁcally, we se-\nlect a roughly balanced number of seeds from each\nsubclass belonging to a given label. In this way,\nwe diversify the vocabulary for each overall class\nby ensuring the equal participation of representa-\ntive samples from even the most underrepresented\nsubclasses.\nRandom Seed Selection. For this strategy we\nsimply select a ﬁxed number of instances in a ran-\ndom manner. We use random selection to evaluate\nwhether the rest of the seed selection strategies lead\nto improvements in classiﬁcation.\n2.2 Text Generation\nWe generate artiﬁcial data using the generative pre-\ntrained model, GPT-2 (Radford et al., 2019). We\nuse GPT-2 model as it gives a state-of-the-art per-\nformance for many text generation tasks and also\nhave been designed with the objective to ﬁt scenar-\nios with few-shot and even zero-shot settings. We\nuse two methods for ﬁne-tuning the GPT-2 model\n— we ﬁne-tune the model on the entire dataset and\nwe also ﬁne-tune a speciﬁc GPT-2 model for each\ngiven class to ensure label-preservation for the gen-\nerated sequences. Fine-tuning a separate GPT-2\nmodel per label ensures that each model has been\nexposed to text associated with a single class. We\nalso perform experiments using a pre-trained GPT-\n2 model. We compare three models in order to\nassess the need of ﬁne-tuning and the use of addi-\ntional methods for label-preservation when using\nTG-based DA for classiﬁcation tasks. These mod-\nels are then leveraged to generate new documents\ngiven a labeled instance. These analyses help iden-\ntify whether ﬁne-tuning a separate model per label\nis a suitable method for ensuring label-preservation\nof the generated data.\nEnsuring Robustness To ensure robustness, the\ntext generation step is performed for three iterations\nand the results are averaged. Additionally, we per-\nform statistical analysis to check overall whether\ntext generation-based methods are suitable for im-\nproving the performance of classiﬁers or they tend\nto add more noise versus using no augmentation\napproaches.\nFigure 1: Overview of the methodology\n2.3 Text Classiﬁcation\nIn this ﬁnal step, we use the augmented training\ndata to train a fastText classiﬁer (Joulin et al., 2017)\ncoupled with domain-trained fastText word embed-\ndings. The reason to use a simple model such as\nfastText is its efﬁciency and that transformer-based\nmodels tend to not perform well with limited data\nin document classiﬁcation and in general tasks that\ndo not require a ﬁne granularity (Joshi et al., 2020).\nIndeed, fastText has been shown to perform equally\nor better with limited labeled data in document clas-\nsiﬁcation, compared to more sophisticated models\nsuch as BERT (Edwards et al., 2020).\n3 Experimental Setting\nIn the following we describe our few-shot text clas-\nsiﬁcation experimental setting.1\n3.1 Safeguarding Domain\nFor our experiments, we selected the Safeguarding\nreports dataset (Edwards et al., 2021). The pur-\npose of the safeguarding reports is to identify and\ndescribe related events that precede a serious safe-\nguarding incident and to reﬂect on agencies’ roles.\nAs a special trait of this dataset, the reports contain\ndomain-speciﬁc terminology which makes them\nhard to analyse with existing text analysis tools\n(Edwards et al., 2019). Further, safeguarding is a\nmulti-disciplinary domain involving terminology\nand issues from various other disciplines such as\ncriminology, healthcare, and law. Thus, approaches\nconducted for the safeguarding documents should\nbe applicable for wider range of domains. Addi-\ntionally, we perform comparison for two additional\ndatasets which do not require domain expert for an-\nnotation. These are: 20 Newsgroups (Lang, 1995)\nand Toxic comments (Hosseini et al., 2017) (more\ninformation is given in the Appendix). However,\nwe conducted the human-in-the-loop, i.e., expert-\nguided seed selection strategy only for the safe-\nguarding domain where the class framework is cre-\nated by subject-matter experts. While the man-\nual annotation of the documents is performed on\n1Code and data are available.\npassage level 2, we include experiments on sen-\ntence level in order to evaluate performance of text\ngeneration methods for generating both short and\nlong sequences. We perform prediction for the top\nclasses of the dataset. However, as mentioned in\nSection 2, we use the sub-classes to select seed\ninstances. For providing clarity and transparency\ninto the sample generation process, we convert the\nmulti-label classiﬁcation task of the Safeguarding\nand Toxic comments dataset to multi-class problem,\nremoving the few instances that were labeled with\nmore than one class in the original dataset. Focus-\ning on samples with a single label can further help\ngenerate stronger class representatives and thus can\nhelp both multi-class and multi-label classiﬁcation.\nThe main features and statistics for the datasets are\nsummarized in Table 1.\nDataset DomainTask ClassSubclassAvg len# TestSafeguarding (passages)Social reportsTheme detection5 34 45 284Safeguarding (sentences)Social reportsTheme detection5 34 18 28420 NewsgroupsNewsgroups285 6 20 285 6,728Toxic commentsWikipedia46 2 5 46 63,978\nTable 1: Overview of the datasets used for text classiﬁ-\ncation: Average number of tokens per instance (Av len),\nnumber of classes (Class), number of subclasses (Subc)\nand number of test instances (Test)\nFiltering training data. We focus on few-shot\nscenarios where the dataset is balanced. We start\nexperiments with 5 and 10 instances per label, ex-\ntracted randomly from the original data (‘base’ in-\nstances), with at least one instance per subclass.\nThen, we add 5, 10, and 20 artiﬁcially generated in-\nstances to the ‘base’ instances (‘add’ instances) in\norder to evaluate the effect of methods over differ-\nent sized training data (consisting of both original\nand artiﬁcially generated samples).\nDomain data. In addition to the datasets with a\nlimited amount of labels, we also leverage domain-\nspeciﬁc corpora (in the form of the original train-\ning sets for each dataset, without making use of\nthe labels) with two purposes: (1) analyzing the\neffect on GPT-2 ﬁne-tuned on more data for gen-\nerating new instances, and (2) recreating a usual\nscenario in practice, which is having a relatively\nlarge unlabeled corpus but a small number of an-\nnotations. The corresponding domain corpus were\nalso used by fastText (Bojanowski et al., 2017) to\nlearn domain-speciﬁc embeddings.\n2Passages in the safeguarding reports are a list of a few\nsentences which could be viewed as short paragraphs. The\nlabels for the classiﬁcation remain unchanged.\n3.2 Text Generation\nAs mentioned in Section 2, we use the GPT-2\nlanguage model (Radford et al., 2019) for gen-\nerating additional training instances. We ﬁne-\ntuned the GPT-2 model using the GPT-2 Hugging\nFace default transformers implementation (Wolf\net al., 2019). In addition to the pre-trained general-\ndomain model, we ﬁne-tune GPT-2 in each training\nset as well as per label using causal language model\ntechnique where the model predicts the next token\nin a sequence. We ﬁne-tune the model for 4 epochs\nand learning rate 5e-5. For generating additional\ntraining sequences we use the sampling method of\nHoltzman et al. (2019).\n3.3 Classiﬁcation\nAs mentioned in Section 2.3, we use fastText3 as\nour text classiﬁer (Joulin et al., 2017, FT) where we\nuse ’softmax’, 2 grams, and domain-trained word\nembeddings. In order to learn domain-speciﬁc\nword embedding models we used the correspond-\ning training sets for each dataset by using fastText’s\nskipgram model (Bojanowski et al., 2017). We use\nfastText word embeddings rather than other word\nembedding models as they tend to deal with OOV\nwords better than Glove and word2vec approaches.\nAlso, fastText embeddings are the default using\nthe fastText classiﬁer. We report results based on\nthe standard micro- and macro- averaged F1 (Yang,\n1999).\n3.4 Data Augmentation Baselines\nFor our baselines, we employ synonym, word em-\nbedding and language model based strategies for\nword replacement, and back-translation for sen-\ntence replacement (see Section A in the Appendix\nfor more details on DA techniques). As imple-\nmentations, we rely on TextAttack (Morris et al.,\n2020) for the synonym and word embedding ap-\nproaches, and nlpaug (Ma, 2019) for the language\nmodel and back-translation. We follow the default\nconﬁgurations for both libraries, where WordNet\n(Miller, 1998) is used as a thesaurus for synonym\nreplacement, BERT (Devlin et al., 2019) ( bert-\nuncased-large) as the language model, and Trans-\nformer NMT models (Vaswani et al., 2017) trained\nover WMT19 English/Germany corpus for back-\ntranslation.\n3We provide classiﬁcation results based on fastText trained\non the entire non-augmented training sets in the appendix.\n3.5 Human-in-the-loop Approach\nFor the purpose of the experiments, we randomly\nselected two samples from the original data, one\nconsisting of sentences (‘sentence sample’) and\nanother one consisting of passages (‘passages sam-\nple’). Each sample contained 20 instances per label\nor 100 instances in total. The ‘sentence sample’\nand the ‘passage sample’ were distributed among\ntwo experts. Participants were asked for each sen-\ntence/passage to choose whether it is a good or bad\nrepresentative of the class, or to indicate whether\nthey are unsure. We use only a sample of the origi-\nnal data and involve two experts in order to evalu-\nate whether expert-guided seed selection strategy\nwork in a real case scenario in which the selection\nprocess is time- and cost- consuming for larger\ndatasets. The experts followed standard procedures\nin thematic analysis for completing the task, sim-\nilar to those used for annotating the safeguarding\nreports (Robinson et al., 2019). Speciﬁcally, par-\nticipants arrived to the ﬁnal selection of the good\ntheme representative samples through discussion.\nThe participants are practitioners in the safeguard-\ning domain working for Welsh Government, per-\nforming qualitative analysis for safeguarding doc-\numents. The results from the experiments (see\nTable 2) show that experts selected more than 10\ninstances per theme for both samples as ‘good rep-\nresentatives’. To select 10 and 5 seeds from the\n‘good representatives’ we use random selection and\nmax-noun selection strategies. An example of the\nprocess is given in Figure 2.\nTheme passages sentences\n#good rep#bad rep#good rep#bad rep\nContact with Agencies12 8 13 7\nIndicative Behaviour12 8 15 5\nIndicative Circumstances11 9 13 7\nMental Health Issues11 9 14 6\nReﬂections 11 9 11 9\nTotal 57 43 66 34\nTable 2: Results from expert study where ‘#good rep’\nrefer to the number of good representative seeds that\nthe expert selected while ‘#bad rep’ refer to the number\nof samples that the expert deemed not good representa-\ntives of the themes\n4 Results and Analysis\nThe aims of our analysis is (1) to identify the most\nsuitable method for ﬁne-tuning GPT-2 model to\nensure generating higher quality training data (see\nSection 4.1), and (2) to understand whether and\nwhich seed selection strategies are beneﬁcial for\nFigure 2: Example of expert-guided seed selection\nimproving DA methods, especially for specialised\ndomains which require domain experts to perform\nmanual annotation (see Section 4.2). The results\nfor the three datasets are displayed in Table 3.\nFigure 3: Micro-F1 results with 5 and 10 ‘base’ in-\nstances per label for the Safeguarding reports dataset.\nFigure 4: Macro-F1 results with 5 and 10 ‘base’ in-\nstances per label for the Safeguarding reports dataset.\n4.1 Can GPT-based Data Augmentation Help\nFew-Shot Text Classiﬁcation?\nThe results in Table 3 indeed conﬁrm the bene-\nﬁts of GPT-based data augmentation. Comparing\ndifferent methods for ﬁne-tuning GPT-2 models\nfor DA, the classiﬁcation results show that GPT-2\nﬁne-tuned per label lead to better results, compared\nto the pre-trained model or GPT-2 ﬁne-tuned on\nthe entire dataset. These results also show that us-\ning a ﬁne-tuned GPT-2 model per label does help\nlabel-preservation for the generated instances. Sur-\nprisingly, the results for the safeguarding reports at\nDA type Tuning typeDA method\nMicro-F1 Macro-F1\n5base 10base 5base 10base\n+5add+10add+10add+20add+5add+10add+10add+20add\n20 Newsgroups\nNone - - .509 .578 .481 .567\nTG (GPT2)\ngen random .539 .536 .572 .555 .519 .519 .564 .548\ndom random .526 .502 .548 .539 .511 .485 .534 .526\nlabel\nrandom .609* .602* .627* .637* .591* .587* .615 .627\nnouns .569 .549 .599 .576 .552 .533 .583 .562\nsubclass .563 .585 .624 .632 .549 .571 .620* .628*\nWR\n- BERT .519 .516 .567 .571 .511 .505 .554 .556\n- embeddings.556 .540 .556 .552 .534 .516 .544 .539\n- synonyms .517 .508 .554 .549 .502 .493 .542 .537\nSR - translation .529 .525 .559 .563 .515 .509 .549 .552\nOriginal data (upperbound) .601 .641 .648 .654 .589 .624 .633 .639\nToxic comments\nNone - - .423 .442 .423 .442\nTG (GPT2)\ngen random .447 .424 .405 .423 .447 .424 .405 .423\ndom random .401 .417 .369 .343 .401 .417 .369 .343\nlabel\nrandom .453* .452* .453 .442 .453* .452* .453 .442\nnouns .417 .399 .502* .461* .417 .399 .502* .461*\nsubclass .427 .440 .419 .421 .427 .440 .419 .421\nWR\n- BERT .447 .443 .426 .422 .447 .443 .426 .422\n- embeddings.441 .441 .432 .432 .441 .441 .432 .432\n- synonyms .423 .411 .433 .429 .423 .411 .433 .429\nSR - translation .446 - .436 - .446 - .436 -\nOriginal data (upperbound) .442 .435 .448 .463 .442 .435 .448 .463\nSafeguard (pass)\nNone - - .326 .326 .299 .300\nTG (GPT2)\ngen random .298 .305 .382 .358 .254 .264 .335 .330\ndom random .333 .288 .323 .309 .276 .246 .287 .267\nlabel*\nrandom .316 .302 .347 .326 .278 .266 .309 .287\nnouns .375 .337 .375 .379 .329 .281 .338 .351\nsubclass .379 .330 .368 .368 .321 .286 .335 .345\nexpert-random.404* .386 .393 .407* .358* .349 .342 .352\nexpert-nouns.389 .435* .410* .407* .335 .382* .351* .366*\nWR\n- BERT .287 .294 .326 .336 .282 .278 .294 .297\n- embeddings.389 .382 .305 .319 .343 .341 .283 .287\n- synonyms .277 .267 .312 .315 .256 .245 .285 .292\nSR - translation .333 .336 .298 .312 .294 .301 .273 .286\nOriginal data (upperbound) .336 .337 .358 .368 .301 .304 .307 .320\nSafeguard (sent)\nNone - - .242 .316 .193 .282\nTG (GPT2)\ngen random .294 .326 .291 .298 .212 .235 .252 .251\ndom random .298 .326 .291 .302 .214 .236 .252 .250\nlabel\nrandom .295 .326 .291 .302 .213 .235 .251 .252\nnouns .358 .368 .361 .389* .285 .302 .327 .358\nsubclass .330 .351 .372 .329 .281 .301 .338 .290\nexpert-random.337* .375* .361* .414* .298* .336* .340* .379*\nexpert-nouns.291 .298 .354 .375 .274 .276 .332 .351\nWR\n- BERT .249 .284 .319 .315 .245 .274 .278 .274\n- embeddings.242 .280 .316 .319 .226 .259 .276 .283\n- synonyms .256 .266 .319 .326 .241 .256 .281 .288\nSR - translation .287 .294 .336 .329 .257 .263 .296 .291\nOriginal data (upperbound) .368 .452 .432 .453 .332 .386 .386 .389\nTable 3: FasText classiﬁcation results based on Micro-F1 and Macro-F1. Text generation is based on GPT-2,\nwhere ‘gen’ refers to the pre-trained general-domain model, ‘dom’ refers to the same model ﬁne-tuned on domain\ndata, and ‘label’, ﬁne-tuned per label. Data is split using 5 or 10 ‘base’ instances per label plus additional 5,\n10, or 20 ‘add’ instances, ‘sent’ refers to sentences. The baselines we compare our approaches to are: the word-\nbased replacement (WR) and sentence-based replacement (SR) strategies, ‘Original data (upperbound)’ refers the\ntraining data extracted from the original dataset using the same amount of ‘base’ and ‘additional’ instances as for\nthe generative models\n.* – Best performing DA methods based on GPT-2 ﬁne-tuned per label lead to statistically signiﬁcant\ndifferences over non-augmented classiﬁcation (‘None’) based on t-test results where pvalue < 0.05.\nthe passage level (see Table 3) show that the pre-\ntrained model outperforms the model ﬁne-tuned on\nthe entire dataset for all settings except for ‘5+5’.\nThis is not the case, however, at the sentence-level\nwhere the model ﬁne-tuned on the entire dataset\nperforms very similarly to the model ﬁne-tuned\nper label. In general, the results clearly suggest\nthat ﬁne-tuning the GPT-2 model on smaller but la-\nbelled data works better for classiﬁcation than ﬁne-\ntuning it on a larger unlabelled corpus, especially\nin settings with longer input sequences. These ﬁnd-\nings are also supported by the results for the other\ntwo datasets,20 Newsgroups and Toxic comments.\nThe main reason for this behaviour can be found\nin that the ﬁne-tuned model without using label-\npreservation techniques leads to label-distortions\nwhich add noise in the generated dataset. We have\ngiven examples of generated instances in the Ap-\npendix.\nStatistical signiﬁcance tests. We used t-\ntest (Student, 1908) to measure whether TG-based\nDA give a signiﬁcant improvement over the\nnon-augmented classiﬁers. In particular, we\ncompared the best performing techniques, which\nare all based on GPT-2 models ﬁne-tuned per label,\nand the base classiﬁer (‘None’ in Table 3). We\nuse as a threshold α= 0.05. Results showed that\npvalue < αfor every setting. This conﬁrms that\nﬁne-tuning GPT-2 model with a small number\nof labelled instances leads to consistent (and\nstatistically signiﬁcant) improvements for the\nsafeguarding reports 45\n4.2 Seed Selection Strategies Comparison\nResults on comparing seed selection strategies for\nthe specialised domain (i.e., safeguarding reports)\n(see Figures 3 and 4) showed that both seed selec-\ntion strategies (noun-guided and subclass-guided\nselection) lead to larger improvements over ran-\ndom selection even for a small number of seed\nsamples. In contrast, experiments on the toxic com-\nments dataset and the 20 newsgroups (see Table 3)\nshowed that random selection is sufﬁcient for im-\nproving classiﬁcation performance over baselines,\nespecially for smaller amount of seeds. This shows\nthat for domains that are similar to the datasets\nused to train GPT-2 (Newsgroups and Wikipedia)\nrandom selection especially for a smaller amount\nof seeds is sufﬁcient for improving classiﬁcation\nperformance over baselines. In contrast, apply-\ning seed selection techniques to a more specialised\ndomain, such as the safeguarding reports, can be\nhighly beneﬁcial for improving classiﬁcation.\nFinally, the human-in-the-loop approach (see\nSection 3.5) revealed that seed selection strategy\nguided by experts outperform all other seed strate-\n4These results are also supported by the results for the\nother two datasets presented in the Appendix\n5We include full results and t-test details in the Appendix.\ngies and baselines for both sentences and passages\n(see Table 3, Figures 3 and 4). This highlights the\npotential beneﬁts for incorporating expert knowl-\nedge into guiding large pre-trained language mod-\nels in highly specialised domains. This study shows\nthat using active learning techniques in combina-\ntion with generative models can help increase the\nefﬁciency of data augmentation methods and thus\nbe beneﬁcial for few-shot learning.\n5 Conclusion\nIn this paper, we presented and evaluated data\naugmentation methods using text generation tech-\nniques and seed selection strategies for improving\nthe quality of generated artiﬁcial sequences and\nsubsequently classiﬁer’s performance in few-shot\nsettings. Our results showed that GPT-2 ﬁne-tuned\nper label, even using only handful of instances,\nleads to consistent classiﬁcation improvements,\nand is shown to outperform competitive baselines\nand the same GPT-2 model ﬁne-tuned on the en-\ntire dataset. This highlights the importance of la-\nbel preservation techniques in the performance of\nTG-based DA methods, especially for generating\nlonger sequences (such as passages or full doc-\numents). Seed selection strategies proved to be\nhighly beneﬁcial for the specialised domain anal-\nysed in this paper, especially when experts are in-\nvolved in the selection of class-indicative instances.\nThis shows that combining generative models and\nactive learning techniques, i.e., injecting experts\nknowledge, can lead to signiﬁcant improvements\nin data augmentation methods especially for more\nspecialised domains which require domain experts\nfor the annotation of documents. In future, we plan\non expanding the experiments for wider range of\nspecialised domains and compare the performance\nof bigger generative models such as GPT-3 (Brown\net al., 2020), Transformer-XL (Dai et al., 2019)\nand CTRL (Clive et al., 2021). Further, we want to\ninvestigate what is the optimum amount of artiﬁcial\ntraining data which can be generated with the de-\nscribed techniques before effecting the classiﬁer’s\nperformance negatively.\nLimitations\nThe main limitation of this research is the lack of\nfurther analysis into the performance of text gen-\neration models and seed selection strategies when\ngenerating higher number of additional training\nsamples. As future work, we plan to investigate the\noptimal number of generated instances using GPT-\nbased generation as well as experiment with other\ngenerative models. Another limitation of the work\nis that generating artiﬁcial training data using GPT-\n2 requires access to large GPU resources which\nlimits the usability of the approach in real-world\nscenarios where such resources are unavailable or\nresponses have to be generated in real-time manner.\nMoreover, the paper presents human-in-the-loop\nanalysis for a single specialised domain (i.e., safe-\nguarding). Safeguarding is a multi-disciplinary\ndomain involving terminology and issues from var-\nious other domains such as criminology, medical\ndomain, and legal domain. While the results pre-\nsented in the paper show clear advantage of leverag-\ning expert knowledge into guiding text generation\nmodels, we believe that extending the analysis for\na wider range of datasets (such as those datasets\nwhere we present extended results in the Appendix)\ncan be beneﬁcial. Additionally, the human-in-the-\nloop seed selection has been carried by two experts\nwhich may cause biases in the process of select-\ning seeds. However, the participants are practi-\ntioners from the safeguarding domain who used\nstandard methodology in thematic analysis for se-\nlecting the seeds. These methods do not require\ninter-annotators agreement, instead experts achieve\nagreement through discussion. Further, analysis\nhave been performed on sentence- and passage-\nlevel where both experiments showed clear advan-\ntage of the human-in-the-loop approach. Finally,\nthe paper presents results for a single high-resource\nlanguage (English). Experiments for other lan-\nguages (especially low-resource) could show a dif-\nferent tendency in which the expert involved may\nbe even more necessary.\nReferences\nAmanuel Alambo, Cori Lohstroh, Erik Madaus, Swati\nPadhee, Brandy Foster, Tanvi Banerjee, Krish-\nnaprasad Thirunarayan, and Michael Raymer. 2020.\nTopic-centric unsupervised multi-document summa-\nrization of scientiﬁc and news articles. arXiv\npreprint arXiv:2011.08072.\nZuhair Ali. 2019. Text classiﬁcation based on fuzzy\nradial basis function. Iraqi Journal for Computers\nand Informatics, 45(1):11–14.\nAli Amin-Nejad, Julia Ive, and Sumithra Velupillai.\n2020. Exploring transformer text generation for\nmedical dataset augmentation. In Proceedings of\nThe 12th Language Resources and Evaluation Con-\nference, pages 4699–4708.\nAteret Anaby-Tavor, Boaz Carmeli, Esther Goldbraich,\nAmir Kantor, George Kour, Segev Shlomov, Naama\nTepper, and Naama Zwerdling. 2020. Do not have\nenough data? Deep learning to the rescue! In Pro-\nceedings of AAAI, pages 7383–7390.\nAshutosh Baheti, Alan Ritter, and Kevin Small. 2020.\nFluent response generation for conversational ques-\ntion answering. arXiv preprint arXiv:2005.10464.\nSteven Bird and Edward Loper. 2004. NLTK: The nat-\nural language toolkit. In Proceedings of the ACL In-\nteractive Poster and Demonstration Sessions, pages\n214–217, Barcelona, Spain. Association for Compu-\ntational Linguistics.\nPiotr Bojanowski, Edouard Grave, Armand Joulin, and\nTomas Mikolov. 2017. Enriching word vectors with\nsubword information. Transactions of the Associa-\ntion for Computational Linguistics, 5:135–146.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nJordan Clive, Kris Cao, and Marek Rei. 2021. Con-\ntrol preﬁxes for text generation. arXiv preprint\narXiv:2110.08329.\nXiaodong Cui, Vaibhava Goel, and Brian Kingsbury.\n2015. Data augmentation for deep neural network\nacoustic modeling. IEEE/ACM Transactions on Au-\ndio, Speech, and Language Processing, 23(9):1469–\n1477.\nZihang Dai, Zhilin Yang, Yiming Yang, Jaime G Car-\nbonell, Quoc Le, and Ruslan Salakhutdinov. 2019.\nTransformer-xl: Attentive language models beyond\na ﬁxed-length context. In Proceedings of the 57th\nAnnual Meeting of the Association for Computa-\ntional Linguistics, pages 2978–2988.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186.\nAleksandra Edwards, Jose Camacho-Collados, Hélène\nde Ribaupierre, and Alun Preece. 2020. Go simple\nand pre-train on domain-speciﬁc corpora: On the\nrole of training data for text classiﬁcation. In Pro-\nceedings of COLING.\nAleksandra Edwards, Alun Preece, and Helene De Rib-\naupierre. 2019. Knowledge extraction from a small\ncorpus of unstructured safeguarding reports. In Eu-\nropean Semantic Web Conference, pages 38–42, Por-\ntoro´ z, Slovenia. Springer.\nAleksandra Edwards, David Rogers, Jose Camacho-\nCollados, Hélène de Ribaupierre, and Alun Preece.\n2021. Predicting themes within complex unstruc-\ntured texts: A case study on safeguarding reports.\nIn Proceedings of the ESWC Workshop Deep Learn-\ning meets Ontologies and Natural Language Pro-\ncessing.\nMarzieh Fadaee, Arianna Bisazza, and Christof Monz.\n2017. Data augmentation for low-resource neural\nmachine translation. In Proceedings of the 55th An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers) , pages 567–\n573, Vancouver, Canada. Association for Computa-\ntional Linguistics.\nPraveen Kumar Badimala Giridhara, Chinmaya Mishra,\nReddy Kumar Modam Venkataramana, Syed Saqib\nBukhari, and Andreas Dengel. 2019. A study of var-\nious text augmentation techniques for relation classi-\nﬁcation in free text. ICPRAM, 3:5.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\nYejin Choi. 2019. The curious case of neural text\ndegeneration. In Proceedings of the International\nConference on Learning Representations (ICLR).\nHossein Hosseini, Sreeram Kannan, Baosen Zhang,\nand Radha Poovendran. 2017. Deceiving google’s\nperspective api built for detecting toxic comments.\narXiv preprint arXiv:1702.08138.\nBrihi Joshi, Neil Shah, Francesco Barbieri, and\nLeonardo Neves. 2020. The devil is in the details:\nEvaluating limitations of transformer-based meth-\nods for granular tasks. In Proceedings of COLING.\nArmand Joulin, Edouard Grave, Piotr Bojanowski, and\nTomas Mikolov. 2017. Bag of tricks for efﬁcient\ntext classiﬁcation. In Proceedings of the 15th Con-\nference of the European Chapter of the Association\nfor Computational Linguistics: Volume 2, Short Pa-\npers, pages 427–431. Association for Computational\nLinguistics.\nVirapat Kieuvongngam, Bowen Tan, and Yiming Niu.\n2020. Automatic text summarization of covid-19\nmedical research articles using bert and gpt-2. arXiv\npreprint arXiv:2006.01997.\nTassilo Klein and Moin Nabi. 2019. Learning to an-\nswer by learning to ask: Getting the best of gpt-2\nand bert worlds. arXiv preprint arXiv:1911.02365.\nTom Ko, Vijayaditya Peddinti, Daniel Povey, and San-\njeev Khudanpur. 2015. Audio augmentation for\nspeech recognition. In Sixteenth Annual Conference\nof the International Speech Communication Associ-\nation.\nAlex Krizhevsky, Ilya Sutskever, and Geoffrey E.\nHinton. 2017. Imagenet classiﬁcation with deep\nconvolutional neural networks. Commun. ACM ,\n60(6):84–90.\nVarun Kumar, Ashutosh Choudhary, and Eunah Cho.\n2020. Data augmentation using pre-trained trans-\nformer models. arXiv preprint arXiv:2003.02245.\nKen Lang. 1995. Newsweeder: Learning to ﬁlter net-\nnews. In Proceedings of the 12th International\nConference on Machine Learning , pages 331–339,\nTahoe City, California.\nMike Lewis, Yinhan Liu, Naman Goyal, Mar-\njan Ghazvininejad, Abdelrahman Mohamed, Omer\nLevy, Ves Stoyanov, and Luke Zettlemoyer. 2019.\nBart: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and\ncomprehension. arXiv preprint arXiv:1910.13461.\nShuai Liu and Xiaojun Huang. 2019. A chinese ques-\ntion answering system based on gpt. In 2019 IEEE\n10th International Conference on Software Engi-\nneering and Service Science (ICSESS) , pages 533–\n537. IEEE.\nJinghui Lu, Maeve Henchion, Ivan Bacher, and\nBrian Mac Namee. 2021. A sentence-level hierar-\nchical bert model for document classiﬁcation with\nlimited labelled data. In International Conference\non Discovery Science, pages 231–241. Springer.\nEdward Ma. 2019. Nlp augmentation.\nhttps://github.com/makcedward/nlpaug.\nGeorge A Miller. 1998. WordNet: An electronic lexical\ndatabase. MIT press.\nJohn X. Morris, Eli Liﬂand, Jin Yong Yoo, Jake\nGrigsby, Di Jin, and Yanjun Qi. 2020. Textattack:\nA framework for adversarial attacks, data augmenta-\ntion, and adversarial training in nlp.\nYannis Papanikolaou and Andrea Pierleoni. 2019. Data\naugmented relation extraction (dare) with gpt-2.\nNeuropharmacology.\nAlec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nAmanda Lea Robinson, Alyson Rees, and Roxanna\nDehaghani. 2019. Making connections: A multi-\ndisciplinary analysis of domestic homicide, mental\nhealth homicide and adult practice reviews. The\nJournal of Adult Protection, 21(1):16–26.\nRoy Schwartz, Jesse Dodge, Noah A Smith, and\nOren Etzioni. 2019. Green ai. arXiv preprint\narXiv:1907.10597.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Improving neural machine translation mod-\nels with monolingual data. In Proceedings of the\n54th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n86–96, Berlin, Germany. Association for Computa-\ntional Linguistics.\nRushdi Shams. 2014. Semi-supervised classiﬁcation\nfor natural language processing. arXiv preprint\narXiv:1409.7612.\nEmma Strubell, Ananya Ganesh, and Andrew McCal-\nlum. 2019. Energy and policy considerations for\ndeep learning in NLP. In Proceedings of the 57th\nAnnual Meeting of the Association for Computa-\ntional Linguistics, pages 3645–3650, Florence, Italy.\nAssociation for Computational Linguistics.\nStudent. 1908. The probable error of a mean.\nBiometrika, pages 1–25.\nChristian Szegedy, Wei Liu, Yangqing Jia, Pierre Ser-\nmanet, Scott Reed, Dragomir Anguelov, Dumitru Er-\nhan, Vincent Vanhoucke, and Andrew Rabinovich.\n2015. Going deeper with convolutions. In Proceed-\nings of the IEEE conference on computer vision and\npattern recognition, pages 1–9.\nRima Türker, Lei Zhang, Maria Koutraki, and Harald\nSack. 2019. Knowledge-based short text categoriza-\ntion using entity and category embedding. In Eu-\nropean Semantic Web Conference , pages 346–362.\nSpringer.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in neural information pro-\ncessing systems, pages 5998–6008.\nCongcong Wang and David Lillis. 2019. Classiﬁca-\ntion for crisis-related tweets leveraging word embed-\ndings and data augmentation. In TREC.\nJason Wei and Kai Zou. 2019. Eda: Easy data augmen-\ntation techniques for boosting performance on text\nclassiﬁcation tasks. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP), pages 6383–6389.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R’emi Louf, Morgan Funtow-\nicz, and Jamie Brew. 2019. Huggingface’s trans-\nformers: State-of-the-art natural language process-\ning. ArXiv, abs/1910.03771.\nXing Wu, Shangwen Lv, Liangjun Zang, Jizhong Han,\nand Songlin Hu. 2019. Conditional bert contextual\naugmentation. In International Conference on Com-\nputational Science, pages 84–95. Springer.\nLiqiang Xiao, Lu Wang, Hao He, and Yaohui Jin.\n2020. Modeling content importance for summariza-\ntion with pre-trained language models. In Proceed-\nings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP) , pages\n3606–3611.\nYiben Yang, Chaitanya Malaviya, Jared Fernandez,\nSwabha Swayamdipta, Ronan Le Bras, Ji-Ping\nWang, Chandra Bhagavatula, Yejin Choi, and Doug\nDowney. 2020. G-daug: Generative data augmenta-\ntion for commonsense reasoning. In Proceedings of\nthe 2020 Conference on Empirical Methods in Nat-\nural Language Processing: Findings , pages 1008–\n1025.\nYiming Yang. 1999. An evaluation of statistical ap-\nproaches to text categorization. Information re-\ntrieval, 1(1-2):69–90.\nDanqing Zhang, Tao Li, Haiyang Zhang, and Bing Yin.\n2020. On data augmentation for extreme multi-label\nclassiﬁcation. arXiv preprint arXiv:2009.10778.\nXinwei Zhang and Bin Wu. 2015. Short text classiﬁ-\ncation based on feature extension using the n-gram\nmodel. In 2015 12th International Conference on\nFuzzy Systems and Knowledge Discovery (FSKD) ,\npages 710–716. IEEE.\nAppendix\nIn Section A we present related research on data\naugmentation strategies. In Section B we describe\nthe classiﬁcation framework for all three datasets.\nWe also present the statistics for the entire datasets\nand the classiﬁcation results using the entire train-\ning data per dataset, with no augmentation. In Sec-\ntion C, we present examples of generated samples\nbetween the GPT models we used in our analysis.\nA Data Augmentation: Related Work\nThe task of data augmentation consists of gener-\nating synthetic additional training samples from\nexisting labelled data (Anaby-Tavor et al., 2020).\nIn the following, we describe standard text augmen-\ntation methods which we use as baselines. We also\nexplain recent DA methods based on text genera-\ntion models.\nWord replacement-based (WR). Simple but\ncommonly used DA techniques are based on word-\nreplacement strategies using knowledge bases (Wei\nand Zou, 2019) such as WordNet (Miller, 1998).\nSuch methods often struggle to preserve the class\nlabel and lead to grammatical distortions of the\ndata (Kumar et al., 2020; Giridhara et al., 2019;\nAnaby-Tavor et al., 2020). Recent DA approaches\naddress the above issues by using language mod-\nels to provide more contextual knowledge such as\nCBERT (Wu et al., 2019) in the word replacement\nprocess. However, methods that make only local\nchanges to given instances produce sentences with\na structure similar to the original ones and thus lead\nto low variability of training instances in the corpus\n(Anaby-Tavor et al., 2020).\nSentence replacement-based (SR). Common\nsentence replacement-based methods are based on\nback-translation strategies where a given sentence\nis translated to a language and then back to the\noriginal language in order to change the syntax but\nnot the meaning of the sentence (Sennrich et al.,\n2016; Fadaee et al., 2017).\nText Generation (TG). Recent language mod-\nels such as GPT-2 (Radford et al., 2019) can ad-\ndress the issues associated with the previous strate-\ngies by generating completely new instances from\ngiven seed samples. GPT-2 was trained with a\ncausal language modeling (CLM) objective which\nmakes it suitable for predicting the next token in\na sequence. This model has been used success-\nfully in text generation tasks such as summaris-\ning (Xiao et al., 2020; Kieuvongngam et al., 2020;\nAlambo et al., 2020) and question answering (Liu\nand Huang, 2019; Baheti et al., 2020; Klein and\nNabi, 2019). Previous research on using text gen-\neration techniques for DA for text classiﬁcation\nfocused on the creation of label-preservation tech-\nniques for the generated synthetic data samples and\ncomparing different TG techniques (Anaby-Tavor\net al., 2020; Wang and Lillis, 2019; Zhang et al.,\n2020; Kumar et al., 2020). However, these works\nare limited in scale and solutions for improving\nquality of generated data.Further, There are two\nmain methods used for label preservation of gener-\nated samples. The ﬁrst approach, using a classiﬁer\nto re-label artiﬁcial sequences, requires either a\nlarge training corpus to ensure high performance of\nthe classiﬁer in ﬁrst place or the generation of large\nvolume of artiﬁcial data to ensure that a substantial\namount of these will not be ﬁltered because of a low\nthreshold (Anaby-Tavor et al., 2020). The other,\nmore widely accepted approach, is prepending the\nclass labels to text sequences during ﬁne-tuning\nof the Transformer-based model (Wang and Lil-\nlis, 2019; Zhang et al., 2020; Kumar et al., 2020).\nSuch an approach cannot ensure label-preservation\nfor all generated sequences. However, our prior-\nity is to allow a fair comparison for seed selection\napproaches without introducing additional noise.\nTherefore, we consider a simple technique based\non ﬁne-tuning a model per label more suitable for\nperforming our analysis.\nB Datasets description\nThe 20 Newsgroups collection is a popular data set\nfor experiments in machine learning. The data is\norganized into 20 different newsgroups, each corre-\nsponding to a different news topic such as computer\nsystems, religion, politics (Lang, 1995). The col-\nlection of the Toxic comments dataset is obtained\nfrom Wikipedia and it is the result from the collab-\noration between Google and Jigsaw for creating a\nmachine learning-based system for automatically\ndetecting online insults, harassment, and abusive\nspeech (Hosseini et al., 2017). Table 4 shows that\nfor the 20 Newsgroups dataset there are 20 sub-\nclasses split between 6 overall classes. The Toxic\ncomments consists of two overall classes - ‘toxic’\nand ‘non-toxic’ where the ‘toxic’ class is overarch-\ning 6 subclasses. The Safeguarding reports consists\nof 5 overall classes and 34 subclasses.\nThe full description of the original datasets is\ngiven in Table 6. Results from performing classi-\nﬁcation using unmodiﬁed datasets (using the full\ntraining data) are given in Table 5.\nB.1 Statistical signiﬁcance test\nTo further evaluate the effect the additional data\ngenerated with GPT-2 have over the classiﬁer’s\nperformance, we performed a statistical test, t-\ntest (Student, 1908), used to compare the means\nof two groups. It is used to determine if there is\na signiﬁcant difference between the means of two\ngroups, which may be related in certain features.\nIt is often used to determine whether a process or\ntreatment actually has an effect on the population of\ninterest, or whether two groups are different from\none another.\nWe use t-test to measure whether the addition of\nGPT-2 generated training data does actually lead\nto improvements compared to non-augmented clas-\nsiﬁer. We speciﬁcally perform t-test between best\nperforming seed selection strategy, highlighted in\nbold and ‘None’ row in Tables 3 and 4). Our H0\nis: Generated data does not lead to overall im-\nDataset Label Sub-labels\nToxic comments non-toxic non-toxic\ntoxic mild toxic, severe toxic, ob-\nscene,threat, insult,identity\nhate\nNewsgroups\ncomputers comp.graphics,\ncomp.os.ms-windows.misc,\ncomp.sys.ibm.pc.hardware,\ncomp.sys.mac.hardware,\ncomp.windows.x\nrecreational\nactivities\nrec.autos, rec.motorcycles,\nrec.sport.baseball,\nrec.sport.hockey\nscience sci.crypt, sci.electronics,\nsci.med, sci.space\nforsale misc.forsale\npolitics talk.politics.misc,\ntalk.politics.guns,\ntalk.politics.mideast\nreligion talk.religion.misc,\nalt.atheism,\nsoc.religion.christian\nSafeguarding Reports\nContact with\nAgencies\nHealth Practitioners, Contact\nwith Third sector orgs, Edu-\ncational Institutions, Contact\nwith Social Care, Police Con-\ntact, Contact with councils or\nLAs\nIndicative\nBehaviour\nLying, Offending, Serious\nThreats to Life, Weapons,\nEmotional Abuse, Domestic\nViolence, Substance Misuse,\nAlcohol Misuse, Harassment,\nSelf Inﬂicted Harm, Stalking,\nControlling Behaviour, Ag-\ngression\nIndicative\nCircum-\nstances\nBereavement,NFA, Home-\nlessness or Constantly\nchanging Address, Family\nStructure, Child Safe-\nguarding, Relationship\nBreakdown, Debt or Finan-\ncial Exploitation, Sex Work,\nRelationship with Children,\nQuality of Relationship\nMental\nHealth\nIssues\nChildren, Victim, Perpetrator,\nSuicidal Ideation\nReﬂectionsReports Assessments and\nConferences, Failures or\nMissed Opportunities\nTable 4: Subclasses for the three datasets\nDataset Micro-F1Macro-F1\n20 Newsgroups 0.768 0.759\nToxic comments 0.908 0.908\nSafeguarding Reports (passages)0.463 0.404\nSafeguarding Reports (sentences)0.505 0.477\nTable 5: FastText classiﬁcation results for the entire\ndatasets with no augmentation.\nprovements in classiﬁer performance and Ha: Gen-\nerated data does lead to overall improvements in\nclassiﬁer performance. We use as a threshold α=\n0.05. Results in Table 7 showed that pvalue < α\nDataset Avg tokens# Train# Test\nSafeguarding Reports (passages)45 1,261 284\nSafeguarding Reports (sentences)18 3,591 284\n20 Newsgroups 285 11,231 6,728\nToxic comments 46 159,57163,978\nTable 6: Description of unmodiﬁed datasets\nfor every dataset. This conﬁrms that augmenting\napproaches using seed selection strategies do lead\nto improvements in classiﬁer’s performance versus\nnon-augmented classiﬁers.\nDataset pmicro pmacro α\n20 Newsgroups 0.01 0.02 0.05\nToxic comments 0.03 0.03 0.05\nSafeguarding Reports (passages)0.00010.00010.05\nSafeguarding Reports (sentences)0.006 0.016 0.05\nTable 7: T-test results - compare classiﬁcation perfor-\nmance with no additional data and results with addi-\ntional data where performance is the highest\nC Analysis GPT-2 models: Comparison\nbetween generated samples\nIn Table 8 we provide examples of generated in-\nstances per GPT model. Results showed that the\nﬁne-tuned model leads to miss-classiﬁcations for\nthe 20 Newsgroup dataset and the Toxic comments\ndataset.\nDataset Label Original Text GPT(gen) generationGPT(dom) genera-\ntion\nGPT(label) genera-\ntion\n20 NewsgroupsComputers There are 3 al-\nternatives: You\ncan try to write a\nsmall C program\nsomething like: int\nmy_int_var;my_int_var\n= system(command);\n4. It’s a bit confusing\nand requires very little\nprogramming knowl-\nedge.5. It uses only\nyour current CPU and\nsome extra memory.\nI am now posting the\nfollowing FAQs to a\ngroup of individuals\nwhose answers are\nfrom people who are\nnow either atheists,\nagnostics, etc.\nIt appears that I am hav-\ning a problem in trying\nto use XRemoteAddIn-\nput(xmodmap) in win-\ndows.\nToxic Com-\nments\nnon-toxic I think the recent edit-\ning by all has been bril-\nliant. If I see any-\nthing that could be im-\nproved I’ll speak up\nhere. I would like to\nsee a Christian Theoso-\nphy section also.\nThank you for your\nhelp, H, for your work\non my blog.You are\nwelcome to submit\ncomments in this\nsection, but please\nnote I am not allowed\nto comment on other\nforums because they\nmay interfere with my\nwork.\nNo need to be an ency-\nclopedic asshole. You\ndon’t see me delet-\ning things because of\nsomething that was on\nmy watchlist. I just\nwanted you to know\nthat my name is now on\nmy watchlist, and I will\ntry to improve it.\nI hope to see the article\nﬁnished as soon as pos-\nsible. But I would like\nto thank you for your\ncontributions.\nSafeguarding re-\nports\nIndicative\nCircumstances\nMedical records show\nthat she struggled for\nmany years with de-\npression, for which she\nwas treated with anti-\ndepressants, also re-\nceiving referrals for\ncounselling. She also\nhad issues with her\nphysical health.\nHer lawyer, Richard\nGage, has asked the\ncourt to intervene if Mr.\nMcDevitt was not crim-\ninally liable in his deci-\nsion.\nShe attended at her GP\nwith a range of de-\npressive symptoms and\nher medication was im-\nproved. It is not known\nhow she gained her\nweight but it is said that\nher mental health de-\nclined and she started\nfollowing a diet with\nvitamin C, which was\nassociated with being\nbetter at controlling her\nmood.\nIn the early 1970s she\nmoved from Los An-\ngeles to New York.\nDuring this time she\nsuffered from depres-\nsion and other prob-\nlems, but there was\nlittle support in New\nYork.She moved into\na small apartment and\nwas living with friends,\nbut had to move into a\nhouse next to her apart-\nment to support her\nmental health.\nTable 8: Examples of generated samples using GPT-2 models, where Safeguarding Reports examples are non-\nverbatim due to data sensitivity.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7784132957458496
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.7746987342834473
    },
    {
      "name": "Machine learning",
      "score": 0.7098777890205383
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6766446828842163
    },
    {
      "name": "Classifier (UML)",
      "score": 0.6630905270576477
    },
    {
      "name": "Exploit",
      "score": 0.658976674079895
    },
    {
      "name": "Generative grammar",
      "score": 0.6553823351860046
    },
    {
      "name": "Selection (genetic algorithm)",
      "score": 0.5669518113136292
    },
    {
      "name": "Generative model",
      "score": 0.4720609784126282
    },
    {
      "name": "Model selection",
      "score": 0.4240250885486603
    },
    {
      "name": "Process (computing)",
      "score": 0.41947656869888306
    },
    {
      "name": "Language model",
      "score": 0.41819101572036743
    },
    {
      "name": "Training set",
      "score": 0.41811490058898926
    },
    {
      "name": "Class (philosophy)",
      "score": 0.410670667886734
    },
    {
      "name": "Computer security",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ]
}