{
    "title": "Synthesize high-dimensional longitudinal electronic health records via hierarchical autoregressive language model",
    "url": "https://openalex.org/W4386324432",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A4323860991",
            "name": "Brandon Theodorou",
            "affiliations": [
                "University of Illinois Urbana-Champaign"
            ]
        },
        {
            "id": "https://openalex.org/A2232363908",
            "name": "Cao Xiao",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2110385854",
            "name": "Jimeng Sun",
            "affiliations": [
                "University of Illinois Urbana-Champaign"
            ]
        },
        {
            "id": "https://openalex.org/A4323860991",
            "name": "Brandon Theodorou",
            "affiliations": [
                "University of Illinois Urbana-Champaign",
                "University of Nevada, Las Vegas"
            ]
        },
        {
            "id": "https://openalex.org/A2232363908",
            "name": "Cao Xiao",
            "affiliations": [
                "University of Nevada, Las Vegas"
            ]
        },
        {
            "id": "https://openalex.org/A2110385854",
            "name": "Jimeng Sun",
            "affiliations": [
                "University of Nevada, Las Vegas",
                "University of Illinois Urbana-Champaign"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2557074642",
        "https://openalex.org/W2517259736",
        "https://openalex.org/W4235292672",
        "https://openalex.org/W3003866816",
        "https://openalex.org/W2965828587",
        "https://openalex.org/W4293262146",
        "https://openalex.org/W2772027160",
        "https://openalex.org/W2964068143",
        "https://openalex.org/W2963561234",
        "https://openalex.org/W2965570621",
        "https://openalex.org/W1966582924",
        "https://openalex.org/W2314398369",
        "https://openalex.org/W2132808850",
        "https://openalex.org/W2146875405",
        "https://openalex.org/W2083384763",
        "https://openalex.org/W3110404953",
        "https://openalex.org/W3115159903",
        "https://openalex.org/W2997064490",
        "https://openalex.org/W2604918751",
        "https://openalex.org/W2904931021",
        "https://openalex.org/W4378576258",
        "https://openalex.org/W2980100290",
        "https://openalex.org/W3088465102",
        "https://openalex.org/W2396881363",
        "https://openalex.org/W2597505554",
        "https://openalex.org/W2970971581",
        "https://openalex.org/W2805183640",
        "https://openalex.org/W2186655027",
        "https://openalex.org/W4310917402",
        "https://openalex.org/W3015471667",
        "https://openalex.org/W2751687090",
        "https://openalex.org/W3103102495",
        "https://openalex.org/W2975565705",
        "https://openalex.org/W3201600616",
        "https://openalex.org/W4210897482",
        "https://openalex.org/W4205760215",
        "https://openalex.org/W3013181797",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W2057058417",
        "https://openalex.org/W6969352923",
        "https://openalex.org/W4385567484",
        "https://openalex.org/W1995228216",
        "https://openalex.org/W3101973032",
        "https://openalex.org/W3158386016",
        "https://openalex.org/W3098576902",
        "https://openalex.org/W3102123817",
        "https://openalex.org/W2066203299"
    ],
    "abstract": "Abstract Synthetic electronic health records (EHRs) that are both realistic and privacy-preserving offer alternatives to real EHRs for machine learning (ML) and statistical analysis. However, generating high-fidelity EHR data in its original, high-dimensional form poses challenges for existing methods. We propose Hierarchical Autoregressive Language mOdel () for generating longitudinal, high-dimensional EHR, which preserve the statistical properties of real EHRs and can train accurate ML models without privacy concerns. generates a probability density function over medical codes, clinical visits, and patient records, allowing for generating realistic EHR data without requiring variable selection or aggregation. Extensive experiments demonstrated that can generate high-fidelity data with high-dimensional disease code probabilities closely mirroring (above 0.9 R 2 correlation) real EHR data. also enhances the accuracy of predictive modeling and enables downstream ML models to attain similar accuracy as models trained on genuine data.",
    "full_text": "Article https://doi.org/10.1038/s41467-023-41093-0\nSynthesize high-dimensional longitudinal\nelectronic health records via hierarchical\nautoregressive language model\nBrandon Theodorou1,2, Cao Xiao2 &J i m e n gS u n1,2\nSynthetic electronic health records (EHRs) that are both realistic and privacy-\npreserving offer alternatives to real EHRs for machine learning (ML) and sta-\ntistical analysis. However, generating high-ﬁdelity EHR data in its original, high-\ndimensional form poses challenges for existing methods. We propose Hier-\narchical Autoregressive Language mOdel (HALO) for generating longitudinal,\nhigh-dimensional EHR, which preserve the statistical properties of real EHRs\nand can train accurate ML modelswithout privacy concerns.HALO generates a\nprobability density function over medical codes, clinical visits, and patient\nrecords, allowing for generating realistic EHR data without requiring variable\nselection or aggregation. Extensive experiments demonstrated thatHALO can\ngenerate high-ﬁdelity data with high-dimensional disease code probabilities\nclosely mirroring (above 0.9R\n2 correlation) real EHR data.HALO also enhances\nthe accuracy of predictive modeling and enables downstream ML models to\nattain similar accuracy as models trained on genuine data.\nThe widespread adoption of electronic health record (EHR) systems\nhas established the foundation for machine learning (ML) and artiﬁcial\nintelligence (AI) applications in healthcare. The EHR data is highly\ncomplex, comprising over 10,000 unique medical codes for diag-\nnoses, procedures, and medications, as well as thousands of lab mea-\nsurements. Each patient record can include multiple visits with\ncombinations of diagnoses, procedures, medications, and labs.\nThese combinations create intricate relationships and complex\npatterns across tens of thousands of medical codes. AI and ML tech-\nniques are used to learn and model complex patterns in EHR\ndata, enabling applications such as clinical predictive modeling\n1,2,\nhealth monitoring 3,4, computational phenotyping 5,6, treatment\nrecommendations7– 9, and more. However, the progress of AI and ML in\nhealthcare is often impeded by the difﬁculty of accessing and sharing\nlarge real EHR datasets. Sharing EHR data is challenging due to privacy,\nsecurity, and legal constraints. While patient de-identiﬁcation can\nalleviate some of these concerns by removing obvious patient identi-\nﬁers such as name, address, and birth date\n10,11, studies have shown\nthat the risk of re-identiﬁcation remains high even after thorough\nde-identiﬁcation12– 14.\nUsing synthetic patient data can offer a safer alternative to sharing\nreal EHR data. Generative models can produce synthetic datasets as\nsubstitutes for real patient data\n15– 21. Various methods have been pro-\nposed in the literature, including structured patient record\ngeneration\n19,20,22– 24 and longitudinal record generation15,16,21.\nTo date, existing methods cannot generate realistic EHR data in its\noriginal, high-dimensional form. The high dimensionality of EHR data,\nalong with rare and sparse variables and complex relationships among\nvariables, makes the generation task a difﬁcult one. Consequently,\nexisting approaches all concede to creating lower-dimensional data by\neither aggregating variables or using a subset of more common vari-\nables of a manageable size. For example, the MedGAN method\n19\nmodeled 615 disease categories without longitudinal information; the\nSynTEG model\n15 aggregates codes to higher level phenotypes and then\nremoves rare phenotypes, resulting in only 1276 variables; the ehrM-\nGAN approach\n21 reduced the variable dimension to be <100, and EVA16\nmodels frequent co-occurrence patterns in the original EHR data\nas one-hot vectors, limiting its ability to generate diverse and novel\nco-occurrence patterns. Our supplementary information provides\na table of these dimensionalities of existing methods. While these\nReceived: 1 March 2023\nAccepted: 23 August 2023\nCheck for updates\n1University of Illinois at Urbana-Champaign, 201 North Goodwin Avenue, Urbana, IL, USA.2Medisyn Inc., Las Vegas, NV, USA.e-mail: jimeng@illinois.edu\nNature Communications|         (2023) 14:5305 1\n1234567890():,;\n1234567890():,;\nlow-dimensional approaches may capture the proper statistics on a\nsmall number of variables and support narrow ML use cases relying\nsolely on those variables, the resulting synthetic data is inadequate for\nbroader applications that require high-dimensional data including\ncomprehensive statistical analysis, patient phenotyping, billing pre-\ndiction and analysis, disease staging, and comprehensive data sharing.\nWe propose an approach for generating high-dimensional EHR\ndata in its native form: the Hierarchical Autoregressive Language\nModel (HALO). This model, shown in Fig.1, takes an autoregressive and\nprobabilistic approach and can capture the hierarchical distribution of\nEHR records and their temporal relationships. Using a hierarchical\napproach to model binary sequences of over a million variables,HALO\ncan efﬁciently learn and represent complex patterns in EHR data.\nHALO works by utilizing a pair of modules to represent both the\nvisit- and code-level structures of a patient record. First, it uses a\ncoarse, visit-level module to factorize the probability along each of a\npatient’sv i s i t sa n dt oe fﬁciently process and represent a patient’sp a s t\nmedical history. It then addsﬁne, code-level modeling to generate\neach variable in a given visit based on both that past history and also\nthe previous variables in the same visits for maximum intra-visit\ncohesion.\nWe evaluate the performance ofHALO by training it on a com-\nprehensive outpatient claims dataset, as well as the MIMIC-III inpatient\nEHR data\n25, and compare the results with a diverse set of existing\nsynthetic EHR data generation techniques such as refs.15,16,26.\nWe evaluate the data quality based on its utility in modeling the\nstatistical data distribution and for supporting ML models.HALO can\naccurately synthesize high-dimensional EHR data via modeling disease\ncode probabilities (d ≈ 10,000), disease code co-occurrence prob-\nabilities within a visit (d ≈ 1,000,000), and conditional probabilities\nacross consecutive visits (d ≈ 5,000,000). In our experiments, we\nfound thatHALOachieves a correlation coefﬁcient of above 0.9R\n2 when\ncompared to real EHR data, demonstrating its ability to generate\nrealistic data.\nIn addition to generating high-ﬁdelity and granular EHR data, we\nshow thatHALO improves predictive modeling on our EHR dataset by\nmore than 17% compared to the leading baseline. We evaluate the\npredictive accuracy and perplexity ofHALO on a hold-off test set,\ndemonstrating its superiority. Furthermore, the synthetic data gener-\nated byHALO enable downstream phenotyping ML models to achieve\ncomparable accuracy to models trained on real data, with an AUC of\n0.938 forHALO data versus 0.943 for real data. We then demonstrate\nthat combining real and synthetic data generated byHALOcan improve\nthe accuracy of ML models even more compared to using just real EHR\ndata. Furthermore, we show thatHALO generates realistic data while\nsimultaneously protecting patients’ privacy in the training data, as\nevaluated by a series of privacy metrics.\nResults\nProblem formulation\nStructured EHRs are multi-level longitudinal records, where each\npatient is represented by a sequence of visits. Each visit is character-\nized by a set of medical codes, reﬂecting the diagnoses, procedures,\nand medications administered during that visit. Additional patient\ninformation, such as demographics, disease phenotype labels, lab test\nresults, and inter-visit time, can also be included. We begin by for-\nmalizing the problem and introducing key notations that will be used\nthroughout.\nEHR data. We represent a patient recordR as a sequence of visits over\ntime such that\nR= V\nð1Þ,Vð2Þ, /C1/C1/C1 VðTÞ ð1Þ\nwhere each visit VðtÞ contains a varying number of medical codes\nmðtÞ\n1 ,mðtÞ\n2 , /C1/C1/C1 ,mðtÞ\njVðtÞ\nC j 2 C,l a bv a l u e slðtÞ\n1 , /C1/C1/C1 ,lðtÞ\njVðtÞ\nL j 2 L, and the inter-visit\ntime gapg(t). C is then the set of all medical codes in our vocabulary,\nFig. 1 | The proposedHALO model. The architecture ofHALO utilizing an auto-\nregressive multi-granularity approach which analyzes at both the visit and code\nlevel to generate next code probabilities based on the history of all previous visits\nas generated through a stack of transformer decoder layers and the previous codes\nin the current visit through a series of masked linear layers.\nArticle https://doi.org/10.1038/s41467-023-41093-0\nNature Communications|         (2023) 14:5305 2\nincluding diagnoses, procedures, and medications andL is the set of\nall labs. Beyond the longitudinal records, a patient record also\npossesses some static informationS containing demographics such\nas gender, race, and birth year and disease phenotype label D\nindicating major and persistent disease conditions.\nMatrix representation. To allow input toHALO and other machine\nlearning models, we then convertR,S,a n dD into a matrix repre-\nsentation R.S p e c iﬁcally, we buildR =[ v\ns, vl, v1, ⋯ , vT, ve], a matrix\ncontaining a sequence of the vector representations for each of the\npatient’s T visits, a preceding start visit, label visit, and a succeeding\nend visit.\nThe start visitv\ns is a one-hot vector containing a special start code\nadded toC to signify the start of the record often required for certain\nmodel architectures.\nThe label visit vl similarly contains special codes added toC\nrepresenting demographic and chronic disease phenotypes fromS\nand D, respectively. For example, this label visit will have codes\nrepresenting the patient’s gender, racial and ethnic groups, birth year,\nand any chronic labels.\nEach subsequent visitvt 2 RjCj is then represented as a multi-hot\nbinary vector representing medical codes, lab values, and inter-visit\ngaps present in that visit. To represent continuous lab values and visit\ngaps in a discrete form, we employ a granular discretization. This is\nachieved by adding multiple range codes toC for each lab test and for\nthe intervals between visits. By converting all medical information into\nbinary variables,c\ni\nt represents the presence of theith code inC in the\ntth visit of the patient recordR.\nFinally, to signal the end of the patient record inve, a special last\nvisit code is added toC, serving a similar purpose to a stop token in\nnatural language generation. This not only enables generative models\nto learn when to terminate records but also allows forR to be padded\nthrough additional columns into a constant length for batch input\nwithout altering its content.\nFigure 2 depicts the format of the visit vector and the EHR\nrepresentation, and we provide a table of notations for reference in our\nsupplementary information.\nGeneration task. is to createR\n0, a synthetic patient record that is\nstatistically similar to and offers the utility ofR without any one-to-one\nmapping to a real patient. OurHALO method does this by learning the\ndistributionP(R).\nExperimental design\nWe evaluate our method and compare it to several baselines\ncomprising both recently proposed models and other logical\nautoregressive model architectures on a series of experiments\non both outpatient and inpatient EHR datasets. To maintain the\nﬁdelity of the original EHR data, our experiments focus on synthe-\nsizing original granular medical codes without aggregating or\ncombining codes. Speciﬁcally, we seek to answer the following\nquestions.\n Is HALO effective at modeling the underlying data distribution of\nelectronic health records?\n Can HALO produce a synthetic dataset that is statistically similar\nto real EHR data?\n Can HALO augment real data for more accurate disease pheno-\ntyping prediction?\n Can HALO generate realistic continuous variables such as lab\nresults and visit time gap?\n Can HALO preserve patient privacy in the training?\nDatasets and experimental setup\nDatasets. We use two datasets for our experiments:\n(1) The outpatient EHR is from a large real-world US claims data. It\ncontains 929,268 patients and binary labels for 11 chronic diseases\n(speciﬁc diseases and patient counts are included in the\nsupplementary information). This yields a ﬁnal real-world\nFig. 2 | The data formatting. aThe visit representation. Each visit is represented as\na multi-hot vector containing indices for medical codes, static label codes to cover\ndemographics and disease phenotypes, and special codes describing the shape and\ntemporal ordering of the patient’s visit.b The EHR representation. An EHR is then\nrepresented as a matrix constructed as a series of temporally ordered visit vectors.\nArticle https://doi.org/10.1038/s41467-023-41093-0\nNature Communications|         (2023) 14:5305 3\noutpatient EHR dataset with an average of 34.16 visits per record\nand 3.52 codes per visit with 9882 unique ICD-10 codes.\n(2) The inpatient EHR is from the MIMIC-III ICU stay dataset25.I t\ncontains 46,520 patients with 25 disease phenotype labels\nas deﬁned by the MIMIC benchmark27. This dataset has an average\nof 1.26 visits per record and 15.11 codes per visit with 6841\nunique ICD-9 codes. Note that this includes patients with just\na single visit (and as we will show,HALO’s Code-Level Module\nallows it to be very effective on those patients).Both datasets\nshare the same patient representation as a series of visits\nalong with chronic disease phenotype labels. We keep the ICD\ncodes in the data without code aggregation or removing any\ninfrequent codes.\nExperiment setup.W eu s ea0 . 8– 0.2 training-test split with an addi-\ntional 0.9– 0.1 training-validation split during training for both out-\npatient and inpatient datasets. We use the Adam optimizer with a\nlearning rate 1e– 4 (which was arrived upon through experimentation).\nWe use a batch size of 48 and train for 50 epochs, saving the model\nwith the lowest loss on the validation set. We implement the model and\ntrain in the Python 3.6.9 coding language using the PyTorch\n1.9.0+cu111 framework\n28 along with the scikit-learn 0.24.2 and NumPy\n1.17.2 packages. Finally, all experiments are done via one NVIDIA TESLA\nV100 GPU with 32 GB RAM. TheHALO source code is publicly available\non GitHub athttps://github.com/btheodorou99/HALO_Inpatient.\nBaseline methods\nBelow we outline the baseline methods and the necessary alterations\nto those baselines to adapt to our problem setting.\n HALO-Coarse: This baseline is an ablation baseline consisting of\njust the coarse, visit-level granularity module of the fullHALO\narchitecture. It generates each code probability based on all\nprevious visits (grouped into a multi-hot representation) but\nwithout theﬁne, inter-visit modeling such thatPðc\ni\niÞ is modeled\nby Pðci\nijv1, /C1/C1/C1 ,vt/C0 1Þ instead of Pðci\nijv1, /C1/C1/C1 ,vt/C0 1,c1\ni , /C1/C1/C1 ,ci/C0 1\ni Þ.I t\nconsists predominantly of 12 transformer decoder blocks in the\nmodel of Radford et al.\n29 augmented to support multi-hot as\nopposed to one-hot inputs and outputs within the embedding\nlayer andﬁnal activation layer.\n GPT model29: We applied the GPT model without any augmen-\ntation to support multi-hot inputs and outputs but instead with\nthe conversion of EHRs to a fully one-hot sequential representa-\ntion. However, this model had to be shrunk down to 3 blocks\nfrom 12 toﬁt into memory because this greatly expanded the\nlength of the sequences.\n LSTM EHR model\n30: is a deep, autoregressive LSTM model,\nadapted to generate structured patient records rather than\nunstructured text as it had previously been utilized, which is\ndirectly analogous to theHALO-coarse model but uses LSTM\nblocks instead of transformer decoder blocks.\n SynTEG\n15: is a GAN-based model that uses a transformer and\nLSTM-based encoder model to generate embeddings of EHRs up\nto a given visit before feeding those embeddings into a\nconditional GAN which generates the next visit.\n EVA16: is a VAE-based model that uses a bidirectional-LSTM\nencoder and CNN-based decoder (using deconvolutions to\nexpand the latent encoding to the proper temporal dimension\nand then masked, diluted 1D convolutions to build the records in\nan autoregressive manner). The only change we made was to\nconvert the output from one-hot code combinations to multi-\nhot code probabilities to allow for greater representative power.\nEvaluating EHR language modeling\nThe ﬁrst evaluation is conducted by predicting the probabilities and\noutputs of the test set. In this phase, we assess the performance of\nHALO against two multi-hot language model baselines, namelyHALO-\nCoarse and LSTM. These baselines explicitly generate a probability\ndistribution without accessing the entire input. It’s worth noting that\nother baseline models, such as the GAN-based SynTEG model, the VAE-\nb a s e dE V Am o d e l ,a n dt h eG P Tm o d e l ,c a n n o tb ed i r e c t l yc o m p a r e di n\nthis task because those methods do not make a single probability\nprediction for each code within the visit.\nOur ﬁrst evaluation aims to assess the capability of the models to\npredict the presence of potential medical codes, given a patient’s past\nmedical history and the previous codes from the current visit. Note\nthat we explore different orderings of codes (such as most to least\nprevalent, alphanumeric, random, etc.) butﬁnd no noticeable differ-\nences, displaying the results of such an exploration in our supple-\nmentary information and settling on a random ordering throughout\nour experiments. This evaluation is crucial in showcasing a model’s\nability to learn patterns from the patient population and its potential to\nperform well in various patient simulation and extension applications.\nWe show the results in Table1 w h e r ew es e et h a tHALOoutperforms the\ntwo compared language model architectures. Upon closer examina-\ntion, we observed that the LSTM baseline model struggled with the\ncomplexity and size of the outpatient EHR dataset, while our proposed\nmodel HALO performed comparably to the HALO-Coarse ablation\nbaseline. In contrast, in the inpatient EHR setting, where the visits are\nshorter but contain more codes,HALO’s multi-granularity approach\nproved to be highly effective. Speciﬁcally, the model achieved a\nnotable 4% reduction in binary cross-entropy (BCE) loss and a 17%\nincrease in F1 Score on test data when compared to the single granu-\nlarity HALO-Coarse model. Notably, bothHALO models signiﬁcantly\noutperformed the LSTM baseline in this setting. These results highlight\nthe signiﬁcant value of our multi-granularity approach in handling the\ncomplex and diverse nature of medical codes in different EHR settings.\nAdditionally, we present perplexity, which evaluates the prob-\nability or likelihood of the test set as quantiﬁed by a model trained on\nthe training set, normalized by the unit of consideration that we are\ninterested in. In our case, this normalizing unit is the number of\nmedical codes in a patient’s medical record (or equivalently number of\nones inR). Perplexity is a metric found commonly in the wider gen-\nerative modeling domain, especially on the task of natural language\ngeneration (e.g. ref.29). We introduce it to the task of synthetic EHR\nTable 1 | Test set modeling metrics\nOutpatient EHR Inpatient EHR\nBCE loss F1 score PP per code BCE loss F1 score PP per code\nLSTM 7.744 × 10 −4 0 660.204 2.600 × 10 −4 0.193 74.565\nHALO-Coarse 1.631 × 10 −4 0.829 3.927 2.019 × 10 −4 0.343 28.448\nHALO 1.624× 10−4 0.828 3.903 1.932 × 10−4 0.414 24.664\nWe include each of our autoregressive, predictive, and likelihood-based models. The bold value denotes the best results. Baseline methods SynTEG, EVA, and GPT are all omitted here because they\neither do not produce a probability distribution, peek at the outputs, or utilize a different, non-comparable data representation.HALOoutperforms both of the baselines, achieving up to a 4% decrease\nin testset BCE loss, a 17% increase in F1 score, and a 13% lower perplexity per present code as compared to the leadingHALO-Coarse baseline. Source data are provided as a Source Dataﬁle.\nArticle https://doi.org/10.1038/s41467-023-41093-0\nNature Communications|         (2023) 14:5305 4\ngeneration here. Perplexity is deﬁned mathematically by\nPP ðDÞ =\nﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ\n1\nPðDÞ\nN\ns\n=\nﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ\n1\nPðRð1Þ, /C1/C1/C1 ,RðjDjÞÞ\nN\ns\n=\nﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ\n1\nPðRð1ÞÞ/C1/C1/C1 PðRðjDjÞÞ\nN\ns\nð2Þ\nwhere D is the test dataset andR(t) is thetth record inD. In practice we\ncalculate the values by summing their log probabilities, using the\nequivalent form\nPP ðDÞ =e x p/C0\n1\nN\nX\nR2D\nlog PðRÞ\n !\nð3Þ\nThe normalized value then also corresponds to how many of the dif-\nferent normalizing units (medical codes) one would have to randomly\npick between on average to achieve the same probability. The results\no ft h ep e r p l e x i t ye v a l u a t i o na r es h o w ni nT a b l e1 as well. We see similar\nresults as with the classiﬁcation evaluation with bothHALO and HALO-\nCoarse performing very well on the outpatient EHR dataset (withHALO\nperforming slightly better) as the LSTM baseline struggles, andHALO\neasily outpacing both baseline methods in this likelihood evaluation\nfor the inpatient EHR dataset, producing a 13% lower perplexity per\npresent code as compared to theHALO-Coarse architecture without\nthe inter-visit modeling. Thus, in both of these test set evaluations, we\nsee that HALO is much more effective in terms of modeling the\nunderlying distribution of EHRs.\nStatistical similarity to real EHRs\nThe second analysis evaluates the statistical similarity of the generated\nand real data. For each method, we generate a synthetic dataset of the\nsame size as the training dataset. We then compare the unigram and\nbigram (both within the same visit and across consecutive visits)\nprobabilities for each unique code and pair of codes within the real and\nsynthetic datasets.\nStatistical comparison results. We evaluate the data at the visit and\nrecord level, considering approximately 10,000 individual codes and\nover a million bigram codes. We also compare various aggregate sta-\ntistics, such as the number of visits per record, medical codes per visit,\nand prevalence of chronic disease labels. The code probability results\nare presented in Fig.3, and the aggregate statistics are in Table2.\nAdditionally, we provideR\n2 values for visit-level normalized code\nprobabilities in our high-dimensional outpatient EHR dataset and a\nlower-dimensional setting. The details can be found in Table3.\nFurthermore, an interactive visualization of 1000 randomly\nselected code-level disease prevalence comparisons between our\nmethod and real data is accessible athttps://vega.github.io/. It allows\nzooming, panning, and hovering over points for speciﬁc disease\nnames. Finally, we provide chronic disease label probabilities, full visit\nlevel code probability plots, probability densities underlying the\naggregated statistics, and a discussion of the various failure modes of\nour baseline methods for that evaluation in our supplementary infor-\nmation. HALO again outperforms the baseline methods in each\nevaluation.\nKey ﬁndings. We observe that besides the GPT baseline struggling\nwith the complexity of the outpatient EHR dataset in terms of stopping\nthe record generation (as is common to many language models in the\ntext generation domain as their overall quality decays for long\nsequences, and the lack of visit level grouping in its data\nrepresentation causes its sequences to be considerably longer), the\nlanguage model architectures (GPT, LSTM,HALO-Coarse, andHALO)\ncan model both the shape of the synthetic records and the temporal\ndependencies much better on average than the VAE and especially\nGAN-based baselines. While each of the compared methods models\nthe unigram code probabilities relatively well, the temporal modeling\nis better shown in the overall synthetic record and visit lengths, the\ngeneration of chronic disease labels, and the sequential bigram eva-\nluation. SynTEG, EVA, and the LSTM baseline thus struggle with these\nevaluations (with the LSTM baseline struggling largely due simply to\noverall weakness).\nThe LSTM andHALO-Coarse language model baselines then falter\nwith respect to same-visit bigram probabilities due to their lack of\nintra-visit dependency modeling while the GPT baseline which models\neach code individually and so offers that intra-visit modeling can\nmaintain relatively stronger performance there.HALO can combine\nand build on each baseline’s strengths without any weaknesses, using\nthe compact multi-hot representation to offer a powerful model that\ndoes not struggle with any length or feature of data while simulta-\nneously maintaining the intra-visit modeling in an even more powerful\nand structured way. As such, it can best maintain performance in this\nhigh-dimensional setting and produces state-of-the-art results that\nclosely model the true training data in all settings from record and visit\nlengths, label probabilities, and all combinations of code probabilities.\nThis signiﬁes that HALO is capable of generating data that looks\nrealistic.\nAccurate disease phenotyping using synthetic EHRs\nThe ﬁnal evaluation explores the utility of the synthetic datasets\nfor training disease classiﬁers. To this end, we utilize two different\nsynthetically supplemented data setups and machine learning classi-\nﬁers to predict chronic disease labels based on patients’visits. In each\nof the two setups, we use a simple bidirectional LSTM with a single-\nlayer fully connected head classiﬁer to predict chronic disease label(s)\nbased on a patient’sv i s i t s .\nAccurate disease phenotyping.I nt h eﬁrst data setup, we assess\nmodel performance in real-world scenarios using synthetic training\ndata. We conduct experiments for each of the 11 chronic disease labels\nin the outpatient EHR dataset, sourced from the Centers for Medicare\nand Medicaid Services and the SynPUF dataset\n31. Additionally, we\nperform experiments for each of the 25 chronic diseases in the inpa-\ntient EHR dataset, based on the benchmark proposed in ref.27.\nFor each chronic disease, we randomly extract 2500 records for\ntraining, ensuring a balanced distribution of positive and negative\nlabels (50– 5 0 ) .T h i sp r o c e s si sr e p e a t e da c r o s so u rs i xs y n t h e t i cd a t a -\nsets (one for each method) and one real training dataset, resulting in a\ntotal of seven balanced training datasets. The selected size of 2500\nrecords strikes a balance between having enough training data for\nmachine-learning models and maintaining sufﬁcient positive labels for\neach disease.\nWe train classiﬁers on each of these datasets and select the best\nmodel for each dataset using a validation set of 250 records, equally\nrepresenting both classes. Finally, we evaluate the models on test sets\nconsisting of 500 records, equally representing both classes, from the\noriginal test set comprising real patient data.\nWe display the average accuracy and F1 score for each synthetic\ndataset from each of the compared models as well as the real training\ndata across each of the chronic disease labels in Table4.N o t et h a tw e\nprovide the standard deviations of each metric in either table as well,\nbut most of that deviation stems from differences between tasks rather\nthan inconsistent performance within each model.\nWe provide a full set of results by chronic disease label and also\nadditional synthetically augmented outpatient results in our supple-\nmentary information. In both datasets, we can see that each synthetic\nArticle https://doi.org/10.1038/s41467-023-41093-0\nNature Communications|         (2023) 14:5305 5\n             Unigram Code Probabilities         Sequential Visit Bigram Probabilities        Same Visit Bigram Probabilities\n               HALO                        HALO - Coarse                           GPT                                  LSTM                                 EVA                                  SynTEG\nOutpatient EHR Training Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nSynthetic Data\nR2: 0.908R2: 0.973R2: 0.986\nR2: 0.958 R 2: 0.896 R 2: 0.661\nR2: 0.024R2: -0.383R2: -0.714\nR2: -7.462R2: -1.130R2: -12.979\nR2: -9.911 R2: -0.884 R2: -6.357\nR2: -95.535 R2: -21.832 R 2: -314.721\nOutpatient EHR Training DataOutpatient EHR Training Data\nOutpatient EHR Training DataOutpatient EHR Training DataOutpatient EHR Training Data\nOutpatient EHR Training DataOutpatient EHR Training DataOutpatient EHR Training Data\nOutpatient EHR Training DataOutpatient EHR Training DataOutpatient EHR Training Data\nOutpatient EHR Training DataOutpatient EHR Training DataOutpatient EHR Training Data\nOutpatient EHR Training DataOutpatient EHR Training DataOutpatient EHR Training Data\nFig. 3 | Code probability plots.These plots show the Unigram, Sequential Visit\nBigram, and Same Record Bigram probabilities for each synthetic dataset. With the\nexception of SynTEG, all models exhibit some correlation in the unigram and\ntemporal bigram evaluations, but many have weak correlations or consistently\nyield higher synthetic probabilities due to a lack of temporal consistency and\nrepetition across visits in the records.HALO and to a lesser extent,HALO-Coarse\nperform the best in all settings, whileHALO is the only one that can realistically\nproduce pairs of codes within and across visits and achieve state-of-the-art results.\nArticle https://doi.org/10.1038/s41467-023-41093-0\nNature Communications|         (2023) 14:5305 6\ndata of GPT, HALO-Coarse, and HALO largely maintains the perfor-\nmance of real data and offers large improvements over the SynTEG,\nEVA, and LSTM baselines.HALO’s synthetic data offers the best pre-\ndiction results.\nPhenotyping of rare conditions.W ee v a l u a t et h eu t i l i t yo fs y n t h e t i c\nEHR data in identifying uncommon conditions. We created a highly\nimbalanced dataset of patients labeled with cancer chronic disease\nfrom the outpatient EHR dataset. The dataset comprised 50,000 EHR\nrecords without the cancer chronic disease label and only 1000\nrecords with the label.\nUsing this imbalanced data, we trained a classiﬁer and compared\nits performance to classiﬁers trained on balanced datasets. For bal-\nancing, we added 49,000 positively labeled synthetic records and also\nused another classiﬁer trained on a dataset balanced using real\nrecords.\nThe evaluation results are summarized in Table5. Notably,HALO\noutperformed all baselines, exhibiting signiﬁcant improvements on\nthe original unbalanced dataset as well as the synthetically augmented\ndatasets. It approached the upper bound performance of the ideal\nbalanced dataset.\nThis experiment underscores the potential of synthetic EHR data\nin supporting the identiﬁcation of uncommon conditions.\nRealistic continuous variables in synthetic EHRs\nWe conclude with a brief exploration to demonstrate the viability of\nour discretized representation of continuous values, and HALO’s\neffectiveness in using it to model those variables. We build new\ntraining datasets including visit gaps in the outpatient EHR dataset and\nlab values in the inpatient EHR dataset. We use these datasets to train a\nnew version of our model and generate another synthetic dataset of\n250,000 and 45,000 records, respectively.\nTable 3 | Code probability correlationsR2 between training and synthetic datasets\nHigh-dimensional outpatient EHR Low-dimensional outpatient EHR\nUnigram code\nprobabilities\nSequential visit bigram\nprobabilities\nSame visit bigram\nprobabilities\nUnigram code\nprobabilities\nSequential visit bigram\nprobabilities\nSame visit bigram\nprobabilities\nEVA 0.910 0.082 0.128 0.957 0.134 0.225\nSynTEG 0.915 0.355 0.082 0.784 0.315 0.211\nLSTM 0.900 0.077 0.127 0.962 0.135 0.225\nGPT 0.743 0.382 0.262 0.924 0.626 0.515\nHALO-\nCoarse\n0.794 0.357 0.176 0.882 0.503 0.247\nHALO 0.914 0.508 0.362 0.949 0.686 0.562\nThe values areR2 values to measure the correlations of the three types of code probabilities for different synthetic datasets against the training data in both high-dimensional and low-dimensional\nsettings. Bold values denote the best results. Although the results showed a drop in performance for each method in the high-dimensional setting,HALOwas able to maintain strong performance with\nminimal decline. Overall, our proposed method achieved state-of-the-art performance, outperforming the baselines in both bigram evaluations in low and high-dimensional settings. Source data are\nprovided as a Source Dataﬁle.\nTable 2 | Aggregate statistics regarding the shape of training\na n dc o m p a r e ds y n t h e t i cd a t a s e t s\nOutpatient EHR Inpatient EHR\nRecord length\nmean\n(std. dev.)\nVisit length\nmean\n(std. dev.)\nRecord length\nmean\n(std. dev.)\nVisit length\nmean\n(std. dev.)\nEVA 29.49 (28.88) 3.35 (1.71) 1.20 (0.723) 11.92 (3.665)\nSynTEG 93.00 (2.30) 3.70 (4.10) 27.55 (3.34) 5.93 (10.96)\nLSTM 32.04 (27.14) 3.22 (1.64) 1.30 (0.56) 9.53 (2.91)\nGPT 95.72 (3.37) 2.70 (1.73) 1.26 (0.73) 9.67 (5.45)\nHALO-\nCoarse\n35.26 (31.87) 3.77 (2.23) 1.13 (0.39) 11.21 (3.91)\nHALO 36.19 (33.41) 3.93 (2.72) 1.31 (0.84) 11.93 (6.45)\nTrain data 34.18 (32.35) 3.52 (2.18) 1.27 (0.92) 11.68 (5.70)\nAggregate statistics on the number of visits per record and the number of codes per visit. The\nvalues are mean (std).HALO outperformed all the baselines while closely approximating the\ndistribution of the true training data. Source data are provided as a Source Dataﬁle.\nTable 4 | Chronic disease classiﬁcation model performance\ntrained on synthetic data\nOutpatient EHR Inpatient EHR\nAvg. accuracy Avg. F1 score Avg. accuracy Avg. F1 score\nEVA 0.508 ± 0.02 0.283 ± 0.26 0.5356 ± 0.05 0.580 ± 0.05\nSynTEG 0.507 ± 0.03 0.514 ± 0.20 0.539 ± 0.06 0.438 ± 0.06\nLSTM 0.506 ± 0.02 0.467 ± 0.28 0.522 ± 0.04 0.565 ± 0.04\nGPT 0.851 ± 0.03 0.854 ± 0.03 0.877 ± 0.05 0.881 ± 0.05\nHALO-\nCoarse\n0.867 ± 0.03 0.863 ± 0.03 0.863 ± 0.05 0.865 ± 0.05\nHALO 0.879 ± 0.03 0.878 ± 0.03 0.882 ± 0.04 0.884 ± 0.04\nReal data 0.891 ± 0.03 0.895 ± 0.03 0.938 ± 0.04 0.937 ± 0.04\nWe compared the average performance in terms of accuracy and F1 Score for each of the 11\nchronic disease labels in our outpatient dataset and 25 chronic disease labels in our inpatient\ndataset. The models were trained on each of our synthetic datasets and tested on real data. The\nreported values represent the mean and standard deviation across the tasks, with bold values\nindicating the best results. GPT,HALO-Coarse, andHALO’s data offer large improvements over\nthe other baselines and perform similarly to real training data.HALO’s synthetic data performs the\nbest with the highest average performance of all synthetic methods. Source data are provided as\naS o u r c eD a t aﬁle.\nTable 5 | Rare disease detection performance on synthetic\nbalanced datasets\nBCE loss Accuracy F1 score AUROC\nOriginal\nimbalanced\n0.693 0.497 0.013 0.417\nBalanced with\nreal data\n0.127 0.951 0.951 0.989\nEVA 0.615 0.695 0.705 0.730\nSynTEG 0.598 0.735 0.758 0.786\nLSTM 0.593 0.702 0.714 0.743\nGPT 0.472 0.880 0.869 0.956\nHALO-Coarse 0.265 0.918 0.916 0.959\nHALO 0.192 0.931 0.931 0.976\nWe present the classiﬁcation results on the test set for the simulated rare-disease detection task.\nWe compare models trained on datasets balanced using each synthetic dataset against models\ntrained on the original imbalanced data (representing the rare disease dataset). Additionally, we\ncompare the results against an upper-bound ideal dataset balanced using real data. The best\nresults are highlighted in bold. Among the evaluated models, EVA and SynTEG exhibit limited\nutility, while the language model architectures LSTM, GPT, andHALO-Coarse offer substantial\nvalue. HALO achieves state-of-the-art performance, closely approaching the results of a true,\nbalanced dataset. The source data can be found in the provided Source Dataﬁle.\nArticle https://doi.org/10.1038/s41467-023-41093-0\nNature Communications|         (2023) 14:5305 7\nWe then show that the distributions of those variables match the\nreal values. In Fig.4a and b, we show thatHALO accurately replicates\nthe distribution of gaps between patient visits and the pattern of\nshorter gaps for longer records, respectively. These captured nuanced\npatterns are on top of the aggregate mean gaps being very similar as\nwell. There are 33.53 days between visits on average within the real\noutpatient EHR data and 35.77 days on average for HALO’ss y n -\nthetic data.\nUsing the inpatient dataset, we then demonstrate thatHALO\nreplicates not only the presence (in Fig.4c) but also the average values\n(in Fig. 4d) of performed lab tests. Speciﬁcl a b si n c l u d e d( c o r r e -\nsponding to points in those two plots) are included in our supple-\nmentary information. Overall, HALO’s approach to continuous\nvariables is effective, and it has the potential to generate compre-\nhensive synthetic patient records with multiple variables of differ-\nent types.\nPrivacy evaluation of synthetic EHRs\nIn addition to demonstrating the highﬁdelity of synthetic EHRs gen-\nerated byHALO, we want to ensure that the privacy of the patients\nwithin the original training dataset is protected. To that end, we con-\nduct a commonly used membership inference attack to test its\nidentiﬁcation risk, and we provide the results of two more evaluations\nin our supplementary information.\nMembership inference attack. The evaluation is the ability to thwart a\nmembership inference attack. These attacks aim to determine whether\nany speciﬁc real patient record was used in the training dataset to\ngenerate the synthetic records. Membership inference attacks are a\nwell-known privacy test in theﬁeld of synthetic EHR generation, and\naddressing them is crucial to ensure the privacy and conﬁdentiality of\npatient identities.\nTo demonstrate thatHALO is not susceptible to such an attack,\nwe show that we can prevent two different attempts at a member-\nship inference attack based on the synthetic data generator and the\nsynthetic dataset itself. We generate an attack dataset by ﬁrst\nselecting 100,000 records from each real dataset used for training\nand assigning them a positive label. Then we select 100,000 records\nfrom the remaining records not used for training as the negative\nlabel set.\nNext, we conduct two attacks:\n In the Model Attack, we label the 100,000 records with the\nhighest log probability from the model as positive, predicting\nthat they were part of the training dataset.\nab\ncd\nFig. 4 | Continuous variable generation performance:HALOeffectively captures\nthe distribution of continuous variables through its discretization approach,\nas demonstrated in four scenarios. aInter-visit gap probability density: The\nprobability density of inter-visit gaps indicates thatHALO closely approximates the\ntrue shape of real data.b Inter-visit gap by visit number: The mean visit gap, as per\nvisit number, across both real and synthetic datasets reveals thatHALO accurately\ncaptures the pattern of patients with many records, showing shorter gaps in their\nsubsequent visits.c Lab presence probabilities: The probability of binary lab pre-\nsence demonstrates thatHALO accurately generates lab variables, even when dis-\ncretized across multiple variables.d Mean lab values: The average value of labs,\nwhen present, conﬁrms thatHALO’s synthetic labs closely resemble those of the real\ndataset. Values in parentheses areR\n2.\nArticle https://doi.org/10.1038/s41467-023-41093-0\nNature Communications|         (2023) 14:5305 8\n I nt h eD a t a s e tA t t a c k ,w el a b e lt h e1 0 0 , 0 0 0r e c o r d sw i t ht h e\nlowest hamming distance to the closest record in the synthetic\ndataset as positive. We pick a hamming distance (equivalent to\nManhattan Distance in our binary setting) as our distance metric\nbetween patient records throughout our privacy evaluations in\naccordance with Yan et al.\n32, but any distance metric could be\nsubstituted interchangeably.These two attacks allow us to test\nthe ability of the synthetic dataset to prevent an attacker from\ninferring whether a real record was used in the training dataset.\nWe show the results of the classiﬁcations from the attacks in\nTable6. The accuracy of both attacks on both datasets is ~50%, which is\nsimilar to a random guess. This shows that neither the model nor the\nsynthetic dataset reveals any meaningful or compromising informa-\ntion about the patient identity in the training dataset. We also perform\nthe dataset attack with each of our baseline datasets and see that each\nsimilarly accomplishes it, achieving a similar probability at around\n50%. Note that we do not perform the model attack with the baseline\nmodels because most of them cannot offer a probability output of\ninput patient records, and the dataset-based attack is the standard one\nused throughout literature in this domain.\nBeyond the membership inference attack, we also show thatHALO\npasses attribute inference attack and nearest neighbor adversarial\naccuracy\n33 evaluations in our supplementary information.\nDiscussion\nIn this paper, we proposed a method HALO for generating high-\ndimensional synthetic longitudinal EHR data. Our method is speciﬁ-\ncally designed to handle the sequential, multi-granular, and high-\ndimensional nature of electronic health records by generating an\nexplicit probability distribution over the codes, visits, and records, and\nHALO can generate realistic data without needing to aggregate or\nremove any codes as past approaches have unanimously done. We\nthen showed thatHALO can produce incredibly realistic synthetic EHR\ndata. Speciﬁcally, we showed thatHALO can capture the probability\ndistribution underlying the records better than other language model\nbaselines and then produce a synthetic dataset that both looks similar\nto and offers the utility of real patient records as measured by medical\ncode occurrence probabilities and machine learning classiﬁcation\ntasks augmented with synthetic data. Finally, we also show that our\nmethod offers this performance without compromising privacy\nthrough several privacy evaluations.\nIn conclusion, one of the key advantages ofHALO is its ability to\ngenerate binary sequences that are over a million variables in length.\nIts impressive performance makes it a promising avenue for develop-\ning and sharing realistic but synthetic EHR datasets that can support\ndiverse applications. This represents an exciting opportunity to\nexpand the use of synthetic data in the healthcareﬁeld and could help\naddress some of the challenges associated with data privacy and\nsecurity.\nWhile we have shown the impressive performance ofHALOin both\nproducing high-quality, high-ﬁdelity, and privacy-preserving, we now\nbrieﬂy discuss some remaining limitations. First, the architecture is\ndesigned in the model of a large language model. While the multi-\nmodal setup allows the model to condition on more patterns per data\npoint and learn more efﬁciently, our high-performing generator still\nrequires relatively large training datasets which might not be available\nin some settings.\nAnother important aspect of our model is that it generates syn-\nthetic records through a probabilistic process. While it learns real-\nworld patterns during training, there is still a chance that some gen-\nerated records may not be clinically meaningful. However, this risk can\nbe mitigated through postprocessing with clinical rules that validate\nthe synthetic records. If our model is deployed in the real world, it is\nimportant to consider implementing such postprocessing steps to\nensure that only clinically relevant synthetic records are produced.\nFinally, ourHALO model focuses on generating longitudinal EHR\ndata, such as medical codes and lab results. However, other crucial\ndata modalities, such as clinical notes and medical images, are not yet\ncovered by the model. To generate fully comprehensive patient\nrecords that include all modalities, it will be necessary to use diverse\ntraining data and develop multiple models to handle each modality.\nThis exciting avenue of research is a promising future direction.\nMethods\nOur study has acquired exempt status from Institutional Review Board\n(IRB) approval. This study has been found to be exempt pursuant to\n45CFR46.104(d)(4) “Secondary research for which consent is not\nrequired: Secondary research uses of identiﬁable private information,\nif (i) The identiﬁable private information is publicly available; AND (ii)\nInformation is recorded by the investigator in such a manner that the\nidentity of the human subjects cannot readily be ascertained directly\nor through identiﬁers linked to the subjects, the investigator does not\ncontact the subjects, and the investigator will not re-identify subjects.\"\nBackground and related work\nOf all the EHR generation methods, rule-based approaches, such as\nSynthea\n34 or SynPUF31, have proven to be the most effective in deli-\nvering practical value. These simple approaches either offer de-\nidentiﬁcation of real records by combining data across multiple\npatients in a suf ﬁciently privacy-preserving way\n31, simulation of\npatients within a complex yet constrained rule-based system34,B a y e -\nsian probabilistic modeling of aggregated, non-temporal patient\nrecords\n35, or proprietary method without detailed explanation36– 38.\nMany of these systems can only produce synthetic patient data with\nTable 6 | Membership inference attack results\nOutpatient EHR Inpatient EHR\nAcc. Precision Recall Acc. Precision Recall\nHALO Dataset Attack 0.501 0.501 0.501 0.492 0.491 0.477\nHALO Model Attack 0.509 0.509 0.509 0.515 0.515 0.515\nEVA Dataset Attack 0.498 0.498 0.496 0.493 0.493 0.477\nSynTEG Dataset Attack 0.500 0.500 0.500 0.491 0.491 0.467\nLSTM Dataset Attack 0.499 0.499 0.496 0.494 0.494 0.481\nGPT Dataset Attack 0.500 0.500 0.500 0.492 0.491 0.455\nHALO-Coarse Dataset Attack 0.500 0.500 0.499 0.491 0.491 0.462\nFor each record in the attack dataset, weﬁnd both the log probability of the record from the trained model (Model Attack) and the hamming distance to the closest record in the synthetic dataset\n(Dataset Attack). The attacks then label half of the records with the highest probability or lowest distance records, respectively, as in the training set. We see that the accuracy for either attack is right\naround 50%, which is similar to a random guess. This indicates that the synthetic dataset and the model do not reveal any patient-identifying information about the original training datasets. We also\nﬁnd that each baseline synthetic dataset similarly thwarts the dataset attack. Source data are provided as a Source Dataﬁle.\nArticle https://doi.org/10.1038/s41467-023-41093-0\nNature Communications|         (2023) 14:5305 9\nlimited capacity in realism and utility. We focus instead on ML methods\nthat have the potential to generate realistic high-dimensional synthetic\npatient data.\nGAN-based methods. Many synthetic data generation methods use\ngenerative adversarial networks (GANs), which involve a generator\nthat creates realistic data, and a discriminator that decides if the data\nis real or fake\n39. The GANs have been applied to patient record\ngeneration ﬁrst in ref. 19 followed by many other GAN-based\napproaches15,17,18,20– 24,40. However, GANs have limitations when gen-\nerating sequential data like EHRs. They usually only produce one\noutput (no time connections) and so most EHR generation methods\naggregate EHR data into one time step\n22– 24, create a representation of\nEHR data18, or do both19,20.\nGANs also struggle with high dimensional and sparse data like\nreal-world EHR, limiting all existing synthetic EHR GAN approaches to\nproduce relatively low dimensional data through the aggregation of\nvisits and medical codes or removal of rare codes. For example, there\nare a few methods in this category which do generate longitudinal\ndata. LongGAN\n40 and EHR-M-GAN21 both focus only on dense lab time\nseries of under a hundred dimensions. CorGAN17 generates records\nwith 1071 distinct codes, and the current state-of-the-art GAN\napproach that we baseline against, SynTEG\n15, both combines and\nremoves rare codes before arriving at aﬁnal dimensionality of 1276.\nWhile GANs have the potential to be conditioned on external\nfactors and labels, such as demographics or disease phenotype labels,\nthe ability to do so has not been extensively explored in existing works\non EHR generation. Moreover, there are only a limited number of\napproaches that can generate synthetic EHR data tailored to speciﬁc\ndiseases. For example, SmoothGAN\n24 focuses on aggregated lab and\nmedication information and does not model individual visits; EHR-M-\nGAN\n21 offers conditional and sequential capabilities but for low\ndimensional (under 100 dimensions) lab time-series information;\nCONAN and MaskEHR\n18,41 model only a single rare-disease population\nfor data augmentation; and EMR-WGAN and HGAN22,23 can only model\nlow-dimensional (both under 1000 dimensions) aggregated EHRs.\nDeep sequential methods. Accurately modeling the longitudinal\nnature of EHRs is crucial for realistic EHR generation. In recent years,\ntwo methods have shown progress in generating sequential EHRs by\nusing either a GAN or a VAE to condition representations of past\npatient visits to generate current visits\n15,16.S p e c iﬁcally, SynTEG15\nmodels the time between visits, and EVA16 offers a conditional variant.\nIn our experiments, we compareHALO to these two models. However,\nboth SynTEG and EVA often need to perform preprocessing steps to\nreduce the dimensionality of the vocabulary by aggregating medical\ncodes and removing rare codes.\nLanguage models. Our objective is to develop an improved method\nfor generating realistic and high-dimensional EHR data by drawing\ninspiration from natural language generation. Language generation\nmodels predict the next word based on the preceding words, thereby\nlearning a probability distribution of languages. Similarly, EHR models\npredict the next visit based on past visits. Also our proposed method\nprovides an explicit probability output that allows for direct modeling\nand evaluation of the underlying data distribution. This approach is\nparticularly beneﬁcial in accurately capturing the complex and high-\ndimensional nature of EHR data.\nThe Transformer architecture, introduced in ref.42, has revolu-\ntionized natural language processing and enabled the development of\nlarge, attention-based models like BERT\n43 and GPT26,29,44.A m o n gt h e s e\nmodels, we draw inspiration from GPT, which relies on a stack of\nTransformer decoder blocks that use masking to predict the next set of\nprobabilities in parallel, allowing for fast training and scalability.\nHowever, applying language models directly to EHR data poses unique\nchallenges. Unlike natural language sequences, EHR data exhibits a\nhierarchical structure that must be captured, with medical codes\nassociated with speciﬁc patient visits, and visits associated with indi-\nvidual patients. Additionally, EHR data contains heterogeneous ele-\nments, including demographic variables, structured medical codes,\nand numeric lab measures, not all of which are discrete tokens.\nAddressing these challenges requires approaches that leverage the\nstrengths of language models while adapting them to the peculiarities\nof EHR data.\nHierarchical autoregressive language model (HALO)\nWe model the probability of patient recordR, P(R), via a hierarchical\nautoregressive model, which utilizes both visit- and code-level struc-\ntures of a patient record. First, it factorizes the probability along the\nvisit level using the autoregressive identity by\nPðRÞ = Pðv\ns,vl, /C1/C1/C1 ,vT ,veÞ\n= PðvsÞPðvljvsÞPðv1jvs,vlÞ/C1/C1/C1 Pðvejvs,vl, /C1/C1/C1 ,vT Þ ð4Þ\nto produce what we call our coarse autoregressive sequence. We then\ncontinue to factorize the probability of visits further along the code\nlevel by converting\nPðv\ntjvs, /C1/C1/C1 ,vt/C0 1Þ = Pc 1\nt jvs, /C1/C1/C1 ,vt/C0 1\n/C0/C1\nPc 2\nt jvs, /C1/C1/C1 ,vt/C0 1,c1\nt\n/C0/C1\n/C1/C1/C1 Pc C\nt jvs, /C1/C1/C1 ,vt/C0 1,c1\nt , /C1/C1/C1 ,cC/C0 1\nt\n/C0/C1 ð5Þ\ninto what we call ourﬁne autoregressive sequence. Thisﬁnal prob-\nability is then rewritten as the product\nPðRÞ =\nY\nt\nYC\ni\nPc i\ntjvs, /C1/C1/C1 ,vt/C0 1,c1\nt , /C1/C1/C1 ,ci/C0 1\nt\n/C0/C1\nð6Þ\nwhere the probability of each code is based on each of the previous\nvisits and each of the previous codes in the current visit. Our multi-\ngranularity approach enables the modeling of high-dimensional\nsequences of many binary variables per record. This is achieved by\ngrouping prior information into signiﬁcantly fewer multivariate time\nsteps for previous visits while retaining the full autoregressive\nmodeling capability for each current visit. OurHALO architecture is\ndesigned to reﬂect this powerful yet compact model, with a powerful\nand efﬁcient structure divided into two distinct granularity levels: visit\nlevel and code level. This allows for each code to be conditioned on all\nprevious visits and the past codes of the current visit.\nVisit-level module. We begin with the coarse, visit-level granularity.\nWe use a stack ofM transformer decoder blocks, which have shown to\nbe effective in the high-dimensional domain of natural language pro-\ncessing, to generate a sequence of visit-level histories, where thet-th\nelement in the sequence,h\nðMÞ\nt 2 R\nnemb, is an embedding that repre-\nsents all of a patient’s medical history through theirt-th visit. Those\nhistories then combine to formHðMÞ 2 R\nðT +3 Þ × nemb (where the 3 in\nT + 3 includes the start, label, and end visits), the output of theﬁrst\nmodule which serves the purpose of thevs, vl, v1, ⋯vt−1 priors in\nEq. (6).\nTo encode each of the multi-hot visit representations [v1 ⋯vn]\ninto aﬁxed-length vector inR\nnemb, we employ an embedding layer\nthat includes two trainable parameter matrices: a code embedding\nmatrix W\nc and a positional embedding matrixWp. The code embed-\nding matrix maps each visit code to a dense vector representation,\nwhile the positional embedding matrix captures the relative position\nof each visit in the sequence. Next, we use a decoder model consisting\nof M = 12 transformer decoder blocks to generate a series of visit his-\ntory representations, which summarize the information contained in\nall previous visits in the coarse, visit-level sequence. The transformer\nArticle https://doi.org/10.1038/s41467-023-41093-0\nNature Communications|         (2023) 14:5305 10\ndecoder blocks employ masked multi-head self-attention, which\nallows the model to attend to all previous visits while preventing\ninformation leakage from future visits. This process is written more\nformally as\nH\nð0Þ = RWe + Wp\nHðmÞ = transformerblockðHðm/C0 1ÞÞ8 m 2½ 1,M/C138\nð7Þ\nwhere R 2 RðT +3 Þ × C is the patient record matrix representation,We 2\nR\nC × nemb is the code embedding matrix,Wp 2 R\nðT +2 Þ × nemb is the\npositional embedding matrix (to recapture the position and order of\nthe sequence of visits), and each transformer block is based on a\ndecoder block from the original transformer architecture\n42 which we\ndescribe in more detail in our supplementary information.\nThus, having processed the multi-hot patient visits through the\ninitial, coarse visit-level module of our architecture, we obtain a\nsequence of visit history representationsH(M), which capture the col-\nlective information of all previous visits up to each time step. These\nrepresentations provide a compressed summary of the patient’s visit\nhistory, enabling downstream modules to make predictions based on\nthe patient’sm e d i c a lt r a j e c t o r y .\nCode-level module. However, we still need to add in the code-level\npriors and generate output probabilities. To construct the input for the\nﬁne, code-level module, we offset and concatenate the previous\nmodule’s visit history embedding outputs with the original record\ninput, R.S p e c iﬁcally, we append theﬁrst T + 2 visit histories with the\nlast T + 2 visit representations [v\nl, v1, ⋯ , vT, ve] to createH0ð0Þ. Each of\nthe T + 2 inputs inH0ð0Þ has a representation of the history of all the\nprevious visits and the codes of the current visit, mirroring both the\nvisit and code priors in Equation (6). The ﬁnal input representation\nH\n0ð0Þ has sizeR\nðT +2 Þ × ðnemb + CÞ\n.\nTo model the distribution of eachPðci\ntÞ,t h i sH0ð0Þ is then fed\nthrough N = 2 masked linear layers which maintain the same dimen-\nsionality and use upper triangular masking of the weight matrix to\nensure that they preserve the autoregressive property of the prob-\nabilities (and have a ReLU activation function between layers). These\nlinear layers are able to efﬁciently model the high-dimensional, intra-\nvisit patterns where other sequential approaches such as additional\nrecurrent or transformer modules would run out of memory. The\nprobabilities are generated formally by\nH\n0ð0Þ = offsetand concatðHðMÞ,RÞ\nH0ðnÞ =m a s k e dlinearðH0ðn/C0 1ÞÞ8 n 2½ 1, N/C138\nO =s i g m o i dðH0ðNÞ½ : , nemb :/C138Þ\nð8Þ\nwhere the submatrix indexing at the end removes the visit-level history\nembedding portions of each vector to extract just the code\nprobabilities, and the masked linear layers are achieved by\nH\n0ðnÞ =m a xð0, H0ðn/C0 1ÞðWðnÞ /C12 MÞ + bðnÞÞ ð9Þ\nwhere the max function is omitted for theﬁnal ﬁne layer (sigmoid is\nused instead), ⊙is element-wise matrix multiplication, M 2\nR\nðnemb + CÞ × ðnemb + CÞ\nis the upper triangular masking matrix (with\nones in the upper triangular portion and zeros in the lower portion) to\npreserve the autoregressive property, and W\nðnÞ 2\nR\nðnemb + CÞ × ðnemb + CÞ\nand bðnÞ 2 R\nnemb + C\na r et h et r a i n a b l ep a r a -\nmeters of the module.\nThe outputO 2 RðT +2 Þ × C is then a matrix of probabilities of each\ncode for each visit after the start visit built from the visit histories and\neach previous code in the same visit. Each code corresponds to a\nconditional probability in the product from Eq. (6). We train our model\nusing the binary cross-entropy loss function over each medical code\n(treating the problem as a multi-label classiﬁcation problem) with\nmasking applied such that the start visit as well as any padded visits (of\nall zeros) do not contribute to the loss. The architecture of our model\nis shown in Fig.1.\nAdditional features and considerations\nFinally, We discuss different variants and add-on features ofHALO.\nConditional generation. Our method generates electronic health\nrecord (EHR) data by using demographicsS and chronic disease\nphenotypesD as labels, which are represented in our label vocabulary\nand applied to individual visits, as shown in Fig.2. We selected these\nlabels based on their relevance to downstream use cases. Each label is\nrepresented as a binary variable inv\nl, indicating the presence of the\ncorresponding disease or demographics group indicator. These indi-\ncators are deﬁned by concepts such as speciﬁc categories of genders,\nraces, ethnicity, age groups, and more. We can easily extend this\nstrategy to include other labels of interest, such as various biomarkers,\npatient outcomes, or even abstract patient embeddings.\nUnconditional generation. Our setup generates electronic health\nrecord (EHR) data with conditional labels by incorporating a“label\nvisit\" in the data format, as illustrated in Fig.2. This format enables easy\ngeneration of labeled and conditional data, which are highly valuable\nfor using synthetic data in machine learning tasks and as an augmen-\ntation tool, particularly for rare cohorts. However, it’s important to\nnote that this formatting is optional. If desired, the“label visit\" com-\nponent can be removed from the EHR representation, and the archi-\ntecture can be trained to generate unconditioned EHRs without any\nmodiﬁcation.\nGeneration of continuous variables. Our model can generate not only\nmedical codes but also continuous variables, such as lab values and\ntemporal gaps between visits. However, the availability of these addi-\ntional variables in the generated data depends on their presence in the\noriginal dataset used for training. For example, the outpatient EHR\ndataset used in our study includes the time between visits, while the\ninpatient EHR dataset includes lab values.\nIn previous models, continuous values were typically generated\nusing either GANs, which lack the autoregressive probabilistic mod-\neling that we employ, or value predictors (such as time series analysis\nmodels), which we often found to produce average values with insuf-\nﬁcient variance. To overcome these limitations, we model continuous\nvariables within the healthcare domain by discretizing lab values and\ntemporal gaps into clinically equivalent buckets. The resulting binary\nvariables are included in the model’sc o n t e x t ,d e n o t e da sC,b e f o r e\nbeing converted back to continuous values through random uniform\nsampling within the corresponding bucket range. By using this\napproach, our model generates more realistic and diverse continuous\nvariables than previous methods.\nMore speciﬁcally, to generate discrete versions of continuous\nvariables, such as lab values and temporal gaps, we divide the range of\neach variable into several“buckets\", as represented by the values\nb\n1,b2, /C1/C1/C1 ,bjlðtÞ\nj j,w h e r ejlðtÞ\nj j refers to the number of buckets required.\nWe determine the bucket ranges by either seeking advice from clin-\nicians on practical ranges, creating granular but equivalent groupings,\nor using a histogram construction algorithm\n45.T h es a m ea p p r o a c hi s\napplied to temporal gaps as well.\nFor example, the heart rate lab test with possible values ranging\nfrom 0 to 400 beats per minute down could be broken down into\ntwenty different buckets splitting the overall span into smaller ranges\nthat offer the same medical meaning for all their contained values. This\nbreakdown could haveb\n1 =( 0 ,4 0 ) a n db7 = (90, 100). These buckets\nthen convert the single continuous variable into many binary variables.\nWhenever the continuous variable is present in the original EHR, a\nArticle https://doi.org/10.1038/s41467-023-41093-0\nNature Communications|         (2023) 14:5305 11\nsingle one of those variables representing the corresponding bucket is\nset to 1 with the rest remaining 0. For instance, if a patient has a heart\nrate lab measurement of 93 bpm on their seventh visit, the seventh of\nthe new heart rate variables would be 1 and the rest would remain 0. If\nthere was no such lab measurement in the visit, they would all be 0.\nThese new binary variables are added to the wider code vocabu-\nlary C and treated in the same way as all of the other medical codes in\nthe vocabulary by ourHALO model during learning and generation.\nAfter generation, the speciﬁc lab values and inter-visit gaps are con-\nverted back into a continuous value by uniformly sampling from the\ncorresponding bucket range at the very end.\nThis discretization allows us to maintain the same powerful and\nprobabilistic modeling process, matching the probabilistic variance of\nreal continuous values in the same way we match the variance of\nmedical code presences. However, by building appropriately granular\nbuckets, we can avoid losing meaningful information and maintain a\nfull representation of a patient. We explore the performance of this\napproach further in our experiments.\nReporting summary\nFurther information on research design is available in the Nature\nPortfolio Reporting Summary linked to this article.\nData availability\nThe MIMIC-III inpatient EHR dataset25 that we use is publicly available\na n dm a yb ed o w n l o a d e da n du s e df r e e l ya f t e rp e r f o r m i n gt r a i n i n ga n d\napplying on physionet.org. Furthermore, we also released the syn-\nthetic data for each of our compared methods for both the inpatient\nand outpatient datasets at https://ﬁgshare.com/articles/dataset/\nHALO_Synthetic_Data/23811162. These datasets can then be used to\nreproduce the results and data statistics.\nCode availability\nWe make our code for the inpatient dataset experiments, including\ndataset construction, modeling building, training, and evaluation,\navailable at https://github.com/btheodorou99/HALO_Inpatient\n46.\nBetween this and the public availability of that dataset, all inpatient\nresults can be fully reproduced. Furthermore,HALO is also included in\nthe open-source machine learning package for healthcare PyHealth47,\nwhere it is available for easy use in concert with various machine\nlearning tasks.\nReferences\n1. Choi, E., Bahadori, M. T., Song, L., Stewart, W. F. & Sun, J. Gram:\ngraph-based attention model for healthcare representation learn-\ning. InProc. 23rd ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining.7 8 7– 795 (ACM, 2017).\n2 . C h o i ,E .e ta l .R E T A I N :A nI n t e r p r e t a b l eP r e d i c t i v eM o d e lf o r\nHealthcare using Reverse Time Attention Mechanism.Adv. Neural\nInf. Process. Syst. 29,3 5 0 4– 3512 (2016).\n3 . F a r r a r ,C .R .&W o r d e n ,K .Structural Health Monitoring: A Machine\nLearning Perspective(John Wiley & Sons, 2012).\n4 . D u g g a l ,R . ,F r e i t a s ,S . ,X i a o ,C . ,C h a u ,D .H .&S u n ,J .R e s t :r o b u s ta n d\nefﬁcient neural networks for sleep monitoring in the wild. InPro-\nceedings of The Web Conference 2020.1 7 0 4– 1714 (ACM, 2020).\n5. Fu, T., Hoang, T. N., Xiao, C. & Sun, J. Ddl: Deep dictionary\nlearning for predictive phenotyping. InProceedings of the Twenty-\nEighth International Joint Conference on Artiﬁcial Intelligence.\n(ed. Kraus, S.) 5857– 5863 (International Joint Conferences on\nArtiﬁcial Intelligence Organization, 2019).\n6. Che, Z. & Liu, Y. Deep learning solutions to computational pheno-\ntyping in health care. In2017 IEEE International Conference on Data\nMining Workshops (ICDMW). 1100– 1109 (2017).\n7. Shang, J., Xiao, C., Ma, T., Li, H. & Sun, J. Gamenet: Graph aug-\nmented memory networks for recommending medication\ncombination. InProc. AAAI Conference on Artiﬁcial Intelligence. 33,\n1126– 1133 (AAAI, 2019).\n8. Wang, L., Zhang, W., He, X. & Zha, H. Supervised reinforcement\nlearning with recurrent neuralnetwork for dynamic treatment\nrecommendation. InProc. 24th ACM SIGKDD International Con-\nference On Knowledge Discovery & Data Mining. 2447– 2456\n(ACM, 2018).\n9. Shang, J., Ma, T., Xiao, C. & Sun, J. Pre-training of graph augmented\ntransformers for medication recommendation. InProceedings of\nthe Twenty-Eighth International Joint Conference on Artiﬁcial Intel-\nligence. (ed. Kraus, S.) 5953– 5959 (International Joint Conferences\non Artiﬁcial Intelligence Organization, 2019).\n10. Neamatullah, I. et al. Automated de-identiﬁcation of free-text\nmedical records.BMC Med. Inform. Decision Mak.8,1 – 17 (2008).\n11. Kushida, C. A. et al. Strategies for de-identiﬁcation and anonymi-\nzation of electronic health record data for use in multicenter\nresearch studies.Med. Care50, S82 (2012).\n12. El Emam, K. et al. The re-identiﬁcation risk of Canadians from\nlongitudinal demographics.BMC Med. Inform. Decision Mak.11,\n1– 12 (2011).\n13. Benitez, K. & Malin, B. Evaluating re-identiﬁcation risks with respect\nto the HIPAA privacy rule.J. Am. Med. Inform. Assoc.17,\n169– 177 (2010).\n1 4 . E lE m a m ,K . ,J o n k e r ,E . ,A r b u c k l e ,L .&M a l i n ,B .As y s t e m a t i cr e v i e wo f\nre-identiﬁcation attacks on health data.PLoS ONE6, e28071 (2011).\n15. Zhang, Z., Yan, C., Lasko, T. A., Sun, J. & Malin, B. A. Synteg: a\nframework for temporal structured electronic health data simula-\ntion. J. Am. Med. Inform. Assoc.28,5 9 6– 604 (2021).\n16. Biswal, S. et al. Eva: Generating longitudinal electronic health\nrecords using conditional variational autoencoders. InMachine\nLearning for Healthcare Conference.149,2 6 0– 282 (PMLR, 2021).\n17. Tor ﬁ, A. & Fox, E. A. Corgan: Correlation-capturing convolutional\ngenerative adversarial networks forgenerating synthetic healthcare\nrecords. InProc. 33rd International Flairs Conference(2020).\n18. Cui, L. et al. Conan: complementary pattern augmentation for rare\ndisease detection. InProc. AAAI Conference on Artiﬁcial Intelli-\ngence. 34,6 1 4– 621 (AAAI, 2020).\n19. Choi, E. et al. Generating multi-label discrete patient records using\ngenerative adversarial networks. InMachine Learning for Healthcare\nConference.68,2 8 6– 305 (PMLR, 2017).\n20. Baowaly, M. K., Lin, C.-C., Liu, C.-L. & Chen, K.-T. Synthesizing\nelectronic health records using improved generative adversarial\nnetworks.J .A m .M e d .I n f o r m .A s s o c .26, 228– 241 (2019).\n21. Li, J. et al. Generating synthetic mixed-type longitudinal electronic\nhealth records for artiﬁcial intelligent applications.npj Digit. Med.6,\n98 (2023).\n2 2 . Z h a n g ,Z . ,Y a n ,C . ,M e s a ,D .A . ,S u n ,J .&M a l i n ,B .A .E n s u r i n ge l e c -\ntronic medical record simulation through better training, modeling,\nand evaluation.J .A m .M e d .I n f o r m .A s s o c .27,9 9– 108 (2020).\n2 3 . Y a n ,C . ,Z h a n g ,Z . ,N y e m b a ,S .&M a l i n ,B .A .G e n e r a t i n ge l e c t r o n i c\nhealth records with multiple data types and constraints.In Proc.\n2020 AMIA Annu. Symp. 1335–\n1344 (American Medical Informatics\nAssociation, 2020).\n24. Rashidian, S. et al. Smooth-gan: towards sharp and smooth syn-\nthetic EHR data generation. InInternational Conference on Artiﬁcial\nIntelligence in Medicine. 18,3 7– 48 (Springer International Publish-\ning, 2020).\n25. Johnson, A. E. et al. Mimic-iii, a freely accessible critical care data-\nbase. Sci. Data3,1 – 9( 2 0 1 6 ) .\n26. Radford, A., Narasimhan, K., Salimans, T. & Sutskever, I. Improving\nlanguage understanding by generative pre-training.https://openai.\ncom/research/language-unsupervised(2018).\n27. Harutyunyan, H., Khachatrian, H., Kale, D. C., Ver Steeg, G. &\nGalstyan, A. Multitask learning and benchmarking with clinical time\nseries data.Sci. Data6, 96 (2019).\nArticle https://doi.org/10.1038/s41467-023-41093-0\nNature Communications|         (2023) 14:5305 12\n28. Paszke, A. et al. Pytorch: an imperative style, high-performance\ndeep learning library. InAdvances in Neural Information Processing\nSystems.32,8 0 2 4– 8035 (Curran Associates, Inc., 2019).\n29. Radford, A. et al. Language models are unsupervised multitask\nlearners.OpenAI blog1, 9 (2019).\n30. Lee, S. H. Natural language generation for electronic health\nrecords.NPJ Digit. Med.1,6 3( 2 0 1 8 ) .\n31. Borton, J. et al. Data entrepreneurs’ synthetic puf: A working puf as\nan alternative to traditional synthetic and non-synthetic pufs. InJSM\nProceedings, Survey Research Methods Section(2010).\n32. Yan, C. et al. A multifaceted benchmarking of synthetic electronic\nhealth record generation models.Nat. Commun.13, 7609 (2022).\n33. Yale, A. et al. Generation and evaluation of privacy preserving\nsynthetic health data.Neurocomputing416,2 4 4– 255 (2020).\n34. Walonoski, J. et al. Synthea: an approach, method, and software\nmechanism for generating synthetic patients and the synthetic\nelectronic health care record.J. Am. Med. Inform. Assoc.25,\n230– 238 (2018).\n35. Tucker, A., Wang, Z., Rotalinti, Y. & Myles, P. Generating high-ﬁdelity\nsynthetic patient data for assessing machine learning healthcare\nsoftware.NPJ Digit. Med.3,1 – 13 (2020).\n36. Kartoun, U. Advancing informatics with electronic medical records\nbots (emrbots).Softw. Impacts2, 100006 (2019).\n37. Foraker, R. et al. Analyses of original and computationally-derived\nelectronic health record data: The national covid cohort colla-\nborative.J. Med. Internet Res.(2021).\n38. Philippidis, A. Synthetic data for a real pandemic: Syntegra applying\nm a c h i n el e a r n i n g - b a s e de n g i n et oc r e a t er e p l i c ao fN I H’s national\ncovid cohort collaborative (n3c) dataset.GEN Edge3,4 2– 47 (2021).\n39. Goodfellow, I. et al. Generative adversarial nets.Adv. Neural Inf.\nProcess. Syst.27,2 6 7 2– 2680 (2014).\n40. Sun, S. et al. Generating longitudinal synthetic ehr data with\nrecurrent autoencoders and generative adversarial networks. In\nHeterogeneous Data Management, Polystores, and Analytics for\nHealthcare. 12921,1 5 3– 165 (Springer, 2021).\n41. Ma, F., Wang, Y., Gao, J., Xiao, H. & Zhou, J. Rare disease prediction\nby generating quality-assured electronic health records. InProc.\n2020 SIAM International Conference on Data Mining.5 1 4– 522\n(SIAM, 2020).\n42. Vaswani, A. et al. Attention is all you need. InAdvances in Neural\nInformation Processing Systems. 5998\n– 6008 (NIPS, 2017).\n43. Kenton, J. D. M.-W. C. & Toutanova, L. K. BERT: pre-training of deep\nbidirectional transformers for language understanding. InPro-\nceedings of the 2019 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Human Language\nTechnologies(eds Burstein, J., Doran, C. & Solorio, T.) 4171– 4186\n(Association for Computational Linguistics, 2019).\n44. Brown, T. et al. Language models are few-shot learners.Adv. Neural\nInf. Process. Syst.33,1 8 7 7– 1901 (2020).\n45. Guha, S., Koudas, N. & Shim, K. Approximation and streaming\nalgorithms for histogram construction problems.ACM Trans.\nDatabase Syst.31,3 9 6– 438 (2006).\n46. btheodorou99. btheodorou99/halo_inpatient:ﬁrst releasehttps://\ndoi.org/10.5281/zenodo.8041405(2023).\n47. Yang, C., Wu, Z., Jiang, P., Lin, Z. & Sun, J. PyHealth: a deep learning\ntoolkit for healthcarepredictive modeling.https://github.com/\nsunlabuiuc/PyHealth(2022).\nAuthor contributions\nB.T. and J.S. proposed the method, B.T. and conducted all the experi-\nments, B.T., C.X., and J.S. wrote the manuscript.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s41467-023-41093-0.\nCorrespondenceand requests for materials should be addressed to\nJimeng Sun.\nPeer review informationNature Communicationsthanks the anon-\nymous reviewer(s) for their contribution to the peer review of this work. A\npeer reviewﬁle is available.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to jur-\nisdictional claims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indicate if\nchanges were made. The images or other third party material in this\narticle are included in the article’s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this licence, visithttp://creativecommons.org/\nlicenses/by/4.0/.\n© The Author(s) 2023, corrected publication 2023\nArticle https://doi.org/10.1038/s41467-023-41093-0\nNature Communications|         (2023) 14:5305 13"
}