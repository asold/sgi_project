{
  "title": "Feasibility of large language models for assessing and coaching surgeons’ non-technical skills",
  "url": "https://openalex.org/W4412420988",
  "year": 2025,
  "authors": [
    {
      "id": null,
      "name": "Obuseh, Marian",
      "affiliations": [
        "Purdue University West Lafayette"
      ]
    },
    {
      "id": "https://openalex.org/A5108998572",
      "name": "Singh SNEHA",
      "affiliations": [
        "Indian Institute of Technology Bombay"
      ]
    },
    {
      "id": null,
      "name": "Anton, Nicholas E.",
      "affiliations": [
        "Indiana University – Purdue University Indianapolis"
      ]
    },
    {
      "id": null,
      "name": "Gardiner, Robin",
      "affiliations": [
        "Indiana University – Purdue University Indianapolis"
      ]
    },
    {
      "id": "https://openalex.org/A3042081376",
      "name": "Stefanidis Dimitrios",
      "affiliations": [
        "Indiana University – Purdue University Indianapolis"
      ]
    },
    {
      "id": null,
      "name": "Yu, Denny",
      "affiliations": [
        "Purdue University West Lafayette"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4391855109",
    "https://openalex.org/W4400055800",
    "https://openalex.org/W4390535718",
    "https://openalex.org/W4205897661",
    "https://openalex.org/W2808020574",
    "https://openalex.org/W4392664000",
    "https://openalex.org/W4240387119",
    "https://openalex.org/W2148606079",
    "https://openalex.org/W4281481746",
    "https://openalex.org/W3196976988",
    "https://openalex.org/W4404180781",
    "https://openalex.org/W2061416046",
    "https://openalex.org/W2123872280",
    "https://openalex.org/W3185341429",
    "https://openalex.org/W4221143046"
  ],
  "abstract": null,
  "full_text": "npj |health systems Brief communication\nhttps://doi.org/10.1038/s44401-025-00027-2\nFeasibility of large language models for\nassessing and coaching surgeons’\nnon-technical skills\nCheck for updates\nMarian Obuseh1 , Sneha Singh2, Nicholas E. Anton3, Robin Gardiner3, Dimitrios Stefanidis3 &D e n n yY u1\nThis study demonstrates Large Language models (LLMs) to assess and coach surgeons on their non-\ntechnical skills, traditionally evaluated through subjective and resource-intensive methods. Llama 3.1\nand Mistral effectively analyzed robotic-assisted surgery transcripts, identiﬁed exemplar and non-\nexemplar behaviors, and autonomously generated structured coaching feedback to guide surgeons’\nimprovement. Ourﬁndings highlight the potential of LLMs as scalable, data-driven tools for enhancing\nsurgical education and supporting consistent coaching practices.\nLarge language models (LLMs) have demonstrated strong performance in\ngeneral natural language processing(NLP) tasks across various domains1.I n\nhealthcare, studies have shown promising results particularly in medical\ndiagnostic support and clinical decision-making2,3. For example, GPT-4\nachieved a diagnostic accuracy of 61.1% in its top six differential diagnoses for\npreviously unpublished challenging clinical cases, surpassing the 49.1% accu-\nracy of physicians\n2. Similarly, a Llama-based model achieved 52% accuracy in\nassigning diagnosis-related groups for hospitalized patients using clinical\nnotes3. These advancements highlight the potential of LLMs in specialized\nhealthcare applications, including skill assessment and training of healthcare\nprofessionals. While substantial work has focused on assessing and training\nsurgeons’ technical skills\n4,5, there is less emphasis on non-technical skills\n(NTS)6. However, these NTS are critical cognitive, social, and interpersonal\nabilities that are directly linked to adverse events and patient safety outcomes7.\nAssessing NTS presents unique challenges due to their primary\nexpression through verbal communication8, which can be dynamic,\nnuanced, context-dependent, and susceptible to interpretation bias. This\nvariability introduces subjectivity into assessments, as observers may\ninterpret the same behaviors differently. Traditional observational assess-\nments are prone to these inconsistencies that can compromise subsequent\ntraining efforts. They are also resource-intensive, requiring signiﬁcant time\nand effort not only to train the raters but also for the raters to conduct the\nassessments for long surgeries\n9,10. Dyadic NTS coaching approaches, while\nbeneﬁcial, demand specialized non-surgeon coaching staff who can focus\nless on technical skills and are also very time-intensive11,12. Given these\nchallenges, there is a clear need for more objective, efﬁcient, and scalable\nmethods to assess NTS, ensuring consistent, high-quality training that\nenhances patient outcomes andstrengthens team dynamics.\nNLP offers a promising solution to these challenges since NTS are\nmostly demonstrated through verbal communication. In this study, we\nexplore the feasibility of LLMs for surgeons’NTS assessment and coaching.\nSpeciﬁcally, we hypothesize that LLMs can differentiate between exemplar\nand non-exemplar NTS behaviors and provide actionable performance\ncoaching feedback to surgeons, supporting scalable and effective surgical\neducation.\nModel performance\nTable 1 presents the performance of LLMs and benchmarking machine\nlearning (ML) models in categorizing NTS behaviors. Overall, LLMs\ndemonstrated higher performance than classical ML models. Llama 3.1\nachieved a macro-averaged F1 score of 0.62 and a prediction accuracy of\n74%, while Mistral showed comparable performance with a macro-averaged\nF1 score of 0.61 and a prediction accuracy of 75%. In comparison, the\nclassical ML models including logistic regression (LR) and support vector\nmachines (SVM), demonstrated lower overall performance. Although their\nprediction accuracy (LR = 74%, SVM = 71%) was comparable to LLMs,\ntheir macro-averaged F1 scores were signiﬁcantly lower (LR = 0.52,\nSVM = 0.51), highlighting their limitations in balancing precision and recall\nacross NTS behaviors.\nFor exemplar NTS behaviors, both LLMs and classical ML models\nperformed excellently, with macro-averaged F1 scores of 0.84 and 0.85\nrespectively. This indicates that both model types were effective in identi-\nfying well-deﬁned, positive behaviors exhibited by surgeons. For non-\nexemplar behaviors, which are morechallenging to identify, Llama 3.1\nachieved a macro-averaged F1 score of 0.41, outperforming LR and SVM,\nboth of which had F1 scores below 0.20. Mistral also performed better than\nthe classical models with an F1 score of0.37. These results show that while\nclassical ML models maintained comparable performance for exemplar\nbehaviors, LLMs provided improved accuracy and F1 scores for non-\nexemplar behavior identiﬁcation.\n1Edwardson School of Industrial Engineering, Purdue University, West Lafayette, IN, USA.2Koita Centre for Digital Health, Indian Institute of Technology,\nBombay, India.3School of Medicine, Indiana University, Indianapolis, IN, USA.e-mail: mobuseh@purdue.edu\nnpj Health Systems|            (2025) 2:25 1\n1234567890():,;\n1234567890():,;\nFigure 1 compares the traditional manual NTS assessment pipeline\nwith the proposed LLM-based automation approach using an example of a\nmissed communication opportunity in the operating room due to the lack of\na vocative address. In the manual approach12, multiple human expert raters,\nincluding a coach, independently assess the surgeon’sN T Sb e h a v i o r su s i n g\nthe Non-Technical Skills for Surgeons(NOTSS) tool. After completing the\nindividual assessments, they engagein group discussions to reach a con-\nsensus on the assessment. The coach then provides dyadic coaching feed-\nback to the surgeon, speciﬁcally targeting improvements to address the\nidentiﬁed communication breakdown. This multi-step process is resource-\nintensive, requiring substantial time for individual assessments, consensus-\nbuilding, and personalized coaching.\nIn contrast, the LLM automation pipeline directly processes surgical\ntranscripts throughﬁne-tuned models to assess NTS behaviors and generate\ncoaching-style feedback. Both Llama 3.1 and Mistral identiﬁed the same\nnon-exemplar behavior in the example scenario. Llama 3.1 highlighted\npotential confusion due to the lack of a vocative address, while Mistral\noffered speciﬁc suggestions for clearer communication. Additional exam-\nples of exemplar and non-exemplar classiﬁcations can be found in Sup-\nplementary Table S1. These resultsdemonstrate that LLMs can automate\nNTS coaching, providing consistent, context-speciﬁc feedback that aligns\nwith human coaches while offering a more efﬁcient and scalable alternative\nto manual methods.\nImplications\nThis study demonstrated the feasibility of LLMs for NTS assessment and\ncoaching in surgeries, addressing key limitations of traditional methods.\nOur results showed that LLMs outperformed ML models despite being\ntrained on signiﬁcantly smaller datasets. Differences in data handling stra-\ntegies should be considered when interpreting classiﬁcation performance\ncomparisons. Although balanced training data were used in both cases to\nmitigate class imbalance effects, the underlying training mechanisms\ndiffered.\nLLM performance was likely constrained by limited context windows,\nwhich restricted the amount of contextual information that could be pro-\ncessed during training\n13. In particular, the shorter context window of Mistral\nlimited the size of the training set. While this enabled consistent evaluation\nacross LLMs and a focus on developing highly targeted prompts, it may\nreduce generalizability. This limitation should be revisited as LLMs advance.\nAdditionally, the underrepresentation of non-exemplar behaviors in the\ndataset likely contributed to lower performance in this category. In this\nstudy, fewer than 17% of observed behaviors were non-exemplar, aligning\nwith prior research indicating that while these behaviors are less frequent,\nthey are not uncommon\n14. Ongoing research is focused on enhancing model\nadaptability through optimizedﬁne-tuning strategies and dataset expan-\nsion, particularly by increasing non-exemplar cases to improve class\nbalance.\nDespite not being explicitly trained on human coaching feedback,\nLLMs demonstrated the ability to generate performance-based feedback\nfor surgeons, offering a scalable alternative to traditional dyadic human\ncoaching, which is often limited by human availability and variability.\nThis scalability could democratize access to high-quality NTS training,\nbeneﬁting a wide range of surgical teams, including those in resource-\nlimited settings. The ability to better identify non-exemplar behaviors,\nwhere coaching is most needed, combined with the generation of\nstructured, context-speciﬁc feedback, makes LLMs preferable in this\nsetting.\nThis study focused on transcript-based, ofﬂine analysis that lays\ncritical groundwork for future efforts by (1) establishing a reproducible\npipeline for building large-scale datasets from real intraoperative\nconversations, (2) demonstrating the advantages of LLMs over tradi-\ntional ML models in capturing the nuance of verbal behaviors during\nRAS, (3) reﬁning prompt engineering strategies to handle domain-\nspeciﬁc language and achieve high performance on NTS performance\nclassiﬁcation and coaching feedback tasks, and (4) producing a trained\nLLM-based model that can be further expanded, reﬁned, validated, and\nadapted. Early-stage large-scale human evaluation of LLM-generated\nfeedback will be a formal part of the system design, with expert review\nhelping to shape model reﬁnement. Initial feedback efforts will focus on\nacceptability, perceived usefulness, trust, and integration into training\nworkﬂows. A full usability study will be necessary before deployment to\nsystematically evaluate acceptability, trust, perceived usefulness, and\nworkﬂow integration in clinical environments. Practical implementa-\ntion will require addressing barriers such as generalizability across\nspecialties and institutions, align ment with clinical education stan-\ndards, andﬁdelity to the dynamic context of live procedures. It will be\nessential to address concerns around accountability, reliability, privacy,\nand the secure handling of clinicaldata to prevent misuse of sensitive\ninformation. Additionally, we recognize that LLMs operate as black-\nbox systems, which presents challenges for interpretability and adop-\ntion. A human-in-the-loop approach will therefore remain essential\nthroughout the design, development, deployment, and post-\ndeployment monitoring phases. While automation reduces the over-\nall burden compared to traditional dyadic coaching, expert oversight by\nsurgical educators or system sta keholders will remain essential to\nensure accountability. Together, these efforts aim to enable scalable,\ntargeted, and high-ﬁdelity NTS coaching whileestablishing a clearer\npathway toward integrating LLM-b ased feedback mechanisms into\nsurgical education programs.\nMethods\nParticipants\nThis study was approved by Indiana University’s Institutional Review\nBoard (protocol 1702481748; approved: March 2023). No race, ethni-\ncity, or patient-identiﬁable data was collected. Between 2023 and 2024,\nnine surgeons (4 women [44%]) from six surgical subspecialties across\nthree hospitals in Indiana University Health system, all performing at\nleast one robotic-assisted surgery (RAS) per month, were recruited.\nThey provided informed consent, and twenty RAS were observed and\nrecorded in the operating room, with each surgeon contributing\n1– 3c a s e s .\nTable 1 | Overall and class performance on test data for each\nmodel category\nOverall performance on test data for each model category\nModel\ncategory\nModel\nname\nPerformance metrics\nAccuracy Precision Recall F1 Score\nClassical ML LR 0.74 0.55 0.71 0.52\nSVM 0.71 0.55 0.73 0.51\nLLM Llama 3.1 0.74 0.61 0.66 0.62\nMistral 0.75 0.60 0.63 0.61\nClass performance on test data for each model category\nModel\ncategory\nModel\nname\nNTS\nperformance\nrating\nPerformance metrics\nPrecision Recall F1 Score\nClassical ML LR Exemplar 0.98 0.75 0.85\nSVM 0.98 0.71 0.83\nLLM Llama 3.1 0.90 0.78 0.84\nMistral 0.88 0.81 0.84\nClassical ML LR Non-exemplar 0.11 0.67 0.19\nSVM 0.11 0.75 0.19\nLLM Llama 3.1 0.33 0.54 0.41\nMistral 0.32 0.45 0.37\nF1 scores (harmonic mean of precision and recall) regarded as most important metric.\nLLM large language model,ML machine learning,LR linear regression,SVM support vector\nmachine, NTS non-technical skills.\nhttps://doi.org/10.1038/s44401-025-00027-2 Brief communication\nnpj Health Systems|            (2025) 2:25 2\nData\nHuman expert raters watched the RASrecordings and used the validated\nNOTSS15 tool to identify operating room interactions that challenged the\nsurgeons’ NTS. Surgeons’ performance was classiﬁed as exemplar (rat-\ning = 4) or non-exemplar (rating < 4). This classiﬁcation approach aligns\nwith prior research distinguishing behaviors meeting the highest standard\nfrom those requiring improvement\n9. The raters identiﬁed 709 NTS events,\nwith 590 categorized as exemplar behaviors and 119 as non-exemplar.\nTranscripts of these interactions constitutes the dataset.\nL a r g el a n g u a g em o d e l s\nThis study used publicly released state-of-the-art models, including Meta’s\nLlama-3.1-8B-Instruct16 (open-weight, under a custom non-commercial\nlicense) and Mistral AI’s Mistral-7B-Instruct-v0.317 (open-weight and open-\nFig. 1 | Comparative workﬂow for current gold standard versus LLM-based approach for NTS assessment and coaching for a surgical event.Classical ML are excluded,\nas they do not support natural language generation.\nhttps://doi.org/10.1038/s44401-025-00027-2 Brief communication\nnpj Health Systems|            (2025) 2:25 3\nsource under Apache 2.0), both accessed via Hugging Face. All experiments\nwere conducted using Google Colab Pro+, which provided cloud-based\naccess to a single A100 GPU. The only cost incurred was the Colab Pro+\nsubscription, which offered sufﬁcient compute capacity for prompt engi-\nneering, model inference, and performance evaluation. These models were\nchosen for their strong performance, computational efﬁciency, and acces-\nsibility, which enable execution within controlled research environments\nwithout reliance on proprietary API services. This supports reproducibility,\ntransparency, and privacy, which are key considerations for clinical\nresearch.\nWhile Llama 3.1 supports a context window of up to 128 K\ntokens\n16, our experiments were constrained by Mistral ’ss h o r t e r\ncontext window of approximately 32 K tokens 17. This limitation\nnecessitated a focus on developin g highly targeted prompts rather\nthan increasing the size of the training dataset. A stratiﬁed sampling\nstrategy was used to construct the training dataset. One exemplar and\none non-exemplar data point were randomly sampled from each of the\nfour NOTSS categories, resulting in eight data points (~1% of data),\ncovering all combinations of NTS performance level and construct.\nThe same training data (n = 4 exemplar class andn = 8 non-exemplar\nclass) was used for both LLMs.\nPrompt design targeted both classiﬁcation of NTS performance\nand generation of coaching feedback. For both models, the generation\nparameters were as follows: max_new_tokens = 512 (prevents overly\nlong coaching feedback), temperature = 0.005 (makes the output con-\nsistent across runs), topp = 0.001 (restricts choices to only the most\nlikely words), topk = 20 (adds a cutoff to avoid unusual or irrelevant\nwords), and do sample = True (to retain some natural language varia-\nbility). Importantly, the models were not trained on any human\ncoaching feedback. Instead, they were prompted to generate feedback\nsolely from the transcripts of surgeon interactions in the operating\nroom, ensuring that feedback generation was independent of expert\ncoaching examples.\nTo evaluate model performance withminimal instruction, an initial\nprompt was executed and outputs were manually reviewed to identify failure\npatterns. Prompts were subsequently reﬁned iteratively using evidence-\nbased strategies, including role prompting (e.g.,“You are an experienced\nnon-technical skills coach”), clear section delimitation, and zero-shot chain-\nof-thought prompting (e.g.,“Think step-by-step”)\n18,19.R eﬁnement con-\ntinued until both models achieved perfect (100%) classiﬁcation and feed-\nback generation performance on the training data. Theﬁnal prompts can be\nfound in the Supplementary Information. Model performance was eval-\nuated on the full test dataset (n = 701; 115 non-exemplar) using classiﬁca-\ntion metrics including accuracy, precision, recall, and macro-averaged\nF1 scores.\nClassical machine learning models\nClassical ML models (Linear Regression and Support Vector Machine) were\nused as benchmarks for evaluating LLM performance. To address class\nimbalance, the majority class (exemplar) was under-sampled to 80% of the\nminority class20, creating a balanced training dataset (n = 190; 95 non-\nexemplar). The models were trained on Term Frequency-Inverse Docu-\nment Frequency (TF-IDF) vectorized unigrams of the balanced training\ndata. Model performance was then evaluated on a held-out test dataset\n(n = 519; 24 non-exemplar) using the metrics as the LLMs.\nData availability\nDue to Indiana University ethics policyand to protect participants privacy,\nthe data used in this study cannot be publicly shared. However, sample de-\nidentiﬁed datapoints are provided in the Supplementary Information.\nCode availability\nDue to Indiana University ethics policyand to protect participants privacy,\nthe full codes used in this study cannot be publicly shared. However, partial\nmodel prompts are provided in the Supplementary Information.\nR e c e i v e d :2 7F e b r u a r y2 0 2 5 ;A c c e p t e d :2 4M a y2 0 2 5 ;\nReferences\n1. Raiaan, M. A. K. et al. A review on large language models:\narchitectures, applications, taxonomies, open issues and challenges.\nIEEE Access12, 26839– 26874 (2024).\n2. Rutledge, G. W. Diagnostic accuracy of GPT-4 on common clinical\nscenarios and challenging cases.Learn Health Syst8, e10438 (2024).\n3. Wang, H., Gao, C., Dantona, C., Hull, B. & Sun, J. DRG-LLaMA: tuning\nLLaMA model to predict diagnosis-related group for hospitalized\npatients. npj Digital Med.7,1 – 9 (2024).\n4. Lam, K. et al. Machine learning for technical skill assessment in\nsurgery: a systematic review.npj Digital Med.5,1 – 16 (2022).\n5. Bjerrum, F., Thomsen, A. S. S., Nayahangan, L. J. & Konge, L. Surgical\nsimulation: current practices and future perspectives for technical\nskills training.Med. Teach.40, 668– 675 (2018).\n6. Mahendran, V., Turpin, L., Boal, M. & Francis, N. K. Assessment and\napplication of non-technical skills in robotic-assisted surgery: a\nsystematic review.Surg. Endosc38, 1758– 1774 (2024).\n7. Flin, R. & O’Connor, P.Safety at the sharp end. safety at the sharp end,\nhttps://doi.org/10.1201/9781315607467 (CRC Press, 2017).\n8. Yule, S., Flin, R., Paterson-Brown, S., Maran, N. & Rowley, D.\nDevelopment of a rating system for surgeons’ non-technical skills.\nMed. Educ.40, 1098– 1104 (2006).\n9. Cha, J. S. et al. Objective nontechnical skills measurement using\nsensor-based behavior metrics in surgical teams.Hum. Factors,\nhttps://doi.org/10.1177/00187208221101292 (2022).\n10. Cha, J. S. & Yu, D. Objective measures of surgeon nontechnical skills\nin surgery: a scoping review.Hum. Factors00, 18720821995319\n(2021).\n11. Granchi, N. et al. Coaching to enhance qualiﬁed surgeons’ non-\ntechnical skills: a systematic review.Brit. J. Surg.108, 1154– 1161\n(2021).\n12. Obuseh, M. et al. Development and application of a non- technical\nskills coaching intervention framework for surgeons: a pilot quality\nimprovement initiative.PLoS One19,1 – 14 (2024).\n13. Press, O., Smith, N. A. & Lewis, M. Train short, test long: attention with\nlinear biases enables input length extrapolation. In:ICLR 2022 - 10th\nInternational Conference on Learning Representations(ICLR, 2021).\n14. Yule, S., Flin, R., Paterson-Brown, S. & Maran, N. Non-technical skills\nfor surgeons in the operating room: a review of the literature.Surgery\n139, 140– 149 (2006).\n15. Yule, S. et al. Surgeons’\nnon-technical skills in the operating room:\nreliability testing of the NOTSS behavior rating system.World J. Surg.\n32, 548– 556 (2008).\n16. Dubey, A. et al. The Llama 3 herd of models. arXiv preprint\narXiv:2407.21783 (2024).\n17. Jiang, A. Q. et al. Mistral 7B. arXiv preprint arXiv:2310.06825 (2023).\n18. Liu, P. et al. Pre-train, prompt, and predict: a systematic survey of\nprompting methods in natural language processing.ACM Comput.\nSurv. 55,1 – 35 (2023).\n19. Wei, J. et al. Chain-of-thought prompting elicits reasoning in large\nlanguage models.Adv. Neural Inf. Process Syst. 35, 24824– 24837\n(2022).\n20. Van Hulse, J., Khoshgoftaar, T. M. & Napolitano, A. Experimental\nperspectives on learning from imbalanced data.ACM Int. Conf. Proc.\nSer. 227, 935– 942 (2007).\nAcknowledgements\nThis study was funded by the Agency for Healthcare Research and Quality\n(AHRQ) (Grant number: R01HS028026). This study was also made possible\nby Indiana University Health and The Advances In Medicine (AIM) grant\nprovided by Cook Medical. Administratively, it was supported by the Indiana\nClinical and Translational Sciences Institute, funded in part by grant\nhttps://doi.org/10.1038/s44401-025-00027-2 Brief communication\nnpj Health Systems|            (2025) 2:25 4\n#UM1TR004402 from the National Institutes of Health, National Center for\nAdvancing Translational Sciences, and Clinical and Translational Sciences\nAward. The content is solely the responsibility of the authors and does not\nnecessarily represent the ofﬁcial views of AHRQ, Indiana University Health,\nCook Medical, or the National Institutes of Health. The authors also\nacknowledge the data cleaning efforts of Maheen Syed, Raunak\nChakrabarty, and Dan-Ha Le.\nAuthor contributions\nConcept and design: M.O. Acquisition, analysis or interpretation of data:\nM.O., S.S., N.A., R.G. Model training and evaluation: M.O., S.S. Drafting of\nthe manuscript: M.O. Critical review of analysis: D.Y. Critical review of\nmanuscript: D.S., D.Y. Project supervision: D.S., D.Y. All authors read and\napproved theﬁnal version of the manuscript.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s44401-025-00027-2\n.\nCorrespondenceand requests for materials should be addressed to\nMarian Obuseh.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to jurisdictional\nclaims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long\nas you give appropriate credit to the original author(s) and the source,\nprovide a link to the Creative Commons licence, and indicate if changes\nwere made. The images or other third party material in this article are\nincluded in the article’s Creative Commons licence, unless indicated\notherwise in a credit line to the material. If material is not included in the\narticle’s Creative Commons licence and your intended use is not permitted\nby statutory regulation or exceeds the permitted use, you will need to\nobtain permission directly from the copyright holder. To view a copy of this\nlicence, visithttp://creativecommons.org/licenses/by/4.0/\n.\n© The Author(s) 2025\nhttps://doi.org/10.1038/s44401-025-00027-2 Brief communication\nnpj Health Systems|            (2025) 2:25 5",
  "topic": "Coaching",
  "concepts": [
    {
      "name": "Coaching",
      "score": 0.9360743761062622
    },
    {
      "name": "Resource (disambiguation)",
      "score": 0.58158278465271
    },
    {
      "name": "Medical education",
      "score": 0.48460420966148376
    },
    {
      "name": "Scalability",
      "score": 0.4663946330547333
    },
    {
      "name": "Psychology",
      "score": 0.4238497018814087
    },
    {
      "name": "Computer science",
      "score": 0.3995418846607208
    },
    {
      "name": "Medicine",
      "score": 0.28753936290740967
    },
    {
      "name": "Psychotherapist",
      "score": 0.08256477117538452
    },
    {
      "name": "Database",
      "score": 0.0
    },
    {
      "name": "Computer network",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I219193219",
      "name": "Purdue University West Lafayette",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I162827531",
      "name": "Indian Institute of Technology Bombay",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I55769427",
      "name": "Indiana University – Purdue University Indianapolis",
      "country": "US"
    }
  ]
}