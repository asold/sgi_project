{
  "title": "Enabling Early Health Care Intervention by Detecting Depression in Users of Web-Based Forums using Language Models: Longitudinal Analysis and Evaluation",
  "url": "https://openalex.org/W4360850261",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5010835445",
      "name": "David Owen",
      "affiliations": [
        "Cardiff University"
      ]
    },
    {
      "id": "https://openalex.org/A5046054327",
      "name": "Dimosthenis Antypas",
      "affiliations": [
        "Cardiff University"
      ]
    },
    {
      "id": "https://openalex.org/A5025487300",
      "name": "Athanasios Hassoulas",
      "affiliations": [
        "Cardiff University"
      ]
    },
    {
      "id": "https://openalex.org/A5032995667",
      "name": "Antonio F. Pardiñas",
      "affiliations": [
        "Cardiff University"
      ]
    },
    {
      "id": "https://openalex.org/A5002661723",
      "name": "Luis Espinosa-Anke",
      "affiliations": [
        "Cardiff University"
      ]
    },
    {
      "id": "https://openalex.org/A5086289154",
      "name": "José Camacho-Collados",
      "affiliations": [
        "Cardiff University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1897149844",
    "https://openalex.org/W2000594564",
    "https://openalex.org/W2297358007",
    "https://openalex.org/W2043693905",
    "https://openalex.org/W2119609580",
    "https://openalex.org/W2106686523",
    "https://openalex.org/W2927148761",
    "https://openalex.org/W4306173662",
    "https://openalex.org/W4223610593",
    "https://openalex.org/W2963261455",
    "https://openalex.org/W2805240699",
    "https://openalex.org/W3097146093",
    "https://openalex.org/W2897583329",
    "https://openalex.org/W3179564441",
    "https://openalex.org/W1989448978",
    "https://openalex.org/W2962848499",
    "https://openalex.org/W2156611669",
    "https://openalex.org/W2053455808",
    "https://openalex.org/W2313099882",
    "https://openalex.org/W2741216199",
    "https://openalex.org/W1980867644",
    "https://openalex.org/W1978394996",
    "https://openalex.org/W2060352284",
    "https://openalex.org/W2056189598",
    "https://openalex.org/W2517456239",
    "https://openalex.org/W2087347434",
    "https://openalex.org/W2953413710",
    "https://openalex.org/W2165612380",
    "https://openalex.org/W2151591509",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2149684865",
    "https://openalex.org/W2039741433",
    "https://openalex.org/W2128310653",
    "https://openalex.org/W2147879411",
    "https://openalex.org/W2972498556",
    "https://openalex.org/W2739681832",
    "https://openalex.org/W4236654575",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W3145434558",
    "https://openalex.org/W3002784191",
    "https://openalex.org/W4284694029",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W23809677",
    "https://openalex.org/W2773200982",
    "https://openalex.org/W2982495231",
    "https://openalex.org/W4200467880",
    "https://openalex.org/W3117866035",
    "https://openalex.org/W2099813784",
    "https://openalex.org/W3104186312",
    "https://openalex.org/W1951724000",
    "https://openalex.org/W2593643174",
    "https://openalex.org/W4242430932",
    "https://openalex.org/W2113671499",
    "https://openalex.org/W2224850994",
    "https://openalex.org/W172260869",
    "https://openalex.org/W2113669296",
    "https://openalex.org/W2402700",
    "https://openalex.org/W2108514834",
    "https://openalex.org/W2140910804",
    "https://openalex.org/W1964286403"
  ],
  "abstract": "Background Major depressive disorder is a common mental disorder affecting 5% of adults worldwide. Early contact with health care services is critical for achieving accurate diagnosis and improving patient outcomes. Key symptoms of major depressive disorder (depression hereafter) such as cognitive distortions are observed in verbal communication, which can also manifest in the structure of written language. Thus, the automatic analysis of text outputs may provide opportunities for early intervention in settings where written communication is rich and regular, such as social media and web-based forums. Objective The objective of this study was 2-fold. We sought to gauge the effectiveness of different machine learning approaches to identify users of the mass web-based forum Reddit, who eventually disclose a diagnosis of depression. We then aimed to determine whether the time between a forum post and a depression diagnosis date was a relevant factor in performing this detection. Methods A total of 2 Reddit data sets containing posts belonging to users with and without a history of depression diagnosis were obtained. The intersection of these data sets provided users with an estimated date of depression diagnosis. This derived data set was used as an input for several machine learning classifiers, including transformer-based language models (LMs). Results Bidirectional Encoder Representations from Transformers (BERT) and MentalBERT transformer-based LMs proved the most effective in distinguishing forum users with a known depression diagnosis from those without. They each obtained a mean F1-score of 0.64 across the experimental setups used for binary classification. The results also suggested that the final 12 to 16 weeks (about 3-4 months) of posts before a depressed user’s estimated diagnosis date are the most indicative of their illness, with data before that period not helping the models detect more accurately. Furthermore, in the 4- to 8-week period before the user’s estimated diagnosis date, their posts exhibited more negative sentiment than any other 4-week period in their post history. Conclusions Transformer-based LMs may be used on data from web-based social media forums to identify users at risk for psychiatric conditions such as depression. Language features picked up by these classifiers might predate depression onset by weeks to months, enabling proactive mental health care interventions to support those at risk for this condition.",
  "full_text": "Original Paper\nEnabling Early Health Care Intervention by Detecting Depression\nin Users of Web-Based Forums using Language Models:\nLongitudinal Analysis and Evaluation\nDavid Owen1, MSc; Dimosthenis Antypas1, MSc; Athanasios Hassoulas2, PhD; Antonio F Pardiñas3, PhD; Luis\nEspinosa-Anke1, PhD; Jose Camacho Collados1, PhD\n1School of Computer Science and Informatics, Cardiff University, Cardiff, United Kingdom\n2Centre for Medical Education, School of Medicine, Cardiff University, Cardiff, United Kingdom\n3Centre for Neuropsychiatric Genetics and Genomics, School of Medicine, Cardiff University, Cardiff, United Kingdom\nCorresponding Author:\nDavid Owen, MSc\nSchool of Computer Science and Informatics\nCardiff University\nAbacws\nSenghennydd Road\nCardiff, CF24 4AG\nUnited Kingdom\nPhone: 44 (0)29 2087 4812\nEmail: owendw1@cardiff.ac.uk\nAbstract\nBackground: Major depressive disorder is a common mental disorder affecting 5% of adults worldwide. Early contact with\nhealth care services is critical for achieving accurate diagnosis and improving patient outcomes. Key symptoms of major depressive\ndisorder (depression hereafter) such as cognitive distortions are observed in verbal communication, which can also manifest in\nthe structure of written language. Thus, the automatic analysis of text outputs may provide opportunities for early intervention\nin settings where written communication is rich and regular, such as social media and web-based forums.\nObjective: The objective of this study was 2-fold. We sought to gauge the effectiveness of different machine learning approaches\nto identify users of the mass web-based forum Reddit, who eventually disclose a diagnosis of depression. We then aimed to\ndetermine whether the time between a forum post and a depression diagnosis date was a relevant factor in performing this\ndetection.\nMethods: A total of 2 Reddit data sets containing posts belonging to users with and without a history of depression diagnosis\nwere obtained. The intersection of these data sets provided users with an estimated date of depression diagnosis. This derived\ndata set was used as an input for several machine learning classifiers, including transformer-based language models (LMs).\nResults: Bidirectional Encoder Representations from Transformers (BERT) and MentalBERT transformer-based LMs proved\nthe most effective in distinguishing forum users with a known depression diagnosis from those without. They each obtained a\nmean F1-score of 0.64 across the experimental setups used for binary classification. The results also suggested that the final 12\nto 16 weeks (about 3-4 months) of posts before a depressed user’s estimated diagnosis date are the most indicative of their illness,\nwith data before that period not helping the models detect more accurately. Furthermore, in the 4- to 8-week period before the\nuser’s estimated diagnosis date, their posts exhibited more negative sentiment than any other 4-week period in their post history.\nConclusions: Transformer-based LMs may be used on data from web-based social media forums to identify users at risk for\npsychiatric conditions such as depression. Language features picked up by these classifiers might predate depression onset by\nweeks to months, enabling proactive mental health care interventions to support those at risk for this condition.\n(JMIR AI 2023;2:e41205) doi: 10.2196/41205\nKEYWORDS\nmental health; depression; internet; natural language processing; transformers; language models; sentiment\nJMIR AI 2023 | vol. 2 | e41205 | p. 1https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nIntroduction\nBackground\nMajor depressive disorder (MDD) is one of the most prevalent\nmental illnesses worldwide, affecting nearly 5% of adults [1].\nDepressive episodes, which are symptoms of MDD and other\npsychiatric conditions, are even more common, with nearly\n30% of individuals developing them at least once in their\nlifetime [2]. The characteristics of MDD and depressive episodes\n(“depression” hereafter) include low mood, feelings of\nworthlessness or guilt, and recurrent thoughts of death [3]. Early\nintervention has been reported to significantly improve patient\noutcomes and reduce the financial burden on health care services\n[4]. However, the stigma associated with psychiatric conditions,\nsuch as depression, leads to patients underreporting to health\ncare services [5,6].\nGiven that a number of individuals who would normally meet\nthe criteria for depression underreport to health care services,\nconsideration should be given to how key symptoms may\nmanifest in written language on social media platforms [7].\nLonghand discussion websites such as Reddit are a rich source\nof such information where users may publish a series of posts\nspanning many months or years [8]. Natural language processing\n(NLP) can be used to identify features in posts that are predictive\nof a user who may have depression. Crucially, if affected users\nare identified before formal diagnosis, this may provide an\nopportunity for early health care intervention in these cases.\nIn this study, we derive a specialized subset of an annotated\ndata set that contains Reddit posts belonging to users who have\nreceived a diagnosis of depression. This subset allowed us to\nconsider posts before each user’s approximate diagnosis date.\nWe used state-of-the-art, domain-specific language models\n(LMs) to assist in the detection of depression. These LMs\noutperformed the baseline approaches in various experimental\nsettings. Notably, they are adept at early detection of depression.\nMoreover, through our model analysis, we provide an exhaustive\nanalysis of the temporal aspect related to preemptive detection,\nproviding insights into the time depression symptoms\nmaterialized before the diagnosis. Finally, we investigated the\nrole of sentiment in depressed users’ posts and provided a\nqualitative analysis based on the model performance.\nRelated Work\nThere is a growing body of literature on the use of NLP\ntechniques to analyze depression patterns on social media [9,10].\nYates et al [11] developed an approach to distinguish forum\nusers who self-reported a diagnosis of depression from those\nwho did not. It used a convolutional neural network to aggregate\nuser posts in a purpose-built data set, the Reddit Self-reported\nDepression Diagnosis (RSDD) data set. Their follow-up work\ninvolved the conception of a sister data set, RSDD-Time [12],\nwhich contained Reddit posts where users declared a past\ndiagnosis of depression, and this diagnosis was linked to an\nestimated date. Dates were inferred from explicit but often\nimprecise time expressions in user posts. However, these works\ndid not consider the preemptive detection of depression among\nReddit users in their data sets. That is, they did not consider\nmethods for detecting depression in users before their diagnoses.\nRecent NLP studies have explicitly focused on the early\ndetection of depression. Preemptive detection of mentions of\ndepression among Twitter users has been demonstrated with a\ndegree of success by Owen et al [13]. Abed-Esfahani [14]\nreported similar findings using Reddit data. However, both\nstudies were limited by the uncertainty of whether the users\nreferring to this condition were formally diagnosed. Shah et al\n[15] also considered approaches for the early detection of\ndepression in Reddit users. In this case, it was determined\nwhether the user had received a physician’s diagnosis. However,\nit was not certain whether the users’ posts occurred before or\nafter their diagnoses because the dates of the diagnoses were\nunknown. To gauge the effectiveness of the preemptive detection\nmethods, a series of user posts before a known diagnosis date\nis required. Eichstaedt et al [16] examined the language in\nFacebook posts that may have been predictive of depression,\nas shown in patients’ medical records. They achieved an\nF1-score of 0.66 via logistic regression modeling, which used\nonly the language preceding each patient’s depression diagnosis.\nTherefore, this study also sought to extend existing work on\npreemptive depression detection. We considered social media\nusers whose depression diagnosis date is known and used LMs\nto harness the language of user posts.\nRen et al [17] performed emotion-driven detection of depression\nusing Reddit, achieving F1-scores exceeding 0.9. Their work\nconsidered individual depression posts, rather than a series of\nposts. Nevertheless, their effective use of emotional semantic\ninformation suggested that the dissection of our own results\ncould be enhanced using sentiment analysis, which we included\nin our analysis to provide further insights.\nObjectives\nWe sought to gauge the performance of several machine learning\nclassifiers in the task of distinguishing between RSDD data set\nusers reporting and not reporting a diagnosis of depression,\nwhich from here onward we will term as “depressed” and\n“controls,” respectively. We then used the best-performing\nclassifier in a temporally driven binary classification task. The\npurpose was to determine the volume of posts in a depressed\nuser’s post timeline, which was the most indicative of their\nillness. To do this, we considered only the posts authored before\nthe depressed users’ estimated diagnosis dates. Moreover, we\nconsidered only posts published up to 6 months before those\ndates.\nThe motivation for considering this 6-month time range hails\nfrom Winkour et al [18], and their observation that over 50%\nof patients with depression experienced their first onset at least\n6 months before their formal diagnosis. Reece et al [19] made\nsimilar observations when examining Twitter users.\nThe time during which individuals with symptoms or traits of\ndepression remain undiagnosed poses serious health risks.\nPatients who remain undiagnosed and thus untreated experience\na worse outcome than would be the case if they were treated\n[20], particularly after their first episode [21]. Methods for\nJMIR AI 2023 | vol. 2 | e41205 | p. 2https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nassessing suitable time points for health care interventions are\nneeded to identify ways to improve patient outcomes. They are\nalso likely to advance the field of psychiatric therapeutics by\nsupporting modifications to clinical guidelines or the design of\nrandomized controlled trials [22]. A larger body of evidence on\nthis matter could also help identify patients to be targeted for\nmore thorough mental health assessments and provided with\nfurther resources, support, and treatment [23].\nMethods\nData Description\nOverview\nOur work is based on the RSDD and RSDD-Time data sets [24].\nThe RSDD contains Reddit posts of 9210 depressed users and\n108,731 control users. The posts were published between\nJanuary 2006 and October 2016. The representation of users in\nRSDD is presented in Textbox 1.\nRSDD-Time contains 598 annotated Reddit posts, each of which\nbelongs to a user who declares that they have been formally\ndiagnosed with depression. The posts were published between\nJune 2009 and October 2016. Of these posts, 529 belonged to\ndepressed users that were also present in the RSDD.\nRSDD-Time annotations include the recency of a user’s\ndiagnosis with respect to the date on which their post was\nauthored. The permissible recency annotations are as follows:\n0, unspecified; 1, in the past; 2, up to 2 months ago; 3, between\n2 months and 1 year ago; 4, between 1 and 3 years ago; and 5,\nmore than 3 years ago.\nThe representation of users in RSDD-Time is depicted in\nTextbox 2.\nTextbox 1. An abstract representation of Reddit Self-reported Depression Diagnosis user data. It is not permissible to reveal true user IDs, post dates,\nor post texts due to privacy reasons.\n{user_id: 1, posts: [ (<date 1>, <text>),..., (<date n>, <text>) ], label: <either depressed or control>},\n{user_id: 2, posts: [ (<date 1>, <text>),..., (<date n>, <text>) ], label: <either depressed or control>},\n...,\n{user_id: n, posts: [ (<date 1>, <text>),..., (<date n>, <text>) ], label: <either depressed or control>}\nTextbox 2. An abstract representation of Reddit Self-reported Depression Diagnosis–Time user data. It is not permissible to reveal true user IDs,\ndiagnosis post texts, or post dates, due to privacy reasons.\n{user_id: 1, diagnosis_post: <text>, post_date: <date>, recency: <0, 1, 2, 3, 4, or 5>},\n{user_id: 2, diagnosis_post: <text>, post_date: <date>, recency: <0, 1, 2, 3, 4, or 5>},\n...,\n{user_id: n, diagnosis_post: <text>, post_date: <date>, recency: <0, 1, 2, 3, 4, or 5>}\nDeriving RSDD-Matched\nWe used this information to estimate the diagnosis dates of the\n529 users present in both RSDD and RSDD-Time. Those with\nrecency annotations of 0 or 1 were ignored because their\ndiagnosis dates could not be estimated with any degree of\naccuracy. For each of the remaining users, we determined\nwhether the estimated diagnosis date fell between the date of\ntheir first RSDD post and the date of their RSDD-Time\ndiagnosis post. A total of 72 depressed users remained in the\nstudy.\nA total of 10 matching control users were sought for each of\nthe 72 depressed users. To accomplish this, candidate control\nusers were randomly retrieved from the RSDD and analyzed\nsequentially. The candidates’ posts dated before the\ncorresponding depressed user’s estimated diagnosis date were\nconsidered. If the number of posts belonging to the candidate\ndid not vary by >15% with respect to the depressed user, the\ncandidate was considered a match. A control user matched in\nthis manner was not considered a candidate for subsequent\ndepressed users.\nBecause sufficient matching control users could not be found\nfor 2 of the depressed users, they were excluded from the\nresulting data set. The data set contained 70 depressed users,\neach of whom had 10 matching control users. Thus, there were\na total of 770 users. The posts were published between April\n2006 and June 2016. We named our data set RSDD-Matched.\nThe characteristics of RSDD-Matched are shown in Table 1.\nStatistics pertaining to individual users in RSDD-Matched can\nbe found in Multimedia Appendix 1.\nBecause RSDD does not include posts made in mental health\nsubreddits, a depressed user’s diagnosis is certain to not be\nrevealed until the time of their diagnosis post. There is language\nindicative of mental health conversation in the other subreddits.\nJMIR AI 2023 | vol. 2 | e41205 | p. 3https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nTable 1. Statistics of the Reddit Self-reported Depression Diagnosis–Matched data set.\nControl usersDepressed users\n70070Total users\n364,74736,826Total posts\n8,188,0901,742,388Total words\n521.1526.1Average posts per user\n22.447.3Average words per post\n11Shortest post (words)\n18942642Longest post (words)\nDescriptive Analysis of RSDD\nTo better understand our data set, we performed a simple\ndescriptive analysis of RSDD. Word-level exploratory analyses\nof corpora have been extensively used in corpus linguistics and\nNLP to gain insight into word prominence. Typically, these\nfollow a bag-of-words [25], pointwise mutual information [26],\nor term frequency–inverse document frequency (TF-IDF) [27]\napproach. In our case, we used lexical specificity [28], which\nis a statistical measure based on hypergeometric distribution,\nto identify the most prominent words in a corpus. We chose to\nuse lexical specificity because it is structured in a way that is\nideal for extracting corpus-specific vocabulary given a global\ncorpus (RSDD) and its subsets (depressed and control users)\n[29]. It is also a more robust metric for term importance when\ndealing with different lengths of text [30], which is often the\ncase for Reddit posts.\nRSDD is partitioned into 2 subsets, or subcorpora, one\ncontaining posts of depressed users, and another containing\nposts of the control users. After lemmatizing the corpus, lexical\nspecificity analysis revealed the unigrams (single words) that\nwere the most frequently used by depressed and control\nparticipants (Table 2). The score column indicates the relevance\nof a unigram to each subset. For reference, the term “woman”\nmakes up 0.18% (460,893/257,873,124) of the total words that\nappear in the depressed user subset compared with only 0.06%\n(569,330/950,988,726) of the control user subset.\nTo put the results into context, we should mention that a lexical\nspecificity score of X for a given word W with frequency f\nmeans that the probability of W occurring at least f times in the\nsubcorpus is lower than 10–X (assuming a random distribution).\nFor instance, a lexical specificity score of 42,234 for “game”\nmeans that the probability of “game” having a frequency of\nf=5,373,938 or higher in the control users subcorpus is 10–42,234\n(ie, an exceptionally low probability which means “game” is\noverrepresented in the control users’subset). In general, we can\nobserve a pattern in which depressed users tend to use more\nrelationship or family-related words (eg, “woman” or\n“relationship”) and words related to the depression symptoms\nthemselves (eg, “life”). In contrast, control users seem to use\nmore mundane terms related to the subreddit communities, such\nas game-related terms (eg, “game” or “team”). Although this\nanalysis is based only on the statistical frequency of the terms\nused, it may provide further evidence that developing automatic\nmethods to identify users with depression may indeed be\nfeasible. In the Results section, we extend this initial inspection\nto better understand the errors made by the automatic models.\nJMIR AI 2023 | vol. 2 | e41205 | p. 4https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nTable 2. Top ranked words of Reddit Self-reported Depression Diagnosis depressed and control users in terms of lexical specificity.\nScoreUser, word\nDepressed users\n338,131.45people\n164,368.51know\n150,440.49thing\n118,483.23feel\n97,250.09time\n96,165.35woman\n79,611.79go\n75,379.17want\n67,769.01life\n62,606.64relationship\nControl users\n42,234.94game\n39,445.65trade\n30,031.17key\n24,333.73team\n17,389.38play\n16,186.61player\n14,032.27shiny\n13,265.87hatch\n10,177.49thank\n10,005.14add\nMethodology\nIn this section, we provide more details of our proposed methods\nfor tackling the depression detection task. Framing the task as\na machine learning problem, we considered 9 methods based\non linear classifiers and more recent LMs.\nThe initial baselines entailed a support vector machine (SVM)\narchitecture. SVM is an algorithm that learns by example to\nassign labels to objects [31]. In our case, the objects are Reddit\nusers, and permissible labels are “depressed” and “control.”\nSVMs have demonstrated effectiveness in the detection of\ndepression-related posts in Reddit [8,32]. Our SVM\nconfigurations used different features derived from user posts.\nThese features included TF-IDF, word embeddings, and a\ncombination of both TF-IDF and word embeddings. The TF-IDF\n[33] features represent the words deemed most notable among\nthe user posts. Word embedding is a real-valued vector\nrepresentation of a word [34]. Words with similar meanings\nhave vectors with similar values.\nThe SVM model used was that of scikit-learn [35], as was the\nTF-IDF vectorizer implementation. The word embeddings\ngenerated for each Reddit post were drawn from global vectors\ntrained on Wikipedia and Gigaword data [36]. These vectors\nhad a dimensionality of 300, similar to the average embedding\ngenerated. We performed Reddit posttext preprocessing before\ntheir input to the SVM. All posts underwent quotation\nnormalization; therefore, each quotation character was\nrepresented by a single apostrophe. All new lines and carriage\nreturn characters were replaced with spaces so that posts were\nrepresented as a single line string. The posts were then\nconcatenated on a per-user basis so that each user’s posting\nhistory was represented as a single-line string. SVM used a\nlinear kernel, which is appropriate for text-classification\nproblems [37-39].\nThe remaining 6 classifiers were transformer-based LMs. LMs\nare a statistical means of predicting words [40], whereas\ntransformers provide a neural-network-based approach to\ngenerating such models [41]. Transformer-based LMs have\nproven effective in detecting psychiatric illness-related Reddit\nposts [12,42,43]. Therefore, we chose to use transformer-based\nLMs to support the detection of depression in RSDD-Matched.\nWe chose Bidirectional Encoder Representations from\nTransformers (BERT) [44] and A Lite BERT (ALBERT) [45],\nwhich are appropriate for a wide variety of applications. We\nalso chose 4 specialist LMs: BioBERT [46], Longformer [47],\nMentalBERT [48], and MentalRoBERTa [48]. BioBERT is\nsuitable for use where biomedical concepts are prevalent, such\nas electronic medical records [49], patient descriptions [50],\nand health-related Twitter posts [51]. Longformer is designed\nfor use when text is formed from long documents. Indeed, there\nwere posts in RSDD-Matched that exceed 2000 words. Finally,\nJMIR AI 2023 | vol. 2 | e41205 | p. 5https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nMentalBERT and MentalRoBERTa are customized for the\ndomain of mental health care and trained using text drawn from\nmental health discussion forums.\nAll 6 transformer-based LMs were pretrained bidirectional\nlanguage representations. This means that for any given word\nin a text segment, its neighboring words to both the left and\nright are examined so that the context of the word is well\nunderstood. These representations lend themselves to high\nperformance in text classification tasks when compared with\ntraditional approaches using SVMs, for example [52,53].\nWe used the Simple Transformers software library [54] to\ndeploy LMs. The library provides an application programming\ninterface to the transformer library, which itself provides access\nto the BERT, ALBERT, BioBERT, Longformer, MentalBERT,\nand MentalRoBERTa models [55]. The BERT, ALBERT,\nBioBERT, Longformer, MentalBERT, and MentalRoBERTa\nclassifiers used were “bert-base-uncased,” “albert-base-v1,”\n“biobert-base-cased-v1.1,” “longformer-base-4096,”\n“mental-bert-base-uncased,” and “mental-roberta-base,”\nrespectively. In addition to the default hyperparameters of the\nSimple Transformers, the LM classifiers were instantiated, with\nthe sliding window enabled. Transformer-based LMs may\nconsume only a limited number of tokens (512 tokens). Because\nthe posting histories of most users in RSDD-Matched exceed\n512 words, a specialist approach to applying LMs to these posts\nis needed. Sliding window is one such approach [56].\nExperimental Setup\nPreemptive Depression Identification Experiment\nThe first experiment examined the performance of several\nmachine learning classifiers in the task of distinguishing between\ndepressed and control users in RSDD-Matched. The purpose\nof this experiment was to understand the extent to which the\npreemptive detection of depression in social media is possible.\nMoreover, this experiment was aimed at understanding the\ncapabilities of machine learning classifiers for this task and the\nsuitability of different methods in the task. The results were\nused to provide a competitive model for subsequent fine-grained\ntemporal experiments.\nWe used 9 different classifiers. Three entailed an SVM, as\ndescribed in the Methodology section. The remaining 6 were\nBERT, ALBERT, BioBERT, Longformer, MentalBERT, and\nMentalRoBERTa, which are also described in the Methods\nsection.\nIn addition to the aforementioned classifiers, we included a\nnaive baseline that predicted positive instances in all cases.\nBecause the number of positive instances (ie, depressed users)\nin RSDD-Matched was small, we chose not to use a traditional\ntrain-test split. Instead, we used 5-fold cross-validation; an\napproach also used by Eichstaedt et al [14]. Furthermore, we\nvaried the number of matching control users across the 4\niterations of the experiment (Table 3).\nThe purpose of these variations is to test the performance of\nclassifiers against increasingly imbalanced data sets. This\nmimics the conditions likely to be observed in web-based forums\nwhere the number of positive instances (ie, depressed users) is\ndwarfed by the number of negative instances (ie, nondepressed\nusers).\nTable 3. Variations of the preemptive depression identification experiment in terms of the number of matching control users considered.\nTotal usersMatching control users per depressed userDepressed users\n140170Variation 1\n280370Variation 2\n420570Variation 3\n7701070Variation 4\nTemporal Experiment\nThe purpose of the second primary experiment was to determine\nwhich posting period in a depressed user’s post timeline was\nthe most indicative of depression. This involved the use of a\nsubset of RSDD-Matched users. The performance of binary\nclassifiers versus temporal subsets of the posts in the 6 months\nbefore the users’ estimated diagnosis dates was measured.\nThe RSDD-Matched subset contained only depressed users who\nhad at least one post in the 2 weeks before their estimated\ndiagnosis date. Of the 70 depressed users in our RSDD subset,\n14 did not have any posts in this 2-week period. Consequently,\nwe used only 56 depressed users in the temporal experiment.\nFurthermore, not all 10 control users matched with each of the\n56 depressed were useable because some did not have at least\none post in this 2-week period. Thus, we performed additional\nrandom exclusions of controls to rebalance the data set. After\nthese exclusions, the data set used in the temporal experiment\ncontained 56 depressed users, each of which had 3 matching\ncontrol users, totaling to 224 users.\nThe results of the preemptive depression identification\nexperiment were used to partially inform the design of the\ntemporal experiment. Because BERT scored the highest average\nF1-score across all runs of the preemptive depression\nidentification experiment, it was decided that this was the sole\ngeneral-purpose transformer-based LM to be used in the\ntemporal experiment. Likewise, MentalBERT had the highest\naverage F1-score; therefore, it was selected as the sole specialist\nLM. The 3 variations of the SVM classifier used in the\npreemptive depression-identification experiment were used once\nagain.\nJMIR AI 2023 | vol. 2 | e41205 | p. 6https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nOnce again, we used 5-fold cross-validation. Two chief\nvariations of the RSDD-Matched subset and several different\ntemporal configurations were used (Table 4).\nThe 2 chief strands to our experimental setup are summarized\nin Figure 1.\nWe complemented the temporal experiment with sentiment\nanalysis. The purpose of this study was to identify whether there\nis a link between sentiment and depression with respect to user\nposts. Text sentiment has been extensively used as a predictor\nfor detecting signs of depressive mood in microblog users\n[57-59]. Specifically, negatively charged text has often been\ncorrelated with depression via expressions of low mood and\nsuicidal ideation [60]. Approaches used to extract sentiment\nfrom social media posts include the use of LMs [61] and\nlexicons such as Valence Aware Dictionary and Sentiment\nReasoner (VADER) [62].\nTo determine whether there is a relationship between sentiment\nand depression, we used BERTweet-sentiment, a state-of-the-art\ntransformer model, to classify each post in RSDD-Matched as\neither negative, neutral, or positive. BERTweet-sentiment is\nbased on the BERTweet [63] implementation, which is trained\non a large Twitter corpus and fine-tuned for sentiment analysis.\nAlthough the model is not trained on Reddit data, we believe\nthat there are enough overlapping lexical characteristics between\nthe 2 domains in terms of internet slang and text lengths that\njustify its use.\nOur sentiment analysis focused on changes in the sentiment\ndistribution of depressed and control users over time. In step\nwith the design of our temporal experiment, each user’s posts\nare divided into 6 temporal bands, namely 0-4, 4-8, 8-12, 12-16,\n16-20, and 20-24 weeks before their estimated diagnosis date\n(for a control user, this is the estimated diagnosis of its matched\ndepressed user). The average percentage of each sentiment in\neach band was considered.\nTo establish whether the diagnosis was associated with the\nsentiment of a post, 2 regression models were used. The first\nwas based on the lme4 framework [64], and the second on mgcv\n[65]. The implementations used were those of the R (version\n4.02) statistical environment [66]. We set our outcome variable\nto be whether a post is “sentimental” (that is, either negative or\npositive) or not (neutral), and a logistic mixed effects regression\nwas fitted using all the available posts with the individual user\nidentifier as a random effect term. As fixed effects, we used the\nestimated depression diagnosis (ie, either depressed or control),\nthe time to estimated diagnosis in weeks, the post’s word count,\nand the interaction term of estimated diagnosis with time.\nHaving sought to establish whether the diagnosis of the user\nwas associated with the sentimentality inferred for each post,\nwe also considered a more fine-grained multinomial regression\nmodel. This is equivalent to fitting a series of logistic models\nagainst a reference category [67] and is similar to the “stacked”\ndesigns used in other disciplines [68]. For our purposes, we will\nconsider “neutral” as the reference category of our multinomial\noutcome, so all effect sizes will indicate the probability of a\npost being positive or negative instead of neutral.\nTable 4. Variations of the temporal experiment in terms of the number of matching control users and numbers of weeks of posts before estimated\ndiagnosis dates considered.\nWeeks of posts included before estimated\ndiagnosis date\nTotal usersMatching control users per depressed userDepressed users\n4, 8, 12, 16, 20, and 24112156Variation 1\n4, 8, 12, 16, 20, and 24224356Variation 2\nJMIR AI 2023 | vol. 2 | e41205 | p. 7https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nFigure 1. Summary of the 2 chief experimental setups. ALBERT: A Lite Bidirectional Encoder Representations from Transformers; BERT: Bidirectional\nEncoder Representations from Transformers; LM: language model; SVM: support vector machine; TF-IDF: term frequency–inverse document frequency;\nRSDD: Reddit Self-reported Depression Diagnosis.\nResults\nPreemptive Depression Identification Experiment\nThe results of the preemptive depression identification\nexperiment are presented in Tables 5-8. Each table shows a\nvariation in the number of matched control users. Positive\npredictive value, sensitivity, and F1-score were used to measure\nthe performance in each variation. The positive predictive value\ndenotes the number of users classified as depressed who were\nindeed depressed. Sensitivity denotes how many of the depressed\nusers were correctly classified as depressed. The F1-score, which\nis the harmonic mean of the positive predictive value and\nsensitivity, is suitable for use with data sets such as ours, where\nthe class distribution (of depressed and controls) is uneven [69].\nIn contrast, accuracy is not suitable for such data sets [70].\nTherefore, we used F1-score as the primary performance metric.\nUsing F1-score as a primary performance indicator,\nMentalBERT performs best across the variations.\nA detailed breakdown of the results of the preemptive depression\nidentification experiment can be found in Multimedia Appendix\n1.\nWord embeddings (vector representations) result in strong\nsensitivity (recall), whereas TF-IDF features cause deficient\nperformance. The positive predictive value (precision) was best\nobserved when using the specialist LM, MentalBERT. The best\nF1-score was also achieved by MentalBERT and exceeded the\nnaive baseline.\nWe now consider the selected users from RSDD-Matched and\nthe performance of the classifiers against them. We will examine\none misclassified user per variation in the experiment (in terms\nof depressed users and the number of matched controls). For\neach variation, we will examine the strongest performing\nclassifier and the user that it misclassified with the highest\nprobability.\nTo identify the potential reasons for the misclassifications, we\nexamined the lexical properties of user posts using 3 approaches.\nThe first approach involves ascertaining the chief topic conveyed\nby the posts, a topic represented by 5 words. Topic modeling\nvia latent Dirichlet allocation was used to accomplish this\n[71,72]. The second approach examines the chief TF-IDF\nfeatures of the user posts. The third approach is to count the\nfrequencies of depressed and control vocabularies (Table 2) that\nappear across the posts.\nWe present the misclassified depressed users with respect to\neach variation in the experiment (Table 9). We also present the\nmisclassified control users with respect to each variation (Table\n10).\nOne depressed user is often misclassified. User d13 was deemed\na control user using 3 different classifiers across 3 different\nvariations. Although depressed vocabulary counts slightly\noutweigh their control counterparts, the totals for both\nvocabularies were nominal. The topic of the user’s posts is\nprobably more indicative of the reasons for the misclassification.\nCertainly, a theme concerning death or dying appears to be\npresent, but this is diluted by optimistic sounding references of\ntemporal and geographic nature. Further diluting references are\nrevealed among the TF-IDF features, where strong terms such\nas “love” are present. It seems that the classifiers construe such\nreferences as those belonging to a control user.\nUser d38 may have been misclassified for similar reasons.\nCounts for both depressed and control vocabularies were small.\nJMIR AI 2023 | vol. 2 | e41205 | p. 8https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nPositive terms, such as “welcome” and “invite” might be deemed\nto belong to a control user.\nAn inferior performance was observed across the classifiers in\nthe most imbalanced environment. We examine depressed user\nd57, which has been misclassified with a probability close to\ncertainty. The depressed vocabulary count dwarfs the control\nvocabulary count. However, when making its decision, the\nclassifier seems to harness the overarching nature of the user’s\nposts, as indicated by the topic model and TF-IDF features. The\nprevalence of “good” natured posts will inevitably see the user\ndeemed similar to a control user when represented in a vector\nspace.\nWe now consider misclassified control users with respect to\neach variation in the experiment (Table 10).\nCertain users appear to be confounding across several different\nclassifiers and variations. User c13 was strongly misclassified\nas a depressed user by both MentalBERT and MentalRoBERTa\nin the relatively noisy environments of 3 and 5 matched control\nusers, respectively (Table 10). The depressed vocabulary counts\nfar outweigh the control vocabulary counts for this user. In\naddition, the theological topic and TF-IDF features of the user’s\nposts are deemed likely to be those of a depressed user,\naccording to the classifier.\nMentalBERT demonstrated adeptness in the most balanced\nvariation in the experiment. We sought possible explanations\nfor the misclassification of user c521. The control vocabulary\ncount slightly outweighed that of depressed vocabulary.\nMoreover, the topic model and TF-IDF features are composed\nof terms that complement the control vocabulary. Intuitive\nreasons for misclassification as depressed are difficult to cite.\nTherefore, it is possible that, in a balanced environment, the\nclassifier simply has too few control users to compare with\ndepressed users.\nIn the noisiest environment, the simpler word-based model\n(SVM using word embeddings) demonstrated the strongest\nperformance. Transformer-based language modeling cannot be\nperformed. The vocabulary of the most strongly misclassified\nuser in this case (c535) only offers a tenuous explanation. The\ncount of depressed vocabulary was small, although it outweighed\nthat of the control vocabulary. However, the topic and TF-IDF\nterms appeared to complement the depressed vocabulary, which\nmay have been the cause of the misclassification.\nTable 5. Binary classification scores using all posts of 70 depressed users and 1 of their matched control usersa.\nF1-score, mean (SD)Sensitivity, mean (SD)Positive predictive value, mean (SD)\n0.590 (N/A)0.557 (N/A)0.637 (N/Ad)SVMb using TF-IDFc\n0.548 (N/A)0.543 (N/A)0.558 (N/A)SVM using word embeddings\n0.596 (N/A)0.557 (N/A)0.673 (N/A)SVM using TF-IDF and word embed-\ndings\n0.709 (0.012)0.805 (0.022)0.638 (0.021)BERTe LMf\n0.683 (0.010)0.786 (0.015)0.606 (0.008)ALBERTg LM\n0.707 (0.005)0.862 (0.022)0.601 (0.005)BioBERT LM\n0.719 (0.018)0.838 (0.036)0.633 (0.009)Longformer LM\n0.738 (0.013)0.848 (0.008)0.660 (0.019)MentalBERT LM\n0.709 (0.006)0.819 (0.022)0.629 (0.002)MentalRoBERTa LM\n0.667 (N/A)1.000 (N/A)0.500 (N/A)Naive baseline—all depression\naLanguage model experiments were run 3 times each, therefore both mean and SD scores are provided.\nbSVM: support vector machine.\ncTF-IDF: term frequency–inverse document frequency.\ndN/A: not applicable.\neBERT: Bidirectional Encoder Representations from Transformers.\nfLM: language model.\ngALBERT: A Lite Bidirectional Encoder Representations from Transformers.\nJMIR AI 2023 | vol. 2 | e41205 | p. 9https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nTable 6. Binary classification scores using all posts of 70 depressed users and 3 of their matched control usersa.\nF1-score, mean (SD)Sensitivity, mean (SD)Positive predictive value, mean (SD)\n0.153 (N/A)0.086 (N/A)0.800 (N/Ad)SVMb using TF-IDFc\n0.459 (N/A)0.529 (N/A)0.411 (N/A)SVM using word embeddings\n0.107 (N/A)0.057 (N/A)0.800 (N/A)SVM using TF-IDF and word embeddings\n0.546 (0.025)0.481 (0.022)0.653 (0.033)BERTe LMf\n0.547 (0.018)0.476 (0.009)0.652 (0.034)ALBERTg LM\n0.496 (0.020)0.410 (0.030)0.654 (0.028)BioBERT LM\n0.534 (0.031)0.476 (0.036)0.653 (0.036)Longformer LM\n0.562 (0.016)0.509 (0.008)0.657 (0.034)MentalBERT LM\n0.522 (0.002)0.471 (0.015)0.614 (0.023)MentalRoBERTa LM\n0.167 (N/A)1.000 (N/A)0.250 (N/A)Naive baseline—all depression\naLanguage model experiments were run 3 times each, therefore both mean and SD scores are provided.\nbSVM: support vector machine.\ncTF-IDF: term frequency–inverse document frequency.\ndN/A: not applicable.\neBERT: Bidirectional Encoder Representations from Transformers.\nfLM: language model.\ngALBERT: A Lite Bidirectional Encoder Representations from Transformers.\nTable 7. Binary classification scores using all posts of 70 depressed users and 5 of their matched control usersa.\nF1-score, mean (SD)Sensitivity, mean (SD)Positive predictive value, mean (SD)\n0.053 (N/A)0.029 (N/A)0.400 (N/Ad)SVMb using TF-IDFc\n0.372 (N/A)0.471 (N/A)0.309 (N/A)SVM using word embeddings\n0.027 (N/A)0.014 (N/A)0.200 (N/A)SVM using TF-IDF and word embeddings\n0.379 (0.017)0.290 (0.022)0.615 (0.028)BERTe LMf\n0.354 (0.006)0.281 (0.009)0.555 (0.030)ALBERTg LM\n0.331 (0.027)0.252 (0.021)0.627 (0.034)BioBERT LM\n0.363 (0.059)0.286 (0.038)0.624 (0.108)Longformer LM\n0.400 (0.040)0.329 (0.043)0.572 (0.002)MentalBERT LM\n0.419 (0.010)0.343 (0.000)0.562 (0.027)MentalRoBERTa LM\n0.286 (N/A)1.000 (N/A)0.167 (N/A)Naive baseline—all depression\naLanguage model experiments were run 3 times each, therefore both mean and SD scores are provided.\nbSVM: support vector machine.\ncTF-IDF: term frequency–inverse document frequency.\ndN/A: not applicable.\neBERT: Bidirectional Encoder Representations from Transformers.\nfLM: language model.\ngALBERT: A Lite Bidirectional Encoder Representations from Transformers.\nJMIR AI 2023 | vol. 2 | e41205 | p. 10https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nTable 8. Binary classification scores using all posts of 70 depressed users and 10 of their matched control usersa.\nF1-score, mean (SD)Sensitivity, mean (SD)Positive predictive value, mean (SD)\n0.000 (N/A)0.000 (N/A)0.000 (N/Ad)SVMb using TF-IDFc\n0.268 (N/A)0.371 (N/A)0.212 (N/A)SVM using word embeddings\n0.000 (N/A)0.000 (N/A)0.000 (N/A)SVM using TF-IDF and word embeddings\n0.025 (0.00)0.014 (0.000)0.100 (0.000)BERTe LMf\n0.025 (0.001)0.014 (0.000)0.089 (0.019)ALBERTg LM\n0.009 (0.016)0.005 (0.008)0.067 (0.115)BioBERT LM\n0.021 (0.037)0.019 (0.033)0.024 (0.019)Longformer LM\n0.026 (0.001)0.014 (0.000)0.167 (0.058)MentalBERT LM\n0.057 (0.018)0.034 (0.008)0.272 (0.185)MentalRoBERTa LM\n0.167 (N/A)1.000 (N/A)0.091 (N/A)Naive baseline—all depression\naLanguage model experiments were run 3 times each, therefore both mean and SD scores are provided.\nbSVM: support vector machine.\ncTF-IDF: term frequency–inverse document frequency.\ndN/A: not applicable.\neBERT: Bidirectional Encoder Representations from Transformers.\nfLM: language model.\ngALBERT: A Lite Bidirectional Encoder Representations from Transformers.\nJMIR AI 2023 | vol. 2 | e41205 | p. 11https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nTable 9. Depressed users most strongly misclassified in each variation of the preemptive depression identification experimenta.\nOne depression user per 10\ncontrol users (1:10)\nOne depression user per 5\ncontrol users (1:5)\nOne depression user per 3\ncontrol users (1:3)\nOne depression user per\ncontrol user (1:1)\nSVMc using word embeddingsMentalRoBERTa LMMentalBERT LMMentalBERT LMbClassifier\nd57d13d38d13User\n0.980.990.940.93Control probability\n55,897169618881696Sum of post lengths in\nwords\nTopic •••• goodnewssir-geonews\n• •••hawaii timehawaiiwelcomed\n•••• peopletimeinvitetime\n• •••dead yearsdeadleave\n•• ••warlockblue problemblue\nChief TF-IDFd features •••• goodlovesirlove\n• •••minnesota knowminnesotageo\n•••• usediablowelcomediablo\n• •••time maketimeinvite\n•• ••warlockman timeman\n••• •budleavebud thank\n•••• linkzoidbergtitanzoidberg\n• •••like wantlikepsn\n•• ••runmonth trymonth\n••• •hawaiineedhawaii like\nDepressed vocabulary counts\n64111people\n93606know\n35303thing\n10222feel\n99585time\n7101woman\n54303go\n71313want\n28202life\n2000relationship\nControl vocabulary counts\n9010game\n2000trade\n4000key\n4232team\n35010play\n8000player\n0000shiny\n0000hatch\n15011thank\n14020add\naLexical properties of those users’ posts are provided.\nbLM: language model.\ncSVM: support vector machine.\ndTF-IDF: term frequency–inverse document frequency.\nJMIR AI 2023 | vol. 2 | e41205 | p. 12https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nTable 10. Control users most strongly misclassified in each variation of the preemptive depression identification experimenta.\nOne depression user per 10\ncontrol users (1:10)\nOne depression user per 5\ncontrol users (1:5)\nOne depression user per 3\ncontrol users (1:3)\nOne depression user per\ncontrol user (1:1)\nSVMc using Word embed-\ndings\nMentalRoBERTa LMMentalBERT LMMentalBERT LMbClassifier\nc535c13c13c521User\n0.910.910.950.99Depressed probability\n1595848984891513Sum of post lengths in words\nTopic •••• peoplegodgodelo\n• •••play shitjesusjesus\n•••• redditpeoplepeopleteam\n• •••bronze guygoodgood\n•• ••lifegames manlife\nChief TF-IDFd features •••• saygodgodteam\n• •••just thankthinkthink\n•••• guywaywaysuck\n• •••elo peoplethingthing\n•• ••tryplay reddittry\n••• •knowknowgame man\n•••• makejesusjesuslike\n• •••good tellpeoplepeople\n•• ••saysydtko watchsay\n••• •likelikewin let\nDepressed vocabulary counts\n648484people\n336362know\n128283thing\n1661feel\n4662time\n0440woman\n5440go\n116163want\n146460life\n0880relationship\nControl vocabulary counts\n0007game\n0000trade\n0000key\n0009team\n0669play\n0002player\n0000shiny\n0000hatch\n1441thank\n0001add\naLexical properties of those users’ posts are provided.\nbLM: language model.\ncSVM: Support Vector Machine.\ndTF-IDF: Term Frequency–-Inverse Document Frequency.\nJMIR AI 2023 | vol. 2 | e41205 | p. 13https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nTemporal Experiment\nWe then performed a temporal experiment. Because BERT\nachieved the highest F1-score across all preemptive depression\nidentification experiment variations, it was selected as the\nexclusive general-purpose LM here. For the same reason,\nMentalBERT was selected as an exclusive specialist LM. The\nresults are presented in Tables 11 and 12. Each table shows a\nvariation in the number of matched control users. The average\nperformance of each LM across the 2 variations is shown in\nFigure 2.\nFor BERT, the strongest sensitivity and F1-scores were observed\nwhen only 12 weeks (approximately 3 months) of posts before\nthe estimated diagnosis dates were considered. Subsets larger\nor smaller than 12 weeks caused degradation in the classifier\nperformance. For MentalBERT, the strongest sensitivity and\nF1-scores were obtained when either 16 or 24 weeks of posts\nwere considered. With BERT scoring a higher F1-score at 12\nweeks than MentalBERT, this suggests that the final 12 weeks\nof posts before a depressed user’s estimated diagnosis date may\nbe the most indicative of their illness.\nAn explanation for the slightly inferior performance of\nMentalBERT may be found in its construction: it is pretrained\non text from mental health subreddits such as “r/depression”\nand “r/mental health” [48]. However, RSDD (from which we\nderived RSDD-Matched) does not contain posts from mental\nhealth subreddits. Therefore, when RSDD-Matched data are\nlimited, as in our temporal experiment, more general-purpose\nmodels, such as BERT, may be able to achieve stronger\nperformance. BERT is pretrained on more general corpora, such\nas Wikipedia [44].\nA detailed breakdown of the results of the temporal experiment\ncan be found in Multimedia Appendix 1.\nWe once again consider selected users from RSDD-Matched\nand the performance of the classifiers against them. We again\nexamined one misclassified user per variation in the experiment\n(in terms of depressed users and number of matched controls).\nFor each variation, we will examine the strongest performing\ntime span, and the user that is misclassified with the highest\nprobability. To identify the reasons for the misclassifications,\nwe again examined the lexical properties of the user posts using\ntopic models, TF-IDF features, and vocabulary (Table 2)\nfrequency counts.\nMisclassified depressed users with respect to the 2 variations\nin the experiment are listed in Table 13.\nUser d52 is a depressed user misclassified in both balanced and\nimbalanced environments, where only the final 12 weeks of\ntheir posts are considered. The vocabulary of these posts\nintersected with very little of the chief depressed vocabulary.\nIt intersects with slightly more of the chief control vocabulary.\nThe topic and TF-IDF features, intuitively speaking, appear to\nbelong to that of a control rather than a depressed user. Perhaps,\na balanced environment with temporally limited post histories\nprovides little training data from which the classifier can learn\nto differentiate between controls and depressed users. Although\nrare, these cases may occur in practice and highlight the\nimportance of being careful in overrelying on automatic models\nfor individual assessments without human expert intervention.\nWe now consider the misclassified control users with respect\nto the 2 variations in the experiment (Table 14).\nFirst, we consider user c481. Both its depressed and control\nvocabulary counts were zero, which offers some insight into\nmisclassification. The topic and TF-IDF features of the posts\nappear to align with those of the control user. However, it is\nlikely that the prevalence of “pain” is a confounding factor. This\nterm may be intuitively linked to depressed users, which may\nmislead the classifier. Again, the limited temporal range of posts\nin this setting provided little data from which the classifier could\nlearn.\nUser c13 is a confounder in the preemptive depression\nidentification experiment and has been proven to be so in the\ntemporal experiment. Even when considering only the last 12\nweeks of the user’s posts in an imbalanced environment,\ntheologically themed vocabulary is not diluted. It intersects\nstrongly with the vocabulary of depressed users and explains\nthis misclassification.\nJMIR AI 2023 | vol. 2 | e41205 | p. 14https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nTable 11. Binary classification scores using 56 depressed users and 1 of their matched control users and 6 temporal post subsetsa.\nF1-score, mean (SD)Sensitivity, mean (SD)Positive predictive value, mean (SD)\nLast 4 weeks\n0.675 (0.023)0.830 (0.039)0.575 (0.027)BERTb LMc\n0.698 (0.017)0.835 (0.026)0.612 (0.026)MentalBERT LM\nLast 8 weeks\n0.700 (0.037)0.854 (0.071)0.598 (0.026)BERT LM\n0.699 (0.022)0.842 (0.047)0.603 (0.020)MentalBERT LM\nLast 12 weeks\n0.726 (0.015)0.912 (0.018)0.605 (0.014)BERT LM\n0.715 (0.008)0.888 (0.010)0.600 (0.013)MentalBERT LM\nLast 16 weeks\n0.684 (0.007)0.863 (0.026)0.570 (0.009)BERT LM\n0.703 (0.016)0.907 (0.028)0.575 (0.009)MentalBERT LM\nLast 20 weeks\n0.694 (0.025)0.893 (0.036)0.569 (0.023)BERT LM\n0.696 (0.014)0.882 (0.027)0.578 (0.018)MentalBERT LM\nLast 24 weeks\n0.683 (0.010)0.871 (0.027)0.565 (0.021)BERT LM\n0.707 (0.011)0.890 (0.010)0.591 (0.014)MentalBERT LM\nAll posts\n0.710 (0.019)0.824 (0.032)0.627 (0.018)BERT LM\n0.732 (0.006)0.861 (0.000)0.638 (0.009)MentalBERT LM\n0.667 (N/A)1.000 (N/A)0.500 (N/Ad)Naive baseline\naThe classifiers used are BERT LM and MentalBERT LM, both of whose experiments were run 3 times each, therefore both mean and SD scores are\nprovided.\nbBERT: Bidirectional Encoder Representations From Transformers.\ncLM: language model.\ndN/A: not applicable.\nJMIR AI 2023 | vol. 2 | e41205 | p. 15https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nTable 12. Binary classification scores using 56 depressed users and 3 of their matched control users and 6 temporal post subsetsa.\nF1-score, mean (SD)Sensitivity, mean (SD)Positive predictive value, mean (SD)\nLast 4 weeks\n0.489 (0.010)0.538 (0.019)0.480 (0.027)BERTb LMc\n0.525 (0.007)0.577 (0.009)0.494 (0.019)MentalBERT LM\nLast 8 weeks\n0.472 (0.035)0.538 (0.036)0.446 (0.032)BERT LM\n0.461 (0.023)0.524 (0.029)0.427 (0.027)MentalBERT LM\nLast 12 weeks\n0.543 (0.035)0.619 (0.037)0.498 (0.031)BERT LM\n0.494 (0.009)0.569 (0.017)0.448 (0.007)MentalBERT LM\nLast 16 weeks\n0.504 (0.011)0.565 (0.021)0.471 (0.010)BERT LM\n0.541 (0.028)0.643 (0.037)0.481 (0.023)MentalBERT LM\nLast 20 weeks\n0.510 (0.034)0.577 (0.037)0.475 (0.039)BERT LM\n0.524 (0.009)0.595 (0.011)0.487 (0.018)MentalBERT LM\nLast 24 weeks\n0.518 (0.033)0.591 (0.036)0.470 (0.033)BERT LM\n0.536 (0.022)0.591 (0.018)0.501 (0.022)MentalBERT LM\nAll posts\n0.562 (0.015)0.519 (0.032)0.625 (0.021)BERT LM\n0.540 (0.003)0.508 (0.010)0.588 (0.005)MentalBERT LM\n0.400 (N/A)1.000 (N/A)0.250 (N/Ad)Naive baseline\naThe classifiers used are BERT LM and MentalBERT LM, both of whose experiments were run 3 times each, therefore both mean and SD scores are\nprovided..\nbBERT: Bidirectional Encoder Representations From Transformer.\ncLM: language model.\ndN/A: not applicable.\nFigure 2. Average performances of Bidirectional Encoder Representations from Transformers (BERT) and MentalBERT between 4 and 24 weeks\nbefore the estimated diagnosis date.\nJMIR AI 2023 | vol. 2 | e41205 | p. 16https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nTable 13. Depressed users most strongly misclassified in each variation of the temporal experiment. Lexical properties of those users’posts are provided.\nOne depression user per 3 control users (1:3)One depression user per control user (1:1)\nLast 12 weeksLast 12 weeksTime span\nBERT LMBERTa LMbClassifier\nd52d52User\n0.9350.869Control probability\n12251225Sum of post lengths in words\nengland belgium hamster time teamengland belgium hamster time teamTopic\nChief TF-IDFc features •• thankthank\n• •team team\n•• playerplayer\n• •help help\n•• timetime\n• •goal goal\n•• cagecage\n• •post post\n•• secondsecond\n• •start start\nDepressed vocabulary counts\n00people\n11know\n11thing\n00feel\n44time\n00woman\n00go\n22want\n00life\n00relationship\nControl vocabulary counts\n22game\n00trade\n00key\n44team\n00play\n11player\n00shiny\n00hatch\n22thank\n11add\naBERT: Bidirectional Encoder Representations From Transformers.\nbLM: language model.\ncTF-IDF: term frequency–inverse document frequency.\nJMIR AI 2023 | vol. 2 | e41205 | p. 17https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nTable 14. Control users most strongly misclassified in each variation of the temporal experiment. Lexical properties of those users’ posts are provided.\nOne depression user per 3 control users (1:3)One depression user per control user (1:1)\nLast 12 weeksLast 12 weeksTime span\nBERT LMBERTa LMbClassifier\nc13c481User\n0.9170.963Depressed probability\n8489258Total length of posts in words\nTopic •• godfood\n• •clove jesus\n•• peopletomorrow\n• •pain good\n•• lifesuspect\nChief TF-IDFc features •• godreply\n• •eat think\n•• wayfood\n• •cat thing\n•• tryclove\n• •pain know\n•• jesussuspect\n• •tooth people\n•• sayvet\n• •water like\nDepressed vocabulary counts\n240people\n180know\n140thing\n30feel\n30time\n20woman\n20go\n80want\n230life\n40relationship\nControl vocabulary counts\n00game\n00trade\n00key\n00team\n30play\n00player\n00shiny\n00hatch\n20thank\n00add\naBERT: Bidirectional Encoder Representations From Transformers.\nbLM: language model.\ncTF-IDF: term frequency–inverse document frequency.\nJMIR AI 2023 | vol. 2 | e41205 | p. 18https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nSentiment Analysis\nA sentiment analysis was then performed to complement the\ntemporal experiment. We present the band-wise changes in\nsentiment for each class (Figures 3 and 4). It is observed that\nnegatively charged posts for depressed users are less frequent\nas we approach the (estimated) diagnosis date, which may be\ndeemed counterintuitive (Figure 3). However, it is also notable\nthat depressed users’ posts were, on average, more negative\nthan those of control users throughout the 24-week period\n(Figure 4). This aligns with previous studies that found a positive\ncorrelation between mental illness and negative sentiments [73].\nWe then sought to establish whether the diagnosis was\nassociated with the sentiment of the post. The results of the\nlogistic regression model (Table 15) indicate that there is a clear\nsignificant association between the diagnosis and the\n“sentimentality” of the post (P<.05), despite no apparent effect\nof temporality. Interestingly, the word count of a post appeared\nas a significant covariate of this model (P=.001), indicating that\nlonger posts are slightly more likely to be classified as\n“sentimental,” irrespective of the depression status of the user.\nTable 16 presents the results of the Multinomial Regression\nModel. Again, all effect size estimates were compatible with\nour inferences on the basis of a simpler logistic model. However,\nthe multinomial analysis gives us an additional perspective: the\neffects of depression diagnosis are similar between positive and\nnegative sentiments, with overlapping CIs statistically\nindistinguishable. This is the case despite the varying effects\nof other covariates, such as word count, which displays\nregression β coefficients of opposite signs in both sentiments\n(more words associate with negative posts, whereas fewer words\nassociate with positive posts).\nFigure 3. Change in the average percentage of positive and negative posts across 6 temporal bands: 0 to 4, 4 to 8, 8 to 12, 12 to 16, 16 to 20, and 20\nto 24 weeks before the estimated diagnosis date (for a control user, this is the estimated diagnosis of its matched depressed user).\nFigure 4. Average percentage of positive and negative posts per temporal band. Temporal bands include 0 to 4, 4 to 8, 8 to 12, 12 to 16, 16 to 20, and\n20 to 24 weeks before the estimated diagnosis date (for a control user, this is the estimated diagnosis of its matched depressed user).\nJMIR AI 2023 | vol. 2 | e41205 | p. 19https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nTable 15. Logistic regression results for predicting whether a post is neutral or not neutral.\nP valueSEOdds ratioβVariable\n<.0010.0351.1770.163Depression diagnosis\n.750.0130.996−0.004Time to diagnosis\n.0010.0121.0410.040Post word count\n.410.0131.0110.011Interaction (diagnosis ×\ntime)\nTable 16. Multinomial regression results for predicting whether a post is positive or negative.\nP valueSEOdds ratioβSentiment and variable\nPositive\n<.0010.0471.2090.190Depression diagnosis\n.370.0161.0150.015Time to diagnosis\n<.0010.0190.932−0.070Post word count\n.0060.0161.0460.045Interaction (diagnosis × time)\nNegative\n<.0010.0411.1630.151Depression diagnosis\n.240.0160.981−0.019Time to diagnosis\n<.0010.0141.1080.103Post word count\n.180.0160.979−0.021Interaction (diagnosis × time)\nDiscussion\nPrincipal Findings\nWe obtained evidence that LMs (particularly BERT-like models)\ncan be used in preemptive mental health detection and analysis\nin longhand forums, even if they have room for improvement.\nIn our preemptive depression detection experiment, depressed\nand control subjects were placed in ratios of 1:1, 1:3, 1:5, and\n1:10. The purpose was to simulate increasingly realistic settings\nin which most users were controls. In the balanced arrangement\nof 1:1, we obtained an F1-score of 0.738 using the MentalBERT\nLM. This is comparable with the works of Eichstaedt et al [14],\nde Choudhury et al [74], and Reece et al [19], who obtained\nF1-scores of 0.660, 0.680, and 0.650, respectively. This study\nprovides evidence that LMs are more effective than existing\nmethods for predicting depression in social media data before\ndiagnosis.\nOur temporal analysis suggested that the final 12 weeks\n(approximately 3 months) of posts before a depressed user’s\nestimated diagnosis date are likely to be the most indicative of\ntheir condition. Another broader interpretation is that LMs do\nnot appear to improve with the addition of more data before\n12-16 weeks. The BERT and MentalBERT obtained F1-scores\nof 0.726 and 0.715, respectively.\nThis is in contrast to a certain extent with the results of\nEichstaedt et al [14], albeit using area under curve scores rather\nthan F1-scores. Six months before the diagnosis date, 0.72 was\nobtained, and 3 months prior, 0.62 was obtained. From these\nresults, it is difficult to draw clear conclusions because the\nresults may be affected by the nature of the data and models\nused.\nWe also observed that posts made during the 4- to 8-week period\nbefore the user’s estimated diagnosis date are also pertinent.\nThey exhibited more negative sentiment than posts made during\nany other 4-week period (up to 24 weeks before their estimated\ndiagnosis date). This finding may be supportive of prior work\nthat distinct changes in mood may be predictive of the onset of\ndepression [75].\nWe were able to corroborate the importance of sentiment in the\ndiscourse of depressed users. We found that depressed users\nare approximately 1.18 times more likely to make a sentimental\npost than nondepressed users.\nLimitations\nConstraints on our investigation primarily concern\nRSDD-Matched, where 70 depressed users make up a small\nsample. However, use 5-fold cross-validation to mitigate this\nand performed different experiments with various numbers of\ncontrol users.\nRSDD-Matched is derived from RSDD and RSDD-Time. As\na result, the diagnosis dates of the users in RSDD-Matched are\nestimates only. Furthermore, posts made in mental health\nsubreddits were deliberately elided from the RSDD and were\nnot available for consideration by our machine classifiers.\nConclusions\nUsing state-of-the-art LMs, this study posits how far the\ndiagnosis of depression in a person with depressive traits can\nbe determined in advance. With this knowledge, it may be\npossible to direct people with depression to physicians much\nJMIR AI 2023 | vol. 2 | e41205 | p. 20https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nsooner than they would otherwise. Moreover, perhaps more\nimportantly, we have shown how these automatic NLP tools\ncan serve to analyze the main traits arising from web-based\nposts.\nWe have also observed that the sentiment exhibited in web-based\nforum postings demonstrates good sensitivity in detecting\ndepressive traits.\nFurther work may include a multimodal approach to the\ndetection of people with depression in web-based forums such\nas Reddit. For example, along with the text of Reddit users’\nposts, we might also consider the subreddits where they have\nupvoted and downvoted posts. The awards received or given\nmay also indicate a user’s mental health. Such a study would,\nof course, be contingent on the ability to synthesize a suitable\ndata set or source an existing one. Moreover, the use of temporal\ninformation such as temporal word embeddings [76] may\nenhance any multimodal approach.\nMethods for gauging the severity of depression in web-based\nforum users should also be investigated. This might involve\nmining language features from user posts and observing how\nthey correlate with ground-truth severity. Features of interest\nmay include terms used in Linguistic Inquiry and Word Count\ndictionaries, sentiment, and emotion [77].\nAcknowledgments\nAFP was supported by the Academy of Medical Sciences “Springboard” award (SBF005 \\\\ 1083). JCC is supported by a UK\nResearch and Innovation (UKRI) Future Leaders Fellowship. The authors thank Professor Nazli Goharian of Georgetown\nUniversity and Dr Andrew Yates of University of Amsterdam for their assistance in supplying Reddit Self-reported Depression\nDiagnosis (RSDD) and RSDD-Time.\nData Availability\nInformation on the RSDD and RSDD-Time data sets used in this study, including their data access procedure, can be found on\nthe web [78].\nConflicts of Interest\nNone declared.\nMultimedia Appendix 1\nReddit Self-reported Depression Diagnosis–Matched metadata and verbose results of the preemptive and temporal experiments.\n[XLSX File (Microsoft Excel File), 956 KB-Multimedia Appendix 1]\nReferences\n1. Global Health Data Exchange (GHDx). Institute of Health Metrics and Evaluation. URL: http://ghdx.healthdata.org/gbd-\nresults-tool?params=gbd-api-2019-permalink/d780dffbe8a381b25e1416884959e88b [accessed 2021-05-01]\n2. Kessler RC, Petukhova M, Sampson NA, Zaslavsky AM, Wittchen H. Twelve-month and lifetime prevalence and lifetime\nmorbid risk of anxiety and mood disorders in the United States. Int J Methods Psychiatr Res 2012 Sep;21(3):169-184 [FREE\nFull text] [doi: 10.1002/mpr.1359] [Medline: 22865617]\n3. Regier DA, Kuhl EA, Kupfer DJ. The DSM-5: classification and criteria changes. World Psychiatry 2013 Jun 04;12(2):92-98\n[FREE Full text] [doi: 10.1002/wps.20050] [Medline: 23737408]\n4. Picardi A, Lega I, Tarsitani L, Caredda M, Matteucci G, Zerella M, SET-DEP Group. A randomised controlled trial of the\neffectiveness of a program for early detection and treatment of depression in primary care. J Affect Disord 2016 Jul\n01;198:96-101 [doi: 10.1016/j.jad.2016.03.025] [Medline: 27015158]\n5. Edwards S, Tinning L, Brown JS, Boardman J, Weinman J. Reluctance to seek help and the perception of anxiety and\ndepression in the United kingdom: a pilot vignette study. J Nerv Ment Dis 2007 Mar;195(3):258-261 [doi:\n10.1097/01.nmd.0000253781.49079.53] [Medline: 17468687]\n6. Wasserman C, Hoven CW, Wasserman D, Carli V, Sarchiapone M, Al-Halabí S, et al. Suicide prevention for youth--a\nmental health awareness program: lessons learned from the Saving and Empowering Young Lives in Europe (SEYLE)\nintervention study. BMC Public Health 2012 Sep 12;12:776 [FREE Full text] [doi: 10.1186/1471-2458-12-776] [Medline:\n22971152]\n7. De Choudhury M, Counts S, Horvitz E. Social media as a measurement tool of depression in populations. In: Proceedings\nof the 5th Annual ACM Web Science Conference. 2013 Presented at: WebSci '13: Web Science 2013; May 2 - 4, 2013;\nParis France [doi: 10.1145/2464464.2464480]\n8. Tadesse MM, Lin H, Xu B, Yang L. Detection of depression-related posts in Reddit social media forum. IEEE Access\n2019;7:44883-44893 [doi: 10.1109/access.2019.2909180]\n9. Malhotra A, Jindal R. Deep learning techniques for suicide and depression detection from online social media: a scoping\nreview. Applied Soft Computing 2022 Nov;130:109713 [doi: 10.1016/j.asoc.2022.109713]\nJMIR AI 2023 | vol. 2 | e41205 | p. 21https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\n10. Zhang T, Schoene AM, Ji S, Ananiadou S. Natural language processing applied to mental illness detection: a narrative\nreview. NPJ Digit Med 2022 Apr 08;5(1):46 [FREE Full text] [doi: 10.1038/s41746-022-00589-7] [Medline: 35396451]\n11. Yates A, Cohan A, Goharian N. Depression and self-harm risk assessment in online forums. In: Proceedings of the 2017\nConference on Empirical Methods in Natural Language Processing. 2017 Presented at: 2017 Conference on Empirical\nMethods in Natural Language Processing; Sep 7–11, 2017; Copenhagen, Denmark [doi: 10.18653/v1/d17-1322]\n12. MacAvaney S, Desmet B, Cohan A, Soldaini L, Yates A, Zirikly A, et al. RSDD-time: temporal annotation of self-reported\nmental health diagnoses. In: Proceedings of the Fifth Workshop on Computational Linguistics and Clinical Psychology:\nFrom Keyboard to Clinic. 2018 Presented at: Fifth Workshop on Computational Linguistics and Clinical Psychology: From\nKeyboard to Clinic; Jun 5, 2018; New Orleans, LA [doi: 10.18653/v1/w18-0618]\n13. Owen D, Camacho-Collados J, Anke L. Towards preemptive detection of depression and anxiety in Twitter. arXiv 2020\nNov [FREE Full text]\n14. Abed-Esfahani P, Howard D, Maslej M, Patel S, Mann V, Goegan S, et al. Transfer learning for depression: early detection\nand severity prediction from social media postings. CAMH. 2019. URL: https://ceur-ws.org/Vol-2380/paper_102.pdf\n[accessed 2022-03-05]\n15. Shah F, Ahmed F, Joy S, Ahmed S, Sadek S, Shil R, et al. Early depression detection from social network using deep\nlearning techniques. In: Proceedings of the IEEE Region 10 Symposium (TENSYMP). 2020 Presented at: IEEE Region\n10 Symposium (TENSYMP); Jun 05-07, 2020; Dhaka, Bangladesh [doi: 10.1109/tensymp50017.2020.9231008]\n16. Eichstaedt JC, Smith RJ, Merchant RM, Ungar LH, Crutchley P, Preoţiuc-Pietro D, et al. Facebook language predicts\ndepression in medical records. Proc Natl Acad Sci U S A 2018 Oct 30;115(44):11203-11208 [FREE Full text] [doi:\n10.1073/pnas.1802331115] [Medline: 30322910]\n17. Ren L, Lin H, Xu B, Zhang S, Yang L, Sun S. Depression detection on reddit with an emotion-based attention network:\nalgorithm development and validation. JMIR Med Inform 2021 Jul 16;9(7):e28754 [FREE Full text] [doi: 10.2196/28754]\n[Medline: 34269683]\n18. Winokur G. Duration of illness prior to hospitalization (onset) in the affective disorders. Neuropsychobiology\n1976;2(2-3):87-93 [doi: 10.1159/000117535] [Medline: 1012452]\n19. Reece AG, Reagan AJ, Lix KL, Dodds PS, Danforth CM, Langer EJ. Forecasting the onset and course of mental illness\nwith Twitter data. Sci Rep 2017 Oct 11;7(1):13006 [FREE Full text] [doi: 10.1038/s41598-017-12961-9] [Medline:\n29021528]\n20. van Beljouw IM, Verhaak PF, Cuijpers P, van Marwijk HW, Penninx BW. The course of untreated anxiety and depression,\nand determinants of poor one-year outcome: a one-year cohort study. BMC Psychiatry 2010 Oct 20;10:86 [FREE Full text]\n[doi: 10.1186/1471-244X-10-86] [Medline: 20961414]\n21. Ghio L, Gotelli S, Marcenaro M, Amore M, Natta W. Duration of untreated illness and outcomes in unipolar depression:\na systematic review and meta-analysis. J Affect Disord 2014 Jan;152-154:45-51 [doi: 10.1016/j.jad.2013.10.002] [Medline:\n24183486]\n22. Agorastos A, Marmar CR, Otte C. Immediate and early behavioral interventions for the prevention of acute and posttraumatic\nstress disorder. Curr Opin Psychiatry 2011 Nov;24(6):526-532 [doi: 10.1097/YCO.0b013e32834cdde2] [Medline: 21941180]\n23. Guntuku SC, Yaden DB, Kern ML, Ungar LH, Eichstaedt JC. Detecting depression and mental illness on social media: an\nintegrative review. Curr Opinion Behavioral Sci 2017 Dec;18:43-49 [doi: 10.1016/j.cobeha.2017.07.005]\n24. SMHD, RSDD, and RSDD-Time Datasets. Georgetown information retrieval lab. URL: https://docs.google.com/forms/d/\ne/1FAIpQLScC-O3MXDd2lZSGqeRHsv1EMVR2xN5WC0cAodsHK3tBOz_FLw/viewform [accessed 2020-11-21]\n25. Zhang Y, Jin R, Zhou Z. Understanding bag-of-words model: a statistical framework. Int J Mach Learn Cyber 2010 Aug\n28;1(1-4):43-52 [doi: 10.1007/s13042-010-0001-0]\n26. Read J. Recognising affect in text using pointwise-mutual information. University of Sussex. 2004 Sep. URL: https:/\n/citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=11185d20f109d28295f4f4ec8a72f33023709137 [accessed\n2022-03-31]\n27. Salton G, Buckley C. Term-weighting approaches in automatic text retrieval. Inform Process Manage 1988 Jan;24(5):513-523\n[doi: 10.1016/0306-4573(88)90021-0]\n28. Lafon P. Sur la variabilité de la fréquence des formes dans un corpus. Mots. Les langages du politique 1980;1(1):127-165\n[doi: 10.3406/mots.1980.1008]\n29. Drouin P. Term extraction using non-technical corpora as a point of leverage. Terminology 2003 Sep 2;9(1):99-115 [doi:\n10.1075/term.9.1.06dro]\n30. Camacho-Collados J, Pilehvar MT, Navigli R. Nasari: integrating explicit knowledge and corpus statistics for a multilingual\nrepresentation of concepts and entities. Artif Intell 2016 Nov;240:36-64 [doi: 10.1016/j.artint.2016.07.005]\n31. Boser B, Guyon I, Vapnik V. A training algorithm for optimal margin classifiers. In: Proceedings of the fifth annual\nworkshop on Computational learning theory. 1992 Presented at: COLT92: 5th Annual Workshop on Computational Learning\nTheory; Jul 27 - 29, 1992; Pittsburgh Pennsylvania USA URL: https://dl.acm.org/doi/proceedings/10.1145/130385 [doi:\n10.1145/130385.130401]\n32. Pirina I, Çöltekin C. Identifying depression on Reddit: the effect of training data. In: Proceedings of the 2018 EMNLP\nWorkshop SMM4H: The 3rd Social Media Mining for Health Applications Workshop & Shared Task. 2018 Presented at:\nJMIR AI 2023 | vol. 2 | e41205 | p. 22https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\n2018 EMNLP Workshop SMM4H: The 3rd Social Media Mining for Health Applications Workshop & Shared Task; Oct,\n2018; Brussels, Belgium [doi: 10.18653/v1/w18-5903]\n33. Salton G, Wong A, Yang CS. A vector space model for automatic indexing. Commun ACM 1975 Nov;18(11):613-620\n[doi: 10.1145/361219.361220]\n34. Turian J, Ratinov L, Bengio Y. Word representations: a simple and general method for semi-supervised learning. In:\nProceedings of the 48th Annual Meeting of the Association for Computational Linguistics. 2010 Presented at: 48th Annual\nMeeting of the Association for Computational Linguistics; Jul 11 - 16, 2010; Uppsala Sweden URL: https://aclanthology.\norg/P10-1040.pdf\n35. Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, et al. Scikit-learn: machine learning in python.\narXiv 2012 Jan 2 [doi: 10.3389/fninf.2014.00014]\n36. Pennington J, Socher R, Manning C. Glove: global vectors for word representation. In: Proceedings of the 2014 Conference\non Empirical Methods in Natural Language Processing (EMNLP). 2014 Presented at: 2014 Conference on Empirical\nMethods in Natural Language Processing (EMNLP); Oct, 2014; Doha, Qatar [doi: 10.3115/v1/d14-1162]\n37. Joachims T. Text categorization with Support Vector Machines: learning with many relevant features. In: Machine Learning:\nECML-98. Berlin, Heidelberg: Springer; 1998. [doi: 10.1007/BFb0026683]\n38. Zhang W, Yoshida T, Tang X. Text classification based on multi-word with support vector machine. Knowl Based Syst\n2008 Dec;21(8):879-886 [doi: 10.1016/j.knosys.2008.03.044]\n39. Luss R, D’Aspremont A. Predicting abnormal returns from news using text classification. Quant Finance 2012 Mar\n29;15(6):999-1012 [doi: 10.1080/14697688.2012.672762]\n40. Jardino M. Multilingual stochastic n-gram class language models. In: Proceedings of the IEEE International Conference\non Acoustics, Speech, and Signal Processing Conference Proceedings. 1996 Presented at: IEEE International Conference\non Acoustics, Speech, and Signal Processing Conference Proceedings; May 9, 1996; Atlanta, GA, USA [doi:\n10.1109/icassp.1996.540315]\n41. Vig J, Belinkov Y. Analyzing the structure of attention in a transformer language model. In: Proceedings of the 2019 ACL\nWorkshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP. 2019 Presented at: 2019 ACL Workshop\nBlackboxNLP: Analyzing and Interpreting Neural Networks for NLP; Aug 1, 2019; Florence, Italy [doi:\n10.18653/v1/w19-4808]\n42. Shen J, Rudzicz F. Detecting anxiety through reddit. In: Proceedings of the Fourth Workshop on Computational Linguistics\nand Clinical Psychology — From Linguistic Signal to Clinical Reality. 2017 Presented at: Fourth Workshop on Computational\nLinguistics and Clinical Psychology — From Linguistic Signal to Clinical Reality; Aug 3, 2017; Vancouver, BC [doi:\n10.18653/v1/w17-3107]\n43. Burdisso SG, Errecalde M, Montes-y-Gómez M. Using text classification to estimate the depression level of reddit users.\nJ Comput Sci Technol 2021 Apr 17;21(1):e1 [doi: 10.24215/16666038.21.e1]\n44. Devlin J, Chang M, Lee K, Toutanova K. BERT: pre-training of deep bidirectional transformers for language understanding.\nIn: Proceedings of NAACL-HLT 2019. 2019 Presented at: NAACL-HLT 2019; Jun 2 - 7, 2019; Minneapolis, Minnesota\nURL: https://arxiv.org/abs/1810.04805\n45. Lan Z, Chen M, Goodman S, Gimpel K, Sharma P, Soricut R. Albert: a lite BERT for self-supervised learning of language\nrepresentations. In: Proceedings of the 8th International Conference on Learning Representations, ICLR 2020. 2020 Presented\nat: 8th International Conference on Learning Representations, ICLR 2020; Apr 26-30, 2020; Addis Ababa, Ethiopia URL:\nhttps://arxiv.org/abs/1909.11942\n46. Lee J, Yoon W, Kim S, Kim D, Kim S, So CH, et al. BioBERT: a pre-trained biomedical language representation model\nfor biomedical text mining. Bioinformatics 2020 Feb 15;36(4):1234-1240 [FREE Full text] [doi:\n10.1093/bioinformatics/btz682] [Medline: 31501885]\n47. Beltagy I, Peters M, Cohan A. Longformer: the long-document transformer. arXiv 2020 [FREE Full text]\n48. Ji S, Zhang T, Ansari L, Fu J, Tiwari P, Cambria E. Mentalbert: publicly available pretrained language models for mental\nhealthcare. In: Proceedings of the Thirteenth Language Resources and Evaluation Conference. 2022 Presented at: Thirteenth\nLanguage Resources and Evaluation Conference; Jun 20-25, 2022; Marseille, France [doi:\n10.1016/b978-0-323-90118-5.00006-0]\n49. Yu X, Hu W, Lu S, Sun X, Yuan Z. BioBERT based named entity recognition in electronic medical record. In: Proceedings\nof the 10th International Conference on Information Technology in Medicine and Education (ITME). 2019 Presented at:\n10th International Conference on Information Technology in Medicine and Education (ITME); Aug 23-25, 2019; Qingdao,\nChina [doi: 10.1109/itme.2019.00022]\n50. Alghanmi I, Espinosa-Anke L, Schockaert S. Interpreting patient descriptions using distantly supervised similar case\nretrieval. In: Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information\nRetrieval. 2022 Presented at: SIGIR '22: The 45th International ACM SIGIR Conference on Research and Development\nin Information Retrieval; Jul 11 - 15, 2022; Madrid Spain [doi: 10.1145/3477495.3532003]\n51. Bai Y, Zhou X. Automatic detecting for health-related twitter data with biobert. In: Proceedings of the Fifth Social Media\nMining for Health Applications Workshop & Shared Task. 2020 Presented at: Fifth Social Media Mining for Health\nApplications Workshop & Shared Task; Online; Barcelona, Spain URL: https://aclanthology.org/2020.smm4h-1.10\nJMIR AI 2023 | vol. 2 | e41205 | p. 23https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\n52. González-Carvajal S, Garrido-Merchán E. Comparing BERT against traditional machine learning text classification. arXiv\n2021 [FREE Full text]\n53. Clavié B, Alphonsus M. The unreasonable effectiveness of the baseline: discussing SVMs in legal text classification. In:\nVolume 346: Legal Knowledge and Information Systems. Amsterdam: IOS Press; 2021. URL: https://tinyurl.com/4dtkv9rt\n54. Simple transformers homepage. Simple Transformers. URL: https://simpletransformers.ai/ [accessed 2021-01-04]\n55. Wolf T, Debut L, Sanh V, Chaumond J, Delangue C, Moi A, et al. Transformers: state-of-the-art natural language processing.\nIn: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations.\n2020 Presented at: 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations; Oct,\n2020; Online [doi: 10.18653/v1/2020.emnlp-demos.6]\n56. Classification specifics. Simple Transformers. URL: https://simpletransformers.ai/docs/classification-specifics/#dealing-with\n-long-text [accessed 2021-04-15]\n57. Wang X, Zhang C, Ji Y, Sun L, Wu L, Bao Z. A depression detection model based on sentiment analysis in micro-blog\nsocial network. In: Trends and Applications in Knowledge Discovery and Data Mining. Berlin, Heidelberg: Springer; 2013.\n[doi: 10.1007/978-3-642-40319-4_18]\n58. Hassan A, Hussain J, Hussain M, Sadiq M, Lee S. Sentiment analysis of social networking sites (SNS) data using machine\nlearning approach for the measurement of depression. In: Proceedings of the 2017 International Conference on Information\nand Communication Technology Convergence (ICTC). 2017 Presented at: 2017 International Conference on Information\nand Communication Technology Convergence (ICTC); Oct 18-20, 2017; Jeju, Korea (South) [doi: 10.1109/ictc.2017.8190959]\n59. Stephen JJ, Prabhu P. Detecting the magnitude of depression in Twitter users using sentiment analysis. Int J Electrical\nComput Eng 2019 Aug 01;9(4):3247 [doi: 10.11591/ijece.v9i4.pp3247-3255]\n60. Liu T, Meyerhoff J, Eichstaedt JC, Karr CJ, Kaiser SM, Kording KP, et al. The relationship between text message sentiment\nand self-reported depression. J Affect Disord 2022 Apr 01;302:7-14 [doi: 10.1016/j.jad.2021.12.048] [Medline: 34963643]\n61. Pota M, Ventura M, Catelli R, Esposito M. An effective BERT-based pipeline for Twitter sentiment analysis: a case study\nin Italian. Sensors (Basel) 2020 Dec 28;21(1):133 [FREE Full text] [doi: 10.3390/s21010133] [Medline: 33379231]\n62. Hutto C, Gilbert E. VADER: a parsimonious rule-based model for sentiment analysis of social media text. Proc Int AAAI\nConf Web Social Media 2014 May 16;8(1):216-225 [doi: 10.1609/icwsm.v8i1.14550]\n63. Nguyen D, Vu T, Nguyen A. BERTweet: a pre-trained language model for English Tweets. In: Proceedings of the 2020\nConference on Empirical Methods in Natural Language Processing: System Demonstrations. 2020 Presented at: Conference\non Empirical Methods in Natural Language Processing: System Demonstrations; Nov 16-20, 2020; Online [doi:\n10.18653/v1/2020.emnlp-demos.2]\n64. Bates D, Mächler M, Bolker B, Walker S. Fitting linear mixed-effects models using lme4. J Stat Softw 2015;67(1):1-48\n[doi: 10.18637/jss.v067.i01]\n65. Wood SN, Pya N, Säfken B. Smoothing parameter and model selection for general smooth models. J Am Statistical Assoc\n2017 Jan 04;111(516):1548-1563 [doi: 10.1080/01621459.2016.1180986]\n66. The R project for statistical computing. CRAN R Project. URL: https://www.r-project.org/ [accessed 2022-07-13]\n67. Matloff N. Statistical Regression and Classification From Linear Models to Machine Learning. Boca Raton, Florida, United\nStates: CRC Press; 2017. URL: https://tinyurl.com/4sfjbp9t\n68. van der Brug W. Issue ownership and party choice. Electoral Stud 2004 Jun;23(2):209-233 [doi:\n10.1016/s0261-3794(02)00061-6]\n69. Guo H, Zhi W, Liu H, Xu M. Imbalanced learning based on logistic discrimination. Comput Intell Neurosci\n2016;2016:5423204 [FREE Full text] [doi: 10.1155/2016/5423204] [Medline: 26880877]\n70. Sokolova M, Japkowicz N, Szpakowicz S. Beyond accuracy, F-Score and ROC: a family of discriminant measures for\nperformance evaluation. In: AI 2006: Advances in Artificial Intelligence. Berlin, Heidelberg: Springer; 2006. [doi:\n10.1007/11941439_114]\n71. Blei D, Ng A, Jordan M. Latent dirichlet allocation. J Mach Learn Res 2003 Mar 1;3:993-1022 [FREE Full text]\n72. Mallet: machine learning for language toolkit homepage. Mallet: MAchine Learning for LanguagE Toolkit. URL: http:/\n/mallet.cs.umass.edu [accessed 2022-04-19]\n73. Howes C, Purver M, McCabe R. Linguistic indicators of severity and progress in online text-based therapy for depression.\nIn: Proceedings of the Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical\nReality. 2014 Presented at: Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to\nClinical Reality; Jun, 2014; Baltimore, Maryland, USA [doi: 10.3115/v1/w14-3202]\n74. de Choudhury M, Gamon M, Counts S, Horvitz E. Predicting depression via social media. Proc Int AAAI Conference Web\nSocial Media 2021 Aug 03;7(1):128-137 [doi: 10.1609/icwsm.v7i1.14432]\n75. van de Leemput IA, Wichers M, Cramer AO, Borsboom D, Tuerlinckx F, Kuppens P, et al. Critical slowing down as early\nwarning for the onset and termination of depression. Proc Natl Acad Sci U S A 2014 Jan 07;111(1):87-92 [FREE Full text]\n[doi: 10.1073/pnas.1312114110] [Medline: 24324144]\n76. Couto M, Pérez A, Parapar J. Temporal word embeddings for early detection of signs of depression. In: Proceedings of the\nCIRCLE (Joint Conference of The Information Retrieval Communities in Europe). 2022 Presented at: CIRCLE (Joint\nJMIR AI 2023 | vol. 2 | e41205 | p. 24https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX\nConference of The Information Retrieval Communities in Europe); Jul 04-07 2022; Toulouse, Fr URL: https://ceur-ws.org/\nVol-3178/CIRCLE_2022_paper_03.pdf\n77. Tausczik YR, Pennebaker JW. The psychological meaning of words: LIWC and computerized text analysis methods. J\nLang Social Psychol 2009 Dec 08;29(1):24-54 [doi: 10.1177/0261927x09351676]\n78. Reddit Self-reported Depression Diagnosis (RSDD) dataset. Georgetown University. URL: https://ir.cs.georgetown.edu/\nresources/rsdd.html [accessed 2023-02-28]\nAbbreviations\nALBERT: A Lite Bidirectional Encoder Representations from Transformers\nBERT: Bidirectional Encoder Representations from Transformers\nLM: language model\nMDD: major depressive disorder\nNLP: natural language processing\nRSDD: Reddit Self-reported Depression Diagnosis\nSVM: support vector machine\nTF-IDF: term frequency–inverse document frequency\nEdited by K El Emam; submitted 23.07.22; peer-reviewed by A Teles, T Zhang; comments to author 11.11.22; revised version received\n06.01.23; accepted 15.01.23; published 24.03.23\nPlease cite as:\nOwen D, Antypas D, Hassoulas A, Pardiñas AF, Espinosa-Anke L, Collados JC\nEnabling Early Health Care Intervention by Detecting Depression in Users of Web-Based Forums using Language Models: Longitudinal\nAnalysis and Evaluation\nJMIR AI 2023;2:e41205\nURL: https://ai.jmir.org/2023/1/e41205\ndoi: 10.2196/41205\nPMID: 37525646\n©David Owen, Dimosthenis Antypas, Athanasios Hassoulas, Antonio F Pardiñas, Luis Espinosa-Anke, Jose Camacho Collados.\nOriginally published in JMIR AI (https://ai.jmir.org), 24.03.2023. This is an open-access article distributed under the terms of\nthe Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use,\ndistribution, and reproduction in any medium, provided the original work, first published in JMIR AI, is properly cited. The\ncomplete bibliographic information, a link to the original publication on https://www.ai.jmir.org/, as well as this copyright and\nlicense information must be included.\nJMIR AI 2023 | vol. 2 | e41205 | p. 25https://ai.jmir.org/2023/1/e41205\n(page number not for citation purposes)\nOwen et alJMIR AI\nXSL•FO\nRenderX",
  "topic": "Machine learning",
  "concepts": [
    {
      "name": "Machine learning",
      "score": 0.5890036225318909
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5152257084846497
    },
    {
      "name": "Major depressive disorder",
      "score": 0.5121445655822754
    },
    {
      "name": "Computer science",
      "score": 0.4530593156814575
    },
    {
      "name": "Depression (economics)",
      "score": 0.43323269486427307
    },
    {
      "name": "Psychology",
      "score": 0.42921769618988037
    },
    {
      "name": "Mental health",
      "score": 0.4207627475261688
    },
    {
      "name": "Natural language processing",
      "score": 0.34979885816574097
    },
    {
      "name": "Cognition",
      "score": 0.3462543487548828
    },
    {
      "name": "Psychiatry",
      "score": 0.31541258096694946
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Macroeconomics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I79510175",
      "name": "Cardiff University",
      "country": "GB"
    }
  ]
}