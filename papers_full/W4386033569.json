{
  "title": "Large Language Models in Hematology Case Solving: A Comparative Study of ChatGPT-3.5, Google Bard, and Microsoft Bing",
  "url": "https://openalex.org/W4386033569",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2099091421",
      "name": "Amita Kumari",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2020758011",
      "name": "Anita Kumari",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2133946663",
      "name": "Amita Singh",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2726628408",
      "name": "Sanjeet K. Singh",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2337313780",
      "name": "Ayesha Juhi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5034041256",
      "name": "Anup Kumar D Dhanvijay",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3118565030",
      "name": "Mohammed Jaffer Pinjar",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2556512418",
      "name": "Himel Mondal",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4313702900",
    "https://openalex.org/W2996219887",
    "https://openalex.org/W4382020836",
    "https://openalex.org/W4381185932",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4376640725",
    "https://openalex.org/W4385900159",
    "https://openalex.org/W4362510886",
    "https://openalex.org/W4285292745",
    "https://openalex.org/W2327037637",
    "https://openalex.org/W4380356334",
    "https://openalex.org/W4368367885",
    "https://openalex.org/W4379376212",
    "https://openalex.org/W4382632493",
    "https://openalex.org/W4376872703",
    "https://openalex.org/W4382774929"
  ],
  "abstract": null,
  "full_text": "Review began\n 08/07/2023 \nReview ended\n 08/15/2023 \nPublished\n 08/21/2023\n© Copyright \n2023\nKumari et al. This is an open access article\ndistributed under the terms of the Creative\nCommons Attribution License CC-BY 4.0.,\nwhich permits unrestricted use, distribution,\nand reproduction in any medium, provided\nthe original author and source are credited.\nLarge Language Models in Hematology Case\nSolving: A Comparative Study of ChatGPT-3.5,\nGoogle Bard, and Microsoft Bing\nAmita Kumari \n \n, \nAnita Kumari \n \n, \nAmita Singh \n \n, \nSanjeet K. Singh \n \n, \nAyesha Juhi \n \n, \nAnup Kumar D.\nDhanvijay \n \n, \nMohammed Jaffer Pinjar \n \n, \nHimel Mondal \n1.\n Physiology, All India Institute of Medical Sciences, Deoghar, Deoghar, IND \n2.\n Pathology, All India Institute of\nMedical Sciences, Deoghar, Deoghar, IND \n3.\n Physiology, All India Institute of Medical Sciences Deoghar, Deoghar, IND\nCorresponding author: \nHimel Mondal, \nhimelmkcg@gmail.com\nAbstract\nBackground\nLarge language models (LLMs), such as ChatGPT-3.5, Google Bard, and Microsoft Bing, have shown\npromising capabilities in various natural language processing (NLP) tasks. However, their performance and\naccuracy in solving domain-specific questions, particularly in the field of hematology, have not been\nextensively investigated.\nObjective\nThis study aimed to explore the capability of LLMs, namely, ChatGPT-3.5, Google Bard, and Microsoft Bing\n(Precise), in solving hematology-related cases and comparing their performance.\nMethods\nThis was a cross-sectional study conducted in the Department of Physiology and Pathology, All India\nInstitute of Medical Sciences, Deoghar, Jharkhand, India. We curated a set of 50 cases on hematology\ncovering a range of topics and complexities. The dataset included queries related to blood disorders,\nhematologic malignancies, laboratory test parameters, calculations, and treatment options. Each case and\nrelated question was prepared with a set of correct answers to compare with. We utilized ChatGPT-3.5,\nGoogle Bard Experiment, and Microsoft Bing (Precise) for question-answering tasks. The answers were\nchecked by two physiologists and one pathologist. They rated the answers on a rating scale from one to five.\nThe average score of the three models was compared by Friedman’s test with Dunn’s post-hoc test. The\nperformance of the LLMs was compared with a median of 2.5 by a one-sample median test as the curriculum\nfrom which the questions were curated has a 50% pass grade.\nResults\nThe scores among the three LLMs were significantly different (p-value < 0.0001) with the highest score by\nChatGPT (3.15±1.19), followed by Bard (2.23±1.17) and Bing (1.98±1.01). The score of ChatGPT was\nsignificantly higher than 50% (p-value = 0.0004), Bard's score was close to 50% (p-value = 0.38), and Bing's\nscore was significantly lower than the pass score (p-value = 0.0015).\nConclusion\nThe LLMs reveal significant differences in solving case vignettes in hematology. ChatGPT exhibited the\nhighest score, followed by Google Bard and Microsoft Bing. The observed performance trends suggest that\nChatGPT holds promising potential in the medical domain. However, none of the models was capable of\nanswering all questions accurately. Further research and optimization of language models can offer valuable\ncontributions to healthcare and medical education applications.\nCategories:\n Medical Education, Healthcare Technology, Hematology\nKeywords:\n ai and robotics in healthcare, microsoft bing, google bard, chatgpt, pathology, hematology, hematologic\ndiseases, natural language processing, search engine, pathologists\nIntroduction\nHematology, the specialized field of medicine focused on the study of blood and its associated disorders,\nholds paramount importance in the realm of healthcare. Precise diagnosis and effective management of\nhematologic conditions, such as anemia, leukemia, and coagulopathies, are imperative for optimizing\npatient outcomes and improving overall public health \n[1]\n.\nThe advent of artificial intelligence (AI) and natural language processing (NLP) has led to the development\n1\n1\n1\n2\n1\n3\n1\n1\n \n Open Access Original\nArticle\n \nDOI:\n 10.7759/cureus.43861\nHow to cite this article\nKumari A, Kumari A, Singh A, et al. (August 21, 2023) Large Language Models in Hematology Case Solving: A Comparative Study of ChatGPT-3.5,\nGoogle Bard, and Microsoft Bing. Cureus 15(8): e43861. \nDOI 10.7759/cureus.43861\nof large language models (LLMs), which exhibit exceptional capabilities in processing and comprehending\nnatural language data \n[2]\n. Prominent among these LLMs are ChatGPT, Google Bard, and Microsoft Bing,\nwhich have garnered substantial interest due to their capacity to comprehend textual information and\ngenerate contextually relevant responses \n[3]\n. These models have demonstrated various levels of accuracy in\nperforming medical examinations, solving complex medical issues, or interpreting radiology reports\n[4,5,6,7,8]\n.\nNevertheless, their efficacy and suitability for domain-specific applications, particularly in addressing\nmedical inquiries pertaining to hematology, remain relatively unexplored. The intricate nature of\nhematology, characterized by a lexicon replete with specialized terminology and a wide array of conditions\nwith nuanced diagnostic and therapeutic considerations, necessitates meticulous scrutiny of language\nmodels' performance in this context.\nThe present study aimed to address this gap in knowledge by exploring the capability of LLMs in solving\nhematology cases and conducting a comparative analysis of three LLMs, namely, ChatGPT, Google Bard, and\nMicrosoft Bing.\nMaterials And Methods\nStudy type and settings\nThis was a cross-sectional study conducted in the Department of Physiology and Pathology, All India\nInstitute of Medical Sciences, Deoghar, Jharkhand, India. The data were collected from three LLMs, namely,\nGoogle Bard Experiment (https://bard.google.com/), Microsoft Bing Precise Conversation based on GPT-4\n(https://www.bing.com/), and ChatGPT-3.5 Free Research version (https://chat.openai.com/), available free\nto any registered users. We used the free version of the LLMs. Henceforth in the article, the models are\nmentioned as Bard, Bing, and ChatGPT.\nHematology cases\nA set of hematology-related cases covering various topics and complexities were carefully designed by\nsubject matter experts. These questions encompassed laboratory calculations, disease interpretations, and\nother relevant aspects of hematology. A total of 50 cases and related questions were made, and content\nvalidity was checked by two experts of curriculum design. An example question and a part of the answer\ngenerated from Google Bard are shown in Figure \n1\n.\nFIGURE\n 1: An example of a question and a part of the answer generated\nfrom Google Bard\nScreenshot captured from Google Bard (https://bard.google.com). The image in the screenshot is that of the\ncorresponding author.\nAnother example question and a part of the answer generated from Microsoft Bing are shown in Figure \n2\n.\n2023 Kumari et al. Cureus 15(8): e43861. DOI 10.7759/cureus.43861\n2\n of \n7\nFIGURE\n 2: An example of a question and a part of the answer generated\nfrom Microsoft Bing Chat\nScreenshot captured from Microsoft Bing (https://www.bing.com/).\nAnother example is shown in Figure \n3\n, where the response was generated from ChatGPT-3.5.\nFIGURE\n 3: An example of a question and a part of the answer generated\nfrom ChatGPT-3.5\nScreenshot captured from ChatGPT (https://chat.openai.com/).\nData collection from LLMs\nThe questions were asked to three LLMs, namely, Bard, Bing, and ChatGPT, on July 30, 2023 to get answers.\n2023 Kumari et al. Cureus 15(8): e43861. DOI 10.7759/cureus.43861\n3\n of \n7\nGenerated answers were stored for further analysis. The answers were coded and blinded to the raters to\nreduce bias.\nAssessing accuracy by three raters\nTo assess the accuracy of the LLMs' responses, three independent raters, with expertise in hematology and\nmedical education, were recruited. The raters evaluated each LLM-generated answer and scored them based\non their correctness with an accuracy score ranging from 1 to 5. The detailed scoring method was as follows:\n5 - Highly accurate: The answer provided by the AI is thoroughly accurate, aligning perfectly with clinical\nknowledge and best practices.\n4 - Moderately accurate: The answer provided by the AI is mostly accurate, with only minor discrepancies\nthat do not significantly impact its clinical reliability.\n3 - Somewhat accurate: The answer provided by the AI contains several inaccuracies that may require\nclarification or verification by a medical professional.\n2 - Slightly accurate: The answer provided by the AI has noticeable inaccuracies, and its clinical reliability is\nquestionable without substantial correction.\n1 - Inaccurate: The answer provided by the AI is fundamentally incorrect and could pose serious risks to\npatient care if relied upon without thorough review and correction.\nData analysis\nThe obtained raters' evaluations were tested for normality by the Shapiro-Wilk test. The data were found not\nto follow normal distributions. Hence, we used nonparametric tests. The data were presented in mean,\nstandard deviation (SD), median, first quartile (Q1), and third quartile (Q3) \n[9]\n. The average (average of the\nthree raters) score awarded to the three LLMs was compared by Friedman’s test with Dunn’s post-hoc\nanalysis. The average score was also compared by a one-sample Wilcoxon signed-rank test with a\nhypothetical value of 2.5 (50% score is the passing score in the curriculum of hematology from where the\ncases and questions were framed). Intraclass correlation coefficient (ICC) was calculated to determine the\nagreement level among the raters in assessing the accuracy of the LLMs' responses \n[10]\n. We used IBM SPSS\nStatistics for Windows, version 20 (released 2011; IBM Corp., Armonk, New York, United States) for\nstatistical analysis. A p-value < 0.05 was considered statistically significant.\nResults\nA total of 50 cases were analyzed by the three raters. The scores among the three LLMs were significantly\ndifferent (p-value < 0.0001), with the highest score by ChatGPT (3.15±1.19), followed by Bard (2.23±1.17) and\nBing (1.98±1.01).\nThe median score with 95% confidence interval (CI) is shown in Figure \n4\n. In the post-hoc analysis, Bard\nversus Bing did not show any significant difference (p-value = 0.33). However, Bard versus ChatGPT (p-value\n< 0.0001) and Bing versus ChatGPT (p-value < 0.0001) showed significant differences.\n2023 Kumari et al. Cureus 15(8): e43861. DOI 10.7759/cureus.43861\n4\n of \n7\nFIGURE\n 4: Average scores of Bard, Bing, and ChatGPT in the answers\nto the hematology questions\nThe bar and whisker indicate a median score with a 95% confidence interval. The comparison was done by\nFriedman’s test (non-parametric analysis of variance (ANOVA)) with Dunn’s post-hoc analysis.\nThe median and first quartiles/third quartiles were as follows: Bard 2.67 (1.67/3), Bing 2 (1.33/2.67), and ChatGPT\n3.67 (3/4).\nThe scores of the three raters are shown in Table \n1\n. The scores among the raters showed a good to excellent\nlevel of reliability.\nLLM\nCentral tendency\nRater 1\nRater 2\nRater 3\nICC, p-value\nGoogle Bard\nMean±SD\n1.88±1.19\n2.12±1.41\n1.94±1.11\n0.83, <0.0001*\nMedian (Q1-Q3)\n3 (1-4)\n2 (0.25 - 3)\n2 (1-3)\nMicrosoft Bing\nMean±SD\n2.52±1.42\n2.02±1.41\n2.16±1.18\n0.78, <0.0001*\nMedian (Q1-Q3)\n2 (1-3)\n2 (1-3)\n2 (1-3)\nChatGPT-3.5\nMean±SD\n3.4±1.26\n3.02±1.25\n3.02±1.27\n0.98, <0.0001*\nMedian (Q1-Q3)\n4 (3.2-4)\n3 (3-4)\n3 (3-4)\nTABLE\n 1: Scores of the answers by the three LLMs as rated by the three raters\n*Statistically significant p-value of the intraclass correlation coefficient (ICC) \n[10]\nLLM: large language model, SD: standard deviation\nInterpretation of ICC: <0.5 = poor reliability, 0.5-0.75 = moderate reliability, 0.75-0.9 = good reliability, >0.90 = excellent reliability \n[9]\nWhen we conducted the Wilcoxon signed-rank test with a hypothetical value of 2.5 (the course from where\nthe questions were prepared needs a 50% score to pass), we found that ChatGPT’s score was significantly\nhigher than the passing score (p-value = 0.0004). The score of Bard was close to 50% (p-value = 0.38).\nHowever, Bing’s score was significantly lower than the passing score (p-value = 0.0015).\nDiscussion\nWe found that ChatGPT performed better than the other two LLMs in problem-solving abilities in\n2023 Kumari et al. Cureus 15(8): e43861. DOI 10.7759/cureus.43861\n5\n of \n7\nhematology. These findings emphasize the importance of selecting the most appropriate language model\nbased on its performance for specific tasks, enabling more effective problem-solving in various scenarios.\nThe LLMs are evolving day by day. Hence, further studies are required in the future to fully explore their\ncapability \n[11]\n. When we tested the models' performance with a minimum passing score (50%) of the\ncurriculum, we found ChatGPT to pass it with the highest margin, indicating that it consistently\noutperformed the threshold. Meanwhile, Bard's score showed no significant difference from the passing\nscore, suggesting that it performed at a level close to the passing requirement. By contrast, Bing's score was\nsignificantly lower than the passing score, indicating that it fell short of meeting the passing standard. These\nresults highlight the varying proficiency levels of the language models in achieving accuracy with the same\nquestions at the same time.\nBased on the finding that laboratory calculations or interpretations for hematology diseases are weak in\nmany cases, caution should be exercised when considering the use of LLMs in medical education. While\nLLMs can provide valuable information and learning resources, their limitations in accurately handling\nlaboratory data for hematology diseases warrant careful supervision and validation by qualified medical\neducators. In the context of healthcare, where precision and accuracy are crucial, the use of LLMs for making\nclinical decisions or providing direct patient care should be approached with caution. LLMs can serve as\nhelpful tools for information retrieval and initial insights, but they should not replace the expertise and\nclinical judgment of healthcare professionals. As technology advances and LLMs undergo further\nrefinement, they may hold more promise for enhancing medical education and supporting healthcare, but\ntheir current limitations necessitate prudent utilization. Some of the potential use of LLMs are summarized\nin Table \n2\n \n[12,13,14,15,16]\n.\nCategory\nBrief\nStudents\nLLMs can act as virtual tutors, helping medical students access supplementary information, explanations, and case studies to reinforce their learning.\nHealthcare professionals\nDoctors, nurses, and other healthcare professionals can use LLMs to stay updated with the latest medical research, treatment guidelines, and evidence-based practices.\nPatients\nLLMs can be used in health applications or chatbots to provide basic medical information and answer common health-related queries for patients.\nResearchers\nLLMs can assist researchers in searching for relevant literature, summarizing papers, and extracting key insights from a vast amount of medical literature.\nRemote health assistants\nLLMs can be particularly valuable in areas with limited access to healthcare resources, where individuals can seek initial medical advice and information.\nTABLE\n 2: Potential audience and brief where large language models (LLMs) can help\nThe substantial agreement among the raters may be attributed to several potential reasons. The raters were\nprovided with clear and well-defined evaluation criteria, ensuring a consistent understanding of the scoring\nmethod. Their familiarity and expertise in assessing hematology-related questions could have contributed to\nmore aligned judgments. However, in-depth analysis and examination of the specific data and rater\nfeedback would be necessary to fully understand the underlying factors influencing the agreement among\nthe raters.\nLimitations\nThe study has several limitations that should be considered when interpreting the findings. The sample size\nof hematology questions and LLM responses was relatively small, potentially impacting the generalizability\nof the results. Rater bias and subjectivity in evaluating LLM responses might have introduced variability.\nOnly three models were tested. The cross-sectional design offers only a snapshot of LLM performance, and\nreal-world applications may present additional challenges. Despite these limitations, this study provides\nvaluable insights into LLM accuracy in hematology questions and underscores the need for further research\nand exploration of ethical considerations in utilizing LLMs in medical education and healthcare.\nConclusions\nThere were variations in the LLM performance, with ChatGPT demonstrating the highest accuracy, Bard\nexhibiting moderate accuracy, and Bing showing comparatively lower accuracy in answering questions of\nhematology. While LLMs hold promise as valuable tools for medical education, caution is warranted in their\nuse, considering their limitations in handling complex medical nuances and potential inaccuracies. This\nstudy emphasizes the need for continuous refinement and validation of LLMs for reliable healthcare\napplications.\nAdditional Information\nDisclosures\n2023 Kumari et al. Cureus 15(8): e43861. DOI 10.7759/cureus.43861\n6\n of \n7\nHuman subjects:\n All authors have confirmed that this study did not involve human participants or tissue.\nAnimal subjects:\n All authors have confirmed that this study did not involve animal subjects or tissue.\nConflicts of interest:\n In compliance with the ICMJE uniform disclosure form, all authors declare the\nfollowing: \nPayment/services info:\n All authors have declared that no financial support was received from\nany organization for the submitted work. \nFinancial relationships:\n All authors have declared that they have\nno financial relationships at present or within the previous three years with any organizations that might\nhave an interest in the submitted work. \nOther relationships:\n All authors have declared that there are no\nother relationships or activities that could appear to have influenced the submitted work.\nAcknowledgements\nThe corresponding author would like to thank Sarika Mondal and Ahana Aarshi for their moral support by\nsacrificing their family time during data analysis, visualization, and drafting of the manuscript. The\nlanguage and grammar were edited with the help of ChatGPT-3.5 free research version (August 3, 2023\nversion) and Grammarly free version browser extension.\nReferences\n1\n. \nObstfeld AE: \nHematology and machine learning\n. J Appl Lab Med. 2023, 8:129-44. \n10.1093/jalm/jfac108\n2\n. \nWang J, Deng H, Liu B, et al.: \nSystematic evaluation of research progress on natural language processing in\nmedicine over the past 20 years: bibliometric study on PubMed\n. J Med Internet Res. 2020, 22:e16816.\n10.2196/16816\n3\n. \nAgarwal M, Sharma P, Goswami A: \nAnalysing the applicability of ChatGPT, Bard, and Bing to generate\nreasoning-based multiple-choice questions in medical physiology\n. Cureus. 2023, 15:e40977.\n10.7759/cureus.40977\n4\n. \nKumah-Crystal Y, Mankowitz S, Embi P, Lehmann CU: \nChatGPT and the clinical informatics board\nexamination: the end of unproctored maintenance of certification?\n. J Am Med Inform Assoc. 2023,\n10.1093/jamia/ocad104\n5\n. \nKung TH, Cheatham M, Medenilla A, et al.: \nPerformance of ChatGPT on USMLE: potential for AI-assisted\nmedical education using large language models\n. PLOS Digit Health. 2023, 2:e0000198.\n10.1371/journal.pdig.0000198\n6\n. \nBhayana R, Krishna S, Bleakney RR: \nPerformance of ChatGPT on a radiology board-style examination:\ninsights into current strengths and limitations\n. Radiology. 2023, 307:e230582. \n10.1148/radiol.230582\n7\n. \nDhanvijay A D, Pinjar M, Dhokane N, et al.: \nPerformance of large language models (ChatGPT, Bing Search,\nand Google Bard) in solving case vignettes in physiology\n. Cureus. 2023, 15:e42972. \n10.7759/cureus.42972\n8\n. \nGhosh A, Bir A: \nEvaluating ChatGPT's ability to solve higher-order questions on the competency-based\nmedical education curriculum in medical biochemistry\n. Cureus. 2023, 15:e37023. \n10.7759/cureus.37023\n9\n. \nMondal H, Mondal S, Majumder R, De R: \nConduct common statistical tests online\n. Indian Dermatol Online J.\n2022, 13:539-42. \n10.4103/idoj.idoj_605_21\n10\n. \nKoo TK, Li MY: \nA guideline of selecting and reporting intraclass correlation coefficients for reliability\nresearch\n. J Chiropr Med. 2016, 15:155-63. \n10.1016/j.jcm.2016.02.012\n11\n. \nFriederichs H, Friederichs WJ, März M: \nChatGPT in medical school: how successful is AI in progress testing?\n.\nMed Educ Online. 2023, 28:2220920. \n10.1080/10872981.2023.2220920\n12\n. \nDave T, Athaluri SA, Singh S: \nChatGPT in medicine: an overview of its applications, advantages, limitations,\nfuture prospects, and ethical considerations\n. Front Artif Intell. 2023, 6:1169595. \n10.3389/frai.2023.1169595\n13\n. \nRuksakulpiwat S, Kumar A, Ajibade A: \nUsing ChatGPT in medical research: current status and future\ndirections\n. J Multidiscip Healthc. 2023, 16:1513-20. \n10.2147/JMDH.S413470\n14\n. \nMohammad B, Supti T, Alzubaidi M, Shah H, Alam T, Shah Z, Househ M: \nThe pros and cons of using\nChatGPT in medical education: a scoping review\n. Stud Health Technol Inform. 2023, 305:644-7.\n10.3233/SHTI230580\n15\n. \nShahsavar Y, Choudhury A: \nUser intentions to use ChatGPT for self-diagnosis and health-related purposes:\ncross-sectional survey study\n. JMIR Hum Factors. 2023, 10:e47564. \n10.2196/47564\n16\n. \nMondal H, Mondal S, Podder I: \nUsing ChatGPT for writing articles for patients' education for dermatological\ndiseases: a pilot study\n. Indian Dermatol Online J. 2023, 14:482-6. \n10.4103/idoj.idoj_72_23\n2023 Kumari et al. Cureus 15(8): e43861. DOI 10.7759/cureus.43861\n7\n of \n7",
  "topic": "Test (biology)",
  "concepts": [
    {
      "name": "Test (biology)",
      "score": 0.6592717170715332
    },
    {
      "name": "Microsoft excel",
      "score": 0.631996750831604
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.6130605340003967
    },
    {
      "name": "Medicine",
      "score": 0.6064832210540771
    },
    {
      "name": "Hematology",
      "score": 0.4716595411300659
    },
    {
      "name": "Scale (ratio)",
      "score": 0.4194568395614624
    },
    {
      "name": "Pathology",
      "score": 0.3642069697380066
    },
    {
      "name": "Medical education",
      "score": 0.3553839921951294
    },
    {
      "name": "Internal medicine",
      "score": 0.31715893745422363
    },
    {
      "name": "Computer science",
      "score": 0.24495995044708252
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4396570500",
      "name": "All India Institute of Medical Sciences, Deoghar",
      "country": null
    }
  ],
  "cited_by": 63
}