{
  "title": "RCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models",
  "url": "https://openalex.org/W4387963755",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2360930257",
      "name": "Wang, Zefan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2488645358",
      "name": "Liu Zi-chuan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1971361141",
      "name": "Zhang YingYing",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4295357077",
      "name": "Zhong, Aoxiao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2031650080",
      "name": "Wang Ji-hong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3215760294",
      "name": "Yin Fengbin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4226575921",
      "name": "Fan, Lunting",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2218371398",
      "name": "Wu, Lingfei",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4222542151",
      "name": "Wen, Qingsong",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4386081878",
    "https://openalex.org/W4386184788",
    "https://openalex.org/W4377865309",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W2938704169",
    "https://openalex.org/W2998839218",
    "https://openalex.org/W4364387555",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4385775086",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W4366566341",
    "https://openalex.org/W2123301721",
    "https://openalex.org/W4367628410",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W3176456866",
    "https://openalex.org/W4380353763",
    "https://openalex.org/W4283026156",
    "https://openalex.org/W4377130677",
    "https://openalex.org/W4366327559",
    "https://openalex.org/W4366328015",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W4385681674",
    "https://openalex.org/W3008374555",
    "https://openalex.org/W4385474529",
    "https://openalex.org/W4378499274",
    "https://openalex.org/W4308643468",
    "https://openalex.org/W4394828156",
    "https://openalex.org/W4386794445",
    "https://openalex.org/W2942544869",
    "https://openalex.org/W4226454612",
    "https://openalex.org/W4387321091",
    "https://openalex.org/W4385681800",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4385682136",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W2131681506",
    "https://openalex.org/W3167387776",
    "https://openalex.org/W4309083387",
    "https://openalex.org/W4385825419",
    "https://openalex.org/W4387835442",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2936695845",
    "https://openalex.org/W4304195432",
    "https://openalex.org/W2017504389",
    "https://openalex.org/W4384345635",
    "https://openalex.org/W3016473712",
    "https://openalex.org/W3021989929",
    "https://openalex.org/W4320165837",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W3117426595",
    "https://openalex.org/W3199174176",
    "https://openalex.org/W4378468509",
    "https://openalex.org/W4386721533",
    "https://openalex.org/W4378718328",
    "https://openalex.org/W4221155815",
    "https://openalex.org/W3126325318",
    "https://openalex.org/W3168887400",
    "https://openalex.org/W4386576685",
    "https://openalex.org/W4221161695",
    "https://openalex.org/W4389158500",
    "https://openalex.org/W4353112996",
    "https://openalex.org/W4385014449",
    "https://openalex.org/W4283828996",
    "https://openalex.org/W3035252911",
    "https://openalex.org/W4386528753"
  ],
  "abstract": "Large language model (LLM) applications in cloud root cause analysis (RCA) have been actively explored recently. However, current methods are still reliant on manual workflow settings and do not unleash LLMs' decision-making and environment interaction capabilities. We present RCAgent, a tool-augmented LLM autonomous agent framework for practical and privacy-aware industrial RCA usage. Running on an internally deployed model rather than GPT families, RCAgent is capable of free-form data collection and comprehensive analysis with tools. Our framework combines a variety of enhancements, including a unique Self-Consistency for action trajectories, and a suite of methods for context management, stabilization, and importing domain knowledge. Our experiments show RCAgent's evident and consistent superiority over ReAct across all aspects of RCA -- predicting root causes, solutions, evidence, and responsibilities -- and tasks covered or uncovered by current rules, as validated by both automated metrics and human evaluations. Furthermore, RCAgent has already been integrated into the diagnosis and issue discovery workflow of the Real-time Compute Platform for Apache Flink of Alibaba Cloud.",
  "full_text": "RCAgent: Cloud Root Cause Analysis by Autonomous Agents\nwith Tool-Augmented Large Language Models\nZefan Wang*\nTsinghua University\nBeijing, China\nwang-zf20@mails.tsinghua.edu.cn\nZichuan Liu*\nNanjing University\nNanjing, China\nzichuanliu@smail.nju.edu.cn\nYingying Zhangâ€ \nAlibaba Group\nHangzhou, China\ncongrong.zyy@alibaba-inc.com\nAoxiao Zhong\nHavard Univerrsity\nCambridge, USA\naoxiaozhong@g.harvard.edu\nJihong Wang*\nXiâ€™an Jiaotong University\nXiâ€™an, China\nwang1946456505@stu.xjtu.edu.cn\nFengbin Yin\nAlibaba Group\nHangzhou, China\nyinfengbin.yfb@alibaba-inc.com\nLunting Fan\nAlibaba Group\nHangzhou, China\nlunting.fan@taobao.com\nLingfei Wu\nAnytime AI\nNew York, USA\nlwu@anytime-ai.com\nQingsong Wenâ€ \nSquirrel Ai Learning\nBellevue, USA\nqingsongedu@gmail.com\nABSTRACT\nLarge language model (LLM) applications in cloud root cause anal-\nysis (RCA) have been actively explored recently. However, current\nmethods are still reliant on manual workflow settings and do not\nunleash LLMsâ€™ decision-making and environment interaction capa-\nbilities. We present RCAgent, a tool-augmented LLM autonomous\nagent framework for practical and privacy-aware industrial RCA\nusage. Running on an internally deployed model rather than GPT\nfamilies, RCAgent is capable of free-form data collection and com-\nprehensive analysis with tools. Our framework combines a variety\nof enhancements, including a unique Self-Consistency for action\ntrajectories, and a suite of methods for context management, stabi-\nlization, and importing domain knowledge. Our experiments show\nRCAgentâ€™s evident and consistent superiority over ReAct across all\naspects of RCAâ€”predicting root causes, solutions, evidence, and\nresponsibilitiesâ€”and tasks covered or uncovered by current rules,\nas validated by both automated metrics and human evaluations. Fur-\nthermore, RCAgent has already been integrated into the diagnosis\nand issue discovery workflow of the Real-time Compute Platform\nfor Apache Flink of Alibaba Cloud.\nCCS CONCEPTS\nâ€¢ Computing methodologies â†’Natural language processing ;\nâ€¢ Software and its engineering â†’Cloud computing.\nâ˜… This research was primarily done during the internship at Alibaba Group.\nâ€ Corresponding authors.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nCIKM â€™24, October 21â€“25, 2024, Boise, ID, USA\nÂ© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0436-9/24/10\nhttps://doi.org/10.1145/3627673.3680016\nKEYWORDS\nRoot Cause Analysis, Large Language Model, Cloud Systems\nACM Reference Format:\nZefan Wang*, Zichuan Liu*, Yingying Zhangâ€ , Aoxiao Zhong, Jihong Wang*,\nFengbin Yin, Lunting Fan, Lingfei Wu, and Qingsong Wenâ€ . 2024. RCAgent:\nCloud Root Cause Analysis by Autonomous Agents with Tool-Augmented\nLarge Language Models. In Proceedings of the 33rd ACM International Con-\nference on Information and Knowledge Management (CIKM â€™24), October\n21â€“25, 2024, Boise, ID, USA. ACM, New York, NY, USA, 9 pages. https:\n//doi.org/10.1145/3627673.3680016\n1 INTRODUCTION\nCloud computing platforms have been increasingly utilized for\napplication and service deployment in recent years [8, 29]. Anom-\nalies in cloud computing systems, such as unrecoverable failures\nand hanged jobs, severely impact customer experience and can po-\ntentially violate service level agreements[2, 58]. Root Cause Anal-\nysis (RCA) [ 1, 31, 61], a core component of site reliability engi-\nneering, is currently receiving ongoing attention from large cloud\ncomputing enterprises such as Amazon, Microsoft, Google, and\nAlibaba. To increase the efficiency of cloud service reliability en-\nhancement, a series of Artificial Intelligence for Operations (AIOps)\napproaches [9, 49, 59] have been widely adopted in RCA to reduce\nthe MTTR (mean time to resolve). While these typical AIOps aid in\nautomated processes, their application faces challenges such as poor\ndata quality, shifting data distribution, laborious data annotation,\nand limited generalization for models [11].\nThe advancements in Large Language Models (LLMs), especially\nwithin the GPT [5, 32â€“34] and LLaMA [45, 46] families, indicate\nan intriguing future of solving intricate reasoning tasks. Recent\nworks demonstrate the use of LLMs in cloud RCA tasks. [ 2, 17]\nfine-tune GPT models for root causes summarization. These works\nrely heavily on the computationally expensive supervised adaption\nto cloud system tasks and do not fully utilize the generalization and\nreasoning abilities of LLMs. One possible solution is to use few-shot\nRAG [22] on LLMs, with representative methods such as RCACopi-\nlot [10], PACE-LM [60], and Xpert[16]. However, these works are\narXiv:2310.16340v3  [cs.SE]  2 Aug 2024\nCIKM â€™24, October 21â€“25, 2024, Boise, ID, USA Zefan Wang et al.\nall based on the GPT family and scenarios within Microsoft, not ad-\ndressing the data privacy concerns associated with using LLMs with\ncloud system data. Furthermore, none of the above methods lever-\nage the autonomous capabilities of LLMs for information collection,\ndecision-making, and environmental interaction [55].\nTool-augmented autonomous agents, as demonstrated in early\nexperiments [6], further unlock the potential of LLMs in interactive\nenvironments. By equipping LLMs with defined tools and associ-\nated documentation, and by facilitating tool invocation through\nmechanisms like function calls or command line inputs, and then\nexecuting these tools and returning environmental feedback, LLMs\ncan handle tasks that require extensive expertise and abilities. A\nrepresentative paradigm within the realm of autonomous agents is\nReAct [55], a workflow that embodies a thought-action-observation\nloop and offers flexibility for extensions [27]. However, the adop-\ntion of LLM agents in the AIOps field, especially with noisy and\nlengthy data, remains limited [21, 28]. The primary challenges are\naction validity and context length, both of which heighten the de-\nmands of LLM-as-agent capabilities [26]. Also, to the best of our\nknowledge, there is no interactive environment built upon realistic\nproduction-level RCA problems for LLM agents to operate on.\nTo this end, we introduce RCAgent, the first practical LLM-\nbased RCA framework within the tool-augmented autonomous\nagent paradigm. We design an enhanced prompting cycle skele-\nton and an interactive environment enriched with external knowl-\nedge and stabilization techniques, tailored for LLM agents to han-\ndle diverse data types. Additionally, we design aggregation meth-\nods for action trajectories and text output, combining subopti-\nmal results from LLMs. Unlike ReAct, our approach operates in a\ntrajectory-level zero-shot way, eliminating the need for manual or\nauto-generated action examples. Furthermore, to facilitate general\nand secure industrial usage, we forgo the use of powerful external\nAPI models and implement this framework on a locally deployed\nmodel, underscoring the efficacy of our stabilization method.\nThe analysis results from RCAgent are being utilized in the\nReal-time Compute Platform for Apache Flink of Alibaba Cloud\nto diagnose anomalous stream processing jobs uncovered by cur-\nrent methods. We have incorporated a feedback mechanism in the\ncompany to identify issues in the PaaS and IaaS layers of the cloud\nsystem, offering insights for development teams.\nWe summarize our contributions as follows:\nâ€¢We propose RCAgent, the first tool-augmented agent based\non LLM for privacy-aware real-world cloud RCA, unleashing\nthe decision-making ability of LLMs in the AIOps field.\nâ€¢We introduce a bag of methods to enhance the tool agent,\nincluding aspects of prompting framework, tool setting, sta-\nbilization, and aggregation methods. These make the agent\nbased on locally deployed LLM a valid solution for complex\nenvironments like cloud systems.\nâ€¢We demonstrate the practical usage of RCAgent with real-\nworld experiments on computing jobs in Alibaba Cloud.\n2 CHALLENGE\nThough tool-augmented LLM agents provide new possibilities for\nthe cloud RCA task, including autonomous decision-making and\nhead\nsnapshot\nThought and Action\nEnvironment\nExpert Agent Prompt\nLog System Databases Code Repositories\nError handling\nAction Cycle of RCAgent\nFramework \nRules\nTask \nRequirement\nTools \nDocumentation\nController Agent Memory\nThought and Action\nParsed Action\nEnvironment\nObservation\nFew-shot Example\nAction Cycle of ReAct\nFramework \nRules\nTask \nRequirement\nTools \nDocumentation\nController Agent Memory\nParsed Action\nY\nN\nReal Observation\n/ Error Traceback\nAgent?N\nN\nY\nError?Y\nN\nExpert Agent\n.\nobservation head\nError?\n(snapshot to observation) \nMemory flow\nLLM generation\nError log\nEnv interaction\nsnapshot 3 observation 3\nKey-value store\nLLM agent\nObservation\nsnapshot 1 observation 1\nsnapshot 2 observation 2.  \nFigure 1: Overview of the action cycles from RCAgent. The\ncycle involves generating verbal thoughts, taking actions, and\nreceiving observation from the environment, all of which are\nrecorded in the prompt alongside the initial memory to boost\nreasoning. Besides, RCAgent includes the key-value store\nfor observation retrieval, allowing the agent to operate on\nlengthy text data. After parsing the action, RCAgent executes\nit directly or invokes an expert agent, depending on its type.\nhandling unseen anomalies without laboriously annotated training\ndata, several critical challenges exist.\nPrivacy. A general LLM method for RCA and other cloud AIOps\ntasks should be internally hosted for security concerns. Specifi-\ncally, transmitting production-level confidential data to external\nAPI induces privacy risks. This means stronger models like Chat-\nGPT cannot be used except for those close collaboration enterprises.\nWhile trading off the modelâ€™s ability for security, we need tech-\nniques to mitigate the gap to some extent.\nContext Length. A fundamental problem for agent usage in real-\nistic cloud environments is context length because various kinds of\ndata, such as logs, code, and database query results, tend to be enor-\nmous. Even if the LLMs can extrapolate to larger context length[35],\nprocessing unnecessarily excessive tokens is highly inefficient.\nAction Validity. Open-ended action generation for LLMs is of\ngreat challenge because less sufficiently aligned LLMs have a larger\npossibility of generating invalid actions[26]. These errors severely\ndamage the performance of autonomous agents on comprehensive\ntasks. The model restriction from privacy concerns and noisy cloud\ndata this problem even more arduous.\n3 METHODOLOGY\nTo systematically and reliably prompt the LLM as a tool-augmented\nautonomous agent for cloud RCA, we propose RCAgent, an en-\nhanced reasoning and acting framework. An overview of our method-\nology at the decision-loop level is shown in Figure 1. For disam-\nbiguousity, the LLM agent with the prompt of thought-action-\nobservation loop is named the controller agent responsible for co-\nordinating actions, and RCAgent additionally employs the LLM as\ntools called the expert agents for domain-specific functionalities.\nRCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models CIKM â€™24, October 21â€“25, 2024, Boise, ID, USA\nIn concordance with the typical implementation of ReAct tool\nagent prompt framework [38], the controller agent is injected with\nthree basic prompts: (i) framework rules that describe the thought-\naction-observation loop, (ii) task requirements that contain instruc-\ntions for the RCA tasks with basic cloud knowledge, and (iii) tools\ndocumentation that describes the description of all invokable tools.\nBecause of its flexibility and readability, JSON is chosen as the data\ninterchange format for all generations in the action step from LLM.\nWe also define a tool named â€˜finalizeâ€™ as an exit point that allows the\nmodel to freely decide when to report findings in a parsable format.\nNote that RCAgent discards the few-shot examples compared to\nthe original ReAct because of limited context length.\nStarting from the tool agent version of ReAct, we propose several\nenhancements to address the challenges of using tool-augmented\nLLM agents in cloud RCA. To deal with the context length challenge\ndescribed in Â§ 2, we first invent an observation management method\nfor compressing token usage introduced in Â§ 3.1. Then, because\nthe LLM itself does not have access to and enough domain-specific\nknowledge about the cloud system, we build tools including LLM-\naugmented ones for the RCAgent, whose designs are described in\nÂ§ 3.2. Addressing the action validity problem, RCAgent has stabiliz-\ning methods presented in Â§ 3.3. Lastly, to improve the performance\nof RCAgent since we are using less capable locally hosted LLM, we\nutilize the aggregation method in RCAgent described in Â§ 3.4.\n3.1 Observation Snapshot Key\nOne of the basic challenges of building autonomous agents in a\ncomprehensive cloud environment is context length [10]. The most\ninflating part of the agent prompt is the observation content in the\naction trajectories, containing a large amount of logs, table entries,\netc. To overcome the information loss from truncating and summa-\nrizing observations, we propose OBservation Snapshot Key (OBSK),\na new method to address the context length problem in realistic\ncloud tasks. As shown in Figure 1, OBSK only shows the head of\nobservation to the controller agent, leaving a hash ID (snapshot key)\nfor further usage. A key-value store is built for mapping the snap-\nshot key to real observation. Thus, when a snapshot key is found\nin a parsed action, RCAgent queries through the key-value store\nand returns the corresponding observation. This ensures necessary\ninformation with controlled length is provided for the controller\nagent as supportive information for decision-making.\n3.2 Tool Preparation\nWe employ data querying functions as information-gathering tools\nand LLM-based expert agents as analytical tools , similar to the data\ncollection and analysis process done by human SREs.\n3.2.1 Information-gathering Tools. Information-gathering tools are\ndesigned in an easy-to-use way, hiding all unrelated details in ac-\ncessing data in cloud systems. For example, instead of giving SQL\ninterface and Log query API to LLM, these tools only accept simple\nparameters like the ID of entities. This semantically minimalist tool\nsetting will reduce the threshold for LLMs to take valid actions, pre-\nventing useless exploration in large data warehouses. Also, to avoid\nthe agentâ€™s ineffective analysis, we deduplicate similar information\nand exclude messages beneath the WARNING level.\nâ€¦ â€¦\nJobConnectorSinkConnectionFailService\nThe `JobConnectorSinkConnectionFail\nService` class extends `RuleDecisionBase` \nand implements the `getDecisionValue` \nmethodâ€¦\nTo complement the analysis of this class, it \nwould be helpful to read the \n`FlinkLifecycleMapper` and the \n`RuleDecisionBase` classâ€¦\nTASKQUEUE\nFunction: \nChecks if there are any \n`FlinkLifecycle` events with \nthe name ending in \n`SINK_CONN_ERROR` and \noccurred within the last \n300000 milliseconds\nMethods: \nExtends `RuleDecisionBase` \nand implements the \n`getDecisionValue` method, \nwhich takes a `DeploymentDto` \nobject as input and returns a \n`DecisionValueResult` object. \nThe class uses the \n`FlinkLifecycleMapper` \ninterface to retrieve \ninformation about the lifecycle \nof Flink jobs based on their \ndeployment ID, job ID, and \nother criteria. If such an event \nis found, the class sets the \nvalue of the \n`DecisionValueResult` object \nto 1 and returns it. If no such \nevent is found, the method \nreturns an empty \n`DecisionValueResult` object.\nFlinkLifecycleMapper\nThe `FlinkLifecycleMapper` interface is a \ndata access layer. It provides methods to \nretrieve the lifecycle of Flink jobs.\nIt would be helpful to review the code file \ncontaining the `FlinkLifecycle` class.\nRuleDecisionBase\nThe `RuleDecisionBase` is an abstract \nclass that implements the `RuleDecision` \ninterface. It provides a base \nimplementation for the decision-making.\nIt seems that the `RuleDecisionBase` class \nis a standalone class that does not depend \non any other classes. \nTherefore, no suggestion is needed.\nSummarization: \nParsed Action\n.\nFigure 2: Code analysis tool in RCAgent.\n3.2.2 Analytical Tools. Analytical tools are proposed to extend\nthe domain knowledge and abilities of the controller agent aug-\nmented by LLMs with their reasoning ability. We name this kind\nof analytical tool the expert agent, which is shown in Figure 1. We\nprovide two expert agents for RCAgent as complementary knowl-\nedge tools, called the Code analysis tool and the Log analysis tool .\nBoth generate analyses and aggregations prompted by the zero-shot\nChain-of-Thought (CoT) [19] and answer extraction instructions.\nCode analysis tool. The code analysis tool works in a recursive\nmanner, which is shown in Figure 2. Given a class name, the code\nanalysis tool searches the corresponding file in the code repository.\nAfter the LLM reading and analyzing the code file, it is prompted\nto suggest any other classes that would be helpful to analyze as\nsupportive information. These suggestions from each code-reading\nround will be stored in a task queue, managing all pending tasks.\nWith this exhaustive search, the code analysis tool stops parsing\nwhen no more code files of interest are recommended, or when\nall remaining recommended files are external dependencies. Then,\nwe utilize an LLM to summarize all the code files, whose result is\npresented to the controller agent as the observation.\nLog analysis tool. The log analysis tool operates in an in-context\nRAG paradigm with some adaptions to lengthy log data. The com-\nplete mechanism is shown in Algorithm 1. We split the logğ¿into\nlines ğ‘† and built edges between lines with the cosine similarity of\nembedding exponentially decayed by document distance as weights\nğ‘Š. This yields a weighted undirected dense graph(ğ‘†,ğ‘Š)regarding\nlines as vertices, describing the relevance of lines that are weak-\nened when other lines are inserted in the middle. Then the graph is\nclustered with Louvain community detection [4], and the overlaps\nbetween clusters are removed by greedily switching the minimum\namount of clustering labels. This clustering functions as seman-\ntic partitioning, and the result log chunks ğ‘ƒ are then fed into the\nlog agent one chunk per round to perform Retrieval-Augmented\nGeneration (RAG) [22]. Moreover, we instruct the expert agent to\noutput evidence supporting its analysis by directly copying log\ncontent, preventing hallucinations of analyzing examples rather\nCIKM â€™24, October 21â€“25, 2024, Boise, ID, USA Zefan Wang et al.\nAlgorithm 1 Pseudo code for log expert agent.\nRequire: Log ğ¿, Max prompt length ğ‘\nEnsure: Interpretations Ëœğ‘…, Evidences Ëœğ¸\n1: ğ‘† â†split ğ¿using delimiters (e.g., newline)\n2: vğ‘  â†EmbeddingModel(ğ‘ ) for each ğ‘  in ğ‘†\n3: ğ‘Š = {ğ‘¤ğ‘–ğ‘—}empty weight matrix\n4: for pairs (ğ‘ ğ‘–,ğ‘ ğ‘—)in ğ‘†Ã—ğ‘† where ğ‘—âˆ’ğ‘– âˆˆ(0,200]do\n5: ğ‘‘ğ‘–ğ‘— â†position distance between ğ‘ ğ‘– and ğ‘ ğ‘— in ğ¿\n6: ğ‘¤ğ‘–ğ‘— â†ğ¶ğ‘œğ‘ ğ‘†ğ‘–ğ‘š(vğ‘ ğ‘– ,vğ‘ ğ‘— )Ã—ğ‘’ğ‘¥ğ‘(âˆ’ğ‘‘ğ‘–ğ‘—)\n7: end for\n8: ğ¶ â†LouvainClustering(ğ‘†,ğ‘Š)\n9: ğ¶â€²â†GreedyOverlapRemoval(ğ¶)\n10: ğ‘ƒ â†partitions from ğ¿indicted by components ğ¶â€²\n11: ğ‘…â€²,ğ¸â€²â†empty initialized filtered results\n12: for each partition ğ‘ in ğ‘ƒ do\n13: ğ¸,ğ´ â†retrieved sorted examples and answers\n14: ğ¼ğ¶ğ‘ƒ â†ğ¸[0 :ğ‘],ğ´[0 :ğ‘] âŠ² In-context prompt\n15: ğ‘…,ğ¸ â†LLMAnalysis(ğ¼ğ¶ğ‘ƒ,ğ‘ )\n16: for each (ğ‘Ÿ,ğ‘’)in ğ‘…,ğ¸ do\n17: if Levenshtein(ğ‘’,ğ‘) < L(ğ‘) - L(ğ‘’) Ã—0.9 then\n18: ğ‘…â€²,ğ¸â€²â†ğ‘…â€²âˆªğ‘Ÿ,ğ¸â€²âˆªğ‘’ âŠ² Filter hallucinations\n19: end if\n20: end for\n21: end for\n22: Ëœğ‘…, Ëœğ¸ â†LLMSummary(ğ‘…â€²,ğ¸â€²)\nthan the partitioned chunk. If the evidence listed by LLMs cannot\nbe fuzzy-matched to the chunk ğ‘, the analysis result is discarded.\nThus, we ensure reliable RAG on lengthy non-natural language.\n3.3 Stabilization\nTo overcome the degradation of action validity induced by noisy\ndata and less capable local LLMs, we introduce two stabilizations.\n3.3.1 JSON Repairing. One of the vital problems in real-world ap-\nplications of tool-augmented LLM autonomous agents is structured\ninference for parsable data. To our knowledge, there is no pain-free\nmethod to guarantee a specific data format (e.g., JSON) for inter-\nactions between LLM agents and the environment. Even though\nthere are some structure helper toolkits, such as Outlines [53] and\nTypeChat [15], they either cannot generate free-form JSON with\nextensive escape characters while not impair generation quality, or\nsolely rely on LLMsâ€™ capability of token error correction. To solve\nthis issue, we employ an intuitive and effective method to generate\nstructured interchange data named JsonRegen.\nBefore LLM inference, all sensitive characters that may corre-\nspond to control symbols in JSON are replaced with insensitive\nones for a clean prompt. When trivial cleaning fails to make the\nJSON-like string parsable, a regeneration process is performed. To\nenforce the LLM to understand JSON structure, we instruct it to\nconvert the content to YAML. The LLM is then prompted to regen-\nerate a JSON with the same structure and content. The regeneration\nproceeds for several rounds or until a valid JSON is parsed.\n3.3.2 Error Handling. The previous work [38] demonstrates that\nLLMs in tool invocation tend to propagate errors, limiting ex-\nploratory actions. These issues are even more pronounced in less\nâ€¦   \nRCAgent TSCCoT SC\nStart\nThought Finalize\nThought Finalize\nThought Finalize\nâ€¦ â€¦  \nAggregation\nStart\nStep\nStepStep\nâ€¦   \nFinalize\nFinalize\nStep Finalize\nStep Step\nâ€¦ â€¦  \nFinalize\nAggregation\nGreedy\nSample\nCombineThought\nThought\nThought\nThought\nFigure 3: Trajectory-level Self-Consistency. Every Step in\nRCAgent means a sequential procedure of thought, action,\nand observation.\ncapable LLMs. Inspired by [42], we use pre-defined criteria to mark\nproblematic actions or states as erroneous. As shown in Figure 1,\nwe provide error messages and suggestions to the controller agent,\nincluding these circumstances: (i) duplicate invocation of stateless\ntools with the same set of arguments, (ii) trivial input to expert\nagents, and (iii) early finalizing without thorough investigation.\nThese error messages can reduce the frequency of meaningless\nactions taken by the control agent by alerting it.\n3.4 Self-Consistency Aggregation\nSelf-Consistency (SC) [50] has proved its efficacy in various close-\nended NLP tasks while aggregating sampled open-ended multi-step\ngeneration like RCA with LLM agent is underexplored. To our\nknowledge, utilizing SC on ReAct style trajectories is also not well-\ndefined. Thus, we propose applying the SC paradigm to free-form\ngeneration on the topic of LLM autonomous agents.\n3.4.1 Self-Consistency for Text Data. To apply SC to text data, we\nutilize two methods in our experiments:\nVote with embedding. . We directly generalize the idea of un-\nweighted SC (majority vote), which performs best across all tasks [50].\nThe voting can be rewritten asarg maxğ‘–(Sim(ağ‘–, 1\nğ¾\nÃğ¾\nğ‘— (ağ‘—))),where\nğ¾ is sample count, and ağ‘– is a one-hot vector representing sampled\nresult ğ‘–with each position as a candidate choice or numerical result.\nWe simply replace a as semantic embeddings for text output. This\nintuitively means the text result closest to the majority is chosen.\nAggregate with LLMs. . Considering the possible diversity of\ngenerated content, we prompt LLM to aggregate the candidates\nand output in similar form and length.\n3.4.2 Self-Consistency for Tool Using Trajectories. SC has been\ncomprehensively tested on CoT reasoning paths, and can naturally\nbe utilized on ReAct style trajectories. However, directly sampling\nmultiple cycles of thought-action-observation can be expensive.\nThis is even more costly while some actions, such as activating\nexpert agents, require heavy consumption. Moreover, random sam-\npling without any history actions or few-shot examples leads to\nflooding errors, e.g. consecutive calling non-existent tools.\nTherefore, we propose a mid-way sampling method named Tra-\njectory-level Self-Consistency (TSC) as shown in Figure 3. Specif-\nically, only when the controller agent is stepping into finaliza-\ntion does the sampling start. This sampling strategy shares most\npreliminary steps between trajectory samples and reduces un-\nnecessary consumption. Besides, the more stable action history\nfrom greedy decoding provides exemplification without additional\ncontext-length consumption from few-shot examples, suppressing\nRCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models CIKM â€™24, October 21â€“25, 2024, Boise, ID, USA\nthe validity drop from sampling. This method strikes a balance\nbetween full-process SC on agent trajectories and one-step CoT SC.\n4 EXPERIMENT\nWe develop and evaluate RCAgent on the Real-time Compute Plat-\nform in Alibaba Cloud, an enterprise-level and high-performance\nsystem capable of real-time stream data computation based on\nApache Flink. This system achieves a throughput of 100 million\ndata records per second during peak hours.\n4.1 Model Configuration\nOur implementation is based on Vicuna-13B-V1.5-16K [62] with\nvLLM [20] backend on a single NVIDIA A100 SXM4 GPU (80 GB).\nWe use the greedy decoding strategy by default for better repro-\nducibility and stability. During self-consistency where random sam-\npling is required, we use the default configuration of Vicuna.\nThe embedding model we use isGTE-LARGE [24], for its slightly\nbetter results on MTEB [30] than text-embedding-ada-002, provid-\ning an internally deployable substitute.\nFor Self-Consistency results, we use10 output samples by default.\nWe employ a step-wise Self-Consistency denoted as SC, which\nonly accepts samples that finalize synchronously after the greedy\ndecoding trajectory, allowing no additional action steps.\n4.2 Dataset Preparation\n4.2.1 Anomaly Selection. For root cause analysis, we collect a\ndataset of 15,616 anomalous jobs of one-month cloud system his-\ntory, either unrecoverable fail, or fail to start in6 minutes. We filter\nthe data and obtain ~5,000 non-trivial anomalous jobs with substan-\ntial log content. We use the Flink Advisor knowledge base, which is\na large rule set distilled from experienced SREsâ€™ domain knowledge,\nto create analysis results for these jobs. Due to the imbalance of\nanomalies, which means a large proportion of anomalies have the\nsame root cause, we reduce the successfully analyzed jobs to an\noffline dataset of 161 jobs. The reduction is done with the class-\nbalance constraint that no more than two jobs have identical root\ncauses. The required annotation of these jobs contains four items:\nthe root cause, solution, evidence, and responsibility determination.\nWe first use LLM to summarize the analysis from Flink Advisor and\noutput the above four items. Then the SRE team proofreads and\nannotates the target output.\nWe guarantee that our annotations do not show uninformative\npatterns like â€œThe root cause of this anomaly is . . . â€ that cause some\nof the semantic scores untrustworthy discovered in [2, 17].\n4.2.2 Data Sources. The available data sources, on which we build\ninformation-gathering tools for the LLM agent, include:\nâ€¢Log data at three levels: platform, runtime, and infrastructure,\nstored in SLS (Simple Log Service) of Alibaba Cloud.\nâ€¢Database containing the history of advisor services\nâ€¢Repositories containing the code of advisor services\nFor log and database entries, only data before the detection time\nof the anomaly can be retrieved, preventing the analysis of future\ninformation and adhering to real-world usage.\nThe retrieval log database for the expert agent is a history subset\nof Flink Advisor with no overlap with the content used for labeling.\nTable 1: Results of root cause prediction on Flink jobs.\nModel\nSemantic Metrics LLM Metric\nMETEOR EmbScore BLEURT BARTScore G-Correctness\nReAct 6.44 89.64 25.17 -6.20 3.06\nRCAgent 15.15 91.47 31.57 -5.74 5.22\nw/o LLM experts 9.60 90.33 27.77 -6.02 3.97\nw/o JsonRegen 13.89 90.74 27.72 -5.84 4.19\nw/o OBSK 12.37 90.97 29.67 -5.77 4.53\nw/o Obs Head 12.27 91.30 30.47 -5.87 4.98\nw/ Summary Head 14.64 91.34 32.11 -5.82 5.16\nw/ SC (LLM) 15.94Â±0.44 91.59Â±0.06 33.74Â±0.44 -5.48Â±0.04 5.38Â±0.01\nw/ TSC (LLM) 16.49Â±0.09 91.67Â±0.03 34.43Â±0.59 -5.40Â±0.01 5.47Â±0.06\nTable 2: Results of solution generation on Flink jobs.\nModel\nSemantic Metrics LLM Metric\nMETEOR BLEURT BARTScore G-Helpfulness\nReAct 6.42 26.97 -4.90 3.41\nRCAgent 12.94 34.68 -4.17 5.48\nw/o LLM experts 8.46 30.46 -4.63 4.13\nw/o JsonRegen 11.41 31.25 -4.40 4.58\nw/o OBSK 10.34 32.13 -4.37 4.68\nw/ SC (LLM) 15.27Â±0.19 37.94Â±0.03 -4.00Â±0.00 5.55Â±0.03\nw/ TSC (LLM) 16.45Â±0.06 39.18Â±0.13 -3.94Â±0.08 5.69Â±0.02\n4.3 Evaluation Metrics\nBesides semantic metric scores includingMETEOR [3], NUBIA [18]\n(6-dim), BLEURT [41], and BARTScore [57] (F-Score, CNNDM),\nwe use additional embedding Score (EmbScore), the cosine simi-\nlarity from the default embedding model in our experiment.\nWe also follow the common practice of using stronger models\nto estimate model prediction [12, 38, 62]. We use greedy decoding\ngpt-4-0613, a frozen version of GPT4[33] for better reproducibility.\nWe prompt the model to judge the accuracy and helpfulness of\nroot cause and solution predictions, marked as G-Correctness and\nG-Helpfulness, respectively, and give a score within 0 âˆ¼10.\n5 RESULT\n5.1 Effectiveness\nWe present the effectiveness of RCAgent on the offline dataset in\nTable 1, 2, and 3. RCAgent outperforms the original ReAct in all\naspects of comprehensive RCA encompassing root cause, solution,\nand evidence prediction. The performance superiority is evident and\nconsistent across all metrics, including +8.71 and +6.52 METEOR\nagainst ReAct in the root cause and solution prediction subtasks.\nEmploying TSC aggregation using LLM summarization, the over-\nall performance of RCAgent gains further enhancements, especially\non solution prediction, witnessing gains of +3.51 METEOR, +4.50\nBLEURT, and +2.28% G-Helpfulness. This boost can be explained\nby the broader diversity of solution sampling.\nTable 3: Semantic scores of evidence of methods.\nModel\nSemantic Metrics\nMETEOR EmbScore BARTScore\nReAct 11.82 90.03 -5.74\nRCAgent 28.10 92.14 -4.62\nw/o LLM experts 13.10 90.63 -5.63\nw/o OBSK 17.79 91.12 -5.13\nw/ Summary Head 18.09 91.67 -5.14\nw/ SC (LLM) 30.15Â±0.83 92.60Â±0.06 -4.41Â±0.05\nw/ TSC (LLM) 30.84Â±0.43 92.78Â±0.02 -4.29Â±0.02\nCIKM â€™24, October 21â€“25, 2024, Boise, ID, USA Zefan Wang et al.\nTable 4: Trajectory statistics of different settings.\nModel Pass Rate Trajectory Length Invalid Rate\nReAct 86.33 7.48 22.82\nRCAgent 99.38 6.78 7.93\nw/o LLM experts 92.55 6.93 16.24\nw/o JsonRegen 85.71 7.91 18.75\nw/o OBSK 96.89 7.21 18.34\nw/ Sampling 70.19 10.66 44.80\nw/ SQL tools 65.84 10.55 70.94\n5.2 Ablation Study\nTo gauge the contribution of each component of RCAgent, we\nconduct an ablation study by removing enhancements introduced\nby RCAgent, including LLM expert agents, JsonRegen, and OBSK.\nThe ablative result is shown in Table 1,2, and 3.\n5.2.1 w/o LLM Expert Agents. We see a drastic drop in all metrics,\nsuch as +8.71 to +3.16 METEOR on root cause prediction, leaving\nonly marginal improvement over ReAct. This shows the power of\nbuilding analytical tools for the LLM, relieving the burden of the\ncontroller agent directly analyzing complex data.\n5.2.2 w/o JsonRegen. The controller and expert agents generate\nmore malformed output, and RCAgent loses a large proportion of\nits performance, primarily due to erroneous decisions.\n5.2.3 w/o OBSK. The controller agent cannot use snapshots any-\nmore and has to operate on truncated data. The absence of snapshots\nimpacts the overall metrics, including âˆ’1.90 BLEURT and âˆ’0.69\nG-Correctness on root cause prediction, though not as dramatically\nas excluding the LLM experts. This indicates that the controller can\nstill put analysis on the log with the expert, while a large part of\nthe environmental observation is lost.\nAdditionally, we test altering the observation head shown to\nthe controller agent. When the observation head is removed and\nonly a snapshot is shown (w/o Obs Head), the performance slightly\ndowngrades for âˆ’1.10 BLEURT, implying the major benefit of the\nsnapshot mechanism. When we prompt the LLM to summarize the\noriginal observation as the alternative head, minimal performance\ndegradation is observed including âˆ’0.06 G-Correctness. The dif-\nference except for BLEURT shows that the truncated observation\nhelps more than the summarized content for the controller agent.\n5.3 Stability\nWe study the action trajectories of different settings in Table 4. With\nall enhancements, the RCAgent achieves a 99.38% Pass Rate within\n15 steps and a 7.93% Invalid Rate, meaning nearly perfect stability\nand a significant edge over ReAct. With such a minuscule chance\nof generating problematic actions, RCAgent consistently delivers\nmore accurate and helpful RCA results with shorter trajectories.\nWhen the LLM expert or OBSK is removed, the controller agent\nmaintains a Pass Rate exceeding 90% while both absences lead to\nan error-prone exploration, diverting some of its actions toward\nredundant tool invocations. The removal of JsonRegen significantly\ndamages the stability due to surging invalid data interchange.\nMoreover, when the default decoding strategy for the controller\nagent is changed to nucleus sampling (w/ Sampling), the stability\ncollapses to 70.19% Pass Rate and 44.80% Invalid Rate with tons of\nerroneous actions and hallucinations. Such results highlight the\nFigure 4: Performance of Self-Consistency at different scales\nand methods. The solid line is the mean score, and the shade\nrepresents the standard deviation. The score is calculated on\nthe concatenated solution and root cause.\nvitality of optimal decoding during initial steps and lead to the\ndesign of our mid-way TSC rather than a pure full-process SC.\nWe also test using the SQL and SLS query execution tools as\nthe information-gathering tool set. A thorough description of all\nrelevant databases is present in the prompt. The substitution dras-\ntically downgrades the Pass Rate by 33.54%, and the gap mainly\nresults from a 70.95% Invalid Rate. This clearly shows the necessity\nof providing semantically minimalist tools for locally hosted LLMs.\n5.4 Self-Consistency\nWe study combinations of SC methods and sample counts each\nfor 10 different runs. The results are detailed in Figure 4. We eval-\nuate concatenated predicted root causes and solutions for better\nnumerical readability.\nThe statistics show that every SC method consistently augments\nthe performance of RCAgent in terms of BARTScore and NUBIA.\nThis enhancement seems to plateau when the number of samples\nreaches 20. Among different methods, TSC brings superiority due to\nits diverse action sampling. In all metrics, LLM aggregation outper-\nforms embedding voting, and this gap broadens with an increasing\nnumber of samples, illustrating LLM aggregationâ€™s ability to offer\nmore comprehensive results as the candidate pool grows.\n6 DEPLOYMENT\nRCAgent has been integrated as a feedback mechanism into the\ninternal operations management platform in our company, aiding\nin the detection of potential platform-side errors and bugs. Specifi-\ncally, RCAgent analyzes all Out-of-Domain (OoD) jobs that existing\nautomatic SRE tools cannot properly handle. Then, jobs labeled as\nplatform responsibility by RCAgent, along with the RCA results,\nare handed to the SRE team of Apache Flink to aid human diagno-\nsis. This procedure improves the efficiency of spotting anomalies\nthat require the DevOps teamâ€™s attention and the workflow of the\nafter-sale service team.\n6.1 Performance on OoD Jobs\nWe evaluate the performance of RCAgent on OoD jobs in the first\ntwo weeks of the systemâ€™s deployment. These OoD job samples are\nsemantically clustered, all of which are beyond the capability of\ncurrent rules and are labeled by experienced SREs for system eval-\nuation. The SRE team is instructed to assign a 0-5 H-Helpfulness\nscore with a set of Likert Scales, spanning from misleading to ex-\nceptionally helpful diagnosis.\nRCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models CIKM â€™24, October 21â€“25, 2024, Boise, ID, USA\nTable 5: Evaluations on the online OoD anomalies. Bold denotes the best results.\nModel\nRoot Cause Responsibility Human\nMETEOR NUBIA BLEURT BARTScore G-Correctness Precision H-Helpfulness\nXGBoost - - - - - 77.65 -\nFinetune T5 4.18 8.20 19.32 -6.61 2.62 77.85 -\nLLM Summary 7.88 14.57 25.40 -6.00 3.58 77.21 -\nReAct 5.21 10.38 20.33 -6.25 2.24 73.53 1.36Â±0.03\nRCAgent 13.77 19.48 31.52 -5.59 3.82 80.74 2.47Â±0.17\nw/ TSC (LLM) 15.72Â±0.61 26.79Â±2.54 35.72Â±0.58 -5.29Â±0.03 4.36Â±0.01 82.06Â±0.42 2.92Â±0.21\nFigure 5: Performance and resource consumption at different data scales.\nThe result is shown in 5. Consistent with all LLM and semantic\nmetrics, human evaluators rate our method with an H-Helpfulness\nof 2.92, indicating moderate support for RCA. A Tukeyâ€™s HSD test\nshows that our method with (ğ‘¡ = 5.84,ğ‘ = 0.001) and without (ğ‘¡ =\n4.08,ğ‘ = 0.001) TSC substantially outperforms ReAct. Furthermore,\nequipped with TSC (LLM), RCAgent demonstrates a precision of\n82.06% in determining the responsibility.\nWe also examine non-agent RCA solutions for comparison. We\nuse all possible types of relevant data of a job, truncated if exceed-\ning the model length constraint, to train XGBoost using document\nembeddings, fine-tune T5, and feed to LLM with a summarization\ninstruction. Despite all the instabilities an autonomous agent so-\nlution would incur, which might explain ReAct being worse than\ntraditional methods, our design outperforms non-agent approaches,\nunderscoring the capability of LLMâ€™s autonomous decision-making.\n6.2 Computational Scalability\nWe show the statistics of LLM agent performance and resource con-\nsumption against varying amounts of data included for different\njobs during our deployment in Figure 5. The data amount is calcu-\nlated by tokenizing all data either presented to the controller agent\nor queried by the OBSK mechanism. While utilizing more data and\nconsuming more resources, RCAgent and its TSC enhancement\nclearly show better performance compared to ReAct. Moreover,\nour methodsâ€™ resource consumption scales nearly linearly as the\ndata amount grows (Pearson Correlation p-value < 0.05 for any\ntype of consumption), without substantial performance degrada-\ntion (ğ‘ = 1.0 based on Kruskal-Wallis H-test). This breakdown of\nperformance and consumption shows RCAgentâ€™s effectiveness in\nhandling a large amount of data.\n7 RELATED WORK\n7.1 LLM as Autonomous Agents\nAs LLMs demonstrate impressive capabilities [ 32, 33, 52], some\nliteratures [36, 44, 54] leverage these models to construct LLM-\nbased agents. A popular paradigm is autonomous agents [36, 43, 48,\n51, 56], in which LLM agents explore self-directedly without human\nintervention and step-by-step instructions. They perform tasks\nwith an action trajectory, adapting their intentions and outputs\naccording to the environment [25]. While autonomous agents have\nbeen implemented and tested on a variety of toy tasks [26, 63], our\nRCAgent is the first work to introduce autonomous LLM agents to\nrealistic cloud RCA tasks.\n7.2 LLM Augmented by Tools\nRecent studies [37, 38, 40, 47] have showcased the proficiency of\nLLMs to invoke tools and make decisions across a wide range of\ntasks. The tools, in the form of simple functions or external APIs,\nextend LLMâ€™s knowledge and capability evidently [6, 23, 39]. While\nstronger LLM can easily grasp tools and accomplish tasks, others\ncan be taught by generated and filtered trajectories [38, 40]. In this\npaper, we aim to augment agents with a comprehensive toolset,\nextending the tool-using paradigm to the real-world cloud RCA.\n7.3 Cloud RCA with LLMs\nRCA in large cloud services is a prominent subject of study within\nsoftware engineering communities [ 7, 13]. A large part of RCA\nis coupled with NLP due to subtasks like log analysis [14, 21, 28].\nAs LLMs advance, they are leveraged for cloud RCA tasks with\nfine-tuning [2, 17] or in-context learning [10, 16]. However, these\nmodels are not aware of the workflow of cloud RCA, leaving them\nsimply analytical tools. We thus investigate tool-augmented LLM\nas agents for the ever-changing environment of cloud RCA.\n8 CONCLUSION\nIn this work, we introduce RCAgent, a tool-augmented LLM au-\ntonomous agent tailored for cloud root cause analysis. RCAgent\nensures secure industrial usage of LLM agents in cloud systems by\nutilizing internally deployed models instead of powerful external\nones like ChatGPT. Our methodology encompasses a spectrum of\nenhancements including unique Self-Consistency for action trajec-\ntories, a comprehensive prompting framework, expert agents, and\nstabilization methods. Furthermore, RCAgentâ€™s efficacy is demon-\nstrated by its practical application in the Real-time Compute Plat-\nform for Apache Flink of Alibaba. In general, this work pioneers\nthe real-world application of LLM agents in the cloud RCA field.\nCIKM â€™24, October 21â€“25, 2024, Boise, ID, USA Zefan Wang et al.\nREFERENCES\n[1] Pooja Aggarwal, Ajay Gupta, Prateeti Mohapatra, Seema Nagar, Atri Mandal,\nQing Wang, and Amit Paradkar. 2020. Localization of operational faults in cloud\napplications by mining causal dependencies in logs using golden signals. In\nInternational Conference on Service-Oriented Computing . 137â€“149.\n[2] Toufique Ahmed, Supriyo Ghosh, Chetan Bansal, Thomas Zimmermann, Xuchao\nZhang, and Saravan Rajmohan. 2023. Recommending Root-Cause and Mitiga-\ntion Steps for Cloud Incidents Using Large Language Models. In International\nConference on Software Engineering . 1737â€“1749.\n[3] Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT\nevaluation with improved correlation with human judgments. In ACL workshop\non Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or\nSummarization. 65â€“72.\n[4] Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefeb-\nvre. 2008. Fast unfolding of communities in large networks. Journal of statistical\nmechanics: theory and experiment 2008, 10 (2008), P10008.\n[5] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot learners. In Advances in Neural\nInformation Processing Systems . 1877â€“1901.\n[6] SÃ©bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric\nHorvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023.\nSparks of artificial general intelligence: Early experiments with gpt-4. arXiv\npreprint arXiv:2303.12712 (2023).\n[7] Haicheng Chen, Wensheng Dou, Yanyan Jiang, and Feng Qin. 2019. Under-\nstanding exception-related bugs in large-scale cloud systems. In International\nConference on Automated Software Engineering . 339â€“351.\n[8] Junjie Chen, Xiaoting He, Qingwei Lin, Yong Xu, Hongyu Zhang, Dan Hao, Feng\nGao, Zhangwei Xu, Yingnong Dang, and Dongmei Zhang. 2019. An empiri-\ncal investigation of incident triage for online service systems. In International\nConference on Software Engineering: Software Engineering in Practice . 111â€“120.\n[9] Pengfei Chen, Yong Qi, and Di Hou. 2016. CauseInfer: Automated end-to-end\nperformance diagnosis with hierarchical causality graph in cloud environment.\nIEEE Transactions on Services Computing 12, 2 (2016), 214â€“230.\n[10] Yinfang Chen, Huaibing Xie, Minghua Ma, Yu Kang, Xin Gao, Liu Shi, Yunjie\nCao, Xuedong Gao, Hao Fan, Ming Wen, et al. 2023. Empowering Practical Root\nCause Analysis by Large Language Models for Cloud Incidents. arXiv preprint\narXiv:2305.15778 (2023).\n[11] Qian Cheng, Doyen Sahoo, Amrita Saha, Wenzhuo Yang, Chenghao Liu, Gerald\nWoo, Manpreet Singh, Silvio Saverese, and Steven CH Hoi. 2023. AI for IT\nOperations (AIOps) on Cloud Platforms: Reviews, Opportunities and Challenges.\narXiv preprint arXiv:2304.04661 (2023).\n[12] Peng Gao, Jiaming Han, Renrui Zhang, Ziyi Lin, Shijie Geng, Aojun Zhou,\nWei Zhang, Pan Lu, Conghui He, Xiangyu Yue, et al. 2023. Llama-adapter v2:\nParameter-efficient visual instruction model. arXiv preprint arXiv:2304.15010\n(2023).\n[13] Supriyo Ghosh, Manish Shetty, Chetan Bansal, and Suman Nath. 2022. How to\nfight production incidents? an empirical study on a large-scale cloud service. In\nSymposium on Cloud Computing . 126â€“141.\n[14] Haixuan Guo, Shuhan Yuan, and Xintao Wu. 2021. LogBERT: Log anomaly\ndetection via bert. In International Joint Conference on Neural Networks . 1â€“8.\n[15] Anders Hejlsberg, Steve Lucco, Daniel Rosenwasser, Pierce Boggan, Umesh\nMadan, Mike Hopcroft, , and Gayathri Chandrasekaran. 2023. Introducing Type-\nChat. https://microsoft.github.io/TypeChat/blog/introducing-typechat/\n[16] Yuxuan Jiang, Chaoyun Zhang, Shilin He, Zhihao Yang, Minghua Ma, Si Qin,\nYu Kang, Yingnong Dang, Saravan Rajmohan, Qingwei Lin, et al. 2023. Xpert:\nEmpowering Incident Management with Query Recommendations via Large\nLanguage Models. arXiv preprint arXiv:2312.11988 (2023).\n[17] Pengxiang Jin, Shenglin Zhang, Minghua Ma, Haozhe Li, Yu Kang, Liqun Li,\nYudong Liu, Bo Qiao, Chaoyun Zhang, Pu Zhao, et al. 2023. Assess and Summarize:\nImprove Outage Understanding with Large Language Models. arXiv preprint\narXiv:2305.18084 (2023).\n[18] Hassan Kane, Muhammed Yusuf Kocyigit, Ali Abdalla, Pelkins Ajanoh, and\nMohamed Coulibali. 2020. NUBIA: NeUral based interchangeability assessor for\ntext generation. In ACL Workshop on Evaluating NLG Evaluation . 28â€“37.\n[19] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke\nIwasawa. 2022. Large language models are zero-shot reasoners. In Advances in\nNeural Information Processing Systems . 22199â€“22213.\n[20] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng,\nCody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient\nMemory Management for Large Language Model Serving with PagedAttention.\nIn Symposium on Operating Systems Principles . 611â€“626.\n[21] Van-Hoang Le and Hongyu Zhang. 2022. Log-based anomaly detection with deep\nlearning: How far are we?. In International Conference on Software Engineering .\n1356â€“1367.\n[22] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin,\nNaman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, et al.\n2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. In\nAdvances in Neural Information Processing Systems . 9459â€“9474.\n[23] Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, and\nYongbin Li. 2023. API-Bank: A benchmark for tool-augmented llms.arXiv preprint\narXiv:2304.08244 (2023).\n[24] Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, and Meishan\nZhang. 2023. Towards General Text Embeddings with Multi-stage Contrastive\nLearning. arXiv preprint arXiv:2308.03281 (2023).\n[25] Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou, Andrew M Dai,\nDiyi Yang, and Soroush Vosoughi. 2023. Training Socially Aligned Language\nModels in Simulated Human Society. arXiv preprint arXiv:2305.16960 (2023).\n[26] Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu,\nHangliang Ding, Kaiwen Men, Kejuan Yang, et al. 2023. Agentbench: Evaluating\nllms as agents. arXiv preprint arXiv:2308.03688 (2023).\n[27] Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke, Rithesh Murthy,\nYihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, et al. 2023. BOLAA:\nBenchmarking and orchestrating LLM-augmented autonomous agents. arXiv\npreprint arXiv:2308.05960 (2023).\n[28] Steven Locke, Heng Li, Tse-Hsun Peter Chen, Weiyi Shang, and Wei Liu. 2021.\nLogAssist: Assisting log analysis through log summarization. IEEE Transactions\non Software Engineering 48, 9 (2021), 3227â€“3241.\n[29] Minghua Ma, Yudong Liu, Yuang Tong, Haozhe Li, Pu Zhao, Yong Xu, Hongyu\nZhang, Shilin He, Lu Wang, Yingnong Dang, et al. 2022. An empirical investi-\ngation of missing data handling in cloud node failure prediction. In ACM Joint\nEuropean Software Engineering Conference and Symposium on the Foundations of\nSoftware Engineering . 1453â€“1464.\n[30] Niklas Muennighoff, Nouamane Tazi, LoÃ¯c Magne, and Nils Reimers. 2023. MTEB:\nMassive Text Embedding Benchmark. In European Chapter of the Association for\nComputational Linguistics . 2006â€“2029.\n[31] Hiep Nguyen, Zhiming Shen, Yongmin Tan, and Xiaohui Gu. 2013. Fchain:\nToward black-box online fault localization for cloud systems. In 2013 IEEE 33rd\nInternational Conference on Distributed Computing Systems . IEEE, 21â€“30.\n[32] OpenAI. 2022. OpenAI: Introducing ChatGPT. https://openai.com/blog/chatgpt\n[33] OpenAI. 2023. GPT-4 Technical Report. arXiv:2303.08774\n[34] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela\nMishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022.\nTraining language models to follow instructions with human feedback. In Ad-\nvances in Neural Information Processing Systems . 27730â€“27744.\n[35] Arka Pal, Deep Karkhanis, Manley Roberts, Samuel Dooley, Arvind Sundararajan,\nand Siddartha Naidu. 2023. Giraffe: Adventures in Expanding Context Lengths\nin LLMs. arXiv preprint arXiv:2308.10882 (2023).\n[36] Joon Sung Park, Joseph C Oâ€™Brien, Carrie J Cai, Meredith Ringel Morris, Percy\nLiang, and Michael S Bernstein. 2023. Generative agents: Interactive simulacra\nof human behavior. arXiv preprint arXiv:2304.03442 (2023).\n[37] Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni\nZeng, Yufei Huang, Chaojun Xiao, Chi Han, et al . 2023. Tool learning with\nfoundation models. arXiv preprint arXiv:2304.08354 (2023).\n[38] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin\nCong, Xiangru Tang, Bill Qian, et al. 2023. Toolllm: Facilitating large language\nmodels to master 16000+ real-world apis. arXiv preprint arXiv:2307.16789 (2023).\n[39] Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing\nDu, Shiwei Shi, Hangyu Mao, Xingyu Zeng, and Rui Zhao. 2023. TPTU: Task\nplanning and tool usage of large language model-based AI agents. arXiv preprint\narXiv:2308.03427 (2023).\n[40] Timo Schick, Jane Dwivedi-Yu, Roberto DessÃ¬, Roberta Raileanu, Maria Lomeli,\nLuke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. Toolformer: Lan-\nguage models can teach themselves to use tools. arXiv preprint arXiv:2302.04761\n(2023).\n[41] Thibault Sellam, Dipanjan Das, and Ankur Parikh. 2020. BLEURT: Learning\nrobust metrics for text generation. In Association for Computational Linguistics .\n7881â€“7892.\n[42] Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath, Karthik\nNarasimhan, and Shunyu Yao. 2023. Reflexion: Language Agents with Verbal\nReinforcement Learning. In Advances in Neural Information Processing Systems .\n[43] Significant-Gravitas. 2023. AutoGPT: the heart of the open-source agent ecosys-\ntem. https://github.com/Significant-Gravitas/Auto-GPT. GitHub repository.\n[44] Theodore Sumers, Shunyu Yao, Karthik Narasimhan, and Thomas L Griffiths.\n2023. Cognitive architectures for language agents.arXiv preprint arXiv:2309.02427\n(2023).\n[45] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne\nLachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro,\nFaisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guil-\nlaume Lample. 2023. LLaMA: Open and Efficient Foundation Language Models.\narXiv:2302.13971\n[46] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-\nmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-\nale, et al. 2023. LLaMA 2: Open foundation and fine-tuned chat models. arXiv\npreprint arXiv:2307.09288 (2023).\nRCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models CIKM â€™24, October 21â€“25, 2024, Boise, ID, USA\n[47] Sai Vemprala, Rogerio Bonatti, Arthur Bucker, and Ashish Kapoor. 2023. Chatgpt\nfor robotics: Design principles and model abilities. Technical Report MSR-TR-\n2023-8, Microsoft 2 (2023), 20.\n[48] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang,\nZhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. 2023. A survey on large\nlanguage model based autonomous agents.arXiv preprint arXiv:2308.11432 (2023).\n[49] Lingzhi Wang, Nengwen Zhao, Junjie Chen, Pinnong Li, Wenchi Zhang, and\nKaixin Sui. 2020. Root-cause metric location for microservice systems via log\nanomaly detection. In International Conference on Web Services . 142â€“150.\n[50] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang,\nAakanksha Chowdhery, and Denny Zhou. 2023. Self-Consistency Improves\nChain of Thought Reasoning in Language Models. In International Conference on\nLearning Representations . 1â€“24.\n[51] Zekun Wang, Ge Zhang, Kexin Yang, Ning Shi, Wangchunshu Zhou, Shaochun\nHao, Guangzheng Xiong, Yizhi Li, Mong Yuan Sim, Xiuying Chen, et al . 2023.\nInteractive natural language processing. arXiv preprint arXiv:2305.13246 (2023).\n[52] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian\nBorgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al.\n2022. Emergent Abilities of Large Language Models. Transactions on Machine\nLearning Research (2022), 1â€“30.\n[53] Brandon T Willard and RÃ©mi Louf. 2023. Efficient Guided Generation for Large\nLanguage Models. arXiv e-prints (2023), arXivâ€“2307.\n[54] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming\nZhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. 2023. The rise and potential\nof large language model based agents: A survey. arXiv preprint arXiv:2309.07864\n(2023).\n[55] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan,\nand Yuan Cao. 2023. ReAct: Synergizing Reasoning and Acting in Language\nModels. In International Conference on Learning Representations . 1â€“33.\n[56] yoheinakajima. 2023. BabyAgi. https://github.com/yoheinakajima/babyagi.\nGitHub repository.\n[57] Weizhe Yuan, Graham Neubig, and Pengfei Liu. 2021. Bartscore: Evaluating\ngenerated text as text generation. In Advances in Neural Information Processing\nSystems, Vol. 34. 27263â€“27277.\n[58] Chaoli Zhang, Tian Zhou, Qingsong Wen, and Liang Sun. 2022. TFAD: A de-\ncomposition time series anomaly detection architecture with time-frequency\nanalysis. In Proceedings of the 31st ACM International Conference on Information\n& Knowledge Management . 2497â€“2507.\n[59] Chaoli Zhang, Zhiqiang Zhou, Yingying Zhang, Linxiao Yang, Kai He, Qingsong\nWen, and Liang Sun. 2022. NetRCA: an effective network fault cause localiza-\ntion algorithm. In IEEE International Conference on Acoustics, Speech and Signal\nProcessing. 9316â€“9320.\n[60] Dylan Zhang, Xuchao Zhang, Chetan Bansal, Pedro Las-Casas, Rodrigo Fonseca,\nand Saravan Rajmohan. 2023. PACE: Prompting and Augmentation for Calibrated\nConfidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis. arXiv\npreprint arXiv:2309.05833 (2023).\n[61] Yingying Zhang, Zhengxiong Guan, Huajie Qian, Leili Xu, Hengbo Liu, Qingsong\nWen, Liang Sun, Junwei Jiang, Lunting Fan, and Min Ke. 2021. CloudRCA: A root\ncause analysis framework for cloud computing platforms. In ACM International\nConference on Information & Knowledge Management . 4373â€“4382.\n[62] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu,\nYonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al . 2023.\nJudging LLM-as-a-judge with MT-Bench and Chatbot Arena. arXiv preprint\narXiv:2306.05685 (2023).\n[63] Xuanhe Zhou, Guoliang Li, and Zhiyuan Liu. 2023. Llm as dba. arXiv preprint\narXiv:2308.05481 (2023).",
  "topic": "Workflow",
  "concepts": [
    {
      "name": "Workflow",
      "score": 0.7785431146621704
    },
    {
      "name": "Computer science",
      "score": 0.761141836643219
    },
    {
      "name": "Cloud computing",
      "score": 0.6964529156684875
    },
    {
      "name": "Variety (cybernetics)",
      "score": 0.6695963144302368
    },
    {
      "name": "Suite",
      "score": 0.6479818224906921
    },
    {
      "name": "Context (archaeology)",
      "score": 0.6084718108177185
    },
    {
      "name": "Consistency (knowledge bases)",
      "score": 0.5589340925216675
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.5440489649772644
    },
    {
      "name": "Root cause analysis",
      "score": 0.49439215660095215
    },
    {
      "name": "Data science",
      "score": 0.41235288977622986
    },
    {
      "name": "Root (linguistics)",
      "score": 0.4106053411960602
    },
    {
      "name": "Software engineering",
      "score": 0.40109479427337646
    },
    {
      "name": "Artificial intelligence",
      "score": 0.23476848006248474
    },
    {
      "name": "Database",
      "score": 0.21825754642486572
    },
    {
      "name": "Engineering",
      "score": 0.12696963548660278
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Linguistics",
      "score": 0.0
    },
    {
      "name": "History",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Forensic engineering",
      "score": 0.0
    }
  ]
}