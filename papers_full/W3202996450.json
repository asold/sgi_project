{
  "title": "Maximum Entropy Language Modeling for Russian ASR",
  "url": "https://openalex.org/W3202996450",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5004578957",
      "name": "Evgeniy Shin",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5039667023",
      "name": "Sebastian Stüker",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5034910585",
      "name": "Kevin Kilgour",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5048075735",
      "name": "Christian Fügen",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5110453805",
      "name": "Alex Waibel",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2187953100",
    "https://openalex.org/W2293139442",
    "https://openalex.org/W2148392518",
    "https://openalex.org/W2160842254",
    "https://openalex.org/W80018330",
    "https://openalex.org/W1993561131",
    "https://openalex.org/W2102667697",
    "https://openalex.org/W2125234026",
    "https://openalex.org/W171608785",
    "https://openalex.org/W2134756243",
    "https://openalex.org/W2032942114",
    "https://openalex.org/W139293362",
    "https://openalex.org/W122584218",
    "https://openalex.org/W1590012787",
    "https://openalex.org/W2096175520",
    "https://openalex.org/W1995560154",
    "https://openalex.org/W2050971845",
    "https://openalex.org/W2069712814",
    "https://openalex.org/W1984635093",
    "https://openalex.org/W2496616370",
    "https://openalex.org/W2090750282",
    "https://openalex.org/W2001792610",
    "https://openalex.org/W1996903695",
    "https://openalex.org/W1631260214"
  ],
  "abstract": "Russian is a challenging language for automatic speech recognition systems due to its rich morphology. This rich morphology stems from Russian’s highly inflectional nature and the frequent use of preand suffixes. Also, Russian has a very free word order, changes in which are used to reflect connotations of the sentences. Dealing with these phenomena is rather difficult for traditional n-gram models. We therefore investigate in this paper the use of a maximum entropy language model for Russian whose features are specifically designed to deal with the inflections in Russian, as well as the loose word order. We combine this with a subword based language model in order to alleviate the problem of large vocabulary sizes necessary for dealing with highly inflecting languages. Applying the maximum entropy language model during re-scoring improves the word error rate of our recognition system by 1.2% absolute, while the use of the sub-word based language model reduces the vocabulary size from 120k to 40k and the OOV rate from 4.8% to 2.1%.",
  "full_text": null,
  "topic": "Principle of maximum entropy",
  "concepts": [
    {
      "name": "Principle of maximum entropy",
      "score": 0.505122721195221
    },
    {
      "name": "Computer science",
      "score": 0.44258710741996765
    },
    {
      "name": "Natural language processing",
      "score": 0.4360675811767578
    },
    {
      "name": "Linguistics",
      "score": 0.40323591232299805
    },
    {
      "name": "Artificial intelligence",
      "score": 0.33108848333358765
    },
    {
      "name": "Mathematics",
      "score": 0.3275960683822632
    },
    {
      "name": "Philosophy",
      "score": 0.12282723188400269
    }
  ],
  "institutions": []
}