{
    "title": "A Comparison of Responses from Human Therapists and Large Language Model–Based Chatbots to Assess Therapeutic Communication: Mixed Methods Study",
    "url": "https://openalex.org/W4410556235",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A5092549804",
            "name": "Till Scholich",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3199649771",
            "name": "Maya Barr",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2330482652",
            "name": "Shannon Wiltsey-Stirman",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2524989785",
            "name": "Shriti Raj",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W3009936362",
        "https://openalex.org/W4386830688",
        "https://openalex.org/W4205828084",
        "https://openalex.org/W4391105189",
        "https://openalex.org/W4390529402",
        "https://openalex.org/W4367663621",
        "https://openalex.org/W4399673257",
        "https://openalex.org/W3029922759",
        "https://openalex.org/W4390485957",
        "https://openalex.org/W4393177920",
        "https://openalex.org/W4317757464",
        "https://openalex.org/W4375951402",
        "https://openalex.org/W4312179235",
        "https://openalex.org/W2920018355",
        "https://openalex.org/W3022528244",
        "https://openalex.org/W4223430747",
        "https://openalex.org/W4399686045",
        "https://openalex.org/W2080518659",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W4392961515",
        "https://openalex.org/W4403813762",
        "https://openalex.org/W4403880728",
        "https://openalex.org/W4394746513",
        "https://openalex.org/W4393970792",
        "https://openalex.org/W2916945592",
        "https://openalex.org/W4389923012",
        "https://openalex.org/W4327585716",
        "https://openalex.org/W4387267058",
        "https://openalex.org/W4409767709",
        "https://openalex.org/W4403540278",
        "https://openalex.org/W4401413185"
    ],
    "abstract": "Background Consumers are increasingly using large language model–based chatbots to seek mental health advice or intervention due to ease of access and limited availability of mental health professionals. However, their suitability and safety for mental health applications remain underexplored, particularly in comparison to professional therapeutic practices. Objective This study aimed to evaluate how general-purpose chatbots respond to mental health scenarios and compare their responses to those provided by licensed therapists. Specifically, we sought to identify chatbots’ strengths and limitations, as well as the ethical and practical considerations necessary for their use in mental health care. Methods We conducted a mixed methods study to compare responses from chatbots and licensed therapists to scripted mental health scenarios. We created 2 fictional scenarios and prompted 3 chatbots to create 6 interaction logs. We recruited 17 therapists and conducted study sessions that consisted of 3 activities. First, therapists responded to the 2 scenarios using a Qualtrics form. Second, therapists went through the 6 interaction logs using a think-aloud procedure to highlight their thoughts about the chatbots’ responses. Finally, we conducted a semistructured interview to explore subjective opinions on the use of chatbots for supporting mental health. The study sessions were analyzed using thematic analysis. The interaction logs from chatbot and therapist responses were coded using the Multitheoretical List of Therapeutic Interventions codes and then compared to each other. Results We identified 7 themes describing the strengths and limitations of the chatbots as compared to therapists. These include elements of good therapy in chatbot responses, conversational style of chatbots, insufficient inquiry and feedback seeking by chatbots, chatbot interventions, client engagement, chatbots’ responses to crisis situations, and considerations for chatbot-based therapy. In the use of Multitheoretical List of Therapeutic Interventions codes, we found that therapists evoked more elaboration (Mann-Whitney U=9; P=.001) and used more self-disclosure (U=45.5; P=.37) as compared to the chatbots. The chatbots used affirming (U=28; P=.045) and reassuring (U=23; P=.02) language more often than the therapists. The chatbots also used psychoeducation (U=22.5; P=.02) and suggestions (U=12.5; P=.003) more often than the therapists. Conclusions Our study demonstrates the unsuitability of general-purpose chatbots to safely engage in mental health conversations, particularly in crisis situations. While chatbots display elements of good therapy, such as validation and reassurance, overuse of directive advice without sufficient inquiry and use of generic interventions make them unsuitable as therapeutic agents. Careful research and evaluation will be necessary to determine the impact of chatbot interactions and to identify the most appropriate use cases related to mental health.",
    "full_text": null
}