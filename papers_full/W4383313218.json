{
  "title": "BioSignal Copilot: Leveraging the power of LLMs in drafting reports for biomedical signals",
  "url": "https://openalex.org/W4383313218",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5100343308",
      "name": "Chunyu Liu",
      "affiliations": [
        "The University of Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A5002335888",
      "name": "Yongpei Ma",
      "affiliations": [
        "The University of Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A5106135516",
      "name": "Kavitha Kothur",
      "affiliations": [
        "Children's Hospital at Westmead",
        "The University of Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A5055081506",
      "name": "Armin Nikpour",
      "affiliations": [
        "Royal Prince Alfred Hospital",
        "The University of Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A5065017416",
      "name": "Omid Kavehei",
      "affiliations": [
        "The University of Sydney"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4319777976",
    "https://openalex.org/W4361866031",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W4377966413",
    "https://openalex.org/W4313197536",
    "https://openalex.org/W4360891289",
    "https://openalex.org/W4321018175",
    "https://openalex.org/W4317910576",
    "https://openalex.org/W4367310920",
    "https://openalex.org/W4376311850",
    "https://openalex.org/W4353114035",
    "https://openalex.org/W4361865652",
    "https://openalex.org/W4366563389",
    "https://openalex.org/W4323030608",
    "https://openalex.org/W4365517815",
    "https://openalex.org/W4378472035",
    "https://openalex.org/W4378072589",
    "https://openalex.org/W4323572088",
    "https://openalex.org/W4376122030",
    "https://openalex.org/W4378498682",
    "https://openalex.org/W4320561510",
    "https://openalex.org/W4375957568",
    "https://openalex.org/W4360976361",
    "https://openalex.org/W6997074781",
    "https://openalex.org/W4321018146",
    "https://openalex.org/W4285005219",
    "https://openalex.org/W4366823741",
    "https://openalex.org/W4365143687",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W3034880799",
    "https://openalex.org/W2029938629",
    "https://openalex.org/W4288693292",
    "https://openalex.org/W2122708981",
    "https://openalex.org/W2164882523",
    "https://openalex.org/W4319964787",
    "https://openalex.org/W2332983105",
    "https://openalex.org/W2945627929",
    "https://openalex.org/W2412620442",
    "https://openalex.org/W2592841437",
    "https://openalex.org/W2791363002",
    "https://openalex.org/W4378509449",
    "https://openalex.org/W4283810944",
    "https://openalex.org/W3015226328",
    "https://openalex.org/W3127637041",
    "https://openalex.org/W3099085560"
  ],
  "abstract": "Abstract Recent advances in Large Language Models (LLMs) have shown great potential in various domains, particularly in processing text-based data. However, their applicability to biomedical time-series signals (e.g. electrograms) remains largely unexplored due to the lack of a signal-to-text (sequence) engine to harness the power of LLMs. The application of biosignals has been growing due to the improvements in the reliability, noise and performance of front-end sensing, and back-end signal processing, despite lowering the number of sensing components (e.g. electrodes) needed for effective and long-term use (e.g. in wearable or implantable devices). One of the most reliable techniques used in clinical settings is producing a technical/clinical report on the quality and features of collected data and using that alongside a set of auxiliary or complementary data (e.g. imaging, blood tests, medical records). This work addresses the missing puzzle in implementing conversational artificial intelligence (AI), a reliable, technical and clinically relevant signal-to-text (Sig2Txt) engine. While medical foundation models can be expected, reports of Sig2Txt engine in large scale can be utilised in years to come to develop foundational models for a unified purpose. In this work, we propose a system (SignalGPT or BioSignal Copilot) that reduces medical signals to a freestyle or formatted clinical, technical report close to a brief clinical report capturing key features and characterisation of input signal. In its ideal form, this system provides the tool necessary to produce the technical input sequence necessary for LLMs as a step toward using AI in the medical and clinical domains as an assistant to clinicians and patients. To the best of our knowledge, this is the first system for bioSig2Txt generation, and the idea can be used in other domains as well to produce technical reports to harness the power of LLMs. This method also improves the interpretability and tracking (history) of information into and out of the AI models. We did implement this aspect through a buffer in our system. As a preliminary step, we verify the feasibility of the BioSignal Copilot (SignalGPT) using a clinical ECG dataset to demonstrate the advantages of the proposed system. In this feasibility study, we used prompts and fine-tuning to prevent fluctuations in response. The combination of biosignal processing and natural language processing offers a promising solution that improves the interpretability of the results obtained from AI, which also leverages the rapid growth of LLMs.",
  "full_text": "BioSignal Copilot: Leveraging the power of LLMs in drafting reports\nfor biomedical signals\nChunyu Liu∗,1, Yongpei Ma∗,1, Kavitha Kothur 2 Armin Nikpour3, Omid Kavehei 1\nAbstract— Recent advances in Large Language Models\n(LLMs) have shown great potential in various domains, particu-\nlarly in processing text-based data. However, their applicability\nto biomedical time-series signals (e.g. electrograms) remains\nlargely unexplored due to the lack of a signal-to-text (sequence)\nengine to harness the power of LLMs. The application of\nbiosignals has been growing due to the improvements in the\nreliability, noise and performance of front-end sensing, and\nback-end signal processing, despite lowering the number of\nsensing components (e.g. electrodes) needed for effective and\nlong-term use (e.g. in wearable or implantable devices). One\nof the most reliable techniques used in clinical settings is\nproducing a technical/clinical report on the quality and features\nof collected data and using that alongside a set of auxiliary or\ncomplementary data (e.g. imaging, blood tests, medical records).\nThis work addresses the missing puzzle in implementing\nconversational artificial intelligence (AI), a reliable, technical\nand clinically relevant signal-to-text (Sig2Txt) engine. While\nmedical foundation models can be expected, reports of Sig2Txt\nengine in large scale can be utilised in years to come to develop\nfoundational models for a unified purpose. In this work, we\npropose a system (SignalGPT or BioSignal Copilot) that reduces\nmedical signals to a freestyle or formatted clinical, technical\nreport close to a brief clinical report capturing key features\nand characterisation of input signal. In its ideal form, this\nsystem provides the tool necessary to produce the technical\ninput sequence necessary for LLMs as a step toward using\nAI in the medical and clinical domains as an assistant to\nclinicians and patients. To the best of our knowledge, this is\nthe first system for bioSig2Txt generation, and the idea can be\nused in other domains as well to produce technical reports to\nharness the power of LLMs. This method also improves the\ninterpretability and tracking (history) of information into and\nout of the AI models. We did implement this aspect through a\nbuffer in our system.\nAs a preliminary step, we verify the feasibility of the\nBioSignal Copilot (SignalGPT) using a clinical ECG dataset\nto demonstrate the advantages of the proposed system. In this\nfeasibility study, we used prompts and fine-tuning to prevent\nfluctuations in response. The combination of biosignal process-\ning and natural language processing offers a promising solution\nthat improves the interpretability of the results obtained from\nAI, which also leverages the rapid growth of LLMs.\n*The first two authors made equal contributions.\n1C. Liu, Y . Ma, O. Kavehei are with the School of Biomed-\nical Engineering, The University of Sydney, NSW 2006, Australia.\nomid.kavehei@sydney.edu.au\n2K. Kothur is with Kids Neuroscience Centre, The Children’s Hospital\nat Westmead, NSW 2145, Australia, and with the Faculty of Medicine and\nHealth, The University of Sydney, NSW 2006, Australia.\n3A. Nikpour is with the Department of Neurology, The Royal Prince\nAlfred Hospital, Camperdown, NSW 2050, Australia, and with the Faculty\nof Medicine and Health, The University of Sydney, Sydney, NSW 2006,\nAustralia.\nI. INTRODUCTION\nThe rapid development of modern technology has revolu-\ntionized the field of large language models (LLMs). One of\nthe significant advancements in the LLM field in recent years\nhas been the creation of Generative Pre-trained Transformers\n(GPTs), which have rapidly gained popularity in various\nfields worldwide [1]. Several theories have been proposed\nto explain the success of LLMs in diverse applications,\nsome focusing on their architectural advancements and others\non using extensive training data. Most prior research has\napplied LLMs, such as GPT-3, to natural language processing\ntasks [2]. These studies strongly suggest LLMs’ potential\nto solve complex domain-specific tasks. While some of the\nmodels, such as GPT-4 present multimodal properties, a look\nat the model repositories and services, such as Hugging\nFace, reveals the lack of reliable technical BioSignal to Text\nengineers to be able to increase the reliability of use of these\nmodels in medical and clinical domain where preparation of\nreports per test or procedure is a routine task [3].\nMany recent studies have noted the potential of GPT\nin healthcare. For instance, [4] reports the utilization of\nChatGPT in the Medical Knowledge Self-Assessment Pro-\ngram (MKSAP) and its success in helping physicians reduce\ndocumentation burdens through the timely provision of the\nmost relevant information. Other studies [5], [6] also mention\nChatGPT’s potential use to help generate medical notes for\nmedical consultations and radiological images by the word-\ning of prompts [5], [7]–[33]. However, these studies focus\non natural language processing or medical images rather,\nand the application of these models in the medical signal\ndomain remains unattended despite the fact that similar tasks\nof report preparation and drafting are involved.\nThe current research on applying natural language process-\ning to biological signal processing is based on the analogy of\nsignals to language and the use of NLP models to help com-\nputers learn signal features [34]. Many previous studies have\nidentified the importance of ECG signal feature extraction\ntechniques in identifying cardiovascular diseases [35]–[38].\nMost previous studies are implemented by combining time-\ndomain, frequency-domain and morphological features with\nmachine learning algorithms [39]. There is a considerable\npublic body of validated clinical and academic knowledge\nthat can be used to harness the power of LLMs and large\ngenerative AI models that are growing fast and becoming\nmore domain-specific. This helps make the information flow\nprocess in the clinical domain from machines to (expert)\nhumans and back more seamless and interpretable. In the\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted July 6, 2023. ; https://doi.org/10.1101/2023.06.28.23291916doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nParameters (Billions) \n0.1\n1\n10\n100\n1000\n2018 2019 2020 2022 20232021\nGPT-4\nPanGu-Σ\nFig. 1. An overall picture of language models release and parameters size,\nwith the publicly accessible GPT-4 [48] and recently reported PanGu-Σ [49]\nmodels highlighted.\ncase of ECG, groundbreaking ECG technologies and devices,\nsuch as Universal ECG TM [40]–[44], can potentially benefit\nfrom obtaining a second-opinion of or an early analysis from\nan AI machine in particular in case of a junior medical doc-\ntor, under pressure emergency department practices, as part\nof a medical education program or in clinically challenging\nscenarios.\nEase of use, low cost, wide availability, unprecedented\nprojected growth, and extremely rapid fine-tunability of\nLLMs for adaptation to particular tasks or domains make\nintegrating them into medical domains as an AI assistant\nwith an expert-in-the-loop necessary [45]. Fig. 1 highlights\nan overall picture of the rapid growth and expansion of LLMs\nin terms of parameter size and release date as one of many\nimportant factors to highlight the incredible pace at which\nthese languages can be developed, adapted and applied,\nfor instance in legal domain [46]. The data for this graph\nis extracted from publicly available information. It is also\nacknowledged that a larger parameter size does not always\ntranslate to a better performance [47]. For example, the\nsource and distribution of the training data play a significant\nrole in a successful domain specificity.\nIn this work, we present SignalGPT; a system to apply\nthe advance of LLMs to the analysis and assistance in\nthe interpretation of various physiological signals such as\nelectrocardiogram (ECG or EKG), scalp or implanted elec-\ntroencephalography (EEG), intracranial electrocorticography\n(ECoG or iEEG), stereo-electroencephalography (sEEG),\nelectrooculography (EOG), electroretinography (ERG), elec-\ntromyogram (EMG), jugular venous pulse (JVP) monitor-\ning, central venous pressure (CVP) monitoring, and pho-\ntoplethysmography (PPG) signals. The created system inte-\ngrates a ChatGPT model with a biomedical signal-processing\npipeline.\nThe engine can process various biomedical data, including\nECG, EEG, EMG, etc. It converts the signal or signals\ninto objective and clinical textual descriptions. One of the\nsimplest examples of a feasibility study is ECG, however, it\nis possible, but more complex to convert an EEG signal into\nits textual description. It should be noted that the signal-to-\ntext engine is not designed to classify or identify abnormally.\nThe system then inputs the sequence (description) into the\nfine-tuned ChatGPT model, which evaluates the description\nalongside the information provided on the subject’s gender,\nage, comorbidity, and more (e.g. could include height, weight\netc). The system then offers its interpretations. Our experi-\nments using ECG signals is only the first step to confirm the\nviability of this method and through a set of experiments,\nwe were able to demonstrate the feasibility of this approach.\nWe acknowledge recent works on the imaging domain,\neither general purpose [3] or specific to medical images [6].\nThe proposed HuggingGPT [3], is a system that employs\na model selector controlled by ChatGPT to solve AI-based\ntasks. While HuggingGPT comes close to our proposed\narchitecture, we note that HuggingGPT does not extend\nto biosignals as there is no Hugging Face model for the\nbiosignal-to-text generation to the best of our knowledge.\nIn contrast, SignalGPT is specifically designed to process\nbiomedical signals with a built-in pipeline that specializes\nin the task. Our model offers a unique advantage over Hug-\ngingGPT in this domain. By leveraging the strength of large\nlanguage models, fine-tuning and combining it with special-\nized biomedical signal processing pipelines, SignalGPT can\nprovide clinicians with detailed interpretation and analysis of\ninput signals, thereby improving the efficiency and accuracy\nof clinical decision-making. Furthermore, the interpretability\nprovided by our model enables doctors to understand the\nreasoning behind SignalGPT’s analysis, promoting greater\ntrust in the system and its output.\nII. METHODS\nSignalGPT is a Generative AI-based biomedical signal\nprocessing and analyzing system combined with ChatGPT,\nwhich is designed for auxiliary clinicians to diagnose the\nabnormalities of the biomedical signal. SignalGPT consists\nof Controller (ChatGPT) and the Biomedical Signal Pro-\ncessing Pipeline. The ChatGPT is considered a controller\nto determine the processing engine in terms of the type of\ninput signal. Another function of the controller is to analyze\nthe description of the given signal based on pre-training\non massive corpus and reinforcement learning from human\nfeedback (RLHF). Biomedical Signal Processing Pipeline\n(BSP) includes a set of signal2text engines for processing\ndifferent types of medical signals, and these engines integrate\ncorresponding data preprocessing methods and models. The\nmodels contain signal-to-text (S2T) generators and signal\nclassifiers. In addition to these two core components, the\nSignalGPT also provides an interactive interface for users\nto obtain mandatory information and a gate for fine-tuning\nChatGPT by providing feedback.\nThe workflow of the SignalGPT is demonstrated in Fig. 2.\nThere are five steps.\n1) The presented system acquires the gender, age, or other\nnecessary information of the person to be analyzed and\ndiagnosed in the interface from the users. The system\nin Fig. 2 requires the gender and age of a patient due to\nECG as an example. This information can improve the\nresults of ChatGPT interpreting and analyzing signals.\nAt the same time, the path and type of the biomedical\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted July 6, 2023. ; https://doi.org/10.1101/2023.06.28.23291916doi: medRxiv preprint \nController\nECG Engine EEG Engine\nEOG Engine EMG Engine\nRaw signal\nInterface\nSignals, \ninformation \nand data\n1\n2\nSignal\nType 3\nTechnical and \nclinically relevant \ndescription of the \nsignal\nMedical Signal Processing Pipeline\nType Engine\nECG ECG2Seq\nEEG EEG2Seq\nECoG ECoG2Seq\nEMG EMG2Seq\nERG ERG2Seq\n… …\n4\nGate\nPrediction of \nthe Engine\nInterpretation and \ndiagnosis of the \nsignal, that may or \nmay not include \nprognosis.\nThe regenerated \ndescription of the\nsignal by the engine \n(or physicians). \n5\nUser feedback \nPhysicians’ corrections\nHistorical data\nBuffer\nSubject’s gender, age, comorbidities, \nheight, weight, signal(s) modalities\n(e.g. ECG), and other auxilary \ninformation.\nIn this ECG there are no clear indication \nof abnormal cardiac activity. \nHere is a summary of patterns \nand features:\nThe heart rate is ... \nFig. 2. SignalGPT architecture.\nsignal are required for importing signal data to an\nappropriate engine.\n2) The ChatGPT extracts the type and path of signal from\nreceiving messages and feeds them into the BSP.\n3) BSP has a built-in lookup table module to record the\nnumber of each engine and the signal types it can\nhandle. The input information finds the corresponding\nengine through this table and sends the biomedical-\nsignal-import path into this engine.\n4) Signal data are imported following its path, prepro-\ncessed, and recognized in the engine generating a\nprediction of the given biomedical signal and the text\nwhich is an objective description of this signal without\nany opinions. This text is sent back to ChatGPT and\nanalyzed there according to what ChatGPT learned from\nthe corpus. This label is fed into the gate to fine-tune\nSignalGPT.\n5) The generated text is transmitted back to ChatGPT\nfor analysis and interpretation, leveraging its learned\nknowledge. The ECG signal description is scrutinized\nby ChatGPT, and its conclusion is extracted to be\ncombined with the prediction produced in step 4 in\norder to fine-tune ChatGPT at the gate. An eventual\nreasonable interpretation is exhibited to the user through\nthe interface.\nIn the SignalGPT workflow, we adopt two approaches to\nfine-tune the output of ChatGPT. (1) We aim to mitigate\nthe impact of the prompt bias in our system, and thus, we\nstandardize the tone of the output generated by the BSP\nmodule. In addition, we pose the same question to ChatGPT\nbefore sending the produced text to it: \"You are a helpful\nand kind Medical AI Assistant. You can find reasonable\nexplanations online and in your knowledge base based on\nuser descriptions of ECGs and answer the user whether there\nis any disease. For example, 1st degree A V block (1dA Vb),\nright bundle branch block (RBBB), left bundle branch block\n(LBBB), sinus bradycardia (SB), atrial fibrillation (AF) and\nsinus tachycardia (ST).\" Not only does the use of consistent\nlanguage help to avoid misleading ChatGPT but also the\nposed question reduces the incidence of incorrect responses.\n(2) After the diagnosis is generated by the ChatGPT, it is\nmatched with the predicted label of the ECG engine of the\nBSP at the gate. If the diagnosis matches the engine’s label,\nit is directly outputted to the user interface, and we collect\nthe feedback from users to fine-tune ChatGPT. However, if\nthere is a discrepancy, ChatGPT is used to re-diagnose based\non the updated description. This text is regenerated by the\nengine or fixed by the physician until a reasonable diagnosis\nis obtained.\nWe also emphasize the importance of the buffer in Sig-\nnalGPT. It plays a critical role in optimizing the system to\nlearn and recall patient information like an actual physician.\nTo achieve this objective, we partitioned the cache into two\nsegments. One segment stores the patient’s historical data for\na comprehensive review and further analysis by the system.\nThe other segment preserves the user feedback and physician\ncorrections, which are then used by the Engine to enhance\nits performance via automatic iteration for human feedback\nreinforcement learning. The physician corrections are used\nto improve the S2T generator, while the user feedbacks are\nused to fine-tune the ChatGPT. The frequency of iteration is\ndetermined by the size of the buffer. Whenever the buffer\nis full, the Engine is iterated, and the buffer is cleared in\npreparation for the next cycle.\nThe SignalGPT workflow highlights the significance of\nchoosing an appropriate engine. A reliable and high-\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted July 6, 2023. ; https://doi.org/10.1101/2023.06.28.23291916doi: medRxiv preprint \nTABLE I\nLABEL SPECIFICATION\nAbnormalities Labels\n1st degree A V block 1dA Vb\nright bundle branch block RBBB\nleft bundle branch block LBBB\nsinus bradycardia SB\natrial fibrillation AF\nsinus tachycardia ST\nperforming engine can significantly enhance the fine-tuned\nChatGPT’s interpretation accuracy and the SignalGPT’s\navailability. And the physicians can intervene in step 4\nto modify the text to increase the accuracy of ChatGPT\ninterpretation.\nIII. EXPERIMENTAL SETUP\nTo validate the feasibility of our system, we conduct exper-\niments utilizing electrocardiogram (ECG) data. To compare\nthe interpretability of ECG analysis using SignalGPT with\nthat just using ChatGPT, we attempted to input unseen ECG\ndata directly into the ChatGPT. However, we discovered that\nthis approach was not feasible as ChatGPT is unable to read\nraw ECG data and generates answers based on its training\ndata. Instead, we experimented with inputting the description\nof the ECG signal into ChatGPT to improve accuracy. This\napproach proved to be effective, as ChatGPT was able to\nprovide more accurate ECG interpretations and diagnoses\nbased on the description of the signal.\nSpecifically, we utilize an ECG dataset collected by the\nTelehealth Network of Minas Gerais (TNMG) from 2010\nto 2016 and organized by the CODE (Clinical outcomes in\ndigital electrocardiography) group [50]. And we implement\ndata preprocessing, feature extraction, and event processing\nusing the Neurokit2 library. The selection of ECG data\nand the use of an established library are deliberate choices\naimed at ensuring the robustness and generalizability of our\nsystem. By conducting these experiments, we are able to\nassess the performance of our engine in processing ECG data\nand demonstrate its potential to be applied to other medical\nsignals.\nA. Dataset\nThe test dataset used in our study comprised 827 12-\nlead ECG records obtained from the Telehealth Network\nof Minas Gerais (TNMG) in Brazil. The ECG recordings\nwere annotated by two certified cardiologists and a senior\nspecialist [50]. This dataset is publicly available through\ndoi.org/10.5281/zenodo.3625006. This dataset contains 670\nnormal and 167 abnormal ECG records, of which 1dA Vb,\nRBBB, LBBB, SB, AF, and ST have 28, 34, 30, 16, 13, and\n36 records, respectively. The 1dA Vb, RBBB, LBBB, SB, AF,\nand ST are the abbreviations of six types of common ECG\nabnormalities which is reported in Table I\nB. ECG Engine\nOur experimental ECG Engine consists of two models.\nOne is designed for generating the objective text of biomed-\nFig. 3. Visualization of waveform segmentation of a normal ECG on lead\nV4 using Neurokit.\nical signals and the other is a classifier to predict the labels\nof ECG abnormalities.\nFirstly, the ECG engine employs Neurokit 0.2.4 to prepro-\ncess the raw ECG signal and perform waveform segmenta-\ntion and feature extraction [51]. Fig. 3 displays the normal\nECG signal from a female in her mid-20s on lead V4. The\nentire ECG record is segmented by heartbeat and features\nof the ECG waveform, such as the onset and peak of the\nP waves, the onset and each cusp in the QRS complex,\nand the onset and peak of the T waves, are identified on\neach heartbeat. Subsequently, all heartbeats are overlaid and\naveraged to obtain summarized features for the lead [51].\nThe extracted features are utilized to characterize the\ninput ECG signal in an objective manner. To ensure that\nthe signal’s interpretation and analysis by ChatGPT are\nunbiased, we have endeavored to maintain a strictly factual\nand quantitative description. This approach is supported by\nthe inclusion of additional numerical values in the descrip-\ntion, which serves to provide a reliable and evidence-based\nfoundation for ChatGPT’s assessment of the ECG signal.\nSecondly, the current study utilizes a deep learning net-\nwork as a classifier which is introduced by [50] to validate\nthe applicability of SignalGPT. The model proposed in [50]\nemployed a classical deep neural network (DNN) to learn\nfeatures of ECG recordings on their private 12-lead ECG\ndataset. It is not only capable of recognizing multi-lead\nfeatures but also has excellent performance. Therefore, we\nadopted this model as our ECG engine in our proposed\nsystem.\nC. Performance Metrics\nGiven the imbalanced distribution of abnormal and normal\nsamples, this study employs sensitivity (TPR), false positive\nrate (FPR). The expressions of TPR and FPR are Eq. 1 and\nEq. 2 to evaluate the performance of the system in abnormal\nsamples.\nTPR = TP\nTP + FN (1)\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted July 6, 2023. ; https://doi.org/10.1101/2023.06.28.23291916doi: medRxiv preprint \nFPR = FP\nFP + TN (2)\nIV. RESULTS\nIn this section, we provide two representative examples\nof ECG diagrams to showcase the system’s functionality.\nSpecifically, the examples include an ECG reading from a\nhealthy female in her mid-20s and another from a male in\nhis mid-70s with atrial fibrillation (AF). We then evaluate\nSignalGPT’s overall performance on the entire dataset and\nanalyze the obtained results along with any associated system\nlimitations.\nA. Case Study\nIn this section, we present an analysis of the SignalGPT\nsystem through the use of two cases, highlighting its ad-\nvantages. In the article, we referenced the age range of the\nsubjects due to publication rules, despite having utilized their\nexact ages in our experiment.\n1) Normal ECG of a female subject in her mid-20s: The\nfirst case is an ECG from a healthy female in her mid-20s,\nas shown in Fig. 4(a). The ECG exhibits a regular rhythm\nwith an RR interval of approximately three and a half major\ndivisions. The P wave is closely related to the QRS complex,\nand the PR interval is about three small grids. The QRS\ncomplex is not wide or deformed.\nThe description of the output of the ECG engine in\nSignalGPT is as follows:\n\" This is an ECG of female in her mid-20s. Heart rate is\n87. R-R intervals are 0.69 s with a variance of 0.0. P waves\nlast 0.09s with 0.05 mV . PR intervals last 0.12s. The QRS\ncomplex lasted 0.09 s with 1.61 mV in limb leads and 1.73\nmV in chest leads. In addition, the amplitude of R waves\nin leads V5 and V6 are 1.86 and 1.7 mV . The maximum of\nR-wave amplitude in leads I, II and III is 1.3 mV . The other\nR-wave amplitude in other leads is 1.1 mV . S-wave amplitude\nin V1 is -0.45 mV . Q-wave amplitude is -0.06 mV . The ST\nsegments last 0.09 s and J-60 points are -0.04 mV . T waves\nlast 0.09s with 0.09 mV . QT intervals last 0.3s.\"\nTo assess the performance of the SignalGPT system in\ninterpreting ECG signals, the output from the ECG engine\nis entered into ChatGPT. The system interprets the output\nand provides a response that reads as follows:\n\" Based on the information provided, there are no clear\nindications of any disease. The ECG shows a normal sinus\nrhythm with a heart rate of 87 beats per minute. The PR\ninterval, QRS complex, and QT interval are all within normal\nlimits. The R-wave amplitude in leads V5 and V6 are slightly\nelevated, but this can be a normal variation. The S-wave\namplitude in V1 is slightly depressed, but this can also be\na normal variation. The ST segments and T waves are also\nwithin normal limits. Overall, this ECG appears to be within\nnormal limits and does not suggest any significant cardiac\nabnormalities or disease. However, it is important to note\nthat a single ECG is not always sufficient to diagnose or rule\nout cardiac disease, and further testing may be necessary if\nthere are any clinical concerns.\"\nIf ChatGPT reads this unseen ECG data directly, its\nresponse is:\n\" The first ECG recording showed sinus tachycardia with\na heart rate of about 120 beats per minute. The QRS complex\nwas narrow and regular, sustained. The time is about 80 ms.\nThe PR interval is about 0.16 seconds, which is within the\nnormal range. The QT interval is also normal.\nST-segment elevation in leads V1-V3 suggests acute ante-\nrior myocardial infarction. There is also mutual ST-segment\ndepression in leads II, III, and aVF , which may be a sign of\ninferior myocardial ischemia.\nA second ECG recording showed sinus rhythm with a\nheart rate of approximately 70 beats per minute. The QRS\ncomplexes are also narrow and regular, with a duration of\napproximately 80 milliseconds. The PR interval was about\n0.20 seconds, which was within the normal range. The QT\ninterval was slightly prolonged.\nT wave inversion in leads V1-V3 may indicate previous\nanterior myocardial infarction. In addition, ST-segment de-\npression in leads II, III, and aVF suggests inferior wall\nischemia.\nTaken together, these findings suggest that the patient likely\nhad a history of anterior myocardial infarction and present\nevidence of inferior wall ischemia on the first ECG recording.\nA second ECG recording indicated persistent anterior wall\nischemia. Further evaluation of additional diagnostic tests,\nsuch as cardiac biomarkers and imaging studies, is needed\nto confirm the diagnosis and guide management.\"\nThe dataset for each patient includes two types of files\nto record their invisible ECG data. Therefore, ChatGPT’s\nanswer involves analyzing both the first and second records.\nWe extract the interpretation of SignalGPT and ChatGPT\nand compare it with the original ECG graph (Fig. 4(a)). Our\nanalysis revealed that SignalGPT provided a more accurate\ninterpretation than the direct use of ChatGPT. Specifically,\nSignalGPT correctly interprets the ECG as normal, indicating\nthat no significant cardiac abnormalities could be recognized.\nIn contrast, direct ChatGPT’s analysis, while closer to human\nlanguage, was less accurate in identifying the absence of\ncardiac abnormalities.\n2) ECG analysis of a male subject in his 70s with a\nclinical diagnosis of atrial fibrillation: Moving on to the\nsecond case, Fig. 4(b) shows the raw ECG of a male\nin his 70s. The ECG displays a disappearance of the P\nwave, which is replaced by the f wave with inconsistent\nfrequency, amplitude, and shape. The equipotential line also\ndisappears, and the RR interval is too short, indicating an\nirregularly irregular rhythm. Moreover, the amplitude of the\nQRS complex is high voltage.\nThe corresponding output of the ECG engine in Signal-\nGPT is shown in the next paragraph. Among them, the\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted July 6, 2023. ; https://doi.org/10.1101/2023.06.28.23291916doi: medRxiv preprint \n(a)\n(b)\nFig. 4. (a) ECG of a female in her mid-20s, which is normal. (b) ECG of a male in his 70s diagnosed as atrial fibrillation (AF). Note that exact ages\nare masked in this figure and also in the text due to our obligations to disclosure of specific and identifiable information (e.g. age).\ninconsistency of the RR interval is expressed by variance.\nHowever, the F wave was misdetected as a P wave, despite\nthe apparently unreasonable duration.\n\" This is an ECG of male in his 70s. Heart rate is 150.\nR-R intervals are 0.43 s with a variance of 0.011. P waves\nlast 0.04s with 0.03 mV . PR intervals last 0.02s. The QRS\ncomplex last 0.08 s with 2.7 mV in limb leads and 5.13 mV\nin chest leads. In addition, the amplitude of R waves in leads\nV5 and V6 are 5.13 and 3.62 mV . The maximum of R-wave\namplitude in leads I, II and III is 2.29 mV . The other R-wave\namplitude in other leads is 3.39 mV . S-wave amplitude in V1\nis -1.8 mV . Q-wave amplitude is 0.01 mV . The ST segments\nlast 0.01 s and J-60 points are -0.1 mV . T waves last 0.04s\nwith -0.09 mV . QT intervals disappear.\"\nThe analysis of SignalGPT output to the interface is:\n\" Based on the information provided, this person appears\nto have atrial fibrillation (AF) with a heart rate of 150\nbeats per minute. There is also evidence of a prolonged QRS\ncomplex duration, with a maximum amplitude of 5.13 mV\nin chest leads, which may indicate a bundle branch block.\nHowever, further evaluation would be necessary to determine\nwhether it is a right bundle branch block (RBBB) or left\nbundle branch block (LBBB). Additionally, there is evidence\nof ST segment depression and T wave inversion, which may\nindicate myocardial ischemia or injury. It is important for\nthis person to seek medical attention for further evaluation\nand management.\"\nThe interpretation of ChatGPT is shown as follows:\n\"This ECG recording shows a sinus rhythm with a rate of\napproximately 75 beats per minute. The P waves are upright\nand present before each QRS complex, with a constant PR\ninterval of around 0.20 seconds, suggesting normal atri-\noventricular conduction. The QRS complexes have a normal\nduration of around 80 milliseconds.\nThere are some abnormal findings in this ECG recording.\nSpecifically, there is ST segment elevation in leads II, III,\nand aVF , which may suggest an acute inferior myocardial\ninfarction. There are also ST segment depressions in leads\nV1-V3, which may indicate ischemia or injury to the anterior\nwall of the heart. These findings suggest that the patient may\nbe experiencing an acute coronary syndrome.\nThere is a normal QT interval, and no signs of atrial\nor ventricular enlargement or hypertrophy are evident. The\naxis of the QRS complex is within normal limits, measuring\naround 60 degrees.\nIn summary, this hypothetical patient’s ECG shows signs\nof acute inferior myocardial infarction and possible anterior\nwall ischemia. Immediate medical attention may be required\nto manage these conditions. Further diagnostic tests, such as\ncardiac enzyme testing and echocardiogram, may be needed\nto confirm the diagnosis and guide treatment.\"\nIn line with the first case, our proposed SignalGPT was\nable to detect typical features of atrial fibrillation, such as\nirregularly irregular rhythms, tachycardia, and irrational P\nwaves. In contrast, the analysis carried out by ChatGPT did\nnot account for these abnormalities. This finding highlights\nthe superiority of SignalGPT in identifying key indicators of\natrial fibrillation over ChatGPT.\nThese two cases further support the superiority of Sig-\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted July 6, 2023. ; https://doi.org/10.1101/2023.06.28.23291916doi: medRxiv preprint \nTABLE II\nPERFORMANCE TO DIFFERENT TYPES OF ECG A BNORMALITIES ON\nTNMG.\nAbnormalities type TPR (%) FPR (%)\n1dA Vb 92.86 1.25\nRBBB 100.00 0.38\nLBBB 100.00 0.00\nSB 100.00 1.48\nAF 92.31 2.46\nST 97.30 1.01\nnalGPT over ChatGPT for biomedical signal analysis. Sig-\nnalGPT was able to detect important features of the ECG\ndata. However, ChatGPT’s analysis failed to identify ab-\nnormalities, highlighting the limitations of directly applying\nlanguage models to biomedical signal processing. These re-\nsults demonstrate the need for complementing the biomedical\nsignal processing pipeline to advanced deep learning models\nlike ChatGPT for accurate interpretation and better patient\noutcomes.\nB. Feasibility verification based on ECG\nThe results of our study are presented in Table II, which\nshowcases the efficacy of our model in identifying various\nECG abnormalities within the test dataset provided in [50].\nAs illustrated in Table 1, SignalGPT demonstrated perfect\nsensitivity (100%) for RBBB, LBBB, and SB. The sensitivity\nfor ST was slightly lower at 97.30%. The sensitivities for\n1dA Vb and AF were the lowest, yet they still surpassed 92%.\nCompared to the experimental outcomes obtained by the\ndirect interpretation of ECG signals by ChatGPT, SignalGPT\nexhibits significantly better performance. The findings of the\nChatGPT experiments reveal that the model cannot make\nprecise diagnoses and cannot effectively leverage its knowl-\nedge base expertise without prompt engineering support.\nIn contrast, the proposed SignalGPT system demonstrates\nremarkable performance by utilizing a biomedical signal\nprocessing pipeline module that enhances the accuracy of\nECG analysis. The experimental outcomes thus illustrate\nthe essential role of an efficient engineering module in\nfacilitating the optimal utilization of the GPT’s inherent\nknowledge base.\nV. CONCLUSIONS AND DISCUSSIONS\nIn conclusion, we propose a collaborative system called\nSignalGPT, which combines multiple biomedical signal pro-\ncessing engines with the state-of-the-art LLM (i.e. Chat-\nGPT). SignalGPT provides a powerful tool for solving task-\nspecific problems in medical signal processing. In particular,\nthe system’s ability to provide detailed interpretation and\nanalysis of input signals can enhance the accuracy and speed\nof interpretation and annotation, ultimately leading to better\nclinical and patient outcomes.\nOne of the critical advantages of SignalGPT is its potential\nto improve the efficiency of clinicians in making diagnoses\nand developing treatment plans. With the growing demand\nfor medical services and the increasing complexity of medi-\ncal data, clinicians are often faced with a significant burden\nof work. By automating some diagnostic and analytical tasks,\nSignalGPT can reduce this burden and allow clinicians to\nfocus on other essential aspects of patient care.\nAnother essential benefit of SignalGPT is its ability to\nidentify patterns and relationships within large amounts of\ndata that might be difficult or impossible to discern using\ntraditional methods. This is particularly important to inter-\npreting medical signals, where slight differences in signal\npatterns in a particular analysis or relative to historical data\ncan have significant implications for a patient’s situation.\nSignalGPT can identify these patterns and relationships using\nadvanced machine learning techniques, allowing for more\naccurate and timely diagnoses.\nOverall, the development of SignalGPT represents a sig-\nnificant step forward in medical signal processing. By pro-\nviding clinicians with a powerful tool for analyzing and in-\nterpreting large amounts of data, SignalGPT has the potential\nto improve the accuracy and speed of preliminary medical\ninterpretation, and ultimately leading to better patient and\nclinical outcomes. Nonetheless, SignalGPT is not without\nits limitations. The overall performance of the system is\nintrinsically tied to the effectiveness of the predictive model.\nSuboptimal model selection can significantly diminish the\naccuracy of SignalGPT’s diagnostic reports, potentially in-\nfluencing the clinical judgments made by physicians. While\nthere is still much work to be done to optimize the system’s\nperformance, the promise of SignalGPT suggests that the\nfuture of medical AI is bright.\nA. Human-expert and agent conversational system\nAs the medical community, industry, academia, and the\ngeneral public continue to debate the applicability, relevance\nand reliability of LLMs in the medical field, the power\nof these emerging tools in \"intelligent\" report drafting and\ndocumentation, as well as their conversational capability can\nenhance the administrative sides of medical practices, at the\nvery least, and to save time. We demonstrate this feature also\nin the conceptual application of SignalGPT in EEG reporting\nin Fig. 5. Building an embedded feature of a chatbot into\nsomething that was otherwise a patient data management\nsystem or conventional AI-assistive technology can create\nthe possibility of Human-expert and agent conversational\nhealth care on the way to a possibility for general intelli-\ngent machines and/or the creation of more domain-specific\nfoundational models.\nREFERENCES\n[1] H. Touvron, T. Lavril, G. Izacard, et al., “LLaMA:\nOpen and efficient foundation language models,”\narXiv preprint arXiv:2302.13971, 2023.\n[2] L. De Angelis, F. Baglivo, G. Arzilli, et al., “ChatGPT\nand the rise of large language models: The new AI-\ndriven infodemic threat in public health,” Available at\nSSRN 4352931, 2023.\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted July 6, 2023. ; https://doi.org/10.1101/2023.06.28.23291916doi: medRxiv preprint \n30-120 mins review and report12-24  hrs EEG\nStructured report is ready in minutes12-24  hrs EEG\nSignalGPT EEG Tech/Nurse\nEEG Tech/Nurse\nEEG Report EEG Report\nEEG + ECG\nEEG + ECG\nNeurologist\nNeurologist\nPatients may spend 5 to 10 days at EMU\nEpilepsy Monitoring Unit (EMU)\nEpilepsy Monitoring Unit (EMU)\n(a)\n(b)\nFig. 5. The role of BioSignal Copilot (SignalGPT) in enhancing the electroencephalogram (EEG) report preparation, for instance, in an epilepsy monitoring\nunit (EMU). (a) Shows EEG and ECG data flow (in sessions, the total can be as long as several days), including evoked potentials studies (Visual Evoked\nPotential Test, Brain Stem Auditory Evoked Response, Somatosensory Evoked Response), from a testing room to the Technologist and/or Nurses for record\nkeeping and report drafting to the neurologist. (b) Shows an alternative pathway where the time can be saved by using SignalGPT as a copilot in the\nmiddle.\n[3] Y . Shen, K. Song, X. Tan, D. Li, W. Lu, and Y .\nZhuang, “HuggingGPT: Solving AI tasks with Chat-\nGPT and its friends in Huggingface,” arXiv preprint\narXiv:2303.17580, 2023.\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted July 6, 2023. ; https://doi.org/10.1101/2023.06.28.23291916doi: medRxiv preprint \n[4] M. D. Wilson, GPT-4 is here. how can doctors\nuse generative AI now? — Chatbots can be help-\nful as \"first-draft\" office or research assistants, Mar.\n2023. [Online]. Available: https : / / www .\nmedpagetoday . com / special - reports /\nexclusives/103616.\n[5] P. Lee, S. Bubeck, and J. Petro, “Benefits, limits,\nand risks of GPT-4 as an AI chatbot for medicine,”\nNew England Journal of Medicine, vol. 388, no. 13,\npp. 1233–1239, 2023.\n[6] P. Rajpurkar and M. P. Lungren, “The current and\nfuture state of ai interpretation of medical images,”\nNew England Journal of Medicine, vol. 388, no. 21,\npp. 1981–1990, 2023.\n[7] K. Singhal, S. Azizi, T. Tu, et al., “Large language\nmodels encode clinical knowledge,” arXiv preprint\narXiv:2212.13138, 2022.\n[8] H. Nori, N. King, S. M. McKinney, D. Carignan, and\nE. Horvitz, “Capabilities of GPT-4 on medical chal-\nlenge problems,” arXiv preprint arXiv:2303.13375 ,\n2023.\n[9] S. Wang, Z. Zhao, X. Ouyang, Q. Wang, and D.\nShen, “Chatcad: Interactive computer-aided diagnosis\non medical image using large language models,” arXiv\npreprint arXiv:2302.07257, 2023.\n[10] F. Antaki, S. Touma, D. Milad, J. El-Khoury, and\nR. Duval, “Evaluating the performance of chatGPT\nin ophthalmology: An analysis of its successes and\nshortcomings,” Ophthalmology Science, p. 100 324,\n2023.\n[11] J. W. Ayers, A. Poliak, M. Dredze, et al., “Comparing\nphysician and artificial intelligence chatbot responses\nto patient questions posted to a public social media\nforum,” JAMA Internal Medicine, 2023.\n[12] C. Shaib, M. L. Li, S. Joseph, I. J. Marshall, J. J.\nLi, and B. C. Wallace, “Summarizing, simplifying,\nand synthesizing medical evidence using GPT-3 (with\nvarying success),” arXiv preprint arXiv:2305.06299,\n2023.\n[13] J. Qiu, L. Li, J. Sun, et al., “Large AI models in health\ninformatics: Applications, challenges, and the future,”\narXiv preprint arXiv:2303.11568, 2023.\n[14] V . Nair, E. Schumacher, G. Tso, and A. Kannan,\n“DERA: Enhancing large language model completions\nwith dialog-enabled resolving agents,” arXiv preprint\narXiv:2303.17071, 2023.\n[15] C. Wu, X. Zhang, Y . Zhang, Y . Wang, and W. Xie,\n“PMC-LLaMA: Further finetuning LLaMA on medi-\ncal papers,” arXiv preprint arXiv:2304.14454, 2023.\n[16] Q. Jin, Y . Yang, Q. Chen, and Z. Lu, “GeneGPT: Aug-\nmenting large language models with domain tools for\nimproved access to biomedical information,” ArXiv,\n2023.\n[17] M. Balas and E. B. Ing, “Conversational AI models for\nophthalmic diagnosis: Comparison of ChatGPT and\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted July 6, 2023. ; https://doi.org/10.1101/2023.06.28.23291916doi: medRxiv preprint \nthe Isabel Pro differential diagnosis generator,” JFO\nOpen Ophthalmology, vol. 1, p. 100 005, 2023.\n[18] V . Socrates, A. Gilson, K. Lopez, L. Chi, R. A.\nTaylor, and D. Chartash, “Predicting relations between\nSOAP note sections: The value of incorporating a\nclinical information model,” Journal of Biomedical\nInformatics, vol. 141, p. 104 360, 2023.\n[19] J. Cain, D. R. Malcom, and T. D. Aungst, “The role of\nartificial intelligence in the future of pharmacy educa-\ntion,” American Journal of Pharmaceutical Education,\np. 100 135, 2023.\n[20] K. D’Oosterlinck, F. Remy, J. Deleu, et al., “BioDEX:\nLarge-scale biomedical adverse drug event extrac-\ntion for real-world pharmacovigilance,” arXiv preprint\narXiv:2305.13395, 2023.\n[21] P. Seidl, A. Vall, S. Hochreiter, and G. Klambauer,\n“Enhancing activity prediction models in drug discov-\nery with the ability to understand human language,”\narXiv preprint arXiv:2303.03363, 2023.\n[22] V . Sorin, Y . Barash, E. Konen, and E. Klang, “Large\nlanguage models for oncological applications,” Jour-\nnal of Cancer Research and Clinical Oncology, pp. 1–\n4, 2023.\n[23] X. Liu, D. McDuff, G. Kovacs, et al., “Large language\nmodels are few-shot health learners,” arXiv preprint\narXiv:2305.15525, 2023.\n[24] Q. Xie and F. Wang, “Faithful AI in healthcare and\nmedicine,” medRxiv, pp. 2023–04, 2023.\n[25] J. D. Weisz, M. Muller, J. He, and S. Houde, “Toward\ngeneral design principles for generative ai applica-\ntions,” arXiv preprint arXiv:2301.05578, 2023.\n[26] G. Keeling, “Algorithmic bias, generalist models, and\nclinical medicine,” arXiv preprint arXiv:2305.04008,\n2023.\n[27] R. E. Harskamp and L. De Clercq, “Performance of\nChatGPT as an AI-assisted decision support tool in\nmedicine: A proof-of-concept study for interpreting\nsymptoms and management of common cardiac con-\nditions (AMSTELHEART-2),”medRxiv, pp. 2023–03,\n2023.\n[28] M. Agrawal, “Towards scalable structured data from\nclinical text,” Ph.D. dissertation, Massachusetts Insti-\ntute of Technology, 2023.\n[29] A. T. Gabrielson, A. Y . Odisho, and D. Canes, Har-\nnessing generative artificial intelligence to improve\nefficiency among urologists: Welcome ChatGPT, 2023.\n[30] A. J. Buabbas, B. Miskin, A. A. Alnaqi, et al., “Inves-\ntigating students’ perceptions towards artificial intel-\nligence in medical education,” in Healthcare, MDPI,\nvol. 11, 2023, p. 1298.\n[31] S. Y . Chng, P. J. Tern, M. R. Kan, and L. T. Cheng,\n“Automated labelling of radiology reports using natu-\nral language processing: Comparison of traditional and\nnewer methods,” Health Care Science, vol. 2, no. 2,\npp. 120–128, 2023.\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted July 6, 2023. ; https://doi.org/10.1101/2023.06.28.23291916doi: medRxiv preprint \n[32] M. Moor, O. Banerjee, Z. S. H. Abad, et al., “Foun-\ndation models for generalist medical artificial intelli-\ngence,” Nature, vol. 616, no. 7956, pp. 259–265, 2023.\n[33] S. Bubeck, V . Chandrasekaran, R. Eldan, et al.,\n“Sparks of artificial general intelligence: Early experi-\nments with GPT-4,” arXiv preprint arXiv:2303.12712,\n2023.\n[34] S. Mousavi, F. Afghah, F. Khadem, and U. R.\nAcharya, “ECG language processing (ELP): A new\ntechnique to analyze ECG signals,” Computer methods\nand programs in biomedicine, vol. 202, p. 105 959,\n2021.\n[35] O. Perlman, Y . Zigel, G. Amit, and A. Katz, “Car-\ndiac arrhythmia classification in 12-lead ECG using\nsynthetic atrial activity signal,” in 2012 IEEE 27th\nConvention of Electrical and Electronics Engineers in\nIsrael, IEEE, 2012, pp. 1–4.\n[36] A. Gibbs, M. Fitzpatrick, M. Lilburn, et al., “A univer-\nsal, high-performance ECG signal processing engine\nto reduce clinical burden,” Annals of Noninvasive\nElectrocardiology, vol. 27, no. 5, e12993, 2022.\n[37] J. Kwong and A. P. Chandrakasan, “An energy-\nefficient biomedical signal processing platform,” IEEE\nJournal of Solid-State Circuits, vol. 46, no. 7,\npp. 1742–1753, 2011.\n[38] S. Mitra, M. Mitra, and B. B. Chaudhuri, “A rough-\nset-based inference engine for ECG classification,”\nIEEE Transactions on instrumentation and measure-\nment, vol. 55, no. 6, pp. 2198–2206, 2006.\n[39] H. V . Denysyuk, R. J. Pinto, P. M. Silva, et al.,\n“Algorithms for automated diagnosis of cardiovascular\ndiseases based on ECG data: A comprehensive sys-\ntematic review,” Heliyon, 2023.\n[40] L. G. Tereshchenko, D. Gatz, A. Feeny, and F. K.\nKorley, “Automated analysis of the 12-lead ECG in\nthe emergency department: Association between high-\nsensitivity cardiac troponin I and the cardiac electrical\nbiomarker,” Critical pathways in cardiology, vol. 13,\nno. 1, pp. 25–28, 2014.\n[41] T. A. Mixon, E. Hardegree, J. Shah, M. Grable,\nand W. Fikes, “Sensitivity and specificity of the\nVectraplex electrocardiogram system with a cardiac\nelectric biomarker in the diagnosis of ST-elevation\nmyocardial infarction,” in Baylor University Medical\nCenter Proceedings, Taylor & Francis, vol. 32, 2019,\npp. 331–335.\n[42] L. G. Tereshchenko, A. Feeny, E. Shelton, et al.,\n“Dynamic changes in high-sensitivity cardiac troponin\nI are associated with dynamic changes in sum absolute\nQRST integral on surface electrocardiogram in acute\ndecompensated heart failure,” Annals of Noninvasive\nElectrocardiology, vol. 22, no. 1, e12379, 2017.\n[43] L. G. Tereshchenko and A. Feeny, “Patient-specific\ntime-varying association between spatial and temporal\nvariability in repolarization and high sensitivity tro-\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted July 6, 2023. ; https://doi.org/10.1101/2023.06.28.23291916doi: medRxiv preprint \nponin I,” in 2016 Computing in Cardiology Confer-\nence (CinC), IEEE, 2016, pp. 333–336.\n[44] I. Strebel, R. Twerenbold, J. Boeddinghaus, et al.,\n“Diagnostic value of the cardiac electrical biomarker,\na novel ecg marker indicating myocardial injury, in pa-\ntients with symptoms suggestive of non-ST-elevation\nmyocardial infarction,” Annals of noninvasive electro-\ncardiology, vol. 23, no. 4, e12538, 2018.\n[45] T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettle-\nmoyer, “QLoRA: Efficient finetuning of quantized\nLLMs,” arXiv preprint arXiv:2305.14314, 2023.\n[46] P. Henderson, M. Krass, L. Zheng, et al., “Pile of law:\nLearning responsible data filtering from the law and a\n256GB open-source legal dataset,”Advances in Neural\nInformation Processing Systems, vol. 35, pp. 29 217–\n29 234, 2022.\n[47] R. Anil, A. M. Dai, O. Firat, et al., “PaLM 2 Technical\nReport,” arXiv preprint arXiv:2305.10403, 2023.\n[48] OpenAI, “GPT-4 Technical Report,” arXiv, 2023.\n[49] X. Ren, P. Zhou, X. Meng, et al., “Pangu-Σ:\nTowards trillion parameter language model with\nsparse heterogeneous computing,” arXiv preprint\narXiv:2303.10845, 2023.\n[50] A. H. Ribeiro, M. H. Ribeiro, G. M. M. Paixão, et al.,\n“Automatic diagnosis of the 12-lead ECG using a deep\nneural network,” Nature Communications, vol. 11,\nno. 1, p. 1760, 2020. DOI : https://doi.org/\n10.1038/s41467-020-15432-4.\n[51] D. Makowski, T. Pham, Z. J. Lau, et al., “Neu-\nroKit2: A python toolbox for neurophysiological sig-\nnal processing,” Behavior Research Methods, vol. 53,\nno. 4, pp. 1689–1696, Feb. 2021. DOI : 10.3758/\ns13428 - 020 - 01516 - y. [Online]. Available:\nhttps : / / doi . org / 10 . 3758 % 2Fs13428 -\n020-01516-y.\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted July 6, 2023. ; https://doi.org/10.1101/2023.06.28.23291916doi: medRxiv preprint ",
  "topic": "Biosignal",
  "concepts": [
    {
      "name": "Biosignal",
      "score": 0.9381975531578064
    },
    {
      "name": "Computer science",
      "score": 0.7001411318778992
    },
    {
      "name": "Key (lock)",
      "score": 0.5400339961051941
    },
    {
      "name": "SIGNAL (programming language)",
      "score": 0.5319125056266785
    },
    {
      "name": "Wearable computer",
      "score": 0.5317104458808899
    },
    {
      "name": "Noise (video)",
      "score": 0.4982266426086426
    },
    {
      "name": "Reliability (semiconductor)",
      "score": 0.44233253598213196
    },
    {
      "name": "Power (physics)",
      "score": 0.3828539252281189
    },
    {
      "name": "Data science",
      "score": 0.3822970390319824
    },
    {
      "name": "Data mining",
      "score": 0.3699681758880615
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3552626967430115
    },
    {
      "name": "Telecommunications",
      "score": 0.21348896622657776
    },
    {
      "name": "Computer security",
      "score": 0.1748165786266327
    },
    {
      "name": "Embedded system",
      "score": 0.1637602150440216
    },
    {
      "name": "Wireless",
      "score": 0.09315904974937439
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Image (mathematics)",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ]
}