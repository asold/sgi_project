{
  "title": "Harnessing LLMs for multi-dimensional writing assessment: Reliability and alignment with human judgments",
  "url": "https://openalex.org/W4400485493",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2106763039",
      "name": "Xiaoyi Tang",
      "affiliations": [
        "University of Science and Technology Beijing"
      ]
    },
    {
      "id": "https://openalex.org/A2098006332",
      "name": "Hongwei Chen",
      "affiliations": [
        "University of Science and Technology Beijing"
      ]
    },
    {
      "id": "https://openalex.org/A2568529061",
      "name": "Daoyu Lin",
      "affiliations": [
        "Aerospace Information Research Institute",
        "Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2104631388",
      "name": "Kexin Li",
      "affiliations": [
        "University of Science and Technology Beijing"
      ]
    },
    {
      "id": "https://openalex.org/A2106763039",
      "name": "Xiaoyi Tang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098006332",
      "name": "Hongwei Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2568529061",
      "name": "Daoyu Lin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2104631388",
      "name": "Kexin Li",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4323655724",
    "https://openalex.org/W4392202731",
    "https://openalex.org/W4366403195",
    "https://openalex.org/W2955427418",
    "https://openalex.org/W3201077663",
    "https://openalex.org/W6720000382",
    "https://openalex.org/W4229364131",
    "https://openalex.org/W4251941390",
    "https://openalex.org/W3040446934",
    "https://openalex.org/W3087421864",
    "https://openalex.org/W2979629418",
    "https://openalex.org/W4384500994",
    "https://openalex.org/W3212331720",
    "https://openalex.org/W2790130598",
    "https://openalex.org/W3097478885",
    "https://openalex.org/W2897175772",
    "https://openalex.org/W6805186932",
    "https://openalex.org/W4384934594",
    "https://openalex.org/W3006224918",
    "https://openalex.org/W1590881479",
    "https://openalex.org/W6741825281",
    "https://openalex.org/W6784475431",
    "https://openalex.org/W4293917978",
    "https://openalex.org/W4220962802",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W4309685935",
    "https://openalex.org/W6848517858",
    "https://openalex.org/W6857369960",
    "https://openalex.org/W4387125424",
    "https://openalex.org/W4390233432",
    "https://openalex.org/W3044596693",
    "https://openalex.org/W2922211092",
    "https://openalex.org/W6683687954",
    "https://openalex.org/W2135972341",
    "https://openalex.org/W4391915208",
    "https://openalex.org/W1991462213",
    "https://openalex.org/W2001833328",
    "https://openalex.org/W2560739164",
    "https://openalex.org/W2110277766",
    "https://openalex.org/W6731959695",
    "https://openalex.org/W6731571318",
    "https://openalex.org/W4200626620",
    "https://openalex.org/W6753456860",
    "https://openalex.org/W3090794351",
    "https://openalex.org/W4205523551",
    "https://openalex.org/W6857180886",
    "https://openalex.org/W6856024400",
    "https://openalex.org/W3185341429",
    "https://openalex.org/W4386322180",
    "https://openalex.org/W3182546273",
    "https://openalex.org/W4280651558",
    "https://openalex.org/W3217357366",
    "https://openalex.org/W4387815597",
    "https://openalex.org/W4385570141",
    "https://openalex.org/W3092489168",
    "https://openalex.org/W4388046560",
    "https://openalex.org/W4237813545",
    "https://openalex.org/W2752294398",
    "https://openalex.org/W1593930920",
    "https://openalex.org/W4313678819",
    "https://openalex.org/W1549393725"
  ],
  "abstract": "Recent advancements in natural language processing, computational linguistics, and Artificial Intelligence (AI) have propelled the use of Large Language Models (LLMs) in Automated Essay Scoring (AES), offering efficient and unbiased writing assessment. This study assesses the reliability of LLMs in AES tasks, focusing on scoring consistency and alignment with human raters. We explore the impact of prompt engineering, temperature settings, and multi-level rating dimensions on the scoring performance of LLMs. Results indicate that prompt engineering significantly affects the reliability of LLMs, with GPT-4 showing marked improvement over GPT-3.5 and Claude 2, achieving 112% and 114% increase in scoring accuracy under the criteria and sample-referenced justification prompt. Temperature settings also influence the output consistency of LLMs, with lower temperatures producing scores more in line with human evaluations, which is essential for maintaining fairness in large-scale assessment. Regarding multi-dimensional writing assessment, results indicate that GPT-4 performs well in dimensions regarding Ideas (QWK=0.551) and Organization (QWK=0.584) under well-crafted prompt engineering. These findings pave the way for a comprehensive exploration of LLMs' broader educational implications, offering insights into their capability to refine and potentially transform writing instruction, assessment, and the delivery of diagnostic and personalized feedback in the AI-powered educational age. While this study attached importance to the reliability and alignment of LLM-powered multi-dimensional AES, future research should broaden its scope to encompass diverse writing genres and a more extensive sample from varied backgrounds.",
  "full_text": null,
  "topic": "Consistency (knowledge bases)",
  "concepts": [
    {
      "name": "Consistency (knowledge bases)",
      "score": 0.708877444267273
    },
    {
      "name": "Reliability (semiconductor)",
      "score": 0.6510682702064514
    },
    {
      "name": "Scope (computer science)",
      "score": 0.5716596245765686
    },
    {
      "name": "Writing assessment",
      "score": 0.48118406534194946
    },
    {
      "name": "Sample (material)",
      "score": 0.44770342111587524
    },
    {
      "name": "Computer science",
      "score": 0.4232825040817261
    },
    {
      "name": "Psychology",
      "score": 0.3905841112136841
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3089074492454529
    },
    {
      "name": "Mathematics education",
      "score": 0.21620574593544006
    },
    {
      "name": "Power (physics)",
      "score": 0.0
    },
    {
      "name": "Chromatography",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ]
}