{
  "title": "Unlocking the Potential of User Feedback: Leveraging Large Language Model as User Simulators to Enhance Dialogue System",
  "url": "https://openalex.org/W4387848958",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2101652490",
      "name": "Zhiyuan Hu",
      "affiliations": [
        "National University of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A2115650769",
      "name": "Yue Feng",
      "affiliations": [
        "University College London"
      ]
    },
    {
      "id": "https://openalex.org/A2257712515",
      "name": "Anh Tuan Luu",
      "affiliations": [
        "Nanyang Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A1755863881",
      "name": "Bryan Hooi",
      "affiliations": [
        "National University of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A1518226153",
      "name": "Aldo Lipani",
      "affiliations": [
        "University College London"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4200253303",
    "https://openalex.org/W4221167095",
    "https://openalex.org/W4284708952",
    "https://openalex.org/W3216055172",
    "https://openalex.org/W4284695140",
    "https://openalex.org/W3214585123",
    "https://openalex.org/W4385574182",
    "https://openalex.org/W4283789934",
    "https://openalex.org/W2997771882",
    "https://openalex.org/W3156287428",
    "https://openalex.org/W4306317758",
    "https://openalex.org/W1593271688"
  ],
  "abstract": "Dialogue systems and large language models (LLMs) have gained considerable attention. However, the direct utilization of LLMs as task-oriented dialogue (TOD) models has been found to underperform compared to smaller task-specific models. Nonetheless, it is crucial to acknowledge the significant potential of LLMs and explore improved approaches for leveraging their impressive abilities. Motivated by the goal of leveraging LLMs, we propose an alternative approach called User-Guided Response Optimization (UGRO) to combine it with a smaller TOD model. This approach uses LLM as an annotation-free user simulator to assess dialogue responses, combining them with smaller fine-tuned end-to-end TOD models. By utilizing the satisfaction feedback generated by LLMs, UGRO further optimizes the supervised fine-tuned TOD model. Specifically, the TOD model takes the dialogue history as input and, with the assistance of the user simulator's feedback, generates high-satisfaction responses that meet the user's requirements. Through empirical experiments on two TOD benchmarks, we validate the effectiveness of our method. The results demonstrate that our approach outperforms previous state-of-the-art (SOTA) results.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7401250004768372
    },
    {
      "name": "Task (project management)",
      "score": 0.7134284973144531
    },
    {
      "name": "Humanâ€“computer interaction",
      "score": 0.49528613686561584
    },
    {
      "name": "Language model",
      "score": 0.4326726496219635
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3457590937614441
    },
    {
      "name": "Engineering",
      "score": 0.11017772555351257
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I165932596",
      "name": "National University of Singapore",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I45129253",
      "name": "University College London",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I172675005",
      "name": "Nanyang Technological University",
      "country": "SG"
    }
  ],
  "cited_by": 16
}