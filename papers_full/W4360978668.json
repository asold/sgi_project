{
  "title": "Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding",
  "url": "https://openalex.org/W4360978668",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2594665765",
      "name": "Ziang Xiao",
      "affiliations": [
        "Johns Hopkins University",
        "Microsoft (United States)",
        "Research Canada"
      ]
    },
    {
      "id": "https://openalex.org/A2127071220",
      "name": "Xingdi Yuan",
      "affiliations": [
        "Microsoft (Canada)"
      ]
    },
    {
      "id": "https://openalex.org/A2158863895",
      "name": "Q. Vera Liao",
      "affiliations": [
        "Microsoft (Canada)"
      ]
    },
    {
      "id": "https://openalex.org/A2749063907",
      "name": "Rania Abdelghani",
      "affiliations": [
        "Institut national de recherche en informatique et en automatique"
      ]
    },
    {
      "id": "https://openalex.org/A2566444938",
      "name": "Pierre-Yves Oudeyer",
      "affiliations": [
        "Institut national de recherche en informatique et en automatique"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4226071117",
    "https://openalex.org/W3173777717",
    "https://openalex.org/W3164718925",
    "https://openalex.org/W2252208617",
    "https://openalex.org/W2546996098",
    "https://openalex.org/W2588117145",
    "https://openalex.org/W3124026294",
    "https://openalex.org/W4296965999",
    "https://openalex.org/W4297801719",
    "https://openalex.org/W4238846128",
    "https://openalex.org/W4229005866",
    "https://openalex.org/W4286252734",
    "https://openalex.org/W2142225512",
    "https://openalex.org/W4221055872",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4294214983",
    "https://openalex.org/W387031967",
    "https://openalex.org/W4224308101"
  ],
  "abstract": "Qualitative analysis of textual contents unpacks rich and valuable\\ninformation by assigning labels to the data. However, this process is often\\nlabor-intensive, particularly when working with large datasets. While recent\\nAI-based tools demonstrate utility, researchers may not have readily available\\nAI resources and expertise, let alone be challenged by the limited\\ngeneralizability of those task-specific models. In this study, we explored the\\nuse of large language models (LLMs) in supporting deductive coding, a major\\ncategory of qualitative analysis where researchers use pre-determined codebooks\\nto label the data into a fixed set of codes. Instead of training task-specific\\nmodels, a pre-trained LLM could be used directly for various tasks without\\nfine-tuning through prompt learning. Using a curiosity-driven questions coding\\ntask as a case study, we found, by combining GPT-3 with expert-drafted\\ncodebooks, our proposed approach achieved fair to substantial agreements with\\nexpert-coded results. We lay out challenges and opportunities in using LLMs to\\nsupport qualitative coding and beyond.\\n",
  "full_text": "Supporting Qualitative Analysis with Large Language\nModels: Combining Codebook with GPT-3 for Deductive\nCoding\nZIANG XIAO, Microsoft Research, Canada\nXINGDI YUAN, Microsoft Research, Canada\nQ. VERA LIAO, Microsoft Research, Canada\nRANIA ABDELGHANI, Inria, France\nPIERRE-YVES OUDEYER, Inria, France\nQualitative analysis of textual contents unpacks rich and valuable information by assigning labels to the data.\nHowever, this process is often labor-intensive, particularly when working with large datasets. While recent\nAI-based tools demonstrate utility, researchers may not have readily available AI resources and expertise, let\nalone be challenged by the limited generalizability of those task-specific models. In this study, we explored the\nuse of large language models (LLMs) in supporting deductive coding, a major category of qualitative analysis\nwhere researchers use pre-determined codebooks to label the data into a fixed set of codes. Instead of training\ntask-specific models, a pre-trained LLM could be used directly for various tasks without fine-tuning through\nprompt learning. Using a curiosity-driven questions coding task as a case study, we found, by combining\nGPT-3 with expert-drafted codebooks, our proposed approach achieved fair to substantial agreements with\nexpert-coded results. We lay out challenges and opportunities in using LLMs to support qualitative coding\nand beyond.\nCCS Concepts: ‚Ä¢ Human-centered computing ‚ÜíHCI design and evaluation methods ; ‚Ä¢ Computing\nmethodologies ‚ÜíNatural language processing .\nAdditional Key Words and Phrases: Qualitative Analysis, Deductive Coding, Large Language Model, GPT-3\nACM Reference Format:\nZiang Xiao, Xingdi Yuan, Q. Vera Liao, Rania Abdelghani, and Pierre-Yves Oudeyer. 2023. Supporting Qualitative\nAnalysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding. In 28th\nInternational Conference on Intelligent User Interfaces (IUI ‚Äô23 Companion), March 27‚Äì31, 2023, Sydney, NSW,\nAustralia. ACM, New York, NY, USA, 6 pages. https://doi.org/10.1145/3581754.3584136\n1 INTRODUCTION\nQualitative coding is a method of qualitative analysis that is used to identify patterns and categories\nin qualitative data, such as social media posts, open-ended survey responses, and field notes.\nOften, scientists will use coded data to derive theory or build models to understand the observed\nphenomenon further [5]. Qualitative coding can be a challenging process because it requires the\nresearcher to understand and analyze data that is often complex, nuanced, and open to multiple\ninterpretations. Multiple researchers need to spend a significant amount of time and effort to review\nthe data, develop a codebook that can accurately describe each label, and iteratively code the data\nuntil reaching a reasonable inter-rater agreement. It is particularly hard when working with large\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\nthe full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses,\ncontact the owner/author(s).\nIUI ‚Äô23 Companion, March 27‚Äì31, 2023, Sydney, NSW, Australia\n¬© 2023 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-0107-8/23/03.\nhttps://doi.org/10.1145/3581754.3584136\n1\narXiv:2304.10548v1  [cs.CL]  17 Apr 2023\nIUI ‚Äô23 Companion, March 27‚Äì31, 2023, Sydney, NSW, Australia Xiao et al.\ndatasets. In this study, we explore a novel approach that leverages large language models (LLMs) to\nfacilitate qualitative coding.\nResearchers have built AI-based tools to assist qualitative analysis [7, 10‚Äì12]. These tools use\nnatural language processing (NLP) and machine learning (ML) algorithms to help researchers\nidentify patterns and themes in qualitative data. Two categories of models are often used, 1)\nunsupervised models, e.g., topic models, to help researchers discover themes, or 2) supervised\nmodels, e.g., logistic regression, to classify data into labels. However, both methods face their own\nchallenges. Unsupervised models are difficult to steer. It is difficult for researchers to use those\nmodels for their complex or nuanced research questions. And supervised models often require\nhigh-quality large datasets or computing resources to achieve reasonable performance. Therefore,\nmost of today‚Äôs qualitative coding still relies on manual effort.\nThe recent advent of LLMs (e.g., GPT-3 [2], PaLM [3], OPT [16]) offers new capabilities, including\ncreative writing [14], programming 1, etc. Unlike traditional task-specific models, LLMs accept\nnatural language prompts as input to perform various tasks [8]. For example, LLMs could perform\nclassification tasks if the prompt specifies a set of labels as the output space [ 4]. Compared to\nunsupervised models, the prompt could include specific instructions and examples (e.g., a codebook)\nto increase LLMs‚Äô performance in a new task with unseen data in a zero-shot/few-shot fashion.\nPrior work shows that LLMs can be prompted to boost an NLG system‚Äôs performance by selecting\nbetter outputs from sampled candidates, according to some pre-defined metrics [15]. Since LLMs\noperate effectively with natural language input and do not require training datasets, they lower the\nbarriers for researchers without extensive AI expertise or resources to leverage AI capabilities in\ndata analysis (although many of today‚Äôs LLMs are proprietary).\nAlthough recent studies have demonstrated LLMs utility in many domains, studies have shown\nLLMs are error-prone and have limited capability in capturing language structure and nuanced\nmeanings [6], which are crucial in qualitative analysis. Therefore, in this preliminary study, we\nasked two research questions,\n‚Ä¢RQ1: To what extent does our LLM-based approach agree with experts in a deductive coding\ntask?\n‚Ä¢RQ2: How do different prompt designs affect the coding results?\nWe examined LLMs‚Äô capability in facilitating a deductive coding task where we combined GPT-3\nwith expert-developed codebooks to analyze children‚Äôs curiosity-driven questions in terms of\nquestion complexity and syntactic structure. We found our proposed approach achieved fair to\nsubstantial agreements with experts (Question complexity: Cohen‚Äôs ùúÖ = 0.61; Syntactic Structure:\nCohen‚Äôs ùúÖ = 0.38). Based on our preliminary findings, we present challenges and opportunities for\nutilizing LLMs in qualitative analysis.\n2 DEDUCTIVE CODING TASK\nWe selected a deductive coding task as our starting point. The goal of deductive coding is to label\nthe data based on a codebook. It is a top-down process where the researchers start by developing a\ncodebook with an initial set of codes along with descriptions and examples based on the research\nfocus or theory [5]. Note that a coding process often involves both inductive coding (e.g. developing\nthe code book) and deductive coding (coding all the data according to a code book). Our approach\ncan be used to complete the second part or combined with the first part to help coders rapidly\niterate on their codebook.\n1https://github.com/features/copilot\n2\nSupporting Qualitative Analysis with Large Language Models IUI ‚Äô23 Companion, March 27‚Äì31, 2023, Sydney, NSW, Australia\n2.1 Case Study: Curiosity-driven questions Analysis\nWe examined our approach in analyzing children‚Äôs curiosity-driven questions. Understanding\nchildren‚Äôs ability to ask curiosity-driven questions informs psychologists of a child‚Äôs learning stage.\nWe looked at two dimensions of a curiosity-driven question, question complexity and syntactic\nstructure. The question complexity looks at if the answer to a question is a simple fact (e.g., ‚ÄúHow big\nis a dinosaur?‚Äù) or requires explaining a mechanism, a relationship, etc.(e.g., ‚ÄúWhy were dinosaurs\nso big?‚Äù) [13]. The syntactic structure has four categories, 1) ‚Äòclosed‚Äô or declarative questions (e.g.,\n‚ÄúDinosaurs were big?‚Äù), 2) questions with questioning words in the middle of the sentence (e.g.,\n‚ÄúThe dinosaurs were how big?‚Äù), 3) questions without an interrogative formulation (e.g., ‚ÄúWhy the\ndinosaurs are big?‚Äù), and 4) questions with a questioning word at the beginning of the sentence\nthat has interrogative syntax (e.g., ‚ÄúWhy are dinosaurs big?‚Äù).\nWe collected a dataset with 668 children‚Äôs questions in French [1] 2. A team of psychologists\nhas developed a codebook and coded each question on the dimension of question complexity and\nsyntactic structure. Our chosen dimensions cover two main categories of deductive coding, binary\ncoding, and multi-level coding, with one focusing on the semantic meaning and the other looking\nat the syntactic structure. Additionally, the dataset and codebook have never been published online\nwhich is unseen by LLMs.\n3 GPT-3 SETUP AND PROMPT DESIGN\nWe chose GPT-3 (davinci-text-002) with a temperature of 0.0 during the prompting process, because\nit was the most advanced version of GPT-3 that was publicly available when we conducted the\nexperiments and 0.0 temperature (greedy decoding) guarantees the reproducibility of this study.\nWe explored two design dimensions of the prompt,\n‚Ä¢Codebook-centered vs. Example-centered: This dimension regards the structure of a prompt.\nIn the codebook-centered prompt, we designed the prompt similar to how researchers read a\ncodebook. The prompt follows the structure of [Code/ Description/ Examples]. For exam-\nple, Code: HIGH; Description: the answer to this question is not a simple fact but requires\nexplaining a mechanism, a relationship, etc.; Examples: Why were dinosaurs so big? The\nexample-centered approach is inspired by the in-context learning in recent LLM works\nwhere the prompt explains the rationale behind each example [8]. For example, ‚ÄúWhy were\ndinosaurs so big?‚Äù is an example of ‚ÄúHIGH‚Äù because the answer to this question is not a sim-\nple fact but requires explaining a mechanism, a relationship, etc. The code, examples, and\ndescriptions are the same for both designs.\n‚Ä¢Zero-shot vs. One-shot vs. Few-shots: Since recent work showed conflicting results on the\nnumber of examples in a prompt [8], we explored different prompt settings. In the Zero-shot\nsetting, we give only Code and Description in Codebook-centered prompts 3. For the One-\nshot setting, we provided only one example for each code. And for the few-shot setting, we\nprovided five examples for each code.\nFor all prompt variants, we included an identity modifier, ‚ÄúI am a developmental psychologist\nwho has expertise in linguistics. ‚Äù and an instruction to constrain output space, ‚ÄúChoose from the\nfollowing candidates: [Code Set]‚Äù.\n2For question complexity, we first used GPT-3 to translate questions into English. For the syntactic structure, we kept\nquestions in French to preserve its syntactic structure.\n3Since the example-centered approach requires at least one example, we did not have the zero-shot setting for the example-\ncentered approach\n3\nIUI ‚Äô23 Companion, March 27‚Äì31, 2023, Sydney, NSW, Australia Xiao et al.\n0.0\n0.3\n0.5\n0.8\n1.0\nCodebook-based Example-based Expert\n0.52\n0.61\n0.88\n0.40\n0.60\n0.40\nZero-shot\nOne-shot\nFew-shot\n(a) Cohen‚Äôs ùúÖ for Question Complexity\n0.0\n0.3\n0.5\n0.8\n1.0\nCodebook-based Example-based Expert\n0.30\n0.35\n0.90\n0.13\n0.38\n0.11\n(b) Cohen‚Äôs ùúÖ for Syntactic Structure\nFig. 1. The Cohen‚Äôs ùúÖ between GPT-3 and experts shows substantial agreement in Question Complexity coding\nand fair agreement in Syntactic Structure coding. In general, Codebook-centered prompts with examples\nachieves the highest agreement.\n4 RESULTS\nWe measured the performance of our GPT-3 based approach with Cohen‚Äôs Kappa [ 9]. Cohen‚Äôs\nKappa measures inter-rater reliability, which indicates how two coders agree with each other. We\ncomputed two sets of Cohen‚Äôs Kappa, between GPT-3 with the expert‚Äôs final coding results and\nbetween two experts who originally coded the dataset using the same codebook.\nFor RQ1, our results suggest that it is feasible to use GPT-3 with an expert-developed codebook for\ndeductive coding. When analyzing curiosity-driven questions, our GPT-3-based approach achieved\nfair (Syntactic Structure: Cohen‚Äôs ùúÖ = 0.38) to substantial (Question complexity: Cohen‚Äôs ùúÖ = 0.61)\nagreement with expert rating (Cohen‚Äôs ùúÖ‚Äôs interpretation is based on [ 9]), see Fig. 1. However,\nthere is a gap between experts‚Äô agreement with our approach and the agreement among experts\n(Question complexity: Cohen‚Äôs ùúÖ = 0.88; Syntactic Structure: Cohen‚Äôs ùúÖ = 0.90).\nFor RQ2, we examined the different prompt designs. We found the codebook-centered design\nperforms better than the example-centered designs, see Fig. 1. And examples play an important role.\nWe observed the largest performance gain when shifting from a zero-shot to a one-shot setting.\nHowever, the performance between one-shot and few-shot settings did not differ much.\n5 OPPORTUNITIES AND CHALLENGES\nOur preliminary findings indicate the feasibility of using LLMs for qualitative analysis. In a deductive\ncoding task, by combining GPT-3 and a codebook, our LLM-based approach achieved fair to\nsubstantial agreement with experts. Considering the accessibility and flexibility of LLMs, we believe\nthis approach has the potential to effectively help researchers to analyze qualitative data, especially\nfor increasingly large datasets. We lay out a few challenges and opportunities for our future studies,\n‚Ä¢Interrogate Model Capability: In this preliminary exploration, we only measured the level of\nagreement. To better understand model capability, we ought to conduct more detailed error\nanalyses on disagreed items. Also, it is unclear if the LLM-based method could be extended\n4\nSupporting Qualitative Analysis with Large Language Models IUI ‚Äô23 Companion, March 27‚Äì31, 2023, Sydney, NSW, Australia\nto different contexts and different coding schemes where the coder needs to capture more\nnuanced signals.\n‚Ä¢Design for Appropriate Reliance: Although our preliminary results show fair to substantial\nagreement with expert rating, the model produces incorrect labels. When deploying such\nan imperfect AI system, we must design for appropriate reliance to prevent over-trusting\nand misuse. For example, when designing the interface, we could consider explainable AI\nmethods to calibrate user trust over time.\n‚Ä¢Design Codebook for LLMs: We constructed our prompts using the codebook for experts.\nAlthough it provides transparency and explicit control, it may limit the model‚Äôs performance.\nFuture study is required to understand how to design a more effective codebook for task\nperformance and model understanding.\n‚Ä¢Support Inductive Coding: We demonstrated the feasibility of using LLMs in deductive coding.\nHowever, for inductive coding, where the process is more bottom-up and exploratory, novel\ninteraction and Human-AI collaboration diagrams are required. We should study interaction\ntechniques and controls to let researchers use LLMs more effectively in the qualitative\nanalysis.\nREFERENCES\n[1] Rania Abdelghani, Pierre-Yves Oudeyer, Edith Law, Catherine de Vulpillieres, and H√©lene Sauz√©on. 2022. Conversational\nagents for fostering curiosity-driven learning in children. arXiv preprint arXiv:2204.03546 (2022).\n[2] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan,\nPranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,\nRewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler,\nMateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\nSutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information\nProcessing Systems , H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates,\nInc., 1877‚Äì1901. https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf\n[3] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham,\nHyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways.\narXiv preprint arXiv:2204.02311 (2022).\n[4] Tianyu Gao, Adam Fisch, and Danqi Chen. 2021. Making Pre-trained Language Models Better Few-shot Learners. In\nProceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint\nConference on Natural Language Processing (Volume 1: Long Papers) . Association for Computational Linguistics, Online,\n3816‚Äì3830. https://doi.org/10.18653/v1/2021.acl-long.295\n[5] Hsiu-Fang Hsieh and Sarah E Shannon. 2005. Three approaches to qualitative content analysis. Qualitative health\nresearch 15, 9 (2005), 1277‚Äì1288.\n[6] Diane M Korngiebel and Sean D Mooney. 2021. Considering the possibilities and pitfalls of Generative Pre-trained\nTransformer 3 (GPT-3) in healthcare delivery. NPJ Digital Medicine 4, 1 (2021), 1‚Äì3.\n[7] Jasy Suet Yan Liew, Nancy McCracken, Shichun Zhou, and Kevin Crowston. 2014. Optimizing features in active\nmachine learning for complex qualitative content analysis. In Proceedings of the ACL 2014 Workshop on Language\nTechnologies and Computational Social Science . 44‚Äì48.\n[8] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021. Pre-train, prompt,\nand predict: A systematic survey of prompting methods in natural language processing.arXiv preprint arXiv:2107.13586\n(2021).\n[9] Mary L McHugh. 2012. Interrater reliability: the kappa statistic. Biochemia medica 22, 3 (2012), 276‚Äì282.\n[10] Michael Muller, Shion Guha, Eric PS Baumer, David Mimno, and N Sadat Shami. 2016. Machine learning and grounded\ntheory method: convergence, divergence, and combination. In Proceedings of the 19th international conference on\nsupporting group work . 3‚Äì8.\n[11] Pablo Paredes, Ana Rufino Ferreira, Cory Schillaci, Gene Yoo, Pierre Karashchuk, Dennis Xing, Coye Cheshire, and\nJohn Canny. 2017. Inquire: Large-scale early insight discovery for qualitative research. In Proceedings of the 2017 ACM\nConference on Computer Supported Cooperative Work and Social Computing . 1562‚Äì1575.\n[12] Tim Rietz and Alexander Maedche. 2021. Cody: An AI-Based System to Semi-Automate Coding for Qualitative\nResearch. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI\n‚Äô21). Association for Computing Machinery, New York, NY, USA, Article 394, 14 pages. https://doi.org/10.1145/3411764.\n5\nIUI ‚Äô23 Companion, March 27‚Äì31, 2023, Sydney, NSW, Australia Xiao et al.\n3445591\n[13] William W Wilen. 1991. Questioning skills, for teachers. What research says to the teacher. (1991).\n[14] Ann Yuan, Andy Coenen, Emily Reif, and Daphne Ippolito. 2022. Wordcraft: Story Writing With Large Language\nModels. In 27th International Conference on Intelligent User Interfaces . 841‚Äì852.\n[15] Xingdi Yuan, Tong Wang, Yen-Hsiang Wang, Emery Fine, Rania Abdelghani, Pauline Lucas, H√©l√®ne Sauz√©on, and\nPierre-Yves Oudeyer. 2022. Selecting Better Samples from Pre-trained LLMs: A Case Study on Question Generation.\narXiv preprint arXiv:2209.11000 (2022).\n[16] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab,\nXian Li, Xi Victoria Lin, et al. 2022. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068\n(2022).\n6",
  "topic": "Codebook",
  "concepts": [
    {
      "name": "Codebook",
      "score": 0.8156088590621948
    },
    {
      "name": "Generalizability theory",
      "score": 0.7419017553329468
    },
    {
      "name": "Computer science",
      "score": 0.7380708456039429
    },
    {
      "name": "Coding (social sciences)",
      "score": 0.7227516174316406
    },
    {
      "name": "Task (project management)",
      "score": 0.4857807457447052
    },
    {
      "name": "Natural language processing",
      "score": 0.4776279330253601
    },
    {
      "name": "Curiosity",
      "score": 0.4773523807525635
    },
    {
      "name": "Qualitative analysis",
      "score": 0.46784886717796326
    },
    {
      "name": "Qualitative research",
      "score": 0.4660654366016388
    },
    {
      "name": "Task analysis",
      "score": 0.4528069496154785
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4410209655761719
    },
    {
      "name": "Qualitative property",
      "score": 0.43636730313301086
    },
    {
      "name": "Machine learning",
      "score": 0.40898334980010986
    },
    {
      "name": "Data science",
      "score": 0.3622381091117859
    },
    {
      "name": "Psychology",
      "score": 0.16827791929244995
    },
    {
      "name": "Social psychology",
      "score": 0.104188472032547
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Social science",
      "score": 0.0
    },
    {
      "name": "Developmental psychology",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Sociology",
      "score": 0.0
    },
    {
      "name": "Statistics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210099137",
      "name": "Research Canada",
      "country": "CA"
    },
    {
      "id": "https://openalex.org/I145311948",
      "name": "Johns Hopkins University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1290206253",
      "name": "Microsoft (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4402554038",
      "name": "Microsoft Research Montr√©al (Canada)",
      "country": null
    },
    {
      "id": "https://openalex.org/I4210153468",
      "name": "Microsoft (Canada)",
      "country": "CA"
    }
  ]
}