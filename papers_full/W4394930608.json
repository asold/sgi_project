{
    "title": "ProSST: Protein Language Modeling with Quantized Structure and Disentangled Attention",
    "url": "https://openalex.org/W4394930608",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2129494870",
            "name": "Mingchen Li",
            "affiliations": [
                "Artificial Intelligence in Medicine (Canada)",
                "Beijing Academy of Artificial Intelligence"
            ]
        },
        {
            "id": "https://openalex.org/A2113131905",
            "name": "Pan Tan",
            "affiliations": [
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A2886955574",
            "name": "Xinzhu Ma",
            "affiliations": [
                "Beijing Academy of Artificial Intelligence",
                "Artificial Intelligence in Medicine (Canada)"
            ]
        },
        {
            "id": "https://openalex.org/A2998632049",
            "name": "Bozitao Zhong",
            "affiliations": [
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A2138109337",
            "name": "Huiqun Yu",
            "affiliations": [
                "East China University of Science and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2118527409",
            "name": "Ziyi Zhou",
            "affiliations": [
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A2138640236",
            "name": "Wanli Ouyang",
            "affiliations": [
                "Beijing Academy of Artificial Intelligence",
                "Artificial Intelligence in Medicine (Canada)"
            ]
        },
        {
            "id": "https://openalex.org/A2098408928",
            "name": "Bingxin Zhou",
            "affiliations": [
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A1963948191",
            "name": "Liang Hong",
            "affiliations": [
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A2112949133",
            "name": "Yang Tan",
            "affiliations": [
                "Beijing Academy of Artificial Intelligence",
                "Artificial Intelligence in Medicine (Canada)"
            ]
        },
        {
            "id": "https://openalex.org/A2129494870",
            "name": "Mingchen Li",
            "affiliations": [
                "East China University of Science and Technology",
                "Beijing Academy of Artificial Intelligence",
                "Shanghai Artificial Intelligence Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A2113131905",
            "name": "Pan Tan",
            "affiliations": [
                "Shanghai Jiao Tong University",
                "Beijing Academy of Artificial Intelligence",
                "Shanghai Artificial Intelligence Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A2886955574",
            "name": "Xinzhu Ma",
            "affiliations": [
                "Shanghai Artificial Intelligence Laboratory",
                "Beijing Academy of Artificial Intelligence"
            ]
        },
        {
            "id": "https://openalex.org/A2998632049",
            "name": "Bozitao Zhong",
            "affiliations": [
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A2138109337",
            "name": "Huiqun Yu",
            "affiliations": [
                "East China University of Science and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2118527409",
            "name": "Ziyi Zhou",
            "affiliations": [
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A2138640236",
            "name": "Wanli Ouyang",
            "affiliations": [
                "Beijing Academy of Artificial Intelligence",
                "Shanghai Artificial Intelligence Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A2098408928",
            "name": "Bingxin Zhou",
            "affiliations": [
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A1963948191",
            "name": "Liang Hong",
            "affiliations": [
                "Shanghai Artificial Intelligence Laboratory",
                "Beijing Academy of Artificial Intelligence",
                "Shanghai Jiao Tong University"
            ]
        },
        {
            "id": "https://openalex.org/A2112949133",
            "name": "Yang Tan",
            "affiliations": [
                "Shanghai Artificial Intelligence Laboratory",
                "East China University of Science and Technology",
                "Beijing Academy of Artificial Intelligence"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2154139219",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W3146944767",
        "https://openalex.org/W4327550249",
        "https://openalex.org/W3177500196",
        "https://openalex.org/W4205773061",
        "https://openalex.org/W2143011057",
        "https://openalex.org/W3177828909",
        "https://openalex.org/W3186179742",
        "https://openalex.org/W3211795435",
        "https://openalex.org/W4387303685",
        "https://openalex.org/W4385255463",
        "https://openalex.org/W4210840673",
        "https://openalex.org/W4224988655",
        "https://openalex.org/W3081836708",
        "https://openalex.org/W2951433247",
        "https://openalex.org/W4281648132",
        "https://openalex.org/W4388024559",
        "https://openalex.org/W4288066876",
        "https://openalex.org/W4317374308",
        "https://openalex.org/W4383550741",
        "https://openalex.org/W3164046276",
        "https://openalex.org/W3121781769",
        "https://openalex.org/W4221159485",
        "https://openalex.org/W4388373618",
        "https://openalex.org/W4224939843",
        "https://openalex.org/W4389279578",
        "https://openalex.org/W3131204112",
        "https://openalex.org/W4223581484",
        "https://openalex.org/W4387966974",
        "https://openalex.org/W2008708467",
        "https://openalex.org/W4383957026",
        "https://openalex.org/W3106745904",
        "https://openalex.org/W3033187248",
        "https://openalex.org/W2967474035",
        "https://openalex.org/W3209435229",
        "https://openalex.org/W4313291879",
        "https://openalex.org/W3213545574",
        "https://openalex.org/W2730472814",
        "https://openalex.org/W2908510526"
    ],
    "abstract": "Abstract Protein language models (PLMs) have shown remarkable capabilities in various protein function prediction tasks. However, while protein function is intricately tied to structure, most existing PLMs do not incorporate protein structure information. To address this issue, we introduce ProSST, a Transformer-based protein language model that seamlessly integrates both protein sequences and structures. ProSST incorporates a structure quantization module and a Transformer architecture with disentangled attention. The structure quantization module translates a 3D protein structure into a sequence of discrete tokens by first serializing the protein structure into residue-level local structures and then embeds them into dense vector space. These vectors are then quantized into discrete structure tokens by a pre-trained clustering model. These tokens serve as an effective protein structure representation. Furthermore, ProSST explicitly learns the relationship between protein residue token sequences and structure token sequences through the sequence-structure disentangled attention. We pre-train ProSST on millions of protein structures using a masked language model objective, enabling it to learn comprehensive contextual representations of proteins. To evaluate the proposed ProSST, we conduct extensive experiments on the zero-shot mutation effect prediction and several supervised downstream tasks, where ProSST achieves the state-of-the-art performance among all baselines. Our code and pretrained models are publicly available 2 .",
    "full_text": null
}