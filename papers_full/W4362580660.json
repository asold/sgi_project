{
  "title": "Infusing behavior science into large language models for activity coaching",
  "url": "https://openalex.org/W4362580660",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2231996058",
      "name": "Madhurima Vardhan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2005058084",
      "name": "Narayan Hegde",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2661942921",
      "name": "Deepak Nathani",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2257028363",
      "name": "Emily Rosenzweig",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A2305091355",
      "name": "Alan Karthikesalingam",
      "affiliations": [
        "Google (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A4284700076",
      "name": "Martin Seneviratne",
      "affiliations": [
        "Google (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A2231996058",
      "name": "Madhurima Vardhan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2005058084",
      "name": "Narayan Hegde",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2661942921",
      "name": "Deepak Nathani",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2257028363",
      "name": "Emily Rosenzweig",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2305091355",
      "name": "Alan Karthikesalingam",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4284700076",
      "name": "Martin Seneviratne",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2890695304",
    "https://openalex.org/W2096528587",
    "https://openalex.org/W2038439321",
    "https://openalex.org/W4310332764",
    "https://openalex.org/W2139141017",
    "https://openalex.org/W2523939115",
    "https://openalex.org/W2123420688",
    "https://openalex.org/W1977519940",
    "https://openalex.org/W4200588694",
    "https://openalex.org/W2972203331",
    "https://openalex.org/W2898938475",
    "https://openalex.org/W2794859034",
    "https://openalex.org/W4283782371",
    "https://openalex.org/W3090433062",
    "https://openalex.org/W3030163527",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4226399820",
    "https://openalex.org/W4297253404",
    "https://openalex.org/W4385307867",
    "https://openalex.org/W4225411436",
    "https://openalex.org/W2953958347",
    "https://openalex.org/W4287888135",
    "https://openalex.org/W4223908421",
    "https://openalex.org/W4318350868",
    "https://openalex.org/W4205991051",
    "https://openalex.org/W4221161806",
    "https://openalex.org/W4303648559",
    "https://openalex.org/W4308244910",
    "https://openalex.org/W3203321135",
    "https://openalex.org/W4281483047",
    "https://openalex.org/W4327644588",
    "https://openalex.org/W4385573257",
    "https://openalex.org/W2136608905",
    "https://openalex.org/W3029493744",
    "https://openalex.org/W2908734263",
    "https://openalex.org/W3000779003"
  ],
  "abstract": "Abstract Large language models (LLMs) have shown promise for task-oriented dialogue across a range of domains. The use of LLMs in health and fitness coaching is under-explored. Behavior science frameworks such as COM-B, which conceptualizes behavior change in terms of capability (C), Opportunity (O) and Motivation (M), can be used to architect coaching interventions in a way that promotes sustained change. Here we aim to incorporate behavior science principles into an LLM using two knowledge infusion techniques: coach message priming (where exemplar coach responses are provided as context to the LLM), and dialogue re-ranking (where the COM-B category of the LLM output is matched to the inferred user need). Simulated conversations were conducted between the primed or unprimed LLM and a member of the research team, and then evaluated by 8 human raters. Ratings for the primed conversations were significantly higher in terms of empathy and actionability. The same raters also compared a single response generated by the unprimed, primed and re-ranked models, finding a significant uplift in actionability from the re-ranking technique. This is a proof of concept of how behavior science frameworks can be infused into automated conversational agents for a more principled coaching experience. Institutional Review Board (IRB) The study does not involve human subjects beyond the volunteer annotators. IRB approval was not sought for this research.",
  "full_text": "Target: PLoS Digital Health 1–12\nInfusing behavior science into large language models for activity\ncoaching\nMadhurima Vardhan*\nNarayan Hegde* hegde@google.com\nDeepak Nathani\nGoogle Research, Bangalore, India\nEmily Rosenzweig\nVerily Life Sciences, San Francisco, USA\nAlan Karthikesalingam\nMartin Seneviratne\nGoogle Health, London, UK\n* equal ﬁrst\nAbstract\nLarge language models (LLMs) have shown promise for task-oriented dialogue across a range of domains.\nThe use of LLMs in health and ﬁtness coaching is under-explored. Behavior science frameworks such as\nCOM-B, which conceptualizes behavior change in terms of capability (C), Opportunity (O) and Motivation\n(M), can be used to architect coaching interventions in a way that promotes sustained change. Here we\naim to incorporate behavior science principles into an LLM using two knowledge infusion techniques: coach\nmessage priming (where exemplar coach responses are provided as context to the LLM), and dialogue re-\nranking (where the COM-B category of the LLM output is matched to the inferred user need). Simulated\nconversations were conducted between the primed or unprimed LLM and a member of the research team,\nand then evaluated by 8 human raters. Ratings for the primed conversations were signiﬁcantly higher in\nterms of empathy and actionability. The same raters also compared a single response generated by the\nunprimed, primed and re-ranked models, ﬁnding a signiﬁcant uplift in actionability from the re-ranking\ntechnique. This is a proof of concept of how behavior science frameworks can be infused into automated\nconversational agents for a more principled coaching experience.\nInstitutional Review Board (IRB) The study does not involve human subjects beyond the volunteer\nannotators. IRB approval was not sought for this research.\n1. Introduction\nIt is estimated that 81% of adolescents and 27% of adults do not achieve the levels of physical activity\nrecommended by the World Health Organization (WHO) (1). A sedentary lifestyle is associated with long\nterm adverse health outcomes, ranging from cardiovascular disease and diabetes to mental health problems\nand cognitive decline (2). A 2022 report found that progress toward these goals has been slower than\nexpected and highlighted digital health tools as a particular opportunity area (3).\nNumerous smartphone nudging tools have been designed to promote physical activity (4; 5). These\ninterventions are low-cost and highly scalable relative to human ﬁtness coaches, with promising early evidence\n(6; 7; 8; 9). One randomized controlled trial of a digital walking coach found short-term improvements in\nphysical activity (10). However, in an era of notiﬁcation overload, there is also a risk of desensitization and\nalert fatigue if the nudge strategy is not well designed.\nAutomated conversational agents oﬀer an opportunity to create interactive dialogue, with widespread\napplications in e-commerce, home automation and healthcare (11; 12). Health and Fitness coaching is\nemerging as a promising use case for these conversational agents (13; 14; 15; 16). However, most traditional\nsystems are limited in their degree of personalization and persuasiveness because they depend on rule-based\nc⃝ M. Vardhan*, N. Hegde*, D. Nathani, E. Rosenzweig, A. Karthikesalingam & M. Seneviratne.\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 3, 2023. ; https://doi.org/10.1101/2023.03.31.23287995doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nINTERNAL - Knowledge infusion for fitness LLMs\nnudge engines with static message content rather than adaptive conversational agents that can mimic realistic\ndialogue from a human coach (17).\nLarge language models (LLMs), such as GPT-3 (18), PaLM (19), Gopher ( 20) and LaMDA (21), excel in\nnatural language generation with greater expressivity and versatility compared to rule-based chatbots. To\ndate, use of LLMs in the health and ﬁtness space has been limited, however interest is growing rapidly fol-\nlowing the release of LLMs tailored to biomedical tasks (22). A major challenge in using LLMs in health care\nis how to ensure the model is personalized and adaptive while still remaining consistent with evidence-based\npractice and within safety guardrails (23). Activity coaching relies on complex interpersonal dynamics where\nthe coach builds rapport with the trainee, provides motivation, helps to overcome pre-existing patterns of\nbehavior, etc.- which are not explicitly optimized in LLMs (24). Knowledge infusion refers to the integration\nof established knowledge or practice into a model. In principle this is often achieved via ﬁnetuning on a\ntask-speciﬁc dataset (25). The disadvantage of ﬁnetuning in the coaching domain is that it requires coaching\ntranscripts, which are diﬃcult to obtain. Finetuning has also been shown to diminish the few-shot perfor-\nmance of a pretrained LLM with in-context prompts - i.e. over-specialization of the model (26). Knowledge\ninfusion is an active area of research and many other methods exist including customizing training objectives\n(27), reinforcement learning with human feedback (28; 29), in-context learning via prompt engineering or\npriming (30; 31) and many associated prompt design variants (32; 33; 34; 35). There have also been numer-\nous strategies to ensemble knowledge infusion techniques, including post-hoc re-ranking or summarization\nof model outputs to further align the model with the task of interest (36; 37). Customizing knowledge infu-\nsion strategies for the health care domain remains an area of active research. Here we propose two simple\nin-context learning methods to infuse behavior science principles into LLMs without the requirement for\nﬁnetuning or reinforcement learning.\nCoaching in the context of physical activity ranges from delivering tailored products that serve elite\nathletes, to creating motivational tools that support inactive users to become ﬁtter through a progressive\nand personalised programs. Our LLM is designed to target latter use case to help users lead more active\nlifestyle using behavioral nudges and resolving barriers through conversations.\nBehavioral science oﬀers theoretical frameworks to help understand the factors inﬂuencing human behavior\nand design eﬀective behavior change interventions for a given context. COM-B is a well-known framework\nwhich conceptualizes behavior change along three axes: Capability (the psychological and physical skills to\nact); Opportunity (the physical and social conditions to act); and Motivation (the reﬂective and automatic\nmental processes that drive action) (38). Behavioral science can be useful to guide the design of automated\nnudging systems for habit formation (39).\nWe extend the PACE (16) work on designing automated physical activity coaching engine based on an\nanalogous behavior science framework called Fogg’s Behavior Model. A rule-based automated nudging agent\nbased on this model had comparable outcomes to human coaches in terms of user step count and engagement.\nIn this study, we extend ﬁndings of the PACE study by connecting the strengths of a behavioral science\nrule-based model with the conversational versatility of an LLM. The goal is to address the broader question\nof how behavior science principles might guide or constrain conversational LLMs. Speciﬁcally, we make use\nof priming and dialogue re-ranking. These are both lightweight techniques that do not require additional\nmodel retraining or ﬁnetuning. Overall, the key contributions contributions of this study are as follows:\n1. Deﬁning evaluation metrics for LLM conversations in the activity coaching domain\n2. Introducing two diﬀerent approaches to behavioral science knowledge infusion: coach phrase priming\nand dialogue re-ranking\n3. Evaluating the beneﬁt of knowledge infusion relative to an unprimed LLM using quantitative and\nqualitative approaches\n2. Methods\nThe following sections outline the datasets, language modeling techniques and evaluation methods used.\n2\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 3, 2023. ; https://doi.org/10.1101/2023.03.31.23287995doi: medRxiv preprint \nINTERNAL - Knowledge infusion for fitness LLMs\n2.1. Data\nThe previous PACE study dataset was re-purposed for this analysis (16). Speciﬁcally, this dataset was used\nto construct the example coaching phrases used in the behavior science priming, create training data for\nﬁnetuning BERT user and coach statement classiﬁers and to select the user queries (initial user responses) in\nsimulated conversations for evaluation. This dataset consists of dialogue transcripts between ﬁtness coaches\nand subjects, generated from real coaching interactions across various activity habit formation related issues.\nIn this Wizard-of-Oz study design, consented subjects were randomized to coaches or coaches using a FBM\nassistant that suggested example responses based on behavior science using a rule-based engine. The dataset\nincluded 520+ conversations from 33 participants over 21 days. A total of 6 independent annotators labeled\nthese conversations as one of Motivation, Capability and Opportunity. Both user and coach statements\nwhere separately annotated with presence or absence of each of these three themes. Data collection and\nannotation protocol is described in detail in (16).\n2.2. Language models\nThe Language Models for Dialog Applications (LaMDA) pretrained LLM was used as the primary archi-\ntecture (21), with no further ﬁnetuning. LaMDA is a decoder-only transformer architecture with 64 layers,\nused here in its 137 billion parameter conﬁguration. We used the following LaMDA hyperparameters: tem-\nperature 0.9; maximum token length 1024, top k (controls sampling diversity) 40. LaMDA has an option to\nprovide context alongside the LLM prompt - this was how the coach phrase priming was conducted. LaMDA\nalso provides top-k outputs, which were used in the re-ranking (see below).\n2.3. Coach phrase priming\nCoach phrase priming was performed by inputting 30 example coach nudges as context to the LLM prior to\nthe prompt. The 30 nudges were selected from the data in the PACE study - speciﬁcally the 10 most common\ncoach responses in each of the three behavior science categories of interest: C/O/M. Details regarding coach\nphrase selection and priming method are described in section 1 of supplementary paper. For example,\nthe Capability category included activity planning and barrier conversations; and Opportunity included\nsocial engagement conversations and activity planning; and Motivation included congratulations and positive\naﬃrmation; [ref]. The order of the 30 nudges was randomized. The priming prompts are shown in Table 1.\n2.4. Simulated dialogue\nThe following LLM conﬁgurations were compared via simulated conversations with a single member of the\nresearch team:\n1. Unprimed (trigger prompt only)\n2. Coach-primed (30 example nudges provided as LLM context)\nAll conversations begin with the trigger prompt: Hey John, It’s time for your morning walk. The sub-\nsequent user responses were sampled from a set of 9 user statements, with 3 each designed to evoke a low\nMotivation, low Capability and low Opportunity (user queries are included in the Supplementary Materials\ntable 2). An example user statement with low opportunity was: I am super busy with work today. I have\nchores to do in the morning and work meetings after that..\nThis culminated in a total of 18 transcripts: 9 each for the unprimed and primed LLMs. The conversations\nwere continued with dialogue between the LLM and the human interlocutor (researcher). The conversations\nwere terminated at a natural breakpoint at the discretion of the researcher. Any follow up questions to the\nLLM response were added appropriately to continue the conversation on the original topic until a logical\nend was reached. Additional example transcripts are contained in the Supplementary Materials.\n3\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 3, 2023. ; https://doi.org/10.1101/2023.03.31.23287995doi: medRxiv preprint \nINTERNAL - Knowledge infusion for fitness LLMs\nTable 1: LLM prompts used in coach phrase priming.\nBeha\nvior Science Priming\nThe\nfollowing is a conversation with an AI Health Coach.\nThe coach tries to motivate the users when the user lacks motivation, can resolve barriers.\nHere are some examples of how a coach can help users:\n”I know you probably have a busy schedule. I still think\nyou can manage and hit your goal of daily step count.”\n”Looks like you are having a busy day. I would recommend\nsetting up gentle reminders daily of your goal to have them\nas part of each day. Hope that can help you be all set for having an exercise routine!”\n”You know, building a new habit is really really hard. But it doesn’t have to be that way :)\nStarting with a little stroll outside for some fresh air cannot be bad idea as long as the\nweather is right. So why not head out today for a few minutes, and come in. What do you think? :) ”\n”You must keep that ﬁre burning, your excitement and conﬁdence for maintaining\na healthy lifestyle will take you far with healthy habit formation.\nI believe a daily stroll with be no problem for you at all:)”\n”So do you reckon you’ll manage your walk today?”\n”It is nice and bright outside today. What is your plan for the day, why not start walking today?”\n”The question you can ask yourself is that do you feel walking can help you?”\n”You knew starting a healthy habit can be hard, but it’s a life changing\nexperience of rebuilding your identity as someone who exercises :)\nIf you’re not feeling up for a long walk today, perhaps we can aim for a shorter one? :)”\n”You know walking can be especially enjoyable as it allows you to put\non your favourite playlist and podcast. So, what do feel like listening to today?”\n...\nCoach prompt: Hey John, It’s time for your morning walk.\n2.5. Constraining LLM responses using a COM-B classiﬁer\nIn order to further constrain or guide the LLM to provide nudges based on COM-B principles, we trained\ntwo classiﬁers to assess C/O/M levels:\n1. User statement classiﬁer: Given a user statement sentence, the user-query classiﬁer assigns a high\nvs low value for each of the capability, opportunity and motivation(COM) dimensions (multi-label\nclassiﬁcation).\n2. Coach statement classiﬁer: Given a shortlist of 15 top LLM outputs, the coach response classiﬁer maps\neach response to either C, O or M (multi-class classiﬁcation).\nThe classiﬁers were designed as follows. The input string (could be multiple sentences) was embedded\nusing a BERT-base model with the ﬁnal layer ﬁnetuned over either a multi-label head (user statement\nclassiﬁer) or 3 separate C/O/M heads (coach statement classiﬁer). Models were optimised with a cross-\nentropy loss. Separate user and coach classiﬁers were trained using samples of 432 user statements and 531\ncoach statements from the PACE study, manually annotated with C/O/M status. These datasets were split\n70:10:20 across train, validation and test splits. Weights were not shared between the user and coach models.\n4\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 3, 2023. ; https://doi.org/10.1101/2023.03.31.23287995doi: medRxiv preprint \nINTERNAL - Knowledge infusion for fitness LLMs\nFigure 1: Comparison of example conversations with unprimed, coach-primed and primed+reranked LLMs.\n2.6. Simulated dialogue with re-ranking\nThe simulated conversation experiment was repeated with the primed LaMDA model, using the above\nclassiﬁers to align the coach response to the inferred user need. For the 9 coach-primed LaMDA transcripts\nabove, a single user statement was manually selected as the most representative of the user’s behavioral\nneed.\nThe selected text was input into the user statement classiﬁer to identify the C/O/M need. The same user\ntext was input into the coach-primed LaMDA model to generate the top 15 candidate responses. These\n15 responses were then separately run through the coach statement classiﬁer to generate a likelihood score\nacross each C/O/M category. The coach action was aligned based on the user’s inferred C/O/M need based\non the rules in Table 2 (i.e. the statement with the highest score in the desired coach action was chosen).\nIn addition, we conducted an ’oracle’ experiment where the user response was manually categorized into\nC/O/M need and the corresponding coach-primed output was chosen.\nTwo manual review exercises were then conducted:\n1. Comparing the coach-primed output to the classiﬁer re-ranked output; and\n2. Comparing coach-primed with the oracle re-ranked output. Note that in both these review exercise,\nonly a single coach response was being adjudicated rather than an entire conversation as previous.\n2.7. Evaluation attributes\nAn evaluation framework was deﬁned based on four key attributes of an LLM-based ﬁtness coach: actionabil-\nity, realism, motivation and empathy. Coupled with a global assessment of coaching quality, these attributes\n5\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 3, 2023. ; https://doi.org/10.1101/2023.03.31.23287995doi: medRxiv preprint \nINTERNAL - Knowledge infusion for fitness LLMs\nTable 2: COM-B policy to select nudge theme based on C/O/M values derived from the user statement\nclassiﬁer.\nCapabilit\ny Opportunity Motivation COM-B Action\nLo\nw High/Low High/Low Boost Capability\nHigh Low High/Low Boost Opportunity\nHigh High High/Low Boost Motivation\nTable 3: Evaluation attributes cross-referenced with established attributes of coaches and LLMs.\nEv\naluation attributes Coach attributes LLM attributes\nActionabilit\ny Professional competence Informativeness\nRealism Context sensitivity Sensibleness & safety\nMotivation BS interventions Interestingness\nEmpathy Social-emotional competences Groundedness\ninformed the design of the quantitative and qualitative review detailed below. Table 3) shows how these\nattributes align with published evaluation frameworks for coaches (40) and for LLMs (21; 41).\n2.8. Quantitative review\nFor each architecture, the unprimed versus coach-primed transcripts generated from the same starting prompt\nwere compared in a pairwise manner. The conversations were evaluated based on the following quantitative\nattributes: average length of reply, number of conversational turns, user sentiment at conversation end, pres-\nence of questions in the coach dialogue and use of coaching-speciﬁc words (’goal’, ’health’, ’routine’, ’recover,\n’challenge’, ’workout’, ’training’, ’rest’). The results for unprimed versus primed LLMs were compared using\na two sided t-test.\n2.9. Qualitative review\n8 independent reviewers were selected to adjudicate the transcripts. Reviewers were blinded to the manner\nof LLM priming (naive vs BS) and Re-Ranked LLM variations (naive vs primed vs re-ranked LLM). Raters\ncompleted a structured survey with Likert scale responses for the same pairwise comparisons of naive-primed\nand coach-primed transcripts as above. Questions evaluated the following attributes of the conversation:\nactionability, realism, empathy, motivation, overall quality. The questions are included in Supplementary\nTable 2.\nTable 4: Quantitative assessment of unprimed versus coach-primed LLM conversations.\nMetric Unprimed\nCoach-primed p value\nAv\nerage length of LLM reply (# words ±S.D.) 25.7 ±6.5\n23.7 ±7.1 0.3\nT\nurns of conversation by user/LLM (# turns ±S.D.) 3.1 ±0.3\n3.7 ±0.7 0.2\nCon\nversations ending with positive user sentiment (%) 30\n60 0.02\nCon\nversations containing a question asked by LLM (%) 0\n30 0.03\nCon\nversations containing coaching-speciﬁc words used by LLM (%) 40\n80 0.08\n6\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 3, 2023. ; https://doi.org/10.1101/2023.03.31.23287995doi: medRxiv preprint \nINTERNAL - Knowledge infusion for fitness LLMs\nTable 5: Qualitative assessment of unprimed versus coach-primed LLM conversations based on the reviews\nof 8 adjudicators.\nSurv\ney question (1, strong disagree 5, strong agree) Unprimed\nCoach-primed p value\nWhich\nconversation provides a better overall coaching experience (%, remainder unsure) 21\n72 -\nThe\nquality of the coaching experience is high 3.42 ±0.88\n3.97 ±1.0 <0.001\nThe\ncoach provides concrete ﬁtness strategies that are actionable to the user 3.61 ±1.1\n4.25 ±0.84 <0.001\nThe\ncoach provides motivation or encouragement to the user 3.68 ±1.1\n3.97 ±0.97 0.095\nThe\ncoach is empathetic toward the user’s needs and challenges 3.51 ±1.0\n3.83 ±1.1 0.123\nThe\nlanguage used by the coach is realistic and appropriate for the setting 3.71 ±1.1\n4.10 ±1.0 0.02\nTable 6: Class balance and model performance on C/O/M classiﬁcation for user statements.\nClass\nbalance (high:low) Classiﬁer performance\n(ROC-AUC)\nTrain Test\nMotiv\nation 220:40 68:16 0.86\nCapability 158:66 51:40 0.77\nOpportunity 112:34 52:13 0.83\n3. Results\nQuantitative analysis (Table 4) showed that the number of turns of dialogue was higher in coach-primed\nversus unprimed. Across both architectures, priming was associated with a signiﬁcant boost in the rate of\nconversations ending in a positive user sentiment, the rate of question-asking by the coach LLM, and the\nuse of coaching-related vocabulary.\nTo determine whether ratings for the primed and unprimed models diﬀered from each other, we ran a series\nof linear mixed model analyses. These included a ﬁxed eﬀect for primed vs unprimed, and random eﬀects\nfor rater and prompt to account for non-independence of the observations. Regarding message content,\nthe ratings of blinded reviewers were overall more favorable for the coach-primed LLMs. The (Table 5).\nSpeciﬁcally, the coach-primed model was rated as signiﬁcantly higher in terms of quality, providing actionable\nsuggestions, and using realistic language. The ratings for the classiﬁer re-ranked versus unprimed were less\nconclusive, but this may be because those ratings were based on a single statement response from the model\nrather than a full back-and-forth dialogue.\nTables 6 and 7 show the performance of the user and coach statement classiﬁers, including the size and label\ndistribution in the train and test sets. The BERT-base model had 81% multi-class accuracy in accurately\nclassifying the coach message as motivation, capability or opportunity.\nTo quantitatively evaluate the re-ranked response compared to the default response, 8 independent re-\nviewers rated both the responses across several dimensions of activity coaching (Table 8). Based on Likert\nscale responses, the re-ranked answers were rated as more actionable [3.66±0.89 vs 2.88±0.85]; however the\nother attributes did not reach statistical signiﬁcance.\nTable 7: Model performance on C/O/M classiﬁcation for coach statements.\nCategory\nTrain Test Precision Recall F1 Score Multi-class accuracy\nMotiv\nation 256 121 0.87 0.86 0.86 0.81\nCapability 139 66 0.88 0.72 0.79\nOpportunity 212 74 0.83 0.71 0.77\n7\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 3, 2023. ; https://doi.org/10.1101/2023.03.31.23287995doi: medRxiv preprint \nINTERNAL - Knowledge infusion for fitness LLMs\nTable 8: Qualitative review of coach-primed versus classiﬁer re-ranked and oracle re-ranked dialogues.\nSurv\ney question (1, strong disagree →5, strong agree) Unprimed Coach-primed Classiﬁer Re-ranked Oracle Re-ranked\np value\n(Classiﬁer re-ranked\nvs Unprimed\nThe\ncoach response provided concrete ﬁtness strategies that are actionable 2.88 ±0.85 3.22 ±0.95 3.66 ±0.89 4.02 ±0.68 0.02\nThe coach response to user questions was in a realistic manner 3.02 ±0.98 3.23 ±0.97 3.59 ±0.99 3.75 ±0.80 0.18\nThe coach response provided motivation or encouragement to the user 3.05 ±1.0 3.19 ±0.85 3.75 ±0.92 3.45 ±1.05 0.36\nThe coach is empathetic toward the user’s needs and challenges 2.94 ±0.99 3.05 ±0.94 3.56 ±0.87 3.77 ±0.83 0.47\nThe language used by the coach is realistic and appropriate for the setting 3.33 ±0.87 3.48 ±0.84 3.69 ±0.87 3.78 ±0.79 0.29\nAverage total score 3.04 ±0.95 3.24 ±1.36 3.65 ±1.32 3.75 ±0.84\n4. Discussion\nThis proof-of-concept study introduces two methods to infuse behavior science into LLM dialogue. We\ndemonstrate that behavior science-based priming is a simple but eﬀective strategy to tailor LLMs for activity\ncoaching, with speciﬁc beneﬁts in terms of actionability and the provision of concrete coaching advice.\nAdditionally, post-hoc re-ranking of LLM responses based on behavior science principles can further enhance\nattributes such as perceived empathy.\nBS priming yielded some signiﬁcant boosts in various proxies for coaching quality. This trend was evident\nacross both quantitative and qualitative metrics. Notably, coach phrase priming was associated with a\nhigher number of conversational turns, a greater rate of question-asking, and more frequent use of coaching\nvocabulary. Manual review also judged coach phrase priming as providing signiﬁcantly greater motivation\nand concrete coaching strategies versus the unprimed LLM. This suggests that BS priming may be an eﬀective\nand accessible strategy for customising LLMs for various coaching scenarios.\nA unique aspect of this work is the combination of priming with post-hoc re-ranking to enable knowledge\ninfusion at multiple touchpoints. Interestingly, re-ranking resulted in signiﬁcant incremental improvements\nin actionability, with upward trends in empathy, motivation and realism that did not meet statistical sig-\nniﬁcance. We demonstrate this uplift both for a classiﬁer-based re-ranking, which introduces error from\nmis-classiﬁcation; and for oracle-based re-ranking, which showed a further marginal advantage over the for-\nmer. Together, these results demonstrate the ability to stitch together multiple simple constraints as part of\na hybrid knowledge infusion strategy. As LLMs become more pervasive in the coaching domain, this will be\nincreasingly important.\nSince Capability has marginally lower user statement classiﬁer accuracy, it was wrongly identiﬁed as\nmotivation in few cases of classiﬁer based BeSci dialogue alignment LLM. This resulted in higher motivational\ncharacter to classiﬁer based LLM over Oracle LLM at the expense of lower empathy and actionability scores.\nThis study has a number of limitations. First, the evaluation was predominantly based on simulated\nconversations with a single human interacting with the LLMs, which invariably introduces bias even in the\npresence of blinding. Future work could trial a similar evaluation with larger groups of users engaging in\ndialogue, as per [ref]. The rudimentary priming method used here could be extended, e.g. by more explicit\ninstruction prompting or chain of thought prompting. The re-ranking method was limited in only focusing\non a single user query and coach response. In reality, it is important to consistently align the coach responses\nto user need throughout a conversation and adapt as the dialogue unfolds. Methods such as reinforcement\nlearning with human feedback can help to oﬀer this adaptability (29). Finally, the behaviour model used\nwas a simplistic one that conceptualizes user behaviour only along three axes - future studies could consider\nusing more sophisticated behavior science frameworks, which may help to better target coach actions.\n5. Conclusion\nKnowledge infusion methods based on behavior science principles can be used to improve the quality of LLM-\ngenerated physical activity related conversations. The combination of coach phrase priming with re-ranking\nof LLM outputs oﬀers optimal results in terms of manually-adjudicated actionability, empathy and overall\ncoaching experience. These methods can help to constrain and guide LLMs in various coaching scenarios.\n8\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 3, 2023. ; https://doi.org/10.1101/2023.03.31.23287995doi: medRxiv preprint \nINTERNAL - Knowledge infusion for fitness LLMs\nReferences\n[1] Regina Guthold, Gretchen A Stevens, Leanne M Riley, and Fiona C Bull. Worldwide trends in insuf-\nﬁcient physical activity from 2001 to 2016: a pooled analysis of 358 population-based surveys with 1 ·9\nmillion participants. Lancet Glob Health, 6(10):e1077–e1086, October 2018.\n[2] I-Min Lee, Eric J Shiroma, Felipe Lobelo, Pekka Puska, Steven N Blair, Peter T Katzmarzyk, and Lancet\nPhysical Activity Series Working Group. Eﬀect of physical inactivity on major non-communicable\ndiseases worldwide: an analysis of burden of disease and life expectancy. Lancet, 380(9838):219–229,\nJuly 2012.\n[3] WHO. GLOBAL ACTION PLAN ON PHYSICAL ACTIVITY 2018-2030: More active people for a\nhealthier world. Technical report, World Health Organization, 2018.\n[4] Judit Bort-Roig, Nicholas D Gilson, Anna Puig-Ribera, Ruth S Contreras, and Stewart G Trost. Mea-\nsuring and inﬂuencing physical activity with smartphone technology: a systematic review. Sports Med.,\n44(5):671–686, May 2014.\n[5] Alexandher Negreiros, Roberto B T Maciel, Bianca Carvalho de Barros, and Rosimeire Simprini Padula.\nQuality assessment of smartphone ﬁtness apps used to increase physical activity level and improve\ngeneral health in adults: A systematic review. Digit Health, 8:20552076221138305, November 2022.\n[6] Art of the nudge. https://www.omadahealth.com/art-of-the-nudge. Accessed: 2023-7-3.\n[7] Anouk Middelweerd, Julia S Mollee, C Natalie van der Wal, Johannes Brug, and Saskia J Te Velde.\nApps to promote physical activity among adults: a review and content analysis. Int. J. Behav. Nutr.\nPhys. Act., 11:97, July 2014.\n[8] Ashish Chaddha, Elizabeth A Jackson, Caroline R Richardson, and Barry A Franklin. Technology to\nhelp promote physical activity. Am. J. Cardiol., 119(1):149–152, January 2017.\n[9] Gemma Flores Mateo, Esther Granado-Font, Carme Ferr´ e-Grau, and Xavier Monta˜ na-Carreras. Mobile\nphone apps to promote weight loss and increase physical activity: A systematic review and Meta-\nAnalysis. J. Med. Internet Res. , 17(11):e253, November 2015.\n[10] Timothy W Bickmore, Rebecca A Silliman, Kerrie Nelson, Debbie M Cheng, Michael Winter, Lori\nHenault, and Michael K Paasche-Orlow. A randomized controlled trial of an automated exercise coach\nfor older adults. J. Am. Geriatr. Soc. , 61(10):1676–1683, October 2013.\n[11] Merav Allouch, Amos Azaria, and Rina Azoulay. Conversational agents: Goals, technologies, vision and\nchallenges. Sensors, 21(24), December 2021.\n[12] Ahmet Baki Kocaballi, Shlomo Berkovsky, Juan C Quiroz, Liliana Laranjo, Huong Ly Tong, Dana\nRezazadegan, Agustina Briatore, and Enrico Coiera. The personalization of conversational agents in\nhealth care: Systematic review. J. Med. Internet Res. , 21(11):e15360, November 2019.\n[13] Mira El Kamali, Leonardo Angelini, Maurizio Caon, Giuseppe Andreoni, Omar Abou Khaled, and\nElena Mugellini. Towards the NESTORE e-coach: a tangible and embodied conversational agent for\nolder adults. In Proceedings of the 2018 ACM International Joint Conference and 2018 International\nSymposium on Pervasive and Ubiquitous Computing and Wearable Computers, UbiComp ’18, pages\n1656–1663, New York, NY, USA, October 2018. Association for Computing Machinery.\n[14] Genta Indra Winata, Holy Lovenia, Etsuko Ishii, Farhad Bin Siddique, Yongsheng Yang, and Pascale\nFung. Nora: The Well-Being coach. June 2021.\n9\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 3, 2023. ; https://doi.org/10.1101/2023.03.31.23287995doi: medRxiv preprint \nINTERNAL - Knowledge infusion for fitness LLMs\n[15] Rafal Kocielnik, Lillian Xiao, Daniel Avrahami, and Gary Hsieh. Reﬂection companion: A conversa-\ntional system for engaging users in reﬂection on physical activity. Proc. ACM Interact. Mob. Wearable\nUbiquitous Technol., 2(2):1–26, July 2018.\n[16] Madhurima Vardhan, Narayan Hegde, Srujana Merugu, Shantanu Prabhat, Deepak Nathani, Martin\nSeneviratne, Nur Muhammad, Pranay Reddy, Sriram Lakshminarasimhan, Rahul Singh, Karina Loren-\nzana, Eshan Motwani, Partha Talukdar, and Aravindan Raghuveer. Walking with PACE - personalized\nand automated coaching engine. In Proceedings of the 30th ACM Conference on User Modeling, Adap-\ntation and Personalization , UMAP ’22, pages 57–68, New York, NY, USA, July 2022. Association for\nComputing Machinery.\n[17] Jingwen Zhang, Yoo Jung Oh, Patrick Lange, Zhou Yu, and Yoshimi Fukuoka. Artiﬁcial intelligence\nchatbot behavior change model for designing artiﬁcial intelligence chatbots to promote physical activity\nand a healthy diet: Viewpoint. J. Med. Internet Res. , 22(9):e22845, September 2020.\n[18] Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss,\nGretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeﬀrey Wu, Clemens\nWinter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.\nLanguage models are Few-Shot learners. May 2020.\n[19] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepa-\nssi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M Dai, Thanumalayan Sankaranarayana\nPillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee,\nZongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei,\nKathy Meier-Hellstern, Douglas Eck, Jeﬀ Dean, Slav Petrov, and Noah Fiedel. PaLM: Scaling language\nmodeling with pathways. April 2022.\n[20] Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoﬀmann, Francis Song, John\nAslanides, Sarah Henderson, Roman Ring, Susannah Young, Eliza Rutherford, Tom Hennigan, Jacob\nMenick, Albin Cassirer, Richard Powell, George van den Driessche, Lisa Anne Hendricks, Maribeth\nRauh, Po-Sen Huang, Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saﬀron Huang, Jonathan\nUesato, John Mellor, Irina Higgins, Antonia Creswell, Nat McAleese, Amy Wu, Erich Elsen, Siddhant\nJayakumar, Elena Buchatskaya, David Budden, Esme Sutherland, Karen Simonyan, Michela Paganini,\nLaurent Sifre, Lena Martens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gri-\nbovskaya, Domenic Donato, Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsim-\npoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas Pajarskas, Toby Pohlen, Zhitao\nGong, Daniel Toyama, Cyprien de Masson d’Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor\nBabuschkin, Aidan Clark, Diego de Las Casas, Aurelia Guy, Chris Jones, James Bradbury, Matthew\nJohnson, Blake Hechtman, Laura Weidinger, Iason Gabriel, William Isaac, Ed Lockhart, Simon Osin-\ndero, Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub, Jeﬀ Stanway, Lorrayne Bennett, Demis\nHassabis, Koray Kavukcuoglu, and Geoﬀrey Irving. Scaling language models: Methods, analysis &\ninsights from training gopher. December 2021.\n[21] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, Yaguang Li, Hongrae Lee, Huaixiu Steven Zheng,\n10\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 3, 2023. ; https://doi.org/10.1101/2023.03.31.23287995doi: medRxiv preprint \nINTERNAL - Knowledge infusion for fitness LLMs\nAmin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin,\nDehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Vincent Zhao, Yanqi\nZhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Pranesh Srinivasan, Laichee Man,\nKathleen Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke,\nJohnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen\nOlson, Alejandra Molina, Erin Hoﬀman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna,\nMatthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise\nAguera-Arcas, Claire Cui, Marian Croak, Ed Chi, and Quoc Le. LaMDA: Language models for dialog\napplications. January 2022.\n[22] Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and Tie-Yan Liu. BioGPT:\ngenerative pre-trained transformer for biomedical text generation and mining. Brief. Bioinform., 23(6),\nNovember 2022.\n[23] Karan Singhal, Shekoofeh Azizi, Tao Tu, S. Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan\nScales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, Perry Payne, Martin Seneviratne, Paul Gam-\nble, Chris Kelly, Nathaneal Scharli, Aakanksha Chowdhery, Philip Mansﬁeld, Blaise Aguera y Arcas,\nDale Webster, Greg S. Corrado, Yossi Matias, Katherine Chou, Juraj Gottweis, Nenad Tomasev, Yun\nLiu, Alvin Rajkomar, Joelle Barral, Christopher Semturs, Alan Karthikesalingam, and Vivek Natarajan.\nLarge language models encode clinical knowledge. 2022.\n[24] Adam Sobieszek and Tadeusz Price. Playing games with ais: The limits of GPT-3 and similar large\nlanguage models. Minds Mach., 32(2):341–364, June 2022.\n[25] Sebastian Ruder, Matthew E Peters, Swabha Swayamdipta, and Thomas Wolf. Transfer learning in\nnatural language processing. In Proceedings of the 2019 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Tutorials , pages 15–18, Minneapolis, Minnesota, June\n2019. Association for Computational Linguistics.\n[26] Yihan Wang, Si Si, Daliang Li, Michal Lukasik, Felix Yu, Cho-Jui Hsieh, Inderjit S Dhillon, and Sanjiv\nKumar. Preserving In-Context learning ability in large language model ﬁne-tuning. November 2022.\n[27] Fedor Moiseev, Zhe Dong, Enrique Alfonseca, and Martin Jaggi. SKILL: Structured knowledge infusion\nfor large language models. May 2022.\n[28] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain,\nStanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion,\nTom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatﬁeld-Dodds, Danny Hernandez, Tristan Hume,\nScott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom\nBrown, Jack Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan. Training a helpful\nand harmless assistant with reinforcement learning from human feedback. April 2022.\n[29] Banghua Zhu, Jiantao Jiao, and Michael I. Jordan. Principled reinforcement learning with human\nfeedback from pairwise or k-wise comparisons, 2023.\n[30] Brian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for Parameter-Eﬃcient prompt\ntuning. April 2021.\n[31] Yanchen Liu, Timo Schick, and Hinrich Sch¨ utze. Semantic-Oriented unlabeled priming for Large-Scale\nlanguage models. February 2022.\n[32] Simran Arora, Avanika Narayan, Mayee F Chen, Laurel Orr, Neel Guha, Kush Bhatia, Ines Chami,\nFrederic Sala, and Christopher R´ e. Ask me anything: A simple strategy for prompting language models.\nOctober 2022.\n11\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 3, 2023. ; https://doi.org/10.1101/2023.03.31.23287995doi: medRxiv preprint \nINTERNAL - Knowledge infusion for fitness LLMs\n[33] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy\nBa. Large language models are Human-Level prompt engineers. November 2022.\n[34] Tongshuang Wu, Michael Terry, and Carrie Jun Cai. AI chains: Transparent and controllable Human-\nAI interaction by chaining large language model prompts. In Proceedings of the 2022 CHI Conference\non Human Factors in Computing Systems, number Article 385 in CHI ’22, pages 1–22, New York, NY,\nUSA, April 2022. Association for Computing Machinery.\n[35] Denny Zhou, Nathanael Sch¨ arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans,\nClaire Cui, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-Most prompting enables complex reasoning\nin large language models. May 2022.\n[36] Jayr Pereira, Robson Fidalgo, Roberto Lotufo, and Rodrigo Nogueira. Visconde: Multi-document QA\nwith GPT-3 and neural reranking. December 2022.\n[37] Mirac Suzgun, Luke Melas-Kyriazi, and Dan Jurafsky. Prompt-and-Rerank: A method for Zero-Shot\nand Few-Shot arbitrary textual style transfer with small language models. May 2022.\n[38] Susan Michie, Maartje M van Stralen, and Robert West. The behaviour change wheel: a new method\nfor characterising and designing behaviour change interventions. Implement. Sci., 6:42, April 2011.\n[39] Aditya Kumar Purohit, Louis Barclay, and Adrian Holzer. Designing for digital detox: Making social\nmedia less addictive with digital nudges. In Extended Abstracts of the 2020 CHI Conference on Human\nFactors in Computing Systems, CHI EA ’20, pages 1–9, New York, NY, USA, April 2020. Association\nfor Computing Machinery.\n[40] Ulrich Georg Strauch, Hagen W¨ asche, and Darko Jekauc. Coach competences to induce positive aﬀective\nreactions in sport and Exercise-A qualitative study. Sports (Basel), 7(1), January 2019.\n[41] Daniel Adiwardana, Minh-Thang Luong, David R So, Jamie Hall, Noah Fiedel, Romal Thoppilan,\nZi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, and Quoc V Le. Towards a human-like\nOpen-Domain chatbot. January 2020.\n12\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 3, 2023. ; https://doi.org/10.1101/2023.03.31.23287995doi: medRxiv preprint \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 3, 2023. ; https://doi.org/10.1101/2023.03.31.23287995doi: medRxiv preprint ",
  "topic": "Coaching",
  "concepts": [
    {
      "name": "Coaching",
      "score": 0.8157499432563782
    },
    {
      "name": "Priming (agriculture)",
      "score": 0.5788813233375549
    },
    {
      "name": "Context (archaeology)",
      "score": 0.577034592628479
    },
    {
      "name": "Psychological intervention",
      "score": 0.575579822063446
    },
    {
      "name": "Empathy",
      "score": 0.550551176071167
    },
    {
      "name": "Ranking (information retrieval)",
      "score": 0.5454918742179871
    },
    {
      "name": "Psychology",
      "score": 0.5370693802833557
    },
    {
      "name": "Applied psychology",
      "score": 0.42111679911613464
    },
    {
      "name": "Social psychology",
      "score": 0.3769014775753021
    },
    {
      "name": "Computer science",
      "score": 0.2664642930030823
    },
    {
      "name": "Artificial intelligence",
      "score": 0.15679019689559937
    },
    {
      "name": "Psychotherapist",
      "score": 0.09189069271087646
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Psychiatry",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Botany",
      "score": 0.0
    },
    {
      "name": "Germination",
      "score": 0.0
    }
  ]
}