{
    "title": "A novel system for strengthening security in large language models against hallucination and injection attacks with effective strategies",
    "url": "https://openalex.org/W4408764887",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A5093745464",
            "name": "Tunahan Gokcimen",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2276120885",
            "name": "Bihter Daş",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4386102168",
        "https://openalex.org/W4386572315",
        "https://openalex.org/W4402266346",
        "https://openalex.org/W4379140845",
        "https://openalex.org/W6857697021",
        "https://openalex.org/W4386333952",
        "https://openalex.org/W6858078726",
        "https://openalex.org/W6855185924",
        "https://openalex.org/W4375949262",
        "https://openalex.org/W4380740969",
        "https://openalex.org/W4385755118",
        "https://openalex.org/W4388886073",
        "https://openalex.org/W6843728012",
        "https://openalex.org/W4385474633",
        "https://openalex.org/W4385894687",
        "https://openalex.org/W4385195544",
        "https://openalex.org/W3132969838",
        "https://openalex.org/W2124612670",
        "https://openalex.org/W3101262357",
        "https://openalex.org/W4353080029",
        "https://openalex.org/W4391591637",
        "https://openalex.org/W4392353733",
        "https://openalex.org/W4399625707",
        "https://openalex.org/W4403970529",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2978017171",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W4377864715",
        "https://openalex.org/W4380993076",
        "https://openalex.org/W4384264626",
        "https://openalex.org/W6777615688",
        "https://openalex.org/W4386997414",
        "https://openalex.org/W6858122333",
        "https://openalex.org/W4389519576",
        "https://openalex.org/W4385328210",
        "https://openalex.org/W4322718191",
        "https://openalex.org/W4384918448",
        "https://openalex.org/W4388412198",
        "https://openalex.org/W6858218828",
        "https://openalex.org/W4330337479",
        "https://openalex.org/W4392679398",
        "https://openalex.org/W4399117902",
        "https://openalex.org/W4206334925",
        "https://openalex.org/W3035547806",
        "https://openalex.org/W4321792635",
        "https://openalex.org/W4401042259",
        "https://openalex.org/W4399490421",
        "https://openalex.org/W4388182168",
        "https://openalex.org/W4388129991",
        "https://openalex.org/W2990138404",
        "https://openalex.org/W4296545269",
        "https://openalex.org/W4389977189",
        "https://openalex.org/W4388049829",
        "https://openalex.org/W4388347957"
    ],
    "abstract": "To address the escalating demand for secure and trustworthy interactions with Large Language Models (LLMs), this study introduces a pioneering security framework that mitigates critical vulnerabilities, including injection attacks, hallucinations, and data privacy breaches. By incorporating advanced technologies such as VectorDB, Kernel, and Retrieval-Augmented Generation (RAG) within a cross-LLM architecture, the system delivers enhanced resilience and adaptability to adversarial scenarios. Comprehensive evaluations across leading models—including PaLM, Llama, GPT-3.5, GPT-4, Gemini, and GPT-4o—reveal the system’s exceptional performance, achieving a 98 % accuracy in eligibility scoring and outperforming conventional models in both reliability and security. This study underscores the significance of a multi-layered defense mechanism that not only detects and neutralizes threats but also ensures ethical, accurate, and contextually relevant responses. The novel cross-LLM strategy enhances system robustness by leveraging the strengths of multiple models, minimizing inconsistencies and reinforcing output integrity. With its adaptability to emerging linguistic manipulation techniques and compliance with strict ethical standards, the proposed framework establishes a secure, scalable ecosystem for LLM applications. The findings promise transformative impacts across domains such as cybersecurity, multilingual processing, and adaptive threat detection, paving the way for safer and more reliable language model deployments.",
    "full_text": null
}