{
  "title": "Embracing Large Language Models for Medical Applications: Opportunities and Challenges",
  "url": "https://openalex.org/W4377197101",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3165109671",
      "name": "Mert Karabacak",
      "affiliations": [
        "Mount Sinai Health System",
        "Neurological Surgery"
      ]
    },
    {
      "id": "https://openalex.org/A2027235618",
      "name": "Konstantinos Margetis",
      "affiliations": [
        "Neurological Surgery",
        "Mount Sinai Health System"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4367668587",
    "https://openalex.org/W3160137267",
    "https://openalex.org/W4282983782",
    "https://openalex.org/W4324303524",
    "https://openalex.org/W3046375318",
    "https://openalex.org/W2963499153",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W3205211246"
  ],
  "abstract": "Large language models (LLMs) have the potential to revolutionize the field of medicine by, among other applications, improving diagnostic accuracy and supporting clinical decision-making. However, the successful integration of LLMs in medicine requires addressing challenges and considerations specific to the medical domain. This viewpoint article provides a comprehensive overview of key aspects for the successful implementation of LLMs in medicine, including transfer learning, domain-specific fine-tuning, domain adaptation, reinforcement learning with expert input, dynamic training, interdisciplinary collaboration, education and training, evaluation metrics, clinical validation, ethical considerations, data privacy, and regulatory frameworks. By adopting a multifaceted approach and fostering interdisciplinary collaboration, LLMs can be developed, validated, and integrated into medical practice responsibly, effectively, and ethically, addressing the needs of various medical disciplines and diverse patient populations. Ultimately, this approach will ensure that LLMs enhance patient care and improve overall health outcomes for all.",
  "full_text": "Review began\n 04/06/2023 \nReview ended\n 05/17/2023 \nPublished\n 05/21/2023\n© Copyright \n2023\nKarabacak et al. This is an open access\narticle distributed under the terms of the\nCreative Commons Attribution License CC-\nBY 4.0., which permits unrestricted use,\ndistribution, and reproduction in any\nmedium, provided the original author and\nsource are credited.\nEmbracing Large Language Models for Medical\nApplications: Opportunities and Challenges\nMert Karabacak \n \n, \nKonstantinos Margetis \n1.\n Neurological Surgery, Mount Sinai Health System, New York, USA\nCorresponding author: \nKonstantinos Margetis, \nkonstantinos.margetis@mountsinai.org\nAbstract\nLarge language models (LLMs) have the potential to revolutionize the field of medicine by, among other\napplications, improving diagnostic accuracy and supporting clinical decision-making. However, the\nsuccessful integration of LLMs in medicine requires addressing challenges and considerations specific to the\nmedical domain. This viewpoint article provides a comprehensive overview of key aspects for the successful\nimplementation of LLMs in medicine, including transfer learning, domain-specific fine-tuning, domain\nadaptation, reinforcement learning with expert input, dynamic training, interdisciplinary collaboration,\neducation and training, evaluation metrics, clinical validation, ethical considerations, data privacy, and\nregulatory frameworks. By adopting a multifaceted approach and fostering interdisciplinary collaboration,\nLLMs can be developed, validated, and integrated into medical practice responsibly, effectively, and\nethically, addressing the needs of various medical disciplines and diverse patient populations. Ultimately,\nthis approach will ensure that LLMs enhance patient care and improve overall health outcomes for all.\nCategories:\n Healthcare Technology, Other\nKeywords:\n data privacy, ethical considerations, generative ai, chatgpt, multimodal learning, domain adaptation,\nreinforcement learning, transfer learning, artificial intelligence, large language models\nEditorial\nIntroduction\nLarge language models (LLMs) have been the focus of significant attention in the field of artificial\nintelligence (AI) in recent years. These models are trained on massive amounts of data and have\ndemonstrated remarkable performance in natural language processing (NLP) tasks such as language\ngeneration, machine translation, and question-answering \n[1-3]\n. With the exponential growth of medical\nliterature and the increasing availability of electronic health records (EHRs), LLMs are now poised to\nrevolutionize medicine.\nLLMs have the potential to transform medical practice in numerous ways, including improving diagnostic\naccuracy, predicting disease progression, and supporting clinical decision-making \n[4,5]\n. By analyzing large\namounts of medical data, LLMs can rapidly develop specialized knowledge for different medical disciplines,\nsuch as radiology, pathology, and oncology \n[6-8]\n. They can be fine-tuned on domain-specific medical\nliterature to ensure that they are up-to-date and relevant. They can be adapted to different languages and\ncontexts, facilitating improved global access to medical knowledge and expertise.\nHowever, integrating LLMs in medicine also presents significant challenges and limitations. The complexity\nof medical language and the diversity of medical contexts can make it difficult for LLMs to capture the\nnuances of clinical practice accurately. Furthermore, ensuring unbiased models and data privacy is crucial\nfor fair and equitable healthcare. Collaboration among medical professionals, data scientists, ethicists, and\npolicymakers is essential for comprehensive LLM development, addressing medical needs, challenges, and\nethical implications. Therefore, this viewpoint article aims to provide a comprehensive overview of the\npotential benefits and challenges of using LLMs in medicine and identify key considerations for their\nsuccessful implementation.\nTransfer learning, domain-specific fine-tuning, and domain adaptation\nTransfer learning is a powerful approach that allows LLMs to leverage pre-trained models as a starting point\nfor further training and adaptation to medical domains \n[9]\n. By applying domain-specific fine-tuning, which\ninvolves training pre-trained LLMs on relevant medicine-specific data to perform well on tasks within the\nmedical field, we can ensure up-to-date and relevant medical knowledge \n[10]\n. Prioritizing recent and highly\ncited articles can improve the model's performance in specific medical domains. This approach would allow\nfor the rapid development of specialized LLMs that can address the unique needs of various medical\ndisciplines.\nDomain adaptation, closely related to domain-specific fine-tuning, is necessary for LLMs to function\neffectively in different medical domains, specialties, and languages. While domain-specific fine-tuning\n1\n1\n \n Open Access\nEditorial\n \nDOI:\n 10.7759/cureus.39305\nHow to cite this article\nKarabacak M, Margetis K (May 21, 2023) Embracing Large Language Models for Medical Applications: Opportunities and Challenges. Cureus\n15(5): e39305. \nDOI 10.7759/cureus.39305\nfocuses on adjusting a model to perform well within a specific field, domain adaptation involves adapting a\nmodel trained in one domain to work effectively in a different but related domain without requiring\nextensive retraining \n[11]\n. Developing models that can adapt to various contexts ensures their applicability\nacross diverse healthcare settings, benefiting both patients and practitioners. Moreover, the ability to adapt\nto different languages can help break down language barriers, facilitating improved global access to medical\nknowledge and expertise.\nAlternative methods for adapting LLMs to medical domains, such as few-shot learning and zero-shot\nlearning, can also be relevant in certain scenarios. Few-shot learning aims to train models to perform well\non new tasks with very limited labeled data by leveraging knowledge learned from other tasks \n[12]\n. Zero-\nshot learning, on the other hand, focuses on training models to perform tasks without any labeled data for\nthe target task, relying solely on knowledge learned from other tasks \n[13]\n. These approaches can be useful\nwhen domain-specific training data is scarce or unavailable, allowing LLMs to adapt to new medical domains\nmore efficiently.\nSeveral examples of LLMs fine-tuned for medical applications showcase the potential of transfer learning,\ndomain adaptation, and alternative methods in this field. BioBERT, a pre-trained biomedical language\nrepresentation model based on the BERT architecture, has been fine-tuned on large-scale biomedical\ncorpora, including PubMed abstracts and PMC full-text articles, leading to significant improvements in\nbiomedical NLP tasks such as named entity recognition, relation extraction, and question-answering \n[14]\n.\nClinicalBERT, another domain-specific model, has been fine-tuned on the MIMIC-III dataset, which consists\nof EHRs from intensive care unit patients, demonstrating enhanced performance in clinical NLP tasks,\nincluding patient mortality prediction, de-identification, and diagnosis classification \n[15]\n. BlueBERT, also\nbased on the BERT architecture and pre-trained on a large corpus of biomedical text data, has achieved state-\nof-the-art performance on various biomedical NLP tasks, including named entity recognition, relation\nextraction, and biomedical question-answering \n[16]\n. These examples highlight the success and potential of\ntransfer learning, domain-specific fine-tuning, domain adaptation, and alternative methods in harnessing\nthe power of LLMs for medical applications.\nReinforcement learning with expert input and dynamic training\nReinforcement learning is a type of machine learning where an agent learns to make decisions by interacting\nwith an environment, receiving feedback in the form of rewards or penalties, and adjusting its actions\naccordingly \n[17]\n. In the case of developing LLMs for medicine, reinforcement learning with expert input is\ncrucial for achieving accurate and unbiased models. Collaborating with medical experts who have agreed to\na relevant declaration of principles would help grow trust in fairness, objectivity, and accuracy in model\ndevelopment. Expert feedback can help guide the model's learning process and enable a more nuanced\nunderstanding of complex medical concepts. This collaboration can lead to the creation of models that\nbetter understand and address the challenges faced by medical professionals in their daily practice.\nDynamic training is the continuous updating and training of a model to incorporate new data and\nknowledge, ensuring the model remains current and relevant \n[18]\n. For medicine-specific LLMs, it is essential\nto keep pace with the rapidly expanding medical knowledge. Continuously updating LLMs with new medical\nliterature will allow them to remain current and adapt to emerging trends and discoveries. This approach is\nespecially relevant for real-time applications, such as clinical decision support systems and telemedicine,\nwhere up-to-date information is crucial.\nCollaboration and interdisciplinary approach\nThe successful implementation of LLMs in medicine requires collaboration between various stakeholders,\nincluding medical professionals, data scientists, ethicists, and policymakers \n[19]\n. An interdisciplinary\napproach ensures that LLMs are developed with a comprehensive understanding of medical needs and\nchallenges, as well as the ethical, legal, and social implications of their use. Establishing partnerships\nbetween academia, industry, and healthcare providers can foster innovation and accelerate the translation\nof research findings into clinical practice.\nIn addition to involving these stakeholders, it is vital to include diverse perspectives, such as patients,\ncaregivers, and representatives from different cultural backgrounds, in the development and evaluation of\nLLMs \n[20]\n. Incorporating these perspectives can help ensure that LLMs address the needs of diverse\npopulations, leading to more equitable healthcare outcomes. Engaging with patient advocacy groups,\ncommunity organizations, and other relevant parties can provide valuable insights into the unique\nchallenges faced by different groups, enabling LLM developers to create models that are tailored to their\nspecific needs. Furthermore, involving diverse perspectives can help identify potential biases and\nunintended consequences in LLM outputs, promoting fairness and inclusivity in the development and\napplication of these technologies.\nEducation and training\nEducation and training are essential for the effective integration of LLMs into medical practice. As LLMs\n2023 Karabacak et al. Cureus 15(5): e39305. DOI 10.7759/cureus.39305\n2\n of \n5\nbecome more prevalent in healthcare, medical professionals need to understand their capabilities and\nlimitations and how to use them effectively in their clinical practice. Medical curricula should incorporate\nfundamental concepts of AI, machine learning, and LLMs, providing future practitioners with the necessary\nknowledge and skills to work with these technologies. This training should include an understanding of how\nLLMs work, how they can be adapted and fine-tuned to specific medical domains, and how to interpret the\nmodel's outputs. Medical students should also receive training in data ethics, privacy, and security to ensure\nthey use LLMs in an ethical and responsible manner.\nContinued professional development programs should be available for current healthcare providers to\nensure they remain competent in using the latest advancements in LLMs and other AI technologies. These\nprograms should be tailored to the specific needs of different healthcare professionals, such as physicians,\nnurses, and other allied health professionals. The training should include hands-on experience with LLMs,\nsuch as how to fine-tune a pre-trained model for a specific medical application or how to interpret the\nmodel's predictions. Additionally, the training should address the challenges and limitations of LLMs in\nmedicine, such as potential biases, privacy concerns, and ethical considerations.\nMoreover, the training should also cover how to integrate LLMs into the clinical workflow, how to\ncommunicate LLM-generated outputs to patients, and how to collaborate with data scientists to fine-tune\nLLMs to specific clinical needs. It is also important to involve patients and caregivers in the training and\neducation process, as they can provide valuable feedback on the usefulness and usability of LLM-generated\noutputs in clinical decision-making. Overall, comprehensive education and training programs can ensure\nthat healthcare professionals are equipped with the necessary skills and knowledge to effectively and\nresponsibly use LLMs in clinical practice.\nEvaluation metrics, benchmarks, and clinical validation\nEstablishing robust evaluation metrics and benchmarks is essential for assessing the performance of LLMs\nin medical applications \n[21]\n. Traditional evaluation methods may not be sufficient as they may not account\nfor the specific challenges and requirements of the medical domain. Developing new evaluation standards\nthat consider both the technical performance and real-world utility of these models is crucial.\nClinical validation, in collaboration with medical professionals, is necessary to assess the real-world utility\nof LLMs. Rigorous evaluation of their performance in clinical settings can help identify areas for\nimprovement and ensure that the models are beneficial to patients and healthcare providers. The validation\nprocess should include diverse clinical scenarios and patient populations to ensure that the models are\ncapable of addressing a wide range of medical challenges. The validation process should aim at both the\napplication process and the content creation of the LLMs in medicine.\nChallenges and limitations of LLMs in medicine\nWhile LLMs have the potential to revolutionize medical practice, it is essential to address their challenges\nand limitations to ensure their safe and effective use. One significant concern is the risk of over-reliance on\nAI technologies, leading to reduced human input in critical decision-making processes. In particular,\nmedical professionals must be cautious about interpreting AI-generated outputs and validating them against\ntheir expertise and context. The development of LLMs should focus on augmenting human expertise rather\nthan replacing it, ensuring that medical professionals retain a central role in patient care.\nAnother challenge is the potential for LLMs to inadvertently generate misleading or incorrect information,\nwhich could have severe consequences in healthcare settings. Ensuring the accuracy and reliability of LLM-\ngenerated outputs is crucial, as errors could lead to incorrect diagnoses, inappropriate treatments, or other\nnegative patient outcomes. To mitigate these risks, rigorous validation processes, continuous monitoring,\nand collaboration with medical experts are essential. Furthermore, developing explainable AI techniques can\nhelp medical professionals better understand the underlying reasoning behind the LLM-generated outputs,\nenabling them to identify and address potential issues more effectively.\nAdditionally, implementing LLMs in healthcare settings comes with significant cost and resource\nimplications. Developing, training, and maintaining LLMs require substantial computational resources,\nwhich can be a barrier to widespread adoption, especially in low-resource settings. Consequently, it is\ncrucial to explore alternative solutions that address these challenges. One possibility is the development of\nmore efficient models that require less computational power while maintaining high performance. Another\noption is leveraging cloud-based resources to allow healthcare providers to access AI capabilities without\ninvesting in expensive hardware and infrastructure. Moreover, exploring collaborations between the public\nand private sectors could help distribute the costs and resources needed for LLM implementation more\nequitably, ensuring that these transformative technologies become accessible to a broader range of\nhealthcare settings. By addressing these challenges and limitations, LLMs can be integrated more safely and\neffectively into medical practice, maximizing their potential to improve healthcare outcomes for diverse\npopulations.\n2023 Karabacak et al. Cureus 15(5): e39305. DOI 10.7759/cureus.39305\n3\n of \n5\nEthical considerations, data privacy, and regulatory framework\nEthical considerations are paramount when implementing LLMs in medicine. To ensure unbiased models\nand mitigate potential biases, it is crucial to focus on fairness and equitable healthcare. This can be\nachieved through fairness-aware machine learning, a subfield that aims to develop algorithms and models\nthat consider fairness and minimize biases by accounting for the potential disparate impact on different\ndemographic groups \n[22]\n. Counterfactual fairness, a criterion that evaluates the fairness of a model by\ncomparing its decisions for an individual with hypothetical alternative decisions it would have made if the\nindividual belonged to a different group, is another important aspect of achieving fair outcomes \n[23]\n. This\napproach helps ensure that models treat individuals consistently, regardless of their group membership,\nthus promoting fairness and equity in LLMs applied to medical settings.\nTransparency in the development and deployment of LLMs is vital for maintaining public trust and fostering\nethical use. Data privacy and security are of utmost importance, particularly when handling sensitive\nmedical information. Compliance with regulations such as the Health Insurance Portability and\nAccountability Act and the General Data Protection Regulation is essential. Advanced privacy techniques\nlike differential privacy can help protect patient data while ensuring useful statistical analysis. Moreover,\nsecure data storage and transmission protocols should be in place to prevent unauthorized access and\npotential data breaches.\nDeveloping a robust regulatory framework for LLMs in medicine is essential to ensure their safe and\neffective use. This framework should address issues related to the development, validation, and deployment\nof LLMs, as well as their ongoing maintenance and monitoring. Policymakers and regulatory agencies must\nwork together to establish standards and guidelines that promote transparency, accountability, and\nresponsible innovation without hindering progress. By considering ethical considerations, data privacy, and\nestablishing a comprehensive regulatory framework, LLMs can be successfully integrated into medical\npractice in a manner that is both beneficial and responsible.\nTen Key Suggestions for LLMs in Medicine\n1.\nTransfer learning, domain adaptation, few-shot learning, and zero-shot learning\n2.\nReinforcement learning with expert feedback according to an explicit code of ethics\n3.\nDynamic model with emphasis on more recent and more cited work\n4.\nRobust and specific evaluation metrics and benchmarks, along with clinical validation\n5.\nData privacy, fairness-aware provisions, and diverse stakeholder involvement\n6.\nInclusion of patients, caregivers, and other diverse perspectives\n7.\nEducation and training prerequisites for the users\n8.\nA regulatory framework for their development, validation, deployment, maintenance, and monitoring\n9.\nAddressing cost and resource implications, exploring efficient models and cloud-based resources\n10.\nEthical considerations, unbiased models, and mitigation strategies for potential risks and limitations\nTABLE\n 1: Summary table of ten key suggestions for implementing LLMs in medicine\nConclusions\nLLMs hold great promise for revolutionizing medical practice by improving diagnostic accuracy, predicting\ndisease progression, and supporting clinical decision-making. The successful implementation of LLMs in\nmedicine requires a multifaceted approach that addresses the unique challenges and considerations specific\nto the medical domain. Key aspects to consider include transfer learning, domain-specific fine-tuning,\ndomain adaptation, reinforcement learning with expert input, dynamic training, interdisciplinary\ncollaboration, education and training, evaluation metrics, clinical validation, ethical considerations, data\nprivacy, and regulatory frameworks (Table \n1\n). By addressing these essential factors, we can ensure that LLMs\nare developed, validated, and integrated into medical practice responsibly, effectively, and ethically.\nFurthermore, fostering an interdisciplinary and collaborative approach involving diverse perspectives will\npromote the creation of LLMs that address the needs of various medical disciplines and diverse patient\npopulations. This comprehensive approach will help maximize the potential of LLMs to improve healthcare\noutcomes and transform the field of medicine. As we continue to explore the possibilities offered by LLMs, it\nis crucial to maintain a patient-centered focus, ensuring that the development and implementation of these\ntechnologies ultimately serve to enhance patient care and improve overall health outcomes for all.\n2023 Karabacak et al. Cureus 15(5): e39305. DOI 10.7759/cureus.39305\n4\n of \n5\nAdditional Information\nDisclosures\nConflicts of interest:\n In compliance with the ICMJE uniform disclosure form, all authors declare the\nfollowing: \nPayment/services info:\n All authors have declared that no financial support was received from\nany organization for the submitted work. \nFinancial relationships:\n All authors have declared that they have\nno financial relationships at present or within the previous three years with any organizations that might\nhave an interest in the submitted work. \nOther relationships:\n All authors have declared that there are no\nother relationships or activities that could appear to have influenced the submitted work.\nReferences\n1\n. \nPlug and play language models: a simple approach to controlled text generation\n. (2019).\nhttps://arxiv.org/abs/1912.02164\n.\n2\n. \nUnsupervised neural machine translation with generative language models only\n. (2021).\nhttps://arxiv.org/abs/2110.05448\n.\n3\n. \nLanguage models as knowledge bases?\n. (2019). \nhttps://arxiv.org/abs/1909.01066\n.\n4\n. \nChatCAD: interactive computer-aided diagnosis on medical image using large language models\n. (2023).\nhttps://arxiv.org/abs/2302.07257\n.\n5\n. \nRasmy L, Xiang Y, Xie Z, Tao C, Zhi D: \nMed-BERT: pretrained contextualized embeddings on large-scale\nstructured electronic health records for disease prediction\n. NPJ Digit Med. 2021, 4:86. \n10.1038/s41746-021-\n00455-y\n6\n. \nYan A, McAuley J, Lu X, Du J, Chang EY, Gentili A, Hsu CN: \nRadBERT: adapting transformer-based language\nmodels to radiology\n. Radiol Artif Intell. 2022, 4:e210258. \n10.1148/ryai.210258\n7\n. \nPathologyBERT -- pre-trained vs. a new transformer language model for pathology domain\n. (2022).\nhttps://arxiv.org/abs/2205.06885\n.\n8\n. \nKather JN: \nArtificial intelligence in oncology: chances and pitfalls\n. J Cancer Res Clin Oncol. 2023,\n10.1007/s00432-023-04666-6\n9\n. \nAn embarrassingly simple approach for transfer learning from pretrained language models\n. (2019).\nhttps://arxiv.org/abs/1902.10547\n.\n10\n. \nYu Gu, Robert Tinn, Hao Cheng, et al.: \nDomain-specific language model pretraining for biomedical natural\nlanguage processing\n. ACM Trans Comput Health. 2022, 3:1-23. \n10.1145/3458754\n11\n. \nEfficient hierarchical domain adaptation for pretrained language models\n. (2021).\nhttps://arxiv.org/abs/2112.08786\n.\n12\n. \nLearning from few examples: a summary of approaches to few-shot learning\n. (2022).\nhttps://arxiv.org/abs/2203.04291\n.\n13\n. \nXian Y, Lampert CH, Schiele B, Akata Z: \nZero-shot learning-a comprehensive evaluation of the good, the\nbad and the ugly\n. IEEE Trans Pattern Anal Mach Intell. 2019, 41:2251-65. \n10.1109/TPAMI.2018.2857768\n14\n. \nLee J, Yoon W, Kim S, Kim D, Kim S, So CH, Kang J: \nBioBERT: a pre-trained biomedical language\nrepresentation model for biomedical text mining\n. Bioinformatics. 2020, 36:1234-40.\n10.1093/bioinformatics/btz682\n15\n. \nClinicalBERT: modeling clinical notes and predicting hospital readmission\n. (2019).\nhttps://arxiv.org/abs/1904.05342\n.\n16\n. \nTransfer learning in biomedical natural language processing: an evaluation of BERT and ELMo on ten\nbenchmarking datasets\n. (2019). \nhttps://arxiv.org/abs/1906.05474\n.\n17\n. \nTraining language models to follow instructions with human feedback\n. (2022).\nhttps://arxiv.org/abs/2203.02155\n.\n18\n. \nDynamic language models for continuously evolving content\n. (2021).\nhttps://dl.acm.org/doi/10.1145/3447548.3467162\n.\n19\n. \nFølstad A, Araujo T, Law EL, et al.: \nFuture directions for chatbot research: an interdisciplinary research\nagenda\n. Computing. 2021, 103:2915-42. \n10.1007/s00607-021-01016-7\n20\n. \nFine-tuning language models to find agreement among humans with diverse preferences\n. (2022).\nhttps://arxiv.org/abs/2211.15006\n.\n21\n. \nHolistic evaluation of language models\n. (2022). \nhttps://arxiv.org/abs/2211.09110\n.\n22\n. \nFairness-aware machine learning: practical challenges and lessons learned\n. (2019).\nhttps://dl.acm.org/doi/10.1145/3289600.3291383\n.\n23\n. \nReducing sentiment bias in language models via counterfactual evaluation\n. (2019).\nhttps://arxiv.org/abs/1911.03064\n.\n2023 Karabacak et al. Cureus 15(5): e39305. DOI 10.7759/cureus.39305\n5\n of \n5",
  "topic": "Adaptation (eye)",
  "concepts": [
    {
      "name": "Adaptation (eye)",
      "score": 0.653668999671936
    },
    {
      "name": "Medicine",
      "score": 0.6137055158615112
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.5201023817062378
    },
    {
      "name": "Health care",
      "score": 0.47439029812812805
    },
    {
      "name": "Engineering ethics",
      "score": 0.4374939799308777
    },
    {
      "name": "Precision medicine",
      "score": 0.41009190678596497
    },
    {
      "name": "Pathology",
      "score": 0.14716178178787231
    },
    {
      "name": "Psychology",
      "score": 0.12605547904968262
    },
    {
      "name": "Engineering",
      "score": 0.10007423162460327
    },
    {
      "name": "Political science",
      "score": 0.09673944115638733
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1320796813",
      "name": "Mount Sinai Health System",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210157890",
      "name": "Neurological Surgery",
      "country": "US"
    }
  ],
  "cited_by": 168
}