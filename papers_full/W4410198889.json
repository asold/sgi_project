{
  "title": "Cognitive phantoms in large language models through the lens of latent variables",
  "url": "https://openalex.org/W4410198889",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5114414615",
      "name": "Sanne Peereboom",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A388354581",
      "name": "Inga Schwabe",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2063875431",
      "name": "Bennett Kleinberg",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2058090646",
    "https://openalex.org/W4309663019",
    "https://openalex.org/W4318919287",
    "https://openalex.org/W2132218683",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2893425640",
    "https://openalex.org/W4323347737",
    "https://openalex.org/W3174936622",
    "https://openalex.org/W2029342244",
    "https://openalex.org/W2003806493",
    "https://openalex.org/W4245601961",
    "https://openalex.org/W6843838130",
    "https://openalex.org/W4402860127",
    "https://openalex.org/W4390511174",
    "https://openalex.org/W6846937427",
    "https://openalex.org/W4211017739",
    "https://openalex.org/W1966359789",
    "https://openalex.org/W4385571158",
    "https://openalex.org/W4404782670",
    "https://openalex.org/W4385573216",
    "https://openalex.org/W4386200967"
  ],
  "abstract": "Large language models (LLMs) increasingly reach real-world applications, necessitating a better understanding of their behaviour. Their size and complexity complicate traditional assessment methods, causing the emergence of alternative approaches inspired by the field of psychology. Recent studies administering psychometric questionnaires to LLMs report human-like traits in LLMs, potentially influencing LLM behaviour. However, this approach suffers from a validity problem: it presupposes that these traits exist in LLMs and that they are measurable with tools designed for humans. Typical procedures rarely acknowledge the validity problem in LLMs, comparing and interpreting average LLM scores. This study investigates this problem by comparing latent structures of personality between humans and three LLMs using two validated personality questionnaires. Findings suggest that questionnaires designed for humans do not validly measure similar constructs in LLMs, and that these constructs may not exist in LLMs at all, highlighting the need for psychometric analyses of LLM responses to avoid chasing cognitive phantoms.",
  "full_text": null,
  "topic": "Latent variable",
  "concepts": [
    {
      "name": "Latent variable",
      "score": 0.6865734457969666
    },
    {
      "name": "Cognition",
      "score": 0.5568142533302307
    },
    {
      "name": "Through-the-lens metering",
      "score": 0.45864492654800415
    },
    {
      "name": "Computer science",
      "score": 0.45717623829841614
    },
    {
      "name": "Natural language processing",
      "score": 0.39610034227371216
    },
    {
      "name": "Cognitive psychology",
      "score": 0.3785566985607147
    },
    {
      "name": "Psychology",
      "score": 0.3741404414176941
    },
    {
      "name": "Lens (geology)",
      "score": 0.29892730712890625
    },
    {
      "name": "Artificial intelligence",
      "score": 0.2877412438392639
    },
    {
      "name": "Optics",
      "score": 0.14107710123062134
    },
    {
      "name": "Neuroscience",
      "score": 0.10817494988441467
    },
    {
      "name": "Physics",
      "score": 0.09571036696434021
    }
  ],
  "institutions": []
}