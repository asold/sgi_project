{
    "title": "easyROC: An Interactive Web-tool for ROC Curve Analysis Using R Language Environment",
    "url": "https://openalex.org/W2788915030",
    "year": 2016,
    "authors": [
        {
            "id": "https://openalex.org/A311803822",
            "name": "Dinçer GÖKSÜLÜK",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2182825343",
            "name": "Selcuk Korkmaz",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2062542500",
            "name": "Gokmen Zararsiz",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3025208604",
            "name": "A. Ergun Karaagaoglu",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2162445884",
        "https://openalex.org/W1544572219",
        "https://openalex.org/W2328176404",
        "https://openalex.org/W1536719366",
        "https://openalex.org/W2111641487",
        "https://openalex.org/W2158698691",
        "https://openalex.org/W2016667287",
        "https://openalex.org/W2021155520",
        "https://openalex.org/W2157825442",
        "https://openalex.org/W1829632160",
        "https://openalex.org/W2078622638",
        "https://openalex.org/W2168759597",
        "https://openalex.org/W2102301083",
        "https://openalex.org/W2005624575",
        "https://openalex.org/W2041285380",
        "https://openalex.org/W2112670427",
        "https://openalex.org/W1524233929",
        "https://openalex.org/W2006617902",
        "https://openalex.org/W2164698543",
        "https://openalex.org/W2033326122",
        "https://openalex.org/W2070595900",
        "https://openalex.org/W2051269613",
        "https://openalex.org/W2140628770",
        "https://openalex.org/W4232875550",
        "https://openalex.org/W4252544871",
        "https://openalex.org/W1990534247",
        "https://openalex.org/W2102150307",
        "https://openalex.org/W4399578865",
        "https://openalex.org/W4361868505",
        "https://openalex.org/W2145126338",
        "https://openalex.org/W4399638148"
    ],
    "abstract": "ROC curve analysis is a fundamental tool for evaluating the performance of a marker in a number of research areas, e.g., biomedicine, bioinformatics, engineering etc., and is frequently used for discriminating cases from controls.There are a number of analysis tools which are used to guide researchers through their analysis.Some of these tools are commercial and provide basic methods for ROC curve analysis while others offer advanced analysis techniques and a command-based user interface, such as the R environment.The R environmentg includes comprehensive tools for ROC curve analysis; however, using a command-based interface might be challenging and time consuming when a quick evaluation is desired; especially for non-R users, physicians etc.Hence, a quick, comprehensive, free and easy-to-use analysis tool is required.For this purpose, we developed a user-friendly webtool based on the R language.This tool provides ROC statistics, graphical tools, optimal cutpoint calculation, comparison of several markers, and sample size estimation to support researchers in their decisions without writing R codes.easyROC can be used via any device with an internet connection independently of the operating system.The web interface of easyROC is constructed with the R package shiny.",
    "full_text": "CONTRIBUTED RESEARCH ARTICLES 213\neasyROC: An Interactive Web-tool for\nROC Curve Analysis Using R Language\nEnvironment\nby Dincer Goksuluk, Selcuk Korkmaz, Gokmen Zararsiz and A. Ergun Karaagaoglu\nAbstract ROC curve analysis is a fundamental tool for evaluating the performance of a marker in a\nnumber of research areas, e.g., biomedicine, bioinformatics, engineering etc., and is frequently used\nfor discriminating cases from controls. There are a number of analysis tools which are used to guide\nresearchers through their analysis. Some of these tools are commercial and provide basic methods\nfor ROC curve analysis while others offer advanced analysis techniques and a command-based user\ninterface, such as the R environment. The R environmentg includes comprehensive tools for ROC curve\nanalysis; however, using a command-based interface might be challenging and time consuming when a\nquick evaluation is desired; especially for non-R users, physicians etc. Hence, a quick, comprehensive,\nfree and easy-to-use analysis tool is required. For this purpose, we developed a user-friendly web-\ntool based on the R language. This tool provides ROC statistics, graphical tools, optimal cutpoint\ncalculation, comparison of several markers, and sample size estimation to support researchers in their\ndecisions without writing R codes. easyROC can be used via any device with an internet connection\nindependently of the operating system. The web interface of easyROC is constructed with the R\npackage shiny. This tool is freely available through www.biosoft.hacettepe.edu.tr/easyROC.\nIntroduction\nThe receiver operating characteristics (ROC) curve is a graphical approach used to visualize and assess\nthe performance of a binary classiﬁer system. This unique feature of ROC curve analysis makes it\none of the most extensively used methods in various ﬁelds of science. It was originally developed\nduring World War II to detect whether a signal on the radar screen represented an object or a noise\n(Egan, 1975; Swets et al., 2000; Fan et al., 2006) and today it is widely used in medicine, radiology,\nbiometrics, bioinformatics and various applications of machine learning and data mining research\n(Fawcett, 2006; Sonego et al., 2008). ROC curve analysis can be implemented for several reasons: (i)\nto assess the overall performance of a classiﬁer using several performance measures, (ii) to compare\nthe performances of classiﬁers, and (iii) to determine the optimal cutpoint for a given classiﬁer,\ndiagnostic test or marker/biomarker. For simplicity of language, we will use the terms classiﬁer\nand diagnostic test throughout the manuscript. The performance of a classiﬁer can be summarized\nusing the point estimations and conﬁdence intervals of several basic performance measures such as\nsensitivity, speciﬁcity or combined measures of sensitivity and speciﬁcity such as likelihood ratios,\naccuracy, area under the ROC curve (AUC), etc. A ROC curve is basically a plot of a classiﬁer’s true\npositive rates (TPR: sensitivity) versus false positive rates (FPR: 1 −speciﬁcity) where each point is\ngenerated by a different threshold value, i.e., cutpoint. For the simplicity of equations, we will use the\nterms TPR and FPR in the equations. One of the major tasks is to determine the optimum cutpoint\nvalue which corresponds to the reasonable TPR and FPR values. The determination of an optimum\nvalue is usually a trade-off between performance measures. The ROC curve is used to ﬁnd the optimal\ncutpoint located on the curve which is the closest point to the top-left corner. However, ﬁnding the\n“optimum” cutpoint is not always based on maximizing the sensitivity and speciﬁcity. It is reasonable\nto select an optimum cutpoint value by regarding alternative selection criteria such as maximization\nof predictive values, diagnostic odds ratio, etc.\nThere are a number of commercial (e.g., IBM SPSS, MedCalc, Stata, etc.) and open-source (R)\nsoftware packages which are used to guide researchers through their ROC curve analysis. Some\nof these software packages provide basic features for ROC curve analysis while others, such as R,\noffer advanced features but also a command-based user interface. The R environment includes\ncomprehensive tools for ROC curve analysis, such as ROCR (Sing et al., 2005), pROC (Robin et al.,\n2011), ROC (Carey and Redestig, 2015) and OptimalCutpoints (Lopez-Raton et al., 2014).\nAll of the R packages mentioned above perform ROC curve analysis using the related package\nfunctions. Although these packages are comprehensive and ﬂexible, they require a good program-\nming knowledge of the R language. However, working with a command-based interface might be\nchallenging and time consuming when a quick evaluation is desired especially for non-R users, such\nas physicians and other health care professionalists. Fortunately, an R package shiny (Chang et al.,\n2015) allows users to create interactive web-tools with a nicely designed, user-friendly and easy-to-use\nuser interface. In this context, we developed a web-tool, easyROC, for ROC curve analysis. The\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 214\nuser interface of easyROC is constructed via shiny and HTML codes. easyROC combines several R\npackages for ROC curve analysis. This tool has three main parts including ROC statistics, cutpoint\ncalculations and sample size estimation. Detailed information about easyROC and the related methods\ntogether with mathematical background are given in Section Material and methods. easyROC is\nfreely available at http://www.biosoft.hacettepe.edu.tr/easyROC and all the source codes are on\nGitHub1.\nMaterial and methods\nTheory behind ROC analysis\nLet us consider the binary classiﬁcation problem where X denotes the value of the classiﬁer for cases\nand controls. Consider the values of controls distributed as X0 ∼G0(.) and cases as X1 ∼G1(.).\nLet ˆY = {0, 1}be the estimated class labels of the subjects for a given threshold value c as given in\nEquation 1.\nˆY =\n{\n1, if X ≥c\n0, if X < c (1)\nParametric ROC curve. The parametric ROC curve is plotted using the FPR ( 1 −Speciﬁcity) and\nTPR (Sensitivity) values given in Equation 2 for all possible cutpoints of a classiﬁer.\nFPRc =P (X ≥c |Y = 0) =\n∫ ∞\nc\nG0(x)dx\nTPR c =P (X ≥c |Y = 1) =\n∫ ∞\nc\nG1(x)dx (2)\nWhen the distribution of the classiﬁer is Normal, the parametric ROC curve is ﬁtted using binormal\nROC properties. Suppose X0 ∼Normal (µ0, σ2\n0 ) and X1 ∼Normal (µ1, σ2\n1 ). The ROC curve is the\nfunction of FPRs; as in Equation 3.\nROC(t) =Φ\n(\na + bΦ−1 (t)\n)\n, (3)\nwhere a = (µ1 −µ0)/σ1, b = σ0/σ1, t = FPRc and Φ is the cumulative distribution function of\nthe standard normal distribution (Zhou et al., 2002). The area under the curve is calculated using\nEquation 4.\nAUC =\n1∫\n0\nROC(t)dt = Φ\n( a√\n1 + b2\n)\n(4)\nFitting the ROC curve by using Equation 3 has two major drawbacks: (i) incorrect ROC curves\nmay arise when the underlying distribution is not normal, (ii) ROC lines are improper when within\nclass variations are not similar, i.e., heteroscedasticity. An example of improper ROC curves is given\nin Figure 1. To overcome these problems, one may nonparametrically ﬁt the ROC curve without\nconsidering distributional assumptions or use parametric/semiparametric alternatives to the binormal\nmodel (Gönen and Heller, 2010).\nNonparametric ROC curve. Consider the estimated class labels in Equation 1. The FPR and TPR\ngiven in Equation 2 are estimated; as given in Equation 5.\n1http://www.github.com/dncR/easyROC\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 215\n0.0 0.2 0.4 0.6 0.8 1.0\n0.0 0.2 0.4 0.6 0.8 1.0\n1 − Specificity\nSensitivity\nµ0 = 55  σ0 = 8\nµ1 = 70  σ1 = 8\nAUC = 0.91\n0.0 0.2 0.4 0.6 0.8 1.0\n0.0 0.2 0.4 0.6 0.8 1.0\n1 − Specificity\nSensitivity\nµ0 = 55  σ0 = 24\nµ1 = 70  σ1 = 8\nAUC = 0.72\n0.0 0.2 0.4 0.6 0.8 1.0\n0.0 0.2 0.4 0.6 0.8 1.0\n1 − Specificity\nSensitivity\nµ0 = 70  σ0 = 4\nµ1 = 70  σ1 = 8\nAUC = 0.5\n0.0 0.2 0.4 0.6 0.8 1.0\n0.0 0.2 0.4 0.6 0.8 1.0\n1 − Specificity\nSensitivity\nµ0 = 70  σ0 = 32\nµ1 = 70  σ1 = 8\nAUC = 0.5\nFigure 1: Parametric ROC curves.\nˆFPRc = 1\nn0\nn0\n∑\nj=1\nI\n[\nX0j ≥c\n]\nˆTPR c = 1\nn1\nn1\n∑\ni=1\nI [ X1i ≥c ] (5)\nThe empirical ROC curve is plotted using ˆFPRc and ˆTPR c and the area under the curve, given\nin Equation 6, is estimated by summing the trapezoids enclosed by the points of the ROC curve.\nThe nonparametric AUC is related to the Mann-Whitney statistic of the rank-sum test (Bamber, 1975;\nHanley and McNeil, 1982).\nˆAUC = 1\nn0n1\nn0\n∑\nj=1\nn1\n∑\ni=1\nΨ\n(\nX1i, X0j\n)\n, (6)\nwhere Ψ = 0 if X0 > X1, Ψ = 1 if X1 > X0 and Ψ = 1/2 if X0 = X1.\nPerformance measures and optimal cutpoints. The predicted and actual classes, i.e., gold standard\ntest results, can be shown with a 2 ×2 cross table; as seen in Table 1. The performance of a classiﬁer is\nbasically measured using the total proportion of true positive (TP) and true negative (TN) cases. By\nusing Table 1, several performance measures are also calculated. Among these performance measures,\nwe focused on the measures given in Table 1 which are widely used and well-known. The optimal\ncutpoint is determined by using one or more performance measures together. An ideal cutpoint, for\nexample, might be selected by maximizing the sensitivity and speciﬁcity of a classiﬁer. A classiﬁer\nwith perfect discriminative ability would have sensitivity and speciﬁcity measures equal to 1. Hence,\nthe area under the curve for a perfect separation will be equal to 1.\nAlthough researchers are usually interested in the overall diagnostic performance of a classiﬁer,\nit is sometimes useful to focus on a portion of the ROC curve to compute the partial AUCs (pAUC).\npAUC is an extension of the AUC measure which considers the trapezoids within a given interval of\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 216\nPredicted Labels Actual Labels Total\nPositive (Y = 1) Negative (Y = 0)\nPositive ( ˆY = 1) TP FP TP + FP\nNegative ( ˆY = 0) FN TN FN + TN\nTotal TP + FN FP + TN n\nTP: True positive\nFP: False positive\nTN: True negative\nFN: False negative\nNPV: Negative predictive value\nPPV: Positive predictive value\nPLR: Positive likelihood ratio\nNLR: Negative likelihood ratio\nSensitivity = TP/(TP + FN )\nSpeciﬁcity = TN /(FP + TN )\nPPV = TP/(TP + FP)\nNPV = TN /(TN + FN )\nPLR = Sensitivity /(1 −Speci f icity)\nNLR = (1 −Sensitivity )/Speci f icity\nTable 1: A 2 ×2 classiﬁcation table and performance measures.\nsensitivity and/or speciﬁcity. Let us consider the pAUC where speciﬁcity (or sensitivity) lies within\nthe interval [t1, t2]. The pAUC is calculated by taking the integral (parametric) as given in Equation 7\nor by summing the trapezoids within the interval (nonparametric).\npAUC (t1, t2) =\nt2∫\nt1\nROC(x)dx (7)\nAs the interval [t1, t2] converges to [0, 1], the pAUC will converge to the overall AUC. The best classiﬁer\ncan be selected using either AUC or pAUC values.\nIdentiﬁcation of the optimal cutpoint is an important task to avoid incorrect conclusions. Various\nmethods are available in the literature to determine the optimal cutpoint. Most of these methods are\nbased on the sensitivity and speciﬁcity measures. However, other methods are also available based on\ncost-beneﬁt, prevalence, predictive values and diagnostic likelihood ratios. Two popular methods are,\nfor example, the Youden index and the minimization of the distance of the point on the curve to the\ntop-left corner, i.e., the point indicating perfect discrimination.\nYouden(c) =max{TPR c −FPRc} (8)\nTable 1 gives the list of optimal cutpoint methods we consider in easyROC. For detailed information\nand mathematical background, see Lopez-Raton et al. (2014).\nStatistical inference. A common subject of interest in ROC analysis is to compare the performances\nof several classiﬁers to select the best one to discriminate cases from controls. For a classiﬁer with\nrandom chance discrimination ability, the equation TPR = FPR holds. In that case, the area under the\ncurve is 0.50. Hence, the discrimination ability of a classiﬁer is mostly tested against the value 0.50.\nH0 : AUC = 0.50\nH1 : AUC ̸= 0.50\nUnder the large sample theory, the signiﬁcance of AUC is tested using the Wald test statistic as\ngiven in Equation 9.\nz =\nˆAUC −AUC\nVar( ˆAUC)1/2\n(9)\nWhen the parametric approach is used, the variance of AUC is estimated using Equation 10 (McClish,\n1989; Zhou et al., 2002).\nVar\n(\nˆAUC\n)\n= f 2Var(ˆa) +g2Var(ˆb) +2 f gCov(ˆa, ˆb), (10)\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 217\nwhere\nf = e−a2/2(1+b2)\n√\n2π(1 + b2)\nand g = −abe−a/2(1+b2)\n√\n2π(1 + b2)3 (11)\nand the estimated variances for a and b as follows:\nˆVar(ˆa) =n1(ˆa2 + 2) +2n0 ˆb2\n2n0n1\n,\nˆVar(ˆb) =(n1 + n0)ˆb2\n2n0n1\n, (12)\nˆCov(ˆa, ˆb) = ˆaˆb\n2n0\n.\nThe estimated values of a and b are used in Equation 11. A number of methods have been proposed\nfor the estimation of the variance of AUC when the nonparametric approach is used. In this paper, we\nwill focus on the methods described below:\n1. Mann-Whitney version of rank-sum test:\nHanley and McNeil (1982) propose the variance estimation given in Equation 13. This method\nestimates the variance using an approximation based on exponential distribution as\nVar\n(\nˆAUC\n)\n= 1\nn0n1\n{\nAUC(1 −AUC) + (n1 −1)(Q1 −AUC2)\n+(n0 −1)(Q2 −AUC2)\n}\n, (13)\nwhere Q1 = ˆAUC/(2 −ˆAUC) and Q2 = 2 ˆAUC\n2\n/(1 + ˆAUC). The Mann-Whitney version\nmight underestimate the variance when the area is nearly 0.5 and overestimate it when the area\nis close to 1 (Hanley and McNeil, 1982; Hanley and Hajian-Tilaki, 1997; Obuchowski, 1994). This\nestimate is mostly used in sample-size estimation.\n2. DeLong et al. (1988)’s estimate:\nSince the exponential distribution approximation in Equation 13 gives biased variance estimates,\nDeLong et al. (1988) suggest an alternative method which is free from distributional assumptions.\nDeﬁne the components T1i for the ith subject from cases and T0j for the jth subject from controls\nas follows:\nψ (T1i) = 1\nn0\nn0\n∑\nj=1\nΨ\n(\nX1i, X0j\n)\ni = 1, 2, . . . ,n1\nψ\n(\nT0j\n)\n= 1\nn1\nn1\n∑\ni=1\nΨ\n(\nX1i, X0j\n)\nj = 1, 2, . . . ,n0 (14)\nUsing the Equation 14 the variance of AUC is estimated as\nVar\n(\nˆAUC\n)\n= 1\nn1\nS2\nT1 + 1\nn0\nS2\nT0 , (15)\nwhere S2\nT1\nand S2\nT0\nare variance estimates of T1 and T0 as in Equation 16.\nS2\nTi = 1\nni −1\nni\n∑\nj=1\n[\nψ\n(\nTij\n)\n−ˆAUC\n]2\ni = 0, 1 (16)\n3. Normal approximation of binomial proportion:\nAnother alternative for variance estimation is to use binomial approximation under the large\nsample theory, as given in Equation 17. For small samples, this method may give biased\nestimates.\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 218\nVar( ˆAUC) = AUC(1 −AUC)\nn0 + n1\n(17)\nThe estimated variance derived from one of the methods described above is used to construct the\nconﬁdence intervals of the AUC. A common method is to use large sample approximation as below:\nˆAUC −z1−α/2Var( ˆAUC)1/2 < AUC < ˆAUC + z1−α/2Var( ˆAUC)1/2. (18)\nWhen the area under the curve is close to 1 or the sample size is relatively small, the large sample\napproximation in Equation 18 produces improper conﬁdence intervals since the upper limit exceeds 1.\nTo solve this problem, Agresti and Coull (1998) proposed thescore conﬁdence interval that guarantees the\nupper limit is less than or equal to 1. Another alternative is to construct the binomial exact conﬁdence\nintervals given in Equation 19 using the relationship between binomial and F-distribution (Morisette\nand Khorram, 1998)\n1\n1 + n −x + 1\nx F2(n−x+1),2x,α/2\n≤p ≤\nx + 1\nn −x F2(x+1),2(n−x),α/2\n1 + x + 1\nn −x F2(x+1),2(n−x),α/2\n, (19)\nwhere p = x/n is the binomial proportion such as sensitivity, speciﬁcity and AUC.\nSample size calculation. In most studies, determining the required sample size is an important step\nfor the research to be able to detect signiﬁcant results. Sample size determination is required for both\nconstructing the conﬁdence interval of the unknown population parameter and testing a research\nhypothesis. Obuchowski (1998) reviewed sample size determination for several study designs. In\nthis paper, we cover the sample size determination for three types of studies based on AUCs. In\naddition, the following sample size calculations can be extended to other performance measures such\nas sensitivity, speciﬁcity, etc.\nThe variance estimates of AUCs can be obtained using one of the Equations 13, 15 and 17. While\nEquation 13 is a good approximation for a variety of underlying distributions, the estimated variance\nwill be underestimated if the test results are in a discrete rating format. To overcome this problem,\nObuchowski (1998) and Obuchowski et al. (2004) suggest an alternative variance estimation method\nfor rating data using the variance function as given in Equation 20 which is based on an underlying\nbinormal distribution. In this section, we focused on sample size calculation for discrete scale data.\nHowever, the same formulas are valid for continuous scale diagnostic tests since the only difference is\nabout estimating the variance of diagnostic test accuracy.\nV( ˆAUC) =0.0099 e−a2/2 ×\n[\n(5a2 + 8) + (a2 + 8)/R\n]\n, (20)\nwhere a =\n√\n2 Φ−1(AUC) and R = n0/n1 is the allocation ratio, i.e., the ratio of the number of controls\nto the number of cases. The estimated variance is then Var( ˆAUC) =V( ˆAUC)/n1. The total sample\nsize is equal to n = n1(1 + R). One of the variance estimations from Equations 13, 15, 17 and 20 is\nused for the sample size calculations. The selection of the appropriate variance estimation method is\nbased on the variable type of the test results and underlying distributions.\n1. Hypothesis test to determine the AUC of a single classiﬁer:\nIn most of the studies with a single classiﬁer, the aim of the study is to determine whether the\ndiagnostic test performs well for discriminating diseased patients from controls. Consider the\nhypotheses H0 : AUC = 0.5 versus H1 : AUC > 0.5 (i.e, one-sided test). The required number\nof cases is determined using Equation 21 (Obuchowski et al., 2004).\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 219\nn1 =\n[\nz1−α\n√\nVar0( ˆAUC) +z1−β\n√\nVar1( ˆAUC)\n]2\n(AUC −0.5)2\n=\n[\nz1−α\n√\n0.0792 ×(1 + 1/R) +z1−β\n√\nVar1( ˆAUC)\n]2\n(AUC −0.5)2 , (21)\nwhere Var0 and Var1 are the variance estimations under the null and alternative hypotheses\nusing Equation 20. z1−α and z1−β are lower-tailed percentile values of the cumulative standard\nnormal distribution. Finally, the total sample size is obtained using n = n1 + n1 ×R.\n2. Comparing the AUCs of two classiﬁers:\nWhen the aim of a study is to compare two classiﬁers, one may consider the hypotheses\nH0 : AUC1 = AUC2 versus H1 : AUC1 ̸= AUC2. The two classiﬁers will be equally performing\nunder the null hypothesis. The required number of cases is calculated using Equation 22.\nn1 =\n[\nz1−α/2\n√\nVar0( ˆAUC1 −ˆAUC2) +z1−β\n√\nVar1( ˆAUC1 −ˆAUC2)\n]2\n(AUC1 −AUC2)2 , (22)\nwhere Var0 and Var1 are the variance estimations under the null and alternative hypotheses; as\ngiven in Equation 23 (Zhou et al., 2002; Obuchowski et al., 2004).\nVar( ˆAUC1 −ˆAUC2) =Var( ˆAUC1) +Var( ˆAUC2) −2Cov( ˆAUC1, ˆAUC2) (23)\nThe total sample size is calculated using the allocation ratio. When two classiﬁers are performed\non the same subjects, the design will be paired yielding the covariance term to be a nonzero\n(usually positive) quantity. However, the covariance term will be zero (i.e., independent\nclassiﬁers) if each test is performed on different subjects. Detailed information on the calculation\nof the covariance term can be found in Zhou et al. (2002).\n3. Non-inferiority of a new classiﬁer to a standard one:\nIn addition to comparing two classiﬁers, some studies are designed to explore the performance\nof a new classiﬁer to that of a standard one. The new classiﬁer should perform as well as but\nnot necessarily better than the standard test (Obuchowski et al., 2004). The hypotheses are\nH0 : AUCstd −AUCnew ≥∆ versus H1 : AUCstd −AUCnew < ∆. The required number of cases\nis calculated using Equation 24\nn1 = (z1−α + z1−β)2 Var1( ˆAUCstd −ˆAUCnew )\n(AUCstd −AUCnew −∆)2 , (24)\nwhere ∆ is the non-inferiority margin, i.e., the minimum acceptable difference between the\nAUCs of the standard and new classiﬁers.\nCurrent ROC analysis tools and easyROC\nROC curve analysis is one of the standard procedures included in most statistical analysis tools such as\nIBM SPSS, Stata, MedCalc and R. Each tool offers different features within ROC curve analysis. Among\ncommercial software packages, IBM SPSS, which is one of the most widely used commercial software\npackages, plots the ROC curve and computes some basic statistics such as AUC and its standard error,\nconﬁdence interval and statistical signiﬁcance. However, it does not provide any method for sample\nsize calculation or cutpoint determination. Stata offers a variety of calculations for ROC curve analysis\nincluding partial AUC, multiple comparisons of ROC curves, optimal cutpoint determination using\nthe Youden index and several performance measures. Another commercial software alternative for\nROC curve analysis is MedCalc, which has comprehensive features compared to most of the other\navailable commercial software packages and is especially developed for biomedical research. MedCalc\nprovides sample size estimation for a single diagnostic test, but it does not have an option for pAUC\ncalculation.\nUnlike commercial software packages, R is an open source and free software package that includes\nall the features of commercial software packages and more through several packages such asROC,\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 220\nIBM SPSS Stata MedCalc ROC ROCR pROC easyROC\nPlots Yes Yes Yes* Yes Yes* Yes* Yes*\nConf. intervals Yes Yes* Yes Yes Yes Yes* Yes*\npAUC No Yes No Yes Yes Yes* Yes*\nStatistical tests No Yes No Yes Yes Yes* Yes*\nDiagnostic measures No Yes Yes No Yes* Yes Yes\nMultiple comp. No Yes Yes* No No Yes* Yes\nCutpoints No Yes Yes No No Yes Yes*\nSample size No No Yes No No Yes Yes*\nFree license No No No Yes* Yes* Yes* Yes*\nOpen source No No No Yes* Yes* Yes* Yes*\nWeb-tool access No No No No No No Yes*\nUser interface Yes Yes* Yes* No No Yes* Yes*\n* Comprehensive ones.\nTable 2: Comparison of easyROC with other tools.\nROCR, pROC and OptimalCutpoints. ROC is an R/Bioconductor package which can plot the\nROC curve and calculate the AUC. It also calculates pAUCs based on false positive rates. This\npackage is originally developed to be used for the ROC analysis with DNA microarrays. ROCR is\na comprehensive R package providing over 25 different performance measures (based on package\nversion 1.0-7). It allows users to create two dimensional performance curves. Although ROCR is\none of the most comprehensive packages for assessing the performance measures, it provides limited\noptions to select the optimum cutpoint. One may use any of the two-dimensional performance graphs\nto determine the optimal cutpoint graphically. It computes the AUC and its conﬁdence interval,\nhowever, it does not provide a statistical test for performance measures.\npROC, on the other hand, offers more comprehensive and ﬂexible features than its free and\ncommercial counterparts. It performs statistical tests for the comparison of ROC curves using DeLong\net al. (1988), Venkatraman and Begg (1996) and Venkatraman (2000) for AUC, and Hanley and McNeil\n(1983) and Pepe et al. (2009) for both AUC and pAUC. It also calculates the conﬁdence intervals for the\nsensitivity, speciﬁcity, ROC curves, pAUC, and smoothed ROC curves. The conﬁdence intervals are\ncomputed using DeLong et al. (1988)’s method for AUCs and using bootstrap for pAUCs, sensitivity\nand speciﬁcity at given threshold(s). Bootstrap conﬁdence intervals and pAUC regions are shown in\nthe ROC curve plot. Several diagnostic measures, such as sensitivity, speciﬁcity, negative and positive\npredictive values, are computed for a given threshold. Like ROCR, pROC also offers limited features\nfor detecting the optimal cutpoint. Two methods, i.e., Youden index and closest point to the top-left\ncorner, are available to ﬁnd the optimal cutpoint. In addition, pROC is an alternative among the ROC\npackages on CRAN to ﬁnd the required sample size for a single diagnostic test or the comparison of\ntwo diagnostic tests. Two versions of pROC are available: (i) for the R programming language and (ii)\nwith a graphical user interface for the S-PLUS statistical software package.\nThere are several packages providing optimal cutpoint calculations through R. OptimalCutpoints\nis a sophisticated R package speciﬁcally developed to determine the optimal cutpoint of a test or\nbiomarker (Lopez-Raton et al., 2014). It includes 34 different cutpoint calculation methods based on\nsensitivity/speciﬁcity measures, cost-beneﬁt analysis, predictive values, diagnostic likelihood ratios,\nprevalences and p-values. A brief description of these methods is given in Supplementary 1. Although\nthese R packages, especially pROC, seem to be a perfect match for ROC curve analysis, none of them\nhas a graphical user interface and all require coding knowledge, which makes them hard to use;\nespecially for non-R users.\nAnother R package worth mentioning is plotROC (Sachs, 2016) which is available on CRAN and\nalso for shiny platforms. plotROC is a ﬂexible and sophisticated R package which can be used to\ncreate nice-looking and interactive ROC graphs. Unlike the packages described above, plotROC has a\nweb-based user interface which is very useful for non-R users. Researchers can use its web service to\ncreate ROC graphics and download the ﬁgures to their local computer. However, it does not provide\nany statistical tests or sample size calculations.\neasyROC aims to extend the features of several ROC packages in R and allows researchers to\nconduct their ROC curve analysis through a single and easy-to-use interface without writing any R\ncode. This tool is a web-based application created via shiny and HTML programming. easyROC\nmakes use of the R packagesplyr (Wickham, 2011),pROC and OptimalCutpoints for conducting ROC\nanalysis. plyr is used for manipulating data while pROC is used for estimation and hypothesis testing\nof pAUCs. easyROC has comprehensive options for ROC curve analysis which other tools do not have\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 221\nModules (Tab panels) Features\nROC curve • Parametric/Nonparametric ROC\n• AUC, pAUC\n– Conﬁdence interval (Exact and Asymptotic)\n– Signiﬁcance test (Wald)\n• Standard error estimation\n– DeLong (1988)\n– Mann-Whitney\n– Binomial approximation\n• Multiple comparison of AUCs\n– Bonferroni\n– False discovery rate\n• ROC plot (customizable)\nCutpoints • 34 different methods for optimum cutpoints\n(Lopez-Raton et al., 2014)\n• Performance measures with conﬁdence intervals\n– Exact CIs\n– Asymptotic CIs\n• Cutpoint graphs (fully customizable)\n– ROC curve\n– Sensitivity & speciﬁcity plot\n– Density plot\n– Scatter plot\nSample size • Single diagnostic test\n• Comparison of two diagnostic tests\n• Noninferiority of a new test to a standard test\nTable 3: Features of easyROC.\n(or partially shares some features). The ROC curve can be estimated using parametric or nonparametric\napproaches. It offers four different methods for the calculation of the standard error and conﬁdence\ninterval of the AUC. Researchers can calculate the pAUCs based on sensitivity and speciﬁcity, if\nnecessary. One may perform pairwise comparisons to ﬁnd the classiﬁers which have similar or\ndifferent discrimination ability. However, the pairwise comparison should be carried out carefully\nsince the type I error increases with the increasing number of comparisons. easyROC offers multiple\ntest corrections in order to keep type I error at a given level. Multiple comparisons of diagnostic tests\ncan be applied using either Bonferroni or false discovery rate correction. Furthermore, the optimal\ncutpoints are determined using the methods fromOptimalCutpoints and the corresponding measures\nat a given cutpoint, including sensitivity, speciﬁcity, positive and negative predictive values, and\npositive and negative likelihood ratios are also returned. One can determine the desired sample size\nfor ROC curve analysis using this tool for three different cases. All these comprehensive features are\naccessible through a graphical user interface, which makes the analysis process easier for all users. The\ncomparison with other tools is given in Table 2 and the features of each module are given in Table 3.\nResults\nCase study on non-alcoholic fatty liver disease\nTo illustrate our application, we used the non-alcoholic fatty liver disease (NAFLD) dataset of Celik-\nbilek et al. (2014). This study was designed to identify the non-invasive miRNA biomarkers of NAFLD.\nThe authors obtained the serum samples of 20 healthy and 20 NAFLD observations and quantiﬁed\nthe expression levels of eight miRNAs using quantitative Real-Time PCR (qPCR) technology. After\nperforming the necessary statistical analysis, the authors revealed that miR-197, miR-146b, miR-181d\nand miR-99a may be potential biomarkers in identifying NAFLD. The normalized expression values\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 222\nFigure 2: Uploading data into easyROC.\nof these miRNAs and the class information (the column named “Group”, where 0 refers to controls\nand 1 refers to cases) of each observation are given in Supplementary 2. This ﬁle can be directly\nused as input to the easyROC web-tool and users can arrange their own data based on this ﬁle. Two\nexample datasets, Mayo and PBC (Murtaugh et al., 1994), are also available in the web-tool for users\nto practice the application. In our example, the aim is to investigate the discriminative performances\nof each miRNA, compare each other and identify the optimal cutpoints for each miRNA in identifying\nNAFLD.\nImplementation of easyROC web-tool\nThe data are uploaded to the easyROC interface using the Data upload tab (Figure 2). easyROC accepts\na delimited text ﬁle with variable names in the ﬁrst row. The status variable is also set by the same tab\npanel. easyROC automatically detects the variable names and exports them into related ﬁelds. When\ndata are correctly uploaded, researchers may proceed with ROC curve analysis, cutpoint estimations\nor sample size calculations. The area under the curve, conﬁdence intervals and signiﬁcance tests for\nAUC, multiple comparisons (if multiple markers are selected) and pAUCs are calculated with the\nROC curve tab (Figures 3 and 4). The ROC curve is estimated using the nonparametric approach. The\nadvanced option allows researchers to select a method for standard error estimation and conﬁdence\nintervals. easyROC selects the DeLong et al. (1988) method by default.\nHere, we select mir197, mir146b, mir181d and mir99a miRNAs to assess their performances and\nto compare them with each other in identifying NAFLD. Since the expression levels of all miRNAs\nare underexpressed in the NAFLD group, lower values will indicate higher risk and therefore we\nshould uncheck the “Higher values indicate higher risks” box. Using DeLong et al. (1988) standard\nerror estimations, we obtained the ROC curves for each miRNA biomarker and AUC values as 0.86\n(0.75–0.97), 0.77 (0.61–0.92), 0.76 (0.60–0.93) and 0.75 (0.59–0.91) for mir181d, mir197, mir99a and\nmir146b, respectively. The results revealed that all miRNAs’ predictive performances are signiﬁcant\nand higher than random chance in identifying NAFLD (Figure 3). By controlling the type I error using\nBonferroni correction, all pairwise comparisons showed non-signiﬁcant results (p > 0.05). This may\nbe due to the small sample size of the data. Increasing the sample size, thus the statistical power of the\ntest, may concretize the predictive ability of mir181d as compared to other miRNAs.\nFinding a suitable cutpoint is one of the aims of ROC curve analysis. We made use of the\nOptimalCutPoints package from R (Lopez-Raton et al., 2014), which has 34 different methods, to\ncalculate cutpoints for each marker. An optimal cutpoint can be computed via the Cut point tab\nby selecting a marker and a method. Then, the application will calculate an optimal cutpoint and\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 223\nFigure 3: ROC curve analysis results.\nFigure 4: Multiple comparison of the diagnostic tests.\nperformance measures such as sensitivity, speciﬁcity, positive and negative predictive value, and\npositive and negative likelihood ratio based on the corresponding cutpoint value. The “ROC01”\nmethod, for example, determines the optimal cutpoint as −0.12977 for mir181d. Using this cutpoint,\na new test observation with a mir181d expression level lower than this value can be assigned as an\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 224\nFigure 5: Determination of optimal cutpoint(s).\nNAFLD patient. Based on the identiﬁed cutpoint, we obtained statistical diagnostic measures with\n95% conﬁdence intervals (Figure 5). We obtain a sensitivity of 0.75 (0.51–0.91) and speciﬁcity of 0.80\n(0.56–0.94). If users select the “Include plots” option, four plots will appear under the statistics results.\nThe ﬁrst plot in the upper-left corner displays the optimal cutpoint on the ROC curve. Users can\nobserve the change of sensitivity and speciﬁcity measures based on the value of the marker on the plot\nplaced in the upper-right corner. The density and scatter of the expression values in each group are\ndisplayed in the bottom-left and bottom-right corners. The plots can be modiﬁed through the “More\nplot options” section. All the results and ﬁgures can be downloaded using the related “Download”\nbuttons in each tab panel.\nConclusion\nSince ROC curve analysis is one of the principal statistical analysis methods, it is used by a wide\nrange of the scientiﬁc community. Both commercial and free software tools are available for users to\nperform it. Generally, easy-to-use and nicely-designed interfaces are offered by commercial software\npackages whereas ﬂexible and comprehensive tools are available in free, open-access, code-based\nsoftware packages, such as R. The ﬁrst novelty of our tool is that it allows the user to use free and\nopen-access software with an easy-to-use interface. In other words, we combine the power of an\nopen-source and free language with a nicely designed and easily accessible interface. This tool offers\nmore comprehensive features and a wide variety of implementations for ROC curve analysis than\nits commercial and free counterparts, which is another novelty of this application. It is speciﬁcally\nconstructed for ROC curve analysis, unlike the commercial software packages, such as IBM SPSS, Stata\nand MedCalc.\nThis web-based application is intended for research purposes only, not for clinical or commercial\nuse. Since it is a non-proﬁt service to the scientiﬁc community, it comes with no warranty and no\ndata security. However, since this web server uses the R packageshiny, each user performs his/her\nanalyses in a new R session. After uploading data, the application only saves responses within its\nR session and prints the results instantly. After a user has quit the application, the corresponding\nR session will be closed and any uploaded data, responses or outputs will not be saved locally or\nremotely.\nThis tool is freely available through http://www.biosoft.hacettepe.edu.tr/easyROC/ and all\nthe source codes are available at http://www.github.com/dncR/easyROCunder GPL version 3. It will\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 225\nbe regularly updated upon the dependent R packages used in this application, including shiny and\nOptimalCutpoints, and new features will be continually added as they are developed.\nBibliography\nA. Agresti and B. A. Coull. Approximate is better than “exact” for interval estimation of binomial\nproportions. The American Statistician, 52(2):119–126, 1998. doi: 10.2307/2685469. [p218]\nD. Bamber. The area above the ordinal dominance graph and the area below the receiver operating\ncharacteristic graph. Journal of Mathematical Psychology , 12(4):387–415, 1975. doi: 10.1016/0022-\n2496(75)90001-2. [p215]\nV . Carey and H. Redestig. ROC: Utilities for ROC, with Uarray Focus , 2015. URL https://www.\nbioconductor.org. R package version 1.44.0. [p213]\nM. Celikbilek, M. Baskol, S. Taheri, K. Deniz, S. Dogan, G. Zararsiz, S. Gursoy, K. Guven, O. Ozbakir,\nM. Dundar, and M. Yucesoy. Circulating microRNAs in patients with non-alcoholic fatty liver\ndisease. World Journal of Hepatology, 6(8):613–620, 2014. [p221]\nW. Chang, J. Cheng, J. Allaire, Y. Xie, and J. McPherson. shiny: Web Application Framework for R, 2015.\nURL https://CRAN.R-project.org/package=shiny. R package version 0.12.1. [p213]\nE. R. DeLong, D. M. DeLong, and D. L. Clarke-Pearson. Comparing the areas under two or more\ncorrelated receiver operating characteristic curves: A nonparametric approach. Biometrics, 44(3):\n837–845, 1988. doi: 10.2307/2531595. [p217, 220, 222]\nJ. P . Egan.Signal Detection Theory and ROC Analysis. Series in Cognition and Perception. Academic\nPress, New York, NY, 1975. [p213]\nJ. Fan, S. Upadhye, and A. Worster. Understanding receiver operating characteristic (ROC) curves.\nCanadian Journal of Emergency Medicine, 8:19–20, 2006. doi: 10.1017/s1481803500013336. [p213]\nT. Fawcett. An introduction to ROC analysis. Pattern Recognition Letters, 27(8):861–874, 2006. doi:\n10.1016/j.patrec.2005.10.010. [p213]\nM. Gönen and G. Heller. Lehmann family of ROC curves. Medical Decision Making, 30(4):509–517, 2010.\ndoi: 10.1177/0272989x09360067. [p214]\nJ. A. Hanley and K. O. Hajian-Tilaki. Sampling variability of nonparametric estimates of the areas\nunder receiver operating characteristic curves: An update. Academic Radiology, 4(1):49–58, 1997. doi:\n10.1016/s1076-6332(97)80161-4. [p217]\nJ. A. Hanley and B. J. McNeil. The meaning and use of the area under a receiver operating characteristic\n(ROC) curve. Radiology, 143(1):29–36, 1982. doi: 10.1148/radiology.143.1.7063747. [p215, 217]\nJ. A. Hanley and B. J. McNeil. A method of comparing the areas under receiver operating characteristic\ncurves derived from the same cases. Radiology, 148(3):839–843, 1983. doi: 10.1148/radiology.148.3.\n6878708. [p220]\nM. Lopez-Raton, M. X. Rodriguez-Alvarez, C. Cadarso-Suárez, and F. Gude-Sampedro. OptimalCut-\npoints: An R package for selecting optimal cutpoints in diagnostic tests. Journal of Statistical Software,\n61(8):1–36, 2014. doi: 10.18637/jss.v061.i08. [p213, 216, 220, 221, 222]\nD. K. McClish. Analyzing a portion of the ROC curve. Medical Decision Making, 9(3):190–195, 1989. doi:\n10.1177/0272989x8900900307. [p216]\nJ. T. Morisette and S. Khorram. Exact binomial conﬁdence interval for proportions. Photogrammetric\nEngineering and Remote Sensing, 64(4):281–283, 1998. [p218]\nP . A. Murtaugh, E. R. Dickson, G. M. Van Dam, M. Malinchoc, P . M. Grambsch, A. L. Langworthy, and\nC. H. Gips. Primary biliary cirrhosis: Prediction of short-term survival based on repeated patient\nvisits. Hepatology, 20(1):126–134, 1994. doi: 10.1002/hep.1840200120. [p222]\nN. A. Obuchowski. Computing sample size for receiver operating characteristic studies. Investigative\nRadiology, 29(2):238–243, 1994. doi: 10.1097/00004424-199402000-00020. [p217]\nN. A. Obuchowski. Sample size calculations in studies of test accuracy. Statistical Methods in Medical\nResearch, 7(4):371–392, 1998. [p218]\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 226\nN. A. Obuchowski, M. L. Lieber, and F. H. Wians. ROC curves in clinical chemistry: Uses, misuses,\nand possible solutions. Clinical Chemistry, 50(7):1118–1125, 2004. doi: 10.1373/clinchem.2004.031823.\n[p218, 219]\nM. Pepe, G. Longton, and H. Janes. Estimation and comparison of receiver operating characteristic\ncurves. The Stata Journal, 9(1):1, 2009. [p220]\nX. Robin, N. Turck, A. Hainard, N. Tiberti, F. Lisacek, J.-C. Sanchez, and M. Müller. pROC: An\nopen-source package for R and S+ to analyze and compare ROC curves. BMC Bioinformatics, 12(1):\n77, 2011. doi: 10.1186/1471-2105-12-77. [p213]\nM. C. Sachs. plotROC: Generate Useful ROC Curve Charts for Print and Interactive Use , 2016. URL\nhttp://sachsmc.github.io/plotROC. R package version 2.0.1. [p220]\nT. Sing, O. Sander, N. Beerenwinkel, and T. Lengauer. ROCR: Visualizing classiﬁer performance in R.\nBioinformatics, 21(20):3940–3941, 2005. [p213]\nP . Sonego, A. Kocsor, and S. Pongor. ROC analysis: Applications to the classiﬁcation of biological\nsequences and 3D structures. Brieﬁngs in Bioinformatics, 9(3):198–209, 2008. [p213]\nJ. A. Swets, R. M. Dawes, and J. Monahan. Better decisions through science. Scientiﬁc American, 283(4):\n82–87, 2000. doi: 10.1038/scientiﬁcamerican1000-82. [p213]\nE. Venkatraman. A permutation test to compare receiver operating characteristic curves. Biometrics, 56\n(4):1134–1138, 2000. doi: 10.1111/j.0006-341x.2000.01134.x. [p220]\nE. Venkatraman and C. B. Begg. A distribution-free procedure for comparing receiver operating\ncharacteristic curves from a paired experiment. Biometrika, 83(4):835–848, 1996. doi: 10.1093/\nbiomet/83.4.835. [p220]\nH. Wickham. The split-apply-combine strategy for data analysis. Journal of Statistical Software, 40(1):\n1–29, 2011. URL http://www.jstatsoft.org/v40/i01/. [p220]\nX.-H. Zhou, D. K. McClish, and N. A. Obuchowski. Statistical Methods in Diagnostic Medicine, volume\n569. John Wiley & Sons, 2002. doi: 10.1002/9780470317082. [p214, 216, 219]\nDincer Goksuluk\nDepartment of Biostatistics, School of Medicine, Hacettepe University\nSihhiye Campus, 06100 - Ankara\nTurkey\ndincer.goksuluk@hacettepe.edu.tr\nSelcuk Korkmaz\nDepartment of Biostatistics, School of Medicine, Hacettepe University\nSihhiye Campus, 06100 - Ankara\nTurkey\nselcukorkmaz@hotmail.com\nGokmen Zararsiz\nDepartment of Biostatistics, School of Medicine, Erciyes University\nGenome and Stem Cell Center, Erciyes University\nTalas, 38039 - Kayseri\nTurkey\ngokmenzararsiz@hotmail.com\nA. Ergun Karaagaoglu\nDepartment of Biostatistics, School of Medicine, Hacettepe University\nSihhiye Campus, 06100 - Ankara\nTurkey\nekaraaga@gmail.com\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 227\nSupplementary material\nSupplementary 1: A brief description of optimal cutpoint methods.\nMethod Description\nYouden Youden index identiﬁes the cutpoint that maximizes the sum of Sensitivity and Speci f icity.\nCB CB is a measure based on the cost and beneﬁt method, and is calculated from the slope of the ROC curve.\nMinValueSp\nMinValueSe\nFor a given minimum value for Speci f icity, MinValueSp identiﬁes the optimal value as the one that gives the maximum Sensitivity .\nIn contrast, for a given minimum value for Sensitivity , MinValueSe identiﬁes the optimal value as the one that gives the maximum\nSpeci f icity.\nValueSp\nValueSe\nFor a given particular value for Speci f icity, ValueSp identiﬁes the optimal value as the one that gives the maximum Sensitivity . In\ncontrast, for a given particular value for Sensitivity , ValueSe identiﬁes the optimal value as the one that gives the maximum Speci f icity.\nMinValueSpSe For given minimum values for Speci f icity and Sensitivity measures, MinValueSpSe identiﬁes the optimal value as the one that gives the\nmaximum Sensitivity or Speci f icity (user-deﬁned).\nMaxSp\nMaxSe MaxSp and MaxSe are two measures based on the maximization of Speci f icity and Sensitivity , respectively.\nMaxSpSe MaxSpSe is a measure based on the simultaneous maximization of both Speci f icity and Sensitivity measures.\nMaxProdSpSe MaxProdSpSe is a measure based on the maximization of the product of Sensitivity and Speci f icity.\nROC01 ROC01 identiﬁes the optimal cutpoint that is closest to the upper-left corner (0, 1) of the ROC graph.\nSpEqualSe SpEqualSe is a measure based on the minimization of the absolute difference between Sensitivity and Speci f icity.\nMaxEfﬁciency MaxEfﬁciency is a measure based on the minimization of the misclassiﬁcation error, (FP + FN )/n.\nContinued on next page\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 228\nSupplementary 1 – Continued from previous page\nMethod Description\nMinimax Minimax is a measure based on the minimization of the most frequent error. Minimax is computed using the equation Minimaxc =\nminc(max(p(1 −Sensitivity ) + (1 −p)(1 −Speci f icity))) where c is the cutpoint and p is the prevalence.\nMaxDOR MaxDOR is a measure based on the maximization of the diagnostic odds ratio, calculated using the equation MaxDORc =\nmaxc[(Sensitivity ×Speci f icity)/((1 −Sensitivity )(1 −Speci f icity))].\nMinValueNPV\nMinValuePPV\nFor a given minimum value for NPV , MinValueNPV identiﬁes the optimal value as the one that gives the maximum PPV. In contrast,\nfor a given minimum value for PPV, MinValuePPV identiﬁes the optimal value as the one that gives the maximum NPV .\nValueNPV\nValuePPV\nFor a given particular value for NPV , ValueNPV identiﬁes the optimal cutpoint as the one that gives the maximum PPV. In contrast, for\na given particular value for PPV, ValuePPV identiﬁes the optimal cutpoint as the one that gives the maximum NPV .\nMinValueNPVPPV For given minimum values for predictive values, MinValueNPVPPV identiﬁes the optimal value as the one that gives the maximum\nNPV or PPV (user-deﬁned).\nPROC01 PROC01 identiﬁes the optimal cutpoint that is closest to the upper-left corner (0, 1) of the partial ROC (pROC) graph.\nNPVEqualPPV NPVEqualPPV is a measure based on the minimization of the absolute difference between NPV and PPV.\nMaxNPVPPV MaxNPVPPV is a measure based on the simultaneous maximization of both NPV and PPV measures.\nMaxSumNPVPPV MaxSumNPVPPV is a measure based on the maximization of the sum of NPV and PPV measures.\nMaxProdNPVPPV MaxProdNPVPPV is a measure based on the maximization of the product of NPV and PPV.\nValueDLR.Negative\nValueDLR.Positive These two measures are based on setting particular values for negative and positive diagnostic likelihood ratios, respectively.\nMinPvalue MinPvalue is a measure based on the minimization of the p-value of the Chi-square test on assessing the independence between the\ndiagnostic and gold standard test.\nContinued on next page\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 229\nSupplementary 1 – Continued from previous page\nMethod Description\nObservedPrev ObservedPrev is a measure which identiﬁes the optimal cutpoint closest to the observed prevalence by minimizing the quantity |c −p|.\nThis method is valid when the diagnostic test takes values within the interval [0, 1].\nMeanPrev MeanPrev is a measure which identiﬁes the optimal cutpoint closest to the average of the diagnostic test values. It is suggested to use\nthis measure if the diagnostic test takes values between 0 and 1.\nPrevalenceMatching PrevalenceMatching is a measure based on the equality of actual and predicted prevalence. The cutpoint minimizes the absolute quantity\n|p(1 −Sensitivity ) −(1 −p)(1 −Speci f icity)|. This method is valid when the diagnostic test takes values within the interval [0, 1].\nFor details, see Lopez-Raton et al. (2014).\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859\nCONTRIBUTED RESEARCH ARTICLES 230\nSupplementary 2: Non-alcoholic fatty liver disease (NAFLD) data (Çelikbilek et al., 2014).\nGrup mir197 mir146b mir181d mir99a Grup mir197 mir146b mir181d mir99a\n1 0.921 0.687 0.474 −0.941 0 1.214 1.122 0.882 1.610\n1 0.967 1.059 0.474 0.575 0 1.401 0.148 0.444 0.625\n1 0.854 1.105 0.722 0.936 0 0.494 −0.179 1.386 0.134\n1 −1.088 −1.353 −0.577 −1.077 0 1.608 1.386 2.242 0.926\n1 0.107 0.515 −0.286 0.560 0 1.274 1.609 0.769 1.108\n1 0.547 1.191 0.583 1.119 0 0.827 1.128 0.452 0.374\n1 −1.081 −1.445 −1.303 −1.202 0 −0.147 −0.545 0.878 0.044\n1 −1.081 −1.308 −1.276 −1.066 0 0.353 0.320 −0.225 0.367\n1 0.841 0.463 −0.290 0.747 0 −1.635 −0.677 −0.838 −0.543\n1 −1.188 −0.975 −1.407 −2.123 0 1.848 1.523 1.712 0.940\n1 −1.014 −0.649 −1.194 −1.786 0 0.987 0.606 0.626 0.542\n1 −1.081 −1.256 −1.229 −0.679 0 0.020 0.503 0.600 0.367\n1 −1.295 −1.204 −1.607 −2.216 0 1.061 1.518 1.217 0.209\n1 −1.081 −1.268 −0.829 −0.658 0 0.474 0.572 0.292 0.786\n1 −1.081 −1.365 −1.376 −1.457 0 −0.868 −0.505 −0.408 −0.117\n1 −1.081 −1.371 −0.812 −1.804 0 −0.414 −0.259 0.665 0.363\n1 −1.081 −0.769 −1.359 −0.156 0 0.394 0.417 1.000 0.130\n1 0.854 1.243 0.444 1.460 0 0.941 0.543 0.431 1.083\n1 −1.074 −1.365 −1.572 −0.339 0 −0.387 −0.202 −0.568 0.345\n1 −0.634 −0.276 −0.130 −0.081 0 −0.674 −0.689 0.995 0.893\nThe R Journal Vol. 8/2, December 2016 ISSN 2073-4859"
}