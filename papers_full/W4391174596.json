{
    "title": "Generative Large Language Models for Detection of Speech Recognition Errors in Radiology Reports",
    "url": "https://openalex.org/W4391174596",
    "year": 2024,
    "authors": [
        {
            "id": null,
            "name": "Reuben A. Schmidt",
            "affiliations": [
                "Western Health",
                "University of Melbourne",
                "Alfred Health",
                "Monash University"
            ]
        },
        {
            "id": "https://openalex.org/A4311782068",
            "name": "Jarrel C. Y. Seah",
            "affiliations": [
                "Alfred Health",
                "Western Health",
                "University of Melbourne",
                "Monash University"
            ]
        },
        {
            "id": "https://openalex.org/A1921903316",
            "name": "Ke Cao",
            "affiliations": [
                "Alfred Health",
                "Monash University",
                "Western Health",
                "University of Melbourne"
            ]
        },
        {
            "id": "https://openalex.org/A2775119032",
            "name": "Lincoln Lim",
            "affiliations": [
                "Alfred Health",
                "Western Health",
                "University of Melbourne",
                "Monash University"
            ]
        },
        {
            "id": "https://openalex.org/A2221989746",
            "name": "Wei Lim",
            "affiliations": [
                "University of Melbourne",
                "Western Health",
                "Alfred Health",
                "Monash University"
            ]
        },
        {
            "id": "https://openalex.org/A2253182466",
            "name": "Justin Yeung",
            "affiliations": [
                "Alfred Health",
                "Western Health",
                "University of Melbourne",
                "Monash University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2015073921",
        "https://openalex.org/W2025269721",
        "https://openalex.org/W1167277758",
        "https://openalex.org/W2043643141",
        "https://openalex.org/W1966843785",
        "https://openalex.org/W2161128009",
        "https://openalex.org/W2761304371",
        "https://openalex.org/W2889947689",
        "https://openalex.org/W4281479095",
        "https://openalex.org/W4362522726",
        "https://openalex.org/W4381480701",
        "https://openalex.org/W4380422747",
        "https://openalex.org/W4385546024",
        "https://openalex.org/W4309791331",
        "https://openalex.org/W4382182493",
        "https://openalex.org/W2890185963",
        "https://openalex.org/W3089474066"
    ],
    "abstract": "This study evaluated the ability of generative large language models (LLMs) to detect speech recognition errors in radiology reports. A dataset of 3233 CT and MRI reports was assessed by radiologists for speech recognition errors. Errors were categorized as clinically significant or not clinically significant. Performances of five generative LLMs-GPT-3.5-turbo, GPT-4, text-davinci-003, Llama-v2-70B-chat, and Bard-were compared in detecting these errors, using manual error detection as the reference standard. Prompt engineering was used to optimize model performance. GPT-4 demonstrated high accuracy in detecting clinically significant errors (precision, 76.9%; recall, 100%; F1 score, 86.9%) and not clinically significant errors (precision, 93.9%; recall, 94.7%; F1 score, 94.3%). Text-davinci-003 achieved F1 scores of 72% and 46.6% for clinically significant and not clinically significant errors, respectively. GPT-3.5-turbo obtained 59.1% and 32.2% F1 scores, while Llama-v2-70B-chat scored 72.8% and 47.7%. Bard showed the lowest accuracy, with F1 scores of 47.5% and 20.9%. GPT-4 effectively identified challenging errors of nonsense phrases and internally inconsistent statements. Longer reports, resident dictation, and overnight shifts were associated with higher error rates. In conclusion, advanced generative LLMs show potential for automatic detection of speech recognition errors in radiology reports. <b>Keywords:</b> CT, Large Language Model, Machine Learning, MRI, Natural Language Processing, Radiology Reports, Speech, Unsupervised Learning <i>Supplemental material is available for this article</i>.",
    "full_text": null
}