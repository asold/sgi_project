{
  "title": "Large Language Models and User Trust: Consequence of Self-Referential Learning Loop and the Deskilling of Health Care Professionals",
  "url": "https://openalex.org/W4392976364",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3173241984",
      "name": "Choudhury, Avishek",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Chaudhry, Zaria",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2979226802",
    "https://openalex.org/W4393564733",
    "https://openalex.org/W4366281673",
    "https://openalex.org/W4366743045",
    "https://openalex.org/W4386757039",
    "https://openalex.org/W4367060129",
    "https://openalex.org/W4294168458",
    "https://openalex.org/W4353016766",
    "https://openalex.org/W4320895630",
    "https://openalex.org/W4206310419",
    "https://openalex.org/W4377043947",
    "https://openalex.org/W4225591000",
    "https://openalex.org/W4378471319",
    "https://openalex.org/W4365148488",
    "https://openalex.org/W4386153819",
    "https://openalex.org/W4366989525",
    "https://openalex.org/W4380360840",
    "https://openalex.org/W4382249028",
    "https://openalex.org/W4384340967",
    "https://openalex.org/W4360620450",
    "https://openalex.org/W4376872703",
    "https://openalex.org/W4386544117",
    "https://openalex.org/W4378214315",
    "https://openalex.org/W3036458852",
    "https://openalex.org/W2281090488",
    "https://openalex.org/W4233667196",
    "https://openalex.org/W4384200891",
    "https://openalex.org/W4387425757",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4386767417",
    "https://openalex.org/W4366420437"
  ],
  "abstract": "As the health care industry increasingly embraces large language models (LLMs), understanding the consequence of this integration becomes crucial for maximizing benefits while mitigating potential pitfalls. This paper explores the evolving relationship among clinician trust in LLMs, the transition of data sources from predominantly human-generated to artificial intelligence (AI)–generated content, and the subsequent impact on the performance of LLMs and clinician competence. One of the primary concerns identified in this paper is the LLMs’ self-referential learning loops, where AI-generated content feeds into the learning algorithms, threatening the diversity of the data pool, potentially entrenching biases, and reducing the efficacy of LLMs. While theoretical at this stage, this feedback loop poses a significant challenge as the integration of LLMs in health care deepens, emphasizing the need for proactive dialogue and strategic measures to ensure the safe and effective use of LLM technology. Another key takeaway from our investigation is the role of user expertise and the necessity for a discerning approach to trusting and validating LLM outputs. The paper highlights how expert users, particularly clinicians, can leverage LLMs to enhance productivity by off-loading routine tasks while maintaining a critical oversight to identify and correct potential inaccuracies in AI-generated content. This balance of trust and skepticism is vital for ensuring that LLMs augment rather than undermine the quality of patient care. We also discuss the risks associated with the deskilling of health care professionals. Frequent reliance on LLMs for critical tasks could result in a decline in health care providers’ diagnostic and thinking skills, particularly affecting the training and development of future professionals. The legal and ethical considerations surrounding the deployment of LLMs in health care are also examined. We discuss the medicolegal challenges, including liability in cases of erroneous diagnoses or treatment advice generated by LLMs. The paper references recent legislative efforts, such as The Algorithmic Accountability Act of 2023, as crucial steps toward establishing a framework for the ethical and responsible use of AI-based technologies in health care. In conclusion, this paper advocates for a strategic approach to integrating LLMs into health care. By emphasizing the importance of maintaining clinician expertise, fostering critical engagement with LLM outputs, and navigating the legal and ethical landscape, we can ensure that LLMs serve as valuable tools in enhancing patient care and supporting health care professionals. This approach addresses the immediate challenges posed by integrating LLMs and sets a foundation for their maintainable and responsible use in the future.",
  "full_text": null,
  "topic": "Deskilling",
  "concepts": [
    {
      "name": "Deskilling",
      "score": 0.7238479256629944
    },
    {
      "name": "Health care",
      "score": 0.5630438923835754
    },
    {
      "name": "Public relations",
      "score": 0.3983500003814697
    },
    {
      "name": "Psychology",
      "score": 0.3950273096561432
    },
    {
      "name": "Medicine",
      "score": 0.3557303249835968
    },
    {
      "name": "Political science",
      "score": 0.1782478392124176
    },
    {
      "name": "Law",
      "score": 0.14287081360816956
    },
    {
      "name": "Engineering",
      "score": 0.12322580814361572
    },
    {
      "name": "Work (physics)",
      "score": 0.0
    },
    {
      "name": "Mechanical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I12097938",
      "name": "West Virginia University",
      "country": "US"
    }
  ]
}