{
    "title": "Shared Temporal Attention Transformer for Remaining Useful Lifetime Estimation",
    "url": "https://openalex.org/W4285266752",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2783768011",
            "name": "Gavneet Singh Chadha",
            "affiliations": [
                "South Westphalia University of Applied Sciences"
            ]
        },
        {
            "id": "https://openalex.org/A2901782022",
            "name": "Sayed Rafay Bin Shah",
            "affiliations": [
                "South Westphalia University of Applied Sciences"
            ]
        },
        {
            "id": "https://openalex.org/A138927069",
            "name": "Andreas Schwung",
            "affiliations": [
                "South Westphalia University of Applied Sciences"
            ]
        },
        {
            "id": "https://openalex.org/A2116771079",
            "name": "Steven X. Ding",
            "affiliations": [
                "University of Duisburg-Essen"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W1540327028",
        "https://openalex.org/W2045186954",
        "https://openalex.org/W1964940259",
        "https://openalex.org/W6682751323",
        "https://openalex.org/W2064675550",
        "https://openalex.org/W6640212811",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W2744067593",
        "https://openalex.org/W2910660149",
        "https://openalex.org/W2952602217",
        "https://openalex.org/W2902700103",
        "https://openalex.org/W6679434410",
        "https://openalex.org/W1902237438",
        "https://openalex.org/W3006585575",
        "https://openalex.org/W2415594836",
        "https://openalex.org/W2772084711",
        "https://openalex.org/W3130218378",
        "https://openalex.org/W3012642762",
        "https://openalex.org/W3042726568",
        "https://openalex.org/W2978540646",
        "https://openalex.org/W3120284962",
        "https://openalex.org/W2979101700",
        "https://openalex.org/W2947621394",
        "https://openalex.org/W3014146531",
        "https://openalex.org/W6771626834",
        "https://openalex.org/W3099793224",
        "https://openalex.org/W6755207826",
        "https://openalex.org/W3137613462",
        "https://openalex.org/W6780226713",
        "https://openalex.org/W3035512902",
        "https://openalex.org/W6623041627",
        "https://openalex.org/W2120841219",
        "https://openalex.org/W2322648887",
        "https://openalex.org/W2898735569",
        "https://openalex.org/W6631190155",
        "https://openalex.org/W6631943919",
        "https://openalex.org/W809430598"
    ],
    "abstract": "This paper proposes a novel deep learning architecture for estimating the remaining useful lifetime (RUL) of industrial components, which solely relies on the recently developed transformer architectures. The RUL estimation resorts to analysing degradation patterns within multivariate time series signals. Hence, we propose a novel shared temporal attention block that allows detecting RUL patterns with the progress of time. Furthermore, we develop a split-feature attention block that enables attending to features from different sensor channels. The proposed shared temporal attention layer in the encoder fulfils the goal of attending to temporal degradation patterns in the individual sensor signals before creating a shared correlation across the feature range. We develop two transformer architectures that are specifically designed to operate with multivariate time series data based on these novel attention blocks. We apply the architectures to the well known C-MAPSS benchmark dataset and provide various hyperparameter studies to analyse their impact on the performance. In addition, we provide a thorough comparison with recently presented state-of-the-art approaches and show that the proposed transformer architectures outperform the existing methods by a considerable margin.",
    "full_text": null
}