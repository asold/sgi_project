{
  "title": "Don’t Trust ChatGPT when your Question is not in English: A Study of Multilingual Abilities and Types of LLMs",
  "url": "https://openalex.org/W4389519117",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2100623889",
      "name": "Xiang Zhang",
      "affiliations": [
        "University of Alberta"
      ]
    },
    {
      "id": "https://openalex.org/A2791816142",
      "name": "Senyu Li",
      "affiliations": [
        "University of Alberta"
      ]
    },
    {
      "id": "https://openalex.org/A2115845150",
      "name": "Bradley Hauer",
      "affiliations": [
        "University of Alberta"
      ]
    },
    {
      "id": "https://openalex.org/A2101203781",
      "name": "Ning Shi",
      "affiliations": [
        "University of Alberta"
      ]
    },
    {
      "id": "https://openalex.org/A330825386",
      "name": "Grzegorz Kondrak",
      "affiliations": [
        "University of Alberta"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3146844750",
    "https://openalex.org/W1894439495",
    "https://openalex.org/W4389523957",
    "https://openalex.org/W4294294857",
    "https://openalex.org/W2081531639",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4385570391",
    "https://openalex.org/W4206732210",
    "https://openalex.org/W4283026156",
    "https://openalex.org/W125505485",
    "https://openalex.org/W2022799155",
    "https://openalex.org/W4303648904",
    "https://openalex.org/W4206118214",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4283773758",
    "https://openalex.org/W2118090838",
    "https://openalex.org/W2076192883",
    "https://openalex.org/W2747680751",
    "https://openalex.org/W1493855351",
    "https://openalex.org/W4286892945",
    "https://openalex.org/W4292939182",
    "https://openalex.org/W2963995027",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4385573424",
    "https://openalex.org/W3161207330",
    "https://openalex.org/W2218641061",
    "https://openalex.org/W4205635927",
    "https://openalex.org/W4389519448",
    "https://openalex.org/W4376312043",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2583818370",
    "https://openalex.org/W3037763555",
    "https://openalex.org/W2997248598"
  ],
  "abstract": "Large language models (LLMs) have demonstrated exceptional natural language understanding abilities, and have excelled in a variety of natural language processing (NLP) tasks. Despite the fact that most LLMs are trained predominantly on English, multiple studies have demonstrated their capabilities in a variety of languages. However, fundamental questions persist regarding how LLMs acquire their multilingual abilities and how performance varies across different languages. These inquiries are crucial for the study of LLMs since users and researchers often come from diverse language backgrounds, potentially influencing how they use LLMs and interpret their output. In this work, we propose a systematic way of qualitatively and quantitatively evaluating the multilingual capabilities of LLMs. We investigate the phenomenon of cross-language generalization in LLMs, wherein limited multilingual training data leads to advanced multilingual capabilities. To accomplish this, we employ a novel prompt back-translation method. The results demonstrate that LLMs, such as GPT, can effectively transfer learned knowledge across different languages, yielding relatively consistent results in translation-equivariant tasks, in which the correct output does not depend on the language of the input. However, LLMs struggle to provide accurate results in translation-variant tasks, which lack this property, requiring careful user judgment to evaluate the answers.",
  "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 7915–7927\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nDon’t Trust ChatGPT when your Question is not in English:\nA Study of Multilingual Abilities and Types of LLMs\nXiang Zhang∗ Senyu Li∗ Bradley Hauer Ning Shi Grzegorz Kondrak\nAlberta Machine Intelligence Institute\nDepartment of Computing Science\nUniversity of Alberta, Edmonton, Canada\n{xzhang23,senyu,bmhauer,ning.shi,gkondrak}@ualberta.ca\nAbstract\nLarge language models (LLMs) have demon-\nstrated exceptional natural language under-\nstanding abilities, and have excelled in a vari-\nety of natural language processing (NLP) tasks.\nDespite the fact that most LLMs are trained pre-\ndominantly on English, multiple studies have\ndemonstrated their capabilities in a variety of\nlanguages. However, fundamental questions\npersist regarding how LLMs acquire their mul-\ntilingual abilities and how performance varies\nacross different languages. These inquiries are\ncrucial for the study of LLMs since users and\nresearchers often come from diverse language\nbackgrounds, potentially influencing how they\nuse LLMs and interpret their output. In this\nwork, we propose a systematic way of qualita-\ntively and quantitatively evaluating the multilin-\ngual capabilities of LLMs. We investigate the\nphenomenon of cross-language generalization\nin LLMs, wherein limited multilingual training\ndata leads to advanced multilingual capabilities.\nTo accomplish this, we employ a novel prompt\nback-translation method. The results demon-\nstrate that LLMs, such as GPT, can effectively\ntransfer learned knowledge across different lan-\nguages, yielding relatively consistent results in\ntranslation-equivariant tasks, in which the cor-\nrect output does not depend on the language\nof the input. However, LLMs struggle to pro-\nvide accurate results in translation-variant tasks,\nwhich lack this property, requiring careful user\njudgment to evaluate the answers.\n1 Introduction\nThe study of bilingualism has long been a topic of\ninterest among linguists (Yu et al., 2022; Hoffmann,\n2014), as it provides insight into the mechanisms of\nlanguage acquisition and processing. Furthermore,\nresearch on multilingualism has contributed to the\ndevelopment of more effective machine learning\nmodels, such as neural translation systems (Zou\net al., 2013). With the rise of large language models\n∗ ∗Equal contribution.\nknife \n(a) Compound(b) Coordinate(c) Subordinate\ncouteau Lexicon\nInternal\nConcept\nEn Fr\nknife couteau \nEn Fr\nTranslation\nType\nknife couteau \nEn Fr\nFigure 1: The three types of bilingualism.\n(LLMs), researchers have discovered many emer-\ngent properties (Wei et al., 2022a) in these models,\nand have used them for a variety of purposes (Wei\net al., 2022b). However, the multilingual ability of\nthese models has not been extensively studied.\nPrevious research has shown that large language\nmodels, such as GPT, are capable of performing\na wide variety of language tasks when the task is\npresented in English (Qin et al., 2023). However,\ninvestigations into the multilingual language abil-\nities of these models have been limited. Shi et al.\n(2023) explore this topic by applying the models to\nmultilingual datasets, and measuring performance\ndifferences across languages. However, they do not\nexplore the underlying mechanisms of how LLMs\nperform different tasks, nor how this affects the\nresults. Moreover, most LLMs (Brown et al., 2020;\nTouvron et al., 2023) are trained on datasets that\nare heavily skewed towards English, which leaves\nopen the question of how multilingual abilities in\nsuch models are acquired.\nIn this study, we present a systematic approach\nto analyzing the multilingual capabilities of LLMs.\nTo facilitate a comprehensive analysis, we pro-\npose categorizing language-dependent abilities into\nthree distinct categories which vary in the impact\nof language choice on the performance: Reasoning\n(least impact), Knowledge Access, and Articulation\n(most impact). We investigate a carefully selected\nset of tasks from these three categories by evalu-\n7915\nating the multilingual abilities of an LLM using a\nnovel prompting method which we call response\nback-translation (RBT). By comparing the gener-\nated answers, we can both measure multilingual\nperformance of the LLM, but also determine the\ntype of multilinguality they exhibit. For example,\nwe examine the capabilities of LLMs on pun detec-\ntion, a highly language-dependent task.\nThe results of our experiments show that the pop-\nular LLM “GPT”: (1) achieves higher performance\nwhen the task is presented in English; (2) achieves\nhigher performance on tasks that can be translated\nwithout altering the correct output; and (3) exhibits\na mixture of coordinate and subordinate bilingual-\nism.\nOur main contributions1 are:\n• We present a first-of-its-kind quantitative and\nqualitative analysis of the multilingual abili-\nties of LLMs.\n• We propose two novel task categorizations to\nfacilitate the multilingual ability analysis.\n• Our work is the first to investigate LLMs with\nrespect to a linguistic typology of bilingualism\nand multilingualism.\n2 Background\nLinguists categorize bilingual individuals into three\ngroups: compound, coordinate, and subordinate\nbilinguals (D’Acierno, 1990). Figure 1 illus-\ntrates this categorization, showing how individuals\nwith different types of English-French bilingualism\nmight internally represent the concept of “knife”.\nCompound bilingualism mostly emerges among\nindividuals who learn two languages simultane-\nously from birth. In this case, both languages are\nequally dominant and integrated, blurring any clear\ndistinction between them and giving the impres-\nsion of a single unified language (Moradi, 2014).\nCompound bilingualism entails a shared mental\nrepresentation of lexicons across both languages\nthey acquire, and compound bilinguals are the most\nflexible in their use of multiple languages, exhibit-\ning the ability to switch between languages without\nlosing consistency in linguistic tasks (De Groot and\nNas, 1991).\nIn contrast, individuals exhibiting coordinate\nbilingualism maintain separate mental represen-\ntations for the lexicon of each language they\n1Our data is publicly available at GitHub.\nlearn. This separation leads to differences when\ntasks are performed under different language set-\ntings (Jakobovits, 1968).\nFinally, subordinate bilingualism is character-\nized by a “translator” behaviour (Marcos, 1976).\nThis type of bilingualism is characterized by a sin-\ngle lexicon representation that is linked to their\ndominant language (Lörscher, 2012). When per-\nforming tasks in languages other than their dom-\ninant one, subordinate bilinguals tend to rely on\ntranslating the task into their dominant language,\nformulating an answer in the dominant language,\nand then translating that answer back into the lan-\nguage of the task. As a result, subordinate bilin-\nguals may experience lower proficiency in com-\nmunicating and completing tasks in the second,\nsubordinate language.\nDespite the demonstration in prior work of con-\nsistent multilingual performance in many large lan-\nguage models (Shi et al., 2023), it remains unclear\nhow the multilingualism of LLMs should be cate-\ngorized. It is an open question whether the LLMs\nexhibit a representation of knowledge shared across\nboth languages (compound), separate representa-\ntions for each language (coordinate), or whether\nthey rely on a translation processes (subordinate).\nWe develop an experimental framework aimed at\nusing performance on various natural language pro-\ncessing tasks to determine how the multilingual\nabilities of LLMs relate to these categories.\n3 Categorizing Language-Dependent\nTasks\nLanguage ability is a multifaceted concept en-\ncompassing various tasks and aspects (Wei et al.,\n2022a). It is therefore difficult to assess a model’s\ncapabilities with respect to a given language. To\nfacilitate such assessment, researchers have often\nclassified tasks into distinct categories (Khurana\net al., 2023), such as parsing and summarization.\nHowever, the delineation of such categories often\nlacks systematic criteria, particularly in the context\nof multilingual analysis.\nIn this section, we propose a novel approach to\ncategorizing NLP tasks, which is better suited to\nanalysis of multilingual abilities. The categoriza-\ntion is two dimensional: one dimension is based\non the linguistic knowledge necessary to complete\nthe task (Section 3.1), the other on how the task is\nimpacted by the language in which it is presented\n(Section 3.2).\n7916\n解释什么是 “ 有限状态机 ” 。 \nExplain what is a \"finite state machine\".\nKnowledge Access Articulation\nWhat is the answer of 12 × 83?\n12 乘以 83 等于多少？ \n996.Response\nEn Prompt\nZh Prompt\nReasoning\nResponse\nCan you write me a cover letter\nfor SDE position?\nI am writing to express my keen\ninterest in the position ……\n你能给我写一封  SDE 职位的求职 \n信吗？ \n我写信是为了表达我对贵公司该 \n职位的浓厚兴趣  ……\nPrompt\nFigure 2: Three categories of NLP tasks.\n3.1 Categorization by Task Properties\nWe classify NLP tasks into three distinct categories:\nReasoning, Knowledge Access, and Articulation.\nThis division is based on the extent to which per-\nformance on each task is influenced by the model’s\ncapabilities with the language used. Figure 2 pro-\nvides an overview of this categorization.\nReasoning The first category includes tasks that\nare minimally influenced by language, on which\nconsistent performance is expected across lan-\nguages. Reasoning tasks involve logical and ra-\ntional thinking to solve problems based on avail-\nable information and logical principles. Examples\ninclude mathematical problem-solving (Lu et al.,\n2023), coding (Li et al., 2023), and common sense\nreasoning (Sap et al., 2020). These tasks can be\nperformed using universal language elements, such\nas mathematical symbols, or rely on general life\nexperience and common sense, which can be ac-\nquired without language. For example, answering\nthe question “If I drop an apple, which direction\nwill it go?” relies more on understanding gravity\nthan on language-specific knowledge.\nKnowledge Access LLMs have the capability\nto function as knowledge bases (KBs) by storing\nknowledge extracted from training data (Heinzer-\nling and Inui, 2021). Knowledge Access tasks de-\npend on the ability to access this knowledge and\nformulate accurate responses based on it. While\nthe underlying knowledge may not be language de-\npendent, models may be less reliable in retrieving\nand utilizing knowledge learned in a language other\nthan the one used to formulate the task. Examples\nof Knowledge Access tasks include factual knowl-\nedge checking (De Cao et al., 2021), knowledge-\nfocused question answering (Wang, 2022), and\nnamed entity recognition (Malmasi et al., 2022).\nArticulation Much of everyday human conver-\nsation is highly language-dependent, as it involves\nthe pragmatics and cultural nuances of the spo-\nken language. For instance, writing a cover letter\nin English significantly differs from writing one\nin Japanese, due to the distinct social norms and\nconventions associated with those languages. The\nArticulation category includes tasks that are heavily\ninfluenced by the language choice, such as summa-\nrization (Nenkova and McKeown, 2012), dialogue\ngeneration (Ni et al., 2023), paraphrasing (Zhou\nand Bhat, 2021), and style writing (Jin et al., 2022).\nThese tasks require an extensive understanding of\nnot only language, but the associated culture, as\nthey involve capturing and reproducing the appro-\npriate style, tone, and manner of expression specific\nto a given language.\n3.2 Categorization by Translatability\nThe second dimension of our task classification\nscheme involves translatability. We introduce the\nconcepts of Translation Equivariant (TE) and Trans-\nlation Variant (TV) tasks.\nA function is considered equivariant if it com-\nmutes with a symmetry transformation. That is,\napplying a transformation before or after comput-\ning the function yields the same result. Formally ,\nf(·) is said to be equivariant under g(·) if:\n∀x ∈D, g (f(x)) =f(g(x)) (1)\nwhere Drepresents the domain of both f and g.\nWe denote translation as a transformation g that\nconverts a given text in language A to an equiva-\nlent text in language B. In practice, g can be im-\nplemented by a machine translation system. We\nfurther use f to denote a function which solves\na given task, given an instance of that task as in-\nput. A task is considered Translation Equivariant\nbetween languages A and B if the correct output\ncan be obtained by translating the input, and then\napplying a method for solving the task, or by solv-\ning the task, and then translating the output; in\nother words, if g(f(x)) = f(g(x)). Most of the\n7917\ntasks in the Reasoning and Knowledge Access cate-\ngories are regarded as Translation Equivariant since\nthe correct output does not depend on the chosen\nlanguage. Figure 3 shows an example where the\nanswer to the question posed in English remains\nthe same in Chinese, regardless of in which order\nthe translation system and the question answering\nsystem are applied.\nA task which is not Translation Equivariant is\nTranslation Variant. For such tasks, translating the\ninput may change the correct output. TV tasks rely\nheavily on the language used, and include many\ntasks in the Articulation category. Representative\nTV tasks that we investigate in our experiments are\nletter writing and pun understanding. The former\nis subject to the conventions of the specific lan-\nguage and culture, while the latter involves word\npolysemy, which is often sensitive to translation.\nFigure 3 shows an example where a pun is present\nin the original English input, but not in the Span-\nish translation, making the classification dependent\nupon the order in which translation is applied.\n4 Methods\nIn this section, we present our approach to analyz-\ning the multilingual ability of LLMs. Our methods\ninvolve prompt translation (PT) and response back-\ntranslation (RBT). They are designed to measure\nperformance of an LLM, and its consistency across\nlanguages. In our experiments, we apply these\nmethods to both TE and TV tasks, with the aim of\ndetermining the type of bilingualism (compound,\ncoordinate, or subordinate) exhibited by an LLM.\n4.1 Prompt Translation\nMultilingual datasets are unvailable for many tasks.\nHowever, with state-of-the-art machine translation\n(MT) systems and LLMs, we can translate monolin-\ngual datasets for TE tasks to generate parallel mul-\ntilingual parallel data with minimal loss of infor-\nmation (Whitehouse et al., 2023; Shi et al., 2023).\nThis is the key intuition behind prompt transla-\ntion (PT); an example is shown in Figure 4a, where\nan English multiple choice question, and its possi-\nble answers, are translated to Chinese. The LLM is\nthen prompted, and the response is given and eval-\nuated, in Chinese. Prompting in distinct languages\nis performed in independent LLM sessions.\nWe measure the differences in multilingual task\nperformance by comparing the answers given by\nthe LLM in each language. Assuming that the LLM\n周二。 \nTranslation Equivariant (TE)\nTranslation Variant (TV)\nYes.\nNo.\nTuesday.\n周一后是周几？ \nWhat day is it after Monday?\nUna bicicleta no puede sostenerse por sí\nsola ya que tiene dos llantas.\nA bicycle can’t stand on its own\nsince it’s two-tired.\nFigure 3: A TE task (common sense reasoning) and a\nTV task (pun detection). Translation is denoted by g,\nand f is the solver function.\nsuccessfully learns to solve a TE task in a language-\nindependent way, the pairwise responses for each\ninstance should be the same after the translation (re-\ngardless of whether it is correct or incorrect). This\nis because TE tasks, such as mathematical problem\nsolving, do not depend on the language used to\nquery the LLMs, as the solution does not depend\non the language used to express the problem.\n4.2 Response Back-Translation\nOne of the goals of our work is to understand what\nthe consistency of LLM output across languages\ntells us about the model, and to determine the type\nof bilingualism an LLM exhibits. This is crucial for\nindividuals who use LLMs for multilingual tasks,\nas it can impact the way task results are gener-\nated, and affect the quality and consistency of the\nresults. For example, a network exhibiting sub-\nordinate bilingualism would produce output that\nappears to be the result of translation, rather than\nresembling text generated by a native speaker of\nthe output language.\nTo quantitatively measure how reasoning is per-\nformed, we propose a prompting method based on\nback-translation, as illustrated in Figure 4b. Simi-\nlar to prompt translation (Section 4.1), we begin by\ntranslating the instance to the target language, and\nprompting the LLM to produce a response in that\nlanguage. After obtaining output from the LLM,\nregardless of the language, we further prompt the\nLLM to generate an explanation for its output (e.g.,\n“Explain how you obtain this result”); and then trans-\nlate the output of the LLM back to the original\nlanguage. We then compare the explanation given\n7918\n(a) Prompt Translation (PT)\nA: (D).\nQ:  在办公室哪里可以找到椅子？ \n选项 : （ A ）体育场（ B ）厨房（ C ）门廊（ D ）隔间    (E ）客厅。 \nA:  (D) 。  \nTranslation\nZh Prompt in One New Session\nPairwise Comparison\nEn Prompt in One New Session\n(b) Response Back-Translation (RBT)\nA:  Because a cubicle is a small workspace that\nis typically found in an office setting. In such an\nenvironment, people often have desks and chairs\nto work at, and these chairs are usually designed\nto be comfortable for long periods of sitting.\nTherefore, it's most likely that you would find a\nchair at an office in a cubicle where people sit\nand work on their computers or other tasks.\nQ ：你能解释一下你选这个答案的原因吗？ \nA ：因为办公室通常有一些隔间或者办公室间隔，员工们在这些隔间或办公室中进行工作。因此，办公室椅子通 \n常会放在这些隔间或办公室中，以便员工可以坐下来工作。在这些隔间或办公室中，椅子通常会搭配办公桌使 \n用，以便员工可以更加舒适地完成工作任务。 \nA: Because offices usually have cubicles or office partitions where employees work. Therefore, office chairs are\ntypically located in these cubicles or offices for employees to sit and work comfortably. Chairs in these cubicles\nor offices are usually paired with office desks to provide a comfortable working environment for employees.\nQ ：把你的解释翻译成英文。 (Q: Translate your answer into English.)\nTranslation\nPairwise Comparison\nEn Prompt in Same Session Zh Prompt in Same Session\nQ:  Can you explain why you chose this answer?\nQ:  Where might you find a chair at an office?\nOptions: (A) stadium (B) kitchen (C) porch (D) cubicle (E) living room.\nFigure 4: An overview of our prompt translation and response back-translation methods.\nin the source language to the explanation back-\ntranslated from the target language.\nIf the LLM is performing translation-based rea-\nsoning, the reasoning process is conducted in one\nlanguage and then translated into another. Since\nthe internal reasoning of the LLM can be partially\nobserved through the output explanation, back-\ntranslating such explanations into the source lan-\nguage allows us to compare the internal reasoning\nused to solve the problem in each language. High\nsimilarity of explanations should indicate homo-\ngeneity in using the same internal reasoning pro-\ncess to perform the task in both languages. On the\nother hand, dissimilarity in the reasoning process\nacross languages should be reflected in a lower\nexplanation similarity.\n4.3 Identifying Multilingual Types\nIn our investigation, we employ both Prompt Trans-\nlation (PT) and Response Back-Translation (RBT)\nto analyze how an LLM solves TE and TV tasks\nin different languages. As depicted in the first two\nsteps in Figure 5, a compound LLM should exhibit\nconsistent results on TE tasks with both methods.\nThis is because a compound model performance\ndoes not depend on the language in which a ques-\ntion is presented. Conversely, subordinate and coor-\ndinate types of networks are expected to yield some-\nwhat different results on TE tasks. A coordinate\nmodel accesses distinct representations in different\nlanguages, which may result in different reasoning\nand answers. Finally, a subordinate model heavily\ndepends on an internal translation process, which\nwe expect to lead to some deterioration of output\nquality across languages.\nTesting on TV tasks provide additional informa-\ntion, which can be used to distinguish between coor-\ndinate and subordinate models. A coordinate LLM\nSubordinate \nResults change\nafter translation?\nCompound \nPrompt Translation\nTV Task\n Same reasoning\nacross all languages?\nResponse Back-Translation\nCompound \nSame results\nacross all languages?\nTE Task\nPrompt Translation\nCoordinate \nYes No\nNo Yes\nYes No\nFigure 5: Flowchart for detecting multilingual types.\nis expected to reason differently for each language,\nwhich may yield different outputs, whether correct\nor not. In contrast, a pure subordinate model is\nexpected to reason only in the dominant language,\nproducing relatively similar results in different lan-\nguages, regardless of whether the correct output is\npreserved after translation.\n5 Experiments\nWe apply the methodology proposed in Section 4\nto TE and TV tasks. As our LLM, we use Chat-\nGPT, via the official web application2, due to its\navailability.\n5.1 Datasets\nReasoning We use 50 instances selected at ran-\ndom from each of two datasets: GSM8K (Cobbe\n2https://chat.openai.com/\n7919\net al., 2021), which contains 7,500 training and\n1,000 test problems, and CommonsenseQA (Tal-\nmor et al., 2019), which contains 12,247 questions.\nWe used ChatGPT to translate these instances into\nFrench, Spanish, German, Japanese, and Chinese.\nGSM8K is a dataset of grade-school math prob-\nlems. Each problem consists of a question and\na multiple-choice answer. CommonsenseQA is a\nquestion answering dataset for testing logic and\ncommon sense. Each instance consists of a ques-\ntion and five answer choices, only one of which is\nconsidered correct.\nKnowledge Access WebQuestions is a dataset of\n6,642 question-answer pairs extracted from Free-\nbase (Bordes et al., 2014). An example question is\n“Where is the Thames River located?” to which the\ncorrect answer is London. To simplify the evalua-\ntion, and avoid the issue of extracting answers from\nChatGPT’s often verbose responses, we manually\nconverted 50 randomly selected instances into the\nmultiple-choice format used by CommonsenseQA.\nTo create plausible incorrect answers (distractors),\nwe randomly selected four incorrect candidate an-\nswers from sets of world city names3 and celebrity\nnames4 (correct answers in this dataset are all ei-\nther city names or celebrity names). This yielded a\nset of 50 multiple choice questions with five pos-\nsible answers each (one correct, four incorrect).\nWe translated the English instances into five other\nlanguages via ChatGPT.\nPuns We randomly selected 80 positive and 80\nnegative instances each from the English, French,\nand Spanish instances in the JOKER@CLEF 2022\ndataset (Ermakova et al., 2022). Each instance is\nannotated with a yes/no classification as to whether\nit contains a pun, and the pun location, if a pun\nis present. An example English instance is “As-\ntronauts work in a nice atmosphere” for which\nthe pun location is the word atmosphere. We used\nChatGPT to translate the French and Spanish in-\nstances into English, and the English instances into\nFrench, Spanish, German, Japanese, and Chinese.\nThis yields 10 balanced sets of 160 instances each\n(three original and seven translated).\nArticulation To test the Articulation abilities of\nan LLM, we prompt the model to generate a cover\nletter for a job application, with randomized spec-\nifications. For each prompt, we first generate the\n3https://simplemaps.com/data/world-cities\n4https://github.com/janester/mad_libs\nTask En Fr De Es Ja Zh\nMR 0.90 0.80 0.78 0.80 0.82 0.78\nCSR 0.68 0.58 0.52 0.54 0.48 0.52\nKA 0.96 0.96 0.94 0.94 0.80 0.68\nTable 1: Accuracy for TE tasks: math reasoning (MR),\ncommonsense reasoning (CSR), and knowledge access\n(KA).\nname and background of an individual, including\ninformation such as level of education, specialties,\nand hobbies. We then randomly select one well-\nknown company to which cover letter is to be ad-\ndressed. Finally, we select a set of topics such\nas “What skills would you want to develop in this\nrole?”. Each of these randomized prompts is then\nprovided to the LLM. The output is then manually\nevaluated by a native speaker of the language of the\nprompt. We generate 50 prompts each in English\nand Chinese. An example is provided in Table 5 in\nthe appendix.\n5.2 Metrics\nSince ChatGPT can give different answers to the\nsame question, we present each multiple-choice\nquestion to ChatGPT five times, and use the\nmost frequent output for evaluation. For comput-\ning similarity between explanations, we use ap-\npendix(Devlin et al., 2019). Specifically, we trans-\nlate all non-English output to English via ChatGPT,\nand compute the cosine similarity of the BERT\nembeddings of the two explanations.\n5.3 Results on TE Tasks\nAs shown in Table 1, the results on TE tasks in En-\nglish are on average much higher in English than in\nother languages. In math reasoning (MR), the least\nlanguage-dependent task, the gap between English\nand other languages is over 10% on average. In\ncommon sense reasoning (CSR), the difference is\nover 15% on average. In knowledge access (KA),\nthere is no substantial difference between English\nand other European languages, but accuracy on\nJapanese and Chinese is 16% and 28% lower, re-\nspectively. To confirm that the accuracy gap is\nnot due to instance translation quality, we manu-\nally compared all 50 Chinese MR questions with\ntheir original English counterparts, and found no\ntranslation errors. Taken together, these results\nprovide strong evidence that GPT is better able to\nreason and retrieve knowledge given an English\n7920\nprompt, compared to prompting in other languages.\nIn terms of multilinguality type, the evidence is\nagainst compound multilingualism in GPT (cf., Fig-\nure 5), as a compound model would be expected\nto exhibit no substantial difference in performance\nacross languages.\nWe also analyzed the BERT similarity values\nbetween explanations in different languages (cf.,\nTable 4 in the Appendix). In commonsense reason-\ning, which relies on logic and conceptual distinc-\ntions, we observe that the average BERT similar-\nity of German, Spanish, Japanese and Chinese to\nFrench is substantially lower than the correspond-\ning average similarity to English (0.849 vs. 0.868),\nwhile French itself is substantially more similar\nto English than to German ( 0.871 vs 0.857). We\ninterpret this as additional evidence of the GPT’s\ndependence on its strong English model.\nOn the other hand, we observe no such trend in\nknowledge access questions. We hypothesize that\nsince these problems are mostly about named en-\ntities, they tend to be more language-independent.\nIndeed, we observe higher performance on French,\nGerman, and Spanish, which use the Latin script,\nand therefore can represent named entities as En-\nglish does, compared to Japanese and Chinese,\nwhich use different orthographies.\n5.4 Cover Letters\nCover letter writing is an example of a TV articula-\ntion task. We found that cover letters generated by\nChatGPT with the same set of instructions in dif-\nferent languages exhibit relatively high BERT simi-\nlarity to their English versions, ranging from 0.818\nJapanese to 0.865 for German. To provide some\ncomparison, we also computed pairwise BERT sim-\nilarities between English cover letters generated\nwith the same prompts by ChatGPT and two other\nLLMs, Claude and Instant-Claude, which yielded\nthe values of 0.618 and 0.643, respectively. This\nindicates that the letters generated in different lan-\nguages by ChatGPT are more similar to each other\nthan the letters in English generated by different\nLLMs.\nCover letters generated in languages other than\nEnglish exhibit a written style which is closer to\nEnglish than to the target language. For exam-\nple, consider the cover letter shown in Table 5 in\nthe Appendix. The expressions 阁下 “from what\nI have gathered” and 狂热的户外运动爱好者“avid\noutdoor enthusiast” are very unnatural in Chinese,\nChinese English Translation Frequency\n诚挚地 Sincerely 54.0%\n致意 Regards 38.4%\n祝愿 Best Wishes 3.6%\n此致敬礼 Salute (Proper Chinese Sign-off) 0.8%\nNo sign-off 3.2%\nTable 2: The frequency of different sign-offs in 250\ndifferent Chinese cover letters generated by ChatGPT.\nLanguage P-Acc L-Acc\nEs 0.488 0.697\nEs-En 0.507 0.714\nFr 0.500 0.886\nFr-En 0.513 0.813\nEn 0.506 0.965\nEn-Fr 0.500 0.646\nEn-De 0.519 -\nEn-Es 0.488 0.607\nEn-Ja 0.519 -\nEn-Zh 0.550 0.511\nTable 3: Accuracy on pun detection (P-Acc) and loca-\ntion (L-Acc). X-Y means the puns were translated from\nlanguage X to language Y before prompting.\nand appear characteristic of literal translations from\nEnglish. The sign-off phrase 真诚的 “Sincerely” is\nsimilarly inappropriate in formal Chinese, although\nit is usual in English. Table 2 shows that less than\n1% of the letters have a proper Chinese sign off.\n5.5 Results on Puns\nTable 3 shows the results on the translation-variant\ntasks of pun detection and location. The accuracy\nof pun detection is close to what we would ex-\npect from a random baseline, as ChatGPT strongly\nfavors positive pun classifications. The sole ex-\nception is a slightly higher accuracy of 0.55 when\nEnglish puns are translated into Chinese, due to a\nhigher proportion of negative classifications.\nSince few conclusions can be drawn from the\npun detection results, we conducted an evalua-\ntion of the pun location results in most datasets,\nwhich required manual extraction of the location\ninformation from ChatGPT’s explanations. The\nresults are shown in Table 3. The pun location ac-\ncuracy on the original English puns is very high at\n96.5%, but drops dramatically when the sentences\nare translated into other languages. When French\npuns are translated to English, there is likewise a\n7921\ndrop in performance, though it is much smaller\nthan what is observed when English puns are trans-\nlated to French. However, the situation is different\nfor Spanish puns, where the location accuracy in-\ncreases slightly after the puns are translated into En-\nglish. This is surprising, as puns are often language-\nspecific, and tend to disappear after translation.\nWhen the prompt is not in English, evidence\nsuggests that ChatGPT relies, at least partly, on\nits English capabilities for semantic interpretation.\nConsider the homonymous English wordbat which\nhas two unrelated senses, translated by different\nwords in Chinese: 蝙蝠 for the “animal” sense,\nand 球拍 for the “club” sense (Hauer and Kondrak,\n2020). When the original English prompt is “What\nis the famous bat brand for baseball?”, ChatGPT\nappears unable to distinguish between these two\ntranslations of bat within a Chinese prompt. Al-\nthough the choice of the Chinese translation of bat\ngreatly affects the meaning of the question, it does\nnot seem to impact ChatGPT’s response. How-\never, when we replace 蝙蝠 “animal bat” with 老虎\n“tiger”, ChatGPT correctly responds that the ques-\ntion makes no sense. We interpret the inability of\nChatGPT to differentiate between the two distinct\nChinese translations of bat as strong evidence of\nsubordinate bilingualism.\n5.6 Analysis of Results\nThe results of our experiments provide evidence\nthat GPT exhibits a substantial degree of subordi-\nnate multilingualism. Many of its responses are\nwhat we would expect from a system which trans-\nlates all input into English, formulates a response\nin English, and then translates this response into\nthe input language. Since translation is an error-\nprone process, the resulting response accuracy is\nfrequently lower than when the input is provided\nin English.\nWe speculate that this behavior is an artifact of\nGPT being trained mostly on monolingual English\ntexts. Consequently, GPT has developed a repre-\nsentation of knowledge and communication that\nis strongly biased towards English. We conclude\nthat since GPT is not designed to take advantage of\nbilingual or multilingual corpora, it is unable to cre-\nate a single multilingual conceptual representation\nanalogous to compound multilingualism.\nMoreover, GPT has less training data for non-\nEnglish languages, compared to its English training\ndata. We postulate that this results in represen-\ntations for non-English languages that are much\nweaker than those GPT can create for English.\nThis often leads to lower performance on even\ntranslation-equivariant tasks when the task is not\npresented in English.\n6 Discussion and Future Directions\nOur research provides robust support for the notion\nthat LLMs have not achieved the ideal behaviour\nof compound multilingualism. Even if the quality\nand quantity of training data in various languages\nwere held constant, we speculate that compound\nmultilingualism would still not be achieved, due to\nthe inherent limitations of current data collection\nmethods and training techniques.\nDrawing a parallel to human multi-modal learn-\ning offers an intuitive understanding of why this\ncould be the case. Consider how humans acquire\nconcepts related to vision and language: A child\ngrows by consistently pairing visual stimuli with\nlinguistic cues, intertwining the two modalities\nover time. Consequently, it is rare to observe a mis-\nmatch between visual and linguistic perceptions.\nIn this context, humans exhibit a highly integrated\nunderstanding of vision and their native languages.\nHowever, unless raised in a perfectly bilingual envi-\nronment, individuals seldom showcase equivalent\nproficiency in two languages. Indeed, bilingual\nindividuals often demonstrate cognitive variations\ndepending on which language is in use.\nA rudimentary multi-modal system can be\nlikened to a crude fusion of a vision model trained\non image data and a language model trained on\ntext. These systems possess minimal, if any, shared\nrepresentations or information overlap. Beneath\nthe facade of a system that seemingly excels at\nboth visual and language tasks, lie two distinct\nnetworks. Nevertheless, recent advancements in\nmulti-modal studies, combined with the availabil-\nity of extensively captioned image data, have given\nrise to more sophisticated systems. These systems\nbridge the gap between the two modalities, moving\nthe field closer to human-like integration.\nAcquiring aligned multilingual data is a signif-\nicant challenge, with the exception of some trans-\nlation datasets. The majority of online articles and\nposts are monolingual and cannot be easily paired.\nTherefore, training on these multilingual corpora\nresults in models that essentially act as an amal-\ngamation of several independent language-specific\nmodels, with minimal information interchange, pri-\n7922\nmarily anchored by the translation datasets which\ncomprise a relatively small portion of the corpus.\nWhen corpora are disproportionately comprised\nof some language or set of languages, the models\ntend to become predominantly subordinate, with\nminimal coordination arising from monolingual\ndatasets.\nMoving forward, our objective is to narrow the\ndivide between languages within a multilingual sys-\ntem and to cultivate language models that lean more\ntowards a compound archetype. This will require\nboth crafting highly parallel paired data across lan-\nguages and innovating training methodologies that\npromote the learning of compound representations\nfor universal concepts irrespective of the language\nused to express them. For the former, we intend to\ndelve into ontology linkages. For the latter, we plan\nto leverage recent advancements in model training,\nsuch as contrastive learning. Our goal is to cre-\nate multilingual models that are both technically\nsophisticated and universally adept.\n7 Conclusion\nWe have proposed a systematic approach to analyz-\ning multilingual abilities of large language models.\nOur experiments provide new evidence for a sub-\nordinate multilingualism in GPT-3.5, with English\nfunctioning as the model’s native language. Our\nexperimental results, supplemented by the analysis\nof specific examples and case studies, demonstrate\nthat such subordinate multilingualism can limit per-\nformance even in language-independent tasks. We\npostulate that explicit inclusion of additional mul-\ntilingual parallel corpora and multimodal datasets\ninto the training data of LLMs could ameliorate\nthis issue.\nLimitations\nAs the OpenAI ChatGPT website application has a\nlimited number of prompts allowed per day and per\nhour, we can not apply our experiment to the whole\ndataset. We used GPT3.5 rather than GPT4 as our\nLLM since access to GPT4 is still restricted. We\nconducted the human evaluation only in English,\nSpanish, and Chinese, as we did not have access to\nfluent speakers of the other languages found in our\ntest sets.\nIn addition to ChatGPT, we also attempted to ap-\nply a different LLM, Llama2 to the same tasks (Tou-\nvron et al., 2023). The outcomes from Llama2,\nhowever, were unexpected for several reasons.\nFirstly, Llama2 frequently produced responses that\nlacked meaningful content, making answer extrac-\ntion challenging. Secondly, Llama2 often declined\nto provide answers to posed questions (cf. Table 7\nin the Appendix). Thirdly, when posed with ques-\ntions in languages other than English, Llama2 usu-\nally responded in English. Lastly, inherent issues\nin the datasets, such as inconsistent capitalization\nand grammatical errors, further complicated the\nevaluation.\nAcknowledgements\nThis research was supported by the Natural Sci-\nences and Engineering Research Council of Canada\n(NSERC), and the Alberta Machine Intelligence In-\nstitute (Amii).\nReferences\nAntoine Bordes, Sumit Chopra, and Jason Weston. 2014.\nQuestion answering with subgraph embeddings. In\nProceedings of the 2014 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 615–620, Doha, Qatar. Association for Com-\nputational Linguistics.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems ,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian,\nJacob Hilton, Reiichiro Nakano, Christopher Hesse,\nand John Schulman. 2021. Training verifiers to solve\nmath word problems. CoRR.\nMaria Rosaria D’Acierno. 1990. Three types of bilin-\ngualism. ERIC.\nNicola De Cao, Wilker Aziz, and Ivan Titov. 2021. Edit-\ning factual knowledge in language models. In Pro-\nceedings of the 2021 Conference on Empirical Meth-\nods in Natural Language Processing , pages 6491–\n6506, Online and Punta Cana, Dominican Republic.\nAssociation for Computational Linguistics.\nAnnette MB De Groot and Gerard LJ Nas. 1991. Lex-\nical representation of cognates and noncognates in\ncompound bilinguals. Journal of memory and lan-\nguage, 30(1):90–123.\n7923\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186.\nLiana Ermakova, Tristan Miller, Fabio Regattin, Anne-\nGwenn Bosser, Claudine Borg, Élise Mathurin,\nGaëlle Le Corre, Sílvia Araújo, Radia Hannachi,\nJulien Boccou, Albin Digue, Aurianne Damoy, and\nBenoît Jeanjean. 2022. Overview of joker@clef\n2022: Automatic wordplay and humour translation\nworkshop. In Experimental IR Meets Multilinguality,\nMultimodality, and Interaction, pages 447–469.\nBradley Hauer and Grzegorz Kondrak. 2020. One\nhomonym per translation. In Proceedings of the\nAAAI Conference on Artificial Intelligence , vol-\nume 34, pages 7895–7902.\nBenjamin Heinzerling and Kentaro Inui. 2021. Lan-\nguage models as knowledge bases: On entity repre-\nsentations, storage capacity, and paraphrased queries.\nIn Proceedings of the 16th Conference of the Euro-\npean Chapter of the Association for Computational\nLinguistics: Main Volume, pages 1772–1791, Online.\nAssociation for Computational Linguistics.\nCharlotte Hoffmann. 2014. Introduction to bilingualism.\nRoutledge.\nLeon A Jakobovits. 1968. Dimensionality of compound-\ncoordinate bilingualism. Language learning.\nDi Jin, Zhijing Jin, Zhiting Hu, Olga Vechtomova,\nand Rada Mihalcea. 2022. Deep learning for text\nstyle transfer: A survey. Computational Linguistics,\n48(1):155–205.\nDiksha Khurana, Aditya Koli, Kiran Khatter, and\nSukhdev Singh. 2023. Natural language processing:\nstate of the art, current trends and challenges. Multi-\nmedia Tools and Applications, 82(3):3713–3744.\nJia Li, Ge Li, Yongmin Li, and Zhi Jin. 2023. En-\nabling programming thinking in large language\nmodels toward code generation. arXiv preprint\narXiv:2305.06599.\nWolfgang Lörscher. 2012. Bilingualism and translation\ncompetence. SYNAPS - A Journal of Professional\nCommunication.\nPan Lu, Liang Qiu, Wenhao Yu, Sean Welleck, and\nKai-Wei Chang. 2023. A survey of deep learning for\nmathematical reasoning. In Proceedings of the 61st\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 14605–\n14631, Toronto, Canada. Association for Computa-\ntional Linguistics.\nShervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta\nKar, and Oleg Rokhlenko. 2022. MultiCoNER: A\nlarge-scale multilingual dataset for complex named\nentity recognition. In Proceedings of the 29th Inter-\nnational Conference on Computational Linguistics,\npages 3798–3809, Gyeongju, Republic of Korea. In-\nternational Committee on Computational Linguistics.\nLuis R Marcos. 1976. Linguistic dimensions in the bilin-\ngual patient. American Journal of Psychoanalysis,\n36(4):347.\nHamzeh Moradi. 2014. An investigation through dif-\nferent types of bilinguals and bilingualism. Inter-\nnational Journal of Humanities & Social Science\nStudies, 1(2):147–154.\nAni Nenkova and Kathleen McKeown. 2012. A survey\nof text summarization techniques. Mining text data,\npages 43–76.\nJinjie Ni, Tom Young, Vlad Pandelea, Fuzhao Xue, and\nErik Cambria. 2023. Recent advances in deep learn-\ning based dialogue systems: A systematic survey.\nArtificial intelligence review, 56(4):3055–3155.\nChengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao\nChen, Michihiro Yasunaga, and Diyi Yang. 2023. Is\nchatgpt a general-purpose natural language process-\ning task solver? arXiv preprint arXiv:2302.06476.\nMaarten Sap, Vered Shwartz, Antoine Bosselut, Yejin\nChoi, and Dan Roth. 2020. Commonsense reason-\ning for natural language processing. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics: Tutorial Abstracts, pages\n27–33, Online. Association for Computational Lin-\nguistics.\nFreda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang,\nSuraj Srivats, Soroush V osoughi, Hyung Won Chung,\nYi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das,\nand Jason Wei. 2023. Language models are multi-\nlingual chain-of-thought reasoners. In The Eleventh\nInternational Conference on Learning Representa-\ntions.\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and\nJonathan Berant. 2019. CommonsenseQA: A ques-\ntion answering challenge targeting commonsense\nknowledge. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4149–4158, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\nBhosale, Dan Bikel, Lukas Blecher, Cristian Canton\nFerrer, Moya Chen, Guillem Cucurull, David Esiobu,\nJude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\nCynthia Gao, Vedanuj Goswami, Naman Goyal, An-\nthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\n7924\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\nIsabel Kloumann, Artem Korenev, Punit Singh Koura,\nMarie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-\nana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-\ntinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-\nbog, Yixin Nie, Andrew Poulton, Jeremy Reizen-\nstein, Rashi Rungta, Kalyan Saladi, Alan Schelten,\nRuan Silva, Eric Michael Smith, Ranjan Subrama-\nnian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-\nlor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\nZheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\nMelanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez, Robert Stojnic, Sergey Edunov, and Thomas\nScialom. 2023. Llama 2: Open foundation and fine-\ntuned chat models.\nZhen Wang. 2022. Modern question answering\ndatasets and benchmarks: A survey. arXiv preprint\narXiv:2206.15030.\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,\nBarret Zoph, Sebastian Borgeaud, Dani Yogatama,\nMaarten Bosma, Denny Zhou, Donald Metzler, Ed H.\nChi, Tatsunori Hashimoto, Oriol Vinyals, Percy\nLiang, Jeff Dean, and William Fedus. 2022a. Emer-\ngent abilities of large language models. Transactions\non Machine Learning Research . Survey Certifica-\ntion.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le,\nand Denny Zhou. 2022b. Chain of thought prompt-\ning elicits reasoning in large language models. In\nAdvances in Neural Information Processing Systems.\nChenxi Whitehouse, Monojit Choudhury, and Al-\nham Fikri Aji. 2023. Llm-powered data augmen-\ntation for enhanced crosslingual performance. arXiv\npreprint arXiv:2305.14288.\nXinyan Yu, Trina Chatterjee, Akari Asai, Junjie Hu,\nand Eunsol Choi. 2022. Beyond counting datasets:\nA survey of multilingual dataset construction and\nnecessary resources. In Findings of the Association\nfor Computational Linguistics: EMNLP 2022, pages\n3725–3743, Abu Dhabi, United Arab Emirates. As-\nsociation for Computational Linguistics.\nJianing Zhou and Suma Bhat. 2021. Paraphrase genera-\ntion: A survey of the state of the art. In Proceedings\nof the 2021 Conference on Empirical Methods in Nat-\nural Language Processing, pages 5075–5086, Online\nand Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nWill Y Zou, Richard Socher, Daniel Cer, and Christo-\npher D Manning. 2013. Bilingual word embeddings\nfor phrase-based machine translation. In Proceed-\nings of the 2013 conference on empirical methods in\nnatural language processing, pages 1393–1398.\nA Appendix\nThe appendix contains four tables.\nTable 4 contains BERT similarity scores between\nthe explanations generated by ChatGPT in different\nlanguages (Section 5.3).\nTable 5 contains a comparison of cover letters\ngenerated by ChatGPT in English and Chinese,\nrespectively (Section 5.4).\nTable 6 contains examples of the explanations\nof an English pun generated by ChatGPT in En-\nglish, Chinese, French, and Spanish (Section 5.5).\nThe pun in question is “a bicycle can’t stand on\nits own because it is two-tired\", with a word-play\ninvolving the homophonic phrases too tired and\ntwo-tire’d. The pun is lost in translation to other\nlanguages, but this does not prevent CHatPGT from\ncorrectly detecting, locating, and explaining it in\nthose languages.\nTable 7 shows an example of a misguided re-\nsponse from Llama2.\nLang. En Fr De Es Ja\nCommon Sense Reasoning\nFr 0.871 1.000\nDe 0.882 0.857 1.000\nEs 0.886 0.864 0.868 1.000\nJa 0.839 0.822 0.850 0.828 1.000\nZh 0.863 0.852 0.872 0.866 0.848\nMath Reasoning\nFr 0.947 1.000\nDe 0.937 0.933 1.000\nEs 0.948 0.947 0.940 1.000\nJa 0.907 0.905 0.910 0.901 1.000\nZh 0.905 0.912 0.902 0.912 0.902\nKnowledge Access\nFr 0.928 1.000\nDe 0.916 0.926 1.000\nEs 0.925 0.922 0.903 1.000\nJa 0.883 0.888 0.878 0.883 1.000\nZh 0.858 0.868 0.864 0.848 0.864\nTable 4: BERT similarity scores for explanations in TE\ntasks.\n7925\nPrompt(EN): You are Johnson Smith from University of Alberta with A GPA of 3.9. You like sapping. You want to join Huawei company.\nWrite a cover letter about: What is it about this role that makes it a good fit for you?, What’s something outside of your work that\nyou’re passionate about?, and What does your next ideal role look like?\nEnglish: Dear Hiring Manager,\nI am writing to express my keen interest in joining Huawei Technologies Co. Ltd. as a [insert desired position]. As an\naccomplished student pursuing a Bachelor’s degree in Computer Science at the University of Alberta, I am excited about the\nopportunity to contribute to Huawei’s innovative work in the technology sector.\nWhat sets Huawei apart for me is its commitment to pushing the boundaries of technological advancement and delivering high-\nquality products and services to its global customers. This aligns perfectly with my own passion for exploring the cutting-edge\ndevelopments in the tech industry. Through my academic journey, I have consistently strived for excellence, maintaining a GPA\nof 3.9, and actively seeking out opportunities to deepen my knowledge and skills in areas such as software development, network\ninfrastructure, and cloud computing.\nI firmly believe that my technical expertise and problem-solving abilities make me an excellent fit for the role at Huawei. With a\nstrong foundation in computer science principles, coupled with practical experience gained through internships and personal\nprojects, I am confident in my ability to contribute to Huawei’s goals and objectives. I am particularly excited about the potential\nto work on projects related to artificial intelligence, network security, and software engineering, areas where I have demonstrated\nexceptional aptitude and interest.\nBeyond my professional pursuits, I am a firm believer in maintaining a well-rounded lifestyle. One of my greatest passions\noutside of work is sapping. I find immense joy in exploring the beauty of nature, hiking through serene trails, and immersing\nmyself in the calmness of the wilderness. Sapping has taught me the importance of resilience, adaptability, and appreciating the\ninterconnectedness of the natural world. I firmly believe that this passion for sapping enhances my creativity and problem-solving\nabilities, enabling me to approach challenges with a fresh perspective and a sense of adventure.\nLooking forward, my ideal role involves being part of a dynamic and collaborative team that encourages innovation and\ncontinuous learning. I aspire to work in an environment that fosters personal growth, provides opportunities for professional\ndevelopment, and empowers individuals to make a meaningful impact. I am enthusiastic about taking on challenging projects\nthat require creativity, critical thinking, and the ability to work effectively both independently and as part of a team. In my next\nrole, I hope to further develop my technical skills while also honing my leadership abilities, with the ultimate goal of making a\nsignificant contribution to the company’s success.\nThank you for considering my application. I am excited about the prospect of contributing to Huawei’s vision and being part of a\ncompany at the forefront of technological innovation. I have attached my resume for your review, and I look forward to the\nopportunity to discuss my qualifications further.\nYours sincerely,\nJohnson Smith\nPrompt(Zh): 你是来自阿尔伯塔大学的约翰逊·史密斯，GPA为3.9。你喜欢程序开发。你希望加入华为公司。请撰写一封求职信，\n内容包括以下问题：这个职位有什么特点使其适合你？你工作之外的兴趣爱好是什么？你心目中的下一个理想职位\n是怎样的？(in a completely new session)\nChinese: 阁下，\n我谨向华为公司递交我的求职信，表达我加入贵公司的热忱和兴趣。我是约翰逊·史密斯，毕业于匿名大学，拥\n有3.9的GPA。我对程序开发充满热情，并且相信华为公司是我继续发展和实现个人职业目标的理想之地。\n在我了解的情况下，华为公司在全球范围内的领先地位和不断创新的文化吸引了我。我对华为的技术解决方案和产\n品充满敬佩，并希望能够为公司的成功作出贡献。我在匿名大学的学习和项目经验为我提供了坚实的编程基础和解\n决问题的能力，这些技能将使我能够在日常工作中充分利用华为的技术平台和工具。\n除了工作之外，我对多种兴趣爱好保持着活跃的参与。我是一个狂热的户外运动爱好者，喜欢徒步旅行、露营和攀\n岩。这些活动锻炼了我的团队合作和领导能力，并培养了我在压力下保持冷静和解决问题的能力。此外，我也热衷\n于参与志愿者活动，尤其是与青少年教育和技术培训相关的项目。这些经历不仅增强了我的沟通和人际关系技巧，\n还培养了我对社会责任的意识。\n在我心目中，下一个理想职位是成为一名技术领导者。我希望在技术领域中不断成长和学习，领导并激励团队实现\n共同目标。我相信通过不断挑战自己，我能够发挥我的领导潜力并在组织中产生积极的影响。\n我期待着有机会加入华为公司，并为实现公司的愿景和目标而努力工作。感谢您抽出宝贵的时间考虑我的申请。我\n期待着与您进一步讨论我对这个职位的适合性。\n谢谢您的关注。\n真诚地，\n约翰逊·史密斯\nPrompt(En): Translate this into English.\nEnglish: Dear Sir/Madam,\nI am writing to express my keen interest in joining Huawei Company and hereby submit my application. My name is Johnson\nSmith, and I am a graduate from the University of Alberta with a GPA of 3.9. I have a strong passion for software development\nand I believe that Huawei Company is the ideal place for me to continue my professional growth and pursue my career goals.\nFrom what I have gathered, Huawei Company’s leading position worldwide and its culture of continuous innovation have\ncaptivated me. I hold great admiration for Huawei’s technological solutions and products, and I aspire to contribute to the\ncompany’s success. My education and project experiences at the University of Alberta have provided me with a solid foundation\nin programming and problem-solving skills, which will enable me to fully leverage Huawei’s technical platforms and tools in my\nday-to-day work.\nOutside of work, I actively engage in various hobbies and interests. I am an avid outdoor enthusiast, enjoying activities such\nas hiking, camping, and rock climbing. These pursuits have honed my teamwork and leadership abilities, as well as fostered\nmy capacity to remain calm and solve problems under pressure. Additionally, I am passionate about participating in volunteer\nactivities, particularly those related to youth education and technical training. These experiences have not only enhanced my\ncommunication and interpersonal skills but also instilled in me a sense of social responsibility.\nIn my vision, my next ideal position is to become a technical leader. I aspire to continuously grow and learn in the field of\ntechnology, leading and motivating teams to achieve common objectives. I believe that by continuously challenging myself, I\ncan unleash my leadership potential and make a positive impact within the organization.\nI am eagerly looking forward to the opportunity to join Huawei Company and contribute to the realization of its vision and goals.\nThank you for taking the time to consider my application. I would be grateful for the chance to further discuss my suitability for\nthis position.\nThank you for your attention.\nSincerely,\nJohnson Smith\nTable 5: Cover letters generated by ChatGPT with the same prompt in English and Chinese.\n7926\nPrompt(En):A bicycle can’t stand on its own because it is two-tired. is there a pun in this sentence?\nEnglish: Yes, there is a pun in this sentence. The phrase \"two-tired\" sounds like \"too tired,\" which suggests that the bicycle is tired and\nneeds to rest. However, the actual meaning of \"two-tired\" in this context is that the bicycle has two tires and therefore cannot\nstand on its own without support. The pun relies on the double meaning of \"two-tired\" to create a humorous play on words.\nPrompt(Zh):这句话有双关么？：自行车不能独自站立，因为它有两个轮胎(in a completely new session)\nChinese: 是的，这句话有双关含义。在字面上，句子表达了一个事实：自行车不能独自站立，因为它有两个轮胎。然而，这\n句话也可以被解释为一个玩笑或谐音。\"两个轮胎\"（two tires）在英语中发音类似于\"too tired\"（太累），所以这个双\n关语可能暗示自行车有两个轮胎，所以它太累了（太累了）不能站立。\nPrompt: Translate this into English.\nEnglish: Yes, this sentence has a pun. Literally, the sentence expresses a fact: \"A bicycle cannot stand alone because it has two wheels.\"\nHowever, the sentence can also be interpreted as a joke or wordplay. \"Two tires\" sounds similar to \"too tired\" in English, so this\npun may suggest that the bicycle has two tires, so it is too tired to stand.\nPrompt(Fr): Y a-t-il un jeu de mots dans cette phrase? \"Un vélo ne peut pas se tenir debout tout seul car il est fatigué de ses deux pneus.\" (in\na completely new session)\nFrench: Oui, il y a un jeu de mots dans cette phrase. Le jeu de mots repose sur une ambiguïté entre le fait d’être fatigué au sens propre,\nc’est-à-dire épuisé physiquement, et le fait d’être fatigué au sens figuré, c’est-à-dire de ressentir la fatigue en raison de l’utilisation\nde ses pneus. Le jeu de mots joue sur le double sens du mot \"fatigué\" pour créer une situation comique où le vélo est censé être\népuisé de supporter son propre poids sur ses deux pneus.\nPrompt: Translate this into English.\nEnglish: Yes, there is a play on words in this sentence. The pun relies on an ambiguity between being \"fatigué\" (tired) in the literal sense,\nmeaning physically exhausted, and being \"fatigué\" (tired) in the figurative sense, meaning feeling tired due to the use of its tires.\nThe wordplay plays on the double meaning of the word \"fatigué\" to create a humorous situation where the bicycle is supposed to\nbe worn out from supporting its own weight on its two tires.\nPrompt(Es): ¿Hay un juego de palabras en esta oración: Una bicicleta no puede mantenerse en pie por sí misma porque tiene dos cansadas?\"\"\n(in a completely new session)\nSpanish: Sí, hay un juego de palabras en esa oración. La palabra \"cansadas\" se utiliza como un juego de palabras para jugar con la idea de\nque una bicicleta tiene \"dos ruedas cansadas\" en lugar de \"dos ruedas de bicicleta\". Es un juego de palabras humorístico que\njuega con el doble sentido de la palabra \"cansadas\", que puede referirse tanto al estado físico de las ruedas de la bicicleta como al\nsentimiento de fatiga o agotamiento.\nPrompt: Translate this into English.\nEnglish: Yes, there is a play on words in that sentence. The word \"cansadas\" is used as a pun to play with the idea that a bicycle has \"two\ntired wheels\" instead of \"two bicycle wheels.\" It is a humorous play on words that plays with the double meaning of the word\n\"cansadas,\" which can refer both to the physical state of the bicycle wheels and to the feeling of fatigue or exhaustion.\nTable 6: ChatGPT explanations of a single English pun in different languages.\nPrompt (En):who is steven seagal sister?\nA. Brenda Seagal\nB. Johnny Depp\nC. Caleb Lane\nD. Jason Statham\nE. Drew Fuller\nResponse: I apologize, but I cannot provide an answer to that question as it contains inaccurate information. Steven\nSeagal does not have a sister named Brenda Seagal, Johnny Depp, Caleb Lane, Jason Statham, or Drew\nFuller. It’s important to rely on credible sources when asking questions to ensure accuracy and avoid\nspreading misinformation. Is there anything else I can assist you with?\nPrompt (Zh):谁是史蒂文-西格尔的妹妹？\nA.布伦达-西格尔\nB.约翰尼-德普\nC.凯莱布-莱恩\nD.杰森-斯坦森\nE.德鲁-富勒\nResponse: I cannot provide an answer to this question as it contains harmful and inappropriate content. The question\nimplies that Stephen Hawking’s sister is a person with a certain name, which is not appropriate or\nrespectful to assume. Additionally, the options provided contain names that do not correspond to real\npeople. It is important to be mindful of the language we use and avoid perpetuating harmful stereotypes\nor misinformation. Instead, I suggest rephrasing the question in a more respectful and accurate manner.\nTable 7: A sample response from Llama2 to a knowledge access question.\n7927",
  "topic": "Variety (cybernetics)",
  "concepts": [
    {
      "name": "Variety (cybernetics)",
      "score": 0.5039011836051941
    },
    {
      "name": "Computer science",
      "score": 0.494730681180954
    },
    {
      "name": "Natural language processing",
      "score": 0.38498711585998535
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3575361967086792
    },
    {
      "name": "Linguistics",
      "score": 0.34810584783554077
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I154425047",
      "name": "University of Alberta",
      "country": "CA"
    }
  ],
  "cited_by": 44
}