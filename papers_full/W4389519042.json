{
  "title": "Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark",
  "url": "https://openalex.org/W4389519042",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2340114479",
      "name": "Minje Choi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2883556698",
      "name": "Jiaxin Pei",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2129553012",
      "name": "Sagar Kumar",
      "affiliations": [
        "University of Cambridge",
        "Northeastern University"
      ]
    },
    {
      "id": "https://openalex.org/A1965045615",
      "name": "Chang Shu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2107950509",
      "name": "David Jurgens",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1966797434",
    "https://openalex.org/W3007949236",
    "https://openalex.org/W1972095489",
    "https://openalex.org/W3205068155",
    "https://openalex.org/W2092143641",
    "https://openalex.org/W2118204981",
    "https://openalex.org/W73399849",
    "https://openalex.org/W2159035740",
    "https://openalex.org/W4285247752",
    "https://openalex.org/W3164271081",
    "https://openalex.org/W4250971714",
    "https://openalex.org/W1638659076",
    "https://openalex.org/W4393814752",
    "https://openalex.org/W2050752640",
    "https://openalex.org/W2766848870",
    "https://openalex.org/W2033111500",
    "https://openalex.org/W1968003444",
    "https://openalex.org/W2922342626",
    "https://openalex.org/W2166224004",
    "https://openalex.org/W4285215550",
    "https://openalex.org/W2607623312",
    "https://openalex.org/W2889287254",
    "https://openalex.org/W2922580172",
    "https://openalex.org/W2962977603",
    "https://openalex.org/W4306676570",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W3124687886",
    "https://openalex.org/W2949678053",
    "https://openalex.org/W3211686893",
    "https://openalex.org/W2235048552",
    "https://openalex.org/W2970062726",
    "https://openalex.org/W2805744755",
    "https://openalex.org/W2115340919",
    "https://openalex.org/W4313490656",
    "https://openalex.org/W3034937117",
    "https://openalex.org/W4319449793",
    "https://openalex.org/W2037072756",
    "https://openalex.org/W3116985850",
    "https://openalex.org/W2741036097",
    "https://openalex.org/W3113763975",
    "https://openalex.org/W3168867926",
    "https://openalex.org/W4285181846",
    "https://openalex.org/W2954226438",
    "https://openalex.org/W3101637242",
    "https://openalex.org/W2953005365",
    "https://openalex.org/W4385571425",
    "https://openalex.org/W3147509388",
    "https://openalex.org/W3191684189",
    "https://openalex.org/W1924770834",
    "https://openalex.org/W3104982372",
    "https://openalex.org/W4287252377",
    "https://openalex.org/W2264742718",
    "https://openalex.org/W3088887450",
    "https://openalex.org/W3008374555",
    "https://openalex.org/W4200086631",
    "https://openalex.org/W3083091152",
    "https://openalex.org/W4287889344",
    "https://openalex.org/W4221095290",
    "https://openalex.org/W4230965853",
    "https://openalex.org/W2742144412",
    "https://openalex.org/W4229005866",
    "https://openalex.org/W2010308673",
    "https://openalex.org/W4226040778",
    "https://openalex.org/W3184890107",
    "https://openalex.org/W2251939518",
    "https://openalex.org/W2761590056",
    "https://openalex.org/W2096086610",
    "https://openalex.org/W3034545571",
    "https://openalex.org/W3183822815",
    "https://openalex.org/W3155500649",
    "https://openalex.org/W3096780468",
    "https://openalex.org/W2963790016",
    "https://openalex.org/W3034951181",
    "https://openalex.org/W3206308953",
    "https://openalex.org/W3211777799",
    "https://openalex.org/W3182280404",
    "https://openalex.org/W1546508205",
    "https://openalex.org/W2964235839",
    "https://openalex.org/W2943552823",
    "https://openalex.org/W2086604918",
    "https://openalex.org/W2964321064",
    "https://openalex.org/W2082282699",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2055892307",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W3201622928",
    "https://openalex.org/W3033129824",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W3205558353",
    "https://openalex.org/W2026618580",
    "https://openalex.org/W2182096631",
    "https://openalex.org/W2970948593",
    "https://openalex.org/W3213250243",
    "https://openalex.org/W3098899291",
    "https://openalex.org/W4287890491",
    "https://openalex.org/W2919820482",
    "https://openalex.org/W4386576685",
    "https://openalex.org/W4385571325",
    "https://openalex.org/W2950385115",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W4239287933",
    "https://openalex.org/W2095248730",
    "https://openalex.org/W2030154159",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W4385571124",
    "https://openalex.org/W2991223644",
    "https://openalex.org/W2014313181",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3098467404",
    "https://openalex.org/W2091034860",
    "https://openalex.org/W3168194750",
    "https://openalex.org/W2916132663",
    "https://openalex.org/W3168261013",
    "https://openalex.org/W3117748961",
    "https://openalex.org/W2595653137",
    "https://openalex.org/W3034834768",
    "https://openalex.org/W4293355737",
    "https://openalex.org/W4285484119",
    "https://openalex.org/W4317463334",
    "https://openalex.org/W4287854809",
    "https://openalex.org/W3173777717",
    "https://openalex.org/W2806198715",
    "https://openalex.org/W2912924812",
    "https://openalex.org/W3211934872",
    "https://openalex.org/W3029296394",
    "https://openalex.org/W2807333695",
    "https://openalex.org/W4205991051",
    "https://openalex.org/W3090813284",
    "https://openalex.org/W3204432444",
    "https://openalex.org/W2954479967",
    "https://openalex.org/W2963052389",
    "https://openalex.org/W3186727973",
    "https://openalex.org/W2109553965",
    "https://openalex.org/W3172917028",
    "https://openalex.org/W1637437975",
    "https://openalex.org/W4287854822",
    "https://openalex.org/W2128662472",
    "https://openalex.org/W3021157794",
    "https://openalex.org/W3173556213",
    "https://openalex.org/W4205923520",
    "https://openalex.org/W4287888944",
    "https://openalex.org/W4385570173",
    "https://openalex.org/W3174783113",
    "https://openalex.org/W2164023483"
  ],
  "abstract": "Large language models (LLMs) have been shown to perform well at a variety of syntactic, discourse, and reasoning tasks. While LLMs are increasingly deployed in many forms including conversational agents that interact with humans, we lack a grounded benchmark to measure how well LLMs understand social language. Here, we introduce a new theory-driven benchmark, SocKET, that contains 58 NLP tasks testing social knowledge which we group into five categories: humor & sarcasm, offensiveness, sentiment & emotion, and trustworthiness. In tests on the benchmark, we demonstrate that current models attain only moderate performance but reveal significant potential for task transfer among different types and categories of tasks, which were predicted from theory. Through zero-shot evaluations, we show that pretrained models already possess some innate but limited capabilities of social language understanding and training on one category of tasks can improve zero-shot testing on others. Our benchmark provides a systematic way to analyze model performance on an important dimension of language and points to clear room for improvement to build more socially-aware LLMs. The resources are released at https://github.com/minjechoi/SOCKET.",
  "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 11370–11403\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nDo LLMs Understand Social Knowledge? Evaluating the Sociability of\nLarge Language Models with the SOCKET Benchmark\nMinje Choi†∗ Jiaxin Pei†∗ Sagar Kumar ‡ Chang Shu♯ David Jurgens†\n†University of Michigan, Ann Arbor, MI, USA\n‡Northeastern University, Boston, MA, USA\n♯ University of Cambridge, Cambridge, UK\n♣{minje, pedropei, jurgens}@umich.edu\n†kumar.sag@northeastern.edu ‡cs2175@cam.ac.uk\nAbstract\nLarge language models (LLMs) have been\nshown to perform well at a variety of syntactic,\ndiscourse, and reasoning tasks. While LLMs\nare increasingly deployed in many forms in-\ncluding conversational agents that interact with\nhumans, we lack a grounded benchmark to\nmeasure how well LLMs understand social\nlanguage. Here, we introduce a new theory-\ndriven benchmark, SOCKET , that contains 58\nNLP tasks testing social knowledge which we\ngroup into five categories: humor & sarcasm,\noffensiveness, sentiment & emotion, trustwor-\nthiness, and other social factors. In tests on the\nbenchmark, we demonstrate that current mod-\nels attain only moderate performance but reveal\nsignificant potential for task transfer among\ndifferent types and categories of tasks, which\nwere predicted from theory. Through zero-shot\nevaluations, we show that pretrained models\nalready possess some innate but limited capa-\nbilities of social language understanding and\ntraining on one category of tasks can improve\nzero-shot testing on others. Our benchmark\nprovides a systematic way to analyze model\nperformance on an important dimension of lan-\nguage and points to clear room for improve-\nment to build more socially-aware LLMs. The\nresources are released at https://github.\ncom/minjechoi/SOCKET.\n1 Introduction\nInterpersonal communication is more than just\nwhat is said. Understanding communication re-\nquires reasoning not only about the content of a\nmessage but also the social implications drawn\nfrom that message (Halliday, 1995). As NLP sys-\ntems, particularly Large Language Models (LLMs),\nare increasingly used in interpersonal settings,\nthese models’ abilities to understand social knowl-\nedge become critical. However, despite the recog-\nnized need for social knowledge (Hovy and Yang,\n∗equal contribution\n2021), the NLP field has limited abilities to test it.\nHere, we introduce SOCKET , a new benchmark\nfor evaluating social knowledge.\nEvaluating NLP systems has remained a key\ncomponent for benchmarking the field’s progress.\nIndeed, the rapid replacement of traditional mod-\nels by LLM-based approaches was strongly moti-\nvated by substantial gains by LLMs on a variety of\ncomprehensive Natural Language Understanding\n(NLU) benchmarks like SuperGLUE (Wang et al.,\n2019) and Natural Questions (Kwiatkowski et al.,\n2019). However, despite the fundamental social\naspect of language, comprehensive benchmarks of\nsocial language remain absent. Instead, existing\ncomputational studies of social language have built\nindividual datasets and models for specific types\nof information like empathy (Sharma et al., 2020),\npoliteness (Danescu-Niculescu-Mizil et al., 2013),\nand humor (Van Hee et al., 2018). While benefi-\ncial, these semantic-level tasks omit broader social\nand narrative-level information (Li et al., 2021) and\npresent only a narrow view of model performance.\nWe introduce SOCKET (Social Knowledge\nEvaluation Tests), a theory-grounded, systematic\ncollection of 58 social language tasks.1 SOCKET\ncovers five categories of social information: sen-\ntiment & emotion, trustworthiness, humor & sar-\ncasm, offensiveness, and social factors, each mo-\ntivated by specific theories. To examine models’\ngeneralizability, SOCKET includes four task for-\nmats: classification, regression, pairwise compari-\nson, and span identification. This construction aims\nat assessing not only NLP models’ performances\non individual tasks but their ability to perform mul-\ntiple task types and to productively benefit from\nrelated tasks and task categories during learning.\nOur study offers the following three contribu-\n1The choice of the term “social knowledge” in framing\nstems from its use for a broad category in psychology (e.g.,\nTuriel, 1983; Adolphs, 2009) that matched the capabilities we\nare interested in.\n11370\ntions to the research community. (1) We moti-\nvate a theoretically-grounded organization of so-\ncial tasks (§2) and subsequently introduce a new\neasy-to-use benchmark, SOCKET , that system-\natically organizes 58 tasks (§3). (2) We bench-\nmark multiple current LLM approaches to mul-\ntitask NLU via standard supervised training and\nzero-shot LLMs (§4). Across all tests, our results\nshow that baseline LLMs perform moderately, at\nbest, but offer promising signs of being able to\nleverage task correlations. (3) We test the abili-\nties of models to make use of cross-task transfer\n(§5) showing multi-task training on strongly cor-\nrelated tasks can maintain or even improve perfor-\nmance in specific tasks, but doing so on weakly\ncorrelated tasks can hurt the overall performance\nof LLMs (§6). We release our framework code and\nprepackaged datasets at https://github.com/\nminjechoi/SOCKET and https://huggingface.\nco/datasets/Blablablab/SOCKET.\n2 Social Information in Natural\nLanguage Processing\nLanguage is inherently social, as meaning is con-\nstructed through social interactions (Wittgenstein,\n1953). A substantial body of research in linguis-\ntic theory and communication studies have ex-\namined how social knowledge is communicated\nvia language understanding. Theories of lan-\nguage grounded in interaction and communication\nsystems such as Systemic Functional Linguistics\n(SFL) by Halliday et al. (1989) assert that the func-\ntion and appropriacy of language in a given context\nis the key to our understanding of language and\nits use (Eggins, 2004; Allan, 2007; Halliday et al.,\n1989; Halliday, 2004). We use these insights to\nprobe linguistic models for their ability to capture\nsocial information, which we define as information\nconveyed through text about broader metatextual\nfunction and contextual appropriacy of the utter-\nances in conversation.\nNLP Studies on Social Information Numerous\nstudies have contributed to the development of\ndatasets and models aimed toward identifying nu-\nanced social information in language across diverse\ncontexts. Computational linguists have modeled\nmultiple forms of social information in language\nlike sentiment (Buechel and Hahn, 2017), polite-\nness (Fu et al., 2020), humor (Meaney et al., 2021),\noffensiveness (ElSherief et al., 2021), and intimacy\n(Pei and Jurgens, 2020), often achieving state-of-\nthe-art results close to human performance in their\nrespective settings. Studies such as Park et al.\n(2021) have also leveraged explicitly-given norms\nto train models to be more accurate in context-\nspecific situations.\nHowever, these plausible results may be achiev-\nable solely by focusing on the statistical and syn-\ntactical instead of the social aspects of language.\nWhether to make advances in language understand-\ning in research or to ensure reliability and safety\nin deployment, it is of vital importance to study\nwhether models are truly capable of gaining a gen-\neralizable understanding of social factors before\nemploying them for tasks that require such knowl-\nedge (Hovy and Yang, 2021). The necessity for\nsuch understanding is exemplified by studies show-\ning that, when measuring the same concept, the\nperformance of a model can vary greatly when\ntested on a different dataset due to factors such\nas changes in dialect, speaker demographics, and\ndataset domain (Miller et al., 2020; Blodgett et al.,\n2016; Wang et al., 2022a).\nDespite this importance, efforts towards ag-\ngregating and synthesizing various datasets into\nthemes have been less practiced. One notable ex-\nception is the work of Kang and Hovy (2021),\nwhere the authors combine existing datasets on\ndifferent linguistic styles to introduce a benchmark\nthat enables them to study cross-style language un-\nderstanding. Similarly, we present a benchmark\ncurated from over fifty different tasks on different\naspects of social information, which we group into\nfive distinctive categories.\nExamining the social knowledge of LLMs LLMs\nare ubiquitous in NLP and their success is at-\ntributed to the ability to capture language charac-\nteristics from the immense amount of text seen\nin pre-training and to effectively apply this in-\nformation on downstream tasks, achieving state-\nof-the-art performances in many language under-\nstanding tasks (Chung et al., 2022a). LLMs have\ndemonstrated less success when solving tasks di-\nrectly related to social knowledge. For tasks\nthat require social information such as detecting\nsarcasm (Farha et al., 2022) or patronizing lan-\nguage (Perez-Almendros et al., 2022), recent mod-\nels exhibit only moderate performance. One major\nchallenge is that compared to humans, LLMs have\nless capability to make predictions outside of the\nprovided input and must perform reasoning only\nbased on their innate social information (Sap et al.,\n11371\n2019b; Zhou et al., 2020). Yet, it is this very social\nknowledge that is crucial for human interactions\nand conversations and is a milestone that should be\nreached for LLMs to engage in meaningful commu-\nnications with humans (Mahowald et al., 2023).\nMore recently, general-purpose LLMs trained\nwith instruction-based prompts have been known\nto achieve strong performances, putting them to use\nin several practical domains such as summarization,\nquestion answering, and classification (Sanh et al.,\n2022). A newly emerging trend is to use curated\nprompts to identify the psychological capabilities\nof instruction-guided LLMs. Ruis et al. (2022)\nand Hu et al. (2022a) examine pragmatic under-\nstanding capabilities using prompts. Coupled with\nadditional steps such as chain-of-thought (CoT)\nreasoning, this prompt-based approach has large\npotential for understanding whether LLMs can pro-\nvide reasoning capabilities like humans.\nThe Inter-relatedness of Social Information So-\ncial language understanding requires accurately\nperceiving different dimensions and facets of com-\nmunication that relate to one another. Interper-\nsonal communication makes frequent use of humor\n(Schnurr, 2010), mitigation, also known as hedg-\ning, (Schneider, 2010), and swearing as a norm\nviolation (Stapleton, 2003) in defining the con-\ntours of the social context for the speakers. Of-\nten, the pragmatics of these different dimensions\nof social language use are intertwined: commu-\nnication with one dimension influences the inter-\npretation of another, e.g., politeness and offensive\nspeech (Culpeper, 2021), humor and politeness (At-\ntardo, 2008), humor and offensiveness (Alberts,\n1992), and mitigation and empathy (LI Hai-hui,\n2019). Understanding one of these dimensions\nrequires models to have the ability to recognize\nthe related dimensions. While past computational\nwork has largely focused on single dimensions,\nSOCKET fills a key gap by testing whether models\ncan accurately recognize multiple, interrelated so-\ncial dimensions—and whether models can benefit\nin their understanding from cross-task transfer.\n3 The S OCKET Benchmark\nHere, we describe the steps taken to curate\nSOCKET as robust benchmark for identifying so-\ncial information embedded in language in interper-\nsonal communication contexts.\n3.1 Task Selection Process\nThe task curation process began with a system-\natic review of literature on social from linguistics,\ncommunications, and psychology to identify likely\ncategories of social knowledge. Then, possible\ndatasets and tasks were identified through a system-\natic review of datasets published at ACL, EMNLP,\nNAACL, EACL, LREC, and SemEval since 2015.\nIn this first pass, we selected more than 100 datasets\nand tasks to detect different types of social infor-\nmation in language (cf. Table 11 in Appendix B.9\nfor all candidate datasets and tasks). Tasks were\nselected based on membership in five categories of\nsocial language (described next) that are motivated\nas core aspects of social language understanding.\nFor each category, we include tasks of sev-\neral distinct objectives: binary and multi-class\nclassification, regression, pairwise similarity de-\ntection, and span identification. 2 Where possi-\nble, we aim for diversity within categories and\nensure one task for each objective. Candidate\ntasks were removed if it was found that train-\ning a bert-base-uncased model on the task\nachieved test performance over 0.95, which would\nprovide little insight into progress at recognizing\nsocial information .\nWhile this process identified many candidate\ntasks in multiple categories, the benchmark still\ndefines only partial progress in social knowledge\ncapabilities. Some abilities recognized by social\nsciences such as deceit have only one or two tasks\nproposed (Ott et al., 2011), providing limited data\nto measure progress. However, recognizing these\nas limitations (discussed in more detail in §8),\nSOCKET provides a diverse set of tasks and ca-\npabilities, described next, for the field to begin to\nmeasure progress.\n3.2 Task categories\nInspired by theories in interpersonal communica-\ntion and interpersonal pragmatics, we provide a\nthematic organization of the tasks in SOCKET into\nfive related categories of social knowledge: Humor\n& Sarcasm, Offensiveness, Sentiment & Emotion,\nSocial Factors, and Trustworthiness.\nHumor & Sarcasm The practice of humor in\nconversations and interactions plays a key role\n2Other task types were initially considered (e.g., genera-\ntion, paraphrasing) but such tasks were not feasible for all\nmodels and often were less standardized in their evaluation,\ncomplicating cross-task comparison if included.\n11372\ncategory dataset task name size type labels category dataset task name size type labels\nHumor & Sarcasm hahackathon (Meaney et al., 2021) humor_rating 6,179 REG RMSESentiment & Emotion crowdflower (CrowdFlower, 2016) crowdflower 40,000 CLS 13 (F1)Humor & Sarcasm humor-pairs (Hossain et al., 2020) humor-pairs 15,095 PAIR 2 (F1)Sentiment & Emotion dailydialog (Li et al., 2017) dailydialog 102,979 CLS 7 (F1)Humor & Sarcasm sarc (Khodak et al., 2018) sarc 321,748 CLS 2 (F1)Sentiment & Emotion emobank (Buechel and Hahn, 2017) arousal 10,062 REG MAEHumor & Sarcasm tweet_irony (Van Hee et al., 2018) tweet_irony 4,601 CLS 2 (F1)Sentiment & Emotion emobank (Buechel and Hahn, 2017) dominance 10,062 REG MAEHumor & Sarcasm hahackathon (Meaney et al., 2021) is_humor 10,000 CLS 2 (F1)Sentiment & Emotion emobank (Buechel and Hahn, 2017) valence 10,062 REG MAEOffensiveness contextual-abuse (Vidgen et al., 2021) IdentityDirectedAbuse 13,450 CLS 2 (F1)Sentiment & Emotion emotion-span (Ghazi et al., 2015) emotion-span 820 SPAN 3 (F1)Offensiveness contextual-abuse (Vidgen et al., 2021) PersonDirectedAbuse 13,450 CLS 2 (F1)Sentiment & Emotion empathy (Buechel et al., 2018) distress 1,859 REG Corr.Offensiveness hahackathon (Meaney et al., 2021) offense_rating 10,000 REG RMSESentiment & Emotion empathy (Buechel et al., 2018) distress_bin 1,859 CLS 2 (F1)Offensiveness hasbiasedimplication (Sap et al., 2020) hasbiasedimplication 44,781 CLS 2 (F1)Sentiment & Emotion same-side-pairs (Körner et al., 2021) same-side-pairs 175 PAIR 2 (F1)Offensiveness hateoffensive (Davidson et al., 2017) hateoffensive 24,783 CLS 3 (F1-M)Sentiment & Emotion sentitreebank (Socher et al., 2013) sentitreebank 119,794 CLS 2 (Acc.)Offensiveness implicit-hate (ElSherief et al., 2021) explicit_hate 21,476 CLS 2 (F1)Sentiment & Emotion tweet_emoji (Barbieri et al., 2018) tweet_emoji 100,000 CLS 20 (F1-M)Offensiveness implicit-hate (ElSherief et al., 2021) implicit_hate 21,476 CLS 2 (F1)Sentiment & Emotion tweet_emotion (Mohammad et al., 2018) tweet_emotion 5,052 CLS 4 (F1-M)Offensiveness implicit-hate (ElSherief et al., 2021) incitement_hate 21,476 CLS 2 (F1)Sentiment & Emotion tweet_sentiment (Rosenthal et al., 2017) tweet_sentiment 59,899 CLS 3 (AvgRec)Offensiveness implicit-hate (ElSherief et al., 2021) inferiority_hate 21,476 CLS 2 (F1)Social Factors complaints (Preo¸ tiuc-Pietro et al., 2019) complaints 3,449 CLS 2 (F1)Offensiveness implicit-hate (ElSherief et al., 2021) stereotypical_hate 21,476 CLS 2 (F1)Social Factors empathy (Buechel et al., 2018) empathy 1,859 REG Corr.Offensiveness implicit-hate (ElSherief et al., 2021) threatening_hate 21,476 CLS 2 (F1)Social Factors empathy (Buechel et al., 2018) empathy_bin 1,859 CLS 2 (F1)Offensiveness implicit-hate (ElSherief et al., 2021) white_grievance_hate 21,476 CLS 2 (F1)Social Factors hayati_politeness (Hayati et al., 2021) hayati_politeness 320 CLS 2 (F1)Offensiveness intentyn (Sap et al., 2020) intentyn 44,781 CLS 2 (F1)Social Factors questionintimacy (Pei and Jurgens, 2020) questionintimacy 2,247 REG 6 (Corr.)Offensiveness jigsaw (Jigsaw, 2017) severe_toxic 200,703 CLS 2 (F1)Social Factors stanfordpoliteness (Fu et al., 2020) stanfordpoliteness 10,956 CLS 2 (MAE)Offensiveness jigsaw (Jigsaw, 2017) identity_hate 200,703 CLS 2 (F1)Trustworthiness bragging (Jin et al., 2022) brag_achievement 6,643 CLS 2 (F1)Offensiveness jigsaw (Jigsaw, 2017) threat 200,703 CLS 2 (F1)Trustworthiness bragging (Jin et al., 2022) brag_action 6,643 CLS 2 (F1-M)Offensiveness jigsaw (Jigsaw, 2017) obscene 200,703 CLS 2 (F1)Trustworthiness bragging (Jin et al., 2022) brag_possession 6,643 CLS 2 (F1-M)Offensiveness jigsaw (Jigsaw, 2017) insult 200,703 CLS 2 (F1)Trustworthiness bragging (Jin et al., 2022) brag_trait 6,643 CLS 2 (F1-M)Offensiveness jigsaw (Jigsaw, 2017) toxic 200,703 CLS 2 (F1)Trustworthiness hypo-l (Zhang and Wan, 2022) hypo-l 3,226 CLS 2 (Acc.)Offensiveness offensiveyn (Sap et al., 2020) offensiveyn 44,781 CLS 2 (F1)Trustworthiness neutralizing-bias-pairs (Pryzant et al., 2020) neutralizing-bias-pairs 93,790 PAIR 2 (Acc.)Offensiveness sexyn (Sap et al., 2020) sexyn 44,781 CLS 2 (F1)Trustworthiness propaganda-span (Martino et al., 2020) propaganda-span 357 SPAN 3 (F1-m)Offensiveness talkdown-pairs (Wang and Potts, 2019) talkdown-pairs 6,510 PAIR 2 (F1)Trustworthiness rumor (Ma et al., 2017) rumor_bool 1,417 CLS 2 (F1)Offensiveness toxic-span (Pavlopoulos et al., 2021) toxic-span 10,621 SPAN 3 (F1)Trustworthiness two-to-lie (Peskov et al., 2020) receiver_truth 11,728 CLS 2 (F1-M)Offensiveness tweet_offensive (Zampieri et al., 2019b) tweet_offensive 14,100 CLS 2 (F1)Trustworthiness two-to-lie (Peskov et al., 2020) sender_truth 11,728 CLS 2 (F1-M)\nTable 1: A list of the datasets covered in the SOCKET benchmark. A total of 58 tasks in 5 categories of social information.\nIncluded are each task’s sample size, task type and evaluation metric used in the original paper. SOCKET covers four types of\ntasks: classification (CLS), regression (REG), pair-wise comparison (PAIR), and span identification (SPAN). F1, F1-M and F1-m\nindicate binary F1, macro F1 and micro F1 scores.\nin maintaining and forming positive social rela-\ntions (Holmes, 2006; Brown et al., 1987; Ziv, 2010).\nWe differ Humor & Sarcasm from Trustworthi-\nness as a social information category because while\nboth categories consider non-cooperative behaviors\n(Grice, 1975), humor is considered to be prosocial\n(Attardo, 2008). In instances where the humor is\nnot considered to be prosocial and is instead of\na derogatory nature, we consider it to be in the\nOffensiveness category. By nature, humor is a sub-\njective concept that can differ depending on both\ndemographic and contextual factors (Ruch, 2010),\nmaking humor detection a difficult task for LLMs.\nSOCKET includes a number of tasks on humor\nthat can occur in various contexts such as in social\nmedia (Meaney et al., 2021), short jokes (Meaney\net al., 2021), and news headlines (Hossain et al.,\n2020). We also include tasks that require detecting\nrelevant concepts of humor such as sarcasm (Kho-\ndak et al., 2018) and irony (Van Hee et al., 2018).\nOffensiveness Detecting offensiveness using com-\nputational methods has gained large attraction in\nrecent years due to the ubiquity of online com-\nmunication and the necessity to implement auto-\nmated content moderation to combat abusive be-\nhaviors (Spertus, 1997). However, most existing\nstudies only focus on limited types of offensive\nlanguages (Jurgens et al., 2019). In this study, we\nconsider offensiveness to be any explicit or implicit\nlanguage directed towards individuals, entities, or\ngroups (Waseem et al., 2017), and the tasks chosen\nare representative of this understanding. SOCKET\nincludes a list of offensiveness detection tasks cov-\nering different levels of harmful content and abu-\nsive language including both explicit and implicit\nhate (ElSherief et al., 2021), abuse (Vidgen et al.,\n2021), and humor-related offensiveness (Meaney\net al., 2021). We also include forms of bias directed\ntowards people and groups, as social bias enforces\nharmful stereotypes (Sap et al., 2020).\nSentiment & Emotion Emotion is a core element\nof interpersonal communication that can be com-\nmunicated through human language in several as-\npects (Majid, 2012; Barrett et al., 2007). Social\ninformation is crucial in the ability to not only\ncommunicate, but also feel emotion. Theories\nof discretized emotion (Ekman, 1992) have been\nsupported by empirical findings that humans use\ndiscrete labels learned through language to direct\ntheir emotional responses to stimuli (Lindquist and\nBarrett, 2008). Moreover, emotional responses\nhave been shown to direct communication with\npeers (Lee et al., 2020), and expressing certain\nemotional responses—such as anger—have been\nshown to have social ramifications (Keltner et al.,\n1993). Interpreting emotions from text using com-\nputational tools has been a popular research topic\nacross numerous areas in social sciences, enabling\nnew discoveries at unprecedented scale (Jackson\net al., 2022). In SOCKET , we include a wide\nrange of tasks from various domains such as daily\ndialogue (Li et al., 2017), written responses to news\nstories (Buechel and Hahn, 2017), and tweets using\ntextual syntax (Mohammad et al., 2018), and also\nemojis (Barbieri et al., 2018).\nTrustworthiness People can detect cues in lan-\nguage that determine the trustworthiness of a mes-\nsage (Newman et al., 2003), leading to studies that\naim to quantify the level of trust in text using com-\nputational methods (Choi et al., 2020). In particu-\n11373\nlar, this direction has gained attention from NLP\ncommunities following increased needs to combat\nand mitigate potential harms coming from the gen-\neration and dissemination of false information in\nonline spaces (Wu et al., 2019). In SOCKET we in-\nclude tasks that require identifying perceived trust\nfrom several dimensions: impartiality (Pryzant\net al., 2020), deception (Ott et al., 2011), propa-\nganda (Martino et al., 2020), rumor (Ma et al.,\n2017) and bragging, as it is considered to be “un-\nplain speaking\" (Haiman, 1998; Jin et al., 2022).\nOther Social Factors Finally, we include tasks\nof a more discursive and rhetorical type, that are\nunderstood to be more reliant on the contextual\nelements of social distance, power, and solidar-\nity. In SOCKET , the tasks included are empa-\nthy (Buechel et al., 2018), politeness (Hayati et al.,\n2021; Fu et al., 2020), intimacy (Pei and Jurgens,\n2020) and complaints (Preo¸ tiuc-Pietro et al., 2019).\nPoliteness, like humor, is understood to be a non-\ncooperative prosocial behavior but unlike humor,\nis concerned with the act of “saving face” (Brown\nand Levinson, 1987). Empathy, shown to be closely\nrelated to politeness (Fukushima and Haugh, 2014),\nis heavily reliant on social positions in the context\nof the conversation (Macagno et al., 2022). Inti-\nmacy, however, has been shown to be more depen-\ndent on notions of time and space between people\nin dialogue (Márquez Reiter and Frohlich, 2020).\n3.3 Dataset Summary\nThe final SOCKET benchmark contains 58 tasks\nfrom 35 datasets, grouped into the five categories\nshown in Figure 1. We denote multiple tasks from\nthe same dataset by adding the task name as a suffix\nfollowing the dataset name and # symbol.\nThe collection of tasks chosen for SOCKET\nmakes it a comprehensive benchmark to measure\nlanguage models’ abilities to capture underlying so-\ncial information. Motivated by theories of systemic\nfunctional linguistics and interpersonal pragmatics,\nSOCKET cuts across a number of dimensions of\ninterpersonal communication, allowing it to also be\na tool to better understand and interpret co-learning\nabilities and dependencies in sociolinguistic tasks.\nHaving this ability allows researchers and users to\nmore efficiently and effectively deploy NLP meth-\nods by providing empirical results on the limits and\naffordances of a variety of out-of-domain social\nlanguage tasks.\nIn total, SOCKET spans 2,616,342 items across\nall tasks, including 269,246 samples in the test set.\nHowever, experimenting with an evaluation set of\nsize can be prohibitive due to model size, available\nresources, and considerations of the environment.\nTherefore, we also release a subset of our data as\nSOCKETT E (SOCKET but Tinier) that contains\nat most 1000 items per task in the test set, reducing\nthe test set to 43,731 samples. In Appendix B.3, we\nshow that performance on SOCKETT E is highly\ncorrelated and we hope that this smaller subset\nenables more rapid progress.\n4 Benchmarks on the Social Knowledge\nCapabilities of LLMs\nWe first train and evaluate several commonly used\nmultitask LLMs on our datasets to obtain bench-\nmark results, which provide a first glimpse of how\ngood LLMs are at learning social knowledge tasks.\nExperiment details are described in Appendix §B.\n4.1 Training Methods\nBERT-based FinetuningWe first apply the stan-\ndard process of fine-tuning on pretrained LLMs.\nWe select two of the most popular LLMs -\nBERT (Devlin et al., 2019) and RoBERTa (Liu\net al., 2019) - as well as two lightweight mod-\nels known to achieve high performance on fine-\ntuning tasks - DeBERTa-V3 (He et al., 2021) and\nMiniLM (Wang et al., 2020).\nPrompt-based finetuning Prompt-based finetun-\ning has emerged as a flexible and effective means\nof adapting models to downstream tasks (Wei et al.,\n2021). As a benchmark, we include the perfor-\nmances of a T5 model (Raffel et al., 2020) trained\non each task via finetuning. We manually design\nprompts for each task. For classification tasks, we\nuse verbalizers to map the class to word labels and\nfor regression tasks, we adopt a method similar to\nGao et al. (2021) in that we use two anchor words\n“Yes” and “No” and consider the probability of pre-\ndicting “Yes” as the final score. For span-based\ntasks, we train the model to directly generate the\nsequence outputs. A list of prompts can be found\nin Table 8 and Table 9 in the Appendix.\nZero-shot predictions We further apply our de-\nsigned prompts to test the performances of LLMs\nin a zero-shot setting where no further finetun-\ning is performed. Using the same prompts pro-\nposed in Table 8, we test SOCKET on several\nwidely used LLMs: GPT (Radford et al., 2018),\nGPT-J-6B (Wang and Komatsuzaki, 2021), OPT\n11374\nCategory Model No. params (B) Humor & Sarcasm Offens. Sent. & Emo. Social Factors Trust. CLS PAIR REG SPANAvg.\nbaseline majority 0.27 0.42 0.12 0.25 0.41 0.39 0.34 0.50 0.00 0.32random 0.40 0.35 0.17 0.36 0.35 0.38 0.51 0.50 0.00 0.32\nzero-shot\nEleutherAI-gpt-j-6b 6 0.39 0.35 0.29 0.33 0.28 0.32 0.26 0.50 0.08 0.32alpaca-native 7 0.39 0.44 0.45 0.55 0.31 0.42 0.48 0.57 0.17 0.43bigscience-bloomz-7b1 7 0.50 0.49 0.43 0.53 0.45 0.49 0.51 0.56 0.09 0.48cerebras-Cerebras-GPT-6.7B 6.7 0.42 0.39 0.30 0.36 0.34 0.35 0.33 0.52 0.13 0.36decapoda-research-llama-13b 13 0.49 0.43 0.36 0.42 0.31 0.38 0.52 0.53 0.17 0.40facebook-opt-13b 13 0.31 0.40 0.19 0.22 0.28 0.31 0.25 0.49 0.13 0.31google-flan-t5-xxl 11 0.66 0.56 0.52 0.60 0.49 0.56 0.64 0.63 0.17 0.55t5-3b 3 0.34 0.41 0.27 0.32 0.35 0.36 0.36 0.49 0.13 0.36llama2-7b-chat 7 0.39 0.27 0.33 0.34 0.24 0.25 0.38 0.56 0.18 0.29GPT-3.5 0.64 0.55 0.57 0.65 0.45 0.57 0.49 0.67 0.21 0.56\nfinetuning\nbert-base-uncased 0.11 0.78 0.76 0.65 0.70 0.62 0.70 0.79 0.77 0.55 0.71roberta-base 0.086 0.79 0.77 0.68 0.72 0.63 0.70 0.83 0.79 0.64 0.72deberta-v3 0.098 0.83 0.77 0.70 0.72 0.66 0.72 0.87 0.79 0.63 0.73MiniLM 0.066 0.77 0.72 0.61 0.67 0.58 0.66 0.78 0.69 0.57 0.67T5* 0.25 0.68 0.72 0.55 0.59 0.47 0.65 0.66 0.45 0.54 0.62\nTable 2: A comparison of the benchmark performances of different models and training schemes. Best-performing\ninstances are shown in bold. The best performing parameter size for each zero-shot model is shown (cf. Figure 1) .\nA full comparison of all models across all settings can be found in Table 4 in the Appendix. The performances on\neach individual task using a DeBERTa-V3 model can be found in Table 10 in the Appendix.\n(Zhang et al., 2022), T5 (Raffel et al., 2020),\nLLaMA (Touvron et al., 2023a), LLaMA-2 (Tou-\nvron et al., 2023b), BLOOM (Workshop et al.,\n2023), BLOOMZ (Muennighoff et al., 2022),\nFLAN-T5 (Chung et al., 2022b), RedPajama (Com-\nputer, 2023), and Alpaca (Taori et al., 2023; Wang\net al., 2022b). We also evaluate the performance of\nGPT-3.5 3 using OpenAI’s API. Samples for which\na model does not provide an appropriate label are\nautomatically marked as incorrect. For each LLM\nvariant, we test zero-shot results for different model\nsizes ranging between 110M and 13B parameters,\nwhich we report in Table 4 in the Appendix.\n4.2 Results\nWe compare model performances across category\ntype and task type as shown in Table 2. Each re-\nported value is the average of the scores on ev-\nery task within the specified group. The ratio-\nnale behind using a unified average score is to\nprovide a high-level comparison of the perfor-\nmances of zero-shot and fine-tuned models un-\nder various settings, including task type (regres-\nsion/classification/pair/span) as well as dimension\nof social knowledge.\nDeBERTa-V3 achieves the best overall perfor-\nmance after full training on each of the SOCKET\ndatasets, followed by other BERT-based models.\nThe prompt-based finetuning of T5 performs worse\nthan standard finetuning, especially on the pairwise\nclassification and regression tasks. Meanwhile,\nmost zero-shot models perform only slightly better\nthan the baseline, indicating that prompting alone\ndoes not elicit correct social knowledge—though\n3https://platform.openai.com/docs/models/gpt-3-5\ntwo models, google-flan-t5-xxl and GPT3.5, are\nmuch closer in performance to supervised models.\nSocial knowledge can be hard to inferOur bench-\nmark results reveal that even our best-performing\nmodel leaves significant room for improvement,\nscoring just above 0.7 overall—compared with the\nmodels’ analogous performance on syntactic and\ndiscourse NLU tasks (He et al., 2021) which are\noften much higher. A comparison among cate-\ngories of social knowledge reveals that humor &\nsarcasm is generally the easiest to detect, while\ntrustworthiness is the hardest. This performance\ngap can be attributed to the level of understand-\ning required for each dimension - while detecting\nhumor or other social emotions can often be cor-\nrelated with cues such as sentiment, detecting the\nlevel of trust within sentences requires more under-\nstanding of the context and may be harder to detect\nusing computational models (Choi et al., 2020). At\na task level, we observe that models struggle most\nin span detection tasks. This is a complex task due\nto its open-ended nature, and thus BERT-based fine-\ntuning does not perform as well as in other types\nof tasks. We highlight that learning the various\naspects of social knowledge is indeed a challenge\nfor current LLMs, and thus call for the need for\nfuture models with improved social capabilities.\nSupervised models significantly outperform\nzero-shot models Table 2 reveals that despite be-\ning much smaller in the number of parameters, fine-\ntuning supervised models such as MiniLM leads\nto much better performance than zero-shot mod-\nels using state-of-the-art LLMs. All the zero-shot\nLLMs performed poorly, many on par with random\nbaselines, apart from FLAN-T5. Figure 1 shows\n11375\n0 2 4 6 8 10 12\nNo. params (billions)\n0.1\n0.2\n0.3\n0.4\n0.5Average score across all tasks\nalpaca-native\nbloom-560m\nbloom-1b1\nbloom-3b\nbloom-7b1\nbloomz-560m\nbloomz-1b1\nbloomz-7b1\nflan-t5-small\nflan-t5-base\nflan-t5-large\nflan-t5-xl flan-t5-xxl\nGPT-111M\nGPT-590M\nGPT-2.7B\nGPT-6.7B\ngpt-j-6b llama-7b\nllama-13b\nllama2-7b-chat\nmpt-7b\nmpt-7b-instruct\nopt-1.3b\nopt-2.7b\nopt-6.7b\nopt-13b\nredpajama\nt5-small\nt5-base t5-large\nt5-3b\nt5-11b\nALPACA\nBLOOM\nBLOOMZ\nFLAN-T5\nGPT\nGPT-J\nLLAMA\nLLAMA2\nMPT\nOPT\nRedPajama\nT5\nFigure 1: A comparison of LLMs on the aggregated scores tested on SOCKET under zero-shot settings. The overall\nperformances vary greatly by model architecture, while larger models do not always guarantee better performance.\na detailed picture of how different LLM parame-\nter sizes influence the ability to comprehend social\nknowledge tasks in a zero-shot setting. Surpris-\ningly, we find that of the various training schemes\nFLAN-T5 is by far the most effective for inferring\nsocial knowledge, even with relatively small mod-\nels. We speculate this performance is due to its\ninitial pretraining on more than 1,000 tasks.\nMore parameters do not guarantee more social\nknowledge Another general trend we observe is a\nweak correlation between the number of parame-\nters and overall performance within the same model\narchitecture (ρ= 0.266, p= .08). This is to some\nextent determined by the model’s ability to under-\nstand the task itself given an instruction prompt as\nwell as a sample input, as larger models are capa-\nble of understanding a wider variety of tasks (cf.\nAppendix Table 6). Of course, it is also possible\nthat larger LLMs could encode a greater amount\nof social knowledge through their greater parame-\nter sizes. Interestingly, we observe that for some\nmodels, larger size does not always guarantee bet-\nter performance. This is the case especially for\nBLOOM, T5 and GPT, where the largest model is\nnot always the best performer within the group.\nModels varied in the ability to follow instruc-\ntions (Appendix Table 6). As expected, instruction-\ntuned models like FLAN-T5 and Alpaca are gener-\nally able to follow the prompt instructions, while\nother models may generate answers that are not\nprovided in the options. For our social tasks,\ninstruction-following was not significantly corre-\nlated with model size ( ρ=0.08, p=0.60). Thus,\nlower model performance in Figure 1 is, in part,\ndue to models being unable to answer questions\nrelating to social knowledge.\nWhen models are able to answer the question,\nare they right? Restricting only to instances in\nwhich a model outputs a valid answer reveals het-\nerogeneity among different model groups (Fig-\nure 3), showing an interplay between model size,\ncoverage, and performance. For architectures such\nas FLAN-T5 or BLOOMZ we observe a posi-\ntive correlation between parameter size and perfor-\nmance, both in its ability to understand instructions\nand to make correct predictions. On the other hand,\nfor certain architectures having larger parameters\ncan actually make it worse at understanding in-\nstructions (e.g. LlaMA) or predicting correctly (e.g.\nOPT). Recognizing that measuring of instruction\nunderstanding and the accuracy of an LLM both\ndepend on how strictly one chooses to map the pre-\ndictions to an answer, overall, our results suggest\nthat while LLMs do contain the potential for under-\nstanding social knowledge, additional steps such as\nfinetuning or instruction tuning are likely needed\nfor better social understanding.\n5 Do we see Cross-task Transfer of Social\nKnowledge?\nIn this section, we examine the relations and de-\npendencies between tasks using the predictions of\nLLMs trained on different tasks and test for depen-\ndencies between tasks that are predicted by theory.\nQuantifying Task Dependency We quantify the\ndependency between two tasks as follows. We fine-\ntune a pretrained LLM on tasktA to obtain a model\nmA, which is used to make predictions on the test\nset of another task tB. The correlation between\nthe predicted values from model mA and the true\nlabels of the test set of tB is considered as the task\n11376\nHumor\n& Sarcasm\nOffensiveness\nSentiment\n& Emotion\nSocial Factors\nTrustworthiness\nH & S Offens. S & E Soc. Trust.\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nFigure 2: Heatmap of task dependency among all task\npairs, annotated at category level. Each value represents\nthe absolute strength of correlation between the true\nlabels of the test set of a specific task (columns) and the\npredictions made on that task using a model trained on\na different task (rows). We observe strong correlations,\nespecially within the Offensiveness, Sentiment & Emo-\ntion, and Social Factors categories. A larger version\nlabeled at the task level is shown in Appendix Figure 6.\ndependency that tA has on tB. We report the ab-\nsolute correlation value, as negatively correlated\ntasks are still informative. We describe how the\ncorrelations are obtained across different task types\nin the Appendix (§B.6). Span identification tasks\nare omitted from this analysis, resulting in 55 × 55\nscores. We also measure the pairwise correlation\nbetween models mA and mB as well as task de-\npendency to gain an additional perspective of task\nsimilarity. Details for the model correlation can be\nfound in Appendix §B.6 and Figure 7.\nThe task dependencies for all task pairs, shown\nin Figure 2, reveal salient block structures within\nthe category,4 especially for the Offensiveness,\nSentiment & Emotion, and Social Factors cate-\ngories, suggesting the existence of shared knowl-\nedge within our thematically grouped tasks. These\ncorrelations align with existing findings from inter-\npersonal pragmatics on the relationships between\nsocial knowledge. For instance, increased self-\ndisclosure or pain-related interactions are known to\npromote both intimacy (questionintimacy) and em-\npathy (empathy) (Parks, 1981; Cano and Williams,\n2010), two elements within the Social Factors cat-\negory, while the usage of emojis (tweet_emoji) as\neffective symbols are indicative of emotional states\nsuch as valence (emobank#_valence) and arousal\n(emobank#_arousal) (Fischer and Herbert, 2021),\nwhich belong to the Sentiment & Emotion category.\nThe Offensiveness category shows mixed results\nin comparison with Arango et al. (2019), whose\n4See Figure 6 for fully labeled version.\nresults show that hate speech datasets are often\noverfit and do not generalize well to other similar\ndatasets . Figures 2 & 6, however, show that of the\nseven datasets included in SOCKET , five of them\nincluded at least one task which showed compara-\nble correlations when tested both within and out\nof domain. Indeed, PersonDirectedAbuse, a task\nlabeled for offensive language specifically directed\ntowards an individual, is actually predicted better\nby models fine-tuned on jigsaw# tasks than it was\non its own.\nInterestingly, correlations are scarce within the\nHumor & Sarcasm, and Trustworthiness categories.\nThis is consistent with findings from (Hu et al.,\n2022b) which show that models without exposure\nto linguistic forms lack the requisite social infor-\nmation to perform well on non-literal pragmatic\nphenomena such as humor and deceit.\nAnother notable individual task is humor_rating\nfrom the Humor & Sarcasm dataset, which per-\nforms well as both the fine-tuning and predicted\ntask alongside a number of tasks from the Emotion\n& Sentiment category—particularly discretized\nemotion tasks, as well as hateoffensive in the Of-\nfensiveness category—which labels comments as\neither “hateful,\" “offensive,\" or neither. While re-\nlationships between offensiveness and humor have\nbeen theorized as early as Freud (1960) and sen-\ntiment recognition has been shown to bolster of-\nfensive language detection (Liu, 2012), relatively\nlittle has been said regarding connections between\nthe three categories and thus, this result presents an\nopportunity for further research.\nWe observe that politeness shows strong transfer\nwith many of the offensive and hate speech detec-\ntion tasks in theSOCKET benchmark. In particular,\nthose tasks with high correlation within the offen-\nsive category are highly correlated in predicting\nthe politeness classification task. This finding is\nsupported by literature showing that impoliteness\ncan fall under the umbrella of offensive language\n(B ˛ aczkowska, 2021) and, although key differences\nexist in the pragmatics of the two, the constructs are\nclosely related (Parvaresh, 2023; Culpeper, 2021).\nInterestingly, regression tasks (from the ha-\nhackathon, emobank, and empathy datasets) in\ngeneral have strong correlations with several other\ntasks. This trend suggests that tasks labeled with\ncontinuous variables may have more expressive\npower compared to ordinal or nominal categoriza-\ntion, and thus have a higher potential for stronger\n11377\ntask dependencies. However, the magnitude of\nthe correlation may be influenced by the relative\nvalue distributions of different correlation methods.\nThis finding calls for a need for more datasets with\ncontinuous labels, which requires more effort but\nallows models to capture more fine-grained con-\ncepts of social knowledge.\n6 Can Multi-task Training improve Social\nKnowledge?\nOur findings reveal significant task transfer, both\nwithin and across task categories, which hints at\nshared knowledge among tasks. Linguistics studies\nof social language also note the interrelated percep-\ntions of different dimensions such as humor and\noffensiveness (Culpeper, 2021; Attardo, 2008; Al-\nberts, 1992; LI Hai-hui, 2019). We now examine\nwhether LLMs can learn a more robust sense of\nsocial knowledge by training on multiple tasks.\nExperimental Setup Recent studies have explored\nthe possibility of multi-task training on LLMs,\nwhich is training a single model on several different\ntasks simultaneously, with effects of improving its\nperformance on both seen and unseen tasks (Agha-\njanyan et al., 2021; Padmakumar et al., 2022). We\napply multi-task training on SOCKET , but make\none clear distinction from prior work. Whereas pre-\nvious studies have shown that multi-task training is\nespecially effective when the grouped tasks are of\nsimilar types (Padmakumar et al., 2022), we intro-\nduce a new setting by grouping tasks instead by our\ndefined categories of social knowledge. We expect\nthat same-category tasks contain social knowledge\nthat can be shared across tasks, resulting in LLMs\nthat learn a more robust concept of the specific\ndimension than when trained on single tasks.\nA popular method for multi-task training is pre-\nfinetuning (Aghajanyan et al., 2021; Shi et al.,\n2022), which involves a first stage of finetuning on\nmultiple tasks using task-specific heads on a shared\nencoder, then re-using the encoder for downstream\ntasks. We apply pre-finetuning in two different set-\ntings: (1) category-wise tasks, where we perform\npre-finetuning on tasks grouped to the same cate-\ngory, and (2) all tasks, where all tasks of SOCKET\nare included in the pre-finetuning stage. Consistent\nwith prior work, we perform the second finetuning\nstage on individual tasks using the pre-finetuned\nmodel as initial weights (Aghajanyan et al., 2021).\nOther training details are identical to §4.\nResults Multitask training had little to negative ef-\nModel type\nCategory Single task Category-wise All tasks\nHumor & Sarcasm 0.76 0.76 0.74*\nOffensiveness 0.76 0.76 0.76\nSentiment & Emotion 0.64 0.64 0.62\nSocial Factors 0.67 0.67 0.66\nTrustworthiness 0.66 0.64* 0.62*\nTable 3: The performances of different multi-task set-\ntings aggregated at category level. Numbers with *\nindicate cases where the prediction results significantly\ndiffer from the single task setting (paired t-tests).\nfect on task performance (Table 3). Although some\ntasks did benefit from being co-trained within cat-\negory (Appendix Table 10)—particularly the Of-\nfensiveness category—when aggregated at the cat-\negory level, the average performance is worse. In\nparticular, the Humor & Sarcasm and Trustworthi-\nness categories have the lowest levels of within-\ntask and cross-task dependencies (§5). The per-\nformance drop is less strong in categories with\nhigh dependency, indicating that while multi-task\ntraining on similar tasks may not always improve\nperformance, task-relatedness can help preserve\nperformance when also learning task-specific new\nconcepts. Together, our results suggest multi-task\ntraining on unrelated social tasks hurts overall\nperformance—a result contrary to social science ex-\npectations of how social information is processed—\nand points to a need to further investigate cases\nwhen applying multi-task training as a practice to\nimprove the social knowledge of LLMs.\n7 Conclusion\nPeople increasingly interact with LLMs in natural\nconversation. To what degree are these models able\nto pick up on the social cues? To help answer this\nquestion, we introduce SOCKET , an NLP bench-\nmark to evaluate how well models perform at learn-\ning and recognizing concepts of social knowledge.\nWe provide benchmark results using several popu-\nlar models and provide case studies of studying the\ninherent social capabilities of LLMs in a zero-shot\nsetting. Surprisingly, LLMs perform moderately\nat best, with even large LLMs (>10b parameters)\nvarying widely in their abilities. Additionally, we\nshow that there exist significant task dependencies\nboth within and across task categories, and that\nmulti-task training on task categories can affect\nmodel performance. Our work contributes to the\nbroader NLP community by fostering future ef-\nforts toward building and evaluating more socially\nresponsible and coherent LLMs.\n11378\n8 Limitations\nCross-cultural and multilingual expansions\nCulture is an important aspects of understanding\nlanguage, especially within the broader setting of\nmultilingual NLP. In this study, however, we make\na clear distinction between cultural knowledge and\nsocial knowledge, the latter of which is our focus\nfor this study. Our work is grounded in social-\npsychological theory and the sociolinguistics of\ninterpersonal communication, especially dyadic\ncommunication. Such studies are often aimed\nat phenomena that are widely shared across cul-\ntures while recognizing that cultural variation exists\nwithin how those phenomena are perceived. In con-\ntrast, work in anthropology or cultural studies pro-\nvides a different perspective and grounding. Such\nwork frequently focuses on cross-cultural perspec-\ntives and what is or is-not shared across cultures.\nFor example, in language, the interpretation of\nwhether something is polite can depend on gender\nnorms (Mills, 2004) and cultural (Lorenzo-Dus and\nBou-Franch, 2003), highlighting the potential con-\ntext sensitivity. Similarly, the perception of toxicity\ncan depend on the cultural identities of the reader\n(Sap et al., 2019a; Ghosh et al., 2021). While highly\nvaluable to study, cultural knowledge is a separate\nconstruct from social knowledge (though interre-\nlated) and not the focus of this benchmark, though\nwe hope that our work inspires other benchmarks\nto help assess such differences.\nRegarding multilingual data, SOCKET currently\ncontains tasks based in English due to the limited\navailability of tasks in non-English. While there\nare a few datasets such as HAHA (Chiruzzo et al.,\n2020) in Spanish and DeTox (Demus et al., 2022)\nin German, we were not able to find sufficient num-\nbers yet to provide a meaningful grouping. This\nhighlights the importance of constructing datasets\nand frameworks capable of capturing social knowl-\nedge for a wide variety of languages, which we\nconsider an important future step.\nAdditional dimensions and forms of social\nknowledge Interpersonal communication con-\nveys a richness of different social information and\ndespite our extensive literature review and data cu-\nration process, we fully acknowledge that other\ndimensions of social knowledge are not included\nin our current benchmark. In creating SOCKET ,\nour aim was to focus on diverse categories of so-\ncial knowledge that have multiple tasks in order to\nget a more robust assessment of model capabilities,\ne.g., multiple tests of a model’s ability to recognize\nhumor, in order to avoid the pitfalls of ascribing\nprogress on the basis of a single task alone (Sub-\nramonian et al., 2023). Nevertheless, SOCKET\nomits several notable dimensions or forms of so-\ncial knowledge. Some social aspects of language\nsuch as pragmatic polysemy (Carston, 2021; Apres-\njan, 1974) and idioms (Strässler, 1982) either had\ntoo few similar datasets to form a theory-backed\ncategory, or there were no existing NLP datasets\nto test the construct. The latter is the case, espe-\ncially in the case of linguistic techniques unique to\nrecognize when a speaker is adopting community-\nspecific dialects such as African-American En-\nglish (Hyter et al., 2015; Rivers et al., 2012; Allan,\n2007) and Queer Language (Barrett, 2006; Hueb-\nner, 2021; Harvey, 2000).\nSocial language understanding happens within\na static, unspecified context for the current tasks\nin SOCKET. However, the social context in which\na message is said can dramatically alter its mean-\ning. NLP is just beginning to incorporate the social\ncontext into language understanding (Hovy and\nYang, 2021). While a handful of datasets have be-\ngun to explore modeling context explicitly, such as\nthrough the preceding conversation (Pavlopoulos\net al., 2020; Menini et al., 2021), the identity of\nthe speaker (Almagro et al., 2022), the social re-\nlationship between speakers (Jurgens et al., 2023),\nor explicit social norms (Park et al., 2021), there\nare currently too few of such tasks to compose a\ncomprehensive benchmark with which to measure\nprogress. Future datasets and benchmarks will be\nneeded to study understanding social knowledge\nwhen controlling for context.\nThus, SOCKET represents a starting point for\nmodeling models’ abilities and provides room for\nimprovement via the addition of new categories or\nconstructs, as additional data becomes available.\nFurther inclusion of other dimensions and corre-\nsponding tasks should be an ongoing goal.\nBenchmarks as markers of progress SOCKET\nfills a current gap for assessing the capabilities of\nLLMs on understanding social language. How-\never, benchmarks as constructs have been rightly\ncritiqued as markers of progress in NLP (e.g., Bow-\nman and Dahl, 2021; Schlangen, 2021; Subramo-\nnian et al., 2023), due to aspects such as changing\nor narrowing the field’s definition of a task, overem-\nphasizing or overselling progress in a particular\n11379\narea, or encouraging leaderboard chasing. In de-\nsigning SOCKET, we aimed to directly address the\npitfalls of benchmark design by selecting a diverse\nset of social language understanding tasks that mir-\nrored human capabilities recognized in social sci-\nence studies; this selection helps ensure a broad\nmeasure of performance and that “progress” is not\ndue to improved performance on one type of task.\nHowever, the benchmark itself does not capture all\nof social knowledge (nor do we claim as such) and\nwe view it only as a starting point—a yardstick by\nwhich to measure current systems—with a need for\nnew tasks and benchmarks as models advance in\ntheir social reasoning capabilities.\nThe use of a single metric to measure progress\nin an area or task can mask meaningful insight and\nfail to contextualize performance. While we follow\ncommon practice in NLP (e.g., Wang et al., 2018,\n2019; Muennighoff et al., 2023) and report a single\nmean score in Table 2, the design of SOCKET in-\ncludes specific task categories and types designed\nto easily and meaningfully inspect what is ulti-\nmately contributing to the single score—e.g., are\nmodels performing well in classification but poorly\nin span recognition? Nevertheless, this design is a\ntrade-off: A single score can and likely does pro-\nmote leaderboard chasing by setting a clear goal\nto pursue, while completely disaggregated scores\nlike those in Table 4 become unwieldy and make\nit hard to assess whether meaningful progress is\nbeing made when comparing two models. Here,\nwe have opted to report both the overall average\nand averages for each category and type (10 scores\ntotal) in an attempt to balance these two tensions.\nTechnical limitations One major limitation of\nthe current benchmark is we only tested LLMs that\nhave up to 13B parameters. Recent studies show\nthat the LLMs may start to show emergent abilities\nwhen they are scaled up above a certain threshold\n(Wei et al., 2022). Due to limited computational\nand financial resources, we are not able to test all\nvery large language models, though we welcome\nfuture researchers to work on our benchmark and\nevaluate the sociability of new and larger LLMs.\nFinally, our zero-shot model performance used\ncurated prompts on pretrained models without any\nfurther finetuning. While it is widely known that\ninstruction-based finetuning specific to downstream\ntasks can greatly improve performance, we delib-\nerately chose not to do so. Finetuning LLMs with\nbillions of parameters can leave a large carbon foot-\nprint, which we avoid for both financial and envi-\nronmental reasons (Hu et al., 2021; Liu et al., 2022;\nLester et al., 2021).\n9 Ethical Considerations\nThe interpretation of social information in commu-\nnication is highly subjective in that it can largely\nvary depending on demographic and contextual\nfactors. Nevertheless, several NLP datasets are cre-\nated via crowdsourcing, which raises concerns on\nwhether the dataset’s labels are truly representative\nof our society (Talat et al., 2022). Even within our\nbenchmark, there is the possibility that for tasks\nsuch as offensiveness or humor the crowdsourced\nlabels may undermine phrases that might disregard\na specific demographic group, which may be in-\nevitably picked up by LLMs that are trained and\nevaluated on these datasets. Improved versions\nof our benchmark should include datasets that are\nmore inclusive in such contexts, which we call for\nfuture work.\nThere has been increasing concern over the\namount of computing resources required for con-\nducting deep learning research at scale, especially\nregarding LLMs where task performance is im-\nproved through larger datasets, increased model\nparameters, and longer training hours. The time\nand amount of computing resources required for\ntraining LLMs has become nontrivial (Bender et al.,\n2021), and it has been increasingly aware among\nmachine learning practitioners to consider the car-\nbon footprint of models and computing methods\nto minimize risks of global warming. This, com-\nbined with limited transparency of experiment re-\nsults, may harm the very concept of open science.\nKeeping this in mind, we focused on conducting\neasily reproducible experiments that can be run on\na single GPU within the time frame of hours or a\ncouple of days at the longest. Some of our findings\ncontribute towards this rightful direction, as can be\nseen in our investigation on multi-task training.\nMore importantly, we highlight the fact that the\nmain contribution of our study is a thoroughly de-\nsigned public framework of tasks for examining\nthe social knowledge of LLMs. While it is indeed\nimportant to develop and improve LLMs that can\nperform better on several tasks, we believe that\ncorrectly evaluating the level of social knowledge\nengraved in these models is an equally important\ntask. Without such scrutiny, the users of LLMs\ndeployed in practical settings may be vulnerable to\n11380\nsocially undesirable or unethical content. We sin-\ncerely hope that our efforts in producing SOCKET\ncan ease difficulties of conducting future studies\nthat aim to examine and improve the social under-\nstanding of LLMs.\nAcknowledgments\nThe authors thank reviewers for their timely and\nvaluable feedback on the paper, with a special\nshout-out to R1 for their very detailed feedback\nwhich certainly made this paper better. We also\nthank the members of the Center for Social Media\nResponsibility, especially Paul Resnick and James\nPark for their support which enabled the initiation\nof this project. This work was supported by the\nNational Science Foundation under Grant Nos. IIS-\n2007251, IIS-2143529, and 2137469. The third au-\nthor was partially supported by grant SES-2200228\nfrom the National Science Foundation.\nReferences\nRalph Adolphs. 2009. The social brain: neural basis\nof social knowledge. Annual review of psychology,\n60:693–716.\nArmen Aghajanyan, Anchit Gupta, Akshat Shrivastava,\nXilun Chen, Luke Zettlemoyer, and Sonal Gupta.\n2021. Muppet: Massive multi-task representations\nwith pre-finetuning. In Proceedings of the 2021 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 5799–5811, Online and Punta\nCana, Dominican Republic. Association for Com-\nputational Linguistics.\nJK Alberts. 1992. Teasing and sexual harassment:\nDouble-bind communication. Constructing and re-\nconstructing gender: The links among communica-\ntion, language, and gender, 10:185.\nKeith Allan. 2007. The pragmatics of connotation. Jour-\nnal of Pragmatics, 39(6):1047–1057.\nManuel Almagro, Ivar R Hannikainen, and Neftalí Vil-\nlanueva. 2022. Whose words hurt? contextual deter-\nminants of offensive speech. Personality and Social\nPsychology Bulletin, 48(6):937–953.\nJu D Apresjan. 1974. Regular polysemy.\nAymé Arango, Jorge Pérez, and Barbara Poblete. 2019.\nHate speech detection is not as easy as you may think:\nA closer look at model validation. In Proceedings\nof the 42nd International ACM SIGIR Conference\non Research and Development in Information Re-\ntrieval, SIGIR’19, page 45–54, New York, NY , USA.\nAssociation for Computing Machinery.\nSalvatore Attardo. 2008. Semantics and Pragmatics\nof Humor. Language and Linguistics Compass ,\n2(6):1203–1215.\nFrancesco Barbieri, Jose Camacho-Collados, Francesco\nRonzano, Luis Espinosa-Anke, Miguel Ballesteros,\nValerio Basile, Viviana Patti, and Horacio Saggion.\n2018. SemEval 2018 Task 2: Multilingual Emoji\nPrediction. In Proceedings of the 12th International\nWorkshop on Semantic Evaluation, pages 24–33, New\nOrleans, Louisiana. Association for Computational\nLinguistics.\nLisa Feldman Barrett, Kristen A Lindquist, and Maria\nGendron. 2007. Language as context for the per-\nception of emotion. Trends in cognitive sciences ,\n11(8):327–332.\nRusty Barrett. 2006. Queer talk. Encyclopedia of Lan-\nguage & Linguistics, 10:316–323.\nValerio Basile, Cristina Bosco, Elisabetta Fersini,\nDebora Nozza, Viviana Patti, Francisco Manuel\nRangel Pardo, Paolo Rosso, and Manuela Sanguinetti.\n2019. SemEval-2019 Task 5: Multilingual Detection\nof Hate Speech Against Immigrants and Women in\nTwitter. In Proceedings of the 13th International\nWorkshop on Semantic Evaluation, pages 54–63, Min-\nneapolis, Minnesota, USA. Association for Compu-\ntational Linguistics.\nEmily M. Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\ndangers of stochastic parrots: Can language models\nbe too big? In Proceedings of the 2021 ACM Confer-\nence on Fairness, Accountability, and Transparency,\nFAccT ’21, page 610–623.\nJulia Birke and Anoop Sarkar. 2006. A Clustering Ap-\nproach for Nearly Unsupervised Recognition of Non-\nliteral Language. In 11th Conference of the European\nChapter of the Association for Computational Lin-\nguistics, pages 329–336, Trento, Italy. Association\nfor Computational Linguistics.\nSu Lin Blodgett, Lisa Green, and Brendan O’Connor.\n2016. Demographic dialectal variation in social\nmedia: A case study of African-American English.\nIn Proceedings of the 2016 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n1119–1130, Austin, Texas. Association for Computa-\ntional Linguistics.\nSamuel R Bowman and George E Dahl. 2021. What\nwill it take to fix benchmarking in natural language\nunderstanding? In 2021 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nNAACL-HLT 2021, pages 4843–4855. Association\nfor Computational Linguistics (ACL).\nPenelope Brown and Stephen C. Levinson. 1987.\nPoliteness: some universals in language usage .\nNumber 4 in Studies in interactional sociolinguis-\ntics. Cambridge University Press, Cambridge [Cam-\nbridgeshire] ; New York.\n11381\nPenelope Brown, Stephen C Levinson, and Stephen C\nLevinson. 1987. Politeness: Some universals in lan-\nguage usage, volume 4. Cambridge university press.\nSven Buechel, Anneke Buffone, Barry Slaff, Lyle Un-\ngar, and João Sedoc. 2018. Modeling empathy and\ndistress in reaction to news stories. In Proceedings\nof the 2018 Conference on Empirical Methods in\nNatural Language Processing (EMNLP 2018).\nSven Buechel and Udo Hahn. 2017. EmoBank: Study-\ning the Impact of Annotation Perspective and Repre-\nsentation Format on Dimensional Emotion Analysis.\nIn Proceedings of the 15th Conference of the Euro-\npean Chapter of the Association for Computational\nLinguistics: Volume 2, Short Papers, pages 578–585,\nValencia, Spain. Association for Computational Lin-\nguistics.\nAnna B ˛ aczkowska. 2021. “You’re too thick to change\nthe station” – Impoliteness, insults and responses to\ninsults on Twitter. Topics in Linguistics, 22(2):62–\n84.\nAnnmarie Cano and Amanda C de C Williams. 2010.\nSocial interaction in pain: Reinforcing pain behaviors\nor building intimacy? PAIN®, 149(1):9–11.\nRobyn Carston. 2021. Polysemy: Pragmatics and sense\nconventions. Mind & Language, 36(1):108–133.\nLuis Chiruzzo, Santiago Castro, and Aiala Rosá. 2020.\nHAHA 2019 dataset: A corpus for humor analy-\nsis in Spanish. In Proceedings of the Twelfth Lan-\nguage Resources and Evaluation Conference, pages\n5106–5112, Marseille, France. European Language\nResources Association.\nMinje Choi, Luca Maria Aiello, Krisztián Zsolt Varga,\nand Daniele Quercia. 2020. Ten social dimensions of\nconversations and relationships. In Proceedings of\nThe Web Conference 2020, pages 1514–1525.\nHyung Won Chung, Le Hou, Shayne Longpre, Bar-\nret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, et al.\n2022a. Scaling instruction-finetuned language mod-\nels. arXiv preprint arXiv:2210.11416.\nHyung Won Chung, Le Hou, Shayne Longpre, Barret\nZoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, Al-\nbert Webson, Shixiang Shane Gu, Zhuyun Dai,\nMirac Suzgun, Xinyun Chen, Aakanksha Chowdh-\nery, Alex Castro-Ros, Marie Pellat, Kevin Robinson,\nDasha Valter, Sharan Narang, Gaurav Mishra, Adams\nYu, Vincent Zhao, Yanping Huang, Andrew Dai,\nHongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Ja-\ncob Devlin, Adam Roberts, Denny Zhou, Quoc V . Le,\nand Jason Wei. 2022b. Scaling instruction-finetuned\nlanguage models.\nJunyoung Chung, Çaglar Gülçehre, KyungHyun Cho,\nand Yoshua Bengio. 2014. Empirical evaluation of\ngated recurrent neural networks on sequence model-\ning. CoRR, abs/1412.3555.\nTogether Computer. 2023. Redpajama: An open source\nrecipe to reproduce llama training dataset.\nHarald Cramér. 1999. Mathematical methods of statis-\ntics, volume 43. Princeton university press.\nCrowdFlower. 2016. The emotion in text,\npublished by crowdflower. https:\n//data.world/crowdflower/\nsentiment-analysis-in-text . Accessed:\n2023-01-14.\nCrowdTruth. 2016. Short text corpus with focus\non humor detection. Original-date: 2016-05-\n10T12:48:54Z.\nJonathan Culpeper. 2021. Impoliteness and hate speech:\nCompare and contrast. Journal of Pragmatics, 179:4–\n11.\nGiovanni Da San Martino, Alberto Barrón-Cedeño,\nHenning Wachsmuth, Rostislav Petrov, and Preslav\nNakov. 2020. SemEval-2020 Task 11: Detection of\nPropaganda Techniques in News Articles. In Pro-\nceedings of the Fourteenth Workshop on Semantic\nEvaluation, pages 1377–1414, Barcelona (online).\nInternational Committee for Computational Linguis-\ntics.\nCristian Danescu-Niculescu-Mizil, Moritz Sudhof,\nDaniel Jurafsky, Jure Leskovec, and Christopher\nPotts. 2013. A computational approach to politeness\nwith application to social factors. In Annual Meeting\nof the Association for Computational Linguistics.\nThomas Davidson, Dana Warmsley, Michael Macy, and\nIngmar Weber. 2017. Automated Hate Speech De-\ntection and the Problem of Offensive Language. Pro-\nceedings of the International AAAI Conference on\nWeb and Social Media, 11(1):512–515. Number: 1.\nChristoph Demus, Jonas Pitz, Mina Schütz, Nadine\nProbol, Melanie Siegel, and Dirk Labudde. 2022.\nDetox: A comprehensive dataset for German offen-\nsive language and conversation analysis. In Proceed-\nings of the Sixth Workshop on Online Abuse and\nHarms (WOAH), pages 143–153, Seattle, Washington\n(Hybrid). Association for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, NAACL-HLT 2019, Minneapolis, MN, USA,\nJune 2-7, 2019, Volume 1 (Long and Short Papers),\npages 4171–4186. Association for Computational\nLinguistics.\nSuzanne Eggins. 2004. Introduction to systemic func-\ntional linguistics. A&c Black.\nPaul Ekman. 1992. An argument for basic\nemotions. Cognition and Emotion , 6(3-\n4):169–200. Publisher: Routledge _eprint:\nhttps://doi.org/10.1080/02699939208411068.\n11382\nMai ElSherief, Caleb Ziems, David Muchlinski, Vaish-\nnavi Anupindi, Jordyn Seybolt, Munmun De Choud-\nhury, and Diyi Yang. 2021. Latent Hatred: A Bench-\nmark for Understanding Implicit Hate Speech. In\nProceedings of the 2021 Conference on Empirical\nMethods in Natural Language Processing, pages 345–\n363, Online and Punta Cana, Dominican Republic.\nAssociation for Computational Linguistics.\nIbrahim Abu Farha, Silviu Vlad Oprea, Steven Wilson,\nand Walid Magdy. 2022. Semeval-2022 task 6: is-\narcasmeval, intended sarcasm detection in english\nand arabic. In Proceedings of the 16th International\nWorkshop on Semantic Evaluation (SemEval-2022),\npages 802–814.\nBrigitte Fischer and Cornelia Herbert. 2021. Emoji\nas affective symbols: affective judgments of emoji,\nemoticons, and human faces varying in emotional\ncontent. Frontiers in psychology, 12:645173.\nSigmund Freud. 1960. Jokes and their relation to the\nunconscious. WW Norton & Company.\nLiye Fu, Susan Fussell, and Cristian Danescu-Niculescu-\nMizil. 2020. Facilitating the Communication of\nPoliteness through Fine-Grained Paraphrasing. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 5127–5140, Online. Association for Computa-\ntional Linguistics.\nSaeko Fukushima and Michael Haugh. 2014. The role\nof emic understandings in theorizing im/politeness:\nThe metapragmatics of attentiveness, empathy and\nanticipatory inference in Japanese and Chinese. Jour-\nnal of Pragmatics, 74:165–179.\nTianyu Gao, Adam Fisch, and Danqi Chen. 2021.\nMaking pre-trained language models better few-shot\nlearners. In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Papers),\npages 3816–3830, Online. Association for Computa-\ntional Linguistics.\nDiman Ghazi, Diana Inkpen, and Stan Szpakowicz.\n2015. Detecting emotion stimuli in emotion-bearing\nsentences. In International Conference on Intelli-\ngent Text Processing and Computational Linguistics,\npages 152–165. Springer.\nDeepanway Ghosal, Navonil Majumder, Rada Mi-\nhalcea, and Soujanya Poria. 2020. Utterance-\nlevel Dialogue Understanding: An Empirical Study.\nArXiv:2009.13902 [cs].\nSayan Ghosh, Dylan Baker, David Jurgens, and Vin-\nodkumar Prabhakaran. 2021. Detecting cross-\ngeographic biases in toxicity modeling on social me-\ndia. In Proceedings of the Seventh Workshop on\nNoisy User-generated Text (W-NUT 2021), pages 313–\n328.\nHerbert P Grice. 1975. Logic and conversation. In\nSpeech acts, pages 41–58. Brill.\nJohn Haiman. 1998. Talk is cheap: sarcasm, alienation,\nand the evolution of language . Oxford University\nPress, Oxford. OCLC: 252598275.\nMichael AK Halliday. 2004. Introduction: How big is a\nlanguage? On the power of language. The language\nof science, 5:19–32.\nMichael Alexander Kirkwood Halliday. 1995. Dis-\ncourse in society: Systemic functional perspectives.\n50. Greenwood Publishing Group.\nMichael Alexander Kirkwood Halliday, Ruqaiya Hasan,\net al. 1989. Language, context, and text: Aspects of\nlanguage in a social-semiotic perspective . Oxford\nUniversity Press Oxford.\nKeith Harvey. 2000. Describing camp talk: lan-\nguage/pragmatics/politics. Language and Literature:\nInternational Journal of Stylistics, 9(3):240–260.\nShirley Anugrah Hayati, Dongyeop Kang, and Lyle\nUngar. 2021. Does BERT Learn as Humans Per-\nceive? Understanding Linguistic Styles through Lex-\nica. In Proceedings of the 2021 Conference on Empir-\nical Methods in Natural Language Processing, pages\n6323–6331, Online and Punta Cana, Dominican Re-\npublic. Association for Computational Linguistics.\nPengcheng He, Jianfeng Gao, and Weizhu Chen. 2021.\nDebertav3: Improving deberta using electra-style pre-\ntraining with gradient-disentangled embedding shar-\ning. CoRR, abs/2111.09543.\nJanet Holmes. 2006. Sharing a laugh: Pragmatic aspects\nof humor and gender in the workplace. Journal of\nPragmatics, 38(1):26–50. Special Issue: Gender and\nHumor.\nNabil Hossain, John Krumm, Michael Gamon, and\nHenry Kautz. 2020. SemEval-2020 Task 7: Assess-\ning Humor in Edited News Headlines. In Proceed-\nings of the Fourteenth Workshop on Semantic Eval-\nuation, pages 746–758, Barcelona (online). Interna-\ntional Committee for Computational Linguistics.\nDirk Hovy and Diyi Yang. 2021. The importance of\nmodeling social factors of language: Theory and\npractice. In The 2021 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies. Associ-\nation for Computational Linguistics.\nEdward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan\nAllen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and\nWeizhu Chen. 2021. Lora: Low-rank adaptation of\nlarge language models.\nJennifer Hu, Sammy Floyd, Olessia Jouravlev, Evelina\nFedorenko, and Edward Gibson. 2022a. A fine-\ngrained comparison of pragmatic language under-\nstanding in humans and language models. arXiv\npreprint arXiv:2212.06801.\n11383\nJennifer Hu, Sammy Floyd, Olessia Jouravlev, Evelina\nFedorenko, and Edward Gibson. 2022b. A\nfine-grained comparison of pragmatic language\nunderstanding in humans and language models.\nArXiv:2212.06801 [cs].\nDaniel R Huebner. 2021. Anachronism: The queer\npragmatics of understanding the past in the present.\nThe American Sociologist, 52(4):740–761.\nYvette D Hyter, Kenyatta O Rivers, and Glenda DeJar-\nnette. 2015. Pragmatic language of african american\nchildren and adolescents. Topics in Language Disor-\nders, 35(1):8–45.\nJoshua Conrad Jackson, Joseph Watts, Johann-Mattis\nList, Curtis Puryear, Ryan Drabble, and Kristen A.\nLindquist. 2022. From text to thought: How ana-\nlyzing language can advance psychological science.\nPerspectives on Psychological Science, 17(3):805–\n826. PMID: 34606730.\nLiwei Jiang, Jena D. Hwang, Chandra Bhagavatula, Ro-\nnan Le Bras, Jenny Liang, Jesse Dodge, Keisuke\nSakaguchi, Maxwell Forbes, Jon Borchardt, Saa-\ndia Gabriel, Yulia Tsvetkov, Oren Etzioni, Maarten\nSap, Regina Rini, and Yejin Choi. 2021. Can Ma-\nchines Learn Morality? The Delphi Experiment.\nPublication Title: arXiv e-prints ADS Bibcode:\n2021arXiv211007574J.\nJigsaw. 2017. Toxic Comment Classification Challenge.\nJigsaw. 2019. Unintended Bias in Toxicity Classifica-\ntion.\nMali Jin, Daniel Preotiuc-Pietro, A. Seza Do˘gruöz, and\nNikolaos Aletras. 2022. Automatic Identification\nand Classification of Bragging in Social Media. In\nProceedings of the 60th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 3945–3959, Dublin, Ireland. As-\nsociation for Computational Linguistics.\nDavid Jurgens, Libby Hemphill, and Eshwar Chan-\ndrasekharan. 2019. A just and comprehensive strat-\negy for using NLP to address online abuse. In Pro-\nceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 3658–\n3666, Florence, Italy. Association for Computational\nLinguistics.\nDavid Jurgens, Agrima Seth, Jackson Sargent, Athena\nAghighi, and Michael Geraci. 2023. Your spouse\nneeds professional help: Determining the contex-\ntual appropriateness of messages through modeling\nsocial relationships. In Proceedings of the 61st An-\nnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 10994–\n11013.\nDongyeop Kang, Varun Gangal, and Eduard Hovy. 2019.\n(Male, Bachelor) and (Female, Ph.D) have differ-\nent connotations: Parallelly Annotated Stylistic Lan-\nguage Dataset with Multiple Personas. In Proceed-\nings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and the 9th Inter-\nnational Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), pages 1696–1706, Hong\nKong, China. Association for Computational Linguis-\ntics.\nDongyeop Kang and Eduard Hovy. 2021. Style is NOT\na single variable: Case studies for cross-stylistic lan-\nguage understanding. In Proceedings of the 59th An-\nnual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Confer-\nence on Natural Language Processing (Volume 1:\nLong Papers), pages 2376–2387, Online. Association\nfor Computational Linguistics.\nDacher Keltner, Phoebe C Ellsworth, and Kari Edwards.\n1993. Beyond simple pessimism: effects of sadness\nand anger on social perception. Journal of personal-\nity and social psychology, 64(5):740.\nMikhail Khodak, Nikunj Saunshi, and Kiran V odra-\nhalli. 2018. A Large Self-Annotated Corpus for Sar-\ncasm. In Proceedings of the Eleventh International\nConference on Language Resources and Evaluation\n(LREC 2018), Miyazaki, Japan. European Language\nResources Association (ELRA).\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\nfield, Michael Collins, Ankur Parikh, Chris Alberti,\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\nton Lee, Kristina Toutanova, Llion Jones, Matthew\nKelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\nUszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-\nral questions: A benchmark for question answering\nresearch. Transactions of the Association for Compu-\ntational Linguistics, 7:452–466.\nErik Körner, Gregor Wiedemann, Ahmad Dawar\nHakimi, Gerhard Heyer, and Martin Potthast. 2021.\nOn Classifying whether Two Texts are on the Same\nSide of an Argument. In Proceedings of the 2021\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 10130–10138, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nKent M. Lee, Kristen A. Lindquist, Nathan L. Arbuckle,\nSamantha M. Mowrer, and B. Keith Payne. 2020.\nAn indirect measure of discrete emotions. Emotion,\n20(4):659–676.\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021.\nThe power of scale for parameter-efficient prompt\ntuning. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\npages 3045–3059, Online and Punta Cana, Domini-\ncan Republic. Association for Computational Lin-\nguistics.\nYan Li, Manoj a Thomas, and Dapeng Liu. 2021. From\nsemantics to pragmatics: where IS can lead in Natu-\nral Language Processing (NLP) research. European\nJournal of Information Systems, 30(5):569–590.\n11384\nYanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang\nCao, and Shuzi Niu. 2017. DailyDialog: A Manually\nLabelled Multi-turn Dialogue Dataset. In Proceed-\nings of the Eighth International Joint Conference\non Natural Language Processing (Volume 1: Long\nPapers), pages 986–995, Taipei, Taiwan. Asian Fed-\neration of Natural Language Processing.\nLI Hai-hui. 2019. Mitigation and Pragmatic Empathy.\nJournal of Literature and Art Studies, 9(2).\nKristen A. Lindquist and Lisa Feldman Barrett. 2008.\nConstructing Emotion: The Experience of Fear as a\nConceptual Act. Psychological Science, 19(9):898–\n903.\nBing Liu. 2012. Sentiment analysis and opinion mining.\nSynthesis lectures on human language technologies,\n5(1):1–167.\nXiao Liu, Kaixuan Ji, Yicheng Fu, Weng Tam, Zhengx-\niao Du, Zhilin Yang, and Jie Tang. 2022. P-tuning:\nPrompt tuning can be comparable to fine-tuning\nacross scales and tasks. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers), pages 61–68,\nDublin, Ireland. Association for Computational Lin-\nguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized BERT pretraining\napproach. CoRR, abs/1907.11692.\nNuria Lorenzo-Dus and Patricia Bou-Franch. 2003.\nGender and politeness: Spanish and british un-\ndergraduates’ perceptions of appropriate requests.\nGénero, lenguaje y traducción, pages 187–199.\nJing Ma, Wei Gao, and Kam-Fai Wong. 2017. Detect\nrumors in microblog posts using propagation struc-\nture via kernel learning. In Proceedings of the 55th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 708–717,\nVancouver, Canada. Association for Computational\nLinguistics.\nFabrizio Macagno, Chrysi Rapanta, Elisabeth Mayweg-\nPaus, and Mercè Garcia-Milà. 2022. Coding empathy\nin dialogue. Journal of Pragmatics, 192:116–132.\nKyle Mahowald, Anna A. Ivanova, Idan A. Blank,\nNancy Kanwisher, Joshua B. Tenenbaum, and\nEvelina Fedorenko. 2023. Dissociating language\nand thought in large language models: a cognitive\nperspective. ArXiv:2301.06627 [cs].\nAsifa Majid. 2012. Current emotion research in the\nlanguage sciences. Emotion Review, 4(4):432–443.\nG. Da San Martino, A. Barrón-Cedeño, H. Wachsmuth,\nR. Petrov, and P. Nakov. 2020. SemEval-2020 Task\n11: Detection of Propaganda Techniques in News\nArticles. ArXiv:2009.02696 [cs].\nB.W. Matthews. 1975. Comparison of the predicted and\nobserved secondary structure of t4 phage lysozyme.\nBiochimica et Biophysica Acta (BBA) - Protein Struc-\nture, 405(2):442–451.\nJ. A. Meaney, Steven Wilson, Luis Chiruzzo, Adam\nLopez, and Walid Magdy. 2021. SemEval 2021 Task\n7: HaHackathon, Detecting and Rating Humor and\nOffense. In Proceedings of the 15th International\nWorkshop on Semantic Evaluation (SemEval-2021),\npages 105–119, Online. Association for Computa-\ntional Linguistics.\nStefano Menini, Alessio Palmero Aprosio, and Sara\nTonelli. 2021. Abuse is contextual, what about nlp?\nthe role of context in abusive language annotation\nand detection. arXiv preprint arXiv:2103.14916.\nJohn Miller, Karl Krauth, Benjamin Recht, and Ludwig\nSchmidt. 2020. The effect of natural distribution shift\non question answering models. In Proceedings of the\n37th International Conference on Machine Learning,\nvolume 119 of Proceedings of Machine Learning\nResearch, pages 6905–6916. PMLR.\nSara Mills. 2004. Class, gender and politeness. Multi-\nlingua, 23.\nAnirudh Mittal, Pranav Jeevan P, Prerak Gandhi,\nDiptesh Kanojia, and Pushpak Bhattacharyya. 2021.\n“So You Think You’re Funny?”: Rating the Humour\nQuotient in Standup Comedy. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 10073–10079, Online\nand Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nSaif Mohammad, Felipe Bravo-Marquez, Mohammad\nSalameh, and Svetlana Kiritchenko. 2018. Semeval-\n2018 task 1: Affect in tweets. In Proceedings of the\n12th international workshop on semantic evaluation,\npages 1–17.\nAbhinav Moudgil. Short Jokes.\nNiklas Muennighoff, Nouamane Tazi, Loic Magne, and\nNils Reimers. 2023. Mteb: Massive text embedding\nbenchmark. In Proceedings of the 17th Conference\nof the European Chapter of the Association for Com-\nputational Linguistics, pages 2006–2029.\nNiklas Muennighoff, Thomas Wang, Lintang Sutawika,\nAdam Roberts, Stella Biderman, Teven Le Scao,\nM Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey\nSchoelkopf, et al. 2022. Crosslingual generaliza-\ntion through multitask finetuning. arXiv preprint\narXiv:2211.01786.\nRosina Márquez Reiter and David M. Frohlich. 2020. A\npragmatics of intimacy. Internet Pragmatics, 3(1):1–\n33.\nPreslav Nakov, Giovanni Da San Martino, Tamer\nElsayed, Alberto Barrón-Cedeño, Rubén Míguez,\nShaden Shaar, Firoj Alam, Fatima Haouari, Maram\n11385\nHasanain, Nikolay Babulkov, Alex Nikolov, Gau-\ntam Kishore Shahi, Julia Maria Struß, and Thomas\nMandl. 2021. The CLEF-2021 CheckThat! Lab on\nDetecting Check-Worthy Claims, Previously Fact-\nChecked Claims, and Fake News. In Advances in\nInformation Retrieval, Lecture Notes in Computer\nScience, pages 639–649, Cham. Springer Interna-\ntional Publishing.\nMatthew L. Newman, James W. Pennebaker, Diane S.\nBerry, and Jane M. Richards. 2003. Lying words:\nPredicting deception from linguistic styles. Person-\nality and Social Psychology Bulletin, 29(5):665–675.\nPMID: 15272998.\nUlf Olsson, Fritz Drasgow, and Neil J Dorans. 1982.\nThe polyserial correlation coefficient. Psychome-\ntrika, 47(3):337–347.\nMyle Ott, Yejin Choi, Claire Cardie, and Jeffrey T. Han-\ncock. 2011. Finding Deceptive Opinion Spam by\nAny Stretch of the Imagination. In Proceedings of the\n49th Annual Meeting of the Association for Compu-\ntational Linguistics: Human Language Technologies,\npages 309–319, Portland, Oregon, USA. Association\nfor Computational Linguistics.\nVishakh Padmakumar, Leonard Lausen, Miguel Balles-\nteros, Sheng Zha, He He, and George Karypis. 2022.\nExploring the role of task transferability in large-\nscale multi-task learning. In Proceedings of the 2022\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, pages 2542–2550, Seattle,\nUnited States. Association for Computational Lin-\nguistics.\nChan Young Park, Julia Mendelsohn, Karthik Radhakr-\nishnan, Kinjal Jain, Tushar Kanakagiri, David Jur-\ngens, and Yulia Tsvetkov. 2021. Detecting Commu-\nnity Sensitive Norm Violations in Online Conversa-\ntions. In Findings of the Association for Computa-\ntional Linguistics: EMNLP 2021, pages 3386–3397,\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nMalcolm R. Parks. 1981. Ideology in interpersonal\ncommunication: Off the couch and into the world.\nAnnals of the International Communication Associa-\ntion, 5(1):79–107.\nVahid Parvaresh. 2023. Covertly communicated hate\nspeech: A corpus-assisted pragmatic study. Journal\nof Pragmatics, 205:63–77.\nJohn Pavlopoulos, Jeffrey Sorensen, Lucas Dixon,\nNithum Thain, and Ion Androutsopoulos. 2020. Tox-\nicity detection: Does context really matter? In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 4296–\n4305.\nJohn Pavlopoulos, Jeffrey Sorensen, Léo Laugier, and\nIon Androutsopoulos. 2021. SemEval-2021 Task\n5: Toxic Spans Detection. In Proceedings of the\n15th International Workshop on Semantic Evaluation\n(SemEval-2021), pages 59–69, Online. Association\nfor Computational Linguistics.\nJiaxin Pei and David Jurgens. 2020. Quantifying inti-\nmacy in language. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 5307–5326, Online. As-\nsociation for Computational Linguistics.\nJiaxin Pei and David Jurgens. 2021. Measuring\nSentence-Level and Aspect-Level (Un)certainty in\nScience Communications. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 9959–10011, Online\nand Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nCarla Perez-Almendros, Luis Espinosa-Anke, and\nSteven Schockaert. 2022. SemEval-2022 task 4:\nPatronizing and condescending language detection.\nIn Proceedings of the 16th International Workshop\non Semantic Evaluation (SemEval-2022), pages 298–\n307, Seattle, United States. Association for Compu-\ntational Linguistics.\nDenis Peskov, Benny Cheng, Ahmed Elgohary, Joe Bar-\nrow, Cristian Danescu-Niculescu-Mizil, and Jordan\nBoyd-Graber. 2020. It Takes Two to Lie: One to\nLie, and One to Listen. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 3811–3854, Online. Association\nfor Computational Linguistics.\nMartin Potthast, Tim Gollub, Matti Wiegmann, Benno\nStein, Matthias Hagen, Kristof Komlossy, Sebstian\nSchuster, and Erika P. Garces Fernandez. 2018. We-\nbis Clickbait Corpus 2017 (Webis-Clickbait-17).\nJohn Pougué-Biyong, Valentina Semenova, Alexandre\nMatton, Rachel Han, Aerin Kim, Renaud Lambiotte,\nand Doyne Farmer. 2021. DEBAGREEMENT: A\ncomment-reply dataset for (dis)agreement detection\nin online debates.\nDaniel Preo¸ tiuc-Pietro, Mihaela G˘aman, and Nikolaos\nAletras. 2019. Automatically Identifying Complaints\nin Social Media. In Proceedings of the 57th Annual\nMeeting of the Association for Computational Lin-\nguistics, ACL.\nReid Pryzant, Richard Diehl Martinez, Nathan Dass,\nSadao Kurohashi, Dan Jurafsky, and Diyi Yang. 2020.\nAutomatically Neutralizing Subjective Bias in Text.\nProceedings of the AAAI Conference on Artificial\nIntelligence, 34(01):480–489. Number: 01.\nAlec Radford, Karthik Narasimhan, Tim Salimans, Ilya\nSutskever, et al. 2018. Improving language under-\nstanding by generative pre-training.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. J. Mach. Learn. Res., 21:140:1–140:67.\n11386\nSudha Rao and Joel Tetreault. 2018. Dear Sir or Madam,\nMay I Introduce the GY AFC Dataset: Corpus, Bench-\nmarks and Metrics for Formality Style Transfer. In\nProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 1 (Long Papers), pages 129–140, New Or-\nleans, Louisiana. Association for Computational Lin-\nguistics.\nAnn-Katrin Reuel, Sebastian Peralta, João Sedoc, Gar-\nrick Sherman, and Lyle Ungar. 2022. Measuring the\nLanguage of Self-Disclosure across Corpora. In Find-\nings of the Association for Computational Linguis-\ntics: ACL 2022, pages 1035–1047, Dublin, Ireland.\nAssociation for Computational Linguistics.\nKenyatta O Rivers, Yvette D Hyter, and Glenda DeJar-\nnette. 2012. Parsing pragmatics. The ASHA Leader,\n17(13):14–17.\nSara Rosenthal, Noura Farra, and Preslav Nakov. 2017.\nSemEval-2017 task 4: Sentiment analysis in Twitter.\nIn Proceedings of the 11th International Workshop\non Semantic Evaluation (SemEval-2017), pages 502–\n518, Vancouver, Canada. Association for Computa-\ntional Linguistics.\nWillibald Ruch. 2010. The sense of humor: Explo-\nrations of a personality characteristic , volume 3.\nWalter de Gruyter.\nLaura Ruis, Akbir Khan, Stella Biderman, Sara Hooker,\nTim Rocktäschel, and Edward Grefenstette. 2022.\nLarge language models are not zero-shot communi-\ncators.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Arun Raja, Manan Dey,\nM Saiful Bari, Canwen Xu, Urmish Thakker,\nShanya Sharma Sharma, Eliza Szczechla, Taewoon\nKim, Gunjan Chhablani, Nihal Nayak, Debajyoti\nDatta, Jonathan Chang, Mike Tian-Jian Jiang, Han\nWang, Matteo Manica, Sheng Shen, Zheng Xin Yong,\nHarshit Pandey, Rachel Bawden, Thomas Wang, Tr-\nishala Neeraj, Jos Rozen, Abheesht Sharma, An-\ndrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan\nTeehan, Teven Le Scao, Stella Biderman, Leo Gao,\nThomas Wolf, and Alexander M Rush. 2022. Multi-\ntask prompted training enables zero-shot task gener-\nalization. In International Conference on Learning\nRepresentations.\nMaarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi,\nand Noah A Smith. 2019a. The risk of racial bias\nin hate speech detection. In Proceedings of the 57th\nannual meeting of the association for computational\nlinguistics, pages 1668–1678.\nMaarten Sap, Saadia Gabriel, Lianhui Qin, Dan Juraf-\nsky, Noah A. Smith, and Yejin Choi. 2020. Social\nBias Frames: Reasoning about Social and Power Im-\nplications of Language. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 5477–5490, Online. Association\nfor Computational Linguistics.\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan\nLe Bras, and Yejin Choi. 2019b. Social IQa: Com-\nmonsense reasoning about social interactions. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP), pages 4463–\n4473, Hong Kong, China. Association for Computa-\ntional Linguistics.\nKlaus R. Scherer and Harald G. Wallbott. 1994. \"Ev-\nidence for universality and cultural variation of\ndifferential emotion response patterning\": Correc-\ntion. Journal of Personality and Social Psychology,\n67(1):55–55. Place: US Publisher: American Psy-\nchological Association.\nDavid Schlangen. 2021. Targeting the benchmark: On\nmethodology in current natural language processing\nresearch. In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natu-\nral Language Processing (Volume 2: Short Papers),\npages 670–674.\nStefan Schneider. 2010. Mitigation. Handbooks of\npragmatics, pages 253–269.\nStephanie Schnurr. 2010. 13. humour. Interpersonal\npragmatics, 6:307.\nAshish Sharma, Adam Miner, David Atkins, and Tim Al-\nthoff. 2020. A computational approach to understand-\ning empathy expressed in text-based mental health\nsupport. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 5263–5276, Online. Association for\nComputational Linguistics.\nYiwen Shi, Taha ValizadehAslani, Jing Wang, Ping\nRen, Yi Zhang, Meng Hu, Liang Zhao, and Hualou\nLiang. 2022. Improving imbalanced learning by pre-\nfinetuning with data augmentation. In Fourth In-\nternational Workshop on Learning with Imbalanced\nDomains: Theory and Applications , pages 68–82.\nPMLR.\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D. Manning, Andrew Ng, and\nChristopher Potts. 2013. Recursive Deep Models for\nSemantic Compositionality Over a Sentiment Tree-\nbank. In Proceedings of the 2013 Conference on\nEmpirical Methods in Natural Language Processing,\npages 1631–1642, Seattle, Washington, USA. Asso-\nciation for Computational Linguistics.\nEllen Spertus. 1997. Smokey: Automatic recognition\nof hostile messages. In Aaai/iaai, pages 1058–1065.\nKaryn Stapleton. 2003. Gender and swearing: A com-\nmunity practice. Women and Language, 26(2):22.\n11387\nGerard Steen, Aletta G. Dorst, and J. Berenike Her-\nrmann, editors. 2011. A method for linguistic\nmetaphor identification: from MIP to MIPVU. Num-\nber 14 in Converging evidence in language and com-\nmunication research. Benjamins, Amsterdam.\nJürg Strässler. 1982. Idioms in English: A pragmatic\nanalysis, volume 183. Gunter Narr Verlag.\nArjun Subramonian, Xingdi Yuan, Hal Daumé III, and\nSu Lin Blodgett. 2023. It takes two to tango: Nav-\nigating conceptualizations of NLP tasks and mea-\nsurements of performance. In Findings of the Asso-\nciation for Computational Linguistics: ACL 2023 ,\npages 3234–3279, Toronto, Canada. Association for\nComputational Linguistics.\nThakur Ashutosh Suman and Abhinav Jain. 2021. AS-\ntarTwice at SemEval-2021 task 5: Toxic span de-\ntection using RoBERTa-CRF, domain specific pre-\ntraining and self-training. In Proceedings of the\n15th International Workshop on Semantic Evaluation\n(SemEval-2021), pages 875–880, Online. Association\nfor Computational Linguistics.\nZeerak Talat, Hagen Blix, Josef Valvoda, Maya Indira\nGanesh, Ryan Cotterell, and Adina Williams. 2022.\nOn the machine learning of ethical judgments from\nnatural language. In Proceedings of the 2022 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies. Association for Computational\nLinguistics.\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\nDubois, Xuechen Li, Carlos Guestrin, Percy\nLiang, and Tatsunori B. Hashimoto. 2023. Stan-\nford alpaca: An instruction-following llama\nmodel. https://github.com/tatsu-lab/\nstanford_alpaca.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurelien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023a. Llama: Open\nand efficient foundation language models.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\nBhosale, Dan Bikel, Lukas Blecher, Cristian Canton\nFerrer, Moya Chen, Guillem Cucurull, David Esiobu,\nJude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\nCynthia Gao, Vedanuj Goswami, Naman Goyal, An-\nthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\nIsabel Kloumann, Artem Korenev, Punit Singh Koura,\nMarie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-\nana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-\ntinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-\nbog, Yixin Nie, Andrew Poulton, Jeremy Reizen-\nstein, Rashi Rungta, Kalyan Saladi, Alan Schelten,\nRuan Silva, Eric Michael Smith, Ranjan Subrama-\nnian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-\nlor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\nZheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\nMelanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez, Robert Stojnic, Sergey Edunov, and Thomas\nScialom. 2023b. Llama 2: Open foundation and\nfine-tuned chat models.\nElliot Turiel. 1983. The development of social knowl-\nedge: Morality and convention. Cambridge Univer-\nsity Press.\nCynthia Van Hee, Els Lefever, and Véronique Hoste.\n2018. SemEval-2018 Task 3: Irony Detection in\nEnglish Tweets. In Proceedings of the 12th Interna-\ntional Workshop on Semantic Evaluation, pages 39–\n50, New Orleans, Louisiana. Association for Compu-\ntational Linguistics.\nBertie Vidgen, Dong Nguyen, Helen Margetts, Patricia\nRossini, and Rebekah Tromble. 2021. Introducing\nCAD: the Contextual Abuse Dataset. In Proceedings\nof the 2021 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 2289–2303,\nOnline. Association for Computational Linguistics.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia, Aman-\npreet Singh, Julian Michael, Felix Hill, Omer Levy,\nand Samuel Bowman. 2019. Superglue: A stick-\nier benchmark for general-purpose language under-\nstanding systems. Advances in neural information\nprocessing systems, 32.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel Bowman. 2018. Glue:\nA multi-task benchmark and analysis platform for nat-\nural language understanding. In Proceedings of the\n2018 EMNLP Workshop BlackboxNLP: Analyzing\nand Interpreting Neural Networks for NLP. Associa-\ntion for Computational Linguistics.\nBen Wang and Aran Komatsuzaki. 2021. GPT-\nJ-6B: A 6 Billion Parameter Autoregressive\nLanguage Model. https://github.com/\nkingoflolz/mesh-transformer-jax.\nWenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan\nYang, and Ming Zhou. 2020. Minilm: Deep self-\nattention distillation for task-agnostic compression\nof pre-trained transformers. In Proceedings of the\n34th International Conference on Neural Information\nProcessing Systems, NIPS’20, Red Hook, NY , USA.\nCurran Associates Inc.\nXuezhi Wang, Haohan Wang, and Diyi Yang. 2022a.\nMeasure and improve robustness in NLP models: A\nsurvey. In Proceedings of the 2022 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, pages 4569–4586, Seattle, United States.\nAssociation for Computational Linguistics.\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa\nLiu, Noah A. Smith, Daniel Khashabi, and Hannaneh\nHajishirzi. 2022b. Self-instruct: Aligning language\nmodel with self generated instructions.\n11388\nZijian Wang and Christopher Potts. 2019. TalkDown:\nA Corpus for Condescension Detection in Context.\nIn Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP), pages 3711–\n3719, Hong Kong, China. Association for Computa-\ntional Linguistics.\nZeerak Waseem, Thomas Davidson, Dana Warmsley,\nand Ingmar Weber. 2017. Understanding abuse: A\ntypology of abusive language detection subtasks. In\nProceedings of the First Workshop on Abusive Lan-\nguage Online, pages 78–84, Vancouver, BC, Canada.\nAssociation for Computational Linguistics.\nZeerak Waseem and Dirk Hovy. 2016. Hateful Sym-\nbols or Hateful People? Predictive Features for Hate\nSpeech Detection on Twitter. In Proceedings of\nthe NAACL Student Research Workshop, pages 88–\n93, San Diego, California. Association for Computa-\ntional Linguistics.\nJason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin\nGuu, Adams Wei Yu, Brian Lester, Nan Du, An-\ndrew M Dai, and Quoc V Le. 2021. Finetuned lan-\nguage models are zero-shot learners. arXiv preprint\narXiv:2109.01652.\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,\nBarret Zoph, Sebastian Borgeaud, Dani Yogatama,\nMaarten Bosma, Denny Zhou, Donald Metzler, et al.\n2022. Emergent abilities of large language models.\narXiv preprint arXiv:2206.07682.\nLudwig Wittgenstein. 1953. Philosophical Investiga-\ntions. Basil Blackwell, Oxford.\nBigScience Workshop, :, Teven Le Scao, Angela Fan,\nChristopher Akiki, Ellie Pavlick, Suzana Ili´c, Daniel\nHesslow, Roman Castagné, Alexandra Sasha Luc-\ncioni, François Yvon, Matthias Gallé, Jonathan\nTow, Alexander M. Rush, Stella Biderman, Albert\nWebson, Pawan Sasanka Ammanamanchi, Thomas\nWang, Benoît Sagot, Niklas Muennighoff, Albert Vil-\nlanova del Moral, Olatunji Ruwase, Rachel Bawden,\nStas Bekman, Angelina McMillan-Major, Iz Belt-\nagy, Huu Nguyen, Lucile Saulnier, Samson Tan, Pe-\ndro Ortiz Suarez, Victor Sanh, Hugo Laurençon,\nYacine Jernite, Julien Launay, Margaret Mitchell,\nColin Raffel, Aaron Gokaslan, Adi Simhi, Aitor\nSoroa, Alham Fikri Aji, Amit Alfassy, Anna Rogers,\nAriel Kreisberg Nitzav, Canwen Xu, Chenghao Mou,\nChris Emezue, Christopher Klamm, Colin Leong,\nDaniel van Strien, David Ifeoluwa Adelani, Dragomir\nRadev, Eduardo González Ponferrada, Efrat Lev-\nkovizh, Ethan Kim, Eyal Bar Natan, Francesco De\nToni, Gérard Dupont, Germán Kruszewski, Giada\nPistilli, Hady Elsahar, Hamza Benyamina, Hieu Tran,\nIan Yu, Idris Abdulmumin, Isaac Johnson, Itziar\nGonzalez-Dios, Javier de la Rosa, Jenny Chim, Jesse\nDodge, Jian Zhu, Jonathan Chang, Jörg Frohberg,\nJoseph Tobing, Joydeep Bhattacharjee, Khalid Al-\nmubarak, Kimbo Chen, Kyle Lo, Leandro V on Werra,\nLeon Weber, Long Phan, Loubna Ben allal, Lu-\ndovic Tanguy, Manan Dey, Manuel Romero Muñoz,\nMaraim Masoud, María Grandury, Mario Šaško,\nMax Huang, Maximin Coavoux, Mayank Singh,\nMike Tian-Jian Jiang, Minh Chien Vu, Moham-\nmad A. Jauhar, Mustafa Ghaleb, Nishant Subramani,\nNora Kassner, Nurulaqilla Khamis, Olivier Nguyen,\nOmar Espejel, Ona de Gibert, Paulo Villegas, Pe-\nter Henderson, Pierre Colombo, Priscilla Amuok,\nQuentin Lhoest, Rheza Harliman, Rishi Bommasani,\nRoberto Luis López, Rui Ribeiro, Salomey Osei,\nSampo Pyysalo, Sebastian Nagel, Shamik Bose,\nShamsuddeen Hassan Muhammad, Shanya Sharma,\nShayne Longpre, Somaieh Nikpoor, Stanislav Silber-\nberg, Suhas Pai, Sydney Zink, Tiago Timponi Tor-\nrent, Timo Schick, Tristan Thrush, Valentin Danchev,\nVassilina Nikoulina, Veronika Laippala, Violette\nLepercq, Vrinda Prabhu, Zaid Alyafeai, Zeerak Ta-\nlat, Arun Raja, Benjamin Heinzerling, Chenglei Si,\nDavut Emre Ta¸ sar, Elizabeth Salesky, Sabrina J.\nMielke, Wilson Y . Lee, Abheesht Sharma, Andrea\nSantilli, Antoine Chaffin, Arnaud Stiegler, Debajy-\noti Datta, Eliza Szczechla, Gunjan Chhablani, Han\nWang, Harshit Pandey, Hendrik Strobelt, Jason Alan\nFries, Jos Rozen, Leo Gao, Lintang Sutawika, M Sai-\nful Bari, Maged S. Al-shaibani, Matteo Manica, Ni-\nhal Nayak, Ryan Teehan, Samuel Albanie, Sheng\nShen, Srulik Ben-David, Stephen H. Bach, Taewoon\nKim, Tali Bers, Thibault Fevry, Trishala Neeraj, Ur-\nmish Thakker, Vikas Raunak, Xiangru Tang, Zheng-\nXin Yong, Zhiqing Sun, Shaked Brody, Yallow Uri,\nHadar Tojarieh, Adam Roberts, Hyung Won Chung,\nJaesung Tae, Jason Phang, Ofir Press, Conglong Li,\nDeepak Narayanan, Hatim Bourfoune, Jared Casper,\nJeff Rasley, Max Ryabinin, Mayank Mishra, Minjia\nZhang, Mohammad Shoeybi, Myriam Peyrounette,\nNicolas Patry, Nouamane Tazi, Omar Sanseviero,\nPatrick von Platen, Pierre Cornette, Pierre François\nLavallée, Rémi Lacroix, Samyam Rajbhandari, San-\nchit Gandhi, Shaden Smith, Stéphane Requena, Suraj\nPatil, Tim Dettmers, Ahmed Baruwa, Amanpreet\nSingh, Anastasia Cheveleva, Anne-Laure Ligozat,\nArjun Subramonian, Aurélie Névéol, Charles Lover-\ning, Dan Garrette, Deepak Tunuguntla, Ehud Reiter,\nEkaterina Taktasheva, Ekaterina V oloshina, Eli Bog-\ndanov, Genta Indra Winata, Hailey Schoelkopf, Jan-\nChristoph Kalo, Jekaterina Novikova, Jessica Zosa\nForde, Jordan Clive, Jungo Kasai, Ken Kawamura,\nLiam Hazan, Marine Carpuat, Miruna Clinciu, Na-\njoung Kim, Newton Cheng, Oleg Serikov, Omer\nAntverg, Oskar van der Wal, Rui Zhang, Ruochen\nZhang, Sebastian Gehrmann, Shachar Mirkin, Shani\nPais, Tatiana Shavrina, Thomas Scialom, Tian Yun,\nTomasz Limisiewicz, Verena Rieser, Vitaly Protasov,\nVladislav Mikhailov, Yada Pruksachatkun, Yonatan\nBelinkov, Zachary Bamberger, Zdenˇek Kasner, Al-\nice Rueda, Amanda Pestana, Amir Feizpour, Am-\nmar Khan, Amy Faranak, Ana Santos, Anthony\nHevia, Antigona Unldreaj, Arash Aghagol, Are-\nzoo Abdollahi, Aycha Tammour, Azadeh HajiHos-\nseini, Bahareh Behroozi, Benjamin Ajibade, Bharat\nSaxena, Carlos Muñoz Ferrandis, Danish Contrac-\ntor, David Lansky, Davis David, Douwe Kiela,\n11389\nDuong A. Nguyen, Edward Tan, Emi Baylor, Ez-\ninwanne Ozoani, Fatima Mirza, Frankline Onon-\niwu, Habib Rezanejad, Hessie Jones, Indrani Bhat-\ntacharya, Irene Solaiman, Irina Sedenko, Isar Ne-\njadgholi, Jesse Passmore, Josh Seltzer, Julio Bonis\nSanz, Livia Dutra, Mairon Samagaio, Maraim El-\nbadri, Margot Mieskes, Marissa Gerchick, Martha\nAkinlolu, Michael McKenna, Mike Qiu, Muhammed\nGhauri, Mykola Burynok, Nafis Abrar, Nazneen Ra-\njani, Nour Elkott, Nour Fahmy, Olanrewaju Samuel,\nRan An, Rasmus Kromann, Ryan Hao, Samira Al-\nizadeh, Sarmad Shubber, Silas Wang, Sourav Roy,\nSylvain Viguier, Thanh Le, Tobi Oyebade, Trieu Le,\nYoyo Yang, Zach Nguyen, Abhinav Ramesh Kashyap,\nAlfredo Palasciano, Alison Callahan, Anima Shukla,\nAntonio Miranda-Escalada, Ayush Singh, Benjamin\nBeilharz, Bo Wang, Caio Brito, Chenxi Zhou, Chirag\nJain, Chuxin Xu, Clémentine Fourrier, Daniel León\nPeriñán, Daniel Molano, Dian Yu, Enrique Manjava-\ncas, Fabio Barth, Florian Fuhrimann, Gabriel Altay,\nGiyaseddin Bayrak, Gully Burns, Helena U. Vrabec,\nImane Bello, Ishani Dash, Jihyun Kang, John Giorgi,\nJonas Golde, Jose David Posada, Karthik Ranga-\nsai Sivaraman, Lokesh Bulchandani, Lu Liu, Luisa\nShinzato, Madeleine Hahn de Bykhovetz, Maiko\nTakeuchi, Marc Pàmies, Maria A Castillo, Mari-\nanna Nezhurina, Mario Sänger, Matthias Samwald,\nMichael Cullan, Michael Weinberg, Michiel De\nWolf, Mina Mihaljcic, Minna Liu, Moritz Freidank,\nMyungsun Kang, Natasha Seelam, Nathan Dahlberg,\nNicholas Michio Broad, Nikolaus Muellner, Pascale\nFung, Patrick Haller, Ramya Chandrasekhar, Renata\nEisenberg, Robert Martin, Rodrigo Canalli, Rosaline\nSu, Ruisi Su, Samuel Cahyawijaya, Samuele Garda,\nShlok S Deshmukh, Shubhanshu Mishra, Sid Ki-\nblawi, Simon Ott, Sinee Sang-aroonsiri, Srishti Ku-\nmar, Stefan Schweter, Sushil Bharati, Tanmay Laud,\nThéo Gigant, Tomoya Kainuma, Wojciech Kusa, Ya-\nnis Labrak, Yash Shailesh Bajaj, Yash Venkatraman,\nYifan Xu, Yingxin Xu, Yu Xu, Zhe Tan, Zhongli\nXie, Zifan Ye, Mathilde Bras, Younes Belkada, and\nThomas Wolf. 2023. Bloom: A 176b-parameter\nopen-access multilingual language model.\nLiang Wu, Fred Morstatter, Kathleen M Carley, and\nHuan Liu. 2019. Misinformation in social me-\ndia: definition, manipulation, and detection. ACM\nSIGKDD Explorations Newsletter, 21(2):80–90.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov,\nSara Rosenthal, Noura Farra, and Ritesh Kumar.\n2019a. Predicting the Type and Target of Offensive\nPosts in Social Media. In Proceedings of the 2019\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long and Short\nPapers), pages 1415–1420, Minneapolis, Minnesota.\nAssociation for Computational Linguistics.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov,\nSara Rosenthal, Noura Farra, and Ritesh Kumar.\n2019b. SemEval-2019 task 6: Identifying and cat-\negorizing offensive language in social media (Of-\nfensEval). In Proceedings of the 13th International\nWorkshop on Semantic Evaluation, pages 75–86, Min-\nneapolis, Minnesota, USA. Association for Compu-\ntational Linguistics.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher De-\nwan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022.\nOpt: Open pre-trained transformer language models.\narXiv preprint arXiv:2205.01068.\nYunxiang Zhang and Xiaojun Wan. 2022. MOVER:\nMask, Over-generate and Rank for Hyperbole Gener-\nation. ArXiv:2109.07726 [cs].\nXuhui Zhou, Yue Zhang, Leyang Cui, and Dandan\nHuang. 2020. Evaluating commonsense in pre-\ntrained language models. In Proceedings of the AAAI\nConference on Artificial Intelligence , volume 34,\npages 9733–9740.\nAvner Ziv. 2010. The social function of humor in inter-\npersonal relationships. Society, 47(1):11–18.\n11390\nA Details on dataset processing\nA.1 Benchmark construction (§3)\nThe SOCKET dataset consists of 58 tasks from 35\nunique, public datasets. The datasets that make\nup the benchmark dataset are processed in a way\nthat is meant to balance uniformity across datasets\nand tasks while minimizing deviations from the\noriginal dataset.\nFor all datasets, key changes from the original\ndataset are twofold:\n• Duplicates and unlabeled items are removed\nfrom all datasets. If duplicates occur across\ndata splits, the splits are recombined, reshuf-\nfled, and split.\n• All datasets are split 80%/10%/10% be-\ntween train/test/dev splits, respectively. Any\ndatasets not split 80%/10%/10% are recom-\nbined, reshuffled, and split 80%/10%/10%.\nAll datasets were made compatible with the Hug-\nging Face Datasets package.\nB Experimental Details\nB.1 Computational resources (§4, §5, §6)\nAll of our experiments were conducted on an\nUbuntu 22.04.1 machine installed with NVIDIA\nRTX A5000 and A6000 GPUs. The Python pack-\nages used in our experiments include Pytorch 1.13,\nTransformers 4.21.3, and Pytorch Lightning 1.6.4.\nB.2 Comparison of all models\nTable 4 contains a detailed version of Table 2,\nwhere the scores of every single task are presented.\nB.3 Details on the comparison between\nSOCKET and S OCKETT E\n32 out of 58 tasks contained more than 1,000 test\nsamples, resulting in a disparity between the sizes\nof the original SOCKET and SOCKETT E variants.\nTo test that both datasets still offer comparable\nevaluations for testing models, we compare their\nscores for a supervised model and compare test set\nperformances. For each task, we train a deberta-\nv3-base model, evaluate using the test sets of both\nversions, and compute the correlation between each\nsetting using Pearson’s r score. We provide eval-\nuation results of SOCKETT E for our models in\nTable 5. Also, we show through Table 7 and Fig-\nure 5 that there exists a strong correlation between\nthe evaluations of both versions, demonstrating that\nSOCKETT E is indeed a representative sample of\nSOCKET.\nB.4 Details on language model finetuning (§4,\n§5, §6)\nB.4.1 Task-specific heads (§4, §5, §6)\nAs our benchmark consists of four different task\ntypes: classification, regression, sentence pair de-\ntection, and span identification - we maintain a\nunified structure for each task where each sample\nis fed into the encoder of an LLM, and the out-\nput states are then fed into a task-specific head\nlayer. For span detection tasks, we feed the last hid-\nden layer into a bidirectional GRU (Chung et al.,\n2014), and then the output vectors of the GRU into\na linear layer that transforms each vector into a\ndimension of 3, corresponding to the [B,I,O] la-\nbels for each token, following earlier work in span\nidentification (Suman and Jain, 2021). For all other\ntasks, we feed the last hidden state of the encoder\ncorresponding to the [CLS] token into a separate\nclassifier/regression head consisting of two linear\nlayers of hidden size 768 and a dropout probabil-\nity of 0.1. We use the mean squared error loss for\nregression tasks and the cross-entropy loss for all\nother tasks.\nB.4.2 Training strategies for language model\nfinetuning (§4, §6)\nWhen training models for the benchmark (§4) and\nthe multi-task (§6) experiments, the learning rate\nwas linearly increased for 6% of the training steps\nup to 1e-5 and linearly decreased afterward. All\nmodels were trained for a maximum of 10 epochs\nusing three different seeds, with early stopping after\nvalidation performance did not increase for three\nconsecutive epochs.\nOur multi-task training in §6 requires two stages\nof training: (1) a pre-finetuning stage that simulta-\nneously trains a model on multiple different tasks,\nand (2) a finetuning stage that loads the model\ntrained from (1) and finetunes it to a single task. In\nthe first stage, a single batch can include several\ndifferent tasks and produce different types of losses.\nTo obtain a unified loss that is differentiable, we\naggregated the loss for each sample and sum them\nup, which we use for backpropagation. For both\nstages, we use the same aforementioned training\nsteps and learning rate strategy.\nFor all settings, the training batch size was set to\n32 with 16-bit precision enabled. Validation was\n11391\nCategory Model No. params (billions) Humor & Sarcasm Offensiveness Sentiment & Emotion Social Factors Trustworthiness CLS PAIR REG SPANAvg.\nbaseline majority 0.27 0.42 0.12 0.25 0.41 0.39 0.34 0.50 0.00 0.32random 0.40 0.35 0.17 0.36 0.35 0.38 0.51 0.50 0.00 0.32\nzero-shot\nEleutherAI-gpt-j-6b 6 0.39 0.35 0.29 0.33 0.28 0.32 0.26 0.50 0.08 0.32alpaca-native 7 0.39 0.44 0.45 0.55 0.31 0.42 0.48 0.57 0.17 0.43bigscience-bloom-560m 0.56 0.30 0.24 0.14 0.26 0.18 0.21 0.26 0.49 0.07 0.22bigscience-bloom-1b1 1 0.26 0.39 0.17 0.25 0.33 0.33 0.21 0.48 0.11 0.31bigscience-bloom-3b 3 0.37 0.44 0.30 0.34 0.30 0.37 0.32 0.51 0.12 0.37bigscience-bloom-7b1 7 0.42 0.27 0.30 0.29 0.20 0.25 0.39 0.51 0.11 0.28bigscience-bloomz-560m 0.56 0.38 0.42 0.34 0.42 0.41 0.40 0.41 0.51 0.10 0.40bigscience-bloomz-1b1 1 0.41 0.44 0.38 0.43 0.41 0.42 0.44 0.52 0.10 0.42bigscience-bloomz-7b1 7 0.50 0.49 0.43 0.53 0.45 0.49 0.51 0.56 0.09 0.48cerebras-Cerebras-GPT-111M 0.11 0.21 0.07 0.18 0.09 0.03 0.05 0.18 0.49 0.07 0.10cerebras-Cerebras-GPT-590M 0.59 0.31 0.11 0.14 0.19 0.09 0.13 0.23 0.00 0.08 0.14cerebras-Cerebras-GPT-2.7B 2.7 0.32 0.19 0.14 0.23 0.16 0.17 0.26 0.49 0.18 0.19cerebras-Cerebras-GPT-6.7B 6.7 0.42 0.39 0.30 0.36 0.34 0.35 0.33 0.52 0.13 0.36decapoda-research-llama-7b 7 0.45 0.44 0.34 0.41 0.22 0.38 0.34 0.52 0.12 0.38decapoda-research-llama-13b 13 0.49 0.43 0.36 0.42 0.31 0.38 0.52 0.53 0.17 0.40facebook-opt-1.3b 1.3 0.41 0.43 0.28 0.33 0.39 0.38 0.34 0.50 0.12 0.38facebook-opt-2.7b 2.7 0.37 0.45 0.29 0.36 0.32 0.37 0.34 0.52 0.18 0.38facebook-opt-6.7b 6.7 0.20 0.31 0.20 0.16 0.17 0.21 0.13 0.48 0.16 0.24facebook-opt-13b 13 0.31 0.40 0.19 0.22 0.28 0.31 0.25 0.49 0.13 0.31google-flan-t5-small 0.08 0.37 0.43 0.23 0.32 0.40 0.38 0.34 0.50 0.08 0.37google-flan-t5-base 0.25 0.45 0.49 0.43 0.45 0.41 0.47 0.44 0.53 0.09 0.45google-flan-t5-large 0.78 0.50 0.52 0.48 0.50 0.41 0.50 0.44 0.59 0.13 0.49google-flan-t5-xl 3 0.59 0.53 0.50 0.60 0.47 0.53 0.58 0.60 0.19 0.52google-flan-t5-xxl 11 0.66 0.56 0.52 0.60 0.49 0.56 0.64 0.63 0.17 0.55mosaicml-mpt-7b 7 0.41 0.42 0.36 0.44 0.32 0.37 0.45 0.54 0.25 0.39mosaicml-mpt-7b-instruct 7 0.20 0.25 0.30 0.34 0.15 0.22 0.25 0.46 0.24 0.25t5-small 0.06 0.12 0.05 0.09 0.18 0.06 0.08 0.09 NaN 0.04 0.08t5-base 0.22 0.41 0.18 0.15 0.31 0.12 0.20 0.30 NaN 0.03 0.20t5-large 0.77 0.36 0.11 0.26 0.26 0.10 0.14 0.30 0.50 0.03 0.18t5-3b 3 0.34 0.41 0.27 0.32 0.35 0.36 0.36 0.49 0.13 0.36t5-11b 11 0.38 0.38 0.14 0.31 0.36 0.33 0.23 0.50 0.03 0.32togethercomputer-RedPajama-INCITE-7B-Instruct 7 0.41 0.48 0.37 0.41 0.42 0.44 0.39 0.53 0.11 0.43llama2-7b-chat 7 0.39 0.27 0.33 0.34 0.24 0.25 0.38 0.56 0.18 0.29GPT-3.5 0.64 0.55 0.57 0.65 0.45 0.57 0.49 0.67 0.21 0.56\nfull\nbert-base-uncased 0.11 0.78 0.76 0.65 0.70 0.62 0.70 0.79 0.77 0.55 0.71roberta-base 0.086 0.79 0.77 0.68 0.72 0.63 0.70 0.83 0.79 0.640.72deberta-v3 0.098 0.83 0.77 0.70 0.72 0.66 0.72 0.87 0.79 0.630.73MiniLM 0.066 0.77 0.72 0.61 0.67 0.58 0.66 0.78 0.69 0.57 0.67T5* 0.25 0.53 0.71 0.48 0.50 0.47 0.63 0.44 0.37 0.54 0.58\nTable 4: A comparison of the benchmark performances of different models and training schemes. Best-performing\ninstances are shown in bold.\nCategory Model No. params (billions) Humor & Sarcasm Offensiveness Sentiment & Emotion Social Factors Trustworthiness CLS PAIR REG SPANAvg.\nbaseline majority 0.27 0.42 0.12 0.25 0.41 0.39 0.34 0.50 0.00 0.32random 0.40 0.35 0.17 0.36 0.35 0.38 0.51 0.50 0.00 0.32\nzero-shot\nEleutherAI-gpt-j-6b 6 0.39 0.35 0.29 0.33 0.28 0.32 0.26 0.50 0.08 0.32alpaca-native 7 0.39 0.44 0.45 0.55 0.31 0.42 0.48 0.57 0.17 0.43bigscience-bloom-560m 0.56 0.30 0.24 0.14 0.26 0.18 0.21 0.26 0.49 0.07 0.22bigscience-bloom-1b1 1 0.26 0.39 0.17 0.25 0.33 0.33 0.21 0.48 0.11 0.31bigscience-bloom-3b 3 0.37 0.44 0.30 0.34 0.30 0.37 0.32 0.51 0.12 0.37bigscience-bloom-7b1 7 0.42 0.27 0.30 0.29 0.20 0.25 0.39 0.51 0.11 0.28bigscience-bloomz-560m 0.56 0.38 0.42 0.34 0.42 0.41 0.40 0.41 0.51 0.10 0.40bigscience-bloomz-1b1 1 0.41 0.44 0.38 0.43 0.41 0.42 0.44 0.52 0.10 0.42bigscience-bloomz-7b1 7 0.50 0.49 0.43 0.53 0.45 0.49 0.51 0.56 0.09 0.48cerebras-Cerebras-GPT-111M 0.11 0.21 0.07 0.18 0.09 0.03 0.05 0.18 0.49 0.07 0.10cerebras-Cerebras-GPT-590M 0.59 0.31 0.11 0.14 0.19 0.09 0.13 0.23 0.00 0.08 0.14cerebras-Cerebras-GPT-2.7B 2.7 0.32 0.19 0.14 0.23 0.16 0.17 0.26 0.49 0.18 0.19cerebras-Cerebras-GPT-6.7B 6.7 0.42 0.39 0.30 0.36 0.34 0.35 0.33 0.52 0.13 0.36decapoda-research-llama-7b 7 0.45 0.44 0.34 0.41 0.22 0.38 0.34 0.52 0.12 0.38decapoda-research-llama-13b 13 0.49 0.43 0.36 0.42 0.31 0.38 0.52 0.53 0.17 0.40facebook-opt-1.3b 1.3 0.41 0.43 0.28 0.33 0.39 0.38 0.34 0.50 0.12 0.38facebook-opt-2.7b 2.7 0.37 0.45 0.29 0.36 0.32 0.37 0.34 0.52 0.18 0.38facebook-opt-6.7b 6.7 0.20 0.31 0.20 0.16 0.17 0.21 0.13 0.48 0.16 0.24facebook-opt-13b 13 0.31 0.40 0.19 0.22 0.28 0.31 0.25 0.49 0.13 0.31google-flan-t5-small 0.08 0.40 0.43 0.30 0.33 0.41 0.39 0.43 0.49 0.06 0.39google-flan-t5-base 0.25 0.42 0.46 0.35 0.36 0.41 0.43 0.42 0.52 0.05 0.42google-flan-t5-large 0.78 0.51 0.52 0.47 0.50 0.47 0.51 0.58 0.54 0.09 0.50google-flan-t5-xl 3 0.57 0.53 0.48 0.55 0.47 0.53 0.51 0.60 0.14 0.51google-flan-t5-xxl 11 0.61 0.55 0.52 0.61 0.47 0.55 0.59 0.62 0.18 0.54mosaicml-mpt-7b 7 0.41 0.42 0.36 0.44 0.32 0.37 0.45 0.54 0.25 0.39mosaicml-mpt-7b-instruct 7 0.20 0.25 0.30 0.34 0.15 0.22 0.25 0.46 0.24 0.25t5-small 0.06 0.33 0.08 0.08 0.25 0.07 0.12 0.09 0.00 0.03 0.12t5-base 0.22 0.41 0.15 0.14 0.28 0.12 0.17 0.33 0.00 0.03 0.17t5-large 0.77 0.37 0.13 0.14 0.25 0.12 0.14 0.32 0.48 0.03 0.16t5-3b 3 0.13 0.21 0.14 0.17 0.23 0.19 0.19 0.48 0.09 0.19t5-11b 11 0.38 0.38 0.14 0.31 0.36 0.33 0.23 0.50 0.03 0.32togethercomputer-RedPajama-INCITE-7B-Instruct 7 0.41 0.48 0.37 0.41 0.42 0.44 0.39 0.53 0.11 0.43llama2-7b-chat 7 0.39 0.27 0.33 0.34 0.24 0.25 0.38 0.56 0.18 0.30GPT-3.5 0.64 0.56 0.57 0.65 0.45 0.57 0.49 0.67 0.21 0.56\nfull\nbert-base-uncased 0.11 0.78 0.76 0.65 0.70 0.62 0.70 0.79 0.77 0.55 0.71roberta-base 0.086 0.79 0.77 0.68 0.72 0.63 0.70 0.83 0.79 0.640.72deberta-v3 0.098 0.83 0.77 0.70 0.72 0.66 0.72 0.87 0.79 0.630.73MiniLM 0.066 0.77 0.72 0.61 0.67 0.58 0.66 0.78 0.69 0.57 0.67T5* 0.25 0.53 0.71 0.48 0.50 0.47 0.63 0.44 0.37 0.54 0.58\nTable 5: A comparison of the benchmark performances of different models and training schemes on theSOCKETT E\ntest set (a subset of SOCKET). Best-performing instances are shown in bold.\n11392\nModel Group No. params (billions) Humor & Sarcasm Offensiveness Sentiment & Emotion Social Factors Trustworthiness CLS PAIR REG SPANTotal ratio\nchavinlo-alpaca-native 13.00 1.00 1.00 1.00 1.00 0.99 1.00 1.00 1.00 0.96 1.00bigscience-bloom-560m 0.56 0.49 0.74 0.42 0.54 0.76 0.71 0.72 0.00 0.80 0.63bigscience-bloom-1b1 1 0.54 0.83 0.53 0.64 0.94 0.86 0.56 0.02 0.91 0.74bigscience-bloom-3b 3 0.89 0.96 0.75 0.89 0.97 0.99 0.92 0.29 0.95 0.90bigscience-bloom-7b1 7 0.94 0.97 0.78 0.76 0.99 0.96 0.99 0.52 0.96 0.91bigscience-bloomz-560m 0.56 1.00 0.99 0.96 1.00 0.99 0.99 1.00 1.00 0.92 0.99bigscience-bloomz-1b1 1 1.00 0.99 0.96 1.00 0.99 0.99 1.00 0.99 0.89 0.98bigscience-bloomz-7b1 7 1.00 1.00 0.99 1.00 0.99 1.00 1.00 1.00 0.97 0.99google-flan-t5-small 0.08 0.94 0.96 0.90 0.94 0.97 0.95 0.92 1.00 0.79 0.94google-flan-t5-base 0.25 1.00 0.98 0.90 1.00 0.90 0.98 0.75 0.98 0.79 0.95google-flan-t5-large 0.78 1.00 1.00 0.91 1.00 0.90 0.97 0.75 1.00 0.98 0.96google-flan-t5-xl 3 1.00 1.00 0.92 1.00 0.93 0.98 0.84 1.00 0.95 0.97google-flan-t5-xxl 11 1.00 1.00 0.92 1.00 1.00 0.98 1.00 1.00 0.99 0.98cerebras-Cerebras-GPT-111M 0.11 0.30 0.22 0.15 0.16 0.27 0.20 0.41 0.01 0.66 0.21cerebras-Cerebras-GPT-590M 0.59 0.66 0.70 0.51 0.64 0.68 0.70 0.66 0.32 0.54 0.64cerebras-Cerebras-GPT-2.7B 2.70 0.73 0.88 0.66 0.62 0.88 0.77 0.60 0.98 0.97 0.79cerebras-Cerebras-GPT-6.7B 6.70 0.83 0.91 0.58 0.72 0.99 0.89 0.81 0.36 0.96 0.82EleutherAI-gpt-j-6b 6 0.70 0.77 0.56 0.65 0.74 0.75 0.53 0.41 0.88 0.70decapoda-research-llama-7b-hf 7 0.73 0.93 0.51 0.78 0.87 0.82 0.99 0.50 0.87 0.80decapoda-research-llama-13b-hf 13 0.44 0.48 0.62 0.50 0.57 0.46 0.57 0.75 0.95 0.53mosaicml-mpt-7b 7 0.87 0.99 0.67 0.96 1.00 0.95 0.86 0.63 0.96 0.91mosaicml-mpt-7b-instruct 7 0.36 0.62 0.72 0.75 0.67 0.66 0.53 0.46 0.99 0.64facebook-opt-1.3b 1.30 0.80 0.95 0.61 0.79 0.97 0.90 0.88 0.48 0.87 0.85facebook-opt-2.7b 2.70 0.82 0.94 0.65 0.83 1.00 0.98 1.00 0.05 0.87 0.87facebook-opt-6.7b 6.70 0.42 0.58 0.24 0.18 0.45 0.41 0.34 0.34 0.90 0.43facebook-opt-13b 13 0.65 0.82 0.30 0.50 0.73 0.70 0.68 0.20 0.74 0.64togethercomputer-RedPajama-INCITE-7B-Instruct 7 1.00 1.00 1.00 1.00 0.99 1.00 1.00 1.00 0.95 1.00t5-small 0.06 0.77 0.76 0.16 0.66 0.60 0.74 0.28 0.00 0.21 0.59t5-base 0.22 0.80 0.88 0.23 0.67 0.84 0.84 0.75 0.00 0.19 0.70t5-large 0.77 0.95 0.88 0.24 0.67 0.85 0.84 0.72 0.14 0.23 0.71t5-3b 3 0.40 0.39 0.46 0.50 0.54 0.46 0.49 0.23 0.58 0.44t5-11b 11 0.80 0.74 0.23 0.61 0.87 0.75 0.56 0.04 0.58 0.64llama2-7b-chat 7 1.00 0.99 0.99 1.00 1.00 0.99 0.99 1.00 0.99 0.99gpt-3.5 1.00 1.00 0.99 1.00 0.92 1.00 0.80 0.99 1.00 0.98\nOverall 0.53 0.57 0.39 0.44 0.57 0.51 0.4 0.39 1.0 0.51\nTable 6: The fraction of samples that each LLM can make inferences given the instruction prompts, when tested in a\nzero-shot setting.\n0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\nRatio of valid samples\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n0.55Overall score across all tasks\ngpt-j-6b\nbloom-1b1\nbloom-3b\nbloom-560m bloom-7b1\nbloomz-1b1\nbloomz-560m\nbloomz-7b1\nGPT-111M GPT-2.7B\nGPT-590M\nGPT-6.7B\nalpaca-native\nllama-13b\nllama-7b\nopt-1.3b\nopt-13b\nopt-2.7b\nopt-6.7b\nflan-t5-base\nflan-t5-large\nflan-t5-small\nflan-t5-xl\nflan-t5-xxl\nllama2-7b\nmpt-7b\nmpt-7b-instruct\nt5-11b\nt5-3b\nt5-base\nt5-large\nt5-small\nredpajama\nGroup\nGPT-J\nBLOOM\nBLOOMZ\nGPT\nALPACA\nLLAMA\nOPT\nFLAN-T5\nLLAMA2\nMPT\nT5\nFigure 3: A comparison of the ratio of valid samples which the LLM was able to make an inference given the\ncorrect instruction prompt (x-axis) versus the overall scores when limited to the samples that the model was capable\nof making an inference (y-axis).\nmade after each training epoch on the validation\nset using Pearson’s r correlation added by 1 and di-\nvided by 2 for regression tasks and macro F1 score\nfor all other tasks. If there were multiple tasks con-\nsidered due to multi-task training, the average of all\ntask performances was used as the final validation\nscore.\nB.5 Details on prompt-based finetuning (§4,\n§5)\nWe use fix prompts fine-tuning for all the prompt-\nbased models. The batch size was set as 32 for\ntraining. For every single task, we set 10 as the\nmax epoch and do early stopping based on the\nvalidation loss. The learning rate is set as 5e-5.\nFor classification tasks, the model is fine-tuned\nto generate the target label. For regression tasks,\nwe first normalized the scores into (0,1) and then\nsplit the labels into two groups. The model is fine-\n11393\n0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\nRatio of valid samples\n0.1\n0.2\n0.3\n0.4\n0.5Overall score across all tasks\ngpt-j-6b\nbloom-1b1\nbloom-3b\nbloom-560m\nbloom-7b1\nbloomz-1b1\nbloomz-560m\nbloomz-7b1\nGPT-111M\nGPT-2.7B\nGPT-590M\nGPT-6.7B\nalpaca-native\nllama-13b\nllama-7b\nopt-1.3b\nopt-13b\nopt-2.7b\nopt-6.7b\nflan-t5-base\nflan-t5-large\nflan-t5-small\nflan-t5-xl\nflan-t5-xxl\nllama2-7b\nmpt-7b\nmpt-7b-instruct\nt5-11b\nt5-3b\nt5-base t5-large\nt5-small\nredpajama\nGroup\nGPT-J\nBLOOM\nBLOOMZ\nGPT\nALPACA\nLLAMA\nOPT\nFLAN-T5\nLLAMA2\nMPT\nT5\nFigure 4: A comparison of the ratio of valid samples which the LLM was able to make an inference given the\ncorrect instruction prompt (x-axis) versus the overall scores across every sample in the test dataset where failed\npredictions are considered incorrect (y-axis).\ntask S OCKET S OCKETTE\ncontextual-abuse#IdentityDirectedAbuse 0.62 0.58\ncontextual-abuse#PersonDirectedAbuse 0.53 0.49\ncrowdflower 0.24 0.22\ndailydialog 0.38 0.38\nhasbiasedimplication 0.86 0.87\nhateoffensive 0.93 0.93\nhumor-pairs 0.98 0.97\nimplicit-hate#explicit_hate 0.72 0.68\nimplicit-hate#implicit_hate 0.71 0.72\nimplicit-hate#incitement_hate 0.68 0.70\nimplicit-hate#inferiority_hate 0.60 0.69\nimplicit-hate#stereotypical_hate 0.68 0.68\nimplicit-hate#threatening_hate 0.63 0.67\nimplicit-hate#white_grievance_hate 0.70 0.68\nintentyn 0.75 0.73\njigsaw#identity_hate 0.80 0.83\njigsaw#insult 0.88 0.87\njigsaw#obscene 0.91 0.91\njigsaw#severe_toxic 0.73 0.74\njigsaw#threat 0.85 1.00\njigsaw#toxic 0.90 0.90\nneutralizing-bias-pairs 0.98 0.98\noffensiveyn 0.82 0.82\nsarc 0.74 0.77\nsentitreebank 0.97 0.97\nsexyn 0.79 0.77\ntoxic-span 0.68 0.69\ntweet_emoji 0.34 0.32\ntweet_emotion 0.81 0.81\ntweet_sentiment 0.71 0.69\ntwo-to-lie#receiver_truth 0.59 0.60\ntwo-to-lie#sender_truth 0.58 0.58\nTable 7: A comparison of the evaluation scores between\nthe test sets for SOCKET versus SOCKETT E when\nevaluated on a DeBERTa-v3 model trained on a single-\ntask setting.\n0.5 1.0\nSOCKET score\n0.2\n0.4\n0.6\n0.8\n1.0SOCKETT e score\nPearson's r: 0.997\nFigure 5: For each of the 32 tasks in SOCKET con-\ntaining more than 1,000 test samples, we evaluate the\nperformance of a deberta-v3 model trained on a single\nSOCKET task on both the original test set as well as the\nsmaller SOCKETT E variant. The correlation between\nthe two scores results in a high Pearson’s r score of\n0.997, indicating SOCKETT E can be reliably deployed\nfor more rapid model testing.\ntuned to predict “yes” or “no” regarding the prompt\nquestion. During inference, the probability of the\n“yes” token is used as the prediction score. For span\ntasks, we directly train the model to generate the\nfull answer.\n11394\nB.6 Details on zero-shot predictions (§4, §5)\nWe use manually designed prompts for all the zero-\nshot prediction tasks and the prompts are shown in\nTable 8.\nB.7 Computing correlation scores of task\ndependencies (§5)\nBecause our framework consists of several task\ntypes, it is challenging to obtain a unified metric of\ncorrelation across different task comparisons. We\nuse the following rules to obtain correlation values:\n• Regression task & regression task: We com-\npute the Pearson’s correlation coefficient of\nthe two arrays.\n• Regression task & binary classification task:\nWe compute the point biserial correlation co-\nefficient of a continuous array and a binary\narray.\n• Regression task & multi-class classification\ntask: We set up a linear regression task using\nthe one-hot coded values of the multi-class\narray as independent variables and the con-\ntinuous array as the dependent variable. We\nreport the root of the R-squared value of the\nregression as correlation (Olsson et al., 1982).\n• Binary classification task & binary classifica-\ntion task: We compute the Matthews’ corre-\nlation coefficient (Matthews, 1975) from the\ntwo binary arrays.\n• Binary or multi-task classification task &\nmulti-class classification task: We compute\nthe Cramer’s V score (Cramér, 1999) from the\ntwo arrays of categorical variables.\nB.8 Computing pairwise model\nsimilarities (§5)\nWe quantify the model similarity between two tasks\nas follows. We finetune a pretrained LLM on task\ntA to obtain a model mA, and another LLM on task\ntB to obtain mB. We obtain pairwise model simi-\nlarities by inferring both models on a sufficiently\nlarge dataset—in this case the entire test set of all\ntasks—and computing the correlation of the two\ninferred arrays. We construct an undirected graph\n(Figure 7) where the thickness and color represent\nabsolute correlation strength and polarity between\nthe two models. The addition of polarity enables us\nto further discover strong negative correlations with\ntask pairs such as politeness and offensiveness.\nB.9 List of all potential tasks and datasets for\nSOCKET\n11395\nType Task Question/OptionsPAIR talkdown-pairs For the quote \"text_a\" and its context \"text_b\", is the quote condescending?[’No’, ’Yes’]REG hahackathon#humor_ratingDetermine the degree of humor of the given sentence: \"text\". The score should be rangingfrom 0.0 to 5.0, and can be a decimal. 0 is not humorous at all, and 5 is very humorous.CLS hahackathon#is_humor For the sentence: \"text\", is it humorous? [’No’, ’Yes’]PAIR humor-pairs The first sentence is \"text_a\". The second sentence is \"text_b\". Is the first sentence funnierthan the second sentence? [’Yes’, ’No’]\nCLS sarc For the sentence: \"text\", is it sarcastic? [’Yes’, ’No’]CLS tweet_irony For the sentence: \"text\", is it ironic? [’No’, ’Yes’]CLS contextual-abuse#IdentityDirectedAbuse For the sentence: \"text\", is it identity directed abuse?[’No’, ’Yes’]CLS contextual-abuse#PersonDirectedAbuse For the sentence: \"text\", is it person directed abuse?[’No’, ’Yes’]REG hahackathon#offense_ratingDetermine the degree of offense of the given sentence: \"text\". The score should be rangingfrom 0.0 to 5.0, and can be a decimal.CLS hasbiasedimplication For the sentence: \"text\", does it imply some biases? [’No’, ’Yes’]CLS hateoffensive For the sentence: \"text\", is it hate or offensive? [’Hate’, ’Offensive’, ’Nei-ther’]CLS implicit-hate#explicit_hate For the sentence: \"text\", is it explicit hate? [’No’, ’Yes’]CLS implicit-hate#implicit_hate For the sentence: \"text\", is it implicitly hateful? [’No’, ’Yes’]CLS implicit-hate#incitement_hate For the sentence: \"text\", is it a hateful incitement to act?[’No’, ’Yes’]CLS implicit-hate#inferiority_hate For the sentence: \"text\", is it inferiority hate? [’No’, ’Yes’]CLS implicit-hate#stereotypical_hate For the sentence: \"text\", is it a hateful message involving stereotypes?[’No’, ’Yes’]CLS implicit-hate#threatening_hate For the sentence: \"text\", is it hateful in a threatening way?[’No’, ’Yes’]CLS implicit-hate#white_grievance_hate For the sentence: \"text\", is it white grievance hate?[’No’, ’Yes’]CLS intentyn For the sentence: \"text\", is it intentional? [’No’, ’Yes’]CLS jigsaw#identity_hate For the sentence: \"text\", is it identity hate? [’No’, ’Yes’]CLS jigsaw#insult For the sentence: \"text\", is it an insult? [’No’, ’Yes’]CLS jigsaw#obscene For the sentence: \"text\", is it obscene? [’No’, ’Yes’]CLS jigsaw#severe_toxic For the sentence: \"text\", is it severely toxic? [’No’, ’Yes’]CLS jigsaw#threat For the sentence: \"text\", is it a threat? [’No’, ’Yes’]CLS jigsaw#toxic For the sentence: \"text\", is it toxic? [’No’, ’Yes’]CLS offensiveyn For the sentence: \"text\", is it offensive? [’No’, ’Yes’]CLS sexyn For the sentence: \"text\", is it sexist? [’No’, ’Yes’]SPAN toxic-span In the sentence: \"text\", which part of it can be identified as toxic?CLS tweet_offensive For the sentence: \"text\", is it offensive? [’No’, ’Yes’]CLS crowdflower For the sentence: \"text\", what is its emotion? [’empty’, ’sadness’,’enthusiasm’, ’neutral’,’worry’, ’love’, ’fun’,’hate’, ’happiness’,’relief’, ’boredom’,’surprise’, ’anger’]CLS dailydialog For the given conversation, \"text\", what is its emotion? [’no emotion’, ’anger’,’disgust’, ’fear’, ’hap-piness’, ’sadness’,’surprise’]REG emobank#arousal Given the V AD model of emotion, determine the degree of arousal of the given sentence:\"text\". The score should be ranging from 0.0 to 5.0, and can be a decimal.REG emobank#dominance Given the V AD model of emotion, determine the degree of dominance of the given sentence:\"text\". The score should be ranging from 0.0 to 5.0, and can be a decimal.REG emobank#valence Given the V AD model of emotion, determine the degree of valence of the given sentence:\"text\". The score should be ranging from 0.0 to 5.0, and can be a decimal.SPAN emotion-span In the sentence: \"text\", which part of it expresses strong emotion?REG empathy#distress Determine the degree of distress of the given sentence: \"text\". The score should be rangingfrom 0.0 to 7.0, and can be a decimal.CLS empathy#distress_bin For the sentence: \"text\", is it showing distress? [’No’, ’Yes’]PAIR same-side-pairs For the sentences: \"text_a\" and \"text_b\", are they on the same side?[’No’, ’Yes’]CLS sentitreebank For the sentence: \"text\", is it positive? [’Yes’, ’No’]CLS tweet_emoji For the sentence: \"text\", what is the emoji that can be added to it? 20 emojisCLS tweet_emotion For the sentence: \"text\", what is its emotion? [’anger’, ’joy’, ’opti-mism’, ’sadness’]CLS tweet_sentiment For the sentence: \"text\", what is its sentiment? [’negative’, ’neutral’, ’pos-itive’]CLS complaints For the sentence: \"text\", is it a complaint? [’No’, ’Yes’]REG empathy#empathy Determine the degree of empathy of the given sentence: \"text\". The score should be rangingfrom 0.0 to 7.0, and can be a decimal.CLS empathy#empathy_bin For the sentence: \"text\", is it expressing empathy? [’No’, ’Yes’]CLS hayati_politeness For the sentence: \"text\", is it polite? [’No’, ’Yes’]CLS questionintimacy For the sentence: \"text\", how intimate do you think it is? [’Very intimate’, ’Inti-mate’, ’Somewhat inti-mate’, ’Not very intimate’,’Not intimate’, ’Not inti-mate at all’]CLS stanfordpoliteness For the sentence: \"text\", is it polite? [’Yes’, ’No’]CLS bragging#brag_achievement For the sentence: \"text\", is it bragging about an achievement?[’No’, ’Yes’]CLS bragging#brag_action For the sentence: \"text\", is it bragging about an action? [’No’, ’Yes’]CLS bragging#brag_possession For the sentence: \"text\", is it bragging about a possession?[’No’, ’Yes’]CLS bragging#brag_trait For the sentence: \"text\", is it bragging about a trait? [’No’, ’Yes’]CLS hypo-l For the sentence: \"text\", is it a hyperbole? [’No’, ’Yes’]PAIR neutralizing-bias-pairs For the sentences: \"text_a\" and \"text_b\", which one is biased?[’the first sentence is bi-ased’, ’the second sen-tence is biased’]SPAN propaganda-span In the sentence: \"text\", which part of it can be identified as the propaganda?CLS rumor#rumor_bool For the sentence: \"text\", is it a rumor? [’No’, ’Yes’]CLS two-to-lie#receiver_truth For the sentence :\"text\", will it be perceived as a lie by the receiver?[’Yes’, ’No’]CLS two-to-lie#sender_truth For the sentence :\"text\", is the sender intending to tell a lie?[’Yes’, ’No’]\nTable 8: The manually designed prompt questions and options used for each task.\n11396\nType Task Question\nREG hahackathon#humor_rating For the sentence:\"text\", is it humorous?\nREG hahackathon#offense_rating For the sentence:\"text\", is it offensive?\nREG emobank#arousal For the sentence:\"text\", is the presented emotion highly arousal?\nREG emobank#dominance For the sentence:\"text\", is the presented emotion highly dominant?\nREG emobank#valence For the sentence:\"text\", is the presented emotion positive?\nREG empathy#distress For the sentence:\"text\", does it show distress?\nREG empathy#empathy For the sentence:\"text\", does it show empathy?\nTable 9: The manually designed prompt questions for fine-tuning regression tasks over the t5 model.\nhahackathon#is_humor\ntweet_ironyhumor-pairs\nsarc\nhahackathon#humor_rating\nhateoffensive\nhahackathon#offense_rating\njigsaw#toxicjigsaw#insult\njigsaw#obscene\noffensiveyn\ntweet_offensive\nintentyn\nhasbiasedimplicationjigsaw#identity_hate\nimplicit-hate#explicit_hate\ncontextual-abuse#IdentityDirectedAbuse\njigsaw#severe_toxic\nimplicit-hate#implicit_hate\njigsaw#threat\nsexyn\nimplicit-hate#stereotypical_hate\ncontextual-abuse#PersonDirectedAbuse\ntalkdown-pairs\nimplicit-hate#inferiority_hate\nimplicit-hate#white_grievance_hate\nimplicit-hate#incitement_hateimplicit-hate#threatening_hate\ncrowdflower\ntweet_emotion\ntweet_sentiment\nemobank#valence\ntweet_emoji\nemobank#dominance\nsentitreebank\nemobank#arousalempathy#distress\ndailydialog\nempathy#distress_bin\nsame-side-pairs\nempathy#empathy\nquestionintimacyhayati_politeness\ncomplaints\nstanfordpoliteness\nempathy#empathy_binneutralizing-bias-pairs\nrumor#rumor_bool\nbragging#brag_achievement\nhypo-l\nbragging#brag_trait\nbragging#brag_possession\ntwo-to-lie#sender_truthtwo-to-lie#receiver_truth\nbragging#brag_action\nhahackathon#is_humor\ntweet_irony\nhumor-pairs\nsarc\nhahackathon#humor_rating\nhateoffensive\nhahackathon#offense_rating\njigsaw#toxic\njigsaw#insult\njigsaw#obscene\noffensiveyn\ntweet_offensive\nintentyn\nhasbiasedimplication\njigsaw#identity_hate\nimplicit-hate#explicit_hate\ncontextual-abuse#IdentityDirectedAbuse\njigsaw#severe_toxic\nimplicit-hate#implicit_hate\njigsaw#threat\nsexyn\nimplicit-hate#stereotypical_hate\ncontextual-abuse#PersonDirectedAbuse\ntalkdown-pairs\nimplicit-hate#inferiority_hate\nimplicit-hate#white_grievance_hate\nimplicit-hate#incitement_hate\nimplicit-hate#threatening_hate\ncrowdflower\ntweet_emotion\ntweet_sentiment\nemobank#valence\ntweet_emoji\nemobank#dominance\nsentitreebank\nemobank#arousal\nempathy#distress\ndailydialog\nempathy#distress_bin\nsame-side-pairs\nempathy#empathy\nquestionintimacy\nhayati_politeness\ncomplaints\nstanfordpoliteness\nempathy#empathy_bin\nneutralizing-bias-pairs\nrumor#rumor_bool\nbragging#brag_achievement\nhypo-l\nbragging#brag_trait\nbragging#brag_possession\ntwo-to-lie#sender_truth\ntwo-to-lie#receiver_truth\nbragging#brag_action\nHumor & Sarcasm\nOffensiveness\nSentiment & Emotion\nSocial Factors\nTrustworthiness\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nFigure 6: A detailed heatmap of Figure 2 showing task dependency among all task pairs as well as task labels.\nEach value represents the absolute strength of correlation between the true labels of the test set of a specific task\n(columns) and the predictions made on that task using a model trained on a different task (rows).\n11397\nSentence Pairs\nRegression\nClassification\nSocial Factors\nOffensiveness\nEmotion & Sentiment\nHumor & Sarcasm\nTrustworthiness\nNode Legend\nis_humor\nsarc\ntweet_irony\nIdentityDirectedAbuse\nPersonDirectedAbuse\nHasBiasedImplication\nHateOffensive\nexplicit_hate\nimplicit_hate\nstereotypical_hate\nintentyn\nidentity_hate\ninsult\nobscene\nsevere_toxic\ntoxic\noffensiveyn\nsexyn\ntweet_offensive\ncrowdflower\ndailydialog\ndistress_bin\nSentiTreeBank\ntweet_emoji\ntweet_emotion\ntweet_sentiment\ncomplaints\nempathy_bin\nhayati_politeness\nQuestionIntimacy\nStanfordPoliteness\nhypo-l\nrumor_bool\nreceiver_truth\nsender_truth\ndistress\nempathy\ndominance\nhumor_rating\narousal\nsame-side-pairs\nvalence\noffense_rating\nFigure 7: Weighted, undirected graph of model correlations. Each edge between nodes iand jis weighted by the\ncorrelation between predictions from a model fine-tuned on task iand predictions from a model fine-tuned on task\nj, evaluated on the entire SOCKET dataset. Nodes are sized proportionally to their weighted degree and a Yifan Hu\nalgorithm is applied for layout, with minor adjustments for readability. Refer to §B.8 for details on how the pairwise\nscore for each edge was computed. We observe strong positive correlations similar to Figure 2, especially within\nthe Sentiment & Emotion category and the Offensiveness category. We also see that across-category transfers may\nhappen in a negative direction such as hayati_politeness and several Offensiveness tasks.\n11398\nDataset Task name Task type Rand. Maj. Single task Categorywise All tasks\nHumor & Sarcasm\nhahackathon humor_rating REG 0.5 0.5 0.68 0.01 0.67 0.01 0.66 0.03\nhahackathon is_humor CLS 0.49 0.38 0.93 0.00 0.93 0.00 0.91 0.01\nhumor-pairs humor-pairs PAIR 0.50 0.34 0.98 0.00 0.98 0.00 0.97 0.00\ntweet_irony tweet_irony CLS 0.49 0.28 0.80 0.01 0.80 0.00 0.75 0.03\nOffensiveness\ncontextual-abuse IdentityDirectedAbuse CLS 0.35 0.50 0.61 0.02 0.62 0.00 0.63 0.01\ncontextual-abuse PersonDirectedAbuse CLS 0.34 0.50 0.54 0.01 0.55 0.02 0.57 0.02\nhahackathon offense_rating REG 0.5 0.5 0.91 0.01 0.91 0.00 0.92 0.01\nhasbiasedimplication hasbiasedimplication CLS 0.50 0.37 0.86 0.00 0.86 0.00 0.87 0.00\nhateoffensive hateoffensive CLS 0.27 0.27 0.93 0.00 0.95 0.01 0.95 0.01\nimplicit-hate explicit_hate CLS 0.37 0.49 0.72 0.00 0.74 0.01 0.73 0.01\nimplicit-hate implicit_hate CLS 0.47 0.43 0.71 0.01 0.71 0.01 0.69 0.01\nimplicit-hate incitement_hate CLS 0.38 0.49 0.67 0.01 0.68 0.01 0.67 0.00\nimplicit-hate inferiority_hate CLS 0.34 0.50 0.59 0.02 0.59 0.01 0.58 0.02\nimplicit-hate stereotypical_hate CLS 0.37 0.49 0.68 0.01 0.66 0.01 0.68 0.01\nimplicit-hate threatening_hate CLS 0.33 0.50 0.60 0.02 0.64 0.01 0.65 0.04\nimplicit-hate white_grievance_hate CLS 0.39 0.48 0.71 0.01 0.71 0.01 0.71 0.02\nintentyn intentyn CLS 0.47 0.42 0.75 0.00 0.74 0.01 0.74 0.01\njigsaw identity_hate CLS 0.34 0.50 0.79 0.01 0.76 0.01 0.79 0.01\njigsaw insult CLS 0.38 0.49 0.88 0.00 0.87 0.01 0.88 0.01\njigsaw obscene CLS 0.38 0.49 0.90 0.01 0.91 0.00 0.91 0.01\njigsaw severe_toxic CLS 0.34 0.50 0.74 0.01 0.73 0.02 0.71 0.02\njigsaw threat CLS 0.34 0.50 0.85 0.02 0.81 0.04 0.80 0.03\njigsaw toxic CLS 0.41 0.47 0.91 0.00 0.90 0.00 0.91 0.01\noffensiveyn offensiveyn CLS 0.50 0.37 0.82 0.00 0.83 0.01 0.83 0.00\nsexyn sexyn CLS 0.37 0.49 0.80 0.01 0.79 0.00 0.79 0.00\ntalkdown-pairs talkdown-pairs PAIR 0.50 0.33 0.89 0.01 0.88 0.01 0.88 0.00\ntoxic-span toxic-span SPAN 0 0 0.68 0.02 0.65 0.05 0.67 0.05\ntweet_offensive tweet_offensive CLS 0.48 0.42 0.81 0.01 0.81 0.01 0.80 0.00\nSentiment & Emotion\ncrowdflower crowdflower CLS 0.06 0.03 0.24 0.00 0.23 0.01 0.22 0.00\ndailydialog dailydialog CLS 0.07 0.13 0.43 0.04 0.47 0.00 0.47 0.02\nemobank arousal REG 0.5 0.5 0.80 0.02 0.81 0.02 0.79 0.02\nemobank dominance REG 0.5 0.5 0.75 0.02 0.75 0.01 0.73 0.02\nemobank valence REG 0.5 0.5 0.92 0.01 0.92 0.00 0.90 0.01\nemotion-span emotion-span SPAN 0 0 0.96 0.01 0.89 0.00 0.86 0.03\nempathy distress REG 0.5 0.5 0.77 0.01 0.75 0.03 0.72 0.01\nempathy distress_bin CLS 0.50 0.31 0.68 0.01 0.69 0.03 0.65 0.02\nsame-side-pairs same-side-pairs PAIR 0.48 0.35 0.66 0.12 0.70 0.09 0.76 0.05\nsentitreebank sentitreebank CLS 0.50 0.31 0.97 0.00 0.96 0.00 0.96 0.01\ntweet_emoji tweet_emoji CLS 0.04 0.02 0.34 0.00 0.33 0.00 0.33 0.00\ntweet_emotion tweet_emotion CLS 0.24 0.14 0.80 0.01 0.81 0.01 0.80 0.00\ntweet_sentiment tweet_sentiment CLS 0.32 0.22 0.71 0.00 0.71 0.01 0.69 0.01\nSocial Factors\ncomplaints complaints CLS 0.50 0.36 0.92 0.01 0.92 0.00 0.91 0.01\nempathy empathy REG 0.5 0.5 0.70 0.04 0.71 0.03 0.70 0.01\nempathy empathy_bin CLS 0.50 0.33 0.63 0.02 0.62 0.01 0.59 0.03\nhayati_politeness hayati_politeness CLS 0.47 0.41 0.87 0.01 0.87 0.05 0.89 0.03\nquestionintimacy questionintimacy CLS 0.16 0.06 0.49 0.03 0.48 0.02 0.46 0.02\nstanfordpoliteness stanfordpoliteness CLS 0.50 0.36 0.70 0.02 0.71 0.01 0.72 0.02\nTrustworthiness\nbragging brag_achievement CLS 0.36 0.49 0.74 0.01 0.69 0.01 0.76 0.03\nbragging brag_action CLS 0.35 0.50 0.59 0.02 0.57 0.06 0.59 0.04\nbragging brag_possession CLS 0.35 0.50 0.70 0.02 0.66 0.03 0.52 0.03\nbragging brag_trait CLS 0.34 0.50 0.67 0.01 0.59 0.07 0.61 0.04\nhypo-l hypo-l CLS 0.48 0.41 0.74 0.01 0.71 0.01 0.69 0.01\nneutralizing-bias-pairs neutralizing-bias-pairs PAIR 0.50 0.33 0.96 0.01 0.96 0.01 0.96 0.00\npropaganda-span propaganda-span SPAN 0 0 0.22 0.10 0.23 0.03 0.24 0.00\nrumor rumor_bool CLS 0.49 0.39 0.85 0.05 0.78 0.02 0.78 0.05\ntwo-to-lie receiver_truth CLS 0.38 0.49 0.57 0.02 0.57 0.02 0.53 0.01\ntwo-to-lie sender_truth CLS 0.38 0.49 0.58 0.02 0.59 0.03 0.55 0.03\nTable 10: Detailed table of performance scores from comparing single-task vs multi-task trained models in\nSection 6 (refer to Table 3 in Section 6). There are no significant gains from the two multi-task settings in the\nHumor & Sarcasm category, where the tasks in general have low task dependency (ref. Section 5). However, for\nother categories we see several instances of tasks where multi-task trained model have greater performance.\n11399\nPaper/Dataset Title Tasks Reference\nAutomatic Identification and Classification of\nBragging in Social Media\nBragging\n(Achievement)\nJin et al. (2022)\nAutomatic Identification and Classification of\nBragging in Social Media (Jin et al., 2022)\nBragging (Ac-\ntion)\nJin et al. (2022)\nAutomatic Identification and Classification of\nBragging in Social Media\nBragging (Pos-\nsession)\nJin et al. (2022)\nAutomatic Identification and Classification of\nBragging in Social Media\nBragging (Trait) Jin et al. (2022)\nAutomatically Identifying Complaints in Social\nMedia\nComplaints Preo¸ tiuc-Pietro et al.\n(2019)\nIntroducing CAD: the Contextual Abuse Dataset Identity Based\nHate\nVidgen et al. (2021)\nIntroducing CAD: the Contextual Abuse Dataset Individual Hate Vidgen et al. (2021)\nIntroducing CAD: the Contextual Abuse Dataset Group-Based\nHate\nVidgen et al. (2021)\nIntroducing CAD: the Contextual Abuse Dataset Counter Speech Vidgen et al. (2021)\nSentiment Analysis in Text Emotion CrowdFlower (2016)\nDailyDialog: A Manually Labelled Multi-turn Di-\nalogue Dataset\nEmotion Li et al. (2017)\nEmoBank: Studying the Impact of Annotation\nPerspective and Representation Format on Dimen-\nsional Emotion Analysis\nEmotion (Va-\nlence)\nBuechel and Hahn\n(2017)\nEmoBank: Studying the Impact of Annotation\nPerspective and Representation Format on Dimen-\nsional Emotion Analysis\nEmotion\n(Arousal)\nBuechel and Hahn\n(2017)\nEmoBank: Studying the Impact of Annotation\nPerspective and Representation Format on Dimen-\nsional Emotion Analysis\nEmotion (Domi-\nnance)\nBuechel and Hahn\n(2017)\nDetecting Emotion Stimuli in Emotion-Bearing\nSentences\nEmotion Ghazi et al. (2015)\nMeasuring the Language of Self-Disclosure across\nCorpora\nDisturbance Reuel et al. (2022)\nMeasuring the Language of Self-Disclosure across\nCorpora\nEmpathy Reuel et al. (2022)\nSemEval 2021 Task 7: HaHackathon, Detecting\nand Rating Humor and Offense\nHumor Rating Meaney et al. (2021)\n11400\nSemEval 2021 Task 7: HaHackathon, Detecting\nand Rating Humor and Offense\nFunny (boolean) Meaney et al. (2021)\nSemEval 2021 Task 7: HaHackathon, Detecting\nand Rating Humor and Offense\nOffensiveness Meaney et al. (2021)\nSocial Bias Frames: Reasoning about Social and\nPower Implications of Language\nBiased Implica-\ntion\nSap et al. (2020)\nSocial Bias Frames: Reasoning about Social and\nPower Implications of Language\nIntent Sap et al. (2020)\nSocial Bias Frames: Reasoning about Social and\nPower Implications of Language\nOffensiveness Sap et al. (2020)\nSocial Bias Frames: Reasoning about Social and\nPower Implications of Language\nSexism Sap et al. (2020)\nAutomated Hate Speech Detection and the Prob-\nlem of Offensive Language\nOffensive Davidson et al. (2017)\nDoes BERT Learn as Humans Perceive? Under-\nstanding Linguistic Styles through Lexica\nPoliteness Hayati et al. (2021)\nDoes BERT Learn as Humans Perceive? Under-\nstanding Linguistic Styles through Lexica\nPositivity Hayati et al. (2021)\nDoes BERT Learn as Humans Perceive? Under-\nstanding Linguistic Styles through Lexica\nAnger Hayati et al. (2021)\nDoes BERT Learn as Humans Perceive? Under-\nstanding Linguistic Styles through Lexica\nDisgust Hayati et al. (2021)\nDoes BERT Learn as Humans Perceive? Under-\nstanding Linguistic Styles through Lexica\nFear Hayati et al. (2021)\nDoes BERT Learn as Humans Perceive? Under-\nstanding Linguistic Styles through Lexica\nJoy Hayati et al. (2021)\nDoes BERT Learn as Humans Perceive? Under-\nstanding Linguistic Styles through Lexica\nSadness Hayati et al. (2021)\nSemEval-2020 Task 7: Assessing Humor in Edited\nNews Headlines\nFunnier Se-\nquence\nHossain et al. (2020)\nMOVER: Mask, Over-generate and Rank for Hy-\nperbole Generation\nHyperbole Zhang and Wan (2022)\nLatent Hatred: A Benchmark for Understanding\nImplicit Hate Speech\nExplicit Hate ElSherief et al. (2021)\nLatent Hatred: A Benchmark for Understanding\nImplicit Hate Speech\nImplicit Hate ElSherief et al. (2021)\nLatent Hatred: A Benchmark for Understanding\nImplicit Hate Speech\nIncitement ElSherief et al. (2021)\nLatent Hatred: A Benchmark for Understanding\nImplicit Hate Speech\nInferiority ElSherief et al. (2021)\nLatent Hatred: A Benchmark for Understanding\nImplicit Hate Speech\nStereotyping ElSherief et al. (2021)\nLatent Hatred: A Benchmark for Understanding\nImplicit Hate Speech\nThreat ElSherief et al. (2021)\nLatent Hatred: A Benchmark for Understanding\nImplicit Hate Speech\nOffensive ElSherief et al. (2021)\nLatent Hatred: A Benchmark for Understanding\nImplicit Hate Speech\nIrony ElSherief et al. (2021)\nLatent Hatred: A Benchmark for Understanding\nImplicit Hate Speech\nOther Hate ElSherief et al. (2021)\n11401\nToxic Comment Classification Challenge Identity-Based\nHate\nJigsaw (2017)\nToxic Comment Classification Challenge Insult Jigsaw (2017)\nToxic Comment Classification Challenge Obscenity Jigsaw (2017)\nToxic Comment Classification Challenge Severe Toxicity Jigsaw (2017)\nToxic Comment Classification Challenge Threat Jigsaw (2017)\nToxic Comment Classification Challenge Toxicity Jigsaw (2017)\nAutomatically Neutralizing Subjective Bias in Text Bias Pryzant et al. (2020)\nSemEval-2020 Task 11: Detection of Propaganda\nTechniques in News Articles\nPropaganda\nTechnique\nDa San Martino et al.\n(2020)\nQuantifying Intimacy in Language Intimacy Pei and Jurgens (2020)\nDetect Rumors in Microblog Posts Using Propaga-\ntion Structure via Kernel Learning\nRumor Detec-\ntion\nMa et al. (2017)\nOn Classifying whether Two Texts are on the Same\nSide of an Argument\nStance Körner et al. (2021)\nA Large Self-Annotated Corpus for Sarcasm Sarcasm Khodak et al. (2018)\nRecursive Deep Models for Semantic Composi-\ntionality Over a Sentiment Treebank\nSentiment Socher et al. (2013)\nFacilitating the Communication of Politeness\nthrough Fine-Grained Paraphrasing\nPoliteness Fu et al. (2020)\nTalkDown: A Corpus for Condescension Detec-\ntion in Context\nCondescension Wang and Potts (2019)\nSemEval-2021 Task 5: Toxic Spans Detection Toxicity Pavlopoulos et al. (2021)\nSemEval 2018 Task 2: Multilingual Emoji Predic-\ntion\nEmoji Barbieri et al. (2018)\nSemEval-2018 Task 1: Affect in Tweets Emotion Mohammad et al. (2018)\nSemEval-2018 Task 3: Irony Detection in English\nTweets\nIrony Van Hee et al. (2018)\nPredicting the Type and Target of Offensive Posts\nin Social Media\nOffensiveness Zampieri et al. (2019a)\nSemEval-2017 Task 4: Sentiment Analysis in Twit-\nter\nSentiment Rosenthal et al. (2017)\nIt Takes Two to Lie: One to Lie, and One to Listen Sender Truth Peskov et al. (2020)\nIt Takes Two to Lie: One to Lie, and One to Listen Receiver Truth Peskov et al. (2020)\n“So You Think You’re Funny?”: Rating the Hu-\nmour Quotient in Standup Comedy\nHumor Rating Mittal et al. (2021)\nDEBAGREEMENT: A comment-reply dataset for\n(dis)agreement detection in online debates\nStance Pougué-Biyong et al.\n(2021)\nThe CLEF-2021 CheckThat! Lab on Detecting\nCheck-Worthy Claims, Previously Fact-Checked\nClaims, and Fake News\nTrustworthiness Nakov et al. (2021)\nFinding Deceptive Opinion Spam by Any Stretch\nof the Imagination\nDeceipt Ott et al. (2011)\nFinding Deceptive Opinion Spam by Any Stretch\nof the Imagination\nFact Ott et al. (2011)\nA Clustering Approach for Nearly Unsupervised\nRecognition of Nonliteral Language\nNonliteral Lan-\ngauge\nBirke and Sarkar (2006)\nDetecting Community Sensitive Norm Violations\nin Online Conversations\nCommunity\nNorms\nPark et al. (2021)\nCan Machines Learn Morality? The Delphi Exper-\niment\nMoral Judge-\nment\nJiang et al. (2021)\n11402\nSemEval-2019 Task 5: Multilingual Detection of\nHate Speech Against Immigrants and Women in\nTwitter\nHate Speech Basile et al. (2019)\nSemEval-2019 Task 6: Identifying and Categoriz-\ning Offensive Language in Social Media (OffensE-\nval)\nOffensiveness Zampieri et al. (2019b)\nCivilComments Toxicity (Jigsaw, 2019)\nCivilComments Very Toxic (Jigsaw, 2019)\n(Male, Bachelor) and (Female, Ph.D) have differ-\nent connotations: Parallelly Annotated Stylistic\nLanguage Dataset with Multiple Personas\nGender Kang et al. (2019)\n(Male, Bachelor) and (Female, Ph.D) have differ-\nent connotations: Parallelly Annotated Stylistic\nLanguage Dataset with Multiple Personas\nAge Kang et al. (2019)\n(Male, Bachelor) and (Female, Ph.D) have differ-\nent connotations: Parallelly Annotated Stylistic\nLanguage Dataset with Multiple Personas\nCountry Kang et al. (2019)\n(Male, Bachelor) and (Female, Ph.D) have differ-\nent connotations: Parallelly Annotated Stylistic\nLanguage Dataset with Multiple Personas\nPolitical view Kang et al. (2019)\n(Male, Bachelor) and (Female, Ph.D) have differ-\nent connotations: Parallelly Annotated Stylistic\nLanguage Dataset with Multiple Personas\nEducation Kang et al. (2019)\n(Male, Bachelor) and (Female, Ph.D) have differ-\nent connotations: Parallelly Annotated Stylistic\nLanguage Dataset with Multiple Personas\nEthnicity Kang et al. (2019)\nWebis Clickbait Corbus 2017 Clickbait Potthast et al. (2018)\nVU Amsterdam Metaphor Corpus Metaphor Steen et al. (2011)\nMeasuring Sentence-Level and Aspect-Level\n(Un)certainty in Science Communications\nUncertainty Pei and Jurgens (2021)\nDear Sir or Madam, May I Introduce the GY AFC\nDataset: Corpus, Benchmarks and Metrics for For-\nmality Style Transfer\nFormality Rao and Tetreault (2018)\nInternational Survey on Emotion Antecedents and\nReactions\nSentiment Scherer and Wallbott\n(1994)\nShort Jokes Joke Moudgil\nShort Text Corpus with Focus on Humor Detection Joke CrowdTruth (2016)\nHateful Symbols or Hateful People? Predictive\nFeatures for Hate Speech Detection on Twitter\nSexism Waseem and Hovy\n(2016)\nHateful Symbols or Hateful People? Predictive\nFeatures for Hate Speech Detection on Twitter\nRacism Waseem and Hovy\n(2016)\nStudying the Dark Triad of Personality through\nTwitter Behavior\nnarcissism Preo¸ tiuc-Pietro et al.\n(2019)\nStudying the Dark Triad of Personality through\nTwitter Behavior\npsychopathy Preo¸ tiuc-Pietro et al.\n(2019)\nStudying the Dark Triad of Personality through\nTwitter Behavior\nMachiavellianism Preo¸ tiuc-Pietro et al.\n(2019)\nUtterance-level Dialogue Understanding: An Em-\npirical Study\nEmotion Ghosal et al. (2020)\nTable 11: Table of all the datasets considered when curating the SOCKET Benchmark.\n11403",
  "topic": "Benchmark (surveying)",
  "concepts": [
    {
      "name": "Benchmark (surveying)",
      "score": 0.8617420792579651
    },
    {
      "name": "Sarcasm",
      "score": 0.7728574275970459
    },
    {
      "name": "Task (project management)",
      "score": 0.6458836793899536
    },
    {
      "name": "Computer science",
      "score": 0.6431645154953003
    },
    {
      "name": "Natural language processing",
      "score": 0.4548807740211487
    },
    {
      "name": "Dimension (graph theory)",
      "score": 0.42086246609687805
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3926929533481598
    },
    {
      "name": "Cognitive psychology",
      "score": 0.3335307836532593
    },
    {
      "name": "Psychology",
      "score": 0.29475390911102295
    },
    {
      "name": "Linguistics",
      "score": 0.1420217752456665
    },
    {
      "name": "Irony",
      "score": 0.1125679612159729
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I27837315",
      "name": "University of Michigan",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I241749",
      "name": "University of Cambridge",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I12912129",
      "name": "Northeastern University",
      "country": "US"
    }
  ]
}