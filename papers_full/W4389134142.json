{
  "title": "Enhancing Real-World Data Extraction in Clinical Research: Evaluating the Impact of the Implementation of Large Language Models in Hospital Settings",
  "url": "https://openalex.org/W4389134142",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A1995576685",
      "name": "Bin Wang",
      "affiliations": [
        "Tsinghua University",
        "Beijing Tsinghua Chang Gung Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2739959521",
      "name": "Lai Junkai",
      "affiliations": [
        "Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2112128979",
      "name": "Han Cao",
      "affiliations": [
        "Beijing Tsinghua Chang Gung Hospital",
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2170971627",
      "name": "Feifei Jin",
      "affiliations": [
        "Peking University People's Hospital",
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A1932550655",
      "name": "Qiang Li",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2327202564",
      "name": "Mingkun TANG",
      "affiliations": [
        "Beijing Tsinghua Chang Gung Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2054682089",
      "name": "Chen Yao",
      "affiliations": [
        "Clinical Research Institute",
        "Peking University First Hospital",
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A2041386386",
      "name": "Ping Zhang",
      "affiliations": [
        "Beijing Tsinghua Chang Gung Hospital",
        "Tsinghua University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2560688864",
    "https://openalex.org/W4360985704",
    "https://openalex.org/W2591987144",
    "https://openalex.org/W4321606060",
    "https://openalex.org/W4385620388",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W4312220150",
    "https://openalex.org/W4380730737",
    "https://openalex.org/W2608029447",
    "https://openalex.org/W2909425525",
    "https://openalex.org/W4312177796",
    "https://openalex.org/W4311635244",
    "https://openalex.org/W4223481518",
    "https://openalex.org/W4385715881",
    "https://openalex.org/W4303443398",
    "https://openalex.org/W4388487668",
    "https://openalex.org/W4387301543",
    "https://openalex.org/W4385328060",
    "https://openalex.org/W4385242971",
    "https://openalex.org/W2159583324",
    "https://openalex.org/W2015070205",
    "https://openalex.org/W4388049829"
  ],
  "abstract": "<title>Abstract</title> Background The application of artificial intelligence (AI) and large language models (LLMs) in the medical sector has become increasingly common. The widespread adoption of electronic health record (EHR) platforms has created demand for the efficient extraction and analysis of unstructured data, which are known as real-world data (RWD). The rapid increase in free-text data in the medical context has highlighted the significance of natural language processing (NLP) with regard to extracting insights from EHRs, identifying this process as a crucial tool in clinical research. The development of LLMs that are specifically designed for biomedical and clinical text mining has further enhanced the capabilities of NLP in this domain. Despite these advancements, the utilization of LLMs specifically in clinical research remains limited. Objective This study aims to assess the feasibility and impact of the implementation of an LLM for RWD extraction in hospital settings. The primary focus of this research is on the effectiveness of LLM-driven data extraction as compared to that of manual processes associated with the electronic source data repositories (ESDR) system. Additionally, the study aims to identify challenges emerging in the context of LLM implementation and to obtain practical insights from the field. Methods The researchers developed the ESDR system, which integrates LLMs, electronic case report forms (eCRFs) and EHRs. The Paroxysmal Atrial Tachycardia Project, a single-center retrospective cohort study, served as a pilot case. This study involved deploying the ESDR system on the hospital local area network (LAN). Localized LLM deployment utilized the Chinese open-source ChatGLM model. The research design compared the AI-assisted process with manual processes associated with the ESDR in terms of accuracy rates and time allocation. Five eCRF forms, predominantly including free-text content, were evaluated; the relevant data focused on 630 subjects, in which context a 10% sample (63 subjects) was used for assessment. Data collection involved electronic medical and prescription records collected from 13 departments. Results While the discharge medication form achieved 100% data completeness, some free-text forms exhibited data completeness rates below 20%. The AI-assisted process was associated with an estimated efficiency improvement of 80.7% in eCRF data transcription time. The AI data extraction accuracy rate was 94.84%, and errors were related mainly to localized Chinese clinical terminology. The study identified challenges pertaining to prompt design, prompt output consistency, and prompt output verification. Addressing limitations in terms of clinical terminology and output inconsistency entails integrating local terminology libraries and offering clear examples of output format. Output verification can be enhanced by probing the model's reasoning, assessing confidence on a scale, and highlighting relevant text snippets. These measures mitigate challenges that can impede our understanding of the model's decision-making process with regard to extensive free-text documents. Conclusions This research enriches academic discourse on LLMs in the context of clinical research and provides actionable recommendations for the practical implementation of LLMs for RWD extraction. By offering insights into LLM integration in the context of clinical research systems, the study contributes to the task of establishing a secure and efficient framework for digital clinical research. The continuous evolution and optimization of LLM technology are crucial for its seamless integration into the broader landscape of clinical research.",
  "full_text": "Enhancing Real-World Data Extraction in Clinical\nResearch: Evaluating the Impact of the\nImplementation of Large Language Models in\nHospital Settings\nBin Wang \nDepartment of Cardiology, Beijing Tsinghua Changgung Hospital, School of Clinical Medicine, Tsinghua\nUniversity https://orcid.org/0000-0003-0012-9835\nJunkai Lai \nInstitute of Automation, Chinese Academy of Sciences https://orcid.org/0000-0002-2272-3870\nHan Cao \nMedical Data Science Center, Beijing Tsinghua Changgung Hospital, School of Clinical Medicine,\nTsinghua University https://orcid.org/0000-0002-9491-6188\nFeifei Jin \nPeking University People's Hospital https://orcid.org/0000-0002-4991-0158\nQiang Li \nDepartment of Information Administration, School of Clinical Medicine, Tsinghua University\nMingkun Tang \nBeijing Tsinghua Changgung Hospital\nChen Yao \nyaochen@hsc.pku.edu.cn\nPeking University Clinical Research Institute, Peking University First Hospital https://orcid.org/0000-\n0003-4224-5535\nPing Zhang \nzhpdoc@126.com\nDepartment of Cardiology, Beijing Tsinghua Changgung Hospital, School of Clinical Medicine, Tsinghua\nUniversity\nResearch Article\nKeywords: Challenge, Data extraction, Electronic health records, Interoperability, Large language models,\nPrompt\nPosted Date: August 30th, 2024\nDOI: https://doi.org/10.21203/rs.3.rs-3644810/v3\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nAdditional Declarations: The authors declare no competing interests.\n 1/46\nEnhancing the interoperability and transparency of real-world data \nextraction in clinical research: evaluating the feasibility and impact \nof the implementation of the ChatGLM in Chinese hospital settings\nBin Wang1,\n฀, Junkai Lai2,3,฀, Han Cao4,฀, Feifei Jin5,6,7,฀, Qiang Li8, \nMingkun Tang4, Chen Yao9,10,*, Ping Zhang1,*\n1Department of Cardiology, Beijing Tsinghua Changgung Hospital, School of \nClinical Medicine, Tsinghua University, Beijing, China.\n2Institute of Automation, Chinese Academy of Sciences, Beijing, China.\n3Hangzhou LionMed Medical Information Technology Co., Ltd, Hangzhou, \nChina.\n4Medical Data Science Center, Beijing Tsinghua Changgung Hospital, \nSchool of Clinical Medicine, Tsinghua University, Beijing, China.\n5Trauma Medicine Center, Peking University People's Hospital, Beijing, \nChina.\n6Key Laboratory of Trauma Treatment and Neural Regeneration, Peking \nUniversity, Ministry of Education, Beijing, China.\n7National Center for Trauma Medicine of China, Beijing, China.\n8Department of Information Administration, Beijing Tsinghua Changgung \nHospital, School of Clinical Medicine, Tsinghua University, Beijing, China.\n9Peking University Clinical Research Institute, Peking University First \nHospital, Beijing, China.\n10Hainan Institute of Real-World Data, Qionghai, China.\n 2/46\n฀These authors contributed equally.\n 3/46\n*Corresponding Author:\nChen Yao\nPeking University Clinical Research Institute, Peking University First \nHospital, No. 8 Xishiku Street, Xicheng District, Beijing, 100034, China\nTel: +8601066551053\nEmail: yaochen@hsc.pku.edu.cn\nPing Zhang\nDepartment of Cardiology, Beijing Tsinghua Changgung Hospital, School of \nClinical Medicine, Tsinghua University, No. 168 Litang Road, Changping \nDistrict, Beijing, 102218, China\nTel: +8601056118899\nEmail: zhpdoc@126.com\nORCID\nBin Wang http://orcid.org/0000-0003-0012-9835\nJunkai Lai https://orcid.org/0000-0002-2272-3870\nHan Cao https://orcid.org/0000-0002-9491-6188\nFeifei Jin https://orcid.org/0000-0002-4991-0158\nChen Yao https://orcid.org/0000-0003-4224-5535\n 4/46\nTotal number of words in the manuscript: 4944\nNumber of words in the abstract: 233\nNumber of figures: 6\nNumber of tables: 3\nNumber of supplementary figures: 1\nNumber of supplementary tables: 2\nNumber of supplementary documents: 2\n 5/46\nAbstract\nAims\nThis study aims to assess the feasibility and impact of the implementation of \nthe ChatGLM for real-world data (RWD) extraction in hospital settings. The \nprimary focus of this research is on the effectiveness of ChatGLM-driven \ndata extraction compared with that of manual processes associated with the \nelectronic source data repository (ESDR) system.\nMethods and results\nThe researchers developed the ESDR system, which integrates ChatGLM, \nelectronic case report forms (eCRFs) and electronic health records (EHRs). \nThe LLaMA (Large Language Model Meta AI) model was also deployed to \ncompare the extraction accuracy of ChatGLM in free-text forms. A single-\ncenter retrospective cohort study served as a pilot case. Five eCRF forms of \n63 subjects, including free-text forms and discharge medication, were \nevaluated.\nResults\nData collection involved electronic medical and prescription records \ncollected from 13 departments. The ChatGLM-assisted process was \nassociated with an estimated efficiency improvement of 80.7% in the eCRF \ndata transcription time. The initial manual input accuracy for free-text \nforms was 99.59%, the ChatGLM data extraction accuracy was 77.13%, and \nthe LLaMA data extraction accuracy was 43.86%. The challenges associated \nwith the use of ChatGLM focus on prompt design, prompt output \n 6/46\nconsistency, prompt output verification, and integration with hospital \ninformation systems.\nConclusion\nThe main contribution of this study is to validate the use of ESDR tools to \naddress the interoperability and transparency challenges of using ChatGLM \nfor RWD extraction in Chinese hospital settings.\nKeywords: Challenge, Data extraction, Electronic health records, \nInteroperability, Large language models, Prompt\n 7/46\nAbbreviations\nAI: artificial intelligence\nBioBERT: Bidirectional Encoder Representations from Transformers for \nBiomedical Text Mining\nCDISC: Clinical Data Interchange Standards Consortium\neCRF: electronic case report form\nEDC: electronic data capture\nEHRs: electronic health records\nESDR: electronic source data repository\nGPT: generative pretrained transformer\nHIS: hospital information system\nLLaMA: Large Language Model Meta AI\nLLMs: large language models\nNLP: natural language processing\nRAG: retrieval-augmented generation\nRWD: real-world data\n 8/46\nIntroduction\nThe heightened interest in the application of artificial intelligence (AI) and \nlarge language models (LLMs) in the medical sector is the result of the \npotential of such models to enhance various facets of healthcare 1. In the \ncontext of clinical research, prior methodologies in natural language \nprocessing (NLP) have predominantly concentrated on named entity \nrecognition, such as by employing notable models such as bidirectional \nencoder representations from transformers for biomedical text mining \n(BioBERT), to identify entities pertinent to clinical research. Models such as \nBIOBERT 2 represent domain-specific language models that were initially \npretrained on extensive biomedical corpora. However, this methodology \nrequires additional rule-based transformations to generate responses to \nspecific clinical queries. The development of LLMs specifically designed for \nbiomedical and clinical text mining has further enhanced the capabilities of \nNLP in this domain 3. In contrast, contemporary LLMs exhibit a question-\nanswer generative pretrained transformer (GPT) structure with supervised \nfine-tuning. At present, LLMs based on the GPT structure employ dialog for \nboth input and output, in which context the input dialog consists of \nquestions and the output dialog comprises direct answers. This approach \neliminates the need for laborious rule-based transformations, thereby \nstreamlining the process by directly providing responses that are more \ngeneral and adaptable than the named entities previously used. \nAdditionally, large clinical language models such as GatorTron 4, which was \n 9/46\ntrained on extensive clinical text, have been associated with promising \nresults with respect to a variety of clinical NLP tasks, including extracting \nclinical concepts and answering medical questions 5,6. These advancements \nhighlight the opportunities for extracting data from medical free text that \nLLMs offer.\n  Previous studies have extensively demonstrated the use of LLMs for \ninformation extraction tasks such as named entity recognition 7 and \nrelationship extraction 8. Integrating LLMs into hospital systems \nnecessitates addressing data privacy, security, interoperability, data \nmapping, standardization, quality, and scalability issues to comply with \nhealthcare regulations and meet clinical research requirements 9-11. \nHealthcare systems are complex, with a variety of data sources and formats, \nas well as stringent privacy and security requirements 12. The lack of \ninteroperability with electronic health record (EHR) systems prevents LLMs \nfrom accessing raw medical documents directly. Similarly, the absence of \ninteroperability with electronic data capture (EDC) systems means that the \ndata extraction results from LLMs cannot be standardized within the \nstructure of electronic case report forms (eCRFs), rendering them \nunsuitable for direct data analysis. Most importantly, the black-box nature \nof LLMs makes it impossible to verify the reliability of the data extraction \nprocess. These challenges significantly limit the feasibility of using LLMs for \nreal-world data (RWD) extraction in actual healthcare settings.\n 10/46\nThe burden of inconsistencies, missing or incomplete observations, and \nthe presence of noise and outliers in EHR data render them unsuitable for \nresearch purposes 13. The use of EHRs for clinical research is associated \nwith historical progress and current applications, and relevant efforts have \nfocused on using the most recent standards and technologies to facilitate \ndata transfer from EHR systems into clinical research databases, thereby \nimproving data quality 14. The primary challenge in translating data \nbetween EHR systems and clinical research databases, such as EDC \nsystems, is the unstructured nature of EHR source data and a lack of \nmethods for improving data interoperability between these systems. First, \nthe majority of clinically relevant source data are documented as narrative \ntext in EHR systems, which can be inconsistent and noisy due to time \nconstraints and physician documentation practices. Second, in China, the \nstandard for source data usage is limited primarily to the International \nClassification of Diseases codes for diagnoses and procedures, making it \nimpossible to extract EHR source data directly from these coding systems \nwithin EDC systems. To improve interoperability between these systems, we \ncreated a framework that uses a digital product designed to connect EHR \nand EDC systems during the data collection process. This framework aims \nto increase transparency and interoperability. Within this framework, we \nset up ChatGLM to learn from the data collection process, allowing them to \nrespond accurately to research queries on the basis of source data. The \ndigital product is called the electronic source data repository (ESDR) 15-18. It \n 11/46\ncan integrate the source data required for clinical studies and facilitate the \nelectronic transfer of study data from the EHR system to the EDC system.\nThe primary objective of this study is to assess the feasibility and impact \nof the implementation of ChatGLM for RWD extraction within a Chinese \nhospital setting. Specifically, this research aims to evaluate the \neffectiveness of ChatGLM-driven data extraction and traceability functions \ncompared with the manual processes associated with the ESDR. \nAdditionally, the investigation seeks to identify and analyze the challenges \nencountered during the implementation of ChatGLM with the goal of \nobtaining insights from practical experiences in the field.\nMethods\nSystem Design\nThe ESDR interface, as detailed in prior research 15, integrates eCRFs and \nEHRs to promote enhanced traceability and eCRF field highlighting 15. For \nfurther information, please refer to previous studies 16-18. Figure 1 shows \nthe ChatGLM workflow description and the composition of the ESDR \nsystem. The clinical research data extraction pipeline is initialized when \nresearch data requirements are sent from the EDC system via the Clinical \nData Interchange Standards Consortium (CDISC) standards to the ESDR. \nOn the basis of source data samples sent from the EHR, ESDR will bind \ncase report data fields to the most relevant type of data source for later \n 12/46\nusage in the ESDR interface. The interface will visualize eCRFs on the left \nalongside relevant patient source data on the right. Data collection is \ninitialized through the manual entry method, where researchers can \nhighlight relevant source data to be used as answers for eCRF data fields. \nThe manual process is recorded as examples and used to optimize ChatGLM \nprompts via the few-shot learning method. For new data, the ChatGLM first \nfinds relevant text sections from the source data and finds related content \nused to localize medical terminology and understanding via the retrieval-\naugmented generation (RAG) method and combines previous examples to \nincrease inference ability. Supplementary file 1 includes several examples \nof prompts.\nPilot Case Selection\nThe pilot cases were selected on the basis of investigator-initiated clinical \nresearch projects that had been ethically approved in the cardiovascular \nmedicine departments that participated in the pilot collaboration. These \nresearch projects required a formal clinical study protocol as well as an \neCRF. To make the pilot more manageable, only ongoing retrospective \nstudies were considered. The Paroxysmal Atrial Tachycardia Project, a \nsingle-center retrospective cohort study, explores the correlations among \nparoxysmal atrial tachycardia, thromboembolic events and atrial fibrillation. \nBaseline data, including sociodemographic information, medical history, \nmedication history, laboratory results, electrocardiogram data, and other \n 13/46\ntypes of information, were drawn from the EHR system. The eCRF field that \naddresses data extraction from free-text sources was given the highest \nevaluation in this investigation (Supplementary Table 1, Supplementary \nfile 2). In addition, ChatGLM's capacity to identify drug terms as \nstandardized terms was evaluated via structured discharge medication.\nEthical Approval\nThis study was conducted in accordance with the principles of the \nDeclaration of Helsinki and received approval from the Beijing Tsinghua \nChanggung Hospital Institutional Review Board (number 21440-4-03). The \nanonymization of patient data adhered to data safety standards.\nImplementation Process\nBeginning on August 1, 2023, researchers deployed the ESDR system on the \nhospital local area network, which interfaced with the hospital information \nsystem (HIS) to obtain certified copies of patient data. LLM localization \ndeployment utilized the Chinese open-source ChatGLM 19. Researchers \ndesigned questions for each eCRF variable, employing preset questions as \nprompts to encourage the ChatGLM to extract answers from free-text data. \nThrough a 2-week optimization process involving three rounds of fine-\ntuning, technicians enhanced the ChatGLM instructions to ensure optimal \ndata extraction. The LLaMA (Large Language Model Meta AI) model 20 was \n 14/46\nalso deployed to compare and reference the accuracy of ChatGLM's \nextraction in free text across different eCRF fields. \nResearch Design\nThe primary objective of this research was to evaluate the efficacy of the \nChatGLM-driven or LLaMA-driven data extraction and traceability functions \n(the AI-assisted process) of ESDR software compared with those of the \nmanual data collection and verification methods associated with the ESDR \nsystem (the ESDR manual process). The study focused on differences in the \naccuracy rates and time allocation associated with these approaches. Five \neCRF forms (Supplementary Table 1, Supplementary file 2), \npredominantly comprising free-text content, were evaluated; the relevant \ndata focused on 630 subjects.\nDuring the implementation phase, technicians utilized ChatGLM or \nLLaMA for batch processing to extract all patient data. To assess the \nextraction efficacy of ChatGLM or LLaMA, this study subsequently \nemployed traditional manual methods for secondary data extraction. Given \nChatGLM's considerable advantage over traditional manual processes, \nemploying the latter for extracting data from all patients appears \nunnecessary. Instead, a subset comprising 10% of the samples (63 subjects) \nwas selected for comparative assessments of extraction effectiveness.\nConceptually, three processes were considered. The traditional manual \nprocess refers to the method commonly employed by clinical researchers, \n 15/46\nthe ESDR manual process that simplifies manual entry, and the AI-assisted \nprocess that automates data extraction via ChatGLM or LLaMA:\nA. Traditional Manual Process:\na) The EDC and EHR platforms were opened separately.\nb) The clinical research coordinator reviewed EDCs for data fields and \nsubsequently examined EHRs for relevant text, manually completing \nthe EDC.\nB. ESDR Manual Process:\na) Manual Data Entry: Participants utilized ESDR software to input \npatient admission records manually into the ESDR eCRF form and \nfilled in the eCRF forms directly.\nb) Manual Verification: In reference to the ESDR records, the \nparticipants manually traced and verified the eCRF form, correcting \nany input errors. This process allowed for the simultaneous viewing \nof relevant EHRs and EDCs on a single platform, thus facilitating \ndata comparison from left to right.\nC. AI-assisted process:\na) AI Data Entry (Batch Processing): Batch processing codes for AI data \nextraction were configured, and AI data extraction was executed for \nall 63 subjects; the total runtime was recorded. This process filled in \nrelevant eCRF fields directly.\nb) AI-Assisted Data Verification (Traceability Function): Researchers \nvalidated the accuracy of fields filled in by the ChatGLM or LLaMA \n 16/46\nwithin the ESDR software, manually correcting incorrectly entered \nfields via the AI-assisted source data location feature to facilitate \nswift tracing. This feature highlights the relevant medical text used \nto populate eCRF forms.\nThe traditional manual process (Process A) involves manual extraction \nand data entry from separate EDC and EHR platforms and thus represents a \nlabor-intensive and error-prone procedure that contributes to inefficiencies. \nOnce a standard practice, this method has become a bottleneck in research \nefficiency because of its resource-intensive requirements. Therefore, given \nthe substantial time investment required for the implementation of the \ntraditional manual process, we opted not to assess this method.\nTo mitigate bias in the assessment across various researchers, a clinician \nproficient in ESDR software employed two procedures to evaluate the \nsampled patient data. The participants utilized both the ESDR manual \nprocess and the AI-assisted process in two workflows to ensure a \ncomprehensive assessment.\nData Collection\nThe accuracy of eCRF data transcription refers to an assessment of whether \nthe values entered into the eCRF are in line with the corresponding source \ndata from the EHRs. After eliminating errors in the source data, if \nconsistency is confirmed, the eCRF question is considered to have been \ncompleted correctly. Data completeness is defined by the presence of the \n 17/46\nrequired eCRF data within the EHR. If the response \"not mentioned\" or \n\"unknown\" is recorded in the verified eCRF field, incompleteness is \nindicated. To calculate the completeness rate of eCRF fields, the eCRF data \nare exported from the ESDR. ESDR employs audit trials to log all user \nactions related to eCRF completion and modifications, including users and \ntimestamps, which can be retrieved to measure the time spent on eCRF \ncompletion.\nData Analysis\nData analysis was guided by descriptive statistics; Python software (version \n3.11.5) was employed, and plotting methods were selected on the basis of \nthe characteristics of the data distribution.\nResults\nDistribution of data sources\nData were drawn from the EHRs and prescription records of 13 \ndepartments (Figure 2). The top three departments were cardiology \n(36.5%, 23), neurology (22.2%, 14), and the cardiac intensive care unit \n(19.0%, 12).\nData Completeness\n 18/46\nThe discharge medication form achieved 100% data completeness for 123 \neCRF fields. However, for free-text forms, which accounted for 27 eCRF \nfields, six fields presented data completeness rates below 20%; all of these \nfields were from the health status form (Figure 3).\neCRF Data Transcription Time\nFor 63 subjects with 9,450 eCRF fields, the ESDR manual process required \napproximately 48,382 seconds (approximately 13.44 hours) to complete, \nwith an average of 5.12 seconds per field (Table 1). In contrast, the \nChatGLM-assisted process required approximately 22,126 s (approximately \n6.15 h), with an average of 2.34 s per field (Table 2). Considering batch \nprocessing time, the actual amount of human resource time invested was \nonly 9,337 seconds (approximately 2.59 hours), with an average of 0.99 \nseconds per field. The ChatGLM-assisted process was associated with an \nestimated efficiency improvement of 80.7%, thus indicating a significant \nreduction in human labor time. In all fields, including free-text forms and \ndischarge medication, ChatGLM-assisted total time savings were highest \n(87.75%) in the respiratory medicine department and lowest (71.31%) in the \ninternal medicine department (Supplementary Figure 1).\neCRF Data Transcription Quality\nFor the ESDR manual process, the overall accuracy of the initial manual \nentry was 99.08%. In the ChatGLM-assisted process, the overall data \n 19/46\nextraction accuracy rate was 94.84%. The initial manual input accuracy for \nfree-text forms was 99.59%, the ChatGLM data extraction accuracy was \n77.13%, and the LLaMA data extraction accuracy was 43.86% (Table 3). \nFigure 4 shows the mean number of characters in the admission notes for \npatients across departments. Figure 5 and Figure 6 illustrate the accuracy \nof free-text form extraction for the two models by field type and department \ncategory, respectively. The mean number of characters in admission notes \nfor six common internal medicine departments (Respiratory Medicine, \nCardiac Intensive Care Unit, Cardiology, Neurology, Internal Medicine, and \nCardiac Surgery) was greater than 1800 (Figure 4). However, the \nextraction accuracy for free-text forms was less than 78% for ChatGLM and \nless than 47% for LLaMA in the six departments listed above (Figure 6). \nThe extraction accuracy of LLaMA was superior to that of ChatGLM in the \nhypertension, diabetes and coronary heart disease fields. However, in terms \nof vital signs and family history, LLaMA performed worse than ChatGLM did \n(Figure 5).\n  Errors in manually entered fields primarily included numerical entry \nerrors (such as inaccuracies in recording the number of cigarettes smoked, \ndiastolic blood pressure, and frequency of alcohol consumption) and \ninstances of missing responses (resulting from the failure to click on single-\nchoice questions). The ChatGLM data extraction exhibited exceptionally \nhigh accuracy with respect to capturing information related to other family \nhistory, frequency of alcohol consumption, and various vital signs. However, \n 20/46\nsome fields, particularly those related to specific diseases such as coronary \nheart disease, diabetes, and hypertension, were associated with lower \naccuracy rates, thus suggesting potential areas for improvement with \nrespect to understanding localized Chinese clinical terminology and clinical \ncontexts in the ChatGLM-assisted data extraction process (Figure 5). The \nextraction errors for discharge medication identified by ChatGLM were \nrelated primarily to the inability to accurately identify data with similar \nnames for certain medications and reasoning errors in unit conversions for \ndoses taken. The accuracy of the LLaMA in extracting vital signs from three \nfields (systolic blood pressure, diastolic blood pressure, and pulse) was less \nthan 5%, and the errors were mainly in the form of null values returned \nwithout recognition.\nChallenges and Possible Solutions Pertaining to the Use of ChatGLM\nThe challenges associated with the use of ChatGLM focus on prompt design, \nprompt output consistency, prompt output verification, and integration with \nhospital information systems (Supplementary Table 2). The limitations \nregarding the use of professional clinical terminology and potential \ninconsistency in prompt outputs can be addressed by the incorporation of \nlibraries regarding local terminology and the provision of clear examples for \nthe intended output format. To enhance output verification, the model’s \nreasoning can be probed, its confidence in the answer assessed on a scale, \n 21/46\nand relevant text snippets highlighted, thereby mitigating issues related to \nunderstanding the model’s decision-making process in the context of large \nfree-text documents. To increase the interoperability of ChatGLM with \nhealth information systems, the development of tools such as the ESDR \nsoftware used in this study is a recommended strategy.\nDiscussion\nInterpretation of the Research Results\nIn this retrospective study, some study-related free text elements were \nabsent, reflecting inherent limitations in terms of data completeness. EHRs, \nwhich are designed for medical rather than research purposes, pose \nchallenges for retrospective research in terms of data quality, as clinicians \nmay not prioritize research elements in their record-keeping. Therefore, the \ndiscrepancy in the completeness of the eCRF fields arises from the initial \nmedical records being incomplete. Since free-text medical records are \ntransmitted intact to ChatGLM or LLaMA for extraction, the results of the \ndata integrity assessment reflect the inherent deficiencies of the medical \nrecords rather than the data extraction process used.\nThe eCRF data transcription time results indicate an 80.7% improvement \nin the ChatGLM-assisted process, a finding that is in line with prior \nresearch 16,17. The batch processing of ChatGLM data extraction requires \nsignificantly less time than does the labor-intensive traditional manual \n 22/46\nprocess. As retrospective research projects become increasingly common, \nthe scalability and cost-effectiveness of batch processing become evident, \nthus emphasizing the substantial value of this approach.\nA comparison of the accuracy of free-text field extraction between LLaMA \nand ChatGLM revealed differences. LLaMA, an exemplary model with \nperformance comparable to that of ChatGPT, exhibits greater accuracy in \nrecognizing disease terms. However, it is less accurate than ChatGLM in \nrecognizing fields such as family history and vital signs. The variation in \naccuracy can be attributed to the fact that the free-text admission records \nare in Chinese, which presents a challenge for the LLaMA model in \nadapting to the recording conventions of the Chinese medical language. \nConversely, the localized Chinese model ChatGLM demonstrates superior \naccuracy. In the overall accuracy comparison of free-text extraction, the \nChatGLM achieved 77.13%, whereas the LLaMA model reached only \n43.86%. Owing to restrictions on the transfer of Chinese medical data from \nhospitals, open-source medical LLMs trained on such data are not yet \nviable. Consequently, ChatGLM was selected as the primary model for this \nstudy, as the differences in language, styles, and information systems \npreclude the deployment of high-performing open-source models such as \nLLaMA, which are unable to achieve optimal performance in the Chinese \nmedical environment.\nA comparative analysis of the extraction accuracy of ChatGLM for free-\ntext fields across different departments revealed a negative correlation \n 23/46\nbetween the length of the admission record and the extraction accuracy. \nThis is because the admission records of inpatients in internal medicine \ndepartments are typically more complex and longer than those in surgical \ndepartments. The efficiency improvement of ChatGLM-Assisted is \ndetermined primarily by the time spent on data traceability and correction \nvia ESDR, resulting in an inverse relationship between the efficiency \nimprovement and extraction accuracy.\nFurthermore, the study highlights the high accuracy of the optimized \nChatGLM with respect to eCRF data transcription quality. This finding \nensures that the efficiency gains from ChatGLM data extraction do not \ncompromise data quality. The results section addresses challenges \npertaining to ChatGLM data extraction and proposes solutions, thus \ncontributing valuable insights for future research endeavors.\nProcess Improvement\nThe adoption of ChatGLM signifies a transformative shift in free-text data \nextraction, overcoming the constraints of conventional NLP methods. \nChatGLM not only enhances the security of medical data but also leads to a \nsignificant increase in data extraction efficiency, thereby prioritizing clinical \nunderstanding over technical intricacies.\nRegarding safety, conventional NLP methods pose security risks, as \ntechnicians handle patient medical records for the purpose of text \nannotation. In contrast, ChatGLM facilitates prompt design implementation \n 24/46\nwithout requiring direct interaction with EHRs, thus effectively mitigating \nthe risk of data exposure and ensuring secure data extraction.\nUnlike rule-based NLP, which relies on predefined patterns and manual \nrule creation, ChatGLM uses deep learning to understand the nuances and \ncontext of language, thereby offering a more adaptable and efficient \napproach. The primary advantage of this approach lies in the substantial \nreduction in the amount of human labor required for data extraction. \nTraditional NLP methods demand extensive manual effort for rule creation \nand maintenance, whereas ChatGLM autonomously learns from vast \ndatasets, leading to significant cost savings and enabling human resources \nto be directed to more complex tasks.\nMoreover, beyond the transformation of data extraction, ChatGLM plays a \ncrucial role in enhancing safety and communication within the healthcare \ndomain. By minimizing the need for meticulous rule creation and \nmaintenance, ChatGLM facilitates collaboration between technical experts \nand healthcare professionals. In contrast to traditional NLP methods, in \nwhich context technical experts grapple with intricate rule sets, ChatGLM \nallows these actors to focus on correcting and fine-tuning the model. This \nability to learn from extensive datasets reduces the likelihood of rule-based \nerrors and establishes a more reliable process for data extraction from \nEHRs.\nEfficacy of the ESDR System with an Integrated ChatGLM\n 25/46\nIn the past, employing traditional NLP models on a central processing unit \noccasionally required as long as one hour for an eCRF to execute. However, \nthe use of a graphics processing unit to run ChatGLM enables the same task \nto be completed within a few minutes. At present, technicians can simply \nconfigure the ChatGLM question prompts during project deployment, thus \neliminating the need for extensive time investments in labeling text and \nsupervising training. Furthermore, the adoption of ChatGLM enhances the \nreusability of ESDR across various research projects. This approach allows \na limited number of technical personnel to support the development of \nmultiple clinical research projects within the hospital efficiently.\nInnovations of This Study\nThe main contribution of this study is to validate the use of ESDR tools to \naddress the interoperability and transparency challenges of using ChatGLM \nfor RWD extraction in Chinese hospital settings. ESDR tools integrate EHR \nsource data and eCRF study data interfaces to achieve interoperability \nbetween ChatGLM and both systems. ChatGLM extracts study data from \nEHR source data and electronically populates it into the eCRF for \ninteroperability. By tracing study data back to the corresponding medical \nrecords, the ESDR tool addresses interoperability and transparency issues \nin assessing the reliability of ChatGLM extraction results.\nComparisons with Similar Work\n 26/46\nLee et al. demonstrated that the performance of a privacy-preserving \nFastChat-T5 is promising with respect to the automatic answering of \nmedical questions on the basis of an evaluation of 84 thyroid cancer \nsurgical pathology reports 21. Chiang et al. discussed GPT-2 models that had \nbeen finetuned on clinical notes regarding the accurate extraction of \nheadache frequency from EHRs 22. The study by Ge et al. compared the use \nof Versa GPT-4, implemented in a protected health information-compliant \nmanner, with manual chart review to extract eight data elements from \nelectronic medical records related to hepatocellular carcinoma 23. Notably, \nthese investigations focused primarily on the stage of theoretical evaluation \nand testing, thus highlighting a substantial gap pertaining to the practical \napplication of LLMs in clinical research projects.\nImplications for Future Research\nTo improve the accuracy of ChatGLM-driven data extraction, researchers \nhave proposed the use of a multiround processing approach. Multiple \nrounds of processing enable the ChatGLM to detect and correct its own \nerrors, resulting in more consistent and accurate data extraction 24. The \neffectiveness of ChatGLM could be improved by incorporating RAG \ntechniques. The RAG algorithm combines the generative capabilities of \nChatGLM with the precision of information retrieval, allowing the model to \naccess a medical knowledge database and retrieve relevant information as \n 27/46\nneeded 25. This approach can address the model's medical knowledge gaps \nand improve its ability to handle localized clinical terms.\n  The success of the ESDR system with ChatGLM integration highlights \npossible avenues for future research on the optimization of data extraction \nand traceability in clinical settings. In the future, this study's insights can \nguide the use of ESDR tools featuring ChatGLM to conduct prospective \nclinical research, expanding the application scenarios of such tools to \nencompass clinical trials. Further studies could explore the scalability of the \nsystem across different healthcare institutions, assess its adaptability to \nvarious types of medical specialty research, and investigate the \ngeneralizability of ChatGLM-driven data extraction in diverse research \nscenarios.\n  Finally, the impact of long-term use of ChatGLM in healthcare settings on \npatient outcomes and data integrity needs to be evaluated in detail. The \npotential benefits of ChatGLM to healthcare systems are considerable, with \nthe ability to guide initial medical record entries, enhance data integrity, \nand manage data quality at the source. By ensuring the accurate capture of \ninformation from the outset, ChatGLM could assist in reducing errors and \ninconsistencies in medical records, which are crucial for reliable research \nand patient care. Its ability to identify critical adverse events from medical \nrecords could facilitate early detection and timely implementation of \ninterventions, thereby preventing complications and reducing hospital \nreadmissions. Healthcare professionals could be supported in their decision-\n 28/46\nmaking by detailed data summaries provided by ChatGLM, which would \nhighlight essential patient information and trends, facilitating more \ninformed decisions. The ability of ChatGLM to analyze large datasets \nrapidly could facilitate the development of personalized treatment plans, the \nprediction of treatment responses, and the optimization of therapeutic \noutcomes. Furthermore, continuous quality improvement initiatives in \nhealthcare settings could benefit from ChatGLM's real-time data \nmonitoring, which would identify areas for enhancement and ensure \nadherence to evidence-based guidelines.\nLimitations\nThe study is conducted within a single center. The impact of ChatGLM could \nvary across different healthcare settings. This study is further constrained \nby the scope of the knowledge input into the model, and as such, it does not \ncomprehensively address the challenge of enhancing prompt design. \nInstead, this research utilized a limited set of terminology specific to the \ngiven hospital and specialty departments. To advance the model's \nunderstanding of the clinical context and terminology related to the specific \nhospital, it is crucial to integrate a broader and more comprehensive source \nof terminology drawn from the local unified medical language system 26, \nsuch as the Chinese Hospital Information Management Association \nterminology dataset 27.\n 29/46\nConclusions\nThe main contribution of this study is to validate the use of ESDR tools to \naddress the interoperability and transparency challenges of using ChatGLM \nfor RWD extraction in Chinese hospital settings. The overall data extraction \naccuracy of ChatGLM in free-text fields is greater than that of the LLaMA \nmodel, suggesting that a localized model of LLMs adapted to the language \nof medical records should be chosen for implementation. However, \nChatGLM shows a decrease in data extraction accuracy and time savings as \nthe complexity increases with the length of the medical-free text.\nAcknowledgments\nWe sincerely thank Hangzhou LionMed Medical Information Technology \nCo., Ltd., for its strong support of our research.\nFunding\nThis work was supported by the Real-World Study Project of the Hainan \nBoao Lecheng Pilot Zone (Real-World Study Base of NMPA) (No. \nHNLC2022RWS017).\nConflict of interest: None declared.\n 30/46\nData availability\nThe datasets used and/or analyzed during the current study are available \nfrom the corresponding author upon reasonable request.\nReferences\n1. Arora A, Arora A. The promise of large language models in health care. \nLancet 2023;401:641.\n2. Lee J, Yoon W, Kim S, Kim D, Kim S, So CH , et al.  BioBERT: a pre-\ntrained biomedical language representation model for biomedical text \nmining. \nBioinformatics 2020;36:1234-1240.\n3. Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW , et al.  Large \nlanguage models encode clinical knowledge. Nature 2023;620:172-180.\n4. Yang X, Chen A, PourNejatian N, Shin HC, Smith KE, Parisien C , et al. \nA large language model for electronic health records. NPJ Digit Med \n2022;5:194.\n5. Skalidis I, Cagnina A, Fournier S. Performance of artificial intelligence \nin answering cardiovascular textual questions. \nEur Heart J Digit Health \n2023;4:364-365.\n6. Skalidis I, Cagnina A, Fournier S. Use of large language models for \nevidence-based cardiovascular medicine. \nEur Heart J Digit Health \n2023;4:368-369.\n 31/46\n7. Wang S, Sun X, Li X, Ouyang R, Wu F, Zhang T , et al. Gpt-ner: Named \nentity recognition via large language models. arXiv preprint \narXiv:2304.10428 2023.\n8. Zhou H, Li M, Xiao Y, Yang H, Zhang R. LEAP: LLM instruction-example \nadaptive prompting framework for biomedical relation extraction. \nJournal of \nthe American Medical Informatics Association 2024.\n9. Wiest IC, Ferber D, Zhu J, van Treeck M, Meyer SK, Juglan R , et al.  \nFrom Text to Tables: A Local Privacy Preserving Large Language Model for \nStructured Information Retrieval from Medical Documents. \nmedRxiv \n2023:2023.2012.2007.23299648.\n10. Chen S, Savova GK, Bitterman DS. Considerations for Prompting Large \nLanguage Models—Reply. \nJAMA Oncology 2024;10:538-539.\n11. Denecke K, May R, Rivera Romero O. Potential of Large Language \nModels in Health Care: Delphi Study. \nJ Med Internet Res 2024;26:e52399.\n12. Shahnaz A, Qamar U, Khalid A. Using Blockchain for Electronic Health \nRecords. \nIEEE Access 2019;7:147782-147795.\n13. Jin F, Yao C, Yan X, Dong C, Lai J, Li L , et al. Gap between real-world \ndata and clinical research within hospitals in China: a qualitative study. BMJ \nOpen 2020;10:e038375.\n14. Nordo AH, Levaux HP, Becnel LB, Galvez J, Rao P, Stem K , et al. Use of \nEHRs data for clinical research: Historical progress and current applications. \nLearn Health Syst 2019;3:e10076.\n 32/46\n15. Wang B, Lai J, Jin F, Liao X, Zhu H, Yao C. Clinical Source Data \nProduction and Quality Control in Real-world Studies: Proposal for \nDevelopment of the eSource Record System. \nJMIR Res Protoc \n2022;11:e42754.\n16. Wang B, Lai J, Liu M, Jin F, Peng Y, Yao C. Electronic Source Data \nTranscription for Electronic Case Report Forms in China: Validation of the \nElectronic Source Record Tool in a Real-world Ophthalmology Study. \nJMIR \nForm Res 2022;6:e43229.\n17. Wang B, Hao X, Yan X, Lai J, Jin F, Liao X , et al. Evaluation of the clinical \napplication effect of eSource record tools for clinical research. BMC Med \nInform Decis Mak 2022;22:98.\n18. Wang B, Lai J, Liao X, Jin F, Yao C. Challenges and Solutions in \nImplementing eSource Technology for Real-World Studies in China: \nQualitative Study Among Different Stakeholders. \nJMIR Formative Research \n2023;7:e48363.\n19. Zeng A, Liu X, Du Z, Wang Z, Lai H, Ding M , et al. Glm-130b: An open \nbilingual pre-trained model. arXiv preprint arXiv:2210.02414 2022.\n20. Touvron H, Lavril T, Izacard G, Martinet X, Lachaux M-A, Lacroix T , et \nal. LLaMA: Open and Efficient Foundation Language Models. ArXiv \n2023;abs/2302.13971.\n21. Lee DT, Vaid A, Menon KM, Freeman R, Matteson DS, Marin MP , et al. \nDevelopment of a privacy preserving large language model for automated \n 33/46\ndata extraction from thyroid cancer pathology reports. medRxiv \n2023:2023.2011.2008.23298252.\n22. Chiang CC, Luo M, Dumkrieger G, Trivedi S, Chen YC, Chao CJ\n, et al. \nA large language model-based generative natural language processing \nframework fine-tuned on clinical notes accurately extracts headache \nfrequency from electronic health records. \nHeadache 2024;64:400-409.\n23. Ge J, Li M, Delk MB, Lai JC. A Comparison of a Large Language Model \nvs Manual Chart Review for the Extraction of Data Elements From the \nElectronic Health Record. \nGastroenterology 2024;166:707-709 e703.\n24. Liu Y, Han T, Ma S, Zhang J, Yang Y, Tian J , et al. Summary of ChatGPT-\nRelated research and perspective towards the future of large language \nmodels. \nMeta-Radiology 2023;1:100017.\n25. Gao Y, Xiong Y, Gao X, Jia K, Pan J, Bi Y , et al.  Retrieval-Augmented \nGeneration for Large Language Models: A Survey. ArXiv \n2023;abs/2312.10997.\n26. Bodenreider O. The Unified Medical Language System (UMLS): \nintegrating biomedical terminology. \nNucleic Acids Res 2004;32:D267-270.\n27. Zhang Y, Xu Y, Shang L, Rao K. An investigation into health informatics \nand related standards in China. \nInt J Med Inform 2007;76:614-620.\n 34/46\nFigure 1 Composition of the electronic source data repository (ESDR) \nsystem and description of the prompt design. \neCRF: electronic case report form\nEDC: electronic data capture\nEHRs: electronic health records\nESDR: electronic source data repository\nRAG: retrieval-augmented generation\nCDISC: Clinical Data Interchange Standards Consortium\nFigure 2 Distribution of departments from which the patient data were \ndrawn. The percentages and numbers of patients in different departments \nare listed in the legend.\nFigure 3 Data completeness across different fields in the free-text forms for \nall patients. (Note: The phrase \"free-text forms\" refers to the overall \ncategory, including four forms: lifestyle and behavior, family history, health \nstatus, and vital signs.)\n 35/46\nFigure 4 The mean number of characters in the admission notes of patients \nfrom different departments.\nFigure 5 The accuracy of ChatGLM or LLaMA data extraction from \ndifferent fields of the free-text forms for all patients.\nFigure 6 The mean accuracy of ChatGLM or LLaMA in extracting data from \nfree-text forms of patients across different departments.\nSupplementary Figure 1 The percentage of time saved by ChatGLM-\nAssisted compared with manual processes from three field types for \npatients in various departments.\n 36/46\nTable 1 Time consumption associated with the ESDR manual process\neCRF Form \nName\nManual Data \nEntry Time (in \nseconds)\nManual Verification \nTime (in seconds)\nTotal (in \nseconds)\nDischarge \nMedication\n12,847 8,883 21,730\nFree-Text \nForms\n15,031 11,621 26,652\nTotal 27,878 20,504 48,382\nNote: The phrase \"free-text forms\" refers to the overall category, which \nincludes 4 forms: lifestyle and behavior, family history, health status, and \nvital signs.\neCRF: electronic case report form\nESDR: Electronic Source Data Repository\n 37/46\nTable 2 Time consumption associated with the ChatGLM-assisted \nprocess\nProcess Time (in \nseconds)\nBatch Processing (Free-Text Forms + Discharge \nMedication)\n12,789\nChatGLM-Assisted Data Traceability (Free-Text Forms) 6,586\nChatGLM-Assisted Data Traceability (Discharge \nMedication)\n2,751\nTotal 22,126\n 38/46\nTable 3 Comparison of accuracy rates with respect to initial data entry or extraction between the two \nprocesses\nForm Name Single-\nPerson \neCRF \nFields\nTotal \nFields\nManual Entry \nVerification \n(Corrected \nFields)\nManual \nData Entry \nAccuracy \n(%)\nChatGLM-\nAssisted Data \nTraceability \n(Corrected \nFields)\nChatGLM \nExtraction \nAccuracy \n(%)\nLLaMA-\nAssisted Data \nTraceability \n(Corrected \nFields)\nLLaMA \nExtraction \nAccuracy \n(%)\nDischarge \nMedication\n123 7749 80 98.97 99 98.72 - -\nFree-Text \nForms\n27 1701 7 99.59 389 77.13 955 43.86\nTotal 150 9450 87 99.08 488 94.84 - -\neCRF: electronic case report form\nLLaMA: Large Language Model Meta AI\n 39/46\nSupplementary Table 1 Data sources for the eCRF data \nvariables and extraction methods using the ESDR.\neCRF Research \nVariable\nData Sources Source \nData \nRecord \nType\nExtractio\nn Method\nLifestyle and Behavior\n Smoking Status\n Number of \nCigarettes Smoked\n Duration of \nSmoking\n Alcohol \nConsumption \nStatus\n Duration of \nAlcohol \nConsumption\n Frequency of \nAlcohol \nConsumption\nAdmission notes \n(Smoking/drinkin\ng history)\nFree text ChatGLM \nor LLaMA\nFamily History\n Family History\nAdmission notes \n(Family History)\nFree text ChatGLM \nor LLaMA\n 40/46\n Family History of \nHypertension\n Family History of \nCoronary Heart \nDisease\n Family History of \nStroke\n Family History of \nDiabetes\n Family History of \nChronic Kidney \nDisease\n Family History of \nSudden Death\n Other Family \nHistory\nHealth Status\n Hypertension\n Coronary Heart \nDisease\n Heart Valve \nDisease\n Heart Failure\nAdmission notes \n(Past history, \ncurrent history, \nphysical \nexamination, \nadmission \ndiagnosis)\nFree text ChatGLM \nor LLaMA\n 41/46\n Stroke/Transient \nIschemic Attack\n Thyroid \nDysfunction\n Diabetes\n Chronic \nObstructive \nPulmonary \nDisease\n Obstructive Sleep \nApnea\n Kidney Disease\nVital Signs\n Systolic Blood \nPressure\n Diastolic Blood \nPressure\n Pulse\nAdmission notes \n(physical \nexamination)\nFree text ChatGLM \nor LLaMA\nDischarge \nMedication*\n Anticoagulant \nDrugs\n Proton Pump \nInhibitors (PPIs)\nHIS system \n(doctor's order)\nStructure\nd\nChatGLM\n 42/46\n Lipid-Lowering \nDrugs\n Beta-Blockers\n Angiotensin-\nConverting \nEnzyme Inhibitors\n Angiotensin II \nReceptor Blockers\n Spironolactone\n Calcium Channel \nBlocker Drugs\n Sacubitril/Valsarta\nn\n* Note: The table shows only the drug category, not the specific \ndrug name. For the discharge medication form, each specific drug \nis associated with three fields: \"whether to take the drug\", \"drug \ndosage\" and \"drug frequency\".\neCRF: electronic case report form\nESDR: Electronic Source Data Repository\nLLaMA: Large Language Model Meta AI\nHIS: hospital information system\n 43/46\nSupplementary Table 2 Challenges and possible solutions \npertaining to the use of ChatGLM.\nTheme Challenge Solution\nPrompt Design Inability to use \nprofessional \nclinical \nterminology, as \nthe ChatGLM may \nnot recognize \nlocal synonyms.\nUtilize local terminology \nlibraries to enhance \nprompts with similar terms; \nincorporate Chinese \nmedical literature to \nprovide context, specifically \nfor major adverse \ncardiovascular events.\nPrompt Output \nConsistency\nLack of \nconsistency in the \nformat and \nanswers \ngenerated by the \nmodel; running \nthe model \nmultiple times \nyields varying \noutputs.\nProvide clear examples of \nthe intended output format; \nimplement a voting \nstructure by querying the \nmodel multiple times and \nselecting the most frequent \noutput to promote enhanced \nconsistency.\nPrompt Output \nVerification\nDifficulty \nverifying outputs \nefficiently due to \nAsk the model to elucidate \nthe reasoning underlying its \nanswer; assess its \n 44/46\na lack of \nunderstanding of \nthe model's \nreasoning, \nconfidence levels, \nand ability to \nlocate relevant \ntext in large free-\ntext documents.\nconfidence level on a scale \nbased on the reasoning thus \nprovided; highlight relevant \ntext snippets used in the \nmodel's reasoning.\nData Security \nand Privacy\nEnsuring \nadherence to \nregulatory \nstandards \npertaining to the \nprotection of \nsensitive patient \ndata.\nDeploying ChatGLM on the \nhospital local area network \nis the most effective \nsolution.\nData \nIntegration\nIntegrating \ndisparate data \nsources from \nhospital systems \n(EHR, lab results, \nimaging, etc.).\nIt is advised that the \nhospital set up a distinct \nplatform for data \nintegration, using \nstandardized protocols \n(such as Health Level 7 and \nfast healthcare \n 45/46\ninteroperability resources) \nto harmonize data formats \nand enable smooth \nintegration between in-\nhospital information \nsystems. ChatGLM can be \nused to perform data \nextraction after the \nnecessary source data for \nthe study has been \nincorporated into the data \nintegration platform.\nInteroperability Ensure \ninteroperability of \nChatGLM in \nextracting data \nfrom healthcare \ninformation \nsystems\nMiddleware tools can be \ndeveloped to integrate \nsource data in EHR systems \nwith structured data in \neCRFs. The use of ChatGLM \ns in middleware tools to \nhighlight the source of the \nresearch data can enhance \ninteroperability and \nfacilitate the validation of \nthe reasoning of ChatGLM \n 46/46\nin the data extraction \nprocess.\nFigures\nFigure 1\nComposition of the electronic source data repository (ESDR) system and description of the prompt\ndesign.\nFigure 3\nData completeness across different \u0000elds in the free-text forms for all patients. (Note: The phrase \"free-\ntext forms\" refers to the overall category, including four forms: lifestyle and behavior, family history,\nhealth status, and vital signs.)\nFigure 4\nThe mean number of characters in the admission notes of patients from different departments.\nSupplementary Files\nThis is a list of supplementary \u0000les associated with this preprint. Click to download.\nSupplementary\u0000le2PartelectronicCaseReportForm.docx\nGraphicalAbstract.png\nSupplementaryFigure1.png",
  "topic": "Context (archaeology)",
  "concepts": [
    {
      "name": "Context (archaeology)",
      "score": 0.6445533037185669
    },
    {
      "name": "Software deployment",
      "score": 0.5744588971138
    },
    {
      "name": "Data extraction",
      "score": 0.5562171339988708
    },
    {
      "name": "Computer science",
      "score": 0.5544702410697937
    },
    {
      "name": "Data science",
      "score": 0.520620584487915
    },
    {
      "name": "Unstructured data",
      "score": 0.4656805396080017
    },
    {
      "name": "Information extraction",
      "score": 0.41046640276908875
    },
    {
      "name": "Knowledge management",
      "score": 0.36583560705184937
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3512471914291382
    },
    {
      "name": "Data mining",
      "score": 0.26383811235427856
    },
    {
      "name": "Big data",
      "score": 0.242025226354599
    },
    {
      "name": "MEDLINE",
      "score": 0.23558294773101807
    },
    {
      "name": "Political science",
      "score": 0.16076114773750305
    },
    {
      "name": "Geography",
      "score": 0.1013612449169159
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ]
}