{
  "title": "Hostility Detection in Hindi Leveraging Pre-trained Language Models",
  "url": "https://openalex.org/W3118711678",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A5046454604",
      "name": "Ojasv Kamal",
      "affiliations": [
        "Indian Institute of Technology Kharagpur"
      ]
    },
    {
      "id": "https://openalex.org/A5000966033",
      "name": "Adarsh Kumar",
      "affiliations": [
        "Indian Institute of Technology Kharagpur"
      ]
    },
    {
      "id": "https://openalex.org/A5074163178",
      "name": "Tejas Vaidhya",
      "affiliations": [
        "Indian Institute of Technology Kharagpur"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2972735048",
    "https://openalex.org/W6836189640",
    "https://openalex.org/W3034138372",
    "https://openalex.org/W3004245558",
    "https://openalex.org/W3099919888",
    "https://openalex.org/W3104561523",
    "https://openalex.org/W6600424091",
    "https://openalex.org/W2340954483",
    "https://openalex.org/W4299448294",
    "https://openalex.org/W3153760598",
    "https://openalex.org/W6675354045",
    "https://openalex.org/W3032985518",
    "https://openalex.org/W6628632905",
    "https://openalex.org/W2963943967",
    "https://openalex.org/W3052520363",
    "https://openalex.org/W6637031373",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3029182029",
    "https://openalex.org/W2970971581",
    "https://openalex.org/W3097821138",
    "https://openalex.org/W2951737564",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W3099076442",
    "https://openalex.org/W2964121744",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3030257662",
    "https://openalex.org/W3016888066",
    "https://openalex.org/W3037438699",
    "https://openalex.org/W2789566302",
    "https://openalex.org/W3102007290",
    "https://openalex.org/W3104382433",
    "https://openalex.org/W3029245643",
    "https://openalex.org/W3049021013",
    "https://openalex.org/W2773126195",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W3212777144"
  ],
  "abstract": null,
  "full_text": "arXiv:2101.05494v1  [cs.CL]  14 Jan 2021\nHostility Detection in Hindi leveraging\nPre-Trained Language Models⋆\nOjasv Kamal ⋆⋆, Adarsh Kumar ⋆⋆, and Tejas Vaidhya\nIndian Institute of Technology, Kharagpur, West Bengal, In dia\n{kamalojasv181, adarshkumar712.ak, iamtejasvaidhya}@gmail.com\nAbstract. Hostile content on social platforms is ever increasing. Thi s\nhas led to the need for proper detection of hostile posts so th at appropri-\nate action can be taken to tackle them. Though a lot of work has been\ndone recently in the English Language to solve the problem of hostile\ncontent online, similar works in Indian Languages are quite hard to ﬁnd.\nThis paper presents a transfer learning based approach to cl assify social\nmedia (i.e Twitter, Facebook, etc.) posts in Hindi Devanaga ri script as\nHostile or Non-Hostile. Hostile posts are further analyzed to determine\nif they are Hateful, Fake, Defamation, and Oﬀensive. This pa per har-\nnesses attention based pre-trained models ﬁne-tuned on Hin di data with\nHostile-Non hostile task as Auxiliary and fusing its featur es for further\nsub-tasks classiﬁcation. Through this approach, we establ ish a robust and\nconsistent model without any ensembling or complex pre-pro cessing. We\nhave presented the results from our approach in CONSTRAINT- 2021\nShared Task[21] on hostile post detection where our model pe rforms ex-\ntremely well with 3rd runner up in terms of Weighted Fine-Grained\nF1 Score 1.\nKeywords: Hostility Detection · Pre-trained Models · Natural Lan-\nguage Processing · Social media · Hindi Language\n1 Introduction\nSocial media is undoubtedly one of the greatest innovations of all tim e. From\nconnecting with people across the globe to sharing of information an d knowledge\nin a minuscule of a second, social media platforms have tremendously changed\nthe way of our lives. This is accompanied by an ever-increasing usage of social\nmedia, cheaper smartphones, and the ease of internet access, w hich have further\npaved the way for the massive growth of social media. To put this int o numbers,\nas per a recent report 2, more than 4 billion people around the world now use\nsocial media each month, and an average of nearly 2 million new users a re joining\n⋆ Shared Task in CONSTRAINT 2021\n⋆⋆ Equal Contribution\n1 refer Section 4.3 for description of Weighted Fine-grained f1-score\n2 https://datareportal.com/reports/digital-2020-octob er-global-statshot\n2 Kamal et al.\nthem every day.\nWhile social media platforms have allowed us to connect with others an d\nstrengthen relationships in ways that were not possible before, sa dly, they have\nalso become the default forums for holding high-stakes conversat ions, blasting\npolarizing opinions, and making statements with little regard for thos e within\nthe screenshot. The recent increase in online toxicity instances ha s given rise to\nthe dire need for adequate and appropriate guidelines to prevent a nd curb such\nactivities. The foremost task in neutralising them is hostile post dete ction. So\nfar, many works have been carried out to address the issue in Englis h [18,28]\nand several other languages [2,16]. Although Hindi is the third larges t language\nin terms of speakers and has a signiﬁcant presence on social media p latforms,\nconsiderable research on hate speech or fake content is still quite hard to ﬁnd.\nA survey of the literature suggests a few works related to hostile p ost detection\nin Hindi, such as [9,25]; however, these works are either limited by inade quate\nnumber of samples, or restricted to a speciﬁc hostility domain.\nA comprehensive approach for hostile language detection on hostile posts,\nwritten in Devanagari script, is presented in [1], where the authors have empha-\nsized multi-dimensional hostility detection and have released the dat aset as a\nshared task in Constraint-2021 Workshop. This paper presents a transfer learn-\ning based approach to detect Hostile content in Hindi leveraging Pre -trained\nmodels, with our experiments based on this dataset. The experimen ts are sub-\ndivided into two tasks, Coarse Grained task : Hostile vs. Non-Hostile Classi-\nﬁcation and Fine Grained subtasks : Sub-categorization of Hostile posts into\nfake, hate, defamation, and oﬀensive.\nOur contribution comprises of improvements upon the baseline in the following\nways:\n1. We ﬁne-tuned transformer based pre-trained, Hindi Languag e Models for\ndomain-speciﬁc contextual embeddings, which are further used in Classiﬁcation\nTasks.\n2. We incorporate the ﬁne-tuned hostile vs. non-hostile detection model as an\nauxiliary model, and fuse it with the features of speciﬁc subcategor y models\n(pre-trained models) of hostility category, with further ﬁne-tun ing.\nApart from this, we have also presented a comparative analysis of v arious\napproaches we have experimented on, using the dataset. The cod e and trained\nmodels are available at this https url 3\n3 https://github.com/kamalojasv181/Hostility-Detection-in-Hindi-Posts.git\nHostility Detection in Hindi leveraging Pre-Trained Langu age Models 3\n2 Related Work\nIn this section, we discuss some relevant work in NLP for Pre-Traine d Model\nbased Text Classiﬁcation and Hostile Post Detection, particularly in t he Indian\nLanguages.\nPretrained-Language Models in Text Classiﬁcation\nPre-trained transformers serve as general language understa nding models that\ncan be used in a wide variety of downstream NLP tasks. Several tra nsformer-\nbased language models such as GPT [23], BERT [5], RoBERTa [14], etc. ha ve\nbeen proposed. Pre-trained contextualized vector representa tions of words, learned\nfrom vast amounts of text data have shown promising results in the task of\ntext classiﬁcation. Transfer learning from these models has prove n to be par-\nticularly useful in tasks where there is a lack of undisputed labeled da ta and\nthe inability of surface features to capture the subtle semantics in the text as\nin the case of hate speech [15]. However, all these pre-trained mod els require\nlarge amounts of monolingual corpus to train on. Nonetheless, Ind ic-NLP [11]\nand Indic-Transformers [8] have curated datasets, trained emb eddings, and cre-\nated benchmarks for classiﬁcation in multiple Indian languages includin g hindi.\n[10] presented a comparative study of various classiﬁcation techn iques for Hindi,\nwhere they have demonstrated the eﬀectiveness of Pre-trained sentence embed-\nding in classiﬁcation tasks.\nHostile Post Detection\nResearchers have been studying hate speech on social media platf orms such as\nTwitter [29], Reddit [17], and YouTube [19] in the past few years. Furt hermore,\nresearchers have recently focused on the bias derived from the h ate speech train-\ning datasets [3]. Among other notable works on hostility detection, D avidson\net al. [4] studied the hate speech detection for English. They argue d that some\nwords might reﬂect hate in one region; however, the same word can be used\nas a frequent slang term. For example, in English, the term ‘dog’ doe s not re-\nveal any hate or oﬀense, but in Hindi (ku ##a) is commonly referred to as a\nderogatory term in Hindi. Considering the severity of the problem, s ome eﬀorts\nhave been made in Non-English languages as well [16,2,7,25]. Bhardwaj et al. [1]\nproposed a multi-dimensional hostility detection dataset in Hindi whic h we have\nfocused on, in our experiments. Apart from this, there are also a f ew attempts\nat Hindi-English code-mixed hate speech [26].\n3 Methodology\nIn the following subsections, we brieﬂy discuss the various methodo logies used\nin our experiments. Each subsection describes an independent app roach used\nfor classiﬁcation and sub-classiﬁcation tasks. Our ﬁnal approach is discussed in\nSection 3.4.\n4 Kamal et al.\n3.1 Single Model Multi-Label Classiﬁcation\nIn this approach, we treat the problem as a Multi-label classiﬁcation task. We\nuse a single model with shared parameters for all classes to captur e correla-\ntions amongst them. We ﬁne tuned the pre-trained BERT transfor mer model to\nget contextualized embedding or representation by using attentio n mechanism.\nWe experimented with three diﬀerent versions of pre-trained BERT transformer\nblocks, namely Hindi BERT(a compressed form of BERT)[6], Indic BER T(based\non the ALBERT architecture)[11], and a HindiBERTa model[24]. The loss func-\ntion used in this approach can be formulated mathematically as:\nL(ˆy, y ) = −\nc∑\nj=1\nyj log ˆyj + (1 − yj)log(1 − ˆyj )\nJ(W (1), b (1), ... ) = 1 /m\nm∑\ni=1\nL( ˆyi, y (i))\nwhere, c is total number of training examples and m is number of diﬀerent\nclasses (i.e. non-hostile, fake, hate, defamation, oﬀensive)\n3.2 Multi-Task Classiﬁcation\nIn this approach, we considered the classiﬁcation tasks as a Multi-t ask Classiﬁ-\ncation problem. As described in Figure 1(a), we use a shared BERT mo del and\nindividual classiﬁer layers, trained jointly with heuristic loss. This is do ne so as\nto capture correlations between tasks and subtasks in terms of c ontextualized\nembeddings from shared BERT model while maintaining independence in classi-\nﬁcation tasks. We experimented with Indic-BERT and HindiBERTa (we dropped\nthe Hindi BERT model in this approach as the performance was poor compared\nto the other two models because of shallow architecture). The heu ristic loss can\nbe formulated mathematically as:\nL = l(x, y ) = {l1, ..., l N }T\nwhere,\nln = − wn[yn ·logσ (xn) + (1 − yn) ·log(1 − σ(xn))]\nLtotal = L(hostile/non− hostile) + λ ·1/N {L(hurt,defame,fake,offensive )}\nif post is Hostile λ = 0 . 5 (contributing to ﬁne grain task ), otherwise λ = 0\n3.3 Binary Classiﬁcation\nUnlike the previous two approaches, here we consider each classiﬁc ation task as\nan individual binary classiﬁcation problem based on ﬁne tuned contex tualised\nembedding. We ﬁne tuned the BERT transformer block and the class iﬁer layer\nHostility Detection in Hindi leveraging Pre-Trained Langu age Models 5\nabove it using the binary target labels for individual classes. Same as in Multi-\ntask approach, we experimented this approach with Indic-BERT an d HindiB-\nERTa. Binary cross-entropy loss used in this approach can be math ematically\nformulated as follows:\nLi(ˆy, y ) = −\nc∑\nj=1\nyj log ˆyj + (1 − yj )log(1 − ˆyj )\nwhere, c is total number of training examples and i is number of independent\nmodels for each task\n3.4 Auxiliary Task Based Binary Sub-Classiﬁcation\nSimilar to the previous approach, each classiﬁcation task is consider ed as an\nindividual binary classiﬁcation problem. However, as an improvement over the\nprevious approach, we treat the coarse-grained task as an Auxilia ry task and\nthen fuse its logits to each of the ﬁne-grained subtasks. The motiv ation is that\na hostile sub-class speciﬁc information shall be present in a post only if the post\nbelongs to hostile class[12]. So, treating it as an Auxiliary task allow us t o exploit\nadditional hostile class-speciﬁc information from the logits of Auxiliar y model.\nThe loss function used in this case was same as described in Binary Clas siﬁcation.\nThe model is described in Figure 1(b).\nHurt \nspeech \nclassiﬁer\nFake news \nclassiﬁer\nInput Text \nDefamation \nclassiﬁer\nClassiﬁer \ncourse \ngrain \nOﬀensive \nclassiﬁer\nBERT \n(Shared) \n(a)\nLinear \nLinear\nDetach \nconc \nBERT \n(ﬁne grain) \nﬁne grain \nhostile \nclasses BERT \n(coarse \ngrain) \nInput Text \n(b)\nFig. 1.(a) Multi-Task Classiﬁcation Model (b)Auxiliary Task Base d Binary sub clas-\nsiﬁcation model.\n4 Experiment\nIn this section, we ﬁrst introduce the dataset used and then prov ide implemen-\ntation details of our experiments in their respective subsections.\n6 Kamal et al.\n4.1 Dataset Description\nAs already mentioned in Section 1, we evaluate our approach based o n the\ndataset proposed in [1]. As described in the dataset paper, the ob jective of the\ntask is a classiﬁcation of posts as Hostile and Non-Hostile and furthe r Multi-\nlabel classiﬁcation of Hostile posts into fake, hate, oﬀensive, and defame classes.\nThe dataset consists of 8192 online posts out of which 4358 samples belong to\nthe non-hostile category, while the rest 3834 posts convey one or more hostile\ndimensions. There are 1638, 1132, 1071, and 810 posts for fake, hate, oﬀensive,\nand defame classes in the annotated dataset, respectively. Same as in the paper\n[1], we split the dataset into 70:10:20 for train, validation, and test, b y ensuring\nthe uniform label distribution among the three sets, respectively.\n4.2 Pre-Processing\nPrior to training models, we perform the following pre-processing st eps:\n• We remove all non-alphanumeric characters except full stop punc tuation\nmarks ( |, ? ) in Hindi, but we keep all stop words because our model trains\nthe sequence of words in a text directly.\n• We replace all user mentions and hashtags with a blank space.\n• We skip emojis, emoticons, ﬂags etc from the posts.\n• We replace the URLs with the string ‘http‘.\n4.3 Experimental Setup\nAll the experiments were performed using Pytorch [20] and Huggin gFace [30]\nTransformers library. As the implementation environment, we used Google Co-\nlaboratory tool which is a free research tool with a Tesla K80 GPU an d 12GB\nRAM. Optimization was done using Adam [13] with a learning rate of 1e-\n5. As discussed earlier in section 3, in our experiments, we used pre- trained\nHindiBert[6], IndicBert[11] and HindiBERTa [24] Models available in Huggin g-\nFace library. Input sentences were tokenized using respective to kenizers for each\nmodel, with maximum sequence length restricted to 200 tokens. We t rained\neach classiﬁer model with a batch size of 16. In all the approaches, we used only\nthe ﬁrst token output provided by each model as input to classiﬁer layer. Each\nclassiﬁer layer has 1 dropout layer with dropout of 0.3 and 1 fully conn ected\nlayer. Each sub-classiﬁcation task (ﬁne grained task) was trained only on the\nhostile labeled examples, i.e. the posts that had at least one label of h ostile\nclass, so as to avoid extreme class-imbalance caused by including non -hostile\nexamples. For the evaluation, we have used weighted f1 score [22] a s a metric for\nmeasuring the performance in both the classiﬁcation tasks. As sug gested in the\nCONSTRAINT-2021 shared task[21], to measure the combined perf ormance of\n4 individual ﬁne-grained sub-tasks together, we have used weight ed ﬁne-grained\nf1 score as the metric, where the weights for the scores of individu al classes are\nthe fraction of their positive examples.\nHostility Detection in Hindi leveraging Pre-Trained Langu age Models 7\nTable 1.Results obtained using various methods and models used. Her e, Baseline: as\ndescribed in the dataset paper [1], MLC: Multi Label Classiﬁcation, MTL: Multitask\nLearning, BC: Binary Classiﬁcation and AUX: Auxiliary Model\nMethod Model Hostile Defamation Fake Hate Oﬀensive Weighte d\nBaseline - 0.8422 0.3992 0.6869 0.4926 0.4198 0.542\nMLC Hindi-BERT 0.952 0.0 0.7528 0.4206 0.5274 0.4912\nIndic-BERT 0.9581 0.3787 0.7228 0.3094 0.5152 0.513\nHindiBERTa 0.9507 0.3239 0.7317 0.4120 0.4106 0.5122\nMTL Indic-BERT 0.9284 0.0513 0.3296 0.0 0.0 0.1260\nHindiBERTa 0.9421 0.31 0.6647 0.2353 0.5545 0.4738\nBC Hindi-BERT 0.9359 0.130 0.7164 0.47698 0.5388 0.5169\nIndic-BERT 0.9520 0.3030 0.757 0.4745 0.5446 0.5618\nHindiBERTa 0.9421 0.2707 0.6596 0.3175 0.6098 0.4960\nAUX Indic-BERT 0.9583 0.42 0.7741 0.5725 0.6120 0.6250\nHindiBERTa 0.9486 0.3855 0.7612 0.5663 0.5933 0.6086\n5 Results\nIn this section, we discuss the results from the diﬀerent approach es proposed\nin section 3. Table 1 summarizes the obtained results for diﬀerent ap proaches,\nalong with the baseline [1]. Since hostile/non-hostile posts are real ph enomenon,\nwe did not perform oversampling and undersampling techniques to ad just class\ndistribution and tried to supply the dataset as realistic as possible. T his was\ndone to avoid overﬁtting (in case of oversampling) and the loss of cr ucial data\n(in case of undersampling). As it’s clear from Table 1, our best model based\non approach described in section 3.4 with Indic-BERT model outperf orms the\nbaseline as well as other approaches in both the tasks, i.e. Coarse G rained Task\nof Hostile vs. Non-Hostile Classiﬁcation and Fine Grained Task of Host ile Sub-\nClassiﬁcation. Moreover, our best model stands as the 3rd runner up in terms\nof Weighted ﬁne grained f1 score in the CONSTRAINT-2021 shared t ask on\nHostile Post detection ( Results can be viewed here 4).\n6 Error Analysis\nAlthough we have received some interesting results, there are cer tain dimensions\nwhere our approach does not perform as expected. Through this section we try to\nbetter understand the obtained f1 scores through some genera l observations and\nsome speciﬁc examples (refer Table 2). Our model did perform comp aratively\nbetter in fake dimension which implies the model was able to capture pa tterns\nin fake samples from dataset to a large extent. However, as can be seen in the\nexample 1, the fake / non-fake classiﬁcation of posts in certain cas es largely\ncontext / knowledge based. Therefore, in absence of any extern al knowledge,\n4 Our team name is Monolith\n8 Kamal et al.\nthe method is quite ineﬃcient, particularly in those kind of samples whic h are\nunder-represented in the dataset. Apart from this, we observe that the defama-\ntion scores are the lowest in general. This could be mainly attributed t o the\noverall under-representation of the class in the dataset. Hence a more balanced\ndataset is critical to boost the defamation f1 score.\nAnother important observation to note is the existence of metaph orical data\nin the dataset, which implies meaning diﬀerent from what semantic info rmation\nis absent. For example, consider example 2 in the Table 2. This tweet h as been\ninspired by the Hindi idiom which means a person after committing ever y sin in\nthe rule book looks to God for atonement and is used to refer to a hy pocritical\nperson indirectly. Such examples lead to mis-classiﬁcation by models w hich are\nprimarily based on contextualized embeddings training on simple datas ets, as\nin our case. However, this could be eliminated if the models are pre-tr ained\n/ ﬁne-tuned on datasets which contain more such examples of meta phorical\nsamples. From our manual inspection, we also observed that the da taset includes\nsome examples, the labels of which are not even apparent to us. For instance,\nconsider example 4. This example simply urges people to speak up and f or some\ncause. Such type of sentence are quite often noticeable in hindi lite rature. It is\nimpossible to conclude that it is an oﬀensive post with the given data. H owever,\nthe fact that it is correctly classiﬁed by our model reﬂects bias in th e dataset with\nrespect to certain kind of examples, against a generalization of the ”Oﬀensive”\ndimension. Apart from this, we also found some examples which, in our opinion\nare labeled incorrectly or are possibly ambiguous to be categorised in dimensions\nbeing considered. Example 5 means we do not want a favour we only as k for\nwhat we deserve which is labeled as defamation however according to us, it\nis ambiguous to classify it into any of the considered dimensions and lar gely\nTable 2. Misclassiﬁed Samples from the dataset\n\nHostility Detection in Hindi leveraging Pre-Trained Langu age Models 9\ndependent on the context. Similarly in example 6, someone is being ref erred as\nku##e which means a dog, according to us it should be hate but is not labeled\nas hate.\n7 Conclusion and Future Work\nIn this paper, we have presented a transfer learning based appro ach leveraging\nthe pre-trained language models, for Multi-dimensional Hostile post detection.\nAs the evaluation results indicate, our ﬁnal approach outperform s baseline, by a\nsigniﬁcant margin in all dimensions. Furthermore, examining the resu lts shows\nthe ability of our model to detect some biases and ambiguities in the pr ocess of\ncollecting or annotating dataset.\nThere is a lot of scope of improvement for ﬁne Grained with few positiv e la-\nbels. Pre-training on relevant data (such as oﬀensive or hate spee ch) is a promis-\ning direction. In case of Fake news detection, it is very diﬃcult to ver ify the\nclaim without the use of external knowledge. In future, we would like to extend\nthe approach purposed in paper [27], by using processed-wikipedia k nowledge it\nis possible to signiﬁcantly improve fake news detection accuracy.\nAcknowledgement\nWe are very grateful for the invaluable suggestions given by Ayush Kaushal. We\nalso thank the organizers of the Shared Task.\nReferences\n1. Bhardwaj, M., Akhtar, M.S., Ekbal, A., Das, A., Chakrabor ty, T.: Hostility detec-\ntion dataset in hindi (2020),\nhttp://arxiv.org/abs/2011.03588\n2. Chowdhury, S.A., Mubarak, H., Abdelali, A., Jung, S.g., J ansen, B.J., Salminen,\nJ.: A multi-platform Arabic news comment dataset for oﬀensi ve language detec-\ntion. In: Proceedings of the 12th Language Resources and Eva luation Conference.\npp. 6203–6212. European Language Resources Association, M arseille, France (May\n2020), https://www.aclweb.org/anthology/2020.lrec-1.761\n3. Davidson, T., Bhattacharya, D., Weber, I.: Racial bias in hate speech and\nabusive language detection datasets. In: Proceedings of th e Third Workshop\non Abusive Language Online. pp. 25–35. Association for Comp utational Lin-\nguistics, Florence, Italy (Aug 2019). https://doi.org/10 .18653/v1/W19-3504,\nhttps://www.aclweb.org/anthology/W19-3504\n4. Davidson, T., Warmsley, D., Macy, M.W., Weber, I.: Automa ted hate speech de-\ntection and the problem of oﬀensive language. CoRR abs/1703.04009 (2017),\nhttp://arxiv.org/abs/1703.04009\n5. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre -training of\ndeep bidirectional transformers for language understandi ng. In: Proceedings\nof the 2019 Conference of the North American Chapter of the As socia-\ntion for Computational Linguistics: Human Language Techno logies, Volume 1\n10 Kamal et al.\n(Long and Short Papers). pp. 4171–4186. Minneapolis, Minne sota (Jun 2019),\nhttps://www.aclweb.org/anthology/N19-1423\n6. Doiron, N.: https://huggingface.co/monsoon-nlp/hindi-bert\n7. Hossain, M.Z., Rahman, M.A., Islam, M.S., Kar, S.: BanFak eNews: A dataset for\ndetecting fake news in Bangla. In: Proceedings of the 12th La nguage Resources and\nEvaluation Conference. pp. 2862–2871. European Language R esources Association,\nMarseille, France (May 2020), https://www.aclweb.org/anthology/2020.lrec-1.349\n8. Jain, K., Deshpande, A., Shridhar, K., Laumann, F., Dash, A.: Indic-transformers:\nAn analysis of transformer language models for indian langu ages (2020)\n9. Jha, V.K., P, H., P N, V., Vijayan, V., P, P.: Dhot-reposito ry and classiﬁcation of\noﬀensive tweets in the hindi language. Procedia Computer Sc ience 171, 2324 – 2333\n(2020), http://www.sciencedirect.com/science/article/pii/S1877050920312448,\nthird International Conference on Computing and Network Co mmunications\n(CoCoNet’19)\n10. Joshi, R., Goel, P., Joshi, R.: Deep learning for hindi te xt classiﬁca-\ntion: A comparison. Lecture Notes in Computer Science p. 94– 101 (2020),\nhttp://dx.doi.org/10.1007/978-3-030-44689-5 9\n11. Kakwani, D., Kunchukuttan, A., Golla, S., N.C., G., Bhat tacharyya, A., Khapra,\nM.M., Kumar, P.: IndicNLPSuite: Monolingual corpora, eval uation benchmarks\nand pre-trained multilingual language models for Indian la nguages. In: Findings\nof the Association for Computational Linguistics: EMNLP 20 20. pp. 4948–4961.\nOnline (Nov 2020), https://www.aclweb.org/anthology/2020.ﬁndings-emnlp.445\n12. Kaushal, A., Vaidhya, T.: Winners at w-nut 2020 shared ta sk-3: Leverag-\ning event speciﬁc and chunk span information for extracting covid entities\nfrom tweets. Proceedings of the Sixth Workshop on Noisy User -generated\nText (W-NUT 2020) (2020). https://doi.org/10.18653/v1/2 020.wnut-1.79,\nhttp://dx.doi.org/10.18653/v1/2020.wnut-1.79\n13. Kingma, D.P., Ba, J.: Adam: A method for stochastic optim ization (2017)\n14. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Le vy, O., Lewis, M.,\nZettlemoyer, L., Stoyanov, V.: Roberta: A robustly optimiz ed BERT pretraining\napproach. CoRR abs/1907.11692 (2019), http://arxiv.org/abs/1907.11692\n15. Malmasi, S., Zampieri, M.: Challenges in discriminatin g profanity from hate speech.\nCoRR abs/1803.05495 (2018), http://arxiv.org/abs/1803.05495\n16. Mitrovi´ c, J., Handschuh, S.: upinf - oﬀensive language detection in german tweets.\nIn: Proceedings of the GermEval 2018 Workshop 14th Conferen ce on Natural Lan-\nguage Processing (09 2018)\n17. Mittos, A., Zannettou, S., Blackburn, J., Cristofaro, E .D.: ”and we will ﬁght for\nour race!” A measurement study of genetic testing conversat ions on reddit and\n4chan. CoRR abs/1901.09735 (2019), http://arxiv.org/abs/1901.09735\n18. Nobata, C., Tetreault, J., Thomas, A., Mehdad, Y., Chang , Y.: Abusive language\ndetection in online user content. Proceedings of the 25th In ternational Conference\non World Wide Web (2016)\n19. Ottoni, R., Cunha, E., Magno, G., Bernardina, P., Meira, W., Almeida, V.: Ana-\nlyzing right-wing youtube channels: Hate, violence and dis crimination (2018)\n20. Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J. , Chanan, G., Killeen, T.,\nLin, Z., Gimelshein, N., Antiga, L., Desmaison, A., K¨ opf, A ., Yang, E., DeVito, Z.,\nRaison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang , L., Bai, J., Chintala,\nS.: Pytorch: An imperative style, high-performance deep le arning library. CoRR\nabs/1912.01703 (2019), http://arxiv.org/abs/1912.01703\nHostility Detection in Hindi leveraging Pre-Trained Langu age Models 11\n21. Patwa, P., Bhardwaj, M., Guptha, V., Kumari, G., Sharma, S., PYKL, S., Das,\nA., Ekbal, A., Akhtar, M.S., Chakraborty, T.: Overview of co nstraint 2021 shared\ntasks: Detecting english covid-19 fake news and hindi hosti le posts. In: Proceedings\nof the First Workshop on Combating Online Hostile Posts in Re gional Languages\nduring Emergency Situation (CONSTRAINT). Springer (2021)\n22. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O.,\nBlondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vand erplas, J., Passos, A.,\nCournapeau, D., Brucher, M., Perrot, M., Duchesnay, E.: Sci kit-learn: Machine\nlearning in Python. Journal of Machine Learning Research 12, 2825–2830 (2011)\n23. Radford, A.: Improving language understanding by gener ative pre-training (2018)\n24. Romero, M.: https://huggingface.co/mrm8488/HindiBERTa\n25. Saﬁ Samghabadi, N., Patwa, P., PYKL, S., Mukherjee, P., D as, A., Solorio, T.:\nAggression and misogyny detection using BERT: A multi-task approach. In: Pro-\nceedings of the Second Workshop on Trolling, Aggression and Cyberbullying. pp.\n126–131. European Language Resources Association (ELRA), Marseille, France\n(May 2020), https://www.aclweb.org/anthology/2020.trac-1.20\n26. Sreelakshmi, K., Premjith, B., Soman, K.: Detection of h ate speech\ntext in hindi-english code-mixed data. Procedia Computer S cience 171,\n737 – 744 (2020). https://doi.org/https://doi.org/10.10 16/j.procs.2020.04.080,\nhttp://www.sciencedirect.com/science/article/pii/S1877050920310498, third In-\nternational Conference on Computing and Network Communica tions (Co-\nCoNet’19)\n27. Thorne, J., Vlachos, A., Christodoulopoulos, C., Mitta l, A.: Fever:\na large-scale dataset for fact extraction and veriﬁcation ( 2018),\nhttp://arxiv.org/abs/1803.05355\n28. Waseem, Z., Davidson, T., Warmsley, D., Weber, I.: Under standing abuse: A typol-\nogy of abusive language detection subtasks. In: Proceeding s of the First Workshop\non Abusive Language Online. pp. 78–84. Association for Comp utational Linguis-\ntics, Vancouver, BC, Canada (Aug 2017). https://doi.org/1 0.18653/v1/W17-3012,\nhttps://www.aclweb.org/anthology/W17-3012\n29. Wijesiriwardene, T., Inan, H., Kursuncu, U., Gaur, M., S halin, V.L., Thirunarayan,\nK., Sheth, A., Arpinar, I.B.: Alone: A dataset for toxic beha vior among adolescents\non twitter (2020)\n30. Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C. , Moi, A., Cis-\ntac, P., Rault, T., Louf, R., Funtowicz, M., Brew, J.: Huggin gface’s transform-\ners: State-of-the-art natural language processing. CoRR abs/1910.03771 (2019),\nhttp://arxiv.org/abs/1910.03771",
  "topic": "Hindi",
  "concepts": [
    {
      "name": "Hindi",
      "score": 0.8615080118179321
    },
    {
      "name": "Offensive",
      "score": 0.8353087902069092
    },
    {
      "name": "Computer science",
      "score": 0.7737138271331787
    },
    {
      "name": "Task (project management)",
      "score": 0.7034185528755188
    },
    {
      "name": "Hostility",
      "score": 0.6681733131408691
    },
    {
      "name": "Constraint (computer-aided design)",
      "score": 0.5989739298820496
    },
    {
      "name": "Natural language processing",
      "score": 0.5693165063858032
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5666933059692383
    },
    {
      "name": "Devanagari",
      "score": 0.538088321685791
    },
    {
      "name": "Social media",
      "score": 0.43492579460144043
    },
    {
      "name": "Transfer of learning",
      "score": 0.41934558749198914
    },
    {
      "name": "Machine learning",
      "score": 0.37804216146469116
    },
    {
      "name": "Speech recognition",
      "score": 0.3451423645019531
    },
    {
      "name": "World Wide Web",
      "score": 0.18525370955467224
    },
    {
      "name": "Psychology",
      "score": 0.1307716965675354
    },
    {
      "name": "Social psychology",
      "score": 0.1128075122833252
    },
    {
      "name": "Mathematics",
      "score": 0.07503056526184082
    },
    {
      "name": "Operations research",
      "score": 0.06887707114219666
    },
    {
      "name": "Character recognition",
      "score": 0.0
    },
    {
      "name": "Image (mathematics)",
      "score": 0.0
    },
    {
      "name": "Geometry",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I145894827",
      "name": "Indian Institute of Technology Kharagpur",
      "country": "IN"
    }
  ],
  "cited_by": 8
}