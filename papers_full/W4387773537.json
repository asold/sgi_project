{
  "title": "Toward Programming Languages for Reasoning: Humans, Symbolic Systems, and AI Agents",
  "url": "https://openalex.org/W4387773537",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2133249608",
      "name": "Mark Marron",
      "affiliations": [
        "University of Kentucky"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6751483195",
    "https://openalex.org/W2116272605",
    "https://openalex.org/W6765556884",
    "https://openalex.org/W2108556169",
    "https://openalex.org/W2154774499",
    "https://openalex.org/W3205260334",
    "https://openalex.org/W2604766223",
    "https://openalex.org/W2052087935",
    "https://openalex.org/W2073407646",
    "https://openalex.org/W1982205631",
    "https://openalex.org/W2125044336",
    "https://openalex.org/W2067901725",
    "https://openalex.org/W4251912342",
    "https://openalex.org/W2138527110",
    "https://openalex.org/W4237412827",
    "https://openalex.org/W2012401665",
    "https://openalex.org/W6635237052",
    "https://openalex.org/W6640145936",
    "https://openalex.org/W2134569009",
    "https://openalex.org/W2046699259",
    "https://openalex.org/W6676680617",
    "https://openalex.org/W6646968476",
    "https://openalex.org/W4254512865",
    "https://openalex.org/W1530276989",
    "https://openalex.org/W1494930385",
    "https://openalex.org/W2136310957",
    "https://openalex.org/W2121610622",
    "https://openalex.org/W2048229966",
    "https://openalex.org/W2156076209",
    "https://openalex.org/W1791762382",
    "https://openalex.org/W6745295520",
    "https://openalex.org/W2138162238",
    "https://openalex.org/W2113766267",
    "https://openalex.org/W2162544703",
    "https://openalex.org/W2114067856",
    "https://openalex.org/W2538856787",
    "https://openalex.org/W3004239592",
    "https://openalex.org/W2126763866",
    "https://openalex.org/W2604664164",
    "https://openalex.org/W2098045685",
    "https://openalex.org/W6755153474",
    "https://openalex.org/W2131135493",
    "https://openalex.org/W1500987966",
    "https://openalex.org/W1557064363",
    "https://openalex.org/W2898125173",
    "https://openalex.org/W4255937913",
    "https://openalex.org/W4244581756",
    "https://openalex.org/W4244639453",
    "https://openalex.org/W1981276685"
  ],
  "abstract": "Integration, composition, mechanization, and AI assisted development are the\\ndriving themes in the future of software development. At their core these\\nconcepts are rooted in the increasingly important role of computing in our\\nworld, the desire to deliver functionality faster, with higher quality, and to\\nempower more people to benefit from programmatic automation. These themes, and\\nhow they impact the human developers driving them, are the foundations for the\\nnext generation of programming languages. At first glance the needs of\\nmechanization tools, AI agents, and human developers along with the various\\ngoals around development velocity, software quality, and software\\ndemocratization are a broad and seemingly diverse set of needs. However, at\\ntheir core is a single challenge that, once resolved, enables us to make\\nradical progress in all of these areas.\\n Our hypothesis is that, fundamentally, software development is a problem of\\nreasoning about code and semantics. This is true for human developers\\nimplementing a feature, symbolic tools building models of application behavior,\\nand even for language based AI agents as they perform tasks. While the\\nparticular aspects of reasoning that each agent struggles with varies to some\\ndegree, they share many common themes and, surprisingly, most mainstream\\nlanguages extensively employ (anti)features that make this task harder or\\ninfeasible! This paper proposes a novel approach to this challenge -- instead\\nof new language features or logical constructs, that add more complexity to\\nwhat is already a problem of complexity, we propose radical simplification in\\nthe form of the Bosque platform and language.\\n",
  "full_text": "arXiv:2407.06356v1  [cs.PL]  8 Jul 2024\nToward Programming Languages for Reasoning –\nHumans, Symbolic Systems, and AI Agents\nMark Marron\nUniversity of Kentucky\nUSA\nmark.marron@protonmail.com\nAbstract\nIntegration, composition, mechanization, and AI assisted de-\nvelopment are the driving themes in the future of software\ndevelopment. At their core these concepts are rooted in the\nincreasingly important role of computing in our world, the\ndesire to deliver functionality faster, with higher quality, and\nto empower more people to beneﬁt from programmatic au-\ntomation. These themes, and how they impact the human\ndevelopers driving them, are the foundations for the next\ngeneration of programming languages. At ﬁrst glance the\nneeds of mechanization tools, AI agents, and human devel-\nopers along with the various goals around development ve-\nlocity, software quality, and software democratization are a\nbroad and seemingly diverse set of needs. However, at their\ncore is a single challenge that, once resolved, enables us to\nmake radical progress in all of these areas.\nOur hypothesis is that, fundamentally, software develop-\nment is a problem of reasoning about code and semantics.\nThis is true for human developers implementing a feature,\nsymbolic tools building models of application behaviour, and\neven for language based AI agents as they perform tasks.\nWhile the particular aspects of reasoning that each agent\nstruggles with varies to some degree, they share many com-\nmon themes and, surprisingly, most mainstream languages\nextensively employ (anti)features that make this task harder\nor infeasible! This paper proposes a novel approach to this\nchallenge – instead of new language features or logical con-\nstructs, that add more complexity to what is already a prob-\nlem of complexity, we propose radical simpliﬁcation in the\nform of the B/o.sc/s.sc/q.sc_u.sc/e.scplatform and language.\n1 Introduction\nThe introduction and widespread use of structured program-\nming [\n17] and abstract data types [ 53] marked a major shift\nin how programs are developed. Fundamentally, the con-\ncepts and designs introduced by these programming method-\nologies simpliﬁed reasoning about program behavior by elim-\ninating substantial sources of, usually entirely accidental [\n8],\ncomplexity. This allowed engineers to focus on the intent\nand core behavior of their code more directly and, as a re-\nsult, produced a drastic improvements in software quality\nAuthor’s address: Mark Marron, University of Kentucky, USA, mark.\nmarron@protonmail.com.\nand ability to construct large software artifacts. Just as acc i-\ndental complexity is an impediment to human understand-\ning of a program it is also an impediment to applying formal\nreasoning techniques, and other mechanization, to software\nsystems. Despite the inability of structured programming to\nfully bridge the chasm of formal mathematical analysis, is-\nsues with loop-invariants and mutation-frames among oth-\ners prevented the practical use of deep veriﬁcation technique s,\nit did provide the needed simpliﬁcations for reasoning about\nlimited forms of program behavior and supported a golden\nage of IDE tooling and compiler development [\n44, 65].\nThis paper takes the view that the next phase of software\ndevelopment and programming languages will be deﬁned\nby (1) componentization, (2) AI assistance, and (3) mecha-\nnization. We are already well into the ﬁrst of these trans-\nformations where, in the last decade, service based (cloud)\napplications [\n9, 26], package ecosystems [ 70, 82], and frame-\nworks [23, 78] have played critical roles in shaping how de-\nvelopers work. The second transformation, the rise of AI\nassisted development, arrived with the release of github’s\nCopilot tool [\n14]. Suddenly, developers are looking at a land-\nscape where they are curators of code generated by an AI\nagent, and integrating rich framework-functionality, in ad-\ndition to writing application code directly!\nIn this new world, the ability for various agents and sys-\ntems to understand and reason about application behavior\nis critical. Humans must reason about increasingly complex\nintegrated systems, AI agents need to ingest and operate\nreliably on complex tasks and codebases, and, with the in-\ncreased demands of AI/human agents, symbolic tooling must\nbe able to scalably process these systems. All three of these\naudiences have challenges when reasoning about code writ-\nten in mainstream languages today. Some of the challenges\nare shared, mutable state is always hard, while some are\nspeciﬁc to a reasoning agent, e.g. symbolic analysis of iter-\native constructs or humans overlooking special case behav-\niors. However, all of the agents must share a common model\nfor representing an application and, our hypothesis is that,\nfoundationally the structure of this representation can be\ndesigned in a way to maximize the ability all three types of\nagents to reason about the semantics of an application.\nThis paper proposes a novel frame for conceptualizing\nthe role and design of a programming language and soft-\nware stack. Speciﬁcally, re-conceptualizing the programming\n1\nMark Marron\nlanguage as the foundation for reasoning and mechaniza-\ntion, with development as a process of integration, valida-\ntion, and composition. This task involves starting from ﬁrst-\nprinciples and looking carefully at the impact each design\nchoice has on the ability of agents to reason about and pro-\ncess code. Using this methodology we identify a set of seven\nmajor sources of complexity and ways, via language design,\nthat they can be eliminated or minimized.\nUsing this insight we develop an intermediate language\nand surface syntax, B/o.sc/s.sc/q.sc_u.sc/e.scIRand B/o.sc/s.sc/q.sc_u.sc/e.screspectively, which\ntake the novel approach of language design by the removal\nof problematic feature and reduction in power of various\nconstructs – as opposed to the usual approach of introduc-\ning new language features or extending them with more\npowerful capabilities. This approach results in a symbolic\nreasoning friendly IR and a human/AI agent reasoning friendly\nsurface syntax. Although seemingly simple this result has\ndeep implications for the future of software-development,\ncompilers, runtimes, and AI agents.\nTo demonstrate some of the possibilities that a language,\nlike B/o.sc/s.sc/q.sc_u.sc/e.sc, creates we look at a case studies of long stand-\ning and impactful problems, a decidable theory for small-\nmodel program validation, and the new and critical problem\nof eﬀectively generating (correct) code that matches devel-\noper/user intents using AI agents. In both of these cases a\nhighly eﬀective solution can be constructed via the straight\nforward framing of the properties of interest and the ability\nto eﬀectively reason about how a piece of B/o.sc/s.sc/q.sc_u.sc/e.sccode in-\nteracts with these properties.\nThe contributions of this paper are:\n• A novel approach for conceptualizing the role and de-\nsign of a programming language and software stack\nthat is focused on the language as a substrate for rea-\nsoning, tools, and agents.\n• An analysis and enumeration of language features that\nimpede analysis and reasoning (\nSection 2 ).\n• An intermediate program representation, B/o.sc/s.sc/q.sc_u.sc/e.scIR,\ndesigned explicitly to support mechanized reasoning\nand analysis (\nSection 4 ) and a surface syntax, B/o.sc/s.sc/q.sc_u.sc/e.sc,\noptimized for humans and AI agents ( Section 5 ).\n• Two case-study systems that demonstrate the viabil-\nity and potential for this approach to language design\nin the future of software development (\nSection 7 ).\n2 Complexity and Confusion\nOur goal is to create a programming system that is opti-\nmized for reasoning – by humans, symbolic analysis tool-\ning, and AI agents (Large Language Model [\n72] type agents\nin particular). The approach we take is to identify and re-\nmove features or concepts that complicate reasoning for our\nagents. Based on a range of experiences and sources includ-\ning developer interviews, personal experience with analy-\nsis/runtime/compiler development, and empirical studies thi s\nsection identiﬁes seven major sources of complexity that\ncan be addressed via thoughtful language design. These are\nsources of various bug categories, increase the eﬀort requir ed\nfor a developer (or AI agent) to reason about and implement\nfunctionality in an application, and greatly complicate (or\nmake it infeasible to) automatically reason about a program.\n2.1 Reasoning Agents and Challenges\nWe begin by looking at the three reasoning agent types we\nare considering – human, symbolic, and Large Language\nModel (LLM) systems. There are common themes in what\naspects of reasoning each of these agents ﬁnd challenging\nbut, given the diﬀerences in their inference modes, we also\nsee how they have unique challenges as well.\nHuman Developers: Humans are remarkably adaptable\nand are able to understand code using many modalities in-\ncluding symbolic modeling, dynamic tracing of execution\non concrete values, inferences from names and comments,\ngrepping code, and even asking a teammate what they were\nthinking when the wrote it. Humans fundamentally have a\nlimited amount of memory and tend to fatigue. Thus, they\noften take mental short-cuts and make assumptions based\non limited syntactic signal and prior experience. These tricks\nare usually safe and eliminate substantial amounts of work.\nHowever, when there are subtle, unusual, or special context\nspeciﬁc behaviors, these reasoning shortcuts will miss them\nand result in erroneous behaviors. These failures range from\ncorner case bugs with indeterminate behaviors like unsta-\nble sorts [\n10], to large scale outages cased by oversights in\nrecovery logic [ 34], or industry-wide security issues from\nassuming that a log statement would never access a remote\nserver and execute un-trusted code [ 55]. In hindsight all of\nthese issues are “obvious” but as humans we are all subject\nto fatigue, oversights, and heuristic biases that let assump -\ntions derived from surface syntax and implicit expectations\nlead to missing critical behaviors.\nSymbolic Analysis Tooling: Symbolic analyses in many\nways are on the opposite end of the spectrum from a human\ndeveloper in terms of their reasoning strengths and weak-\nnesses. They do not understand anything apart from the\ncode itself as written and do not bring any preconceived no-\ntions about what it might do. Thus, these agents will never\noverlook a subtle corner case or possibility. However, this a t-\ntention to speciﬁcs and lack of intuitive understanding often\nleads to them getting “lost in the details” and being unable to\nscale to realistic codebases where they must deal with non-\ndeterminism, loop/inductive invariant generation, aliasing,\nand more. In practice, to be feasible, they are often simpli-\nﬁed substantially, at a cost of imprecision, which generally\n2\nToward Programming Languages for Reasoning – Humans, Symbo lic Systems, and AI Agents\nleads to issues with false positives/negatives and reduces th e\nvalue they can provide.\nAI Agents: Large-Language-Model (LLM) agents [ 72] are\nan interesting addition to this spectrum. They can perform\nheuristic resesoning like humans but they do not get tired\nand can hold huge amounts of context while performing a\ntask currently up to 32k tokens (“words”). However, these\nmodels are strongly syntax based and, as a result, if there\nare important semantic properties of the code that are not\nsyntactically visible then the agent must fall back to like-\nlihoods learned in the training data. These features make\nAI agents remarkably capable when performing certain cod-\ning tasks. However, these properties also lead them to mak-\ning mistakes that can be quite perplexing. Current LLM’s\n(like GPT-4) are prone to making-up and using API’s that\nsound plausible but that don’t actually exist or using API’s\nin ways that defy common sense – for example picking a\nhard-coded time to schedule a meeting instead of correctly\nquerying a schedule availability API to ﬁnd a mutually open\nslot. The propensity to make these types of mistakes is com-\npounded by the inability of these AI agents to leverage tools\nto validate assumptions in code they generate. Thus, just\nlike human developers, improvements in symbolic reason-\ning based tools can lead to immediate improvements in the\nperformance of statistically based AI agents as well.\n2.2 Sources of Complexity\nGiven the capabilities of the agents we want to support, hu-\nmans, symbolic tools, and AI systems, we next look at seven\ncommonly appearing features in modern languages that im-\npede their reasoning.\nMutable State and Frames: Mutable state is a deeply\ncomplicated concept to model and reason about. The intro-\nduction of mutability into a programming language destroys\nthe ability to reason about the application in a monotone [\n68]\nmanner which forces the programmer (and any analysis tools)\nto identify which facts remain true after an operation and\nwhich are invalidated. The ability for mutable code to aﬀect\nthe state of the application via both return values and side\naﬀects on arguments (or other global state) also introduces\nthe need to reason about the logical frame [\n58, 79] of every\noperation.\nImplicit Behaviors: Behaviors that are not explicit in\nthe syntax of the code create opportunities for misunder-\nstanding, oversights, and increase the cognitive load when\nreasoning. Examples of this include implicit nullability, the\n“billion dollar mistake”, unchecked exceptions, and APIs with\nundeclared implicit error behaviors. A common example is\nthe min operation in C# vs. Python. In C# the min operator\nreturn is declared as Option<T> so that the possibility of a\ninvalid result is syntactically explicit in the declaration. I n\nPython one must look into the API docs to ﬁnd the comment\nthat the min function throws an error on the empty list.\nHidden Semantics: Similar to implicit behaviors, many\nlanguages have implicit rules that aﬀect program behaviors.\nThese include implicit type coercion, numeric truncation,\nand ﬂow-sensitive or other advanced of type inference al-\ngorithms. These increase the cognitive load to understand\na block of code as they require additional work to simulate\na non-trivial hidden algorithm to extract implicit program\nsemantics and create opportunities for simple oversights to\ncreate unexpected outcomes.\nLoops, Recursion, and Invariants: Loops and recursion\nrepresent a fundamental challenge to reasoning as the code\ndescribes the eﬀects of a single step but understanding the\nfull construct requires generalization to a quantiﬁed prop-\nerty over a set of values. Invariants [\n28, 38] provide the\nneeded connection but a generalized technique for their com-\nputation is, of course, impossible in general and has proved\nelusive even for restricted applications.\nIndeterminate Behaviors: Indeterminate behaviors, in-\ncluding undeﬁned, under speciﬁed, or non-deterministic or\nenvironmental behavior, require a programmer or analysis\ntool to reason about and account for all possible outcomes.\nWhile truly undeﬁned behavior, e.g. uninitialized variables,\nhas disappeared from most languages there is a large class of\nunder-speciﬁed behavior, e.g. sort stability, map/dictionary\nenumeration order, etc., that remains. These increase the\ncomplexity of the development process and, as time goes\non, are slowly being seen as liabilities that should be re-\nmoved [\n10]. Less obviously the inclusion of non-deterministic\nand/or environmental interaction results in code that can-\nnot be reliably tested (ﬂakey tests), behaves diﬀerently for\nnon-obvious reasons, and frequently mixes failure logic widely\nthrough a codebase.\nData Invariant Violations: Programming languages gen-\nerally provide operators for accessing, and in imperative\nlanguages updating, individual elements in arrays/tuples or\nﬁelds in objects/records. The fact that these accessors/up -\ndaters operate on an individual elementwise basis results in\nprogrammers updating the state of an object over multiple\nsteps, or manually exploding an object before creating an\nupdated copy, during this span invariants which normally\nhold are temporarily invalidated before being restored. Dur-\ning these intervals the number of details that must be tracked\nand restored can increase drastically increasing opportuni-\nties for mistakes and oversights to occur.\nEquality and Aliasing: Programming languages live at\nthe boundary of mathematics and engineering. Although\nlanguage semantics are formulated as a mathematical con-\ncept there are common cases, e.g. reference equality, pass\nby-value vs. by-reference, or evaluation orders, that expose\n3\nMark Marron\nand favor one particular hardware substrate, generally a Von\nNeumann architecture, either intentionally for performance\nor accidentally by habit or history. While seemingly minor\nthese choices have a major impact on comprehensibility –\nmerely exposing reference equality pulls in the complex-\nity of reasoning about aliasing relations and greatly com-\nplicates compilation on other architectures.\n3 B/o.sc/s.sc/q.sc_u.sc/e.scDesign Philosophy\nThe unique value proposition of B/o.sc/s.sc/q.sc_u.sc/e.scis not based on a\nsingle big new feature, or even a number of smaller novel\nfeatures, instead the novelty comes from a holistic process\nof simpliﬁcation and feature selection with a single focus to-\nward what will simplify reasoning about code. The ﬁrst part\nof this process is eliminating, or minimizing, the sources\nof complexity identiﬁed in\nSection 2 . This process primar-\nily involves the design of the B/o.sc/s.sc/q.sc_u.sc/e.scIRin Section 4 . The\nsecond part of the process centers around how to connect\nthis core IR to a user friendly surface syntax, and, how to\nmake this syntax amenable to human and LLM agent un-\nderstanding. This involves the development of the language\nstructure and the introduction of a variety of intentional but\nsubtle features that fade into the background and lead devel-\nopers onto a path of producing clean code without eﬀort or\nconscious thought.\nThe idea of a solver integrated or aware language has been\nexplored in several contexts – examples include Rosette [\n86],\nwhy3 [27], Dafny [49], and Ivy [ 60]. The design of B/o.sc/s.sc/q.sc_u.sc/e.scIR\nis unique in that it does not attempt to expose the solver, in-\ncluding limitations it has, to the developer. Instead it is de-\nsigned to naturally encourage and simplify the mapping of\ncode written by a non-expert developer (one who is not an\nexpert in logics or provers) into one of many possible reason-\ning frameworks such as SMT solvers, deductive logical en-\ngines, abstract interpretation, and simple dataﬂow solvers.\nAt the core of B/o.sc/s.sc/q.sc_u.sc/e.scIRis a let-based functional language.\nAlthough there are many functional languages that have\nkey properties we want in the IR, in their attempts to also\nbe general purpose languages or due to historical accident,\nthey also end up with features like mutable cells, visible\naliasing, lazy evaluation, non-local eﬀects and ﬂow, or inde-\nterminate behaviors in their speciﬁcations. Thus, the B/o.sc/s.sc/q.sc_u.sc/e.scIR\ncan be seen as a highly regularized functional language that\nis fully aligned with the goal of eliminating the complexities\nidentiﬁed in\nSection 2 .\nIn Section 5 this paper shows how a selection of language\nfeatures and syntactic structures can connect a regularized\nIR like the B/o.sc/s.sc/q.sc_u.sc/e.scIRto a block-structured (and imperative\nlooking) source language that developers are comfortable\nwith. As described in\nSection 5 we can use syntactic sugar\nto support commonly used and easily understood program-\nming constructs like block-structured code, reassignment\nof variables, updates through (shallow) references, early r e-\nturns, and object-oriented data types. These constructs are\nheavily used and well understood features in modern soft-\nware engineering so supporting them allows developers to\neasily express their intents in a natural way. However, by\nour careful construction, these features can in fact be com-\npiled directly down into the core B/o.sc/s.sc/q.sc_u.sc/e.scIRrepresentation.\nThus giving us the best of both worlds, where developers\ncan express their domain and business logic in an intuitive\nsyntactic form and, unlike in a standard imperative or object-\noriented language, the underlying semantics are the well-\nbehaved B/o.sc/s.sc/q.sc_u.sc/e.scIRstructures.\n4 B/o.sc/s.sc/q.sc_u.sc/e.scIRIntermediate Representation\nGiven the sources of complexity identiﬁed in\nSection 2 , the\nﬁrst task is to construct an intermediate language (IR) that\neliminates or reduces the impact of each of them. As many\nof the issues are tied to mutability and loops, the design pro-\ncess starts with a strict functional language core. This core\nuses classic let bindings, if-then-else conditionals, a spe-\ncial assert expression, and a restricted deﬁnition of equality .\n4.1 Primitive Types and Values\nThe B/o.sc/s.sc/q.sc_u.sc/e.scIRlanguage provides a standard assortment of\nprimitive types and values including a special none value\n(None type), a Bool, Nat and Int numbers, safe BigNat and\nBigInt numbers, along with Float, Decimal, and Rational\nnumbers. The B/o.sc/s.sc/q.sc_u.sc/e.scIRString type represents immutable\nunicode string values (a special ASCIIString is also pro-\nvided). The language includes support for commonly used\ntypes/values in modern cloud applications like ISO/Plain ti mes,\nSHA hashcodes, UUIDs, timestamps, and other miscellany.\n4.2 Self Describing Types and Values\nStructural Tuple and Record types provide standard forms\nof self describing types. Structural types do not allow sub-\ntyping ( i.e. not covariant). This allows for an analysis to\nknow, and precisely encode, the types of values in a struc-\ntural type. This representation results in substantial simpl i-\nﬁcations when reasoning about operations on these values\nas lookups are always statically resolved. Examples of thes e\ntypes include:\n[Int , String ]\n// a tuple type\n[5i , /quotedbl.Var ok /quotedbl.Var]// a tuple of type [Int , String ]\n{p1 : Int , p2 : String } //a record type\n{p1 =5i , p2 =/quotedbl.Var ok /quotedbl.Var}// a record of type { p1 : Int , p2: String }\nThe B/o.sc/s.sc/q.sc_u.sc/e.scIRrepresentation also supports self describ-\ning ad-hoc union types. The sub-typing relation on union\ntypes is deﬁned as being a subtype of any enumerated type\nin the union.\nInt | None\n// a union type\nif true then 5i else none // expression of type Int | None\n4\nToward Programming Languages for Reasoning – Humans, Symbo lic Systems, and AI Agents\n4.3 Nominal Types\nB/o.sc/s.sc/q.sc_u.sc/e.scIRsupports a nominal type system that allows the\nconstruction of object-oriented style type inheritance struc-\ntures. Abstract concepts provide a means for inheritance\nand multi-inheritance via conjunction.\nIn the following example there are two concepts declared,\nWithName and Greeting,that deﬁne a ﬁeld and abstract method\nrespectively. The concrete entity GenericGreeting is de-\nclared to provide the Greeting concept and, implements the\nrequired sayHello method. The NamedGreeting provides\nboth the WithName concept, so it inherits the ﬁeld name and\nthe Greeting concept. Using the name ﬁeld it implements\nthe sayHello method to return a customized string with\nthe name information.\nconcept WithName {\nfield name: String ;\n}\nconcept Greeting {\nabstract method sayHello (): String ;\n}\nentity GenericGreeting provides Greeting {\noverride method sayHello () : String {\nreturn /quotedbl.Var hello world /quotedbl.Var;\n}\n}\nentity NamedGreeting provides WithName , Greeting {\noverride method sayHello () : String {\nreturn String :: concat (/quotedbl.Var hello /quotedbl.Var,this . name );\n}\n}\nIn B/o.sc/s.sc/q.sc_u.sc/e.scIR, nominal subtyping is based on the transitive\nclosure of the provides relation. In this example the entity\nGenericGreeting is a subtype of just Greeting while the\nentity NamedGreeting is a subtype of both WithName and\nGreeting.\nThe nominal type system diﬀers from many object-oriented\ntype systems in that the concepts are always abstract and can\nnever be concretely instantiated while entity (class) types\nare always concrete and can never be subclassed. This pre-\nvents confusion in type checks where an instance of test\nmay be intended to check for an exact type but actually in-\ncludes all subtypes as well. More generally this enables us to\neasily determine if a given operation has a single concrete\nbehavior or may be dynamic in nature.\n4.4 Typedecls\nPrimitive datatypes are a frequent source of implicit non-\nsyntactic information in code. Strings and integers are of-\nten used to represent semantically distinct concepts, like a\nzipcode or a temperature, just via convention and use. These\nuses make certain classes of bugs possible, like adding a tem-\nperature in Fahrenheit to one in Celsius, and hide important\ninformation in implicit channels. Sometimes this design is\nmotivated by performance concerns, e.g. space/boxing over-\nheads, but is often just an issue of simply wanting to avoid\nthe eﬀort to declare a new datatype and implement all the\nassociated methods (particularly for numeric types).\nThe B/o.sc/s.sc/q.sc_u.sc/e.scIRrepresentation provides explicit support\nfor these cases via a StringOf type and typedeclsthat man-\nage the new-type creation, ensuring that the type represen-\ntation is isomorphic to the underlying type, generation of\nthe standard operators, and allow customization of the un-\nderlying value with user-deﬁned invariants.\nThe example below shows the declaration of a typed string\nZipcode using a regex and the parametric StringOf type.\nThese structured strings are frequently used in modern web\napplications – OpenAPI [\n73] and Microsoft TypeSpec [ 89]\nboth natively support similar constructs. As shown in the\nexample this allows us to declare typed string literals, chec k\nthey satisfy the constraints on construction, and are used in\ntype-safe ways.\ntypedecl ZipcodeValidator = /[0 -9]{5}( -[0 -9]{4}) ?/;\ntypedecl Zipcode = StringOf < ZipcodeValidator >;\ntypedecl Celsius = Float ;\n// create a literal zipcode string\n/quotedbl.Var40502/quotedbl.Var Zipcode// Ok\n/quotedbl.VarABC /quotedbl.Var Zipcode// Type Error\nfunction isNYZipcode ( zc : Zipcode ): Bool {...}\nisNYZipcode (/quotedbl.Var40502/quotedbl.Var Zipcode )// Ok returns false\nisNYZipcode (/quotedbl.Var40502/quotedbl.Var)// Error arg is a String\nlet temp = 10 _Celsius + 1 _Celsius // Type safe operation\nThe typedecl type constructor also supports creating new\ntypes for any primitive type such as Ints, Floats, UUIDs, etc.\nIn the example a new type for the temperature Celsius is\ncreated and, all well-typed, operations are permitted on the\nnew numeric types.\n4.5 Key Types and Equality\nEquality is a multifaceted concept in programming [\n69] and\nensuring consistent behavior across the many areas it sur-\nfaces in a modern programming language such as ==, .equals,\nSet.has, and List.sort, is source of subtle bugs [\n39]. This com-\nplexity further manifests when equality can involve refer-\nential identity which introduces issue of needing to model\naliasing relations on values, in addition to their structural\ndata, in order to understand the equality relation.\nTo avoid these behavioral complications, and the need to\nmodel aliasing, the B/o.sc/s.sc/q.sc_u.sc/e.scIRlanguage is referentially trans-\nparent. The only values which may be compared for equality\nare speciﬁc primitive values including none, booleans, prim-\nitive integral numbers, strings, and typedecls of these prim-\nitive types. In conjunction with the immutability of the val-\nues (\nSection 4.6 ) this ensures that B/o.sc/s.sc/q.sc_u.sc/e.scIRcode is referen-\ntially transparent and functions do not need to use frame\nrules [58].\n5\nMark Marron\nListStructure := List<T>{ /u1D4521, . . . , /u1D452/u1D457} | slice( /u1D459,/u1D456, /u1D457) | concat( /u1D4591, /u1D4592) . . .\nListAccess := size( /u1D459) | get( /u1D459, /u1D45B) | . . .\nListCompute := map<fn>( /u1D459) | filter<p>( /u1D459) | | join<p>( /u1D4591, /u1D4592) | . . .\nListPred := has<p>( /u1D459) | find<p>( /u1D459) | count<p>( /u1D459) | . . .\nListIterate := sum( /u1D459) | reduce<fn>( /u1D459) | . . .\nFigure 1. B/o.sc/s.sc/q.sc_u.sc/e.scIRList<T> Operations\n4.6 Operations\nThe expression language for B/o.sc/s.sc/q.sc_u.sc/e.scIRis designed explicitly\nwith the needs of symbolic reasoning systems in mind. The\nlanguage allows recursion but most code is expected to use a\nrich language of higher-order functor libraries (see\nFigure 1).\nOtherwise, the B/o.sc/s.sc/q.sc_u.sc/e.scIRexpression semantics are constructed\nto ensure referential transparency, that all expressions are\nside-eﬀect free, that any expression deterministically eval -\nuates to unique result value and, with the inclusion of an\nerror-result, that they are total as well.\nPrimitive expressions include special constants like true,\nfalse, none, literal integral i values or literal ﬂoat f values,\nliteral strings s, and variables (either local, global, or argu-\nment). B/o.sc/s.sc/q.sc_u.sc/e.scIRhas the standard assortment of numeric\nand logical Operators. The constructor operations are all\nsimple and explicit operations for tuples and records. The\nconstructors for nominal entity types takes the type name +\nthe full list of values to initialize the ﬁelds with. Deconstru ct-\ning compound values is done with a standard indexing for\ntuples ( /u1D452./u1D456where /u1D456is a constant), or named property/ﬁeld\naccessor (/u1D452./u1D45Dand /u1D452./u1D453respectively).\nThe type manipulation operators include standard is and\nas operations to test value types (or subtype) and to perform\n(checked) casts on them. The inject operation is used to\nconvert a primitive value into a matching typdecl type and\nthe and extract operation extracts primitive values. The\nassert operation provides a way to explicitly generate an\nerror value (for user deﬁned errors) in addition to implic-\nitly deﬁned error sources, like cast failures, out-of-bounds\nindexing, etc..\n4.7 Collection Functors\nContainers and operations on them play a major role in\nmost programs and these semantics inherently involve rea-\nsoning over the container contents. Instead of introducing\na primitive looping construct, and attempting to tackle the\nloop invariant generation problem, the B/o.sc/s.sc/q.sc_u.sc/e.scIRlanguage\nincludes a rich set of container datatypes and functor based\noperations on them. In practice these operations, and param-\neterizeable functors, are suﬃcient to cover the majority of\niterative operations [\n1].\nFigure 1 shows a sample of the operations that are pro-\nvided for processing lists (maps, sets, stacks, and queues\nare also supported). These operations provide a structured\nway to process the values in collections. Most of these op-\nerations are familiar from libraries such as LINQ [ 52], Java\nStreams [41], or lodash [ 54]. One unique restriction on them\nis that the lambda parameters are passed as parametric ar-\nguments which specialize each functor. This preserves the\nﬁrst-order nature of the language, since we do not need to\npass function types, and as we see later, can be ensured with\na simple syntactic restriction on how lambdas can be used\nin the source language.\n5 B/o.sc/s.sc/q.sc_u.sc/e.scSource Representation\nThe construction of the B/o.sc/s.sc/q.sc_u.sc/e.scIRlanguage, as described in\nSection 4 , is free of many features that complicate reasoning\nw.r.t.application behavior. However, it is not particularly hu-\nman (or LLM AI) friendly and does not address many prob-\nlems identiﬁed in the context of implicit behaviors or hid-\nden semantics. At a high-level the B/o.sc/s.sc/q.sc_u.sc/e.sclanguage is de-\nsigned to be easily accessible to a developer coming from\nTypeScript, C#, or Java while mapping well to the restricted\nB/o.sc/s.sc/q.sc_u.sc/e.scIRrepresentation. B/o.sc/s.sc/q.sc_u.sc/e.scuses a block-based struc-\nture, allows reassignment of variables, has an extensive set\nof control-ﬂow operators, object-oriented language features ,\nand other language features designed to simplify common\nprogramming idioms.\nThis section describes the speciﬁc features of the B/o.sc/s.sc/q.sc_u.sc/e.sc\nsource language exposed to developers that are related to\nour key objective, supporting reasoning.\nFigure 2 is a par-\ntial implementation of a binary-tree in B/o.sc/s.sc/q.sc_u.sc/e.scthat con-\ntains many of these features. It uses the extended Algebraic\nData Type (ADT) declaration form (\nSection 5.1 ) to declare\nthe various types associated with a tree, early returns and\nother block structured control ﬂow including variable re-\nassignment (\nSection 5.4 ), explicit ﬂow-typing and binding\n($) as described in Section 5.2 , explicit recursion tags to de-\nnote recursive call paths ( Section 5.8 ), and the use of data in-\nvariants (Section 5.6 ). Later we will describe how ref meth-\nods work and show how they allow simulated in place ( Section 5.7 )\nupdates.\n5.1 Enhanced Algebraic Data Types\nThe type system that is presented to the surface user of the\nB/o.sc/s.sc/q.sc_u.sc/e.sclanguage closely mirrors the type system of the core\nB/o.sc/s.sc/q.sc_u.sc/e.scIRlanguage. The major ergonomic addition in the\n6\nToward Programming Languages for Reasoning – Humans, Symbo lic Systems, and AI Agents\ndatatype ITree using {\nsize : Nat\n} of\nNil {}\n| Leaf { v: Int }\n| Node {\ninvariant test size == l. size + r. size + 1n;\nfield v: Int ;\nfield l: ITree ;\nfield r: ITree ;\n}\n& {\nconst empty = Nil {0n };\nmethod isEmpty () {\nreturn this ?< Nill >;\n}\nrecursive method has (x: Int ): Bool {\nmatch ( this ) {\nNill => return false ;\n| Leaf => return $ .v == x;\n| Node => {\nif ($.v == x) {\nreturn true ;\n}\nvar tchild : ITree ;\nif (x < $.v) {\ntchild = $.l;\n}\nelse {\ntchild = $.r;\n}\nreturn tchild . has [recursive ]( x);\n}\n}\n}\n}\nFigure 2. Bosque Binary-Tree Example\nB/o.sc/s.sc/q.sc_u.sc/e.scsource language is the provision of syntax for cre-\nating algebraic-data-types. This syntax allows for the com-\npact subtyping, as provided by most ADT implementations,\nalong with inheritance of ﬁelds and deﬁnition/override of\nmethods, invariants, etc. These features make the ADT syn-\ntax more useful and practical.\nIn the binary-tree example these features allow us to de-\nclare a ﬁeld size which is inherited by each of the cases, Nil,\nLeaf, and Node. The simple cases of Nil and Leaf are simi-\nlar to the traditional ADT style where only the public ﬁelds\nare speciﬁed. When, inevitably the data types get more com-\nplex as in the case of the Node type, B/o.sc/s.sc/q.sc_u.sc/e.scsupports ex-\npanding the declaration with invariants and other type\nmembers. To simulate the desirable encapsulation proper-\nties of object-oriented languages this declaration allows a\ntailing block that can include any member type declarations.\nThese are all deﬁned in the scope of the enclosing ADT\ntype, in our example the ITree type. The example includes\ndeclarations of a member constant, empty, and three mem-\nber methods. This shorthand provides a compact way to\nFlowSpecial := none | some | ok | err | result\nFlowType := <Type>\nFlowEQ := [literal]\nFlowAlt := FlowSpecial | FlowType | FlowEQ\nFlowOp := FlowAlt | !FlowAlt\nFigure 3. B/o.sc/s.sc/q.sc_u.sc/e.scFlow Typing and Binding\ngroup logically related subtypes and operations in addition\nto avoiding the need for mostly trivial class declarations (in\nour examples it would be 1 abstract class plus 3 concrete\nclasses in a language like Java or TypeScript).\n5.2 Explicit Flow Typing and Binding\nA key principle in the design of the B/o.sc/s.sc/q.sc_u.sc/e.scsurface language\nis to ensure that, as much as possible, the behavior of an\nexpression is explicit in the syntax. One area where behav-\nior is often implicitly encoded is type ﬂow and automatic\ninference/coercion. Flow based typing is a very convenient\nfeature but requires a user of the language to know the ﬂow-\nrules [\n80, 88] of the checker, and to run the algorithm, to un-\nderstand type properties [ 15, 80]. As a balance between the\nconvenience of implicit ﬂow-typing and the simplicity of\nexplicit type coercion, B/o.sc/s.sc/q.sc_u.sc/e.scprovides specialized explicit\nﬂow typing expressions and binding.\nThe explicit ﬂow type operations shown in\nFigure 3 are\ndesigned to cover common idiomatic type tests (FlowSpe-\ncial), support standard is/subtype checks (FlowType), and\nenable ﬂow type inference when testing against constant\nvalues (FlowEQ). The ability to negate these tests allows\nthem to be used easily in control-ﬂow contexts as well. These\noperations can be used for is-testing using the ? operator\nor as-casting using the @ operator. This explicit operations\nhave the beneﬁt of clearly indicating in the source which\nvariables and type constraints are of relevance, it is applica-\nble to arbitrary expressions as opposed to only variables or\nsome limited forms, and it ensures that they compiler type-\nchecker does not experience compounding growth in man-\naging ﬂow-type information ( e.g. exponential path-sensitivity)\nor arbitrary limits on what inferences\n1 are made (e.g. discard\non path joins, only top-level variables, ...).\nExamples of these operations for type testing and coer-\ncion expressions include:\nx? some // test if x is a subtype of Some\nx@ some // coerce of x to a Some type or fail\nx?! < Nat > // test if x is not a Nat\nx@[5 i] // test if x is 5 and coerce to Int type\nfoo (x).f?<Bar > // test if arbitrary expression is type Bar\n1From a engineering perspective it is also removes the very painful probl em\nof later changes to these type-inference heuristics introducing (subt le) bugs\ninto an application!\n7\nMark Marron\nThe typing tests also enable special narrowing statements\nin blocks – rebinding the type of the variable. In this case\nnarrowing the type of x, which is initially declared as a Nat\n| none , to be a Nat (and raising a runtime error if it is\nnot). This explicit narrowing, as opposed to an implicit ﬂow-\nsensitive analysis around say, assert(x != none), enables\nus to explicitly encode the intent in the source so that it is\nexplicit and obvious to humans or AI agents.\nlet x: Nat ? = ...;\nlet e = x + 2n; // type error\n...\n// check that x is a Nat ( error otherwise ) and narrow\nx@<Nat >;\n...\nlet y = x + 2n; // ok\nThe typing tests are also used in control ﬂow expressions\nand statements to provide bindings in branches of control\nﬂow structures. B/o.sc/s.sc/q.sc_u.sc/e.scprovides the special $ variable that\nis automatically bound to the narrowed results of the condi-\ntional guard. Consider the following example where a vari-\nable may be Nat | none. With the ﬂow-type check if none\n(x) we know that on the false branch the type of x must be\na Nat. Instead of leaving this information implicit and sim-\nply reusing the variable x B/o.sc/s.sc/q.sc_u.sc/e.sccode leaves the type of x\nunchanged and introduces the new binder $ with the same\nvalue but the type restricted based on the test.\nlet x: Nat ? = ...;\nif none (x) {\nreturn 0n;\n}\nelse {\n// Binder for $ to value of x ( with type Nat )\nreturn $ + 10 n;\n}\nFinally, these FlowOp typing tests are also used to handle\nearly return statements in blocks. In the following example\nthe ?? operator syntactically reduces to if none (foo(...))\n{return none;} let x = foo(...)@!none; while the\n@@ operator reduces to the code if !<Nat>(x) {return\nx@Int;} x@<Nat>; . Thus, this syntax allows a developer\nto succinctly express these common check-and-early-return\nidioms in an explicit way and without ﬁlling the code with\nconditional ﬂows that obscure the underlying algorithm.\nfunction bar (k: Int ): Nat | Int | None {\n// test / narrow call result -- return none if fails\nlet x: Nat | Int = foo (...) ?? ! none ;\nlet e = x + 2n; // type error\n...\n// check / narrow type of x -- return Int otherwise\nx @@ <Nat >;\nreturn x + 2n; // ok\n}\nThese operators provide shorthand notation for common\nidioms [2] that developers use and ensure that they are syn-\ntactically surfaced in the code. This both simpliﬁes writing\nthe code, reduces the opportunities for developers to miss\nimportant behaviors, and provides AI agents with explicit\nrepresentations.\n5.3 Lambdas\nHigher order functions are a powerful programming mech-\nanism that can be used to great eﬀect to simplify code. How-\never, their use can also lead to diﬃcult to reason about ﬂows\nand inscrutable behaviors. Empirical work on the use of lamb-\ndas in large codebases [\n57] provides a compelling quantita-\ntive result that matches the anecdotal intuition. In particula r\nthe vast majority of use of lambdas are in direct positions\n(87.5% are passed directly as arguments in calls) and very\nfew examples of classic functional programming techniques,\nlike currying, were seen.\nWith this in mind the B/o.sc/s.sc/q.sc_u.sc/e.sclanguage provides a syn-\ntactically restricted version of lambdas where they:\n1. Cannot be stored in local variables or returned as func-\ntion/method results\n2. Can capture arguments but cannot modify their val-\nues\nB/o.sc/s.sc/q.sc_u.sc/e.sclambdas are also split into two categories. Pred-\nicates are denoted with the pred keyword, which must re-\nturn a Bool result, and other functions that may return any\ntype with the fn keyword.\n// takes a predicate\nl. allOf (pred (x) => x >= 0i)\n// takes a function\nl.map <Int >(fn (x) => x + 1i)\nIn combination these restrictions and conventions pro-\nvide the vast majority of beneﬁt that most developers get\nfrom lambda style expressions while prohibiting their more\nproblematic uses. These restrictions also ensure that we can\nsyntactically convert code using lambdas to a de-functionalized\nform where the functions are reduced to direct parametric\nspecializations as needed by the B/o.sc/s.sc/q.sc_u.sc/e.scIRlanguage (\nSection 4.7 ).\n5.4 Block Structure with Re-bindable Variables\nInterviews and conversations with developers, ranging from\nfortune 100 companies to 3-person startups, suggested a strong\npreference for block-scoped ﬂows and mutable variables over\na classic-functional let-bound expression tree (which B/o.sc/s.sc/q.sc_u.sc/e.scIR\nis). In order to unify these two representations we lever-\naged the loop-freedom of the source language to convert\nmultiple-assignments and convergent-dataﬂow into dynamic\nsingle assignment form [\n90]. Consider the code:\nfunction abs (x: Int ): Int {\nvar y = x;\nif (y < 0) {\ny = -y;\n}\nreturn y;\n}\n8\nToward Programming Languages for Reasoning – Humans, Symbo lic Systems, and AI Agents\nThis function shows the use of multiple updates to the\nsame variable and block structured conditional ﬂows. We\ndistinguish between variables, let, that are ﬁxed and those,\nvar, that can be updated. This ability to set/update a variable\nas a body executes simpliﬁes a variety of common coding\npatterns.\nSince the language is loop free, it can be easily converted\nto a SSA form [\n16], and the loop freedom also ensures that\nany assignment is also a single assignment dynamically! A\nsimple treeiﬁcation pass, with the introduction of continu-\nation functions if needed, also eliminates all DAG control\nﬂow. Thus, our block structured ﬂows and updated variables\nbecomes the following let-bound expression:\nfunction abs (x: Int ): Int {\nlet (y = x) in\nif y < 0 then -y else y\n}\nSimilar transformations allow B/o.sc/s.sc/q.sc_u.sc/e.scto support many\nother familiar block structured ﬂow features. The running\nbinary-tree example has an implementation utilizes these\nheavily, including early returns, merging control ﬂows, cre-\nating and later assigning variables (the tchild variable) and\nchecking for any possible uninitialized uses. These constructs\nare heavily used and well understood features in modern\nsoftware engineering so supporting them allows developers\nto easily express their intents in a natural way.\n5.5 Constructrors and Bulk Operators\nEven with immutable objects there can be subtle challenges\nwith constructor semantics and implementing operations\nwhich create a copy of a value with updates to some subset\nof the contained values. Constructor bodies where ﬁelds are\ninitialized sequentially with, potentially other computatio n\nmixed in, can lead to issues where methods are invoked on\npartially initialized values. Updates to objects are often i m-\nplemented by copying ﬁelds/properties individually while\nreplacing the some subset with new values. These issues can\nlead to both subtle bugs during initial coding and also make\nit diﬃcult to update data representations when refactoring\ncode or adding a new feature at some later date.\nConsider the code shown below. The use of atomic con-\nstructors prevents the partially initialized object problem [\n24,\n25, 42] when constructing the Baz object. This example also\nshows how the bulk algebraic operations simplify the up-\ndate/copy of the Baz object and eliminate the problem of\ntemporarily violated invariants during a series of single ﬁeld\nupdates\n2. B/o.sc/s.sc/q.sc_u.sc/e.scprovides explicit support for data invari-\nants, e.g. in the Node entity in our example) and described\nmore below, these are automatically checked on both initial\nconstruction and any updates.\nconcept Bar {\nfield f: Int ;\n2Fields can be declared as private, in which case these raw operations will\nnot be visible outside the type declaration.\n}\nentity Baz provides Bar {\nfield g: Int ;\nfield h: Bool ;\n}\n// create a Baz value with all fields initialized\nvar x = Baz {1 , 2, true };\n// copy of x with f updated to 3 and h to false\nvar y = x.{ f=3 , h= false };\nTo make these operations more useful they also handle\nthe common case of wanting to update a ﬁeld with a func-\ntion of that ﬁeld value. This is done by extending the range\nof where binders can be used and, for each ﬁeld updated, cre-\nating a variable that is scoped to the update expression and\nthat is bound to the original value of the ﬁeld. In the code\nbelow this allows us to increment the value of the ﬁeld f by\n3 and then assign the new value in the update.\n// copy of x with f incremented by 3\nvar y = x.{ f= $f + 3};\n5.6 Data Validation\nProgram logic checks are fundamental to quickly catching\nbugs and make implicit assumptions explicit in program. Thus,\nthe B/o.sc/s.sc/q.sc_u.sc/e.scsurface language provides a rich set of valida-\ntion features to support a broad range of uses including dy-\nnamic checking, static validation, optimization, and docu-\nmentation for human (and AI) developers. Including them\nas ﬁrst class components of the language provides several\nadvantages over libraries or 3rd party implementations.\nFrom a reasoning perspective having builtin validation\noperators ensures that every application will have the same\nlook and semantics around assertions. It also gives the com-\npiler and runtime direct knowledge of these special opera-\ntions for example an optimizer can move them oﬀ the hot\npath aggressively, do short circuit evaluation of any mes-\nsage or line number computations, and, if they are disabled,\ncan easily remove all of the dead code. In B/o.sc/s.sc/q.sc_u.sc/e.scwe use this\nawareness along with a new level, safety, that we ensure\nis always checked – e.g. the compiler is never allowed [\n74]\nto optimize it out!\nAssert/Pre/Post: The ﬁrst form of validation is a classic\nconditional assert statement that can be used to place ad-\nhoc checks in a block of code. B/o.sc/s.sc/q.sc_u.sc/e.scalso supports pre/-\npost conditions on functions and methods. These features\nallow developers to insert, explicit, information on expecta -\ntions/assumptions for any bit of code or invocation.\nInvariants and Validates:The ability to explicitly state\ndata invariants is one of the most powerful validation fea-\ntures in the B/o.sc/s.sc/q.sc_u.sc/e.sclanguage. These invariants allow a de-\nveloper to state a property in a single location – this prop-\nerty ensures that at every creation site it must be preserved\n9\nMark Marron\nand provides a guarantee for every use of the type in a pro-\ngram. An example invariant is seen in the binary-tree exam-\nple.\nIngesting data from external sources, such as command\nline args, network data, ﬁle reads, etc., is a critical task. Writ-\ning code to validate data, even structured data in JSON or\nXML form, is a tedious and error prone task [\n4]. Errors in\nthis code are ampliﬁed as they open opportunities for exter-\nnal, and potentially malicious, sources to directly interact\nwith the application.\nBy default B/o.sc/s.sc/q.sc_u.sc/e.scchecks all active invariants whenever\nan value is constructed. These are generally not as exten-\nsive as would be needed to fully validate untrusted inputs.\nThus, B/o.sc/s.sc/q.sc_u.sc/e.scprovides a validate keyword that allows the\nspeciﬁcation of checks that must be run on eternal inputs.\nWhen compiling B/o.sc/s.sc/q.sc_u.sc/e.scto executable code these validate\nchecks are combined with the invariants in a special func-\ntion that the host can use to create values from untrusted\nexternal data sources.\nFigure 4 shows code from a sample trading application\nprovided by Morgan Stanley that was ported to B/o.sc/s.sc/q.sc_u.sc/e.sc(see\nSection 7 ). In this code there are several invariants and exter-\nnal validations on the SaleInfo type. The check available\n>= 0I is performed everytime an SaleInfo value is created.\nThe invariant startAvailable >= 0Iis marked as test so\nit is only enabled when running the code in a test build.\nThe two validate checks are too expensive to run on\nevery internal operation but if we received a JSON value en-\ncoding this info from, say, a HTTP request from a 3rd party\nwe deﬁnitely want to check that the data is well formed and\nconsistent with our requirements (we can also use these for\nstatic veriﬁcation).\nLevels: The validate feature is a special, and very im-\nportant, case of the general problem of balancing checking\nuseful properties against the cost of running these checks.\nTo support the ability to utilize these speciﬁcation featur es\nwithout concern about how they will impact the performance\nend-users experience B/o.sc/s.sc/q.sc_u.sc/e.scallows any use of a validation\nannotation to be pre-ﬁxed with a level, spec, debug, test,\nrelease, or safety.\nThe debug, test, release levels are useful for controlling\nwhich checks are run dynamically under which conditions.\nThe spec level is useful for checks which would always be\ninfeasible to check at runtime but which are useful for docu-\nmentation, static analysis tools, and sampling based check-\ning if a program is run in debug build mode. The safety\nlevel is for checks that a developer wants to run, even if they\ncan be proven to always hold! This counter-intuitive feature\nis to ensure that a compiler will never eliminate tests that\nare critical to data integrity and may still be possible due to\nhardware or other failure modes.\nentity SaleOrder {\nfield id : StringOf < ValidID >;\nfield quantity : BigInt ;\n}\nentity SaleInfo {\nfield available : BigInt ;\nfield startAvailable : BigInt ;\nfield orders : List < SaleOrder >;\n// check sanity on every operation\ninvariant available >= 0I;\ninvariant test startAvailable >= 0I;\n// too expensive on every change\n// but * must * check on untrusted inputs\nvalidate orders . unique (pred (a , b) => a. id !== b. id );\nvalidate startAvailable - orders . sumOf <USD >( fn (a) =>\na. quantity ) == available ;\n}\nFigure 4. Declarations from Sample Trading App\n5.7 By-Ref Methods\nAs very common task is sequentially processing data with\nan environment of some sort. This can be clumsy to do man-\nually, requiring manual packing and unpacking of env/value\nresults, and the common functional solution of introducing\nmonadic features clashes with our desire to keep behavior\nsyntactically explicit. So, B/o.sc/s.sc/q.sc_u.sc/e.scintroduces the concept of\nref methods. These are explicitly tagged at both def and call\nsites and manage the update of the receiver variable with the\nnew state automatically.\nIn the following example the Counter is initialized to 0/u1D45B\nand at each ref method invoke the receiver variable is up-\ndated with the result of the this value in the called method\nas well as assigning the result value. The statement this.{ctr\n= $ctr + 1n};updates the value of this with the new ctr\nvalue. Any calls to the generateNextID are required to be\ntop-level (not nested in other expressions) and annotated\nwith a ref attribute. If either of these conditions are not sat-\nisﬁed the type-checker will reject the code.\nentity Counter {\nfield ctr : Nat ;\nfunction create () : Counter {\nreturn Counter {0n };\n}\nmethod ref generateNextID (): Nat {\nlet id = this . ctr ;\nthis .{ ctr = $ctr + 1n };\nreturn id;\n}\n}\nvar ctr = Counter :: create () ; // create a Counter\n// id1 is 0 -- ctr is updated\nlet id1 = ref ctr . generateNextID () ;\n// id2 is 1 -- ctr is updated again\n10\nToward Programming Languages for Reasoning – Humans, Symbo lic Systems, and AI Agents\nlet id2 = ref ctr . generateNextID ();\n5.8 Recursion\nComplex recursive control ﬂows obfuscate the intent and\nhinder automated analysis and tooling. Thus, B/o.sc/s.sc/q.sc_u.sc/e.scis de-\nsigned to encourage limited uses of recursion, increase the\nclarity of the recursive structure, and enable compilers/run-\ntimes to avoid stack related issues [\n59]. To accomplish these\ngoals B/o.sc/s.sc/q.sc_u.sc/e.scborrows from the design of the async/await\nsyntax and semantics [ 3] which is used to add structured\nasynchronous execution to a language. In this design the\nasync/await keywords are used to explicitly identify func-\ntions that are asynchronous and when these functions are\ninvoked.\nThe B/o.sc/s.sc/q.sc_u.sc/e.sclanguage takes a similar approach by intro-\nducing the recursive keyword which is used at both dec-\nlaration sites to indicate a function/method is recursive and\nagain at the call site so to aﬃrm that the caller is aware of\nthe recursive nature of the call. This feature is used in the\nbinary-tree example when implementing the has method.\nThis method is declared as recursive and later in the body\nat the callsite tchild.has[recursive](x) the call is explic-\nitly annotated as being potentially recursive.\nIn B/o.sc/s.sc/q.sc_u.sc/e.scthe type-checker will process the call-graph\nfor cycles and ﬂag all caller-callee relations inside the same\ncycle as requiring both annotations at the declaration and\ncall-site. Thus, mutually recursive calls will require annot a-\ntions on declarations and, recursive, call-sites as well. Thes e\nannotations primarily serve to make the, otherwise, implic-\nitly recursive nature of these calls explicit in the code syn-\ntax. This provides clarity to the developer on which calls\nmay involve recursion so they are not caught oﬀ-guard by\nthe re-entrant nature of the code. This information also pro-\nvides the compiler with the opportunity to convert an stack\nbased call into a CPS form to avoid possible stack-overﬂows\nor enable static stack size computation for small-stacks. The\ncombination of explicit demarcation of recursive execution\nalong with the ability to place strong pre/post conditions on\nthese calls serve as limits on the complexity that recursion\ncan introduce when reasoning about a block of code while\nstill allowing recursion as an option for when functors can-\nnot (or cannot reasonably) be used to express a computation.\n6 Simplicity and Clarity\nGiven the design of the core IR (\nSection 4 ) and the surface\nlanguage ( Section 5 ) this section looks at how they resolve\nthe challenges outlined in Section 2 for each of the agents.\n6.1 Areas of Simpliﬁcation\nImmutable State and Local Reasoning:The use of im-\nmutable value semantics and restrictions on exposing mem-\nory/object identity via equality operations ensures that the\nB/o.sc/s.sc/q.sc_u.sc/e.sclanguage is referentially transparent. As a result rea-\nsoning about the eﬀects of a statement in general, and func-\ntion/method calls in particular, can be done independently\nof the external context and using purely monotone reason-\ning. Speciﬁcally, no property that holds before some opera-\ntion can be invalidated by the eﬀect of the operation and the\nonly parts of the program state that inﬂuence the operation\nare the argument values.\nExplicit Behavior:The lifting of implicit information to\na textually explicit form with typedecls, explicit ﬂow typ-\ning, and restricted lambda syntax ensure that the intent of\nblocks of code can be largely understood from their syntax.\nThe addition of explicit support for pre/post, assert, and\ninvariant declaration syntax lets us lift, otherwise diﬀuse\nand implicit information, into an explicit form that can be\neasily discovered. These features ensure that code can be\nreasoned about, primarily, by looking at the text and explicit\ndeclarations without the need to do extensive simulation of\nbehavior, like a type-checking algorithm, a mutability chec k,\nor searching a codebase for diﬀuse information e.g. every lo-\ncation a given type is constructed in the application.\nDeclarative Collection Processing and Recursion:The\nelimination of loops in favor of collection functors eliminates\na major source of diﬃculty for symbolic analysis tooling.\nThey also enhance the readability of the code by providing\nexplicit and declarative ways of expressing operations on\ncollections. The addition of explicit recursive annotations\nprovides a simple way to identify recursive calls to avoid un-\nexpected reentrancy issues and as a way to explicitly identify\nthese calls for specialized processing when needed.\nFully Deterministic Behavior:Exhaustively specifying\nthe semantics of each operation, including canonical order-\nings for associative containers, sort stability, and evaluatio n\norders gives B/o.sc/s.sc/q.sc_u.sc/e.sccode a powerful property. Speciﬁcally,\nfor any input there is a single, unique, and deterministic\nvalue that is the result. Thus, although B/o.sc/s.sc/q.sc_u.sc/e.scprograms\nare deﬁned in terms of evaluation order and ﬂow their se-\nmantics is isomorphic to the direct encoding in ﬁrst-order\nlogic (\nSection 7.2 ).\nAtomic Data Operations:The use of atomic construc-\ntors and bulk-data operations in B/o.sc/s.sc/q.sc_u.sc/e.sc, along with auto-\nmatically checked invariants, makes it possible to ensure no\nvalue is ever in a partially deﬁned or invalid state. This pre-\nvents accidental corruption and the construction of cyclic\nreference loops. Combined with the validate support, these\nfeatures ensure that when reasoning about code semantics,\nwe can make strong guarantees about the properties that\nmust hold at all program points.\nValue Equality and Explicit Identity:The restriction\nof equality comparisons to, primitive based, KeyType val-\nues prevents the exposure of reference equality information\n11\nMark Marron\n(which would violate referential transparency). It also en-\nsures that the deﬁnition of equality is uniform across an\napplication and avoids the need to check for possible diﬀer-\nences between, say, equality used in an associative container\nand equality as implemented in a == operator. The elimina-\ntion of semantically visible aliasing has additional beneﬁts\nfor runtime and compiler implementations.\n6.2 Reasoning Agents and Beneﬁts\nHuman Developers:The B/o.sc/s.sc/q.sc_u.sc/e.sclanguage provides a unique\ncombination of features that eliminate various bug classes\nand simplify reasoning scenarios that humans ﬁnd challeng-\ning. The primary area of improvement comes from regular-\nizing application behavior in a way that reduces (or elim-\ninates) special cases a human developer needs to keep in\nmind. For example there is no need to remember that sort or-\nder may change sometimes, that negation may overﬂow in\none speciﬁc case (INT_MIN), wonder if a call modiﬁes global\nstate, ﬁgure out what deﬁnition of equality will be used for\na comparison. The second major beneﬁt that B/o.sc/s.sc/q.sc_u.sc/e.scpro-\nvides for a human when reasoning about code is a strong\nbias for explicit intent expression. This includes the ability\nto explicitly specify logical invariants, the use of ﬂow-type\ninformation, and the use of collection functors instead of de-\npending on idiomatic loop structure to convey intent. These\nfeatures enable developers to understand code explicitly in-\nstead of relying on (failable) intuition and patterns.\nSymbolic Analysis Tooling:The B/o.sc/s.sc/q.sc_u.sc/e.scIRrepresenta-\ntion is well-suited to supporting symbolic analysis tools. By\nconstruction, it eliminates major sources of complexity, in-\ncluding aliasing, mutability, and nondeterminism, and greatly\nsimpliﬁes other sources like inductive invariants. As a re-\nsult it is, almost trivially, mappable to an eﬃciently solv-\nable decidable/semi-decidable fragment of ﬁrst order logic\n(\nSection 7.2 ). Other symbolic analysis techniques, including\nabstract-interpretation based, also beneﬁt from the reduced\nneeds to perform strong-updates or frequently apply generic\nwidening. Thus, these models are able to avoid getting ”lost\nin the details” of possible eﬀects of an operation or losing in-\nformation by making conservative assumptions in general\ncases. In practice this leads to increased scalability and pre -\ncision of the analysis and, as a result, much more practical\nvalue from the tools/optimizations that they power.\nAI Agents: As with human developers, the features in\nB/o.sc/s.sc/q.sc_u.sc/e.scthat explicitly encode intent in the syntax provides\na major boost to LLM based agents. The features in B/o.sc/s.sc/q.sc_u.sc/e.sc\nalso provide a richer set of information modalities for the\nmodels to use and extract information from. As seen in the\nSection 7.3 case study an agent working with B/o.sc/s.sc/q.sc_u.sc/e.sccode\ncan use the textual language, evaluation of concrete values,\nand queries to symbolic tools that understand the declara-\ntive nature of invariants and assertions. These features im-\nprove the ability of the agent to extract useful information\nfrom the (limited) context it is given, provide symbolic guard rails\nto limit the possibility of producing catastrophically wrong\nresults, and allows the system to catch these mistakes quickl y\nand minimize the impact when the agent does generate er-\nroneous outputs.\n7 Case Studies\nIn this section we examine how the features of B/o.sc/s.sc/q.sc_u.sc/e.scim-\npact mechanized development. This section uses two case\nstudies, small model validation and AI assisted programming\nas representative studies to illustrate the potential for B/o.sc/s.sc/q.sc_u.sc/e.sc\nto power the future of software development.\n7.1 Implementation\nThe B/o.sc/s.sc/q.sc_u.sc/e.sclanguage, including a compiler/type-checker,\nruntime, checker, synthesizer framework, and Cloud API\nspeciﬁcation framework, have all been implemented as open-\nsource software and are publicly available\n3. The initial im-\nplementation uses 30kloc of TypeScript and 5kloc of B/o.sc/s.sc/q.sc_u.sc/e.sc\ncode. We expect this count to grow rapidly as the language\nmoves from a collection of proof-of-concept components to\na full-featured platform. There is active collaboration wi th\ncolleagues at Microsoft to apply B/o.sc/s.sc/q.sc_u.sc/e.scto technical chal-\nlenges in API/Data Speciﬁcation and software quality assur-\nance.\n7.2 Small-Model Validation\nMotivation. Developers care deeply about the quality and\nreliability of the software they ship. However, there is a\nconstant tension between time spent on quality and time\nspent building new features or addressing other client needs.\nFor the majority of applications this calculation makes full -\nprogram veriﬁcation an impractical option and, even with\nthe needed resources, maintaining full-behavioral speciﬁca-\ntions is a Sisyphean task for most teams as they experience\ncontinuously changing business requirements and evolving\nfeature sets.\nAs a result (most) development teams are not interested\nin a system that performs full-proofs of correctness. Instead\nthe sweet-spot is simple logical checks (asserts, pre/post ,\nand data invariants) that can be written in the same lan-\nguage, and inline, as the application. Full proofs that these\nchecks are always satisﬁed, are of course nice but develop-\ners often do not have time and technical ability to debug/re-\nsolve proof failures, so more practically useful is generati ng\ninputs that trigger them if they can fail. In general the pref-\nerence is for small inputs, or small reproductions that, are\n3B/o.sc/s.sc/q.sc_u.sc/e.sc source code is available at\nh/t_tps://github.com/BosqueLanguage/BosqueCore\n12\nToward Programming Languages for Reasoning – Humans, Symbo lic Systems, and AI Agents\neasy to debug and, are considered to exist for most possi-\nble failures (the small-model hypothesis [\n40]). Under these\nconstraints we want to create a checker that:\n1. Can be applied to any runtime or user deﬁned as-\nsert/invariant failure\n2. Does not require any specialized annotations or de-\nveloper knowledge of proof systems\n3. Provides actionable results in the form of a witness\ninput when a failing condition is found\nThis problem has been studied as a semi-decision pro-\ncedure for 20+ years in the form of Model Checking [ 47],\nDynamic-Symbolic Analysis [75], concrete Fuzzing [29], and\nrecently by formulating new (underapproximating) logics\nfor modeling program semantics [\n71]. Despite the impor-\ntance of the problem and the substantial amount of work\non the topic it remains an unresolved challenge in practice.\nDirect Solution withB/o.sc/s.sc/q.sc/u.sc/e.sc. In contrast to other widely\nused languages\n4 where the semantics are not eﬃciently en-\ncodable in ﬁrst-order logic (FOL), due to features like loop s,\nmutability, non-deterministic behaviors, etc. as identiﬁed in\nSection 2 , B/o.sc/s.sc/q.sc_u.sc/e.sccan be converted in a direct manner into\neﬃciently decidable FOL theories. The design restrictions\non the B/o.sc/s.sc/q.sc_u.sc/e.scIRcore language enable us to map it, almost\nentirely, to eﬃciently decidable theories supported by a SAT-\nModule-Theory (SMT) solver [\n18]. Operations on numbers,\ndata-types, and functions all map to core decidable theo-\nries – Integers, Constructors, Uninterpreted Functions, and\nInterpreted Functions. Strings and Sequences are used to\nmodel strings and collections. In Z3 the theories of Strings\nand Sequences are semi-decision procedures in the unbounded\ncase. However, as we are interested in small-model inputs\nthese are always bounded and become fully (and eﬃciently)\ndecidable. As a result we can guarantee that an actionable\n(small) reproduction of a failure can be found if it exists and,\nfrom a practical perspective, this can be done automatically\nand eﬃciently in practice.\nExample and Case Study.To illustrate how this system\nworks we show a (simpliﬁed) piece of code from a sample\napplication, consisting of 2Kloc of code, published by Mor-\ngan Stanley [\n64]. The relevant type deﬁnitions deﬁnitions,\nSaleOrder and SaleInfo are in Figure 4. The function in\nFigure 5 takes a sale order, checks if there is available inven-\ntory to satisfy it, and then either accepts the order (adding it\nto the history) or returns none to indicate it was rejected. In\nthis function there is one user deﬁned property that needs to\nbe checked, speciﬁcally that whenever an order is accepted\nthe inventory must be reduced. This is clearly not a full, or\neven very complete speciﬁcation, but in practice these types\nof sanity check conditions are very popular as they are eﬀec-\ntive in ﬁnding bugs and easy for developers to understand.\n4A notable exception is Elm [ 22, 30].\nfunction process (\nsales : SaleInfo , order : SaleOrder\n): SaleInfo ?\nensures $return != none == >\n$return @< SaleInfo >. available <= sales . available ;\n{\nif ( sales . available < order . quantity ) {\nreturn none ;\n}\nelse {\nreturn sales .{\navailable = $available - order . quantity ,\norders = $orders . pushBack ( order )\n};\n}\n}\nFigure 5. Order Processing from Trading App\nUsing the tooling that B/o.sc/s.sc/q.sc_u.sc/e.scprovides we can run the\nstatic checker over the application. This checker will enu-\nmerate every possible error in the application and then trans-\nlate the relevant code to a (small-model) decidable fragment\nof logic. Each of these logical formula are passed to the Z3\nSMT solver for either a satisfying assignment, which would\nbe the failing input, or unsat which indicates that there does\nnot exist any small-model input that can trigger the error!\nWhen running the checker tool on the sample Fintech ap-\nplication we are able to produce a result for every error in\nunder 0.2/u1D460per error (including process startup and loading\nSMTLIB ﬁles). For the ensures clause the tool reports that\nan error is possible and that is corresponds to the case where\nthe order entity is:\n{\nid : /quotedbl.Var order_1 /quotedbl.Var,\nquantity : -1\n}\nIf this concrete input is given to the application the en-\nsures assertion will trigger as the negative quantity results\nin an increase in the availability. This is an error in the\nbusiness logic, as SaleOrder is expected to always have a\npositive quantity. A developer can ﬁx this bug by adding\nan invariant to the SaleOrder or changing the type of the\nquantity ﬁeld to be a BigNat (instead of a BigInt). After\neither of the changes re-running the checker will report that\nthere is no small input that can trigger this ensures clause.\nThis case study shows how the design of the B/o.sc/s.sc/q.sc_u.sc/e.scIR\nrepresentation enables the direct solution of a foundational\nsoftware-engineering problem. The design of the intermedi-\nate language enables us to directly map code to eﬃciently\ndecidable logics and avoid the complexities that have pre-\nvented the widespread use of these types of checkers in the\npast. Conversion of the full language semantics and check-\ning of arbitrary user properties is among the most challeng-\ning reasoning problems in the SE tooling space. Thus, this\nis a clear demonstration that B/o.sc/s.sc/q.sc_u.sc/e.sccreates opportunities\nfor advancement in the practical development of other tools,\n13\nMark Marron\nwith simpler reasoning needs such as those based on ab-\nstract interpretation or dataﬂow analysis, as well.\n7.3 AI Assisted Programming\nAI assisted programming is in its early stages but several key\nchallenges are already clear. The ﬁrst is a need to provide\nguardrails for the code that these probabilistic agents gen-\nerate. This is tied with the desire to provide multi-modal in-\nputs for them to work with – the program synthesis commu-\nnity [\n32, 33, 56] has long looked at combinations of natural-\nlanguage, formal specs, examples, and context as speciﬁca-\ntions for generating code. Finally, the current large-language-\nmodel (LLM) agents are most eﬀective when dealing with\ntext and, the more relevant information that can be hoisted\ninto this representation, the more eﬀective the agents are.\nAs an example consider the code below where we use a\nLLM agent to generate code for a function body that a de-\nveloper has sketched out in TypeScript.\n/* Find the largest pair of values from the lists . */\nfunction maxPair (x: number [] , y: number []) :\n[ number , number ]\n{\n// generate the implementation code here\n}\nIn a language such as TypeScript (or Java) the LLM must\nresolve the users intent solely from the the natural language\nin comments and (partial) code context. In our example pass-\ning this to GPT-4 (or Github Copilot) and asking for code\ncompletions produces multiple possible solutions the high-\nest ranked in both cases is the following:\nlet maxPair : [ number , number ] = [0 , 0];\nfor (let i = 0; i < x. length ; i ++) {\nif (x[i] > maxPair [0]) {\nmaxPair [0] = x[i ];\nmaxPair [1] = y[i ];\n}\n}\nInterestingly this solution only looks for the maximum value\nin x and is unlikely to be the desired functionality. If we sam-\nple more solutions we also ﬁnd versions that take the max\nfrom each list independently which is more likely to be the\ndesired response but just from the source text it is diﬃcult\nto make this choice with conﬁdence.\nIn contrast B/o.sc/s.sc/q.sc_u.sc/e.schas multiple features which are de-\nsigned to make intent and speciﬁcations explicit in the source\ncode. The expressive type system, including unions, nullable-\ntypes, and typedecls, along with the explicit syntactic sup-\nport for pre/post conditions and invariants trivially exposes\nrich contextual information directly to the LLM. The code\nbelow shows the same signature but augmented with par-\ntial logical postconditions and examples of inputs and the\ncorresponding outputs.\n/* Find the largest pair of values from the lists . */\nfunction maxPair (x: List <Int >, y: List <Int >): [Int , Int ]\nensures x. contains ( $return .0) ;\nensures y. contains ( $return .1) ;\nexamples [\n[ List {3 , 2} , List{3 , 5}] => [2 , 5]\n];\n{\ndefer ;\n}\nWith this extra contextual information the code comple-\ntions generated are much higher quality. The top ranked so-\nlutions we extract include the following two candidates:\n(1)\nreturn [x. max () , y. max () ];\n(2) return List ::zip <Int , Int >(x, y)\n. maxArg <Int >(fn (v) => v .0 + v .1) ;\nJust having the ensures and examples as textual hints re-\nsulted in a substantial improvement in the generated code.\nThe highest ranked output (#1) is quite plausible. However,\nwe can use the ensures and examples to further check the\ngenerated code. By running the examples as test cases we\nsee that output (1) is not the desired result. Instead a slightl y\nlower ranked output #2\n5 satisﬁes the example and the en-\nsures clauses. Thus, after re-ranking we suggest output #2,\nwhich in this case, is the actual desired output. A prelimi-\nnary evaluation with manually blanking out bodies shows\nthat the additional information available in B/o.sc/s.sc/q.sc_u.sc/e.sc(plus\nthe absence of loops which are known problems for synthe-\nsis [\n76]) consistently improves results over simple text/code.\nThis case study shows how B/o.sc/s.sc/q.sc_u.sc/e.scenables the combi-\nnation of natural language via comments and declarations,\ndeclarative constraints via the ensures clauses, and exam-\nples, in a form that a LLM can consume and use to drive\nthe code generation task. These features provide a way to\nscreen for invalid generations, by simply running the pro-\nvided samples, and provide guardrails by validating the gen-\nerated code against pre/post conditions and invariants (us-\ning methods like the previously described small-model val-\nidator). In addition to supporting the direct code synthe-\nsis task, this multi-modal interaction capability also opens\nup a variety of options for exploring user experiences and\nmulti-round interactions as part of the code generation pro-\ncess [\n56].\n8 Related Work\nThroughout this paper we have discussed the conceptual\nframeworks [8, 17, 43, 53] and language constructs [ 1, 6, 21,\n63, 66, 88] that have motivated the development and the de-\nsign of the B/o.sc/s.sc/q.sc_u.sc/e.sclanguage. Thus, this section focuses on\ntopics related to the complexity issues identiﬁed and con-\nnections to other lines of research.\nInvariant generation: The problem of generating loop\ninvariants goes back to the introduction of loops as a con-\ncept [\n28, 38]. Despite substantial work on the topic [ 35, 50,\n5The exact rank of this version varies per run.\n14\nToward Programming Languages for Reasoning – Humans, Symbo lic Systems, and AI Agents\n81, 83] the problem of generating precise loop invariants re-\nmains an open problem. This has severely limited the usabil-\nity and adoption of formal methods in industrial develop-\nment workﬂows. Notable successes include seL4 [\n45], Com-\npCert [ 51], and Everest [ 77]. However, all of these systems\nrequired expertise in formal methods that is beyond what\nis available to most development teams. The B/o.sc/s.sc/q.sc_u.sc/e.sclan-\nguage seeks to sidestep this challenge entirely by avoiding\nthe presence of unconstrained iteration.\nEquality and Reference Identity: Equality is a compli-\ncated concept in programming [\n69]. Despite this complex-\nity it has been under-explored in the research literature and\nis often deﬁned based on historical precedent and conve-\nnience. This can result in multiple ﬂavors of equality living\nin a language that may (or may not) vary in behavior and re-\nsults in a range of subtle bugs [\n39] that surface in surprising\nways.\nReference identity, and the equality relation it induces,\nis a particularly interesting example. Identity is often the\ndesired version of equality for classic object-oriented pro -\ngramming [\n69] and having it as a default is quite conve-\nnient. However, in many cases a programmer desires equal-\nity based on values, or a primary key, or an equivalence re-\nlation and a default equality based on identity is, instead, a\nsource of bugs. Further, the fact that it is based on memory\naddresses is a complication to pass-by-value optimizations\nof attempts to compile to non Von Neumann architectures\nlike FPGAs [\n46].\nAlias Analysis: The introduction of identity as an ob-\nservable feature in a language semantics immediately pulls\nin the concept of aliasing. This is another problem that has\nbeen studied extensively over the years [\n36, 37, 48, 61, 62, 84]\nand remains an open and challenging problem. A major mo-\ntivation for this work is, in a sense, to undo the introduc-\ntion of reference identity and identify code where reference\nequality does not need to be preserved. This is critical to\nmany compiler optimizations including classic transforma-\ntions like scalar ﬁeld replacement, conversion to pass-by-\nvalue, and copy-propagation [\n44, 65]. This information is\nalso critical to compiling to accelerator architectures lik e\nSIMD hardware [ 5].\nFrames and Ownership: The problem of aliasing is fur-\nther compounded with the introduction of mutation. Once\nthis is in the language the problem of computing frames [\n79]\nand purity [85] becomes critical. Often developers work around\nthe problem of explicit frame reasoning by using an owner-\nship [12, 13] discipline in their code. This may be a com-\npletely convention driven discipline or, more recently, may\nbe augmented by runtime support such as smart pointers [\n66]\nand type system support [ 31, 80, 87, 91].\nConcurrency, and Environmental Interaction: Rea-\nsoning in concurrent (parallel) applications with mutablil-\nity is a challenging problem. As all B/o.sc/s.sc/q.sc_u.sc/e.scvalues are im-\nmutable the problem of Read-Write or Write-Write depen-\ndencies do not exist, so parallelism for performance can be\ndone aggressively without concern for changing application\nbehavior. Concurrency and non-determinism that result from\nenvironmental interaction such as user interactions, network,\nor external interaction with other processes are currently\nbeyond the scope of B/o.sc/s.sc/q.sc_u.sc/e.sc. Instead it operates as a pure\ncomputation language that can be embedded by a host (or\nother language like Node.js modules [\n67]) that manage async\nbehavior and IO. A promising direction is integrating a core\ncomputation language (like B/o.sc/s.sc/q.sc_u.sc/e.sc) with an interaction fo-\ncused language such as P/P# [\n20] that has sophisticated meth-\nods for analyzing and testing concurrency and environmen-\ntal interactions [\n19].\nIncorrectness and Under Approximate Analysis: In-\ncorrectness Logic [71] and other under approximate approaches [ 7]\nrepresent an interesting and recent development in the de-\nsign space of program analysis. These systems look to fuse\nthe power of symbolic representations to capture many con-\ncrete states while under (rather than over) approximating\nreachability. Interestingly, one of the motivations for intro-\nducing Incorrectness Logic is that (p. 4) “...the exact reason-\ning of the middle line of the diagram [strongest post seman-\ntics] is deﬁnable mathematically but not computable (un-\nless highly incomputable formulae are used to describe the\npost). ” However, as shown in this paper, this middle line of\nexact and decidable semantics is practical to compute when\nthe language semantics are designed appropriately.\nSynthesis: Program synthesis is an active topic of research\nbut the need to reason about loops has limited the applica-\ntion of synthesis to mostly straight-line code. Work on code\nwith loops has been more limited due to the challenge of rea-\nsoning about loops in code [\n5, 11] and the diﬃcultly synthe-\nsizers have constructing reasonable code that includes raw\nloop and conditional control-ﬂow [\n76]. Thus, a language like\nB/o.sc/s.sc/q.sc_u.sc/e.sc, that provides high-level functors as primitives and\ncan be eﬀectively reasoned about opens new possibilities for\nprogram synthesis.\n9 Onward!\nThis paper argues for a foundational re-conceptualization of\nthe role of programming languages in the process of build-\ning software systems. Instead of being a set of increasingly\npowerful features and logical abstractions that a developer\nuses to formalize what is typed into a ﬁle, we advocate for\n15\nMark Marron\nthem to be built as a substrate that is optimized for mech-\nanization and reasoning tasks. This mindset led to revisit-\ning many common assumptions about the features in a lan-\nguage and a drastic push for simpliﬁcation of their seman-\ntics.\nSection 2 enumerated these features, and the challenges\nthey create for human/symbolic/statistical agents, while Section 4\nand Section 5 show how a practical language can be designed\nto address these challenges.\nTo validate the eﬀectiveness of the design in actually ad-\ndressing the challenges identiﬁed we looked at two case\nstudies that exercise diﬀerent aspects of reasoning about an\napplication. Both applications in\nSection 7 provide capabili-\nties that are beyond the current state of the art in any main-\nstream programming ecosystem and, both, were built us-\ning variations on standard approaches. The key to enabling\nthem was the ability to eﬀectively perform reasoning on the\napplication semantics!\nWith this initial success it is time to move Onward! Based\non our experience with the language, case studies and proof-\nof-concept systems, we believe the core of the language is\nstable enough to build on. The compiler for B/o.sc/s.sc/q.sc_u.sc/e.scis now\nbeing written in B/o.sc/s.sc/q.sc_u.sc/e.sc, collaborators are working with us\non applying B/o.sc/s.sc/q.sc_u.sc/e.scto solve critical technical challenges,\nand the potential for innovative tooling and platform re-\nsearch is massive\n6. We believe this is a unique opportunity\nfor the academic and industrial communities to advance into\na new era of programming languages that fully embraces\nthe forces of mechanization, integration, AI driven coding,\nthat are shaping the software development landscape.\nAcknowledgements\nThis work is the result of many years of conversations, expe-\nriences, and thinking. I would like to give a special thanks to\nEd Maurer, Gaurav Seth, Brian Terlson, Hitesh Kanwathirtha,\nMike Kaufman, Todd Mytkowicz, and Earl Barr for all their\nthoughts and conversations. I would also like to thank Stephen\nGoldbaum and Richard Perris for their insights on how tech-\nnology is impacting the FinTech sector. Finally, I want to ac-\nknowledge the the Node.js community for their innovation\nand willingness to experiment!\nReferences\n[1] Miltiadis Allamanis, Earl T. Barr, Christian Bird, Premkumar T. D e-\nvanbu, Mark Marron, and Charles A. Sutton. Mining semantic loop\nidioms. IEEE Transactions on Software Engineering , 44, 2018.\n[2] Miltiadis Allamanis and Charles Sutton. Mining idioms from source\ncode. In FSE, 2014.\n[3] Async/await, 2018.\nh/t_tps://blogs.msdn.microso/f_t.com/dsyme/2007/10/10/introducing-f-asynchronous-workflows/ .\n[4] Vaggelis Atlidakis, Patrice Godefroid, and Marina Polishchuk. Re stler:\nStateful REST API fuzzing. In ICSE, 2019.\n[5] Gilles Barthe, Juan Manuel Crespo, Sumit Gulwani, Cesar Kunz, a nd\nMark Marron. From relational veriﬁcation to SIMD loop synthesis.\nIn PPoPP, 2013.\n6This project is fully open-source at:\nh/t_tps://github.com/BosqueLanguage/BosqueCore\n[6] Gavin Bierman, Erik Meijer, and Wolfram Schulte. The essence of\ndata access in C /u1D714: The power is in the dot! In ECOOP, 2005.\n[7] Sam Blackshear, Nikos Gorogiannis, Peter W. O’Hearn, and Ilya\nSergey. Racerd: Compositional static race detection. 2018.\n[8] Frederick P. Brooks, Jr. No silver bullet essence and accidents of soft-\nware engineering. Computer, 20, 1987.\n[9] Sebastian Burckhardt, Chris Gillum, David Justo, Konstantinos K allas,\nConnor McMahon, and Christopher S. Meiklejohn. Durable func-\ntions: Semantics for stateful serverless. Proceedings ACM Program-\nming Languages, 5, 2021.\n[10] V8 doesn’t stable sort, 2018.\nh/t_tps://bugs.chromium.org/p/v8/issues/detail?id=90.\n[11] Berkeley Churchill, Rahul Sharma, JF Bastien, and Alex Aiken. Sound\nloop superoptimization for google native client. In ASPLOS, 2017.\n[12] Dave Clarke and Sophia Drossopoulou. Ownership, encapsulat ion\nand the disjointness of type and eﬀect. In OOPSLA, 2002.\n[13] David G. Clarke, John M. Potter, and James Noble. Ownership t ypes\nfor ﬂexible alias protection. In OOPSLA, 1998.\n[14] Copilot, 2023. h/t_tps://github.com/features/copilot.\n[15] Will Crichton. The usability of ownership. In HATRA, 2020.\n[16] Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and\nF. Kenneth Zadeck. Eﬃciently computing static single assignment\nform and the control dependence graph. ACM Transactions on Pro-\ngramming Language Systems , 13, 1991.\n[17] O. J. Dahl, E. W. Dijkstra, and C. A. R. Hoare, editors. Structured\nProgramming. Academic Press Ltd., London, UK, UK, 1972.\n[18] Leonardo de Moura, Nikolaj Bjørner, and et. al. Z3 SMT Theore m\nProver. https://github.com/Z3Prover/z3, 2021.\n[19] Pantazis Deligiannis, Alastair F. Donaldson, Jeroen Ketema, Akas h\nLal, and Paul Thomson. Asynchronous programming, analysis and\ntesting with state machines. In PLDI, 2015.\n[20] Ankush Desai, Vivek Gupta, Ethan Jackson, Shaz Qadeer, Srira m Ra-\njamani, and Damien Zuﬀerey. P: Safe asynchronous event-driven pro-\ngramming. In PLDI, 2013.\n[21] Azure durable functions, 2019.\nh/t_tps://docs.microso/f_t.com/en-us/azure/azure-functions/durable/durable- \n[22] 2019. h/t_tps://elm-lang.org/.\n[23] express.js, 2019. h/t_tps://expressjs.com/.\n[24] Manuel Fähndrich and K. Rustan M. Leino. Declaring and checking\nnon-null types in an object-oriented language. In OOPSLA, 2003.\n[25] Manuel Fahndrich and Songtao Xia. Establishing object invariants\nwith delayed types. In OOPSLA, 2007.\n[26] Roy Thomas Fielding. Architectural Styles and the Design of Network-\nBased Software Architectures . PhD thesis, 2000.\n[27] Jean-Christophe Filliâtre and Andrei Paskevich. Why3 — where p ro-\ngrams meet provers. In ESOP, 2013.\n[28] R. W. Floyd. Assigning meanings to programs. Mathematical Aspects\nof Computer Science , 19, 1967.\n[29] American fuzzy lop, 2023. h/t_tps://github.com/google/AFL.\n[30] Stephen Goldbaum, Attila Mihaly, Tosha Ellison, Earl T. Bar r, and\nMark Marron. High assurance software for ﬁnancial regulation and\nbusiness platforms. In VMCAI, 2021.\n[31] Colin S. Gordon, Matthew J. Parkinson, Jared Parsons, Aleks Br om-\nﬁeld, and Joe Duﬀy. Uniqueness and reference immutability for safe\nparallelism. In OOPSLA, 2012.\n[32] Sumit Gulwani. Automating string processing in spreadsheets using\ninput-output examples. In POPL, 2011.\n[33] Sumit Gulwani and Mark Marron. Nlyze: Interactive programming\nby natural language for spreadsheet data analysis and manipulation.\nIn SIGMOD, 2014.\n[34] Zhenyu Guo, Sean McDirmid, Mao Yang, Li Zhuang, Pu Zhang, Ying-\nwei Luo, Tom Bergan, Madan Musuvathi, Zheng Zhang, and Lidong\nZhou. Failure recovery: When the cure is worse than the disease. In\nHotOS XIV , 2013.\n[35] Ashutosh Gupta and Andrey Rybalchenko. Invgen: An eﬃcient in-\nvariant generator. In CAV, 2009.\n16\nToward Programming Languages for Reasoning – Humans, Symbo lic Systems, and AI Agents\n[36] Ben Hardekopf and Calvin Lin. Flow-sensitive pointer analysis for\nmillions of lines of code. In CGO, 2011.\n[37] Michael Hind. Pointer analysis: Haven’t we solved this problem ye t?\nIn PASTE, 2001.\n[38] C. A. R. Hoare. An axiomatic basis for computer programming. Com-\nmunications of the ACM , 12, 1969.\n[39] David Hovemeyer and William Pugh. Finding bugs is easy. SIGPLAN\nNotices, 39, 2004.\n[40] Daniel Jackson and Craig A. Damon. Elements of style: Analyzing a\nsoftware design feature with a counterexample detector. ISSTA , 1996.\n[41] Java streams, 2019. h/t_tps://docs.oracle.com/javase/8/docs/api/java/util/stream/package-summary.html.\n[42] On partially-constructed objects, 2010.\nh/t_tp://joeduﬀyblog.com/2010/06/27/on-partiallyconstructed-objects/.\n[43] Deepak Kapur, David R. Musser, and Alexander A. Stepanov. Te cton:\nA language for manipulating generic objects. In Program Speciﬁcation,\n1982.\n[44] Ken Kennedy and John R. Allen. Optimizing Compilers for Modern\nArchitectures: A Dependence-based Approach . Morgan Kaufmann Pub-\nlishers Inc., San Francisco, CA, USA, 2002.\n[45] Gerwin Klein, Kevin Elphinstone, Gernot Heiser, June Andronick,\nDavid Cock, Philip Derrin, Dhammika Elkaduwe, Kai Engelhardt,\nRafal Kolanski, Michael Norrish, Thomas Sewell, Harvey Tuch, and\nSimon Winwood. sel4: Formal veriﬁcation of an os kernel. In SOSP,\n2009.\n[46] Stephen Kou and Jens Palsberg. From OO to FPGA: Fitting round\nobjects into square hardware? In OOPSLA, 2010.\n[47] Daniel Kroening, Edmund Clarke, and Karen Yorav. Behavioral con-\nsistency of C and Verilog programs using bounded model checking.\nIn DAC, 2003.\n[48] Chris Lattner, Andrew Lenharth, and Vikram Adve. Making context-\nsensitive points-to analysis with heap cloning practical for the real\nworld. In PLDI, 2007.\n[49] K. Rustan M. Leino. Dafny: An automatic program veriﬁer for fu nc-\ntional correctness. In LPAR, 2010.\n[50] K. Rustan M. Leino and Francesco Logozzo. Loop invariants on de-\nmand. In APLAS, 2005.\n[51] Xavier Leroy. A formally veriﬁed compiler back-end. Journal Auto-\nmated Reasoning, 43, 2009.\n[52] LINQ, 2019.\nh/t_tps://docs.microso/f_t.com/en-us/dotnet/csharp/programming-guide/concepts/linq/ .\n[53] Barbara Liskov and Stephen Zilles. Programming with abstract data\ntypes. In VHLL, 1974.\n[54] lodash, 2019. h/t_tps://lodash.com/.\n[55] log4j CVE, 2021. h/t_tps://nvd.nist.gov/vuln/detail/CVE-2021-44228.\n[56] Mikaël Mayer, Gustavo Soares, Maxim Grechkin, Vu Le, Mark Ma r-\nron, Oleksandr Polozov, Rishabh Singh, Benjamin Zorn, and Sumit\nGulwani. User interaction models for disambiguation in program-\nming by example. In UIST, 2015.\n[57] Davood Mazinanian, Ameya Ketkar, Nikolaos Tsantalis, and Danny\nDig. Understanding the use of lambda expressions in Java. Proceed-\nings ACM Programming Languages , 1, 2017.\n[58] John McCarthy and Patrick J. Hayes. Some philosophical prob lems\nfrom the standpoint of artiﬁcial intelligence. In Machine Intelligence\n4, pages 463–502. Edinburgh University Press, 1969.\n[59] Steve McConnell. Code Complete, Second Edition . Microsoft Press,\nRedmond, WA, USA, 2004.\n[60] Kenneth L. McMillan and Oded Padon. Ivy: A multi-modal veriﬁca-\ntion tool for distributed algorithms. In CAV, 2020.\n[61] Mario Méndez-Lojo, Augustine Mathew, and Keshav Pingali. Paral lel\ninclusion-based points-to analysis. In OOPSLA, 2010.\n[62] Ana Milanova, Atanas Rountev, and Barbara G. Ryder. Parameter ized\nobject sensitivity for points-to analysis for Java. ACM Transactions\non Software Engineering and Methodology , 14, 2005.\n[63] Robin Milner, Mads Tofte, and David Macqueen. The Deﬁnition of\nStandard ML. MIT Press, Cambridge, MA, USA, 1997.\n[64] Morphir, 2021.\nh/t_tps://github.com/finos/morphir.\n[65] Steven S. Muchnick. Advanced Compiler Design and Implementation .\nMorgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1997.\n[66] David R. Musser, Gilmer J. Derge, and Atul Saini. STL Tutorial and\nReference Guide, Second Edition: C++ Programming with the St andard\nTemplate Library . Addison-Wesley Longman Publishing Co., Inc.,\nBoston, MA, USA, 2001.\n[67] Node-api, 2023. h/t_tps://nodejs.org/api/n-api.html.\n[68] Flemming Nielson, Hanne R. Nielson, and Chris Hankin. Principles\nof Program Analysis . Springer-Verlag, Berlin, Heidelberg, 1999.\n[69] James Noble, Andrew P. Black, Kim B. Bruce, Michael Homer, a nd\nMark S. Miller. The left hand of equals. In Onward!, 2016.\n[70] npm.js, 2023. h/t_tps://www.npmjs.com/.\n[71] Peter W. O’Hearn. Incorrectness logic. In POPL, 2019.\n[72] OpenAI. GPT-4 technical report, 2023.\n[73] Openapi 3.0 pattern, 2023.\nh/t_tps://swagger.io/docs/specification/data-models/data-types/\n[74] Redhat: Optimized check cves, 2019.\nh/t_tps://www.redhat.com/en/blog/security-flaws-caused-compiler-optimizations .\n[75] Nils Klarlund Patrice Godefroid and Koushik Sen. DART: Directed\nautomated random testing. In PLDI, 2005.\n[76] Daniel Perelman, Sumit Gulwani, Dan Grossman, and Peter Provost .\nTest-driven synthesis. In PLDI, 2014.\n[77] Jonathan Protzenko, Jean-Karim Zinzindohoué, Aseem Rastogi,\nTahina Ramananandro, Peng Wang, Santiago Zanella-Béguelin, An-\ntoine Delignat-Lavaud, Cătălin Hriţcu, Karthikeyan Bhargavan, Cé-\ndric Fournet, and Nikhil Swamy. Veriﬁed low-level programming\nembedded in F*. In ICFP, 2017.\n[78] react, 2019.\nh/t_tps://reactjs.org/.\n[79] John C. Reynolds. Separation logic: A logic for shared mutab le data\nstructures. In LICS, 2002.\n[80] Rust, 2022. h/t_tps://www.rust-lang.org/.\n[81] Sriram Sankaranarayanan, Henny B. Sipma, and Zohar Manna. Non-\nlinear loop invariant generation using gröbner bases. In POPL, 2004.\n[82] Semantic versioning 2.0.0, 2018. h/t_tps://semver.org/.\n[83] Xujie Si, Hanjun Dai, Mukund Raghothaman, Mayur Naik, and\nLe Song. Learning loop invariants for program veriﬁcation. In Ad-\nvances in Neural Information Processing Systems 31 , pages 7751–7762.\n2018.\n[84] Bjarne Steensgaard. Points-to analysis in almost linear time. In POPL,\n1996.\n[85] Alexandru Sălcianu and Martin Rinard. Purity and side eﬀect analysis\nfor Java programs. In VMCAI, 2005.\n[86] Emina Torlak and Rastislav Bodik. Growing solver-aided language s\nwith Rosette. In Onward!, 2013.\n[87] Jesse A. Tov and Riccardo Pucella. Practical aﬃne types. In POPL,\n2011.\n[88] 3.3, 2019. h/t_tps://www.typescriptlang.org/.\n[89] Microsoft typespec, 2023. h/t_tps://microso/f_t.github.io/typespec/standard-library/built-in- \n[90] Peter Vanbroekhoven, Gerda Janssens, Maurice Bruynooghe, and\nFrancky Catthoor. Transformation to dynamic single assignment us-\ning a simple data ﬂow analysis. In APLAS, 2005.\n[91] Philip Wadler. Linear types can change the world! In Programming\nConcepts and Methods , 1990.\n17",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.728623628616333
    },
    {
      "name": "Programming language",
      "score": 0.6285912990570068
    },
    {
      "name": "Artificial intelligence",
      "score": 0.47906121611595154
    }
  ]
}