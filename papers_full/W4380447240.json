{
  "title": "Applications of ChatGPT and Large Language Models in Medicine and Health Care: Benefits and Pitfalls",
  "url": "https://openalex.org/W4380447240",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2791999835",
      "name": "Andrew A. Borkowski",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4214528748",
    "https://openalex.org/W4323835279",
    "https://openalex.org/W4324308091",
    "https://openalex.org/W4321436564",
    "https://openalex.org/W3153590458",
    "https://openalex.org/W4322757547",
    "https://openalex.org/W4323050332",
    "https://openalex.org/W4323314501",
    "https://openalex.org/W4319460874",
    "https://openalex.org/W4322761615",
    "https://openalex.org/W4321167341",
    "https://openalex.org/W4324020772",
    "https://openalex.org/W4317748910",
    "https://openalex.org/W4221149706",
    "https://openalex.org/W4313197536",
    "https://openalex.org/W4296382983",
    "https://openalex.org/W4323076364",
    "https://openalex.org/W3111618744",
    "https://openalex.org/W4360837628",
    "https://openalex.org/W4384071683"
  ],
  "abstract": "Careful consideration is needed to ensure the responsible and ethical use of large language models in medicine and health care. <i>The development of [artificial intelligence] is as fundamental as the creation of the microprocessor, the personal computer, the Internet, and the mobile phone. It will change the way people work, learn, travel, get health care, and communicate with each other.</i> Bill Gates1.",
  "full_text": "170 • FEDERAL PRACTITIONER  •  JUNE 2023 mdedge.com/fedprac\nBackground: The use of large language models like ChatGPT \nis becoming increasingly popular in health care settings. These \nartificial intelligence models are trained on vast amounts of \ndata and can be used for various tasks, such as language \ntranslation, summarization, and answering questions. \nObservations: Large language models have the potential to \nrevolutionize the industry by assisting medical professionals \nwith administrative tasks, improving diagnostic accuracy, and \nengaging patients. However, pitfalls exist, such as its inability \nto distinguish between real and fake information and the need \nto comply with privacy, security, and transparency principles. \nConclusions: Careful consideration is needed to ensure \nthe responsible and ethical use of large language models in \nmedicine and health care.\nCOMMENTARY\nApplications of ChatGPT and Large  \nLanguage Models in Medicine and Health \nCare: Benefits and Pitfalls\nAndrew A. Borkowski, MDa,b,c; Colleen E. Jakey, MD,a,b; Stephen M. Mastorides, MDa,b; Ana L. Kraus, MDa,b; Gitanjali Vidyarthi, \nMDa,b; Narayan Viswanadhan, MDa,b; Jose L. Lezama, MDa,b\nAuthor affiliations  \ncan be found at the  \nend of this article.\nCorrespondence:  \nAndrew Borkowski  \n(andrew.borkowski@va.gov)\nFed Pract. 2023;40(6).\nPublished online June 16.\ndoi:10.12788/fp.0386 A\ns the world emerges from the pan-\ndemic and the health care system \nfaces new challenges, technology has \nbecome an increasingly important tool for \nhealth care professionals (HCPs). One such \ntechnology is the large language model \n(LLM), which has the potential to revolu-\ntionize the health care industry . ChatGPT, \na popular LLM developed by OpenAI, has \ngained particular attention in the medical \ncommunity for its ability to pass the United \nStates Medical Licensing Exam.2 This article \nwill explore the benefits and potential pit-\nfalls of using LLMs like ChatGPT in medi -\ncine and health care. \nBENEFITS\nHCP burnout is a serious issue that can lead \nto lower productivity , increased medical er-\nrors, and decreased patient satisfaction. 3 \nLLMs can alleviate some administrative bur-\ndens on HCPs, allowing them to focus on \npatient care. By assisting with billing, cod-\ning, insurance claims, and organizing sched-\nules, LLMs like ChatGPT can free up time \nfor HCPs to focus on what they do best: pro-\nviding quality patient care. 4 ChatGPT also \ncan assist with diagnoses by providing accu-\nrate and reliable information based on a vast \namount of clinical data. By learning the re-\nlationships between different medical con-\nditions, symptoms, and treatment options, \nChatGPT can provide an appropriate differ-\nential diagnosis (Figure 1). It can also inter-\npret medical tests, such as imaging studies \nand laboratory results, improving the accu-\nracy of diagnoses. 5 LLMs can also identify \npotential clinical trial opportunities for pa-\ntients, leading to improved treatment op -\ntions and outcomes.6\nImaging medical specialists like radiolo-\ngists, pathologists, dermatologists, and oth-\ners can benefit from combining computer \nvision diagnostics with ChatGPT report cre-\nation abilities to streamline the diagnostic \nworkflow and improve diagnostic accuracy \n(Figure 2). By leveraging the power of LLMs, \nHCPs can provide faster and more accu-\nrate diagnoses, improving patient outcomes. \nChatGPT can also help triage patients with \nurgent issues in the emergency department, \nreducing the burden on personnel and allow-\ning patients to receive prompt care.7,8\nAlthough using ChatGPT and other LLMs \nin mental health care has potential benefits, it \nis essential to note that they are not a substi-\ntute for human interaction and personalized \ncare. While ChatGPT can remember infor -\nmation from previous conversations, it can-\nnot provide the same level of personalized, \nThe development of [artificial intelligence] is as fundamental as the creation of the micro-\nprocessor , the personal computer , the Internet, and the mobile phone. It will change the way \npeople work, learn, travel, get health care, and communicate with each other .\nBill Gates1\nJUNE 2023  • FEDERAL PRACTITIONER • 171mdedge.com/fedprac\nhigh-quality care that a professional thera-\npist or HCP can. However, by augmenting \nthe work of HCPs, ChatGPT and other LLMs \nhave the potential to make mental health care \nmore accessible and efficient. In addition to \nproviding effective screening in underserved \nareas, ChatGPT technology may improve the \ncompetence of physician assistants and nurse \npractitioners in delivering mental health \ncare. With the increased incidence of mental \nhealth problems in veterans, the pertinence \nof a ChatGPT-like feature will only increase \nwith time.9\nChatGPT can also be integrated into \nhealth care organizations’ websites and mo-\nbile apps, providing patients instant access to \nmedical information, self-care advice, symp-\ntom checkers, scheduling appointments, and \narranging transportation. These features can \nreduce the burden on health care staff and \nhelp patients stay informed and motivated \nto take an active role in their health. Addi-\ntionally , health care organizations can use \nChatGPT to engage patients by providing re-\nminders for medication renewals and assis-\ntance with self-care.4,6,10,11\nThe potential of artificial intelligence (AI) \nin the field of medical education and research \nis immense. According to a study by Gilson \nand colleagues, ChatGPT has shown prom-\nising results as a medical education tool. 12 \nChatGPT can simulate clinical scenarios, \nprovide real-time feedback, and improve di-\nagnostic skills. It also offers new interactive \nand personalized learning opportunities for \nmedical students and HCPs.13 ChatGPT can \nhelp researchers by streamlining the pro-\ncess of data analysis. It can also adminis-\nter surveys or questionnaires, facilitate data \ncollection on preferences and experiences, \nand help in writing scientific publications.14 \nNevertheless, to fully unlock the potential \nof these AI models, additional models that \nperform checks for factual accuracy , plagia-\nrism, and copyright infringement must be  \ndeveloped.15,16\nAI BILL OF RIGHTS\nIn order to protect the American public, the \nWhite House Office of Science and Tech-\nnology Policy (OSTP) has released a blue-\nprint for an AI Bill of Rights that emphasizes \n5 principles to protect the public from the \nharmful effects of AI models, including safe \nFIGURE 1 Medical Robot Image  \nCreated by Artificial Intelligence\nSource: www.beta.dreamstudio.ai\nGlossary of Terms\nArtificial intelligence (AI): The simulation of human intelligence in machines \nthat are programmed to mimic human cognitive abilities, such as reasoning, \nlearning, perception, and problem solving.\nMachine learning (ML): A subset of AI that involves using algorithms and  \nstatistical models to enable computers to improve their performance on a  \nspecific task without being explicitly programmed.\nDeep learning (DL): A subset of ML that uses artificial neural networks with \nmultiple layers to enable computers to learn from large amounts of data and \nmake predictions or decisions based on that data.\nLarge language models (LLM): A type of DL that uses vast amounts of text \ndata to learn the structure and patterns of human language; these models  \nhave revolutionized the field of natural language processing and have enabled \ncomputers to perform a wide range of language-related tasks.\nNatural language processing (NLP): A branch of AI that focuses on enabling \ncomputers to understand, interpret, and generate human language; it involves \nusing various techniques such as ML, DL, and linguistic analysis to process and \nanalyze natural language data.\nFIGURE 2 Pathology Colon Biopsy  \nReport Created by ChatGPT  \n(www.chat.openai.com)\nArtificial Intelligence\n172 • FEDERAL PRACTITIONER  •   JUNE 2023\nmdedge.com/fedprac\nand effective systems; algorithmic discrimi-\nnation protection; data privacy; notice and \nexplanation; and human alternatives, con-\nsiderations, and fallback (Figure 3).17 Other \ntrustworthy AI frameworks, such as the \nWhite House Executive Order 13960 and \nthe National Institute of Standards and Tech-\nnology AI Risk Management Framework, \nare essential to building trust for AI services \namong HCPs and veteran patients. 18,19 To \nensure that ChatGPT complies with these \nprinciples, especially those related to privacy , \nsecurity , transparency , and explainability , it \nis essential to develop trustworthy AI health \ncare products. Methods like calibration and \nfine-tuning with specialized data sets from \nthe target population and guiding the mod-\nel’s behavior with reinforcement learning \nwith human feedback (RLHF) may be ben-\neficial. Preserving the patient’s confidenti-\nality is of utmost importance. For example, \nMicrosoft Azure Machine Learning Services, \nincluding ChatGPT GPT-4, are Health In-\nsurance Portability and Accountability Act– \ncertified and could enable the creation of \nsuch products.20\nOne of the biggest challenges with LLMs \nlike ChatGPT is the prevalence of inaccu-\nrate information or so-called hallucinations.16 \nThese inaccuracies stem from the inability of \nLLMs to distinguish between real and fake \ninformation. To prevent hallucinations, re-\nsearchers have proposed several methods, \nincluding training models on more diverse \ndata, using adversarial training methods, and \nhuman-in-the-loop approaches.21 In addition, \nmedicine-specific models like GatorTron, \nmedPaLM, and Almanac were developed, in-\ncreasing the accuracy of factual results. 22-24 \nUnfortunately , only the GatorTron model is \navailable to the public through the NVIDIA \ndevelopers’ program.25\nDespite these shortcomings, the future of \nLLMs in health care is promising. Although \nthese models will not replace HCPs, they \ncan help reduce the unnecessary burden on \nthem, prevent burnout, and enable HCPs and \npatients spend more time together. Establish-\ning an official hospital AI oversight govern-\ning body that would promote best practices \ncould ensure the trustworthy implementation \nof these new technologies.26\nCONCLUSIONS\nThe use of ChatGPT and other LLMs in \nhealth care has the potential to revolution-\nize the industry . By assisting HCPs with \nadministrative tasks, improving the accu-\nracy and reliability of diagnoses, and en -\ngaging patients, ChatGPT can help health \ncare organizations provide better care to \ntheir patients. While LLMs are not a sub-\nstitute for human interaction and person-\nalized care, they can augment the work of \nHCPs, making health care more accessi-\nble and efficient. As the health care indus-\ntry continues to evolve, it will be exciting to \nsee how ChatGPT and other LLMs are used \nto improve patient outcomes and quality \nof care. In addition, AI technologies like \nChatGPT offer enormous potential in med-\nical education and research. To ensure that \nthe benefits outweigh the risks, developing \ntrustworthy AI health care products and es-\ntablishing oversight governing bodies to en-\nsure their implementation is essential. By \ndoing so, we can help HCPs focus on what \nmatters most, providing high-quality care to \npatients.\nAcknowledgments\nThis material is the result of work supported by resources and \nthe use of facilities at the James A. Haley Veterans’ Hospital.\nAuthor affiliations\naJames A. Haley Veterans’ Hospital, Tampa, Florida\nbUniversity of South Florida Morsani College of Medicine, \nTampa\ncNational Artificial Intelligence Institute, Washington, DC\nAuthor disclosures \nThe authors report no actual or potential conflicts of interest or \noutside sources of funding with regard to this article.\nFIGURE 3 AI Bill of Rights17\nSource: Executive Office of the President, Office of Science and Technology Policy\nArtificial Intelligence\nJUNE 2023  • FEDERAL PRACTITIONER • 173\nmdedge.com/fedprac\nDisclaimer\nThe opinions expressed herein are those of the authors and do \nnot necessarily reflect those of Federal Practitioner, Frontline \nMedical Communications Inc., the U.S. Government, or any \nof its agencies.\nReferences\n  1.   Bill Gates. The age of AI has begun. March 21, 2023. \nAccessed May 10, 2023. https://www.gatesnotes.com  \n/the-age-of-ai-has-begun \n  2.   Kung TH, Cheatham M, Medenilla A, et al. Performance \nof ChatGPT on USMLE: Potential for AI-assisted medi-\ncal education using large language models.  PLOS Digit \nHealth. 2023;2(2):e0000198. Published 2023 Feb 9. \ndoi:10.1371/journal.pdig.0000198\n  3.   Shanafelt TD, West CP , Sinsky C, et al. Changes in \nburnout and satisfaction with work-life integration in \nphysicians and the general US working population be-\ntween 2011 and 2020. Mayo Clin Proc. 2022;97(3):491-\n506. doi:10.1016/j.mayocp.2021.11.021\n  4.   Goodman RS, Patrinely JR Jr, Osterman T, Wheless L, \nJohnson DB. On the cusp: considering the impact of ar-\ntificial intelligence language models in healthcare.  Med. \n2023;4(3):139-140. doi:10.1016/j.medj.2023.02.008\n  5.   Will ChatGPT transform healthcare?  Nat Med. \n2023;29(3):505-506. doi:10.1038/s41591-023-02289-5\n  6.   Hopkins AM, Logan JM, Kichenadasse G, Sorich MJ. \nArtificial intelligence chatbots will revolutionize how can-\ncer patients access information: ChatGPT represents a \nparadigm-shift. JNCI Cancer Spectr. 2023;7(2):pkad010. \ndoi:10.1093/jncics/pkad010\n  7.   Babar Z, van Laarhoven T, Zanzotto FM, Marchiori E. \nEvaluating diagnostic content of AI-generated radiology \nreports of chest X-rays. Artif Intell Med. 2021;116:102075. \ndoi:10.1016/j.artmed.2021.102075\n  8.   Lecler A, Duron L, Soyer P . Revolutionizing radiol-\nogy with GPT-based models: current applications, fu-\nture possibilities and limitations of ChatGPT. Diagn \nInterv Imaging. 2023;S2211-5684(23)00027-X.  \ndoi:10.1016/j.diii.2023.02.003\n  9.   Germain JM. Is ChatGPT smart enough to practice mental \nhealth therapy? March 23, 2023. Accessed May 11, 2023. \nhttps://www.technewsworld.com/story/is-chatgpt-smart \n-enough-to-practice-mental-health-therapy-178064.html\n10. Cascella M, Montomoli J, Bellini V, Bignami E. Eval -\nuating the feasibility of ChatGPT in healthcare: an \nanalysis of multiple clinical and research scenarios.  J \nMed Syst. 2023;47(1):33. Published 2023 Mar 4.  \ndoi:10.1007/s10916-023-01925-4\n11.   Jungwirth D, Haluza D. Artificial intelligence and pub-\nlic health: an exploratory study.  Int J Environ Res Pub-\nlic Health. 2023;20(5):4541. Published 2023 Mar 3. \ndoi:10.3390/ijerph20054541\n12.   Gilson A, Safranek CW, Huang T, et al. How does Chat-\nGPT perform on the United States Medical Licensing Ex-\namination? The implications of large language models \nfor medical education and knowledge assessment. JMIR \nMed Educ. 2023;9:e45312. Published 2023 Feb 8. \ndoi:10.2196/45312\n13.   Eysenbach G. The role of ChatGPT, generative language \nmodels, and artificial intelligence in medical education: a \nconversation with ChatGPT and a call for papers.  JMIR \nMed Educ. 2023;9:e46885. Published 2023 Mar 6. \ndoi:10.2196/46885\n14.   Macdonald C, Adeloye D, Sheikh A, Rudan I. Can \nChatGPT draft a research article? An example of \npopulation-level vaccine effectiveness analysis.  J \nGlob Health. 2023;13:01003. Published 2023 Feb 17. \ndoi:10.7189/jogh.13.01003\n15.   Masters K. Ethical use of artificial intelligence in health \nprofessions education: AMEE Guide No.158. Med Teach. \n2023;1-11. doi:10.1080/0142159X.2023.2186203\n16.   Smith CS. Hallucinations could blunt ChatGPT’s success. \nIEEE Spectrum. March 13, 2023. Accessed May 11, 2023. \nhttps://spectrum.ieee.org/ai-hallucination\n17.   Executive Office of the President, Office of Science and \nTechnology Policy. Blueprint for an AI Bill of Rights. \nAccessed May 11, 2023. https://www.whitehouse.gov  \n/ostp/ai-bill-of-rights\n18.   Executive office of the President. Executive Order 13960: \npromoting the use of trustworthy artificial intelligence in \nthe federal government. Fed Regist. 2020;89(236):78939-\n78943.\n19.   US Department of Commerce, National institute of Stan-\ndards and Technology. Artificial Intelligence Risk Manage-\nment Framework (AI RMF 1.0). Published January 2023. \ndoi:10.6028/NIST.AI.100-1\n20.   Microsoft. Azure Cognitive Search—Cloud Search Ser -\nvice. Accessed May 11, 2023. https://azure.microsoft.com \n/en-us/products/search\n21.   Aiyappa R, An J, Kwak H, Ahn YY . Can we trust the evalu-\nation on ChatGPT? March 22, 2023. Accessed May 11, \n2023. https://arxiv.org/abs/2303.12767v1\n22.   Yang X, Chen A, Pournejatian N, et al. GatorTron: a large \nclinical language model to unlock patient information from \nunstructured electronic health records. Updated Decem-\nber 16, 2022. Accessed May 11, 2023. https://arxiv.org  \n/abs/2203.03540v3\n23.   Singhal K, Azizi S, Tu T, et al. Large language models en-\ncode clinical knowledge. December 26, 2022. Accessed \nMay 11, 2023. https://arxiv.org/abs/2212.13138v1\n24.   Zakka C, Chaurasia A, Shad R, Hiesinger W. Alma-\nnac: knowledge-grounded language models for clinical \nmedicine. March 1, 2023. Accessed May 11, 2023. \nhttps://arxiv.org/abs/2303.01229v1\n25.   NVIDIA. GatorTron-OG. Accessed May 11, 2023. https://\ncatalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models \n/gatortron_og\n26.   Borkowski AA, Jakey CE, Thomas LB, Viswanadhan N, \nMastorides SM. Establishing a hospital artificial intel-\nligence committee to improve patient care.  Fed Pract. \n2022;39(8):334-336. doi:10.12788/fp.0299",
  "topic": "Automatic summarization",
  "concepts": [
    {
      "name": "Automatic summarization",
      "score": 0.6304707527160645
    },
    {
      "name": "Health care",
      "score": 0.5978429317474365
    },
    {
      "name": "Computer science",
      "score": 0.5782623291015625
    },
    {
      "name": "Transparency (behavior)",
      "score": 0.5436387062072754
    },
    {
      "name": "Internet privacy",
      "score": 0.4564010202884674
    },
    {
      "name": "The Internet",
      "score": 0.44868457317352295
    },
    {
      "name": "Mobile phone",
      "score": 0.42097195982933044
    },
    {
      "name": "Knowledge management",
      "score": 0.3531981110572815
    },
    {
      "name": "Artificial intelligence",
      "score": 0.29931357502937317
    },
    {
      "name": "Computer security",
      "score": 0.23937225341796875
    },
    {
      "name": "World Wide Web",
      "score": 0.1975841224193573
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Economic growth",
      "score": 0.0
    },
    {
      "name": "Telecommunications",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210156221",
      "name": "Allen Institute for Artificial Intelligence",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210088910",
      "name": "James A. Haley Veterans' Hospital",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I2613432",
      "name": "University of South Florida",
      "country": "US"
    }
  ],
  "cited_by": 22
}