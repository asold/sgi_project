{
    "title": "An Open-source Fine-tuned Large Language Model for Radiological Impression Generation: A Multi-reader Performance Study",
    "url": "https://openalex.org/W4401217287",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A4321188182",
            "name": "Adrian Serapio",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A2770880433",
            "name": "Gunvant Chaudhari",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A2990465406",
            "name": "Cody Savage",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A2190349507",
            "name": "Yoo Jin Lee",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A2212491338",
            "name": "Maya Vella",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A5106114378",
            "name": "Shravan Srid",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A2949458704",
            "name": "Jamie Schroeder",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A2098251169",
            "name": "Jonathan Liu",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A2512552713",
            "name": "Adam Yala",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A2146337925",
            "name": "Jae Ho Sohn",
            "affiliations": [
                "University of California, San Francisco"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3089474066",
        "https://openalex.org/W1913339316",
        "https://openalex.org/W4233624763",
        "https://openalex.org/W2559874490",
        "https://openalex.org/W4362522726",
        "https://openalex.org/W4376640725",
        "https://openalex.org/W4380423243",
        "https://openalex.org/W4382182493",
        "https://openalex.org/W4387472906",
        "https://openalex.org/W4307079201",
        "https://openalex.org/W2981852735",
        "https://openalex.org/W4295312788",
        "https://openalex.org/W2980282514",
        "https://openalex.org/W2908510526",
        "https://openalex.org/W1972978214",
        "https://openalex.org/W2136148671",
        "https://openalex.org/W3003257820",
        "https://openalex.org/W2901906577",
        "https://openalex.org/W3035965352",
        "https://openalex.org/W4366330426",
        "https://openalex.org/W2129514346",
        "https://openalex.org/W4385381606",
        "https://openalex.org/W4367186868",
        "https://openalex.org/W4318069287",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W3099878876"
    ],
    "abstract": "<title>Abstract</title> Background The impression section integrates key findings of a radiology report but can be subjective and variable. A fine-tuned open-source Large Language Model (LLM) was evaluated in its ability to generate radiological report impressions across different imaging modalities and hospitals. We sought to clinically validate an open-source fine-tuned LLM that automatically generates impressions to summarize radiology reports. Methods In this institutional review board-approved retrospective study, we fine-tuned an open-source LLM to generate the impression from the remainder of the radiology report. CT, US, and MRI radiology reports from Hospital 1 (n = 372716) and Hospital 2 (n = 60049), both under a single institution, were included in this study. The ROUGE score was used for automatic natural language evaluation and a reader study with five thoracic radiologists was performed for a clinical evaluation of CT chest impressions with a subspecialist baseline. We also stratified the results of the reader performance study based on the diagnosis category and the original impression length to gauge case complexity. Results The large language model achieved ROUGE-L scores of 46.51, 44.2, and 50.96 on the Hospital 1 dataset across the CT, US, and MRI modalities respectively. Upon external validation on the Hospital 2 independent test dataset, the model achieved ROUGE-L scores of 40.74, 37.89, and 24.61 for the same set of modalities. For the reader performance study, the model achieved overall mean scores of 3.56/4, 3.92/4, and 3.37/4, 18.29 seconds, and 12.32 words for clinical accuracy, grammatical accuracy, stylistic quality, edit time, and edit distance respectively. The LLM achieved the highest clinical accuracy ratings for acute/emergent findings. In terms of impression length, the LLM performed the best in clinical accuracy on shorter impressions. Conclusions We demonstrated that an open-source fine-tuned LLM can generate high-quality radiological impressions of clinical accuracy, grammatical accuracy, and stylistic quality across multiple imaging modalities and hospitals.",
    "full_text": null
}