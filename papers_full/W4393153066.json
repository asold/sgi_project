{
    "title": "Language-Guided Transformer for Federated Multi-Label Classification",
    "url": "https://openalex.org/W4393153066",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5111224541",
            "name": "I-Jieh Liu",
            "affiliations": [
                "National Taiwan University"
            ]
        },
        {
            "id": "https://openalex.org/A5012894733",
            "name": "Ci-Siang Lin",
            "affiliations": [
                "National Taiwan University"
            ]
        },
        {
            "id": "https://openalex.org/A5032964198",
            "name": "Fu-En Yang",
            "affiliations": [
                "National Taiwan University"
            ]
        },
        {
            "id": "https://openalex.org/A5090045508",
            "name": "Yu-Chiang Frank Wang",
            "affiliations": [
                "National Taiwan University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3089555680",
        "https://openalex.org/W2969224942",
        "https://openalex.org/W2932399282",
        "https://openalex.org/W6741263554",
        "https://openalex.org/W2037227137",
        "https://openalex.org/W4221148875",
        "https://openalex.org/W4293141861",
        "https://openalex.org/W6687483927",
        "https://openalex.org/W4312699393",
        "https://openalex.org/W1836465849",
        "https://openalex.org/W3006555759",
        "https://openalex.org/W3107026593",
        "https://openalex.org/W6793191782",
        "https://openalex.org/W6759238902",
        "https://openalex.org/W6765541894",
        "https://openalex.org/W3124293845",
        "https://openalex.org/W6639102338",
        "https://openalex.org/W3167841610",
        "https://openalex.org/W2541884796",
        "https://openalex.org/W3211770985",
        "https://openalex.org/W6808848689",
        "https://openalex.org/W4286231692",
        "https://openalex.org/W3043723611",
        "https://openalex.org/W3193756050",
        "https://openalex.org/W4309208182",
        "https://openalex.org/W1522301498",
        "https://openalex.org/W4302307546",
        "https://openalex.org/W3038022836",
        "https://openalex.org/W3167456680",
        "https://openalex.org/W2734358244",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W4287647398",
        "https://openalex.org/W4287663929",
        "https://openalex.org/W4312950667",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2982112268",
        "https://openalex.org/W3158969156",
        "https://openalex.org/W4214673031",
        "https://openalex.org/W3213291156",
        "https://openalex.org/W1861492603",
        "https://openalex.org/W2955213239",
        "https://openalex.org/W4318619660",
        "https://openalex.org/W3118608800",
        "https://openalex.org/W2194775991",
        "https://openalex.org/W3129603732",
        "https://openalex.org/W3184087575",
        "https://openalex.org/W3182158470",
        "https://openalex.org/W4309202064",
        "https://openalex.org/W4312869277",
        "https://openalex.org/W3166396011"
    ],
    "abstract": "Federated Learning (FL) is an emerging paradigm that enables multiple users to collaboratively train a robust model in a privacy-preserving manner without sharing their private data. Most existing approaches of FL only consider traditional single-label image classification, ignoring the impact when transferring the task to multi-label image classification. Nevertheless, it is still challenging for FL to deal with user heterogeneity in their local data distribution in the real-world FL scenario, and this issue becomes even more severe in multi-label image classification. Inspired by the recent success of Transformers in centralized settings, we propose a novel FL framework for multi-label classification. Since partial label correlation may be observed by local clients during training, direct aggregation of locally updated models would not produce satisfactory performances. Thus, we propose a novel FL framework of Language-Guided Transformer (FedLGT) to tackle this challenging task, which aims to exploit and transfer knowledge across different clients for learning a robust global model. Through extensive experiments on various multi-label datasets (e.g., FLAIR, MS-COCO, etc.), we show that our FedLGT is able to achieve satisfactory performance and outperforms standard FL techniques under multi-label FL scenarios. Code is available at https://github.com/Jack24658735/FedLGT.",
    "full_text": "Language-Guided Transformer for Federated Multi-Label Classification\nI-Jieh Liu1, Ci-Siang Lin1,2, Fu-En Yang1,2, Yu-Chiang Frank Wang1,2\n1Graduate Institute of Communication Engineering, National Taiwan University\n2NVIDIA\n{r11942087, d08942011, f07942077}@ntu.edu.tw frankwang@nvidia.com\nAbstract\nFederated Learning (FL) is an emerging paradigm that en-\nables multiple users to collaboratively train a robust model\nin a privacy-preserving manner without sharing their private\ndata. Most existing approaches of FL only consider tradi-\ntional single-label image classification, ignoring the impact\nwhen transferring the task to multi-label image classification.\nNevertheless, it is still challenging for FL to deal with user\nheterogeneity in their local data distribution in the real-world\nFL scenario, and this issue becomes even more severe in\nmulti-label image classification. Inspired by the recent suc-\ncess of Transformers in centralized settings, we propose a\nnovel FL framework for multi-label classification. Since par-\ntial label correlation may be observed by local clients during\ntraining, direct aggregation of locally updated models would\nnot produce satisfactory performances. Thus, we propose\na novel FL framework of Language-Guided Transformer\n(FedLGT) to tackle this challenging task, which aims to\nexploit and transfer knowledge across different clients for\nlearning a robust global model. Through extensive exper-\niments on various multi-label datasets (e.g., FLAIR, MS-\nCOCO, etc.), we show that our FedLGT is able to achieve\nsatisfactory performance and outperforms standard FL tech-\nniques under multi-label FL scenarios. Code is available at\nhttps://github.com/Jack24658735/FedLGT.\n1 Introduction\nFederated Learning (FL) is a machine learning paradigm\nthat enables multiple clients to collaboratively perform\nmodel training by leveraging their decentralized data. This\napproach offers significant advantages over traditional cen-\ntralized approaches, as it mitigates the risks of privacy dis-\nclosure and is efficient for large-scale machine learning tasks\nwithout collecting large amounts of data on the server. FL\nhas been successfully applied in real-world studies including\nhealth care, finance, and recommendation systems. As a pi-\noneering work, the vanilla FL algorithm FedAvg (McMahan\net al. 2017) learns from multiple local clients in a privacy-\npreserving manner, and the trained models or gradients are\nsent to the central server. Then, the server performed an ag-\ngregation step to obtain a global model. However, user data\ndistribution often has non-IID (non-independent and iden-\ntical distribution) characteristics in the real world, which is\nCopyright ¬© 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nCentral ServerLocal model uploadGlobal model broadcast\nClient 1Client K\nLiquidGlassPlant\nLabel: [Liquid, Glass]Label: [Liquid, Plant]\n: Highlabel correlation: Lowlabel correlation\nLiquidGlassPlant? ?FedAvg\n/\n LiquidGlassPlant\nLocal model upload \nFigure 1: Challenges in multi-label federated learning. Since\ndiverse label correlations are observed across clients, aggre-\ngating local models might not be sufficiently generalizable.\nreferred to as data heterogeneity. Data heterogeneity across\ndifferent clients can be caused by various factors, such as\ndemographic diversity, data collection methods, and sensor\ndifferences. In the presence of data heterogeneity, FedAvg\nmay struggle to effectively leverage the data diversity across\nclients, resulting in degraded performance of the aggregated\nglobal model.\nTypically, data heterogeneity contains the aspects such as\nlabel distribution skew or domain shift, presenting substan-\ntial obstacles in the progress of FL development. For in-\nstance, consider a scene understanding task in FL. In this\nscenario, certain clients possess a larger volume of indoor\nscene data, while others may have more outdoor scene data.\nAs a result, their local models tend to be biased towards their\nrespective scenes due to environmental variations in light-\ning, texture, etc., posing challenges in achieving a consen-\nsus during the model aggregation process (i.e., hard to ob-\ntain a robust global model). In addition, some clients may\nhave more data for specific classes, resulting in a class im-\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n13882\nbalanced issue that can also cause the performance degrada-\ntion of the aggregated global model. Prior works (Li et al.\n2020; Karimireddy et al. 2020; Gao et al. 2022; Li, He, and\nSong 2021; Li et al. 2021) tackle data heterogeneity mainly\non standard single-label image classification benchmark-\ning datasets, e.g., EMNIST (Cohen et al. 2017), CIFAR-\n10 (Krizhevsky, Hinton et al. 2009), etc. However, multi-\nlabel image classification is a more practical and challenging\nsetting. For example, single-label image classification usu-\nally needs the model to recognize only one object or one\nmain concept in an input image, whereas multi-label image\nclassification aims to recognize all the object categories or\nconcepts, which is more challenging due to the understand-\ning of the inter-class relationships.\nTo mitigate performance degradation induced by data het-\nerogeneity (e.g., label distribution skew) on FL, various\nworks (Li et al. 2020; Karimireddy et al. 2020; Gao et al.\n2022; Li, He, and Song 2021; Li et al. 2021; Huang, Ye,\nand Du 2022; Su et al. 2022; Mendieta et al. 2022; Wang\net al. 2020; Tan et al. 2021; Zhuang et al. 2021; Luo et al.\n2021) have been proposed to address this impact. For ex-\nample, FedProx (Li et al. 2020) introduces a regularization\nterm to mitigate the label distribution skew issues from the\nlocal learning step of FL. On the other hand, a previous FL\nmethod for addressing domain shift called FedBN (Li et al.\n2021) proposes utilizing the batch normalization layer (Ioffe\nand Szegedy 2015) in local clients to capture the domain-\nspecific information. However, these FL previous works ne-\nglect the emerging form of data heterogeneity such as multi-\nlabel issues but only focus on traditional single-label non-\nIID issues, leaving the ‚Äúmulti-label FL‚Äù task to remain un-\nresolved and challenging.\nIntuitively, it is achievable to directly apply the cur-\nrent multi-label classification frameworks from centralized\nlearning (Chen et al. 2019b,a, 2020; Lanchantin et al. 2021)\nto FL. However, when performing multi-label classification\nunder FL, the objects or concepts present in an image may\nexhibit significant variations across clients, potentially caus-\ning performance deterioration. For example, as Figure 1 de-\npicted, the positive label set of each client is inconsistent\nor even disjoint, learning of the label correlation may have\nunfavorable impacts and degrade the global model perfor-\nmance after the aggregation step. Thus, one of the main chal-\nlenges for multi-label image classification in FL is how to ef-\nfectively learn label relationships, as well as precisely cap-\nture the complex connections between visual features and\nassociated labels in a privacy-preserving manner.\nIn this paper, we propose a framework called FedLGT\nthat aims to tackle the multi-label FL issues and ver-\nify our effectiveness on a challenging multi-label FL\ndataset (Song, Granqvist, and Talwar 2022) called FLAIR.\nOur FedLGT utilizes a pre-trained off-the-shelf text encoder\nby CLIP (Radford et al. 2021) to construct universal label\nembedding. The label embedding contains rich and distinct\nrelationships among the labels. Utilizing this technique en-\nables the clients to perform local learning with more dis-\ncriminative label relationships. Besides, with the goal of\ntraining a robust global model from decentralized data, we\nalso design a knowledge-transfer approach called Client-\nAware Masked Label Embedding inspired by (Lanchantin\net al. 2021) to assist local learning via knowledge from the\nglobal model. Specifically, the approach aims to transfer and\ndistill the knowledge from the global model by encouraging\nthe local models to learn more for the classes that the global\nmodel still predicts with relatively low confidence. Through\nconducting extensive experiments on FLAIR, our proposed\nframework is able to derive a global model with better gen-\neralization performance without any communication over-\nheads.\nOur contributions to this work are highlighted as follows:\n‚Ä¢ To the best of our knowledge, we are the first to tackle\nthe problem of label discrepancy across different clients\nfor multi-label FL.\n‚Ä¢ We propose Client-Aware Masked Label Embedding\nwhen training FedLGT. It is served as a customized\nmodel update technique while exploiting the label cor-\nrelation at each client.\n‚Ä¢ We utilize Universal Label Embedding in FedLGT,\nwhich advances pre-trained label embedding derived\nfrom large-scale vision and language models (e.g., CLIP)\nfor aligning local models for multi-label FL.\n2 Related Works\n2.1 Federated Learning\nIn general, the common vanilla FL algorithm (i.e., Fe-\ndAvg (McMahan et al. 2017)) consists of several steps in-\ncluding local training, uploading client models, performing\nmodel aggregation, and broadcasting back to the clients on\nthe server side. Under such FedAvg training procedures,\nthe inconsistency between local objectives and the global\nobjective would be more serious under data heterogeneity\n(e.g., domain shift). The main direction of existing previ-\nous methods could be broadly divided intolabel distribution\nskew or domain shift. Label distribution skew can arise due\nto disparate local data in different clients, leading to bias\nlocal models towards majority classes. On the other hand,\ndomain shift does not specifically highlight the differences\nin label distributions across clients. Instead, the image fea-\ntures may exhibit significant variations, such as cartoons,\nsketches, etc., even under the same label annotation. In the\nsubsequent sections, we mainly introduce the works that are\npopular or more relevant to our paper.\nLabel Distribution Skew Label distribution skew is a\nkind of common challenge in FL. For example, assume that\nsome hospitals want to train a model to classify medical\nimages. However, one client may have some rare diseases,\nwhile other clients have other common diseases. Thus, the\nlabel distribution will differ significantly or even disjoint\n(i.e., label spaces are not overlapped), leading to degradation\nof model performance. In terms of label distribution skew,\nexisting FL methods focus on handling client local bias\ncompared to the global model. For instance, FedProx (Li\net al. 2020) restricts the gradient updates by introducing a\nproximal term to improve the convergence speed. SCAF-\nFOLD (Karimireddy et al. 2020) designs a new control vari-\nate for each client by measuring the gradient dissimilarity\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n13883\nbetween local clients and the global model, utilizing this\nmechanism to refine the local clients‚Äô drift. More recently,\nFedDC (Gao et al. 2022) learns an auxiliary local drift vari-\nable by Expectation-Maximum (EM) algorithm to track the\ninconsistency of local-global models.\nDomain Shift Domain shift (i.e., distribution shift) is an-\nother challenge among many real-world FL applications. For\ninstance, a healthcare organization wants to perform train-\ning on patient data of certain diseases (i.e., the label dis-\ntributions are the same) from different hospitals. Each of\nthem maintains its own private dataset of medical images\nwhich may have different characteristics due to variations in\nthe data acquisition process, patient populations, etc., result-\ning in potential domain shifts. Several previous works have\nbeen proposed to mitigate the domain shift of FL (Li et al.\n2021; Huang, Ye, and Du 2022; Su et al. 2022). FedBN (Li\net al. 2021) does not aggregate the parameters of batch nor-\nmalization (BN) layers, so the domain-specific information\ncan be preserved in local clients. FCCL (Huang, Ye, and Du\n2022) builds a cross-correlation matrix on the server with the\nhelp of unlabeled public data. Besides, it balances the inter-\ndomain and intra-domain information in the local training\nstage to tackle the domain shift. Recent FL works (Su et al.\n2022; Guo et al. 2023; Chen et al. 2022; Sun et al. 2022)\nutilize vision-language pre-trained models, which perform\nprompt tuning during training rounds and thus reduce the\nnumber of learnable parameters. FedAPT (Su et al. 2022)\nlearns a global adaptive network with the global prompt un-\nder the FL setting, then the framework generates domain-\nspecific prompts for CLIP to handle the domain shift is-\nsue under FL. Inspired by this trend, our approach leverages\nvision-language pre-trained models (e.g., CLIP) to circum-\nvent the challenges of training components that could dete-\nriorate the model performance under the constraints of FL.\n2.2 Multi-Label Image Classification\nCentralized Learning Multi-label image classification\nhas become an emerging research field since several real-\nistic applications may view this task as a foundation, such\nas weakly supervised segmentation, scene understanding,\netc. Since multi-label image classification requires recog-\nnition of all objects or concepts present in an image, it\nis critical yet challenging to understand the inherent rela-\ntionships between different classes. There are many direc-\ntions for multi-label image classification, such as improving\nloss functions (Ridnik et al. 2021), modeling label relation-\nships (Chen et al. 2019b; Lanchantin et al. 2021), etc. The\nmost related to our work is how to model the label relation-\nships so that co-occurrence dependencies between different\nclasses would be considered appropriately. Specifically, re-\ncent methods (Chen et al. 2019b,a, 2020) utilize graph for-\nmulation to represent label relationships. For example, ML-\nGCN (Chen et al. 2019b) build Graph Convolutional Net-\nwork (GCN) to represent the correlation between objects or\nconcepts, and such a method usually builds label correlation\ngraphs based on extra knowledge from label co-occurrence\nstatistics.\nBased on Transformer, C-Tran (Lanchantin et al. 2021)\nfuses image features and the associated labels by label mask\ntraining. Similar to BERT (Devlin et al. 2018), C-Tran aims\nto capture semantic information by predicting the unknown\nlabels on the images with the help of known labels. However,\nin FL settings, label co-occurrence information might dif-\nfer across distinct clients. As confirmed later by our experi-\nments, applying standard FL techniques with C-Tran might\nnot be preferable.\nFederated Learning Intuitively, one can utilize central-\nized multi-label learning models in FL schemes. That is, one\ncan view each local client as a multi-label classification task\nand perform aggregation on the server side. However, ex-\nisting centralized approaches require interaction with train-\ning data to capture a global view of the label relationships,\nwhich is infeasible under FL scenarios. For example in\nFig.1, one client primarily captures images of drinks and\nglass, while the other client mainly takes pictures of land-\nscapes and plants. Thus, the former client‚Äôs model learns a\nhigh correlation between ‚Äúliquid‚Äù and ‚Äúglass‚Äù, whereas the\nlatter client‚Äôs model learns a high correlation between ‚Äúliq-\nuid‚Äù and ‚Äúplant‚Äù. However, aggregating these models on the\nserver side could lead to confusion between these categories\n(i.e., ‚Äúliquid‚Äù, ‚Äúglass‚Äù, and ‚Äúplant‚Äù) for the global model, re-\nsulting in a degradation of performance.\nTo the best of our knowledge, recent FL works did not\naddress multi-label learning tasks, and thus the above is-\nsue would limit the model performances. As discussed\nin the following section, we propose a Transformer-based\nmodel while tackling the inherent label distribution differ-\nences between clients. Compared to popular FL techniques\nlike FedAvg, our method achieves impressive results on a\nlarge-scale dataset for multi-label FL (i.e., FLAIR (Song,\nGranqvist, and Talwar 2022)).\n3 Proposed Method\n3.1 Problem Formulation and Setup\nIn this work, we assume that K clients would be involved\nin the federated learning process in each communication\nround, and local private datasets are available for clients\nD = {D1, D2, ..., DK} during training. For each client, it\ncan be viewed as solving a standard multi-label image classi-\nfication task. To be more specific, given an imagex with the\ncorresponding label y = [y1, ..., yC], where C is the number\nof classes, yi = 1 indicates i-th class is present in the image,\nand yi = 0 is not present, then the local clients attempt to\npredict the existence of each category of the image. The goal\nis to obtain a global aggregated model handling multi-label\nclassification on FL that solves the objective\nw‚àó = arg min\nw\nŒ£K\nk=1\n|Dk|\n|D| Lk(w), (1)\nIn multi-label FL, each client and server share the same\nlabel space with a total of C categories. However, label dis-\ntributions might differ across different clients. Thus, based\non a recent SOTA centralized multi-label learning model of\nC-Tran (Lanchantin et al. 2021), our goal is to tackle the\nmulti-label FL task.\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n13884\nCA-MLE\nULE .\nx Backbone\nTransformer BlockLocal model ùíòùíåùíï\n‚Ñí!\"#Plate0.50.10.20.80.40.6\n\"ùëåPlantLandLiquidSkyGlass\nMLP head\nùëô!ùëô\"ùëô#\nùëß!ùëß\"ùëß$\nùë†!%ùë†\"%ùë†#%\ny\n ÔºöVisual embedding\nÔºöGradient update path\nÔºöState embeddingÔºöLabel embedding\n$ùëô!$ùëô\"$ùëô#\nÔºöMasked label embedding\nÔºöElement-wise sum\nFigure 2: Overview of FedLGT. Given an image with multi-labels to predict, the global model from each communication round\nupdates the local model with Client-Aware Masked Label Embedding (CA-MLE), which exploits partial label correlation\nobserved at each client. In order to properly align local models for multi-label FL, universal label embeddings (ULE) are\nutilized in FedLGT. (Best viewed in color.)\n3.2 A Brief Review for C-tran\nC-Tran (Lanchantin et al. 2021) is a centralized\nTransformer-based (Vaswani et al. 2017) multi-label\nimage classification framework, which is designed to ob-\nserve image features and label correlations simultaneously.\nIn C-Tran, the image features are extracted by ResNet (He\net al. 2016), while the labels are described by both label L\nand state S embeddings. The label embeddings are defined\nas L = {l1, l2, ..., lC}, where each lc ‚àà Rd represents c-th\nclass labels ( d denotes the embedding dimension). On the\nother hand, a set of state embeddings S = {s1, s2, ..., sC}\n(with each sc ‚àà Rd) are viewed as tokens, indicating\nthe presence of the corresponding labels of unknown,\npositive, and negative. Note the encoded token value for the\nassociated state embeddings is ‚àí1, 1, and 0, respectively.\nAlso, only the unknown state would contribute the loss to\nthe model during training. With label and state embeddings,\nC-Tran proposes a training pipeline of Label Mask Training\n(LMT) that randomly masks partial amounts of labels and\nhas the model perform prediction, implicitly exploiting\nlabel correlations. Specifically, the state embeddings would\nbe added to the aforementioned label embeddings to form\nthe masked label embeddings Àúlc for LMT:\nÀúlc = lc + sc, (2)\nwhere sc is one of the states among unknown, positive, neg-\native. Thus, the masked label embeddings can be formulated\nas ÀúL = {Àúl1, Àúl2, ...,ÀúlC} in the LMT process.\nAs shown in Fig. 2, the image features Z extracted by the\nvision backbone (e.g., ResNet (He et al. 2016)) would be\nconcatenated with the masked label embeddings ÀúL, and sent\ninto the transformer model. Thus, one has\nÀÜY = w(x, ÀúL), (3)\nwhere x denotes the input image, ÀúL represents the masked\nlabel embeddings, and ÀÜY is the predicted logit ( w denotes\nthe network model). However, as noted in Section 2, C-Tran\ncannot easily preserve label co-occurrence across different\nclients in FL settings. Thus, how to extend C-Tran for FL\nmulti-label classification remains a challenging task.\n3.3 Federated Language-Guided Transformer\nIn multi-label FL, we aim to learn a global model that gen-\neralizes to different clients with potential label distribution\nskews and diverse label correlations. Instead of simply per-\nforming model aggregation (like FedAvg) with pure visual\ninput which might lead to degraded multi-label classification\nperformances, we extend C-Tran and propose a novel learn-\ning scheme of Federated Language-Guided Transformer\n(FedLGT). As depicted in Fig. 2, we introduce model updat-\ning and feature embedding learning schemes for FedLGT, as\npresented below.\nClient-Aware Masked Label Embedding To train global\nand client models in multi-label FL settings, how to tackle\nthe domain shift or label skews across clients while jointly\nexploiting inherent label co-occurrence information is a\nchallenging problem. At the t-th training round, each client\napplies the global model wt to output the prediction vector\nP = {p1, p2, ..., pC}, where each of pc ‚àà [0, 1] represents\na probability indicating the presence of the associated label.\nHowever, since the global model would not generalize to\neach client during training rounds, one would expect some\nclass labels to be with lower confidence (i.e.,pc is around 0.5\ninstead of being close to1 or 0). In such cases, a client-aware\ntraining strategy is necessary for updating the associate local\nmodel and calibrating the state embeddings sc.\nTo address this problem, we proposeclient-aware masked\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n13885\nx\nCA-MLE\nULE\n ùëô!ùëô\"ùëô#\nùë†!$ùë†\"$ùë†#$\ny\nGlobal model wt\nThe photo contains [CLASS]Prompt templateText Encoder\nRandom masksCalibrate    by Eq. (4)\nP\nùë†!ùë†\"ùë†#\nFigure 3: Details of CA-MLE and ULE. With the input im-\nage x and label y, CA-MLE generates the prediction by\nglobal model wt and calibrates the state embeddings, while\nULE advances the pre-trained label embeddings from CLIP\nfor model aggregation purposes.\nlabel embedding (CA-MLE) as depicted in Fig. 3 for local\nmodel updating. In CA-MLE, we would modify the orig-\ninal state embeddings of c-th class to be unknown if the\npc is uncertain, otherwise, the state embeddings remain un-\nchanged. More precisely, the calibrated state embeddings\nS‚Ä≤ = {s‚Ä≤\n1, s‚Ä≤\n2, ..., s‚Ä≤\nC} are defined as\ns‚Ä≤\nc :\n\u001aunknown, œÑ ‚àí Œµ ‚â§ pc ‚â§ œÑ + Œµ\nsc, otherwise , (4)\nwhere œÑ denotes the threshold (typically 0.5 as set in most\nmulti-label works (Lanchantin et al. 2021; Liu et al. 2021))\nto determine the presence of the corresponding class, and\nŒµ as the adaptable margin to describe the uncertainty. Note\nthat only the unknown state would contribute losses to the\ntraining. Namely, if the probability lies in the interval, it in-\ndicates that the c-th class is uncertain for the global model\nwt, and such a class is enforced to be further learned during\nthat training round.\nWith calibrated state embeddings mentioned above, we\nview these embeddings as the masks to indicate which parts\nshould be learned more during local training. We would not\nperform training by randomly generated masks as Eq. (2)\nstated. Instead, we utilize these calibrated state embeddings\ns‚Ä≤\nc to each of the label embeddings to form the masked label\nembeddings to enhance the local training. Through the use\nof this calibration technique, we can harness the knowledge\ncontained within the global model through state embeddings\nto guide the local training. Namely, it allows the local clients\nto focus more on those classes that are still challenging for\nthe global model when local training, resulting in learning a\nbetter generalized and robust model after FL aggregation.\nUniversal Label Embedding In federated multi-label\nclassification, the aggregated global model would not prop-\nerly capture label correlation across different clients, since it\ndoes not have access to data for each client. Recall that, for\neach client, the local models may only capture the partial\nAlgorithm 1: Training of FedLGT\nInput: Communication rounds T, local epochs E,\nnumber of all clients K, the fraction of active\nclient in each round œÅ, the initial model w0,\nk-th client dataset Dk;\nOutput: The trained global model wt\n1 Build universal label embedding L in Sec. 3.3\n2 for t = 1, 2, ..., Tdo\n3 Sample R = ‚åàœÅ ¬∑ K‚åâ clients to train\n4 for k = 1, 2, ...Rin paralleldo\n5 wt\nk ‚Üê LocalUpdate(wt, L)\n6 wt+1 ‚Üê Œ£K\nk=1\n|Dk|\n|D| wt\nk\n7 return wt\n8 LocalUpdate(wt, L)\n9 for e = 1, 2, ..., Edo\n10 wt\nk ‚Üê wt\n11 for (xk, yk) ‚àà Dk do\n12 P ‚Üê wt(xk, yk, L)\n13 Produce ÀúL with P by CA-MLE in Sec. 3.3\n14 Update wt\nk by Lbce\n15 return wt\nk\nview of label correlations. Since an aggregation step is com-\nmonly deployed in FL to update the global model, it would\nbe desirable to design a proper local model alignment mech-\nanism, so that the inherent label co-occurrence information\nobserved at each client would be properly shared and aggre-\ngated at the server.\nTo accomplish this, as depicted in Fig. 3, we propose\nto deploy universal label embedding (ULE) across clients\nin FedLGT. That is, we advance the large vision-language\n(VL) pre-trained model of CLIP (Radford et al. 2021) and\nutilize its (fixed) text encoder for deriving pre-aligned and\nfixed label embeddings. To be more specific, we build a\nprompt ‚ÄúThe photo contains [CLASS]‚Äù as the input of the\ntext encoder to generate the embedding for the associated\nc-th class label lc. Such pre-trained/aligned label embed-\ndings thus serve as the guidance during training of FedLGT,\nensuring the updates of local models are aligned with pre-\ndetermined embedding space and thus favoring the subse-\nquent model aggregation process.\n3.4 Training of FedLGT\nIn FedLGT, we perform local model updates and global\nmodel aggregation in one communication round to achieve\na federated learning process.\nLocal Model Update During the local model update, as\ndepicted in Figure 2, each client k would go through CA-\nMLE with ULE to produce masked label embeddings. For\nCA-MLE, the client would receive an aggregated global\nmodel from the previous round, and it would make a predic-\ntion on a given image to obtain the logits. With these logits\nfrom the global model, it can be served as guidance for the\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n13886\nMetrics C-AP\nC-P C-R C-F1 O-AP O-P O-R O-F1\nCentralized (upper\nbound)\nResNet 67.71 75.71 55.42 64.00 90.40 84.09 78.96 81.44\nC-Tran 71.60 76.30 62.00 68.40 91.50 84.40 80.70 82.50\nFederated\nFedA\nvg 40.63 42.74 26.53 32.74 77.39 78.35 56.31 65.53\nFedC-Tran 56.00 49.40 38.20 43.10 88.10 83.10 72.50 77.40\nOurs 60.90 67.80\n46.50 55.10 88.70 84.00 75.90 79.70\nTable 1: Comparisons of coarse-grained multi-label classifi-\ncation task on FLAIR. Bold denotes the best result under the\nFL setting.\nlocal model in the training process. It implies that the local\nmodel wt\nk would identify the classes which are not properly\ndescribed from the perspective of the global model. Thus,\nthis allows the local model to focus more on those classes\nduring training. As for ULE, the label correlations would be\naligned according to fixed label embeddings across different\nclients. After passing these components, we follow Eq. (2) to\nperform element-wise addition of these embeddings to form\nmasked label embedding to serve as the label inputs of the\nlocal model.\nWith masked label embedding, we leverage the self-\nattention mechanism in the transformer block to capture the\nrelationships between the input image features and label cor-\nrelations. To be more specific, we concatenate the masked\nlabel embeddings and image features extracted by the vi-\nsion backbone (e.g., ResNet) as the input tokens of the trans-\nformer. Next, the output embeddings generated by the trans-\nformer are sent to the classifier (i.e., MLP head) to produce\nthe multi-label classification results (i.e., ÀÜY in Figure 2).\nAs for the loss function to update the local model for\nclient k (i.e., wt\nk shown in Figure 2), we adopt binary cross-\nentropy loss with our adjustment for masks, and only the\nmasked labels would be optimized during training, which is\nformulated as:\nLbce = ‚àí\nX\ns‚Ä≤\ncis unknown\n‚àÄc‚àà[1,C]\nyc log(pc), (5)\nGlobal Model Aggregation Once the local training is\ndone, the clients would upload their local models wt\nk to the\nserver and perform the aggregation step in FL. Specifically,\nwe utilize the vanilla FedAvg (McMahan et al. 2017) aggre-\ngation process, and it can be derived as follows:\nwt+1 = Œ£K\nk=1\n|Dk|\n|D| wt\nk, (6)\nAs soon as the training of our framework is converged, the\ntrained aggregated global model is capable of performing\nmulti-label image classification tasks by setting all the state\nembeddings to unknown for prediction.\nWith the above learning process, we are able to transfer\nthe knowledge of the global model to local clients, with in-\nherent and partial label correlation properly shared and up-\ndated. The pseudo-code of our proposed framework is de-\nscribed in Algorithm 1. Once the training of FedLGT is com-\nplete, we apply the learned model for testing.\nMetrics C-AP\nC-P C-R C-F1 O-AP O-P O-R O-F1\nCentralized (upper\nbound)\nResNet 20.26 32.97 10.92 16.40 47.95 68.73 30.04 41.81\nC-Tran 27.50 33.10 13.30 18.90 54.20 71.00 34.70 46.60\nFederated\nFedA\nvg 2.03 1.99 0.40 0.66 27.31 65.47 10.50 18.10\nFedC-Tran 3.30 3.00 1.00 1.50 36.70 69.10 20.60 31.70\nOurs 10.60 6.50\n1.40 2.30 42.20 69.80 21.90 33.40\nTable 2: Comparisons of fine-grained multi-label classifica-\ntion task on FLAIR. Bold denotes the best result under the\nFL setting.\n4 Experiments\n4.1 Experimental Setup\nDatasets To demonstrate the effectiveness of our pro-\nposed learning framework, we conduct extensive evaluations\non various benchmark datasets, including FLAIR (Song,\nGranqvist, and Talwar 2022), MS-COCO (Lin et al. 2014),\nand PASCAL VOC (Everingham et al. 2015). Specifically,\nwe primarily evaluate our method on the recently intro-\nduced multi-label FL dataset, FLAIR. FLAIR is a large-\nscale multi-label FL dataset, which contains a wide vari-\nety of photos collected from real users on Flickr. FLAIR\nprovides real-user data partitions with each input image in\n256 √ó 256 pixels. Thus, FLAIR naturally captures vari-\nous non-IID characteristics, including quantity skew (i.e.,\nusers have different numbers of samples), label distribu-\ntion skew, and domain shift, leading to a more challeng-\ning scenario for FL. FLAIR is defined in a two-level hier-\narchy, one task called coarse-grained with 17 categories,\nthe other calledfine-grained with 1,628 categories. Besides,\nwe also validate the performance of our method on central-\nized datasets partitioned artificially for FL, including MS-\nCOCO and PASCAL VOC. To the best of our knowledge,\nthese datasets have not been explored before in the con-\ntext of multi-label FL. MS-COCO contains about 122,218\nimages containing common objects, and the standard multi-\nlabel formulation covers 80 object class annotations for each\nimage. Moreover, the images in PASCAL VOC include mul-\ntiple labels, corresponding to 20 object categories, which is\na relatively easier task than FLAIR and MS-COCO.\nImplementation Details We use ResNet-18 (He et al.\n2016) as our vision backbone across all datasets mentioned\nabove. For the universal label embeddings, we build a\nprompt ‚ÄúThe photo contains [CLASS]‚Äù as the input of the\ntext encoder for CLIP (Radford et al. 2021), whereas for\nthe state embeddings, we build the prompt with one of the\n‚Äòpositive‚Äù or ‚Äònegative‚Äù for CLIP, and ‚Äúunknown‚Äù is fixed\nwith all zeros. Note that for FLAIR coarse-grained level\nsince the categories are abstract, we build the prompts in\ntwo ways via the fine-grained level information. One collects\nthe fine-grained labels for each coarse-grained label to build\nthe prompts (i.e., [CLASS] parts), and the other builds all\nembeddings of the fine-grained labels, and for each coarse-\ngrained label, taking average on corresponding fine-grained\nto build the coarse level embeddings. As for CA-MLE, we\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n13887\nMetrics C-AP\nC-P C-R C-F1 O-AP O-P O-R O-F1\nMS-COCO\nFedAvg\n69.20 71.00 60.30 65.20 77.80 75.80 65.30 70.20\nFedC-Tran 76.70 76.00 67.10 71.20 83.90 79.40 71.60 75.30\nOurs 78.30 77.20 70.00 73.40 84.70 80.20 73.70 76.80\nPASCAL\nVOC\nFedAvg 87.50 87.90 73.30 79.90 91.80 91.70 78.30 84.50\nFedC-Tran 89.60 88.20 79.60 83.60 93.70 91.70 83.40 87.30\nOurs 90.80 88.80 82.50 85.50 94.10 91.80 85.30 88.40\nTable 3: Comparisons on MS-COCO and PASCAL VOC for\nour FedLGT with FL baselines.\nset the threshold œÑ to 0.5 and the uncertainty margin Œµ is\n0.02. For each round of local training, we train 5 epochs\nusing the Adam (Kingma and Ba 2014) optimizer with a\nlearning rate of 0.0001, and the batch size is set to 16. For\nthe detail settings about FL, the communication round T is\nset to 50, and the fraction of active clients in each round\nis designed to achieve a level of participation equivalent to\n50 clients, thus ensuring the data distribution is represen-\ntative of the overall population. Besides, we observed that\nthe statistics of FLAIR (Song, Granqvist, and Talwar 2022)\nsuggest that the number of images across different users may\nhave significant variations, leading to severe quantity skew\nissues. Thus, we follow some previous FL works (Li et al.\n2019; Cho, Wang, and Joshi 2020) focusing on non-uniform\nclient sampling to handle this issue. The concept is sampling\nclients at random such that the probability is the correspond-\ning fraction of data at that client. With the help of this sam-\npling scheme, we could guarantee our client quality, avoid-\ning biased to very tiny local client datasets. Due to page lim-\nitations, we report the results with different sampling strate-\ngies in the supplementary materials. For all experiments, we\nimplement our model by PyTorch and conduct training on a\nsingle NVIDIA RTX 3090Ti GPU with 24GB memory.\n4.2 Performance Results and Analysis\nAs for the evaluation metrics, we follow the convention of\nworks on multi-label image classification (Lanchantin et al.\n2021; Ridnik et al. 2021) and use the metrics of per-class (C)\nand overall (O) average precision (i.e., C-AP and O-AP),\nprecision (C-P, O-P), recall (C-R, O-R), F1 scores (C-F1,\nO-F1), with details provided in the supplementary materi-\nals. For the coarse-grained task in FLAIR, we first utilize\nC-Tran (Lanchantin et al. 2021) to conduct centralized learn-\ning experiments and compare the centralized results to pure\nResNet-18 baseline. As shown in Table 1, the centralized C-\nTran improves the performance. However, as we transfer the\nC-Tran directly to FL (i.e., FedC-Tran across all our tables),\nit surpasses the baseline FedAvg though. The gap between\nFedC-Tran and centralized is still present and has room for\nimprovement. Hence, our proposed method could perform\nfavorably against FedC-Tran (e.g., 4.9% on C-AP, 12% on\nC-F1, etc.). Similarly, as for the fine-grained task shown\nin Table 2, the centralized C-Tran still overcomes ResNet-18\nbaseline. But, FedC-Tran has a huge performance drop when\ntransferred to FL compared to coarse-grained ones, which\nmay be caused by the corrupted label relationships due to the\nMetrics C-AP\nC-F1 O-AP O-F1\nFedC-Tran 56.00\n43.10 88.10 77.90\nFedC-Tran + CA-MLE 56.10 45.00 88.30 78.40\nFedC-Tran + ULE 59.70 54.90 88.30 78.90\nOurs 60.90 55.10\n88.70 79.70\nTable 4: Abaltion studies of our FedLGT using coarse-\ngrained task on FLAIR. Note that CA-MLE means client-\naware masked label embedding, while ULE is universal la-\nbel embedding. Bold denotes the best result.\naggregation step in FL. Thus, our method could avoid cor-\nrupt label relationships, leading to much more performance\nboosting (e.g., over 3√ó on C-AP, 1.5√ó on C-F1, etc.). Be-\nsides, as Table 3 presented, we also verify our effectiveness\non extra datasets designed for centralized multi-label prob-\nlems (MS-COCO, PASCAL VOC), and still achieve favor-\nable performance over FedC-Tran baseline.\n4.3 Ablation Studies\nAs reported in Table 4, we first perform ablation studies\nabout the two components in our method. From ‚ÄúFedC-Tran\n+ CA-MLE‚Äù of Table 4 (i.e., only using the client-aware\nmasked label embedding), we observe that the improvement\nis not obvious (e.g., 0.1% on C-AP) compared to FedC-\nTran baseline, which may be caused by the corrupted la-\nbel correlations. Next, from ‚ÄúFedC-Tran + ULE‚Äù of Table 4\n(i.e., only using universal label embedding), the improve-\nment (e.g., 3.7% on C-AP) becomes more significant since\nthe label embeddings are not corrupted by aggregation step.\nThus, it can be seen the importance of ULE for the robust-\nness and semantically label correlations. In the last row, our\nproposed method including the two aforementioned compo-\nnents is able to achieve satisfactory performance compared\nwith the baselines (e.g., 4.9% on C-AP), and highlights the\nimportance of ULE with the further improvements intro-\nduced by CA-MLE. Due to page limitation, additional ab-\nlation studies on the fine-grained FLAIR are provided in the\nsupplementary materials.\n5 Conclusion\nIn this paper, we tackle the challenging problems of multi-\nlabel FL. With the proposed framework of FedLGT, we are\nable to exploit local label correlation via learning client-\naware masked label embedding. With universal label embed-\nding derived from pre-trained vision and language model,\nthe alignment of locally learned models can be performed\nin the same embedding space, allowing aggregation of such\nmodels for improved performance. We verified our proposed\nmethods by conducting extensive experiments on the chal-\nlenging dataset FLAIR as well as benchmarks of MS-COCO\nand PASCAL VOC. Our experiments confirmed the robust-\nness and effectiveness of our proposed learning scheme for\nmulti-label FL.\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n13888\nAcknowledgements\nThis work is supported in part by the National Science and\nTechnology Council under grant 112-2634-F-002-007. We\nalso thank to National Center for High-performance Com-\nputing (NCHC) for providing computational and storage re-\nsources.\nReferences\nChen, J.; Xu, W.; Guo, S.; Wang, J.; Zhang, J.; and Wang,\nH. 2022. FedTune: A Deep Dive into Efficient Federated\nFine-Tuning with Pre-trained Transformers. arXiv preprint\narXiv:2211.08025.\nChen, T.; Lin, L.; Chen, R.; Hui, X.; and Wu, H. 2020.\nKnowledge-guided multi-label few-shot learning for general\nimage recognition. IEEE Transactions on Pattern Analysis\nand Machine Intelligence, 44(3): 1371‚Äì1384.\nChen, T.; Xu, M.; Hui, X.; Wu, H.; and Lin, L. 2019a. Learn-\ning semantic-specific graph representation for multi-label\nimage recognition. In Proceedings of the IEEE/CVF inter-\nnational conference on computer vision, 522‚Äì531.\nChen, Z.-M.; Wei, X.-S.; Wang, P.; and Guo, Y . 2019b.\nMulti-label image recognition with graph convolutional net-\nworks. In Proceedings of the IEEE/CVF conference on com-\nputer vision and pattern recognition, 5177‚Äì5186.\nCho, Y . J.; Wang, J.; and Joshi, G. 2020. Client se-\nlection in federated learning: Convergence analysis and\npower-of-choice selection strategies. arXiv preprint\narXiv:2010.01243.\nCohen, G.; Afshar, S.; Tapson, J.; and Van Schaik, A. 2017.\nEMNIST: Extending MNIST to handwritten letters. In 2017\ninternational joint conference on neural networks (IJCNN),\n2921‚Äì2926. IEEE.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2018.\nBert: Pre-training of deep bidirectional transformers for lan-\nguage understanding. arXiv preprint arXiv:1810.04805.\nEveringham, M.; Eslami, S. A.; Van Gool, L.; Williams,\nC. K.; Winn, J.; and Zisserman, A. 2015. The pascal vi-\nsual object classes challenge: A retrospective. International\njournal of computer vision, 111: 98‚Äì136.\nGao, L.; Fu, H.; Li, L.; Chen, Y .; Xu, M.; and Xu, C.-\nZ. 2022. Feddc: Federated learning with non-iid data via\nlocal drift decoupling and correction. In Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pattern\nRecognition, 10112‚Äì10121.\nGuo, T.; Guo, S.; Wang, J.; Tang, X.; and Xu, W. 2023.\nPromptfl: Let federated participants cooperatively learn\nprompts instead of models-federated learning in age of foun-\ndation model. IEEE Transactions on Mobile Computing.\nHe, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep resid-\nual learning for image recognition. In Proceedings of the\nIEEE conference on computer vision and pattern recogni-\ntion, 770‚Äì778.\nHuang, W.; Ye, M.; and Du, B. 2022. Learn from others and\nbe yourself in heterogeneous federated learning. InProceed-\nings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition, 10143‚Äì10153.\nIoffe, S.; and Szegedy, C. 2015. Batch normalization: Accel-\nerating deep network training by reducing internal covariate\nshift. In International conference on machine learning, 448‚Äì\n456. pmlr.\nKarimireddy, S. P.; Kale, S.; Mohri, M.; Reddi, S.; Stich, S.;\nand Suresh, A. T. 2020. Scaffold: Stochastic controlled av-\neraging for federated learning. In International Conference\non Machine Learning, 5132‚Äì5143. PMLR.\nKingma, D. P.; and Ba, J. 2014. Adam: A method for\nstochastic optimization. arXiv preprint arXiv:1412.6980.\nKrizhevsky, A.; Hinton, G.; et al. 2009. Learning multiple\nlayers of features from tiny images.\nLanchantin, J.; Wang, T.; Ordonez, V .; and Qi, Y . 2021. Gen-\neral multi-label image classification with transformers. In\nProceedings of the IEEE/CVF Conference on Computer Vi-\nsion and Pattern Recognition, 16478‚Äì16488.\nLi, Q.; He, B.; and Song, D. 2021. Model-contrastive feder-\nated learning. In Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, 10713‚Äì10722.\nLi, T.; Sahu, A. K.; Zaheer, M.; Sanjabi, M.; Talwalkar, A.;\nand Smith, V . 2020. Federated optimization in heteroge-\nneous networks. Proceedings of Machine learning and sys-\ntems, 2: 429‚Äì450.\nLi, X.; Huang, K.; Yang, W.; Wang, S.; and Zhang, Z. 2019.\nOn the Convergence of FedAvg on Non-IID Data. In Inter-\nnational Conference on Learning Representations.\nLi, X.; Jiang, M.; Zhang, X.; Kamp, M.; and Dou, Q. 2021.\nFed{BN}: Federated Learning on Non-{IID} Features via\nLocal Batch Normalization. In International Conference on\nLearning Representations.\nLin, T.-Y .; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ra-\nmanan, D.; Doll ¬¥ar, P.; and Zitnick, C. L. 2014. Microsoft\ncoco: Common objects in context. In Computer Vision‚Äì\nECCV 2014: 13th European Conference, Zurich, Switzer-\nland, September 6-12, 2014, Proceedings, Part V 13, 740‚Äì\n755. Springer.\nLiu, S.; Zhang, L.; Yang, X.; Su, H.; and Zhu, J. 2021.\nQuery2label: A simple transformer way to multi-label clas-\nsification. arXiv preprint arXiv:2107.10834.\nLuo, M.; Chen, F.; Hu, D.; Zhang, Y .; Liang, J.; and Feng,\nJ. 2021. No fear of heterogeneity: Classifier calibration for\nfederated learning with non-iid data. Advances in Neural\nInformation Processing Systems, 34: 5972‚Äì5984.\nMcMahan, B.; Moore, E.; Ramage, D.; Hampson, S.; and\ny Arcas, B. A. 2017. Communication-efficient learning of\ndeep networks from decentralized data. In Artificial intelli-\ngence and statistics, 1273‚Äì1282. PMLR.\nMendieta, M.; Yang, T.; Wang, P.; Lee, M.; Ding, Z.; and\nChen, C. 2022. Local learning matters: Rethinking data\nheterogeneity in federated learning. In Proceedings of the\nIEEE/CVF Conference on Computer Vision and Pattern\nRecognition, 8397‚Äì8406.\nRadford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.;\nAgarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.;\net al. 2021. Learning transferable visual models from nat-\nural language supervision. In International conference on\nmachine learning, 8748‚Äì8763. PMLR.\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n13889\nRidnik, T.; Ben-Baruch, E.; Zamir, N.; Noy, A.; Friedman,\nI.; Protter, M.; and Zelnik-Manor, L. 2021. Asymmetric\nloss for multi-label classification. In Proceedings of the\nIEEE/CVF International Conference on Computer Vision ,\n82‚Äì91.\nSong, C.; Granqvist, F.; and Talwar, K. 2022. FLAIR: Fed-\nerated Learning Annotated Image Repository. Advances in\nNeural Information Processing Systems, 35: 37792‚Äì37805.\nSu, S.; Yang, M.; Li, B.; and Xue, X. 2022. Cross-domain\nFederated Adaptive Prompt Tuning for CLIP.arXiv preprint\narXiv:2211.07864.\nSun, G.; Mendieta, M.; Yang, T.; and Chen, C. 2022. Explor-\ning Parameter-Efficient Fine-tuning for Improving Commu-\nnication Efficiency in Federated Learning. arXiv preprint\narXiv:2210.01708.\nTan, Y .; Long, G.; Liu, L.; Zhou, T.; Lu, Q.; Jiang,\nJ.; and Zhang, C. 2021. Fedproto: Federated proto-\ntype learning over heterogeneous devices. arXiv preprint\narXiv:2105.00243, 3.\nVaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,\nL.; Gomez, A. N.; Kaiser, ≈Å.; and Polosukhin, I. 2017. At-\ntention is all you need. Advances in neural information pro-\ncessing systems, 30.\nWang, J.; Liu, Q.; Liang, H.; Joshi, G.; and Poor, H. V . 2020.\nTackling the objective inconsistency problem in heteroge-\nneous federated optimization. Advances in neural informa-\ntion processing systems, 33: 7611‚Äì7623.\nZhuang, W.; Gan, X.; Wen, Y .; Zhang, S.; and Yi, S. 2021.\nCollaborative unsupervised visual representation learning\nfrom decentralized data. In Proceedings of the IEEE/CVF\ninternational conference on computer vision, 4912‚Äì4921.\nThe Thirty-Eighth AAAI Conference on ArtiÔ¨Åcial Intelligence (AAAI-24)\n13890"
}