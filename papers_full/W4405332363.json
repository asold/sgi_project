{
  "title": "A head-to-head comparison of the accuracy of commercially available large language models for infection prevention and control inquiries, 2024",
  "url": "https://openalex.org/W4405332363",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5014886935",
      "name": "Oluchi Abosi",
      "affiliations": [
        "University of Iowa Health Care"
      ]
    },
    {
      "id": "https://openalex.org/A5005359544",
      "name": "Takaaki Kobayashi",
      "affiliations": [
        "University of Iowa Health Care"
      ]
    },
    {
      "id": "https://openalex.org/A5111362006",
      "name": "Natalie Ross",
      "affiliations": [
        "University of Iowa Health Care"
      ]
    },
    {
      "id": "https://openalex.org/A5068564094",
      "name": "Alexandra Trannel",
      "affiliations": [
        "University of Iowa Health Care"
      ]
    },
    {
      "id": "https://openalex.org/A5001530532",
      "name": "Guillermo Rodriguez‐Nava",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A5008060476",
      "name": "Jorge Salinas",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A5031586445",
      "name": "Karen Brust",
      "affiliations": [
        "University of Iowa Health Care"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4206316414",
    "https://openalex.org/W4310676767",
    "https://openalex.org/W4394808347",
    "https://openalex.org/W4392915068",
    "https://openalex.org/W4392823314",
    "https://openalex.org/W4403813762",
    "https://openalex.org/W4387242094",
    "https://openalex.org/W4389984066"
  ],
  "abstract": "Abstract We investigated the accuracy and completeness of four large language model (LLM) artificial intelligence tools. Most LLMs provided acceptable answers to commonly asked infection prevention questions (accuracy 98.9%, completeness 94.6%). The use of LLMs to supplement infection prevention consults should be further explored.",
  "full_text": "Concise Communication\nA head-to-head comparison of the accuracy of commercially\navailable large language models for infection prevention and control\ninquiries, 2024\nOluchi J Abosi MBChB, MPH, CIC1 , Takaaki Kobayashi MD, MPH1, Natalie Ross MD1, Alexandra Trannel MS1 ,\nGuillermo Rodriguez Nava MD2, Jorge L. Salinas MD2 and Karen Brust MD1\n1University of Iowa Health Care, Iowa City, IA, USA and2Stanford University, Stanford, CA, USA\nAbstract\nWe investigated the accuracy and completeness of four large language model (LLM) artificial intelligence tools. Most LLMs provided\nacceptable answers to commonly asked infection prevention questions (accuracy 98.9%, completeness 94.6%). The use of LLMs to supplement\ninfection prevention consults should be further explored.\n(Received 9 July 2024; accepted 8 November 2024; electronically published 12 December 2024)\nBackground\nInfection prevention and control (IPC) programs are essential in\npreventing healthcare-associated infections (HAIs) and ensuring\npatient and staff safety. They oversee HAI surveillance, outbreak\ninvestigation, policy development, provide guidance on infection\ntransmission prevention, and occupational health.\n1 Their impor-\ntance was emphasized during the COVID-19 pandemic, with\na 500% surge in consultations.2\nArtificial intelligence (AI) is a growing field in computer science\nthat includes large language models (LLMs). LLMs are neural\nnetworks based on transformers simulating human responses.\n3\nThey have demonstrated capabilities in solving complex cases,\nexcel in clinical reasoning, history-taking, and empathetic\ncommunication.\n4 For the lone infection preventionist (IP) or\nfacilities without IP support, LLMs present the possibility for\npersonalized support related to infection prevention inquiries.\nAI research in medicine primarily targets clinical contexts\n4,5,w e\ninvestigated the accuracy and completeness of four LLMs using\nreal-world infection prevention questions.\nMethods\nThe IP team at the University of Iowa Health Care Medical Center\nis led by hospital epidemiologists. It is an 866-bed tertiary care\ncenter encompassing 250 specialty and subspecialty outpatient\nclinics. IPs respond to urgent infection prevention questions via\nmultiple communication modalities 24 hours a day. Domains\ncovered include communicable infections, isolation precautions,\nenvironmental cleaning, public health inquiries, and laboratory\ntesting. All calls received by the IP are recorded in a shared excel\nspreadsheet with date, time, and query details for each encounter.\n2\nUsing 2022 data, 31 sample questions were categorized into the\nthree most common domains: transmission-based precautions,\ncommunicable disease exposures, and environmental cleaning\n(Supplemental Tables 1, 2). The study was approved as non-\nhuman subjects research by the University of Iowa Institutional\nReview Board.\nWe evaluated four LLMs: Microsoft Copilot (formerly Bing AI),\nGPT-3.5, GPT-4, and OpenEvidence between December 2023 and\nJanuary 2024. These four LLMs were chosen for ease of use, access,\nand familiarity. Each LLM was queried once for each question.\nTwo epidemiologists and one certified IP reviewed each question\nusing 5-point and 6-point Likert scales for accuracy and\ncompleteness per our internal policies (Supplemental Table3).\nResponses ≥3 were deemed accurate, and those≥4 complete. We\ncalculated acceptable accuracy percentages by dividing the number\nof responses with a score≥3 by the total number of responses.\nAdditional sensitivity analysis with accuracy scores of≥ 4 was\nperformed. Similarly, we calculated acceptable completeness\npercentages as the number of responses with a score≥4 divided\nby the total number of responses. Each reviewer assessed 31\nquestions per LLM for both accuracy and completeness without a\nqualifying prompt. Additionally, we re-evaluated the quality of\nresponses of the same 31 questions, restricting the LLMs to Centers\nfor Disease Control and Prevention (CDC) databases by adding\nthe statement: “Follow CDC guidelines in the United States.”\nWe compared the accuracy and completeness of the LLMs using\npaired 2-tailed t-tests with Microsoft Copilot as the reference and\ncalculated 95% confidence intervals from binomial distributions.\nStatistical analyses were performed using Python 3.10.\nCorresponding author: Oluchi J. Abosi; Email:oluchi-abosi@uiowa.edu\nCite this article:Abosi OJ, Kobayashi T, Ross N,et al. A head-to-head comparison of\nthe accuracy of commercially available large language models for infection prevention and\ncontrol inquiries, 2024.Infect Control Hosp Epidemiol2025. 46: 309–311, doi: 10.1017/\nice.2024.205\n© The Author(s), 2024. Published by Cambridge University Press on behalf of The Society for Healthcare Epidemiology of America. This is an Open Accessarticle, distributed under the\nterms of the Creative Commons Attribution licence (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted re-use, distribution and reproduction, provided the\noriginal article is properly cited.\nInfection Control & Hospital Epidemiology(2025), 46, 309–311\ndoi:10.1017/ice.2024.205\nhttps://doi.org/10.1017/ice.2024.205 Published online by Cambridge University Press\nResults\nOverall, GPT-4 had the highest accuracy: 98.9% (95% CI 94.3%–\n99.9%) without CDC restrictions and 97.9% (95% CI 92.6%%–\n99.6%) with restrictions (P < .001 for GPT-4 vs other LLMs)\n(Table 1). For specific domains, GPT-4 had the highest accuracy for\nisolation precaution responses (98.0% without CDC restrictions and\n98.0% with restrictions,P < .001) and for healthcare personnel\nexposure responses (100% without CDC restrictions and 95.8% with\nrestrictions, P < .001). OpenEvidence was the only LLM not\nreaching 100% accuracy for patient exposure and environmental\ncleaning responses (Figure1,S u p p l e m e n t a lT a b l e4).\nFor completeness, GPT-4 led with 90.3% (95% CI 82.4%–\n95.1%) without CDC restrictions and 94.6% (95% CI 87.8%–\n97.9%) with restrictions (P < .001) (Table1). Similarly, for specific\ndomains, GPT-4 had the highest completeness for isolation\nprecaution responses (88.2% without CDC restrictions and 92.2%\nwith restrictions, p<.001) and for healthcare personnel exposure\nresponses (95.8% with and without CDC restrictions,P < .001).\nMicrosoft Copilot was the only LLM achieving 100% completeness\nTable 1. Percentage of overall acceptable accuracy and completeness score across large language models response to infection prevention questions withoutand\nwith CDC statementsa,b\nAcceptable Accuracy Acceptable Completeness\nLLM\nWithout CDC statementc (n = 93) With CDC statement c (n = 93)\nWithout CDC statementc\n(n = 93) With CDC statement c (n = 93)\n% (95% CI) P valued % (95% CI) P valued % (95% CI) P valued % (95% CI) P valued\nOpenEvidence 83.9 (74.8 –90.4) <0.001 75.3 (66.7 –84.0) <0.001 72.0 (61.9 –80.3) <0.001 68.8 (58.6 –77.5) 0.16\nGPT-3.5 88.2 (79.7 –93.7) 0.76 90.3 (82.4 –95.1) <0.001 67.7 (57.6 –76.6) <0.001 66.7 (56.5 –75.9) <0.001\nGPT-4 98.9 (94.3 –99.9) <0.001 97.9 (92.6 –99.6) <0.001 90.3 (82.4 –95.1) <0.001 94.6 (87.8 –97.9) <0.001\nBing AI (Microsoft Copilot) 88.2 (79.7 –93.7) Reference 80.7 (71.1 –87.8) Reference 81.7 (72.7 –88.5) Reference 68.8 (58.6 –77.5) Reference\nLLMs, Large Language Models.\naThe accuracy scale was a 5-point Likert scale (with 1 indicating completely incorrect; 2, more incorrect than correct; 3, approximately equal correct and incorrect; 4, more correct that incorrect;\nand 5, completely correct). The completeness scale was a 6-point Likert scale (with 1 indicating addresses no aspect of the question, and the answer isnot within the topic queried; 2, addresses\nno aspect of the question, and the answer is within the topic queried; 3, addresses some aspect of the question, but significant parts are missing or incomplete; 4, addresses most aspects of the\nquestions but missing small details; and 5, addresses all aspects of the question without additional information; 6 addresses all aspects of the question and provides additional information\nbeyond what was expected).\nbResponses with scores≥3 was deemed accurate\ncWithout limiting the models search to CDC-only references versus with prompt limiting the models search to CDC-only references.\ndPairwise t-test results, with Bing AI (Microsoft Copilot) as reference\nFigure 1. Heatmap of acceptable accuracy and completeness score percentages by category across large language models in response to infection prevention questions without\nand with CDC statementsa, b. LLM, Large Language Models.a The accuracy scale was a 5-point Likert scale (with 1 indicating completely incorrect; 2, more incorrect than correct;\n3, More correct than incorrect but missing some major elements; 4, More correct than incorrect but missing some minor elements; and 5, completely correct). a The completeness\nscale was a 6-point Likert scale (1, addresses no aspect of the question, and the answer is not within the topic queried; 2, addresses no aspect of the question, and the answer is\nwithin the topic queried; 3, addresses some aspect of the question, but significant parts are missing or incomplete; 4, addresses most aspects of the questions but missing small\ndetails; 5, addresses all aspects of the question without additional information; and 6 addresses all aspects of the question and provides additional information beyond what was\nexpected). b Responses with scores≥3 were deemed accurate. Responses with scores≥4 were deemed complete.cWithout limiting AI tool search to CDC-only references versus\nwith prompt limiting AI tool search to CDC-only references.\n310 Oluchi J Abosiet al.\nhttps://doi.org/10.1017/ice.2024.205 Published online by Cambridge University Press\nfor patient exposure responses, both with and without CDC\nrestrictions (P < .05, except GPT-4 with CDC restrictions), and for\nenvironmental cleaning responses (P < .05, except GPT-4 with\nCDC restrictions) (Figure1, Supplemental Table5). The results of\nthe sensitivity analysis are summarized in Supplemental Table6.\nGPT-3.5 and OpenEvidence lagged in both accuracy and\ncompleteness. Limiting LLMs to CDC-only references decreased\nresponse accuracy and completeness, particularly accuracy. Only\nGPT-3.5 and OpenEvidence showed improved accuracy with CDC\nrestrictions for isolation precautions and patient exposures,\nrespectively. With CDC restrictions, GPT-4 demonstrated\nimproved completeness for isolation precautions, patient expo-\nsures, and environmental cleaning and disinfection. GPT-3.5 and\nOpenEvidence again showed improved completeness for isolation\nprecautions and patient exposures, respectively.\nDiscussion\nFew studies have evaluated LLMs in practical IPC settings. A recent\nstudy evaluated the accuracy of AI tools in identifying HAIs\nconcordant with National Healthcare Safety Network (NHSN)\ndefinitions using fictional scenarios. The AI tools correctly\nidentified whether cases met NHSN definitions when given clear\nprompts.\n6 Herein, we evaluated the accuracy and completeness of\nfour LLMs using real infection prevention queries. Most LLMs\nprovided acceptable answers to the commonly asked inquiries.\nProspective studies are needed to explore the application of AI in\nreal-world IPC scenarios and assess the effectiveness of LLMs in\ninfection control.\nIn this study, GPT-4 provided the most accurate and complete\nresponses across most categories, whereas OpenEvidence was the\nleast accurate and GPT-3.5 the least complete. LLMs performed\nbetter in areas concerning patient exposures and environmental\ncleaning, but their performance decreased in transmission-based\nprecautions. Using CDC prompts negatively impacted accuracy\nand completeness, a trend consistent across all categories.\nHowever, using this prompt may not have been the best approach.\nOpenEvidence, which primarily searches PubMed or peer-\nreviewed articles, performed poorly, likely due to its limited\nreferences. Microsoft Copilot and both versions of ChatGPT have\n“knowledge” extracted from websites, textbooks, journals, and\npublic-facing data sources. LLMs have the potential for continuous\nlearning and improvement through regular exposure to new data\nand scenarios. By processing real-world infection prevention\nqueries, these models can be continuously refined. Their accuracy\nand completeness can be improved by using techniques such as\nprompt engineering and retrieval-augmented generation without\nthe need for extensive retraining, which requires significant\ncomputing power not readily available.\n7\nAfter the COVID-19 pandemic, infection prevention con-\nsultation calls increased significantly. Although calls were\nprimarily associated with COVID-19, numbers have not yet\nreturned to pre-pandemic levels.2 The shift of focus from other\ninfection prevention activities due to increased calls could have\nnegative consequences and should be addressed.\n8 Integration of\nLLMs into IPC programs could significantly enhance resource\nallocation.\n9 LLMs efficiently handling frequently asked queries\nwould allow human experts to concentrate on more complex and\nnuanced issues requiring specialized knowledge and critical\nthinking. Optimizing human resources would lead to more\neffective IPC programs and generate better overall healthcare\noutcomes.\nLimitations include the small sample size of questions and\nevaluators from a single tertiary care center. We chose four readily\navailable LLMs. Alternate LLMs or newer versions may provide\ndifferent answers and impact results. Each LLM was queried only\nonce. There is a lack of standardized methods to evaluate\nAI-generated responses. Although acceptable accuracy was scored\nat ≥3, we assigned this score for neutral categorization. A score of\n≥4 would have resulted in fewer responses considered accurate\n(Supplemental Table6). The magnitude of reduction was greater\nfor LLMs with limited or outdated information sources.\nAdditionally, not all LLMs provided output that included\nreferences or citations. However, we sought to be comprehensive\nby modifying assessment tools used in prior studies that assessed\nAI performance.\n10 Four categories were assessed, but each category\nhad a different number of questions, ranging from 3 to 17,\ncomparative to calls received. Additionally, although responses\nwere independently reviewed by each evaluator, they could see\nresponses to prompts with and without CDC restrictions,\npotentially influencing scoring.\nIn conclusion, LLMs show promise as tools to potentially\nsupplement IPC programs and reduce workload. Their perfor-\nmances could be further enhanced through retrieval-augmented\ngeneration using official guidelines or local policies. Further\ndevelopment will enable LLMs to significantly contribute to the\nadvancement of infection prevention practices.\nSupplementary material.The supplementary material for this article can be\nfound athttps://doi.org/10.1017/ice.2024.205.\nFinancial support.None.\nCompeting interests.None.\nReferences\n1. Holmes K, McCarty J, Steinfeld S. Infection Prevention and Control\nPrograms APIC Text Online . Boston: Association for Professionals in\nInfection Control and Epidemiology; 2021.\n2. Alsuhaibani M, Kobayashi T, McPherson C,et al.Impact of COVID-19 on\nan infection prevention and control program, Iowa 2020-2021.Am J Infect\nControl 2022;50:277–82.\n3. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN,et al.\nAttention is all you need.Paper presented at: 31st Annual Conference on\nNeural Information Processing Systems (NIPS); Dec 4–9, Long Beach, CA;\n2017.\n4. Goh E, Gallo R, Hom J,et al. Influence of a Large Language Model on\nDiagnostic Reasoning: A Randomized Clinical Vignette Study. medRxiv.\nhttps://doi.org/10.1101/2024.03.12.24303785.\n5. Han T, Adams LC, Bressem KK, Busch F, Nebelung S, Truhn D.\nComparative analysis of multimodal large language model performance on\nclinical vignette questions.JAMA. 2024;331:1320–21.\n6. Wiemken TL, Carrico RM. Assisting the infection preventionist: Use of\nartificial intelligence for health care –associated infection surveillance.\nAm J Infect Control2024;52:625–29.\n7. Gao Y, Xiong Y, Gao X,et al. Retrieval-Augmented Generation for Large\nLanguage Models: A Survey; 2024.arXiv preprint arXiv:231210997. https://\ndoi.org/10.48550/arXiv.2312.10997\n8. Pintar PA, McAndrew NS. An unheard voice: Infection prevention\nprofessionals reflect on their experiences during the covid-19 pandemic.\nAm J Infect Control2023;51:890–94.\n9. Guerra R. Enhancing risk management in hospitals: leveraging artificial\nintelligence for improved outcomes.Italian J Med2024;18:1721.\n10. Goodman RS, Patrinely JR, Stone CA, Jr,et al.Accuracy and Reliability of\nChatbot Responses to Physician Questions. JAMA Netw Open. 2023;6:\ne2336483–e83.\nInfection Control & Hospital Epidemiology 311\nhttps://doi.org/10.1017/ice.2024.205 Published online by Cambridge University Press",
  "topic": "Completeness (order theory)",
  "concepts": [
    {
      "name": "Completeness (order theory)",
      "score": 0.6369891166687012
    },
    {
      "name": "Disease control",
      "score": 0.474230021238327
    },
    {
      "name": "Medicine",
      "score": 0.4367806315422058
    },
    {
      "name": "Head start",
      "score": 0.4273505210876465
    },
    {
      "name": "Head (geology)",
      "score": 0.41779637336730957
    },
    {
      "name": "Computer science",
      "score": 0.35656481981277466
    },
    {
      "name": "Artificial intelligence",
      "score": 0.32535016536712646
    },
    {
      "name": "Psychology",
      "score": 0.24076730012893677
    },
    {
      "name": "Environmental health",
      "score": 0.18452861905097961
    },
    {
      "name": "Mathematics",
      "score": 0.07977798581123352
    },
    {
      "name": "Biology",
      "score": 0.0728447437286377
    },
    {
      "name": "Developmental psychology",
      "score": 0.060727447271347046
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210142782",
      "name": "University of Iowa Health Care",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I97018004",
      "name": "Stanford University",
      "country": "US"
    }
  ],
  "cited_by": 1
}