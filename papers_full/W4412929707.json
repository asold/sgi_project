{
  "title": "A large language model digital patient system enhances ophthalmology history taking skills",
  "url": "https://openalex.org/W4412929707",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2512343975",
      "name": "Ming Jie Luo",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2923513779",
      "name": "Shaowei Bi",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2773659918",
      "name": "Jianyu Pang",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2516553864",
      "name": "Lixue Liu",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2555964045",
      "name": "Ching-kit Tsui",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A5002671672",
      "name": "Yunxi Lai",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2702921752",
      "name": "Wenben Chen",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2141026601",
      "name": "Yahan Yang",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2895078850",
      "name": "Kezheng Xu",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2980797784",
      "name": "Lanqin Zhao",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2096206629",
      "name": "Ling-Jin",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2232064656",
      "name": "Duoru Lin",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2169663165",
      "name": "Xiaohang Wu",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2108246486",
      "name": "Jingjing Chen",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2098876242",
      "name": "Rongxin Chen",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2098831879",
      "name": "Zhenzhen Liu",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2605319546",
      "name": "Yuxian Zou",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2123956294",
      "name": "Yangfan Yang",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2106067126",
      "name": "Yiqing Li",
      "affiliations": [
        "Sun Yat-sen University"
      ]
    },
    {
      "id": "https://openalex.org/A2111647575",
      "name": "Haotian Lin",
      "affiliations": [
        "Sun Yat-sen University",
        "Hainan Eye Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2512343975",
      "name": "Ming Jie Luo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2923513779",
      "name": "Shaowei Bi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2773659918",
      "name": "Jianyu Pang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2516553864",
      "name": "Lixue Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2555964045",
      "name": "Ching-kit Tsui",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5002671672",
      "name": "Yunxi Lai",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2702921752",
      "name": "Wenben Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2141026601",
      "name": "Yahan Yang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2895078850",
      "name": "Kezheng Xu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2980797784",
      "name": "Lanqin Zhao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096206629",
      "name": "Ling-Jin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2232064656",
      "name": "Duoru Lin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2169663165",
      "name": "Xiaohang Wu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2108246486",
      "name": "Jingjing Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098876242",
      "name": "Rongxin Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098831879",
      "name": "Zhenzhen Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2605319546",
      "name": "Yuxian Zou",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2123956294",
      "name": "Yangfan Yang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2106067126",
      "name": "Yiqing Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2111647575",
      "name": "Haotian Lin",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2141791438",
    "https://openalex.org/W2032135060",
    "https://openalex.org/W2150829078",
    "https://openalex.org/W2343537248",
    "https://openalex.org/W2102059763",
    "https://openalex.org/W1965388506",
    "https://openalex.org/W2007619687",
    "https://openalex.org/W2415522413",
    "https://openalex.org/W2790677937",
    "https://openalex.org/W2624736049",
    "https://openalex.org/W2152225508",
    "https://openalex.org/W1974432375",
    "https://openalex.org/W4307201126",
    "https://openalex.org/W4220742161",
    "https://openalex.org/W2036488299",
    "https://openalex.org/W2009683697",
    "https://openalex.org/W2294009851",
    "https://openalex.org/W2131804230",
    "https://openalex.org/W3022756532",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W6854308750",
    "https://openalex.org/W4382918229",
    "https://openalex.org/W4387440167",
    "https://openalex.org/W4388287351",
    "https://openalex.org/W4319460874",
    "https://openalex.org/W4391745580",
    "https://openalex.org/W4400775727",
    "https://openalex.org/W4387014587",
    "https://openalex.org/W4386776401",
    "https://openalex.org/W4389577325",
    "https://openalex.org/W4400593735",
    "https://openalex.org/W4406327404",
    "https://openalex.org/W4400284205",
    "https://openalex.org/W6870841478",
    "https://openalex.org/W4313197536",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4391170193",
    "https://openalex.org/W4388759569",
    "https://openalex.org/W4404562099",
    "https://openalex.org/W3130938027",
    "https://openalex.org/W4388922836",
    "https://openalex.org/W4395085952",
    "https://openalex.org/W4402957955",
    "https://openalex.org/W4391225179",
    "https://openalex.org/W4386897457",
    "https://openalex.org/W4376866715",
    "https://openalex.org/W4390268440",
    "https://openalex.org/W4393094536",
    "https://openalex.org/W6862617764",
    "https://openalex.org/W4385266429",
    "https://openalex.org/W4400079353",
    "https://openalex.org/W4408098677",
    "https://openalex.org/W4390918905",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W2334344335",
    "https://openalex.org/W638508087",
    "https://openalex.org/W2118348276",
    "https://openalex.org/W4400921803",
    "https://openalex.org/W4398775037",
    "https://openalex.org/W4400657362",
    "https://openalex.org/W4392193048",
    "https://openalex.org/W4393201572",
    "https://openalex.org/W6852874933",
    "https://openalex.org/W6796581206",
    "https://openalex.org/W4310923934",
    "https://openalex.org/W2331393505",
    "https://openalex.org/W4256161595",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W2164973508",
    "https://openalex.org/W6633697127",
    "https://openalex.org/W2026229280",
    "https://openalex.org/W4251166405",
    "https://openalex.org/W2110065044"
  ],
  "abstract": null,
  "full_text": "npj |digital medicine Article\nPublished in partnership with Seoul National University Bundang Hospital\nhttps://doi.org/10.1038/s41746-025-01841-6\nA large language model digital patient\nsystem enhances ophthalmology history\ntaking skills\nCheck for updates\nMing-Jie Luo1,4,S h a o w e iB i1,4, Jianyu Pang1,4, Lixue Liu1,4, Ching-Kit Tsui1, Yunxi Lai1,W e n b e nC h e n1,\nYahan Yang1,K e z h e n gX u1,L a n q i nZ h a o1,L i n gJ i n1, Duoru Lin1, Xiaohang Wu1,J i n g j i n gC h e n1,\nRongxin Chen1, Zhenzhen Liu1, Yuxian Zou1,Y a n g f a nY a n g1, Yiqing Li1 & Haotian Lin1,2,3\nClinical trainees face limited opportunities to practice medical history-taking skills due to scarce case\ndiversity and access to real patients. To address this, we developed a large language model-based\ndigital patient (LLMDP) system that transforms de‑identiﬁed electronic health records into\nvoice‑enabled virtual patients capable of free‑text dialog and adaptive feedback, based on our\npreviously established open-source retrieval-augmented framework. In a single‑center randomized\ncontrolled trial (ClinicalTrials.gov: NCT06229379;N = 84), students trained with LLMDP achieved a\n10.50-point increase in medical history-taking assessment scores (95% CI: 4.66–16.33, p < 0.001)\ncompared to those using traditional methods. LLMDP-trained students also demonstrated greater\nempathy. Participants reported high satisfaction with LLMDP, emphasizing its role in reducing training\ncosts and boosting conﬁdence for real patient interactions. Theseﬁndings provide evidence that LLM-\ndriven digital patients enhance medical history-taking skills and offer a scalable, low-risk pathway for\nintegrating generative AI into ophthalmology education.\nAccording to Kolb ’s experiential learning cycle, students must\nundergo concrete experiencesto effectively acquire skills1,2. In medical\neducation, it is crucial for students to gain extensive exposure to real-\nworld clinical scenarios3,4. However, the standard case-based learning\napproach often faces a signi ﬁcant shortage of materials featuring\nauthentic clinical cases5,6. Furthermore, due to a scarcity of clinical\nmentors and limited opportunities for hands-on practice, students\nfrequently miss out on critical interactions with actual patients7,8. This\nlimitation hinders the enhancement of students’ medical history tak-\ning abilities9.\nTo address this issue, standardizedpatients (SPs) were proposed for\nclinical teaching, which allowed medical students to develop clinical skills\nindependently of real cases and hasgained widespread global adoption10,11.\nHowever, individuals portraying SPs require specialized training, which often\nfalls short of achieving authentic portrayals12. This limitation impacts the\nefﬁciency of medical training, contributes to high teaching costs, and there-\nfore does not fully resolve the issue of limited clinical educational resources13.\nWith the advancement of digital and multimedia technology, vir-\ntual patients (VPs) have emerged as a potential solution to these\nchallenges\n14–16. While VPs effectively foster intrinsic motivation and\nbaseline clinical reasoning competence, maintaining their utility\nrequires continuous updates to reﬂect evolving clinical standards\n17–20.\nGuided by the Calgary-Cambridge communication framework 12,21,\nwhich emphasizes structured communication skill development, VPs\nshould exhibit diverse personalities, linguistic habits, and communica-\ntion styles. Additionally, teaching content should be adapted based on\nregional differences, students’ knowledge levels, and variations in dis-\nease spectra to enhance learning experiences and improve knowledge\nretention. Consequently, students may encounter outdated or incom-\nplete information, hindering their ability to grasp the latest clinical\npractices and knowledge, especially for the rare cases. Moreover, the\nﬁxed nature of responses presents another limitation: virtual patients’\nresponses are typically preprogrammed and sometimes overly rigid,\nwhich prevents realistic doctor-patient interaction training.\n1State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University, Guangdong Provincial Key Laboratory of Ophthalmology and\nVisual Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, Guangzhou, China.2Center for Precision Medicine and Department of\nGenetics and Biomedical Informatics, Zhongshan School of Medicine, Sun Yat-sen University, Guangzhou, Guangdong, China.3Hainan Eye Hospital and Key\nLaboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University, Haikou, China.4These authors contributed equally: Ming-Jie Luo, Shaowei\nBi, Jianyu Pang, Lixue Liu. e-mail: linht5@mail.sysu.edu.cn\nnpj Digital Medicine|           (2025) 8:502 1\n1234567890():,;\n1234567890():,;\nLarge language models (LLMs), such as ChatGPT (Open AI, San\nFrancisco, CA, USA), represent a recent signiﬁcant advancement in\nhealthcare22–24. Through a literature search, we found that LLM applica-\ntions in medicine such as answering medical examination questions25,26,\nproviding diagnostic and treatment recommendations27,28, summarizing\nclinical research articles29, and generating patient education materials30 are\nbeing increasingly explored. Gray M et al.31 demonstrate the use of LLMs to\ngenerate authentic patient-clinician dialogs, while Cook et al.32,33 and\nMcKell et al.34 further supported their potential for enhancing medical\neducation. Their established effectiveness in medical consultations lays the\nfoundation for exploring their potential impact on medical education\n35–37.\nBy processing extensive medical literature and electronic health records\n(EHRs), LLMs has demonstrated the ability to extract detailed clinical\ninformation from patient discharge summaries\n38. This capability is crucial\nfor creating VPs that accurately simulate real patients for educational\npurposes39,40. This innovative approach aims to address the shortage of\nauthentic clinical scenarios prevalent in traditional case-based learning.\nWhile there have been feasibility studies exploring the use of LLMs in\nmedical education\n18,30, such as those by Potter & Jefferies41 and Yao et al.42,\nthese studies primarily served as proofs-of-concept without rigorous\nrandomized controlled trials (RCTs) or comprehensive validation. Using\nLLMs to build digital patients (DPs) to simulate real-world doctor-patient\ninteraction is a promising area, but their effectiveness in medical education\nrequires thorough evaluation\n43–46.\nIn this study, we developed an LLM-based digital patient (LLMDP)\nsystem that not only virtualizes case information resembling a digital twin47,\nb u ta l s os e r v e sa sad y n a m i c“digital patient” by simulating realistic, emo-\ntionally rich patient interactions akin to conversing with a real patient. Using\nour previously established retrieval-augmented LLM framework28 and a\nlarge-scale knowledge base, the system allowed medical students to practice\nophthalmology history taking in Chinese conversation with DPs (Fig.1a).\nThen, its effectiveness and correlation were preliminarily validated through\na controlled experiment (Fig.1b, c). Finally, we conducted a randomized\ncontrolled trial to assess the effects of the system on students’ history taking\nability measured by medical history-taking assessment scores (Fig.1d).\nResults\nOphthalmic data curation and LLM selection with modelﬁne-\ntuning\nWe curated a comprehensive ophthalmic dataset by incorporating data\nfrom various sources, including electronic health records (EHRs),\nclinical guidelines, ophthalmology textbooks, multiple-choice questions,\nand patient-doctor consultation dialogs (Fig.2a, b). The dataset was\nprocessed into an instruction-output format, with the accuracy of the\ndata being validated by ophthalmologists. Theﬁnal dataset comprised\n59,343 entries, covering a wide range of ocular diseases (Fig.2c). After\nevaluating multiple LLMs using 50 ophthalmic tasks in ophthalmic\nknowledge, information extraction, and instruction alignment as\ndescribed in Methods, Baichuan-13B-Chat was selected for its best\nperformance in open source LLMs, achieving a win rate comparable to\nGPT-3.5 Turbo (Fig.2d, e), while also addressing patient privacy con-\nsiderations. Fine-tuning of Baichuan-13B-Chat over 20 epochs further\nenhanced its performance, enabling its integration into the LLMDP\nsystem for effective simulation of digital patients in clinical consulta-\ntions (Fig.2f, g).\nKnowledge base construction and LLMDP system development\nWe constructed knowledge bases (KBs) for simulating DPs by analyzing\npatient notes and integrating them withslit-lamp photographs, covering 24\nkey ocular diseases (Fig.3a and Supplementary Note 1). The LLMDP system\nused these KBs to match student inquiries with accurate responses during\nhistory-taking simulations (Fig.3b). When no direct match was found, the\nsystem generated answers using patient notes, translated into colloquial\nlanguage for realistic interactions. Accessible through various devices, the\nsystem provided real-time feedback and personalized guidance (Fig.3c, d).\nAdditionally, an automatic scoring system was implemented based on\nobjective structured clinical examination (OSCE) checklists to objectively\nevaluate students’ proﬁciency in medical history-taking (see Methods:“The\ndevelopment of the automatic scoring system”). This scoring system ana-\nlyzed key points from the consultations, providing standardized and\nobjective assessments.\nComparative validation experiment and correlation analysis\nThe two validation experiments were conducted at the end of development\nof the LLMDP system to test its function including validating its effective-\nness in medical training using SPs andthe correlation between automated\nscoring and manual scoring.\nIn validation experiment 1, participants were examined using SPs to\ncompare LLMDP-based training with the traditional real patient-based\ntraining method. Preliminary results showed that the LLMDP group\ndemonstrated improved medical history taking skills compared to the\ncontrol group (mean ± SD: 78.13 ± 8.35 vs. 67.08 ± 7.21, respectively), with\nan average score increase of 11.05 points (mean difference, 6.61–15.48, 95%\nCI, p < 0.001, Fig.4b).\nFig. 1 | Overview of the study design.The LLM-based digital patient (LLMDP)\nsystem development and validation process comprises four stages:a Clinical\ninstructors used a large language model (LLM) to extract information from elec-\ntronic health records and generated a digital patient knowledge base (KB). The KB\nwas used to construct an LLM-based digital patient (LLMDP) system.b A controlled\nexperiment was conducted to preliminarily validate the effectiveness of LLMDP\nsystem in medical history-taking training compared to traditional patient-based\ntraining methods.c The correlation of an automated scoring model, incorporated in\nthe LLMDP system, was tested in comparison to manual scoring to show that it\nprovides valid scores for trainee proﬁciency. d A randomized clinical trial was\nconducted to assess the effect of the LLMDP system on students’ medical history\ntaking abilities compared with that of traditional methods. EHR electronic health\nrecord, KB knowledge base, LLM large language model, LLMDP large language\nmodel-based digital patient, MHTA medical history-taking assessment.\nhttps://doi.org/10.1038/s41746-025-01841-6 Article\nnpj Digital Medicine|           (2025) 8:502 2\nIn validation experiment 2, participants were consecutively evaluated\ntwice using both assessment methods:ﬁrst by real patient encounters and\nthen by the automatic scoring system. The results indicated high positive\ncorrelation between the scores obtained from the LLMDP system and those\nfrom real patient encounters (Pearson’s correlation coefﬁcient,r = 0.88, 95%\nCI: [0.79, 0.93],p < 0.001, Fig.5b).\nClinical trial to evaluate LLMDP’s effectiveness in medical\nhistory taking\n84 fourth-year medical students who had not received prior clinical training\nwere enrolled and divided into traditional real patient-based training group\nand LLMDP-based training group. The baseline ophthalmology theoretical\nexamination scores in the control group were similar to those in the LLMDP\nhttps://doi.org/10.1038/s41746-025-01841-6 Article\nnpj Digital Medicine|           (2025) 8:502 3\ngroup (75.82 ± 8.44 vs. 77.05 ± 7.81), as well as the levels of understanding of\nLLMs before the trial (Table1).\nThe effectiveness of these methods was assessed through MHTA,\nwhich was designed to evaluate students’ proﬁciency in medical history\ntaking process. The LLMDP group (64.62 ± 9.52) demonstrated a perfor-\nmance improvement in comparison to the control group (54.12 ± 8.80),\nwith an average score increaseof 10.50 (mean difference, 4.66–16.33, 95%\nCI, p < 0.001), as shown in Fig.6b.\nAdditionally, in deconstructing the patient history-taking process,\nwe noted that participants who received LLMDP training demonstrated\nsigniﬁcant improvements in all subitems of the history-taking process in\nMHTA (Supplementary Table 1), including in the collection of identi-\nﬁcation and demographic information (Effect size: 0.78, 95% CI:\n0.33–1.22), the history of present illness section (0.56, 0.12–1.00), past\nmedical history (1.04, 0.58–1.49), and other medical history (0.76,\n0.31–1.20).\nFig. 2 | Ophthalmic dataset construction, LLM selection, and modelﬁne-tuning.\nOphthalmic dataset construction, LLM benchmarking, and modelﬁne-tuning\nworkﬂow includes:a The preprocessing workﬂow for the ophthalmic instruction\ntraining data. EHR, guidelines, textbooks, multiple-choice questions and knowledge\nfrom ophthalmology textbooks, and patient-doctor consultation dialogs were used\nto construct ophthalmic dataset. After being processed into an instruction-output\nformat, the accuracy of the data was sampled and checked by ophthalmologists.\nb The source distribution of the ophthalmic instruction dataset.c The distribution of\nocular diseases in the ophthalmic instruction dataset.d A workﬂow for comparing\nLLMs using the Chatbot Arena approach. The LLMs were given 50 instruction tasks\nin Chinese, including ophthalmic knowledge, EHR information extraction, doctor’s\nquestion paraphrasing, patient’s answer paraphrasing and consultation-related\nqueries. Two ophthalmologists compared the output of the two anonymized LLMs.\nFinally, the win rate between different models was calculated.e Human evaluation\ncomparing the Baichuan-13B-Chat model with other models. The win, tie and loss\nrates of Baichuan-13B-Chat versus the other models are shown.f The BLEU and\nROUGE-L performance metrics on the test set across theﬁne-tuning epochs. The\nmodel trained at 20 epochs was selected for the study.g Human evaluation com-\nparing theﬁne-tuned Baichuan-13B-Chat model with other models. LLM large\nlanguage model, BLEU Bilingual Evaluation Understudy, ROUGE-L Recall-\nOriented Understudy for Gisting Evaluation - Longest Common Subsequence, EHR\nelectronic health record.\nFig. 3 | Development and demonstration of the LLMDP system.The framework\nintegrates knowledge base construction, clinical interaction simulation, multi-\nplatform deployment, and automated feedback generation.a Using the LLM to\nconstruct a KB for DPs. After 24 eye diseases were selected from a clinical teaching\nsyllabus, a clinical inquiry question set was compiled, and EHRs for relevant clinical\ncases were collected. A LLM was used to answer questions based on patient notes and\ncreating patient information sheets that were weighted according to clinical sig-\nniﬁcance. The sheets were then combined with slit-lamp photographs to form a\ncomprehensive KB for DPs.b An example of a history-taking process between the\nuser and LLMDP system. Medical students’ questions were transcribed and matched\nto the KB for answers. If a match was found, then the LLMDP system provided as an\noutput; otherwise, the LLMDP system created an answer from the patient notes.\nResponses were then converted into colloquial language by the LLM, transformed\ninto speech, and provided to students through the HCI interface.c The LLMDP\nsystem can be accessed through a web browser on various devices (e.g., iPad,\nsmartphone, PC).① Initiate consultation by voice input;② make corrections to the\ninquiry text if necessary;③ the LLMDP system responds via voice output.\nd Concluding the consultation, reviewing the score and personalized guidance, and\naccessing detailed feedback.① After completing the consultation, click“End” to view\nthe score and receive personalized guidance.② The exam results are displayed.\n③ Personalized guidance is shown.④ Drag the slider down to view the full text of the\nfeedback. LLM large language model, DP digital patient, KB knowledge base, TTS\ntext-to-speech, ASR automatic speech recognition, HCI human-computer interface,\nLLMDP large language model-based digital patient, EHR electronic health record.\nThe language used in the study was originally Chinese and was translated into\nEnglish for presentation purposes.\nhttps://doi.org/10.1038/s41746-025-01841-6 Article\nnpj Digital Medicine|           (2025) 8:502 4\nStudents’ attitudes toward using LLMs in medical education\nAll participants completed a standardized quantitative questionnaire based\non the widely usedﬁve-point Likert scale (Methods) about their attitudes\ntoward the application of LLMs in medical education after using the\nLLMDP system during the trial.\nThe quantitative questionnaire results from participants are sum-\nmarized in Table2. After using LLMDP, subjects were highly satisﬁed\nwith the history taking instruction provided by the LLMDP and felt that\nthe LLMDP achieved overall better teaching and learning outcomes\n(48.81% agreement vs. 21.42% disagreement). Additionally, it helped\novercome psychological barriers to learning how to ask questions\n(65.48% agreement vs. 17.85% disagreement) and saved both time\n(57.15% agreement vs. 22.62% disagreement) and ﬁnancial costs of\ninstruction (66.67% agreement vs. 14.28% disagreement). Overall, the\nLLMDP achieves better teaching and learning outcomes (48.81%\nagreement vs. 21.42% disagreement), and participants expressed a will-\ningness to recommend the LLMDP for learning medical history taking\nability to other students (44.05% agreement vs. 25.00% disagreement).\nHowever, participants also believed that LLMDP could not fully imitate\nthe interaction process with patients due to the absence of a physical\nbody (37.29% agreement vs. 20.34% disagreement) and that the guidance\nprovided by LLMDP for medical image analysis was insufﬁcient (40.68%\nagreement vs. 16.95% disagreement).\nAt the end of the trial, the participants had a group discussion about\nthe merits and drawbacks of employing LLMs in medical education.\nThree aspects of using LLMs in medical education, namely, accessibility,\ninteraction, and effectiveness, were discussed. Their representative opi-\nnions are summarized in Supplementary Table 2 and educators’ attitudes\ntoward using LLMs in medical education are shown in Supplementary\nTable 3.\nAfter the MHTA, the expert panel assessed all students’ empathy\nperformance based on the backendrecordings from the MHTA process.\nThe results showed that students in the LLMDP group exhibited better\ne m p a t h y( S u p p l e m e n t a r yF i g .1 b ) .\nFig. 4 | Comparison of the effectiveness between traditional teaching methods\nand the LLMDP system using standardized patients during the\ndevelopment phase.A validation study demonstrates enhanced clinical competency\nthrough standardized assessments.a Study process: A group of 50 participants from\nthe Zhongshan School of Medicine, Sun Yat-sen University, who had not received\nprior clinical training, were divided equally into two groups. The experimental group\nof 25 participants used the LLMDP for training, while the control group of 25\nparticipants interacted with real patients. After completing of their respective\ntraining sessions, both groups underwent a standardized evaluation using\nstandardized patients and were scored by ophthalmologists. A total of 6 SPs were\nused for this examination, each uniformly trained to play the same patient role to\nensure fairness.b Performance comparison evaluated using standardized patients\nand scored by ophthalmologists. The LLMDP group (78.13 ± 8.35, mean ± SD)\ndemonstrated a performance improvement in comparison to the control group\n(67.08 ± 7.21, mean ± SD), with an average score increase of 11.05 points (mean\ndifference, 6.61–15.48, 95% CI,p < 0.001). LLMDP large language model-based\ndigital patient, SPs standardized patients.\nFig. 5 | Convergent validity of LLMDP-based assessments against real patient\nevaluations. Evaluation of the correlation between the assessment methods of real\npatient encounters and LLMDP-based scenarios.a Study process: Another set of 50\nfourth-year medical students from the Zhongshan School of Medicine, Sun Yat-sen\nUniversity, who were undergoing traditional clinical internships were included.\nParticipants were consecutively evaluated twice using both assessment methods\n(real patient encounters and LLMDP-based scenarios) for their medical history-\ntaking assessment (MHTA).b Scatter plot comparing the evaluation scores mea-\nsured using the two methods. Each data point on the graph represents a participant,\nwith the position on the plot corresponding to the scores from the two methods. A\nmoderate positive correlation between the two methods was shown. Pearson’s\ncorrelation coefﬁcient r = 0.88 (95% CI: [0.79, 0.93]). LLMDP large language model-\nbased digital patient; MHTA: medical history-taking assessment;.\nhttps://doi.org/10.1038/s41746-025-01841-6 Article\nnpj Digital Medicine|           (2025) 8:502 5\nDiscussions\nIn this study, we developed an LLM-based digital patient system for medical\neducation, and validated its efﬁcacy in control experiments and in a pro-\nspective randomized controlled trial. Our study has three main implications,\nwhich are to: (1) demonstrate the feasibility of developing an LLMDP sys-\ntem for medical education, (2) provide evidence of its effectiveness in\nimproving history-taking skills, and (3) explore the students’ experiences\nwith the system.\nThe potential of the LLMDP system extends beyond merely replicating\ntraditional medical education methods; it provides possibilities for trans-\ncending the limitations of traditional training paradigm. Building on our\nprior LLM augmentation framework\n28, we incorporated clinical guidelines,\nEHRs and doctor-patient conversations. This has enabled the simulation of\ndynamic digital patients that signiﬁcantly surpass earlier digital models\nreliant on static, scripted interactions, which lacked the capability to inter-\npret nuanced language or complex instructions effectively22. Our system’s\nadvanced semantic understanding capabilities facilitate dynamic, con-\ntextually relevant dialogs across a widerange of clinical scenarios, offering\nscalability and realism unattainable by the earlier virtual patient models15,19.\nImportantly, LLMDP uses real, anonymized EHR data to generate clinically\nauthentic patient scenarios, validated rigorously by expert clinicians to\nensure educational relevance and accuracy which is one of the key advan-\ntages as supported in the literature48.W eh a v et a k e ng r e a tc a r et oe n s u r et h a t\nthe cases generated reﬂect actual patient conditions, incorporating diverse\nsymptoms, medical histories, and responses. Additionally, all patient data\nand scenario content undergo rigorous review and validation by expert\nclinicians before being integrated into the LLMDP system, ensuring their\nclinical relevance and educational value.\nRecent advances have begun to tackle the rigidness of traditional\nhistory-taking training. Conventional methods—whether involving real\nstandardized patients or static computer-based cases– are resource-\nintensive and offer limited scenario variability49. Correspondingly, prior\nwork has highlighted thatﬁxed virtual cases often lack interactivity and\nadaptive feedback15,19. To address these gaps, several studies have applied\nLLMs to simulation. For example, Potter and Jefferies showed that a GPT-\ndriven agent could serve as a generative“virtual patient” for communication\ntraining41; Yao et al. developed a related LLM-powered patient dialog\nsystem42; Borg et al. combined an LLM with a social robot to create more\nauthentic case encounters50; and Holderried et al. found that a ChatGPT\nchatbot acting as a simulated patientproduced highly plausible history\nresponses51. Our LLMDP differs from these earlier systems in several key\nways. First, every case is instantiated from real EHR data rather than a\nscripted scenario. Second, the digital patient can exhibit diverse personalities\nand emotional styles—an advance speciﬁcally noted as desirable in prior\nwork\n50. Third, LLMDP continuously tracks the student’s history-taking\nprogress as they go. And fourth, the system automatically generates feed-\nback on the completeness and correctness of the history, building on\nﬁndings that LLMs can score student interviews with high agreement to\nexpert raters49. By grounding simulation in authentic data and by delivering\nreal-time tracking and feedback, the LLMDP directly addresses limitations\nof earlier approaches—in particular, overcoming the static, one-shot nature\nof prior virtual cases– and thus extends the existing literature on AI-based\npatient simulators.\nThe state-of-the-art semantic understanding capabilities of LLMs\n52\nenable the system to effectively interpret student inputs while role-playing\npatients with diverse personalities and communication styles. This ability to\ninteract with students in a manner that closely mimics real patient\nencounters, helping trainees overcomepsychological barriers often asso-\nciated with real-life medical history taking process, such as anxiety or hes-\nitation, thereby creating a more conducive environment for learning. Unlike\nconventional methods, which often rely on standardized cases and static\nteaching materials\n15,19, the LLMDP can dynamically generate patient\nTable 1 | Baseline characteristics of participants in the two\ngroups of the clinical trial\nControl\nn = 42\nLLMDP\nn = 42\nFemale sex,n (%) 21 (50.0) 20 (47.6)\nAge (years) 20.9 (0.4) 21.1 (0.4)\nYears of medical school 4 (0) 4 (0)\nBaseline ophthalmic exam scores 75.82 (8.44) 77.05 (7.81)\nBaseline understanding of LLM,n (%)\nUnfamiliar 4 (9.5) 5 (12.0)\nHeard of but never used 16 (38.1) 15 (35.1)\nUsed occasionally 21 (50.0) 15 (35.1)\nRegular use 1 (2.4) 7 (16.7)\nThe values are shown as the means (SDs) unless otherwise stated.\nLLM large language model,LLMDP large language model-based digital patient.\nFig. 6 | A randomized controlled trial testing the efﬁcacy of LLMDP training in\nclinical history taking education.A RCT with 84 medical trainees with no prior\nclinical experience compares ophthalmology history-taking performance across\ntraining modalities.a The trial proﬁle. Out of 84 assessed participants, all subjects\nwere included and randomized into control and LLMDP groups with no with-\ndrawals. They underwent initial training and the medical history-taking assessment\n(MHTA). b Participants’ clinical consultation scores on MHTA was 54.12 ± 8.80 for\nthe control group and 64.62 ± 9.52 for the LLMDP group, showing a mean difference\nof 10.50, 95% CI: 4.66–16.33, p < 0.001. Symbols: Blue circle (control), orange circle\n(LLMDP). The error bars represent the SDs. The data are shown as the means ± SDs\nand were analyzed using independent t tests with two-sidedp values (p < 0.05 was\nconsidered to indicate statistical signiﬁcance). MHTA medical history taking\nassessment, LLMDP large language model-based digital patient.\nhttps://doi.org/10.1038/s41746-025-01841-6 Article\nnpj Digital Medicine|           (2025) 8:502 6\nscenarios tailored to the speciﬁc learning needs. By aligning with the\nCalgary-Cambridge communication standards, which emphasize adapting\ncommunication strategies to meet the unique needs of each patient, the\nLLMDP system offers a more dynamic and personalized learning experi-\nence. It draws on a vast database of realcases, including rare and atypical\npresentations often underrepresented in conventional curricula, preparing\ntrainees to recognize and manage a broad spectrum of conditions they might\nencounter in clinical practice. Additionally, the system can simulate patients\nwith different personality traits, enhancing the realism and complexity of\ndoctor-patient interactions. In line with Kolb’s experiential learning cycle,\nthe automatic scoring system embedded within the LLMDP facilitates a\nfeedback loop that is integral to the learning process. It not only evaluates\nstudent performance but can also provide context-speciﬁc suggestions that\nhighlights areas for improvement. This adaptability allows for targeted\nreinforcement of weak areas, ensuring that students receive a more perso-\nnalized and effective learning experience. As they navigate complex patient\nhistories and evolving clinical situations, they develop critical thinking and\ndecision-making skills in real-time.\nEmpathy assessment required careful methodological design. Students\nwho trained with the LLMDP demonstrated signiﬁcantly higher empathic\ncommunication in subsequent assessments, consistent with our system’s\ndesign as an emotionally responsive“digital patient” rather than a static case\nrepository. Thisﬁnding parallels prior work showing that AI-driven virtual\npatient simulations can boost learner empathy: for example, trainees\ninteracting with virtual patients in low-pressure, interactive settings produce\nmore empathic responses\n53, and virtual patient encounters that include\nempathic feedback have yielded higher empathy scores in later standar-\ndized‐patient interviews\n54. By offering immersive, lifelike patient dialogs, the\nLLMDP likely reduced student anxiety and built conﬁdence, enabling more\nnatural patient-centered communication. Overall, our results underscore\nthat emphasizing realistic emotional dynamics in communication training\ncan meaningfully enhance empathic skills, in line with the current evidence.\nWe selected history-taking as the primary clinical skill to assess because\nit is a foundational component of the medical consultation process, serving\nas the gateway to other clinical competencies. While medical training\nencompasses a wide range of skills, effective history-taking is crucial for\naccurate diagnosis and management. Additionally, current-generation AI,\nincluding LLMs, faces signiﬁcant limitations in generating highly authentic\ndisease images and facilitating complex physical examinations. Given these\nconstraints, focusing on history-taking represents the most practical\napplication of available technology at this stage. Future work will extend the\nLLMDP system to incorporate additional clinical skills, such as physical\nexamination and diagnosis, as AI capabilities in these areas evolve.\nOur study was conducted in the context of ophthalmology clinical\nteaching, but it has the potential to be applied to medical history taking\ntraining across disciplines. While a signiﬁcant portion of the DP cases in this\nstudy involved eye diseases, the clinical diagnostic process we employed\nadheres to a holistic approach, encompassing various aspects such as disease\ncharacteristics, treatment history, past medical history, and family history.\nThis diagnostic thinking process is consistent across medical specialties,\nfocusing on primary symptoms, their onset, potential triggers, duration, and\nassociated symptoms. Moreover, many ophthalmic conditions, such as\ndiabetic retinopathy, thyroid-associated ophthalmopathy, and steroid-\ninduced cataracts, are related to systemic diseases\n55, enhancing students’\nunderstanding of the interconnectedness of different body systems. How-\never, the current capabilities of LLMs, including advanced models like GPT-\n4V, remain limited in their understanding and processing of medical\nimages\n56,57, making it hard for current LLMs to mimic human physician who\nis capable of simultaneously good at verbal communication and guiding\nmedical students in disease image recognition and diagnosis as pointed out\nby the participants. This limitation reﬂects a broader challenge at the cutting\nedge of industry innovation, where foundational technological advance-\nments are required. The inability of LLMs to simultaneously excel in lan-\nguage interaction and medical image recognition impedes their real-world\nTable 2 | Participants’ attitudes to using large language models in medical history-taking courses after the trial\nItem Agreement Disagreement\nAgree\nentirely\nSomewhat agree Undecided Somewhat\ndisagree\nDisagree\nentirely\nPositive:\nThe LLMDP allows me to learn more comprehensive knowledge about\nophthalmic diseases.\n28.57% 22.62% 25.00% 15.48% 8.33%\nThe LLMDP allows me to fully practice my clinical reasoning ability. 38.10% 22.62% 27.38% 5.95% 5.95%\nThe LLMDP helps to improve my doctor patient communication skills. 30.95% 11.90% 22.62% 19.05% 15.48%\nThe LLMDP provides me with more accurate knowledge about\nophthalmic diseases.\n29.76% 19.05% 29.76% 14.29% 7.14%\nThe LLMDP saves the time costs of teaching. 38.10% 19.05% 20.24% 13.10% 9.52%\nThe LLMDP saves theﬁnancial costs of teaching. 42.86% 23.81% 19.05% 8.33% 5.95%\nThe LLMDP helps me overcome psychological barriers when learning\nto ask patients questions.\n44.05% 21.43% 16.67% 7.14% 10.71%\nThe LLMDP makes me more interested in diagnostics. 29.76% 22.62% 22.62% 15.48% 9.52%\nOverall, the LLMDP achieves better teaching and learning outcomes. 32.14% 16.67% 29.76% 10.71% 10.71%\nI will recommend using the LLMDP for learning medical history taking\nability to other students.\n23.81% 20.24% 30.95% 13.10% 11.90%\nNegative:\nUsing commercial models like ChatGPT makes it hard to ensure data\nprivacy and security.\n10.17% 35.59% 35.59% 16.95% 1.69%\nThe LLMDP lacks a physical body, making the interaction different from\nreal patients.\n3.39% 33.90% 42.37% 20.34% 0.00%\nThe LLMDP provides limited guidance for diagnosing medical images,\nwhich may reduce their usefulness in clinical settings.\n6.78% 33.90% 42.37% 13.56% 3.39%\nLLM large language model,LLMDP large language model-based digital patient.\nhttps://doi.org/10.1038/s41746-025-01841-6 Article\nnpj Digital Medicine|           (2025) 8:502 7\ndeployment, highlighting an urgent need for breakthroughs in foundational\nAI technology.\nFeedback from both students and educators underscored the trans-\nformative impact and potential limitations of the LLMDP system in clinical\neducation. Students particularly highlighted the convenience and cost-\neffectiveness of the LLMDP system, noting that it provides an economical\nmeans of practicing logical thinking in various clinical scenarios. Moreover,\nthe system signiﬁcantly reduces the reliance on human actors for SP roles,\nthereby cutting both manpower needs and associated costs. The LLMDP\nsystem, accessible via mobile devices such as smartphones, tablets, and\nlaptops, facilitates a personalized andﬂexible educational experience,\nenabling students to practice independently. Thisﬂexibility allows students\nto engage in natural oral interactions anytime and anywhere, which is\nespecially beneﬁcial for beginners and those lacking conﬁdence, as it pro-\nvides them with ample opportunities to reﬁn et h e i rs k i l l sa n db u i l dc o n -\nﬁdence in real-world settings. At the same time, students reported that the\nLLMDP system alleviated their anxiety when dealing with patients and\nenhanced their empathy. This feature isparticularly valuable because real\npatients are often affected by physical and psychological conditions that\nmake it challenging to participate in educational activities. Moreover, SPs\nmay vary in their performance, especially under heavy teaching workloads.\nIn contrast, the LLMDP system is designed to provide more consistent\nteaching assistance, contributing to a more standardized learning\nexperience.\nWe acknowledge several limitations. Our system employs local lan-\nguage models to preserve data privacy, which comes at some cost to per-\nformance– the local model may not match that of commercial models\n58,59.\nTo counterbalance this, engineering techniques such asﬁne-tuning, disease\nknowledge bases, and prompt engineering, as applied in this study, are\nessential to enhance the local model’s capabilities in patient simulation\n38.I t\nfocuses on text-based history-taking only, without simulating a physical\npathophysiological body which allows for physical examination, interpret-\ning imaging or laboratory results,or covering broader diagnostic and\nmanagement processes. A promising future direction is to integrate basic\npathophysiological models into the LLMDP, enabling realistic simulation of\nunderlying disease processes\n60. Our study was conducted at a single insti-\ntution and focused on a speciﬁc history-taking skillset. Further research is\nneeded to explore the system’s utility in a wider variety of contexts and with\nmore extensive interventions, as wellas to establish its long-term impact\nacross different institutions and broader and more complex clinical skill sets.\nIn conclusion, we developed the LLMDP system and validated its\neffectiveness in enhancing medical history taking skills through a series of\nexperiments. Using the LLMDP system signiﬁcantly improved students’\nabilities in this area and achieved high satisfaction among both students and\nteachers. By integrating advanced generative AI, the LLMDP system has the\npotential to signiﬁcantly advance the current approach to medical educa-\ntion, providing a valuable blueprintfor future development and expansion\nby other educators and researchers in theﬁeld.\nMethods\nOphthalmic dataset construction, LLM selection, and modelﬁne-\ntuning\nFirst, we curated a comprehensive ophthalmic dataset by incorporating data\nfrom various sources, including EHRs, clinical guidelines, ophthalmology\ntextbooks, multiple-choice questions, and patient-doctor consultation dia-\nlogs (Fig.2a, b). The dataset was processed into an instruction-output for-\nmat, with the accuracy of the data beingvalidated by ophthalmologists. The\nﬁnal dataset comprised 59,343 entries, covering a wide range of ocular\ndiseases (Fig.2c).\nUsing previously established method\n28, we designed multiturn prompt\ntemplates and constructed a dataset with an instruction-output format to\nprocess the online medical consultation dialog data, by using historical\ndialog and patient notes as context and the patient’s actual response as the\noutput target. For nondialogue text data such as EHRs, clinical guidelines,\nand medical textbooks, we utilized text headings as weak supervision signals\nand designed rule-based templates toautomatically map the text into the\ndataset using LLMs. The detailed processes are provided in Supplementary\nNote 2.\nTo accurately reﬂect real-world performance and nuanced differences\nof these models, the performance ofseveral LLMs were evaluated by human\ndoctors using previously established evaluation standards\n28.B r i eﬂy, to\nenable human evaluation of the LLMs, we adopted an approach similar to\nthe model comparison method used in the Chatbot Arena project where\nhuman evaluate the output of LLMs\n61. We prepared 50 Chinese instruction\ntasks to evaluate the accuracy of LLMs in terms of ophthalmic knowledge,\ninformation extraction capabilities, and Chinese instruction alignment\nabilities (Fig.2d). Considering the models’ capabilities andu s a b i l i t y ,w e\nincluded Baichuan-13B-Chat, LLaMA2-Chinese-Alpaca2 (13B), LLaMA2-\n70B-Chat, ChatGLM2-6B and GPT-3.5Turbo (ChatGPT); detailed model\ninformation is provided in the Supplementary Note 3. Apart from GPT-3.5\nTurbo, among theﬁve models evaluated, Baichuan-13B-Chat demonstrated\nthe best overall performance in understanding and responding to Chinese\ninstructions and was therefore chosen for our study (Fig.2e).\nTo enhance the model’s ability to perform effectively in our speciﬁc\ncontext, weﬁne-tuned it using 8 Nvidia Tesla A800 GPUs (each with 80GB\nof memory). Fine-tuning helps adapt a pre-trained model to a specialized\ntask by updating its parameters based on new data. To make this process\nmore efﬁcient, we used LoRA (Low-Rank Adaptation)\n62, a technique that\nreduces the number of trainable parameters by introducing low-rank\nmatrices, thereby lowering computational requirements. This was imple-\nmented within DeepSpeed\n63, an advanced deep learning framework\ndesigned to optimize large-scale modeltraining. The key training settings\nwere as follows: Batch size: 4 (number of samples processed at a time),\nLearning rate: 5e-5 (determines how much the model updates during\ntraining), Weight decay:0 (no additional penalty for large weight values),\nScheduler: Cosine (gradually adjusts the learning rate over time), and\nTraining epochs: 25 (one epoch means the model has seen the entire dataset\nonce). The training process lasted approximately 19 h. The best results were\nobserved at epoch 20, where the model demonstrated superior performance\non automated evaluation metrics (BLEU and ROUGE, Fig.2f) and was\npreferred in human assessments (Fig.2g). Based on theseﬁndings, we\nselected this version for further studies.\nThe development of the LLMDP system\nIn developing the LLMDP system, we utilized theﬁne-tuned LLM to analyze\npatient notes and generate a Knowledge Base (KB) for simulating digital\npatients (Fig.3). First, in accordance with the syllabus requirements, 24\nocular diseases, all of which are prioritized for student mastery, were\nincluded (Supplementary Note 1). Next,a clinical inquiry question set for\nthese 24 ocular diseases was compiled by enumerating all the questions\nconcerning symptoms, signs, and pertinent notes based on ophthalmology\ntextbooks, standardized patient notes, and outline and scoring criteria of\nprevious standardized history-takingexams. EHRs, including patient notes\nand slit-lamp photographs as the ocular images, for patients with the 24\ndiseases were gathered. Using theﬁne-tuned LLM, all questions in the\nclinical inquiry question set corresponding to each disease were answered\nbased on the patient notes, and the patient information sheet was generated\nusing a standard prompt template (Supplementary Fig. 2a). Importance\nweights were assigned to each question in the patient information sheet\nbased on the diagnostic signiﬁcance of each question after the expert panel\ndiscussion\n64 (Supplementary Tables 6 and 7), with speciﬁc scores calculated\naccording to a predeﬁned rubric: 5 points for patient identiﬁcation and\ndemographics, 50 points for history of present illness, 25 points for past\nmedical history, and 20 points for other medical history. The sheet was then\ncombined with the slit-lamp photographs to form a KB for the DPs.\nWhen participants interacted with the LLMDP system, their inquiry\naudio was converted into text through an automatic speech recognition\n(ASR) algorithm\n65. Then, the system matched the inquiry questions with the\nKB of the DPs using Sentence Bidirectional Encoder Representations from\nTransformers (SBERT) embeddings (distiluse-base-multilingual-cased-\nhttps://doi.org/10.1038/s41746-025-01841-6 Article\nnpj Digital Medicine|           (2025) 8:502 8\nv1)66 as a semantic textual similarity model. If a match was found, then the\ncorresponding answer was output. If no match was found, then the LLMDP\ngenerated an answer based on the entire patient note using a prompt\ntemplate (Supplementary Fig. 2b). Notably, the LLMDP system is designed\nto understand the meaning and intent behind students’ questions rather\nthan requiringﬁxed wording patterns. Next, the answer generated in the\nprevious phase was reﬁned into more colloquial language using the LLM,\nsimulating the patient’s tone to enhance realism; at the same time, the LLM\ncould randomly assign personality traits to the patient, further enriching the\nauthenticity of the dialog scenario (Supplementary Fig. 2c). Finally, the\nresponse was converted into speech through the text-to-speech (TTS)\nalgorithm\n67 and provided as feedback to the students via the human-\ncomputer interaction (HCI) interface (Fig.3b).\nThe development of the automatic scoring system\nTo establish a scoring system to evaluate the participants’ proﬁciency in\nmedical history taking, weﬁrst identiﬁed key points in clinical consultation\nfor each patient based on the objective structured clinical examination\n(OSCE) checklists for ophthalmic history taking68,69, which are widely used\nas the National Medical Licensing Examination70 along with ophthalmo-\nlogic textbooks and standardized medical records (Supplementary Fig. 3).\nThen, we preliminarily formulated medical inquiry questions about each\nkey point and recruited experts in the relevant subspecialties for group\ndiscussion to determine theﬁnal medical inquiry questions and evaluate\ntheir clinical importance for each case. The expert panel consisted of 9\nprofessors, including 3 cataract specialists, 2 glaucoma specialists, 1 retina\nspecialist, 1 cornea specialist, 1 orbitspecialist, and 1 trauma specialist. The\nspeciﬁc discussion process\n64 is outlined in Supplementary Fig. 3:ﬁrst, the\nimportance of each category of medical history was determined (Supple-\nmentary Table 6), followed by assigning scores to each individual question,\nwith an illustrative example shown in Supplementary Table 7.\nUpon the completion of history taking, the dialog between participants\nand the DP was used to calculate the medical history taking assessment\n(MHTA) scores. During the history taking practice phase, after each session,\nthe system displayed real-time scores, including points earned and points\nlost, to facilitate improvement in the examination phase, this feedback\nfeature was turned off.\nUser instructions for the LLMDP system\nThe LLMDP system interface includes a voice chat window where users\nverbally interact with the system, an avatar with an image of the real patient’s\neye represents the DP’s visual presence and a feedback window showing user\nprogress (Fig.3c, d). After entering their student ID and choosing a topic,\nusers are directed to the conversational interface designed for practicing\nmedical history taking. This interface comprises three main components.\nFirst, a dynamic virtual character is presented on the main screen, enhan-\ncing the realism of the interactions, and simulating real-life patient con-\nversations. Second, the response section appears beneath the virtual\ncharacter. Here, students can engage incontinuous dialog by either using the\n“speak” button for voice commands or typing their responses directly. Upon\nsubmitting their responses, the system provides immediate feedback\nthrough both text and voice outputs. Finally, the sidebar features question\nindicators that track the student’s progress. As students address each\nquestion in a section, the corresponding checkboxes are marked, offering\ninstant feedback on students’ progress. During the practice period, the\nsystem displays feedback in real time which medical history sections the\nparticipants had completed. While in the examination period, this feedback\nfeature was turned off. During the training phase, our digital patient\nsimulation deliberately presents scenarios reﬂecting realistic emotional\nresponses (e.g., a patient experiencing an acute angle-closure glaucoma\nattack feeling anxious). The system assesses students’ responses, scores their\nempathetic communication skills, andprovides targetedfeedback (Sup-\nplementary Note 4). Users can access the LLMDP system via smartphones,\ntablets, or computer browsers. The user guide for the LLMDP system can be\nfound in Supplementary Note 5.\nSystem validation\nAt the end of development of the LLMDPsystem, we conducted two initial\nexperiments to preliminarily validateits effectiveness in medical history-\ntaking training and assess the correlation of its automated scoring function\nwith manual scoring.\nValidation experiment 1: Effectiveness in medical history taking\ntraining\nThis experiment involved 50 fourth-year medical students from the\nZhongshan School of Medicine, Sun Yat-sen University. The goal was to\nexplore the potential of the LLMDP system to enhance medical history\ntaking skills compared to traditional methods. Participants were divided\ninto traditional real patient based training group and LLMDP-based\ntraining group (Fig.4a). Traditional real patient based training refers to the\nconventional teaching method where students, in groups ofﬁve, engage in\nmedical history taking practice under the guidance of a physician instructor,\nwhile interacting with actual patients in a clinical environment. Under\ntraditional training, participants weretrained with three real patients for 1 h,\nwith 10 min of training and 10 min of explanation for each case. In contrast,\n“LLMDP-based training” refers to each student independently utilizing the\nLLMDP system for individual practice. Under the LLMDP system, three\ncases were provided, and the training duration was 1 h. During the exam-\nination, all participants conducted medical history-taking assessments with\nSPs. Their performance was evaluatedby attending doctors following the\nOSCE criteria and was compared between two groups witht test.\nValidation experiment 2: Correlation of automated scoring with\nmanual scoring\nThis experiment involved a different cohort of 50 fourth-year students who\nwere undergoing traditional clinical internships at the same institution. The\ngoal was to assess the correlation of the LLMDP system’s automated scoring\ncompared to manual scoring by attending doctors. Participants were con-\nsecutively evaluated twice using both assessment methods:ﬁrst by real\npatient assessment (manual scoring), followed immediately by an assess-\nment using the LLMDP system (LLMDP system scoring), without receiving\nany feedback between the two assessments (Fig.5a). To minimize recall bias\nand ensure a fair comparison, different cases were used for the real patient\nand LLMDP assessments. In the real patient assessment, students conducted\nmedical history taking assessment with actual patients in a clinical envir-\nonment, and their performance was evaluated by attending doctors fol-\nlowing the OSCE criteria. Pearson’s correlation coefﬁcient and scatter plot\nwere used to determine the correlation between the scores obtained from the\nLLMDP system and those from real patient encounters.\nDesign and procedures of the randomized controlled trial\nThe predeﬁned protocol of this trial was approved by the Institutional\nReview Board/Ethics Committee of Zhongshan Ophthalmic Center (iden-\ntiﬁer: 2023KYPJ283) and was prospectively registered at ClinicalTrials.gov\n(Registration Number: NCT06229379). The inclusion criterion for this\ns t u d yw a sf o u r t h - y e a rs t u d e n t sm a j o r i n gi nc l i n i c a lm e d i c i n ea tt h e\nZhongshan School of Medicine, Sun Yat-sen University. Having recently\ncompleted their theoretical courses and exams in ophthalmology, these\nstudents were about to embark on the clinical rotation stage. Prior to this\nphase, they had not received any clinical training. After online and ofﬂine\nenrollment, a total of 84 students ultimately participated in this study and\nsigned informed consent forms.\nIn the trial from Nov. 14 to Dec. 7, 2023, 84 participants were\ndivided into two groups, with 42 individuals assigned to the control\ngroup who underwent traditional real patient based training and another\n42 participants assigned to the LLMDP group where they underwent\nLLMDP-based training (Fig.6a). Traditional real patient based training\nrefers to the conventional teaching method where students, in groups of\nﬁve, engage in medical history taking practice under the guidance of a\nphysician instructor, while interacting with actual patients in a clinical\nenvironment. Following standard clinical teaching practices, participants\nhttps://doi.org/10.1038/s41746-025-01841-6 Article\nnpj Digital Medicine|           (2025) 8:502 9\nin the traditional training group engaged with three real patients over the\ncourse of 1 h, with each case allocated 10 min for history taking training\nand 10 min for instructor feedback. The LLMDP system mirrored this\nstructure, providing three cases within the same training duration as the\ncontrol group. Additionally, before taking exams with the LLMDP sys-\ntem, each student was provided with a 10-min orientation to ensure their\nfamiliarity with the LLMDP exam system.\nOutcome measures\nThe primary outcome was the participants’ MHTA scores. The scores for\nMHTA were automatically calculatedby the system based on the dialogs,\naccording to predetermined scoring criteria (Supplementary Table 5).\nAdditionally, we analyzed the impact of LLMDP training on speciﬁch i s t o r y\ntaking components by deconstructing MHTA into key subitems, including\nidentiﬁcation and demographic information, history of present illness, past\nmedical history, and other medical history.\nThe secondary outcome is to investigate the attitudes toward the\napplication of LLMs in medical education, as well as the differences in\nempathy toward patients between the two groups. All participants com-\npleted a standardized quantitative questionnaire based on the widely used\nﬁve-point Likert scale about their attitudes toward the application of LLMs\nin medical education after using the LLMDP system after the trial (Sup-\nplementary Note 6). Additionally, at the end of the trial, all 84 students and\ntheir 8 supervising teachers were asked to independently discuss questions\nabout the use of LLMDP in medical education. The results of the students’\ndiscussion were recorded, transcribed and coded by three different authors\n(MJL, SWB, LXL). A panel of 9 experts participated in the discussion to\nprovide further insights. Following discussions in regular meetings, a cate-\ngory system consisting of main and subcategories (according to Mayring’s\nqualitative content analysis) was agreed upon\n71. Text passages shown in\nSupplementary Table 2 were used as quotations to illustrate each category.\nInductive category formation was performed to reduce the content of the\nmaterial to its essentials (bottom-up process). In theﬁrst step, the goal of the\nanalysis and the theoretical background were determined. From this,\nquestions about LLMDP in medical education were developed and pre-\nsented to the students for discussion. Two main topics were identiﬁed,\nnamely positive and negative attitudes toward LLMDP in medical educa-\ntion. In the second step, we worked through the individual statements of the\nstudents systematically and derived various categories: accessibility, inter-\naction, and effectiveness. To avoid disrupting the MHTA process, we\nrecorded the entire session in the system’s backend, and after the assess-\nment, an expert panel used the recordings to assess students’ empathy\nperformance, according to the scoring criteria shown in Supplementary\nFig. 1a.\nRandomization and blinding\nThe participants were randomly assigned in a 1:1 ratio to either the tradi-\ntional teaching group or the LLMDP teaching group. Stratiﬁed block ran-\ndomization was utilized, with theoretical ophthalmology exam scores\nserving as the stratiﬁcation factor. The randomization process was carried\nout by a central randomization system.\nThe collection, entry, and monitoring of primary and secondary out-\ncome data were performed by staff who were blinded to group assignment.\nParticipants were not blinded due to the nature of the interventions. Sta-\ntistical analyses were performed by an independent statistician blinded to\ngroup allocation.\nStatistical analysis\nThe trial sample size calculationw a sb a s e do nt h ep r i m a r yo u t c o m e\n(MHTA). In the pilot study, the control group (n = 10) had a mean score of\n54.59 ± 7.33, while the experimental group (n = 10) had a mean score of\n62.05 ± 9.13. Based on theseﬁndings, we assumed a seven-point improve-\nment and an SD of 9.5, where the effect size was estimatedto be 0.74, yielding\na sample size of 40 participants per group, 80 in total. The pilot data were not\nincluded in theﬁnal analysis. Ultimately, 84 participants were enrolled in the\nformal trial to account for potential ex c l u s i o n s .T h es a m p l es i z ew a sc a l -\nculated using PASS 16 software (NCSS, LLC, USA).\nThe intention to treat population is same with the population of per\nprotocol in this trial since no students discontinued or withdrew after\nrecruitment. Descriptive statistics, including the means and SDs for con-\ntinuous variables, and frequencies and percentages for categorical variables,\nwere employed to present the data. Thebaseline characteristics of the par-\nticipants in the treatment groups were compared usingt tests for continuous\nvariables and χ2 tests for categorical variables. Continuous data were\nexamined for normality using Shapiro–Wilk test. Independent t tests were\nconducted to assess differences in MHTA scores between study groups. To\naddress multiplicity issues, allp values and conﬁdence intervals for the\nsubitem scores of the MHTA were corrected using the Benjamini‒Hochberg\nprocedure to control the false discovery rate (FDR) at 0.05\n72.\nAll the statistical analyses were conducted using SPSS statistical soft-\nware for Windows (version 24.0, IBM Corporation, Armonk, New York,\nUSA), GraphPad Prism (version 9, GraphPad Software, San Diego, USA),\nand R (version 4.3.1, R Foundation for Statistical Computing, Vienna,\nAustria).\nData availability\nResearchers who meet the criteria for access can obtain these data through\nthe State Key Laboratory of Ophthalmology at the Zhongshan Ophthalmic\nCenter, Sun Yat-sen University. Researchers who wish to obtain access to\nthe unrestricted data can send theirdata requests to the corresponding\nauthor.\nCode availability\nThe code for the LLMDP system is available on GitHub (https://github.\ncom/pangjianyu-sunivers/LLMDP).\nReceived: 9 December 2024; Accepted: 24 June 2025;\nReferences\n1. Kolb, D. A. Experience as the Source of Learning and Development\n(Prentice Hall, 1984).\n2. Kolb, D. A. Experiential Learning: Experience as the Source of\nLearning and Development(FT Press, 2014).\n3. Fallow ﬁeld, L. et al. Efﬁcacy of a Cancer Research UK communication\nskills training model for oncologists: a randomised controlled trial.\nLancet 359, 650–656 (2002).\n4. Curtis, J. R. et al. Effect of communication skills training for residents\nand nurse practitioners on quality of communication with patients with\nserious illness: a randomized trial.Jama 310, 2271–2281 (2013).\n5. McLean, S. F. Case-based learning and its application in medical and\nhealth-care ﬁelds: a review of worldwide literature.J. Med Educ.\nCurric. Dev.3, JMECD.S20377 (2016).\n6. AlHaqwi, A. I. & Taha, W. S. Promoting excellence in teaching and\nlearning in clinical education.J. Taibah Univ. Med. Sci.10,9 7–101\n(2015).\n7. Irby, D. M., Cooke, M. & O’Brien, B. C. Calls for reform of medical\neducation by the Carnegie Foundation for the Advancement of\nTeaching: 1910 and 2010.Acad. Med.85, 220–227 (2010).\n8. Cooke, M., Irby, D. M., Sullivan, W. & Ludmerer, K. M. American\nmedical education 100 years after the Flexner report.N. Engl. J. Med.\n355, 1339–1344 (2006).\n9. Stillman, P. L. & Sawyer, W. D. A new program to enhance the teaching\nand assessment of clinical skills in the People’s Republic of China.\nAcad. Med.67, 495–499 (1992).\n10. Brender, E., Burke, A. & Glass, R. M. Standardized patients.JAMA\n294, 1172–1172 (2005).\n11. Wilbur, K., Elmubark, A. & Shabana, S. Systematic review of\nstandardized patient use in continuing medical education.J. Contin.\nEduc. Health Prof.38,3 –10 (2018).\nhttps://doi.org/10.1038/s41746-025-01841-6 Article\nnpj Digital Medicine|           (2025) 8:502 10\n12. Keiser, M. M. & Turkelson, C. Using students as standardized\npatients: development, implementation, and evaluation of a\nstandardized patient training program.Clin. Simul. Nurs.13, 321–330\n(2017).\n13. Calvert, M. J. & Freemantle, N. Cost-effective undergraduate medical\neducation? J. R. Soc. Med102,4 6–48 (2009).\n14. Kneebone, R. et al. The human face of simulation: patient-focused\nsimulation training.Acad. Med81, 919–924 (2006).\n15. Bruno, R. R. et al. Virtual and augmented reality in critical care\nmedicine: the patient’s, clinician’s, and researcher’s perspective.Crit.\nCare 26, 326 (2022).\n16. Liu, Z. et al. Simulation-based training in asthma exacerbation for\nmedical students: effect of prior exposure to simulation training on\nperformance. BMC Med Educ.22, 223 (2022).\n17. Cook, D. A. & Triola, M. M. Virtual patients: a critical literature review\nand proposed next steps.Med. Educ.43, 303–311 (2009).\n18. Cook, D. A., Erwin, P. J. & Triola, M. M. Computerized virtual patients\nin health professions education: a systematic review and meta-\nanalysis. Acad. Med.85, 1589–1602 (2010).\n19. Berman, N. B., Durning, S. J., Fischer, M. R., Huwendiek, S. & Triola,\nM. M. The role for virtual patients in the future of medical education.\nAcad. Med91, 1217–1222 (2016).\n20. McGaghie, W. C., Siddall, V. J., Mazmanian, P. E. & Myers, J. Lessons\nfor continuing medical education from simulation research in\nundergraduate and graduate medical education: effectiveness of\ncontinuing medical education: American College of Chest Physicians\nEvidence-Based Educational Guidelines.Chest 135, 62s–68s (2009).\n21. Iversen, E. D. et al. Codebook for rating clinical communication skills\nbased on the Calgary-Cambridge Guide.BMC Med. Educ.20,1 –9\n(2020).\n22. Thirunavukarasu, A. J. et al. Large language models in medicine.Nat.\nMed 29, 1930–1940 (2023).\n23. Egli, A. ChatGPT, GPT-4, and other large language models: the next\nrevolution for clinical microbiology?Clin. Infect. Dis.77, 1322–1328\n(2023).\n24. Decker, H. et al. Large language model-based chatbot vs surgeon-\ngenerated informed consent documentation for common procedures.\nJAMA Netw. Open6, e2336997 (2023).\n25. Antaki, F. et al. Capabilities of GPT-4 in ophthalmology: an analysis of\nmodel entropy and progress towards human-level medical question\nanswering. Br. J. Ophthalmol.108, 1371–\n1378 (2024).\n26. Gilson, A. et al. How does ChatGPT perform on the United States\nMedical Licensing Examination (USMLE)? The implications of large\nlanguage models for medical education and knowledge assessment.\nJMIR Med. Educ.9, e45312 (2023).\n27. Masalkhi, M. et al. A side-by-side evaluation of Llama 2 by Meta with\nChatGPT and its application in ophthalmology.Eye (Lond.)38,\n1789–1792 (2024).\n28. Luo, M. J. et al. Development and evaluation of a retrieval-augmented\nlarge language model framework for ophthalmology.JAMA\nOphthalmol. 142, 798–805 (2024).\n29. Waisberg, E., Ong, J., Masalkhi, M. & Lee, A. G. Large language model\n(LLM)-driven chatbots for neuro-ophthalmic medical education.Eye\n(Lond.) 38, 639–641 (2024).\n30. Kianian, R., Sun, D., Crowell, E. L. & Tsui, E. The use of large language\nmodels to generate education materials about uveitis.Ophthalmol.\nRetin. 8, 195–201 (2024).\n31. Gray, M. et al. Increasing realism and variety of virtual patient\ndialogues for prenatal counseling education through a novel\napplication of ChatGPT: exploratory observational study.JMIR Med\nEduc. 10, e50705 (2024).\n32. Cook, D. A. Creating virtual patients using large language models:\nscalable, global, and low cost.Med Teach.47,4 0–42 (2025).\n33. Cook, D. A., Overgaard, J., Pankratz, V. S., Del Fiol, G. & Aakre, C. A.\nVirtual patients using large language models: scalable, contextualized\nsimulation of clinician-patient dialog with feedback.J. Med. Internet\nRes. 27, e68486 (2025).\n34. McKell, D. et al. Creating a culture of teaching and learning.Med Sci.\nEduc. 34, 961–966 (2024).\n35. Singhal, K. et al. Large language models encode clinical knowledge.\nNature 620, 172–180 (2023).\n36. Savage, T., Nayak, A., Gallo, R., Rangan, E. & Chen, J. H. Diagnostic\nreasoning prompts reveal the potential for large language model\ninterpretability in medicine.NPJ Digit Med7, 20 (2024).\n37. Benary, M. et al. Leveraging large language models for decision\nsupport in personalized oncology.JAMA Netw. Open6, e2343689\n(2023).\n38. Stanceski, K. et al. The quality and safety of using generative AI to\nproduce patient-centred discharge instructions.NPJ Digit Med.7,\n329 (2024).\n39. Burton, M. J. et al. The lancet global health commission on global eye\nhealth: vision beyond 2020.Lancet Glob. Health9, e489–e551 (2021).\n40. Betzler, B. K. et al. Large language models and their impact in\nophthalmology. Lancet Digit Health5, e917–e924 (2023).\n41. Potter, L. & Jefferies, C. Enhancing communication and clinical\nreasoning in medical education: Building virtual patients with\ngenerative AI.Future Healthc. J.11, 100043 (2024).\n42. Yao, H. et al. Enhancing empathic communication in healthcare\neducation through virtual conversations: leveraging large language\nmodels for real-time feedback. inProc. 26th Symposium on Virtual\nand Augmented Reality41–50 (2024).\n43. Benítez, T. M. et al. Harnessing the potential of large language models\nin medical education: promise and pitfalls.J. Am. Med Inf. Assoc.31,\n776–783 (2024).\n44. Mannstadt, I. & Mehta, B. Large language models and the future of\nrheumatology: assessing impact and emerging opportunities.Curr.\nOpin. Rheumatol.36,4 6–51 (2024).\n45. Abd-Alrazaq, A. et al. Large language models in medical education:\nopportunities, challenges, and future directions.JMIR Med Educ.9,\ne48291 (2023).\n46. Divito, C. B., Katchikian, B. M., Gruenwald, J. E. & Burgoon, J. M. The\ntools of the future are the challenges of today: The use of ChatGPT in\nproblem-based learning medical education.Med. Teach.46, 320–322\n(2024).\n47. Katsoulakis, E. et al. Digital twins for health: a scoping review.NPJ\nDigit Med7, 77 (2024).\n48. Safranek, C. W., Sidamon-Eristoff, A. E., Gilson, A. & Chartash, D. The\nrole of large language models in medical education: applications and\nimplications. JMIR Med Educ.9, e50945 (2023).\n49. Holderried, F. et al. A language model–powered simulated patient with\nautomated feedback for history taking: prospective study.JMIR Med.\nEduc. 10, e59213 (2024).\n50. Borg, A. et al. Virtual patient simulations using social robotics\ncombined with large language models for clinical reasoning training in\nmedical education: mixed methods study.J. Med. Internet Res.27,\ne63312 (2025).\n51. Holderried, F. et al. A generative pretrained transformer\n(GPT)–powered chatbot as a simulated patient to practice history\ntaking: prospective, mixed methods study.JMIR Med. Educ.10,\ne53961 (2024).\n52. Lee, P., Bubeck, S. & Petro, J. Beneﬁts, limits, and risks of GPT-4 as an\nAI chatbot for medicine.N. Engl. J. Med388, 1233–1239 (2023).\n53. Foster, A. et al. Using virtual patients to teach empathy: a randomized\ncontrolled study to enhance medical students’ empathic\ncommunication. Simul. Healthc.11, 181–189 (2016).\n54. Kleinsmith, A., Rivera-Gutierrez, D., Finney, G., Cendan, J. & Lok, B.\nUnderstanding empathy training with virtual patients.Comput Hum.\nBehav. 52\n, 151–158 (2015).\n55. Hazin, R., Lum, F. & Daoud, Y. J. Ophthalmic features of systemic\ndiseases. Ann. Med44, 242–252 (2012).\nhttps://doi.org/10.1038/s41746-025-01841-6 Article\nnpj Digital Medicine|           (2025) 8:502 11\n56. Jin, Q. et al. Hiddenﬂaws behind expert-level accuracy of multimodal\nGPT-4 vision in medicine.NPJ Digit Med.7, 190 (2024).\n57. Xu, P., Chen, X., Zhao, Z. & Shi, D. Unveiling the clinical incapabilities:\na benchmarking study of GPT-4V(ision) for ophthalmic multimodal\nimage analysis.Br. J. Ophthalmol.108, 1384–1389 (2024).\n58. Wan, P. et al. Outpatient reception via collaboration between nurses\nand a large language model: a randomized controlled trial.Nat. Med.\n30, 2878–2885 (2024).\n59. Van Veen, D. et al. Adapted large language models can outperform\nmedical experts in clinical text summarization.Nat. Med.30,\n1134–1142 (2024).\n60. Laubenbacher, R., Mehrad, B., Shmulevich, I. & Trayanova, N. Digital\ntwins in medicine.Nat. Comput Sci.4, 184–191 (2024).\n61. Zheng, L. et al. Judging llm-as-a-judge with mt-bench and\nchatbot arena. Adv. Neural Inform. Process. Syst.36,\n46595 –46623 (2023).\n62. Hu, E. J. et al. Lora: Low-rank adaptation of large language models.\nICLR 1, 3 (2022).\n63. Li, C. et al. Deepspeed data efﬁciency: Improving deep learning model\nquality and training efﬁciency via efﬁcient data sampling and routing.\nProc. AAAI Conf. Artif. Intell.38, 18490–18498 (2024).\n64. O ’Brien, B. C., Harris, I. B., Beckman, T. J., Reed, D. A. & Cook, D. A.\nStandards for reporting qualitative research: a synthesis of\nrecommendations. Acad. Med89, 1245–1251 (2014).\n65. Yu, D. & Deng, L.Automatic Speech Recognition(Springer, 2016).\n66. Reimers, N. & Gurevych, I. Sentence-BERT: sentence embeddings\nusing siamese BERT-networks. inConference on Empirical Methods\nin Natural Language Processing(2019).\n67. Kim, J., Kong, J. & Son, J. Conditional variational autoencoder with\nadversarial learning for end-to-end text-to-speech. inInternational\nConference on Machine Learning5530-–5540 (PMLR, 2021).\n68. Khan, K. Z., Ramachandran, S., Gaunt, K. & Pushkar, P. The objective\nstructured clinical examination (OSCE): AMEE guide no. 81. Part I: a\nhistorical and theoretical perspective.Med. Teach.35, e1437–e1446\n(2013).\n69. Morrison, J. ABC of learning and teaching in medicine: evaluation.\nBMJ 326, 385–387 (2003).\n70. National Medical Examination Center.\nNational Medical Examination\nWebsite https://www1.nmec.org.cn/ (2023).\n71. Mayring, P. & Fenzl, T.Qualitative Inhaltsanalyse(Springer, 2019).\n72. Benjamini, Y. & Hochberg, Y. Controlling the false discovery rate: a\npractical and powerful approach to multiple testing.J. R. Stat. Soc. B\n(Methodol.) 57, 289–300 (1995).\nAcknowledgements\nThe authors would like to acknowledgeﬁnancial support from the Major\nProgram of the National Natural Science Foundation of China (Grant No.\n92368205), the National Natural Science Foundation of China (Grant No.\n82371111), and the Natural Science Foundation of Guangdong Province\n(Grant No. 2024A1515012292), the Science and Technology Planning\nProjects of Guangdong Province (Grant No. 2018B010109008).\nAuthor contributions\nConceptualization: H.T.L., M.J.L., S.W.B., J.Y.P., Y.X.L., L.X.L., C.K.T., L.J.\nand Y.X.Z.; methodology: H.T.L., M.J.L., S.W.B., L.X.L., C.K.T. and Y.X.L.;\nsoftware design and engineering: M.J.L., J.Y.P. and S.W.B.; resources:\nH.T.L., Y.F.Y., Y.Q.L. and Y.X.Z.; data collection and curation: M.J.L.,\nS.W.B., J.Y.P., L.X.L., C.K.T., K.Z.X., Y.X.L., W.B.C., Y.H.Y. and R.X.C.;\nwriting original draft: M.J.L., S.W.B., J.Y.P. and L.X.L.; writing-review &\nediting: H.T.L., M.J.L., S.W.B., J.Y.P., L.X.L., L.Q.Z., C.K.T., Y.X.L., W.B.C.,\nY.H.Y., K.Z.X., L.J., D.R.L., X.H.W., J.J.C., R.X.C., Z.Z.L., Y.X.Z., Y.F.Y. and\nY.Q.L.; funding acquisition: H.T.L., D.R.L., X.H.W. and M.J.L.; supervision:\nH.T.L., M.J.L., S.W.B., J.Y.P. and L.X.L. contributed equally to this work.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s41746-025-01841-6\n.\nCorrespondenceand requests for materials should be addressed to\nHaotian Lin.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to\njurisdictional claims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution-NonCommercial-NoDerivatives 4.0 International License,\nwhich permits any non-commercial use, sharing, distribution and\nreproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative\nCommons licence, and indicate if you modiﬁed the licensed material. You\ndo not have permission under this licence to share adapted material\nderived from this article or parts of it. The images or other third party\nmaterial in this article are included in the article’s Creative Commons\nlicence, unless indicated otherwise in a credit line to the material. If material\nis not included in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted use,\nyou will need to obtain permission directly from the copyright holder. To\nview a copy of this licence, visithttp://creativecommons.org/licenses/by-\nnc-nd/4.0/\n.\n© The Author(s) 2025\nhttps://doi.org/10.1038/s41746-025-01841-6 Article\nnpj Digital Medicine|           (2025) 8:502 12",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.4252289831638336
    },
    {
      "name": "Psychology",
      "score": 0.33512789011001587
    },
    {
      "name": "Ophthalmology",
      "score": 0.334745317697525
    },
    {
      "name": "Medicine",
      "score": 0.28861868381500244
    }
  ]
}