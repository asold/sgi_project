{
    "title": "Stabilized In-Context Learning with Pre-trained Language Models for Few Shot Dialogue State Tracking",
    "url": "https://openalex.org/W4386566453",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A5101989589",
            "name": "Derek Chen",
            "affiliations": [
                "Columbia University",
                "The Dialogue"
            ]
        },
        {
            "id": "https://openalex.org/A5100728328",
            "name": "Kun Qian",
            "affiliations": [
                "Columbia University",
                "The Dialogue"
            ]
        },
        {
            "id": "https://openalex.org/A5016175345",
            "name": "Yu Zhou",
            "affiliations": [
                "Columbia University",
                "The Dialogue"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4294646197",
        "https://openalex.org/W4205991051",
        "https://openalex.org/W2997771882",
        "https://openalex.org/W2998572029",
        "https://openalex.org/W2964006684",
        "https://openalex.org/W3186138538",
        "https://openalex.org/W2963491014",
        "https://openalex.org/W3045703328",
        "https://openalex.org/W3184589118",
        "https://openalex.org/W2251058040",
        "https://openalex.org/W3160847843",
        "https://openalex.org/W3156697766",
        "https://openalex.org/W4286981949",
        "https://openalex.org/W4221159409",
        "https://openalex.org/W3153427360",
        "https://openalex.org/W4281262985",
        "https://openalex.org/W3174770825",
        "https://openalex.org/W3156636935",
        "https://openalex.org/W4320086632",
        "https://openalex.org/W2138621090",
        "https://openalex.org/W3206345746",
        "https://openalex.org/W3172407229",
        "https://openalex.org/W3152546689",
        "https://openalex.org/W4287795696",
        "https://openalex.org/W2945475330",
        "https://openalex.org/W2954492830",
        "https://openalex.org/W4297801719",
        "https://openalex.org/W3045979540",
        "https://openalex.org/W4293569541",
        "https://openalex.org/W3034284249",
        "https://openalex.org/W3200895474",
        "https://openalex.org/W3173777717",
        "https://openalex.org/W3035194816",
        "https://openalex.org/W2784070054",
        "https://openalex.org/W3005680577",
        "https://openalex.org/W3133702157",
        "https://openalex.org/W3205058818",
        "https://openalex.org/W2794363191",
        "https://openalex.org/W2601450892",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W4281490030",
        "https://openalex.org/W2604763608",
        "https://openalex.org/W3034573951",
        "https://openalex.org/W4226451629",
        "https://openalex.org/W3197770791",
        "https://openalex.org/W2970641574",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W3198599617",
        "https://openalex.org/W3099700870",
        "https://openalex.org/W3212511129",
        "https://openalex.org/W2963809228"
    ],
    "abstract": "Prompt-based methods with large pre-trained language models (PLMs) have shown impressive unaided performance across many NLP tasks. These models improve even further with the addition of a few labeled in-context exemplars to guide output generation. However, for more complex tasks such as dialogue state tracking (DST), designing prompts that reliably convey the desired intent is nontrivial, leading to unstable results. Furthermore, building in-context exemplars for dialogue tasks is difficult because conversational contexts are long while model input lengths are relatively short.To overcome these issues we first adapt a meta-learning scheme to the dialogue domain which stabilizes the ability of the model to perform well under various prompts. We additionally design a novel training method to improve upon vanilla retrieval mechanisms to find ideal in-context examples. Finally, we introduce a saliency model to limit dialogue text length, allowing us to include more exemplars per query. In effect, we are able to achieve highly competitive results for few-shot DST on MultiWOZ.",
    "full_text": "Findings of the Association for Computational Linguistics: EACL 2023, pages 1551–1564\nMay 2-6, 2023 ©2023 Association for Computational Linguistics\nStabilized In-Context Learning with Pre-trained\nLanguage Models for Few Shot Dialogue State Tracking\nDerek Chen, Kun Qian, Zhou Yu\nDialogue NLP Lab\nColumbia University\n{dc3761, kq2157, zy2461}@columbia.edu\nAbstract\nPrompt-based methods with large pre-trained\nlanguage models (PLMs) have shown impres-\nsive unaided performance across many NLP\ntasks. These models improve even further with\nthe addition of a few labeled in-context ex-\nemplars to guide output generation. However,\nfor more complex tasks such as dialogue state\ntracking (DST), designing prompts that reliably\nconvey the desired intent is nontrivial, leading\nto unstable results. Furthermore, building in-\ncontext exemplars for dialogue tasks is difficult\nbecause conversational contexts are long while\nmodel input lengths are relatively short.\nTo overcome these issues we first adapt a meta-\nlearning scheme to the dialogue domain which\nstabilizes the ability of the model to perform\nwell under various prompts. We additionally\ndesign a novel training method to improve\nupon vanilla retrieval mechanisms to find ideal\nin-context examples. Finally, we introduce a\nsaliency model to limit dialogue text length, al-\nlowing us to include more exemplars per query.\nIn effect, we are able to achieve highly compet-\nitive results for few-shot DST on MultiWOZ.\n1 Introduction\nTremendous gains have been made on dialogue\nstate tracking (DST) using large pre-trained lan-\nguage models (PLMs) (Hosseini-Asl et al., 2020;\nPeng et al., 2021), Fine-tuning such systems though\nrequire significant amounts of data, which in turn\nrequire substantial effort to collect. Recently,\nprompting has emerged as a technique for achiev-\ning strong performance in a less resource inten-\nsive manner (Schick and Schütze, 2021; Liu et al.,\n2021). Even better performance is possible with\nin-context exemplars providing a pattern for the\nmodel to follow (Brown et al., 2020). Ideally, we\nshould be able to apply these concepts to complex\ntasks like DST, but results so far have been lim-\nited (Madotto et al., 2021).\nExemplars PromptQuery\nExemplar Context:\nI would like a train \nto Cambridge \narriving at 14:00\nExemplar Prompt:\nTrain destination is\nExemplar Target:\ncambridge\nNaive:\nArea of the restaurant\nQuestion:\nWhere is the desired \nrestaurant location?\nStatement:\nThe preferred \nrestaurant area is\nPrevious Context:\n<customer> Can you help me \nfind somewhere to eat?\n<agent> Sure, what type of \nfood would you prefer?\n<customer> Korean food \nsounds pretty good right now.\nCurrent Turn:\n<agent> We have many places \nthat fit that criteria.  Do you \nhave a specific area in mind? \n<customer> In the north.\nDialogue Query\nPossible Prompts\nT5\nTarget Value:\nin the north\n> Calculate Loss\nPredicted Value: north \nMeta-Training Inference\nNo Gradient Update!\nExemplar Context:\nI would like a train \nto Cambridge \narriving at 14:00\nExemplar Prompt:\nTrain destination is\nExemplar Target:\ncambridge\nExemplar Context:\nI would like a train \nto Cambridge \narriving at 14:00.\nExemplar Prompt:\nTrain destination is\nExemplar Target:\ncambridge\nIn-Context Exemplars\nFigure 1: Our system squeezes multiple in-context ex-\nemplars, dialogue query with conversational context,\nand a full prompt into the finite input length of a large\nPLM to successfully perform few-shot dialogue state\ntracking, without any need for task-specific training.\nOne reason for the lack of progress comes from\nthe difficulty of hand-crafting prompts (patterns)\nand targets (verbalizers), which are highly sensi-\ntive to exact phrasing (Lester et al., 2021a). While\nmanually designed prompts have been found to\nbe brittle and unstable (Gu et al., 2021), automat-\nically designed prompts (Gao et al., 2021a) can-\nnot be easily applied to DST since many slots are\nnon-enumerable (Rastogi et al., 2020). A second\nmajor hurdle is around dialogue sequence lengths,\nwhich are often much longer than those for other\ntasks (Quan and Xiong, 2020; Kottur et al., 2021)\npreventing the inclusion of many exemplars for\nguidance. Full conversations consist of long histo-\nries going back many turns, such that the context\nitself (sans prompt) is already capable of filling\n1551\na model’s entire input length. Since state track-\ning requires carrying over previous dialogue states,\nnaively truncating prior context effectively equates\nto random guessing (Heck et al., 2020; Kim et al.,\n2020). A third issue is selecting the exemplars\nthemselves. Prior work recommends choosing a\nrepresentative example from each class (Gao et al.,\n2021a), but this is not possible in many cases since\nmost domain-slot-value label combinations simply\ndo not appear in the dataset. Moving to the few-\nshot scenario further exacerbates this sparsity.\nSeparately, recall that our main goal is to do\nwell in few-shot DST because we purposefully\noperate in a practical, low-resource data setting.\nCorrespondingly, we aim to achieve good results\nwith a similar low-resource model setting where\ntraining should be possible on a single publicly-\navailable commodity server. This precludes the\nusage of gigantic models such as GPT-3, which\nare prohibitively expensive to train and bear high\neconomic and environmental costs for inference\nalone (Strubell et al., 2019; Bender et al., 2021).\nWe directly tackle each of the three aforemen-\ntioned issues to achieve state-of-the-art perfor-\nmance on MultiWOZ when restricted to models\nunder 100 billion parameters. To minimize prompt\nissues, we introduce a meta in-context learning\n(ICL) framework to stabilize training and reduce\nvariance in prompt performance. To deal with long\ndialogues, we are inspired by summarizaton work\nto condense dialogue histories and filter out non-\nsalient sentences. Our third contribution is design-\ning a novel loss function to train a retrieval model\nthat selects ideal exemplars for priming our down-\nstream model. Our analysis and ablations show\nthat all components help improve our state tracking\nperformance. Finally, we show that unlike other\nmodels which only work on specialized LMs, our\nproposed methods work on any sort of LM, and\ncan be improved with additional training.\n2 Related Works\n2.1 Few-Shot Dialog State Tracking\nNearly all recent works on dialogue state tracking\nleverage large pre-trained LMs to achieve good\nperformance (Heck et al., 2020; Kim et al., 2020;\nPeng et al., 2021). These methods require fine-\ntuning on large amounts of annotated data, whereas\nwe hope to do well with minimal data.\nFew-shot learning can be achieved in many ways,\nwith transfer learning probably being the most pop-\nular, where knowledge is transferred from one do-\nmain to another (Wu et al., 2019; Campagna et al.,\n2020). Data augmentation also supports few-shot\nlearning by generating additional training exam-\nples from the few-shot data (Yin et al., 2020; Sum-\nmerville et al., 2020; Mi et al., 2021). Clustering\ntechniques like prototypical networks have also\nshown prior success (Snell et al., 2017).\n2.2 Meta In-context Learning with Prompting\nThis work leans on the few-shot techniques of\nmeta-learning (Finn et al., 2017) and prompting\nwith large PLMs (Madotto et al., 2021). Meta-\nlearning allows you to get away with only a few\nexamples at test time by pre-training a model to\nlearn how to learn (Nichol et al., 2018). More re-\ncent methods which circumvent the need to calcu-\nlate second-order gradients (Nichol and Schulman,\n2018) have been successfully applied to the task\nof DST (Dingliwal et al., 2021), but still require\nfine-tuning on the query set.\nUsing prompts as natural language instructions\nhave been found to work well on a wide vari-\nety of NLP tasks, including dialogue state track-\ning (Yang et al., 2022). Prompts can be brittle\nthough, so prompt engineering has become its own\ncomplex task with numerous ideas on finding dis-\ncrete prompts (Gao et al., 2021a) or tuning soft\nprompts, such as through adapters (Xu et al., 2022),\nprefix tuning (Li and Liang, 2021), or prompt tun-\ning (Lester et al., 2021b). Others have even altered\nthe prompt structure into code in order to fit the ca-\npabilities of the network (Lee et al., 2021). Inspired\nby the success of meta in-context learning on clas-\nsification tasks (Min et al., 2021; Chen et al., 2022),\nour work aims to side-step the prompt design issue\naltogether. Concretely, our method applies meta-\nlearning to teach a model to recognize arbitrary\ninstructions, thereby eliminating the need to rely\non domain expertise to craft an optimal prompt.\n2.3 Exemplar Retrieval\nLastly, our work is related to retrieval with dense\nvectors to find good exemplars for in-context learn-\ning (Liu et al., 2022). Using dense vectors for\nsimilarity search have been applied to dialogue in\nthe past, but mainly in the context of open-domain\nchat (Adolphs et al., 2021; Komeili et al., 2022) or\nknowledge-base retrieval (Eric et al., 2017). Lee\net al. (2021) is concurrent work which leverages\nembeddings to search for exemplars in dialogue.\n1552\n<customer> Ok, letʼs go with that.\n<agent> Just to confirm, the restaurant \nreservation is for 2 people on the south \nside?  What time do you prefer?\n<customer> Yes, thatʼs right.  I would like \na time of 19:30.  And can I get a reference \nnumber as well?\n<agent> No problem, I booked it for you.  \nThe reference number is 7B926AE.\n<customer> Great, thanks so much!\nexpensive\nIn-context Exemplars\nFew-shot \nCandidate Pool\nExemplar \nRetrieval\nDSTC\nSGD\nGSIM\nABCD\nMultiWOZ\n  Conversation 1\n  Conversation 2\n  Conversation 3\n  Conversation N\nQuery Set \nfor \nMeta-test\n    Support Sets \nfor \nMeta-train\nFine-tuned \nSentence \nEmbedder\ndepart at 3:30\ntime of 19:30\n4 seats please\n15:30 is good\nhe north korean food\nI want at least 3 stars\nchinese food\narrive by 8:30\n<customer> I need a  reservation for 18:30time of 19:30\n18:30<sep> time of the restaurant is\n8:00 is available 15:30 is good …\n…\nSaliency \nFiltering\n1\n2\n3\n4\ncheap\nsouth side\nFor 2 people\nFigure 2: Our method SM2 includes (1) meta-learning with various support sets, (2) saliency filtering to remove\nirrelevant utterances and (3) improved exemplar retrieval from a few-shot candidate pool. Exemplars are full\nutterances with dialogue context, which we display as short phrases for illustrative purposes only. They are\nconcatenated and fed into the model for prediction in Step 4. Items in green boxes, including the target value, are\nonly available during meta-training. Purple items are raw text, while yellow ones represent their embedding vectors.\n3 Our Method\nThis section describes our proposal of a Stabilized\ndialogue state tracker, which leverages Meta in-\ncontext learning, dialogue Summarization and a\nnovel Multi-part training loss for fine-tuning a re-\ntrieval model, which we refer to as SM2 for short.\n3.1 Preliminaries\nThe goal of dialogue state tracking (DST) is to ex-\ntract key information from the conversation as a\nmeans of understanding the customer’s intentions\nin each dialogue turn. More formally, given the\ndialogue history H = {C1,A1,C2,A2,...,C t}\ncomposed of a series of utterances between a cus-\ntomer Ci and an agent Ai, the model should predict\nthe cumulative dialogue state up to currentt-th turn.\nThis state is represented as a set of (domain, slot,\nvalue) tuples, which our system produces by iter-\nating over valid domain-slot pairs and then aggre-\ngating all non-null, predicted values for the given\nturn. A few-shot setup only allows access to K% of\nthe available labeled data, with k=[1,5,10] for our\nexperiments, where samples are randomly selected\nfrom the full labeled dataset. While we compare\nto models trained on k-shot data, our system actu-\nally goes a step further since our eventual model\nreceives no gradient signalfrom the task-specific\ndata and instead relies solely on in-context learning\nto perform inference.\n3.2 Stabilized Meta-learning\nThe intuition behind prompting is that large PLMs\nunderstand instructions when written in natural lan-\nguage (Brown et al., 2020). Thus, we write natural\nlanguage patterns in an attempt to elicit the dia-\nlogue state from the model. However, as previously\ndiscussed, minor tweaks in prompt text may cause\nextreme changes in generated output, leading to\nhighly unstable results (Gu et al., 2021).\nRecent works on Meta-ICL (Min et al., 2021;\nChen et al., 2022) have shown promise in stabi-\nlizing the variance of prompts such that crafting\nthe perfect prompt is no longer necessary, and in-\nstead, any reasonable natural language prompt will\nsuffice. Classic meta-learning leverages abundant\nlabeled data from support sets to adapt a model to\nquickly learn a limited-data target task, denoted as\nthe query set. Finn et al. (2017) proposes MAML\nthat simulates the inner adaptation step during meta-\ntraining by conducting a temporary one-step update\nbefore computing the loss. Afterwards, a costly\nsecond-order gradient is calculated in the outer\nloop to train the model for faster future adapta-\ntions. To get around the expensive loss calculation,\nvariants such as FOMAML have since been devel-\noped (Nichol et al., 2018; Nichol and Schulman,\n2018). Meta-ICL ingeniously avoids this calcula-\ntion by replacing the inner adaptation step with in-\ncontext learning, which does not require computing\ngradients! More specifically, in-context learning\nrefers to the use of exemplars to guide the model to-\nwards exhibiting ideal behavior. Critically, these ex-\nemplars are included as part of the standard model\ninput and thus do not require gradient updates to\nprovide a useful boost.\nFollowing the idea of Meta-ICL, we consider\neach dataset as a single task and treat MultiWOZ\nas the held out target task. Specifically, all support\ndatasets are transformed into the DST format for\n1553\nmeta-training, where the in-context inner loop con-\nsists of support set training examples. Although\nthe model does not learn about the query set in\nmeta-training, it is familiarizing itself with com-\nplex DST prompts during that time, allowing it\nto quickly adapt to the target task in meta-testing.\nFurthermore, since the prompt meaning is learned\nduring meta-training, theoretically any prompt can\nbe used to instruct the model, including prompts\nconstructed from random tokens (See Table 2).\n3.3 Dialogue Compression\nCondensing the dialogue context not only fits more\nexemplars into the model input sequence, but also\nhelps the model focus on more relevant text for\npredicting dialogue states. We introduce two gen-\neral ideas under the umbrella of compressing long\ndialogues into shorter input sequences.\nContext Summarization As the task name im-\nplies, DST requires tracking dialogue states over\nlong periods of time, including slot-values that\nwere carried over from the start of the conversation.\nIndeed, initial experiments validated a monotonic\ndecrease in joint goal accuracy as each marginal ut-\nterance was removed. Therefore, as an alternative\nto simply removing prior utterances, we propose\nsummarizing the dialogue history instead. The\nsummary of all prior turns is represented as the\npredicted dialogue state up to that point, which is\nrepresented as a series of (domain, slot, value) tu-\nples. We tried further limiting the input length by\nonly including state tuples directly related to the\ncurrent slot prediction, but surprisingly found that\nthis formulation of the summary fared worse.\nSaliency Filtering Many sentences within a con-\nversation do not contain valuable information, such\nas \"Thanks, that is all I need today.\" or \"Good bye\".\nIn order to filter away these lines, the first instinct\nis to train a large model, but our situation only has\naccess to a few labeled examples, so to keep things\nsimple, we instead gather a small handful of heuris-\ntics to identify non-salient utterances. For example,\nlines that discuss a \"reference number\" or are ex-\ncessively terse are targeted for removal. We verify\nthe performance of our heuristics on the limited\nfew-shot examples, where we heavily weight the\nmodel’s recall of salient utterances over its preci-\nsion. We take a very conservative approach since\naccidentally dropping a single relevant sentence\ncan cause a severe penalty in joint goal accuracy.\n3.4 Multi-part Retrieval Training\nExemplars are the only guiding signal when dealing\nwith in-context learning, so selecting quality cases\nis of utmost importance. To do so, we fine-tune the\nsentence embedder used during retrieval by taking\nadvantage of the limited, few-shot data available.\nExemplar Retrieval Exemplars are retrieved\nbased on their proximity to the query example.\nConcretely, we first encode all available exemplars\ninto a shared embedding space using a SBERT em-\nbedder (Reimers and Gurevych, 2019) where the\nraw text fed into the embedder is the exemplar’s\ndialogue history. For each incoming query, we en-\ncode the instance in the same manner, and then\ncompare their embeddings to rank the closest ex-\nemplars in the few-shot candidate pool (Step 3 in\nFigure 2). Finally, we keep pulling exemplars from\nthe top of the stack to feed into the model until the\nentire context length of 512 is at capacity. Since\nthe exemplar embeddings are pre-computed, look-\ning for similar exemplars during inference is a very\nquick operation.\nEmbedder Fine-tuning To improve the perfor-\nmance of our retrieval model, we explore two cate-\ngories of training techniques. Inspired by the rise\nof contrastive learning (Hadsell et al., 2006) as\na pre-training method for NLP tasks (Gao et al.,\n2021b; Karpukhin et al., 2020), we first study a\nCONTRASTIVE loss which brings positive exam-\nples closer together while pushing negative exam-\nples further apart. In our case, exemplars sharing\nthe same domain and slot are positive (Y=0) while\nall others are negative (Y=1). The loss becomes:\nLoss(i,j) = 1 −Y\n2 [dist(zi,zj)]2 +\nY\n2 {max(0,m −dist(zi,zj)))}2\nwhere zi represents the embedding vector for\nutterance iwhile mis a margin, set to 1. We ex-\nplored various distance functions (e.g. euclidean)\nand found that distance based on cosine similarity\nworked best:\ndist(zi ·zj) = 1− zi ·zj\n|zi|·|zj|\nSince we retrieve exemplars based on cosine score,\nwe can directly optimize for this as second tech-\nnique with a MEAN -SQUARED ERROR loss. More\nspecifically, the positive pair is assigned a target\n1554\nscore of 1 when the two examples share the same\ndomain and slot and 0 otherwise, mirroring the\nsetup of the contrastive loss. The model’s predicted\ncosine score is then compared against this target to\ncalculate an averaged L2-loss. We generate κpairs\nfor each of N exemplars, and train our ranker with:\nL(i,j) = 1\nNK\nN∑\ni=1\nK∑\nj=1\n||Target(i,j) −Pred(i,j)||2\nMulti-part Modification The standard method\nfor selecting negatives has a few drawbacks since\nall negatives are treated the same. While this is nec-\nessary for unsupervised contrastive learning, our\ncase deals with labeled exemplars. Even binary la-\nbels would provide a useful training signal, but we\neven have varying degrees of similarity. In particu-\nlar, a positive example would be an exemplar that\nhas a matching domain, slot and value. However,\nexemplars that contain a matching domain or slot\nstill deserves partial consideration rather than being\ndeemed a pure negative example. Consequently,\nwe introduce a MULTI -CONTRASTIVE loss where\nthe different elements of domain, slot and value\nare considered positive attributes, weighted with\ntheir respective lambdas. These coefficients were\nchosen by tuning on a held-out development set:\nLoss(i,j) =λd + λs + λv\n4 [dist(zi,zj)]2+\nλn\n4 {max(0,m −dist(zi,zj)))}2\nwhere:\nλd = 3, λ s = 7, λ v = 10\nλn = 1.0, margin = 1.0\nFor a final loss function, we also test a novel cosine\nsimilarity loss where the target label is modified to\ninclude multiple parts, MULTI -MSE . The target is\naltered such that a matching domain for each pair\ngets λd = 0.3, a matching slot receives another\nλs = 0.3 boost and matching values get an addi-\ntional λv = 0.4, where the weights are derived by\ntuning on the dev set. The final target score is the\ncumulative sum of the three components - positive\npairs sharing all elements get a full score of 1, neg-\native pairs with no matching elements receive a 0,\nand most pairs lie somewhere in the middle.\nTarget(i,j) =\n∑\ne\nλe[1{ei = ej}],∀e∈{d,s,v }\ns.t. λd + λs + λv = 1\nDataset # Dialogs # Domains # Slots\nMultiWOZ 8,438 7 24\nSGD 16,142 16 214\nGSIM 1,500 2 13\nDSTC2 1,612 1 8\nABCD 8,034 30 231\nTable 1: Statistics of involved task-oriented dialogue\ndatasets. Note that the numbers reported are for the\ntraining portions for all datasets.\n3.5 Model Input\nThe eventual sequence we feed into the model takes\nall of the above ideas into account. We start with\na context summary represented as the predicted\ndialogue state, followed by the current turn which\nconsists of two utterances. Each utterance includes\na special <agent> or <customer> token for the re-\nspective speaker. Next, a separator token is added,\nalong with a discrete prompt describing the do-\nmain and slot. Lastly, we prepend as many exem-\nplars as we can fit into the model maximum token\nlength, truncating from the beginning when neces-\nsary. This results in a final model input of:\n[N exemplars][prev_dialog_state][agent_utt]\n[customer_utt] <sep> [prompt][value]\nNotably, the final [value] token is only present\nduring meta-training, and belongs to the support\ndatasets. This value is precisely what we hope to\npredict when testing the left out query set.\n4 Experiments\nThis section outlines our training implementation\ndetails as well as key experiments.\n4.1 Training Setup\nWe consider Schema Guided Dialogue (SGD) (Ras-\ntogi et al., 2020), DSTC2 (Henderson et al.,\n2014), Action-Based Conversations Dataset\n(ABCD) (Chen et al., 2021), and Google Simulated\nChat (GSIM) (Shah et al., 2018) as support sets\n(listed in Table 1). We then use MultiWOZ 2.1\n(Budzianowski et al., 2018; Eric et al., 2019) as a\nquery set, as well as MultiWOZ 2.4 (Zang et al.,\n2020) which is the cleanest version of MultiWOZ\nat time of writing. All datasets have dialogue\ncompression techniques applied and use the best\nperforming embedder for exemplar retrieval.\nFor our training we use T5 (Raffel et al., 2020)\nwith both the three and eleven billion parameters\n1555\nPrompt Style Prompt Example\nStatement “The destined location of the taxi is”\nQuestion “Where is the destination of the taxi ?”\nSchema “<domain> taxi - rent cheap cabs to\navoid traffic <slot> destination - what\nplace you want the taxi to take you”\nNaive “destination of the taxi is”\nNone “taxi destination”\nRandom “blue cobra”\nTable 2: Examples for different prompt styles. Here we\nconsider a domain of “taxi” and a slot of “destination”.\nversions (T5-3b/T5-11b), where our best models\nare selected through early stopping on validation\ndata. We set the learning rate as 3e−4, employ\nan Adafactor (Shazeer and Stern, 2018) optimizer\nand cosine scheduler with warmup of 10,000 steps.\nOur best system uses an ensemble of exemplar em-\nbedders that were trained with of κ= [20,30,40]\nand learning rate of 3e−5. More details can be\nfound in Appendix C.\n4.2 Prompt Variations\nModel training can be considered stable if different\nprompts produce similar outcomes. To test this, we\ncollect six prompts based on common sense and\nprior work. As much as possible, we use prompts\ndesigned by others to avoid biasing the rankings.\nSince LMs supposedly operate on prompts as\ncontinuation of natural language, the (a) Statement\nprompt takes the form ‘The restaurant cuisine is\n<blank>’, where we hope the model completes the\nsentence with the correct slot-value. (b) A Ques-\ntion prompt reverses the meaning with ‘What is\nthe restaurant cuisine?’ (c) Schema comes from\n(Lee et al., 2021) and MWOZ 2.2 descriptions,\nwhich aims to provide the model with the maxi-\nmum amount of information. It includes a special\ntoken, name, and full description for both the do-\nmain and slot. (See Table 2) (d) Naive takes the\nopposite approach by simply following the format\nof “<slot> of the <domain> is <blank>”. (e) Taken\neven further, the None prompt does not use any nat-\nural language at all, instead opting to only include\nthe domain and slot name for evaluation purposes.\n(f) Finally, we include a Random prompt which\ndrops any notion of semantics by replacing the\ndomain with a random color and the slot with a\nrandom animal. To empathize with the difficulty\nof hand-engineering a prompt, note that each op-\ntion (except for random) seems reasonable, and it\nis hard to know a priori which one works best.\nMRR@10 NDCG@10 MAP@100\nDefault 16.7% 9.59% 1.81%\nContrastive 17.4% 10.6% 2.28%\nMulti-contrast 17.1% 9.89% 1.90%\nMean Squared 25.1% 15.5% 3.31%\nMulti-MSE 26.8% 18.4% 5.24%\nTable 3: Results of fine-tuning the sentence embedder\nwith various loss functions. Multi-part cosine is best.\nAs a baseline, we start with in-context learning\nwithout meta-training. We feed in the prompts\ndirectly and measure their variance as the standard\ndeviation among scores. Then, we perform meta-\nlearning with all prompts again and measure their\nresults, where we expect that the variance among\nthe scores has now decreased.\n4.3 Filtering Threshold\nIn order to verify that our saliency model success-\nfully removes irrelevant sentences, we employ two\nexperts to annotate 50 dialogs, which is well below\nthe allowed 1% of few-shot data. We then run the\nsaliency model on this tiny evaluation set with dif-\nferent filtering thresholds, ranging from 0.1 to 0.9,\nwith results illustrated in Figure 3. As the threshold\nincreases, only sentences with high relevance are\nleft, as evidenced by high precision and low recall.\nA maximum F1-score is reached at 0.6, but we\nwould rather keep all relevant sentences at the ex-\npense of amassing a handful of irrelevant sentences\nthan to risk missing important information. As a re-\nsult, we choose 0.4 as the filtering threshold, which\nachieves a recall of 0.998 and acceptably high pre-\ncision. Qualitative examples of irrelevant sentences\nthat were removed can be found in section 5.4.\n4.4 Retrieval Methods\nWe adapt SBERT (Reimers and Gurevych, 2019)\nto our DST task with four different objective func-\ntions: standard contrastive loss, multi-part con-\ntrastive loss, binary cosine similarity loss and multi-\npart cosine similarity loss. We test with number\nof pairs per exemplar in a range from 10 to 100 in\nincrements of ten. We found κ= 30to work best,\nwhich we use moving forward. As a control, we\nalso include the default SBERT model without any\nfurther fine-tuning. We evaluate the results of train-\ning on the few-shot examples with Mean Recipricol\nRank (MRR@10), Normalized Discounted Cumu-\nlative Gain (NDCG@10) and Maximum Average\nPrecision (MAP@100) as our metrics.\n1556\nModels Parameter MultiWOZ2.1 MultiWOZ2.4\nSize 1% 5% 10% 1% 5% 10%\nTRADE (Wu et al., 2019)\n<1B\n12.58 31.17 36.18 - - -\nSGPDST (Lee et al., 2021) 32.11 43.14 46.92 - - -\nDS2-BART (Shin et al., 2022) 28.25 37.71 40.29 30.55 42.53 41.73\nDS2-T5 (Shin et al., 2022) 33.76 44.20 45.38 36.76 49.89 51.05\nIC-DST GPT-Neo 2.7b (Hu et al., 2022)\n<100B\n16.70 26.90 31.65 17.36 29.62 34.38\nIC-DST CodeGen 2.7b (Hu et al., 2022) 20.72 29.62 33.81 21.87 33.16 37.45\nSM2-3b (Our Method) 38.06 39.94 39.85 37.59 49.22 50.33\n- Saliency Filtering 36.11 38.26 38.63 - - -\n- Context Summarization 37.02 37.83 37.80 - - -\n- Embedder Fine-tuning 27.15 30.88 31.40 - - -\nSM2-11b (Our Method) 38.36 44.64 46.02 40.03 51.14 51.97\nIC-DST Codex-davinc 175b (Hu et al., 2022) >100B 43.13 47.08 48.67 48.35 55.43 56.88\nTable 4: DST performance using 1%, 5% and 10% of the training set. Naive prompt used for our method. Bolded\nnumbers indicate highest performance on models under 100 billion parameters. Note that models <1B params\nfine-tune on task data. Ablation results are also included for dialogue compression and embedder training.\nAs is shown in Table 3, the multi-part cosine loss\nshowcases the strongest ability to select meaning-\nful exemplars. This shows the benefit of providing\npartial credit to all elements of the dialogue state.\nSurprisingly though, the multi-part contrastive loss\nunderperformed. Preliminary error analysis re-\nvealed negative examples were successfully sep-\narated from positive examples, but the different\npositive examples were mixed together. We adopt\nthe embedder trained with the MULTI -MSE for all\nremaining experiments.\n5 Results and Analysis\nThe goal of this work is to achieve strong results\non DST without worrying about tedious prompt-\nengineering. Consequently, we first analyze the\nability of the best performing models and then dis-\ncuss performance stability across different prompts.\n5.1 Main Results\nTable 4 shows that methods based on in-context\nlearning clearly surpass those based on fine-tuning\nwith few-shot data, as evidenced by the strong per-\nformance of SM2 as well as the concurrent work\nof IC-DST (Hu et al., 2022). In fact, our SM2-\n11b model is able to achieve the best joint goal\naccuracy on MultiWOZ 2.1 and 2.4 for most few-\nshot splits, when focused on models less than 100B\nparameters. Furthermore, when considering just\nmodels operating with in-context learning, SM2-\n3b greatly outperforms the IC-DST 2.7b models\nin the same order of magnitude. We note that our\nmethod is agnostic to model size, so it is certainly\npossible to combine them with systems larger than\n100B params. Doing so would likely yield strong\nperformance without sacrificing stability.\nOn that note, Table 5 shows that models trained\nwith SM2 exhibit roughly a 2x reduction in vari-\nance over models trained under other regimes.\nWhile fine-tuning on certain prompts produces\nsome of the highest scores we observe, other\nprompts yield some of the lowest, highlighting how\nhand-crafting prompts are wrought with danger.\nThe instability is most pronounced for the random\nprompt, which meta-learning is able to smooth over.\nAlso worth noting is that meta-learning from SM2\nis able to stabilize prompt performance across mul-\ntiple model types, including sequence-to-sequence\n(row 4) or auto-regressive LMs (row 5). This is in\ncontrast to purely in-context models, such as those\nwhich were pre-trained on code and must always\nobey a rigid coding structure during inference.\n5.2 Ablation Study\nTo evaluate the different contributions, we run three\nablation experiments, each of which removes one\nof the key components of SM2. The results pre-\nsented in Table 4 show that each change makes\na noticeable impact. Without saliency filtering,\nmodel performance drops by a small, but consis-\ntent amount of roughly 1-2%. Disabling context\nsummarization means truncating dialogue history\nto four utterances and precluding previous dialogue\nstate, which causes an even bigger decrease in ac-\ncuracy. Using the default SBERT embedder deals\nthe most damage of all, leading to a nearly 10%\ndrop. This suggests that exemplar selection is most\ncritical for in-context learning methods.\n1557\nPrompt Style None Naive Schema Statement Question Random STDEV\nFine-Tune 35.3 39.2 38.7 41.1 39.3 24.7 6.02\nIn-Context 17.5 19.9 14.6 18.9 12.4 4.80 5.58\nPre-train 31.8 35.4 28.2 27.8 34.6 17.2 6.65\nSM2 T5-3b 33.9 39.9 30.0 38.2 35.6 33.1 3.58\nSM2 GPT-XL 9.70 8.70 8.50 11.4 8.90 1.20 3.53\nTable 5: Joint goal accuracy over different prompt styles. Models trained with 5% of training data. The backbone\nmodel of Fine-tune and In-Context is T5-3b. Instability is measured as standard deviation of the accuracy scores.\nThe proposed ideas are also independently ap-\nplicable to other NLP tasks. For example, com-\npressing inputs to fit more exemplars into an model\ninput sequence can be applied to dialogue genera-\ntion with large LMs or even reading compression,\nwhich requires reasoning over long supporting para-\ngraphs. A multi-part training mechanism can be ap-\nplied to tasks that contain multiple elements, such\nas the premise, hypothesis and labels of NLI.\n5.3 Additional Discussion\nWe now turn our attention to the impact of different\ntraining regimes, as shown in Table 5. Fine-tuning\n(row 1) serves as an oracle since it represents train-\ning directly on the data in the target domain. Un-\nsurprisingly, SM2 reaches lower average results\nin comparison. In contrast, SM2 significantly out-\nperforms in-context learning (row 2) since neither\nperform gradient updates, while SM2 includes a\nmeta-learning stage. Finally, to disentangle the\neffects of pre-training and meta-ICL, we also com-\npare against a baseline which does not perform\nin-context learning (row 3). Rather than learning\nthe prompts, this baseline instead simply performs\ntransfer learning from the source datasets to the\ntarget dataset. Such a setup does not work as well\ndue to the domain shift from the source distribution\nto the target distribution.\nDigging deeper, we notice that our method dis-\nplays a meaningful jump in performance when go-\ning from 1% to 5% data, but not much when go-\ning to 10%. The increased amount of data fails\nto provide much marginal value since the exem-\nplars being selected did not change much despite\nchoosing from a larger candidate pool. Instead, the\nfinite sequence length became the bottleneck on\ndownstream accuracy.\nThe performance of the in-context methods are\ninteresting in their own right. Statement prompt\ndoes best, while Random does worst, but despite\nhaving no training, is well above chance. This sur-\nprising result confirms other research on prompt\nanalysis, which found that large PLMs sometimes\nperform too well, implying that the models are actu-\nally paying attention to superficial cues rather than\ntruly understanding the text within a prompt (Web-\nson and Pavlick, 2021; Kavumba et al., 2022).\n5.4 Qualitative Analysis\nThe top half of Table 6 shows an utterance with\n“domain=restaurant” and “slots=price range, food\ntype”. Despite having minimal n-gram overlap with\nthe example, the first exemplar E1 receives a high\nscore by matching the same domain and slot of\nthe target utterance. On the other hand, the second\nexemplar E2 discusses an entirely different topic,\nproducing a low score. This demonstrates the effec-\ntiveness of the sentence embedder in distinguishing\nthe value of these exemplars. The bottom half of\nTable 6 shows how the saliency model successfully\nconserves a large amount of token space. Short\nsentences and those void of any dialog state infor-\nmation are safe for removal. When all sentences\nin an utterance are filtered, then we also remove\nthe associated speaker token. Despite our conserva-\ntive thresholds, the majority of useless information\nis successfully trimmed out to allow the model to\nfocus on the most pertinent areas instead.\n6 Conclusion\nIn this paper, we presented a method of perform-\ning few-shot dialogue state tracking by leveraging\nlarge pre-trained LMs with prompts. Our technique\ndoes not require any gradient-based training for the\ntarget task and instead relies on in-context learn-\ning to guide model generation. To enable success\nin this low-resource setting, we stabilize training\nacross prompts with Meta-ICL, apply saliency fil-\ntering and context summarization to reduce dia-\nlogue length, and fine-tune a sentence embedder\nwith a custom loss objective to improve exemplar\nretrieval. These techniques combined allow us to\nreach state-of-the-art results on MultiWOZ when\nlimited to models under 100 billion parameters.\n1558\nExemplar Retrieval\nDialog ID Target Utterance Exemplar Score\nSSNG0074.json\nI am looking for a restaurant in the\nmoderate price range that serves\nbistro type food.\nE1: I would love to help. any particular\nfood you’d like? no, I’d just like for it to\nbe in the east and moderately priced.\n0.738\nE2: Seventeen locations meet your cri-\nteria. Would you prefer a guesthouse or\na hotel? A hotel is fine whichever you\nrecommend.\n-0.074\nSaliency Filtering\nPMUL0287.json\n<Agent>: The phone number is 01223259988. <User>: Perfect. Can you help me with\na reservation for 6 people at 14:30 this coming sunday? And please make sure I have a\nconfirmation number to use. <Agent>:our reservation is set!\nPMUL1635.json\n<Agent>: What day will you be staying? <User>: Friday and Can you book it for me\nand get a reference number ? <Agent>:Booking was successful. Reference number is :\nBMUKPTG6. Can I help you with anything else today? <User>: I am looking to book\na train that is leaving from Cambridge to Bishops Stortford on Friday.\nTable 6: Examples of how exemplar retrieval and saliency filtering operate. Same colored text represents matching\ndomain and slots. The strikethrough of text means removal of the irrelevant sentence by the saliency model.\nMoving forward, we plan to explore techniques\nthat push model and data efficiency even further.\nDistillation and pruning can lead to much fewer\nmodel parameters, while numerous data augmen-\ntation techniques seem promising in maximizing\nthe advantage of limited labeled data. Lastly, rather\nthan meta-learning across different dialog domains,\nwe also would like to explore meta-train model\nwith different prompt styles. With the current\nframework, the prompt used in inference is re-\nquired to be the same as the training. However,\nwe might want to use flexible prompts in practice.\nConsequently, we could meta-train across different\nprompt styles to allow the model to quickly learn a\nnew prompt style during inference.\n7 Limitations\nOur method is model-agnostic and can be com-\nbined with larger pre-trained model over 100 bil-\nlion parameters for further improvement on DST\ntask. However, due the budget limit, this is unlikely\nto be directly validated. Ironically, our method also\nhas the limitation that it cannot be combined with\nsmaller models since the emergent behavior of be-\ning to understand prompts only seems to occur with\nsufficiently large pre-trained models.\nSeparately, the proposed saliency filtering and\nthe exemplar retrieval module are designed based\non the dialog state tracking task, but not specifically\nfor the MultiWOZ dataset. As a result, we planned\nto apply our framework to other task-oriented di-\nalog datasets, e.g. SGD (Rastogi et al., 2020) to\nverify that our framework is generalizable, but have\nnot done so yet due to time constraints. We also\nran our experiments with a different model type\nin GPT-XL, but did not have a chance to properly\ntune the parameters, leading to low performance.\nWe would have liked to run our experiments with\ndifferent random seeds. Considering the stability\nof our framework among different prompt styles,\ndifferent random seeds should not cause high vari-\nance. However, we still need to run experiments to\nverify this assumption.\n1559\nReferences\nLeonard Adolphs, Kurt Shuster, Jack Urbanek, Arthur\nSzlam, and Jason Weston. 2021. Reason first, then\nrespond: Modular generation for knowledge-infused\ndialogue. CoRR, abs/2111.05204.\nEmily M. Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\ndangers of stochastic parrots: Can language mod-\nels be too big? In Proceedings of the 2021\nACM Conference on Fairness, Accountability, and\nTransparency, FAccT ’21, page 610–623, New York,\nNY , USA. Association for Computing Machinery.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, T. J. Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens\nWinter, Christopher Hesse, Mark Chen, Eric Sigler,\nMateusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. ArXiv,\nabs/2005.14165.\nPawel Budzianowski, Tsung-Hsien Wen, Bo-Hsiang\nTseng, Iñigo Casanueva, Stefan Ultes, Osman Ra-\nmadan, and Milica Gasic. 2018. Multiwoz - A large-\nscale multi-domain wizard-of-oz dataset for task-\noriented dialogue modelling. In Proceedings of the\n2018 Conference on Empirical Methods in Natural\nLanguage Processing, Brussels, Belgium, October\n31 - November 4, 2018, pages 5016–5026. Associa-\ntion for Computational Linguistics.\nGiovanni Campagna, Agata Foryciarz, Mehrad Morad-\nshahi, and Monica Lam. 2020. Zero-shot trans-\nfer learning with synthesized data for multi-\ndomain dialogue state tracking. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 122–132, Online.\nAssociation for Computational Linguistics.\nDerek Chen, Howard Chen, Yi Yang, Alexander Lin,\nand Zhou Yu. 2021. Action-based conversations\ndataset: A corpus for building more in-depth task-\noriented dialogue systems. In Proceedings of the\n2021 Conference of the North American Chapter\nof the Association for Computational Linguistics:\nHuman Language Technologies, pages 3002–3017,\nOnline. Association for Computational Linguistics.\nTing Chen, Simon Kornblith, Mohammad Norouzi, and\nGeoffrey E. Hinton. 2020. A simple framework\nfor contrastive learning of visual representations.\nIn Proceedings of the 37th International Conference\non Machine Learning, ICML 2020, 13-18 July\n2020, Virtual Event, volume 119 of Proceedings\nof Machine Learning Research, pages 1597–1607.\nPMLR.\nYanda Chen, Ruiqi Zhong, Sheng Zha, George\nKarypis, and He He. 2022. Meta-learning via lan-\nguage model in-context tuning. In Proceedings\nof the 60th Annual Meeting of the Association\nfor Computational Linguistics (V olume 1: Long\nPapers), pages 719–730, Dublin, Ireland. Associa-\ntion for Computational Linguistics.\nSaket Dingliwal, Bill Gao, Sanchit Agarwal, Chien-Wei\nLin, Tagyoung Chung, and Dilek Z. Hakkani-Tür.\n2021. Few shot dialogue state tracking using meta-\nlearning. In EACL.\nMihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi,\nSanchit Agarwal, Shuyag Gao, and Dilek Hakkani-\nTur. 2019. Multiwoz 2.1: Multi-domain dialogue\nstate corrections and state tracking baselines. arXiv\npreprint arXiv:1907.01669.\nMihail Eric, Lakshmi Krishnan, Francois Charette, and\nChristopher D. Manning. 2017. Key-value retrieval\nnetworks for task-oriented dialogue. In Proceedings\nof the 18th Annual SIGdial Meeting on Discourse\nand Dialogue, pages 37–49, Saarbrücken, Germany.\nAssociation for Computational Linguistics.\nChelsea Finn, P. Abbeel, and Sergey Levine. 2017.\nModel-agnostic meta-learning for fast adaptation of\ndeep networks. In ICML.\nTianyu Gao, Adam Fisch, and Danqi Chen. 2021a.\nMaking pre-trained language models better few-shot\nlearners. In Proceedings of the 59th Annual Meeting\nof the Association for Computational Linguistics\nand the 11th International Joint Conference on\nNatural Language Processing (V olume 1: Long\nPapers), pages 3816–3830, Online. Association for\nComputational Linguistics.\nTianyu Gao, Xingcheng Yao, and Danqi Chen.\n2021b. Simcse: Simple contrastive learning\nof sentence embeddings. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing, EMNLP 2021, Virtual Event\n/ Punta Cana, Dominican Republic, 7-11 November,\n2021, pages 6894–6910. Association for Computa-\ntional Linguistics.\nYuxian Gu, Xu Han, Zhiyuan Liu, and Minlie Huang.\n2021. PPT: pre-trained prompt tuning for few-shot\nlearning. CoRR, abs/2109.04332.\nRaia Hadsell, Sumit Chopra, and Yann LeCun.\n2006. Dimensionality reduction by learning\nan invariant mapping. 2006 IEEE Computer\nSociety Conference on Computer Vision and Pattern\nRecognition (CVPR’06), 2:1735–1742.\nMichael Heck, Carel van Niekerk, Nurul Lubis, Chris-\ntian Geishauser, Hsien-Chin Lin, Marco Moresi, and\nMilica Gasic. 2020. TripPy: A triple copy strategy\nfor value independent neural dialog state tracking.\nIn Proceedings of the 21th Annual Meeting of the\nSpecial Interest Group on Discourse and Dialogue,\npages 35–44, 1st virtual meeting. Association for\nComputational Linguistics.\n1560\nMatthew Henderson, Blaise Thomson, and Jason D\nWilliams. 2014. The second dialog state track-\ning challenge. In Proceedings of the 15th annual\nmeeting of the special interest group on discourse\nand dialogue (SIGDIAL), pages 263–272.\nEhsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu,\nSemih Yavuz, and Richard Socher. 2020. A simple\nlanguage model for task-oriented dialogue. arXiv\npreprint arXiv:2005.00796.\nYushi Hu, Chia-Hsuan Lee, Tianbao Xie, Tao Yu,\nNoah A. Smith, and Mari Ostendorf. 2022. In-\ncontext learning for few-shot dialogue state tracking.\nArXiv, abs/2203.08568.\nVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\nS. H. Lewis, Ledell Wu, Sergey Edunov, Danqi\nChen, and Wen-tau Yih. 2020. Dense passage re-\ntrieval for open-domain question answering. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing, EMNLP\n2020, Online, November 16-20, 2020, pages 6769–\n6781. Association for Computational Linguistics.\nPride Kavumba, Ryo Takahashi, and Yusuke Oda.\n2022. Are prompt-based models clueless? In\nProceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (V olume\n1: Long Papers), pages 2333–2352, Dublin, Ireland.\nAssociation for Computational Linguistics.\nSungdong Kim, Sohee Yang, Gyuwan Kim, and Sang-\nWoo Lee. 2020. Efficient dialogue state tracking\nby selectively overwriting memory. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 567–582, Online.\nAssociation for Computational Linguistics.\nMojtaba Komeili, Kurt Shuster, and Jason Weston.\n2022. Internet-augmented dialogue generation. In\nProceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (V olume\n1: Long Papers), pages 8460–8478, Dublin, Ireland.\nAssociation for Computational Linguistics.\nSatwik Kottur, Chinnadhurai Sankar, Zhou Yu, and\nAlborz Geramifard. 2021. DialogStitch: Synthetic\ndeeper and multi-context task-oriented dialogs. In\nProceedings of the 22nd Annual Meeting of the\nSpecial Interest Group on Discourse and Dialogue,\npages 21–26, Singapore and Online. Association for\nComputational Linguistics.\nChia-Hsuan Lee, Hao Cheng, and Mari Ostendorf. 2021.\nDialogue state tracking with a language model us-\ning schema-driven prompting. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 4937–4949, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021a.\nThe power of scale for parameter-efficient prompt\ntuning. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\npages 3045–3059, Online and Punta Cana, Domini-\ncan Republic. Association for Computational Lin-\nguistics.\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021b.\nThe power of scale for parameter-efficient prompt\ntuning. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\npages 3045–3059, Online and Punta Cana, Domini-\ncan Republic. Association for Computational Lin-\nguistics.\nXiang Lisa Li and Percy Liang. 2021. Prefix-\ntuning: Optimizing continuous prompts for gener-\nation. In Proceedings of the 59th Annual Meeting of\nthe Association for Computational Linguistics and\nthe 11th International Joint Conference on Natural\nLanguage Processing (V olume 1: Long Papers),\npages 4582–4597, Online. Association for Computa-\ntional Linguistics.\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,\nLawrence Carin, and Weizhu Chen. 2022. What\nmakes good in-context examples for gpt-3? In\nDEELIO.\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang,\nHiroaki Hayashi, and Graham Neubig. 2021. Pre-\ntrain, prompt, and predict: A systematic survey of\nprompting methods in natural language processing.\nArXiv, abs/2107.13586.\nAndrea Madotto, Zhaojiang Lin, Genta Indra Winata,\nand Pascale Fung. 2021. Few-shot bot: Prompt-\nbased learning for dialogue systems. ArXiv,\nabs/2110.08118.\nFei Mi, Wanhao Zhou, Lingjing Kong, Fengyu Cai,\nMinlie Huang, and Boi Faltings. 2021. Self-training\nimproves pre-training for few-shot learning in task-\noriented dialog systems. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing, EMNLP 2021, Virtual Event\n/ Punta Cana, Dominican Republic, 7-11 November,\n2021, pages 1887–1898. Association for Computa-\ntional Linguistics.\nSewon Min, Mike Lewis, Luke Zettlemoyer, and Han-\nnaneh Hajishirzi. 2021. Metaicl: Learning to learn in\ncontext. ArXiv, abs/2110.15943.\nAlex Nichol, Joshua Achiam, and John Schulman. 2018.\nOn first-order meta-learning algorithms. ArXiv,\nabs/1803.02999.\nAlex Nichol and John Schulman. 2018. Reptile: a\nscalable metalearning algorithm. arXiv: Learning.\nBaolin Peng, Chunyuan Li, Jinchao Li, Shahin Shayan-\ndeh, Lars Liden, and Jianfeng Gao. 2021. Soloist:\nBuilding task bots at scale with transfer learning and\nmachine teaching. Transactions of the Association\nfor Computational Linguistics, 9:807–824.\n1561\nJun Quan and Deyi Xiong. 2020. Modeling long\ncontext for task-oriented dialogue state generation.\nIn Proceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics, pages\n7119–7124, Online. Association for Computational\nLinguistics.\nColin Raffel, Noam Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020. Exploring the\nlimits of transfer learning with a unified text-to-text\ntransformer. Journal of Machine Learning Research,\n21(140):1–67.\nAbhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara,\nRaghav Gupta, and Pranav Khaitan. 2020. Towards\nscalable multi-domain conversational agents: The\nschema-guided dialogue dataset. In Proceedings of\nthe AAAI Conference on Artificial Intelligence, vol-\nume 34, pages 8689–8696.\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert:\nSentence embeddings using siamese bert-networks.\nIn Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing. Associa-\ntion for Computational Linguistics.\nTimo Schick and Hinrich Schütze. 2021. Exploiting\ncloze-questions for few-shot text classification and\nnatural language inference. In Proceedings of the\n16th Conference of the European Chapter of the\nAssociation for Computational Linguistics: Main\nV olume, pages 255–269, Online. Association for\nComputational Linguistics.\nPararth Shah, Dilek Hakkani-Tür, Gokhan Tür, Ab-\nhinav Rastogi, Ankur Bapna, Neha Nayak, and\nLarry Heck. 2018. Building a conversational agent\novernight with dialogue self-play. arXiv preprint\narXiv:1801.04871.\nNoam M. Shazeer and Mitchell Stern. 2018. Adafactor:\nAdaptive learning rates with sublinear memory cost.\nArXiv, abs/1804.04235.\nJamin Shin, Hangyeol Yu, Hyeongdon Moon, Andrea\nMadotto, and Juneyoung Park. 2022. Dialogue sum-\nmaries as dialogue states (DS2), template-guided\nsummarization for few-shot dialogue state tracking.\nIn Findings of the Association for Computational\nLinguistics: ACL 2022, pages 3824–3846, Dublin,\nIreland. Association for Computational Linguistics.\nJake Snell, Kevin Swersky, and Richard S. Zemel. 2017.\nPrototypical networks for few-shot learning. ArXiv,\nabs/1703.05175.\nEmma Strubell, Ananya Ganesh, and Andrew Mc-\nCallum. 2019. Energy and policy considerations\nfor deep learning in NLP. In Proceedings of\nthe 57th Annual Meeting of the Association for\nComputational Linguistics, pages 3645–3650, Flo-\nrence, Italy. Association for Computational Linguis-\ntics.\nAdam Summerville, Jordan Hashemi, James Ryan,\nand William Ferguson. 2020. How to tame your\ndata: Data augmentation for dialog state tracking.\nIn Proceedings of the 2nd Workshop on Natural\nLanguage Processing for Conversational AI, pages\n32–37, Online. Association for Computational Lin-\nguistics.\nAlbert Webson and Ellie Pavlick. 2021. Do prompt-\nbased models really understand the meaning of their\nprompts? CoRR, abs/2109.01247.\nChien-Sheng Wu, Andrea Madotto, Ehsan Hosseini-Asl,\nCaiming Xiong, Richard Socher, and Pascale Fung.\n2019. Transferable multi-domain state generator\nfor task-oriented dialogue systems. In Proceedings\nof the 57th Annual Meeting of the Association\nfor Computational Linguistics, pages 808–819, Flo-\nrence, Italy. Association for Computational Linguis-\ntics.\nYan Xu, Etsuko Ishii, Samuel Cahyawijaya, Zihan\nLiu, Genta Indra Winata, Andrea Madotto, Dan Su,\nand Pascale Fung. 2022. Retrieval-free knowledge-\ngrounded dialogue response generation with adapters.\nIn Proceedings of the Second DialDoc Workshop on\nDocument-grounded Dialogue and Conversational\nQuestion Answering, pages 93–107, Dublin, Ireland.\nAssociation for Computational Linguistics.\nYuting Yang, Wenqiang Lei, Juan Cao, Jintao Li, and\nTat-Seng Chua. 2022. Prompt learning for few-shot\ndialogue state tracking. ArXiv, abs/2201.05780.\nYichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, and\nQun Liu. 2020. Dialog state tracking with reinforced\ndata augmentation. In AAAI.\nXiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara,\nRaghav Gupta, Jianguo Zhang, and Jindong Chen.\n2020. Multiwoz 2.2 : A dialogue dataset with addi-\ntional annotation corrections and state tracking base-\nlines. CoRR, abs/2007.12720.\n1562\nA Loss Functions\nGao et al. (2021b) proposes a softmax-based con-\ntrastive loss:\nLi = −log esim(hi,h+\ni )/τ\n∑N\nj=1 esim(hi,h+\nj )/τ\nwhich is popular among NLP tasks. However, this\nloss function requires extremely large batch sizes\nto work well (Chen et al., 2020). This is espe-\ncially difficult for us since we specifically target\na low-resource setting with small GPU memory\nrequirements. More critically, this softmax con-\ntrastive loss views all negatives as being the same.\nHowever, in the case of dialog state tracking, where\ndialog state is represented as (domain, slot, value),\nthe matching is decided at three levels. For exam-\nple, two dialogue examples can (and should) be\nconsidered a negative pair when they have differ-\nent values for all three elements. In another case\nthough, they might be considered a negative pair\nby not having matching “value”, but still sharing\nthe same “domain” and “slot”. The softmax con-\nstrastive loss considers these two cases as the same,\nwhich is not ideal for the DST task. Therefore, we\nimplement the for our experiments. The classic\nmax-margin contrastive loss (Hadsell et al., 2006)\nis also unable to make a clear distinction for partial\ncredit either, but should be able to when the loss is\nthe sum of multiple elements. Therefore, we use\nthe max-margin loss for our experiments.\nB Filtering Results\n0.00\n0.25\n0.50\n0.75\n1.00\n0.00\n0.05\n0.10\n0.15\n0.20\n0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\nRecall F1 Precision JGA\nFigure 3: Graph of precision, recall and F1 when vary-\ning the acceptance threshold. Joint goal accuracy (JGA)\ncorrelates closely with recall due to the nature of DST.\nC Other Implementation Details\nIn this section, we introduce more implementation\ndetails. For training, we search the learning rate\nwithin the interval [3e-5, 1e-4, 3e-4, 1e-3, 3e-3]. In\norder to deploy large pre-trained models like T5-\n3b and T5-11b, we first adjust the batch size. To\nachieve a balance between GPU memory consump-\ntion and batch performance, we alter the number\nof gradient accumulation steps to maintain a con-\nsistent effective batch size of 64 across runs. Fur-\nthermore, we also change everything into bitfloat\n16 (BF16) and adopt AdaFactor as the optimizer to\nlower the number of parameters.\nWe additionally perform ensemble decoding for\nmultiple times using different retrieval embedders.\nThese sentence embedders are distinguished by\nbeing trained on different levels of kappa, where\nwe end up choosing embedders trained with kappa\nof [20,30,40]. These values were selected since\nthey were the models which had the best results\nas measured by MRR@10 and MAP@10. We run\nexemplar retrieval with these models and take the\nmajority vote of the system.\nIn addition to adopting different prompts for\nour models, we also apply the concept of verbaliz-\ners (Schick and Schütze, 2021). More specifically,\nwe use verbalizers to map natural sounding output\nto the more limited slot-values in the ontology. For\nexample, given the prompt ‘Whether the hotel of-\nfers wifi’, we consider both ‘True’ (or ‘False’) and\n‘Yes’ (or ’No’) to be the same answer.\nD Input Example\n(See next page.)\n1563\nExemplar 0 (Truncated) <pad> options available. Would you like to narrow it down by departure time or arrival time?\n<customer> I’d like to leave after 21:45, if possible. I won’t need to book. I’ll just need the\narrival time, please? <sep> departure of the train is cambridge</s>\nExemplar 1 taxi destination kambar, taxi departure lovell lodge <agent> when would you like to arrive?\n<customer> It doesn’t matter. I just want to leave there after 10:45 <sep> destination of the taxi\nis kambar</s>\nExemplar 2 taxi destination riverboat georgina, taxi departure archway house, hotel area north, hotel day\nthursday, hotel stay 5, hotel people 3, hotel stars 4, attraction name cambridge punter, attraction\ntype boat <agent> what time would you like to leave or arrive by? <customer> I’d like to leave\nthe hotel by 3:15 please. <sep> stars of the hotel is 4</s>\nExemplar 3 train day saturday, train destination cambridge, train departure ely <agent> sure, do you know\nwhat time you want to arrive? <customer> I want to arrive by 11:30. <sep> departure of the train\nis ely</s>\nExemplar 4 restaurant area centre, restaurant people 8, restaurant day thursday, restaurant time 14:00,\nrestaurant food chinese, restaurant price range cheap, taxi destination charlie chan, taxi departure\nmuseum of classical archaeology, attraction name museum of classical archaeology <agent>\nWhen would you like the leave and arrive by? <customer> I don’t mind what time we leave, but\nI need to arrive at the restaurant by 14:00. <sep> departure of the taxi is museum of classical\narchaeology</s>\nExemplar 5 restaurant area south, restaurant food asian oriental, restaurant name any, restaurant price range\nany, train arrive by none, train day wednesday, train destination cambridge, train departure\nlondon kings cross, train leave at none, attraction area east <agent> what time were you wanting\nto leave by or arrive by? <customer> I want to arrive by 12:15. <sep> arrive by of the train is\n12:15</s>\nPrev State taxi destination pizza hut fen ditton\nDialog Context <agent> What time do you want to leave and what time do you want to arrive by? <customer> I\nwant to leave after 17:15.\nPrompt leave at of the taxi is</s>\nLabel after 17:15\nTable 7: A practical example used during inference which uses our fine-tuned sentence embedder for exemplar\nretrieval. To be easy to read, we separate each component, including exemplars, query sequence and prompt. Each\nexemplar contains previous states, dialog context, prompt and label, which corresponds to Sec. 3.5. The 0-th\nexemplar is truncated so that the entire sequence length can fit into the model.\n1564"
}