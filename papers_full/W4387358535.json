{
    "title": "CellPLM: Pre-training of Cell Language Model Beyond Single Cells",
    "url": "https://openalex.org/W4387358535",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2312434675",
            "name": "Hongzhi Wen",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A2126774293",
            "name": "Wenzhuo Tang",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A2622604469",
            "name": "Xinnan Dai",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A2594987546",
            "name": "Jiayuan Ding",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A1898282297",
            "name": "Wei Jin",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A2030096930",
            "name": "Yuying Xie",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A2146463745",
            "name": "Jiliang Tang",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A2312434675",
            "name": "Hongzhi Wen",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A2126774293",
            "name": "Wenzhuo Tang",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A2622604469",
            "name": "Xinnan Dai",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A2594987546",
            "name": "Jiayuan Ding",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A1898282297",
            "name": "Wei Jin",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A2030096930",
            "name": "Yuying Xie",
            "affiliations": [
                "Michigan State University"
            ]
        },
        {
            "id": "https://openalex.org/A2146463745",
            "name": "Jiliang Tang",
            "affiliations": [
                "Michigan State University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3087138957",
        "https://openalex.org/W2562947047",
        "https://openalex.org/W3159800610",
        "https://openalex.org/W2950993016",
        "https://openalex.org/W3099810371",
        "https://openalex.org/W4312114998",
        "https://openalex.org/W2140679639",
        "https://openalex.org/W3208940117",
        "https://openalex.org/W2937443931",
        "https://openalex.org/W4317757307",
        "https://openalex.org/W2526724898",
        "https://openalex.org/W4316096017",
        "https://openalex.org/W4307210265",
        "https://openalex.org/W2561754210",
        "https://openalex.org/W4280596398",
        "https://openalex.org/W2951381561",
        "https://openalex.org/W4360942779",
        "https://openalex.org/W3024013192",
        "https://openalex.org/W1981641790",
        "https://openalex.org/W4306639438",
        "https://openalex.org/W4200362915",
        "https://openalex.org/W3092318937",
        "https://openalex.org/W2951217100",
        "https://openalex.org/W2177899970",
        "https://openalex.org/W4366814680",
        "https://openalex.org/W4225981439",
        "https://openalex.org/W3132661792",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W3022968840",
        "https://openalex.org/W2792693509",
        "https://openalex.org/W3090295751",
        "https://openalex.org/W2901677030",
        "https://openalex.org/W2965552103",
        "https://openalex.org/W2964643116",
        "https://openalex.org/W3175283754",
        "https://openalex.org/W3023701177",
        "https://openalex.org/W2969093152",
        "https://openalex.org/W3009609875",
        "https://openalex.org/W3140605903",
        "https://openalex.org/W2993523018",
        "https://openalex.org/W2612519453",
        "https://openalex.org/W4285596404",
        "https://openalex.org/W2951560273",
        "https://openalex.org/W4288758477",
        "https://openalex.org/W4212891644",
        "https://openalex.org/W3182503854",
        "https://openalex.org/W2781865485",
        "https://openalex.org/W3111521801",
        "https://openalex.org/W2471536144",
        "https://openalex.org/W2591733518",
        "https://openalex.org/W2966569571",
        "https://openalex.org/W4378838672",
        "https://openalex.org/W3007172120",
        "https://openalex.org/W2805619986",
        "https://openalex.org/W3138479716",
        "https://openalex.org/W2989539713",
        "https://openalex.org/W3121168830",
        "https://openalex.org/W4313561039",
        "https://openalex.org/W4297243391",
        "https://openalex.org/W2986063762",
        "https://openalex.org/W2913668833"
    ],
    "abstract": "Abstract The current state-of-the-art single-cell pre-trained models are greatly inspired by the success of large language models. They trained transformers by treating genes as tokens and cells as sentences. However, three fundamental differences between single-cell data and natural language data are overlooked: (1) scRNA-seq data are presented as bag-of-genes instead of sequences of RNAs; (2) Cell-cell relations are more intricate and important than inter-sentence relations; and (3) The quantity of single-cell data is considerably inferior to text data, and they are very noisy. In light of these characteristics, we propose a new pre-trained model CellPLM , which takes cells as tokens and tissues as sentences. In addition, we leverage spatially-resolved transcriptomic data in pre-training to facilitate learning cell-cell relationships and introduce a Gaussian mixture prior distribution as an additional inductive bias to overcome data limitation. CellPLM is the first single-cell pre-trained transformer that encodes cell-cell relations and it consistently outperforms existing pre-trained and non-pre-trained models in diverse downstream tasks, with 100x times higher inference speed compared to existing pre-trained models.",
    "full_text": null
}