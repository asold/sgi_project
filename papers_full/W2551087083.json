{
  "title": "LSTM-Based System-Call Language Modeling and Robust Ensemble Method for Designing Host-Based Intrusion Detection Systems",
  "url": "https://openalex.org/W2551087083",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4287288326",
      "name": "Kim, Gyuwan",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Yi, Hayoon",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1566973763",
      "name": "Lee Jangho",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2230571236",
      "name": "Paek Yun-Heung",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2978664967",
      "name": "Yoon, Sungroh",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W248959849",
    "https://openalex.org/W2129860818",
    "https://openalex.org/W1562890122",
    "https://openalex.org/W2120617515",
    "https://openalex.org/W2101899163",
    "https://openalex.org/W1591801644",
    "https://openalex.org/W1988918299",
    "https://openalex.org/W2167240430",
    "https://openalex.org/W2950635152",
    "https://openalex.org/W2135143063",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2964308564",
    "https://openalex.org/W2133590498",
    "https://openalex.org/W2143612262",
    "https://openalex.org/W2139731313",
    "https://openalex.org/W1843891098",
    "https://openalex.org/W2088476668",
    "https://openalex.org/W2131970275",
    "https://openalex.org/W1981738628",
    "https://openalex.org/W2132339004",
    "https://openalex.org/W2141599568",
    "https://openalex.org/W1811853421",
    "https://openalex.org/W2259472270",
    "https://openalex.org/W2187089797",
    "https://openalex.org/W2155653793"
  ],
  "abstract": "In computer security, designing a robust intrusion detection system is one of the most fundamental and important problems. In this paper, we propose a system-call language-modeling approach for designing anomaly-based host intrusion detection systems. To remedy the issue of high false-alarm rates commonly arising in conventional methods, we employ a novel ensemble method that blends multiple thresholding classifiers into a single one, making it possible to accumulate 'highly normal' sequences. The proposed system-call language model has various advantages leveraged by the fact that it can learn the semantic meaning and interactions of each system call that existing methods cannot effectively consider. Through diverse experiments on public benchmark datasets, we demonstrate the validity and effectiveness of the proposed method. Moreover, we show that our model possesses high portability, which is one of the key aspects of realizing successful intrusion detection systems.",
  "full_text": "LSTM-B ASED SYSTEM -CALL LANGUAGE MODELING\nAND ROBUST ENSEMBLE METHOD FOR DESIGNING\nHOST-BASED INTRUSION DETECTION SYSTEMS\nGyuwan Kim, Hayoon Yi, Jangho Lee, Yunheung Paek, Sungroh Yoon‚àó\nSeoul National University\n{kgwmath,hyyi,ubuntu,ypaek,sryoon}@snu.ac.kr\nABSTRACT\nIn computer security, designing a robust intrusion detection system is one of the\nmost fundamental and important problems. In this paper, we propose a system-call\nlanguage-modeling approach for designing anomaly-based host intrusion detec-\ntion systems. To remedy the issue of high false-alarm rates commonly arising in\nconventional methods, we employ a novel ensemble method that blends multiple\nthresholding classiÔ¨Åers into a single one, making it possible to accumulate ‚Äòhighly\nnormal‚Äô sequences. The proposed system-call language model has various advan-\ntages leveraged by the fact that it can learn the semantic meaning and interactions\nof each system call that existing methods cannot effectively consider. Through\ndiverse experiments on public benchmark datasets, we demonstrate the validity\nand effectiveness of the proposed method. Moreover, we show that our model\npossesses high portability, which is one of the key aspects of realizing successful\nintrusion detection systems.\n1 I NTRODUCTION\nAn intrusion detection system (IDS) refers to a hardware/software platform for monitoring network\nor system activities to detect malicious signs therefrom. Nowadays, practically all existing computer\nsystems operate in a networked environment, which continuously makes them vulnerable to a variety\nof malicious activities. Over the years, the number of intrusion events is signiÔ¨Åcantly increasing\nacross the world, and intrusion detection systems have already become one of the most critical\ncomponents in computer security. With the explosive growth of logging data, the role of machine\nlearning in effective discrimination between malicious and benign system activities has never been\nmore important.\nA survey of existing IDS approaches needs a multidimensional consideration. Depending on the\nscope of intrusion monitoring, there exist two main types of intrusion detection systems: network-\nbased (NIDS) and host-based (HIDS). The network-based intrusion detection systems monitor com-\nmunications between hosts, while the host-based intrusion detection systems monitor the activity on\na single system. From a methodological point of view, intrusion detection systems can also be clas-\nsiÔ¨Åed into two classes (Jyothsna et al., 2011): signature-based and anomaly-based. The signature-\nbased approaches match the observed behaviors against templates of known attack patterns, while\nthe anomaly-based techniques compare the observed behaviors against an extensive baseline of nor-\nmal behaviors constructed from prior knowledge, declaring each of anomalous activities to be an\nattack. The signature-based methods detect already known and learned attack patterns well but have\nan innate difÔ¨Åculty in detecting unfamiliar attack patterns. On the other hand, the anomaly-based\nmethods can potentially detect previously unseen attacks but may suffer from making a robust base-\nline of normal behavior, often yielding high false alarm rates. The ability to detect a ‚Äòzero-day‚Äô\nattack (i.e., vulnerability unknown to system developers) in a robust manner is becoming an impor-\ntant requirement of an anomaly-based approach. In terms of this two-dimensional taxonomy, we\ncan classify our proposed method as an anomaly-based host intrusion detection system.\n‚àóTo whom correspondence should be addressed.\n1\narXiv:1611.01726v1  [cs.CR]  6 Nov 2016\nIt was Forrest et al. (1996) who Ô¨Årst started to use system-call traces as the raw data for host-based\nanomaly intrusion detection systems, and system-call traces have been widely used for IDS research\nand development since their seminal work (Forrest et al., 2008). System calls represent low-level\ninteractions between programs and the kernel in the system, and many researchers consider system-\ncall traces as the most accurate source useful for detecting intrusion in an anomaly-based HIDS.\nFrom a data acquisition point of view, system-call traces are easy to collect in a large quantity in\nreal-time. Our approach described in this paper also utilizes system-call traces as input data.\nFor nearly two decades, various research has been conducted based on analyzing system-call traces.\nMost of the existing anomaly-based host intrusion detection methods typically aim to identify mean-\ningful features using the frequency of individual calls and/or windowed patterns of calls from se-\nquences of system calls. However, such methods have limited ability to capture call-level features\nand phrase-level features simultaneously. As will be detailed shortly, our approach tries to address\nthis limitation by generating a language model of system calls that can jointly learn the semantics\nof individual system calls and their interactions (that can collectively represent a new meaning)\nappearing in call sequences.\nIn natural language processing (NLP), a language model represents a probability distribution over\nsequences of words, and language modeling has been a very important component of many NLP\napplications, including machine translation (Cho et al., 2014; Bahdanau et al., 2014), speech recog-\nnition (Graves et al., 2013), question answering (Hermann et al., 2015), and summarization (Rush\net al., 2015). Recently, deep recurrent neural network (RNN)-based language models are show-\ning remarkable performance in various tasks (Zaremba et al., 2014; Jozefowicz et al., 2016). It\nis expected that such neural language models will be applicable to not only NLP applications but\nalso signal processing, bioinformatics, economic forecasting, and other tasks that require effective\ntemporal modeling.\nMotivated by this performance advantage and versatility of deep RNN-based language modeling,\nwe propose an application of neural language modeling to host-based introduction detection. We\nconsider system-call sequences as a language used for communication between users (or programs)\nand the system. In this view, system calls and system-call sequences correspond to words and\nsentences in natural languages, respectively. Based on this system-call language model, we can\nperform various tasks that comprise our algorithm to detect anomalous system-call sequences: e.g.,\nestimation of the relative likelihood of different words (i.e., system calls) and phrases (i.e., a window\nof system calls) in different contexts.\nOur speciÔ¨Åc contributions can be summarized as follows: First, to model sequences of system calls,\nwe propose a neural language modeling technique that utilizes long short-term memory (LSTM)\n(Hochreiter & Schmidhuber, 1997) units for enhanced long-range dependence learning. To the best\nof the authors‚Äô knowledge, the present work is the Ô¨Årst end-to-end framework to model system-call\nsequences as a natural language for effectively detecting anomalous patterns therefrom. 1 Second,\nto reduce false-alarm rates of anomaly-based intrusion detection, we propose a leaky rectiÔ¨Åed linear\nunits (ReLU) (Maas et al., 2013) based ensemble method that constructs an integrative classiÔ¨Åer\nusing multiple (relatively weak) thresholding classiÔ¨Åers. Each of the component classiÔ¨Åers is trained\nto detect different types of ‚Äòhighly normal‚Äô sequences (i.e., system call sequences with very high\nprobability of being normal), and our ensemble method blends them to produce a robust classiÔ¨Åer\nthat delivers signiÔ¨Åcantly lower false-alarm rates than other commonly used ensemble methods. As\nshown in Figure 1, these two aspects of our contributions can seamlessly be combined into a single\nframework. Note that the ensemble method we propose is not limited to our language-model based\nfront-end but also applicable to other types of front-ends.\nIn the rest of this paper, we will explain more details of our approach and then present our experi-\nmental results that demonstrate the effectiveness of our proposed method.\n1In the literature, there exists only one related example of LSTM-based intrusion detection system Staude-\nmeyer & Omlin (2013), which, however, was in essence a feature-based supervised classiÔ¨Åer (rather than an\nanomaly detector) requiring heavy annotation efforts to create labels. In addition, their approach was not an\nend-to-end framework and needed careful feature engineering to extract robust features for the classiÔ¨Åcation.\n2\nnormal training data \nquery sequence \nsystem call \nlanguage model \nùêøùêøùëÄùëÄ1 \nsystem call \nlanguage model \nùêøùêøùëÄùëÄ2 \nsystem call \nlanguage model \nùêøùêøùëÄùëÄùëöùëö \nthresholding \nclassifier ùê∂ùê∂ùëìùëì1 \nthresholding \nclassifier ùê∂ùê∂ùëìùëì2 \nthresholding \nclassifier ùê∂ùê∂ùëìùëìùëöùëö \nensemble \nclassifier ùê∂ùê∂ùëìùëìÃÖ \nnormal \nor \nabnormal \nFigure 1: Overview of the proposed method.\n(a) language model architecture (b) estimation of sequence probability\nembedding layer \nhidden layer \noutput layer \ninput layer ùüé ‚àô ‚àô ‚àô ùüéùüèùüé ‚àô‚àô‚àô ùüé\n‚ãØ\nùëÉ(ùë•1) ùëÉ(ùë•2|ùë•1) ùëÉ(ùë•3|ùë•1:2) ùëÉ(ùë•ùëõ|ùë•1:ùëõ‚àí1)\nùë•1\nfork\nùë•2\nsetgid\nùë•ùëõ‚àí1\nioctl\nùë•ùëõ\nclose\n[GO]\nFigure 2: System-call language model.\n2 P ROPOSED METHOD\nFigure 1 shows the overview of our proposed approach to designing an intrusion detection system.\nOur method consists of two parts: the front-end is for language modeling of system calls in various\nsettings, and the back-end is for anomaly prediction based on an ensemble of thresholding classiÔ¨Åers\nderived from the front-end. In this section, we describe details of each component in our pipeline.\n2.1 L ANGUAGE MODELING OF SYSTEM CALLS\nFigure 2 illustrates the architecture of our system-call language model. The system call language\nmodel estimates the probability distribution of the next call in a sequence given the sequence of\nprevious calls. We assume that the host system generates a Ô¨Ånite number of system calls. We index\neach system call by using an integer starting from 1 and denote the Ô¨Åxed set of all possible system\ncalls in the system as S = {1,¬∑¬∑¬∑ ,K}. Let x= x1x2 ¬∑¬∑¬∑xl(xi ‚ààS) denote a sequence of lsystem\ncalls.\nAt the input layer, the call at each time stepxi is fed into the model in the form of one-hot encoding,\nin other words, a K dimensional vector with all elements zero except position xi. At the embed-\nding layer, incoming calls are embedded to continuous space by multiplying embedding matrix W,\nwhich should be learned. At the hidden layer, the LSTM unit has an internal state, and this state\nis updated recurrently at each time step. At the output layer, a softmax activation function is used\nto produce the estimation of normalized probability values of possible calls coming next in the se-\nquence, P(xi|x1:i‚àí1). According to the chain rule, we can estimate the sequence probability by the\nfollowing formula:\nP(x) =\nl‚àè\ni=1\nP(xi|x1:i‚àí1) (1)\nGiven normal training system call sequence data, we can train this LSTM-based system call lan-\nguage model using the back-propagation through time (BPTT) algorithm. The training criterion\n3\nminimizes the cross-entropy loss, which is equivalent to maximizing the likelihood of the system\ncall sequence. A standard RNN often suffers from the vanishing/exploding gradient problem, and\nwhen training with BPTT, gradient values tend to blow up or vanish exponentially. This makes it\ndifÔ¨Åcult to learn long-term dependency in RNNs (Bengio et al., 1994). LSTM, a well-designed RNN\narchitecture component, is equipped with an explicit memory cell and tends to be more effective to\ncope with this problem, resulting in numerous successes in recent RNN applications.\nBecause typical processes in the system execute a long chain of system calls, the number of system\ncalls required to fully understand the meaning of a system-call sequence is quite large. In addi-\ntion, the system calls comprising a process are intertwined with each other in a complicated way.\nThe boundaries between system-call sequences are also vague. In this regard, learning long-term\ndependence is crucial for devising effective intrusion detection systems.\nMarkov chains and hidden Markov models are widely used probabilistic models that can estimate\nthe probability of the next call given a sequence of previous calls. There has been previous work on\nusing Markov models in intrusion detection systems (Hofmeyr et al., 1998; Hoang et al., 2003; Hu\net al., 2009; Yolacan et al., 2014). However, these methods have an inherent limitation in that the\nprobability of the next call is decided by only a Ô¨Ånite number of previous calls. Moreover, LSTM\ncan model exponentially more complex functions than Markov models by using continuous space\nrepresentations. This property alleviates the data sparsity issue that occurs when a large number of\nprevious states are used in Markov models. In short, the advantages of LSTM models compared to\nMarkov models are two folds: the ability to capture long-term dependency and enhanced expressive\npower.\nGiven a new query system-call sequence, on the assumption that abnormal call patterns deviate from\nlearned normal patterns, yielding signiÔ¨Åcantly lower probabilities than those of normal call patterns,\na sequence with an average negative log-likelihood above a threshold is classiÔ¨Åed as abnormal, while\na sequence with an average negative log-likelihood below the threshold is classiÔ¨Åed as normal. By\nchanging the threshold value, we can draw a receiver operating characteristic (ROC) curve, which\nis the most widely used measure to evaluate intrusion detection systems.\nCommonly, IDS is evaluated by the ROC curve rather than a single point corresponding to a speciÔ¨Åc\nthreshold on the curve. Sensitivity to the threshold is shown on the curve. The x-axis of the curve\nrepresents false alarm rates, and the y-axis of the curve represents detection rates. 2 If the threshold\nis too low, the IDS is able to detect attacks well, but users would be annoyed due to false alarms.\nConversely, if the threshold is too high, false alarm rates becomes lower, but it is easy for IDS to\nmiss attacks. ROC curves closer to (0,1) means a better classiÔ¨Åer (i.e., a better intrusion detection\nsystem). The area under curve (AUC) summarizes the ROC curve into a single value in the range\n[0,1] (Bradley, 1997).\n2.2 E NSEMBLE METHOD TO MINIMIZE FALSE ALARM RATES\nBuilding a ‚Äòstrong normal‚Äô model (a model representing system-call sequences with high probabil-\nities of being normal) is challenging because of over-Ô¨Åtting issues. In other words, a lower training\nloss does not necessarily imply better generalization performance. We can consider two reasons for\nencountering this issue.\nFirst, it is possible that only normal data were used for training the IDS without any attack data.\nLearning discriminative features that can separate normal call sequences from abnormal sequences\nis thus hard without seeing any abnormal sequences beforehand. This is a common obstacle for\nalmost every anomaly detection problem. In particular, malicious behaviors are frequently hidden\nand account for only a small part of all the system call sequences.\nSecond, in theory, we need a huge amount of data to cover all possible normal patterns to train the\nmodel satisfactorily. However, doing so is often impossible in a realistic situation because of the\ndiverse and dynamic nature of system call patterns. Gathering live system-call data is harder than\ngenerating synthetic system-call data. The generation of normal training data in an off-line setting\ncan create artifacts, because these data are made in Ô¨Åxed conditions for the sake of convenience in\ndata generation. This setting may cause normal patterns to have some bias.\n2A false alarm rate is the ratio of validation normal data classiÔ¨Åed as abnormal. A detection rate is the ratio\nof detected attacks in the real attack data.\n4\nAll these situations make it more difÔ¨Åcult to choose a good set of hyper-parameters for LSTM\narchitecture. To cope with this challenge, we propose a new ensemble method. Due to the lack\nof data, different models with different parameters capture slightly different normal patterns. If\nfunction f ‚ààS‚àó‚Ü¶‚ÜíR, which maps a system call sequence to a real value, is given, we can deÔ¨Åne a\nthresholding classiÔ¨Åer as follows:\nCf (x; Œ∏) =\n{normal for f(x) ‚â§Œ∏;\nabnormal otherwise. (2)\nMost of the intrusion detection algorithms, including our proposed method, employ a thresholding\nclassiÔ¨Åer. For the sake of explanation, we deÔ¨Åne a term ‚Äòhighly normal‚Äô sequence for the classiÔ¨Åer\nCf as a system call sequence having an extremely lowf value so it will be classiÔ¨Åed as normal even\nwhen the thresholdŒ∏is sufÔ¨Åciently low to discriminate true abnormals. Highly normal sequences are\nrepresented as a Ô¨Çat horizontal line near(1,1) in the ROC curve. The more the classiÔ¨Åer Ô¨Ånds highly\nnormal sequences, the longer this line is. Note that a highly normal sequence is closely related to\nthe false alarm rate.\nOur goal is to minimize the false alarm rate through the composition of multiple classiÔ¨Åers\nCf1 ,Cf2 ,...,C fm into a single classiÔ¨Åer Cf , resulting in accumulated ‚Äòhighly normal‚Äô data (here\nmis the number of classiÔ¨Åers used in the ensemble). This is due to the fact that a low false alarm\nrate is an important requisite in computer security, especially in intrusion detection systems. Our\nensemble method can be represented by a simple formula:\nf(x) =\nm‚àë\ni=1\nwiœÉ(fi(x) ‚àíbi). (3)\nAs activation function œÉ, we used a leaky ReLU function, namely œÉ(x) = max(x,0.001x). In-\ntuitively, the activation function forces potential ‚Äòhighly normal‚Äô sequences having f values lower\nthan bi to keep their low f values to the Ô¨Ånal f value. If we use the regular ReLU function instead,\nthe degree of ‚Äòhighly normal‚Äô sequences could not be differentiated. We set the bias term bi to the\nmedian of f values of the normal training data. In (3), wi indicates the importance of each classiÔ¨Åer\nfi. Because we do not know the performance of each classiÔ¨Åer before evaluation, we setwi to 1/m.\nMathematically, this appears to be a degenerated version of a one-layer neural network. The basic\nphilosophy of the ensemble method is that when the classiÔ¨Åcation results from various classiÔ¨Åers\nare slightly different, we can make a better decision by composing them well. Still, including bad\nclassiÔ¨Åers could degrade the overall performance. By choosing classiÔ¨Åers carefully, we can achieve\nsatisfactory results in practice, as will be shown in Section 3.2.\n2.3 B ASELINE CLASSIFIERS\nDeep neural networks are an excellent representation learning method. We exploit the sequence\nrepresentation learned from the Ô¨Ånal state vector of the LSTM layer after feeding all the sequences\nof calls. For comparison with our main classiÔ¨Åer, we use two baseline classiÔ¨Åers that are commonly\nused for anomaly detection exploiting vectors corresponding to each sequence: k-nearest neigh-\nbor (kNN) and k-means clustering (kMC). Examples of previous work for mapping sequences into\nvectors of Ô¨Åxed-dimensional hand-crafted features include normalized frequency and tf-idf (Liao &\nVemuri, 2002; Xie et al., 2014).\nLet T be a normal training set, and let lstm(x) denotes a learned representation of call sequence\nxfrom the LSTM layer. kNN classiÔ¨Åers search for k nearest neighbors in T of query sequence x\non the embedded space and measure the minimum radius to cover them all. The minimum radius\ng(x; k) is used to classify query sequence x. Alternatively, we can count the number of vectors\nwithin the Ô¨Åxed radius, g(x; r). In this paper, we used the former. Because the computational cost\nof a kNN classiÔ¨Åer is proportional to the size ofT, using a kNN classiÔ¨Åer would be intolerable when\n5\nthe normal training dataset becomes larger.\ng(x; k) = minr s.t.\n‚àë\ny‚ààT\n[\nd(lstm(x),lstm(y)) ‚â§r\n]\n‚â•k (4)\ng(x; r) = 1‚àí 1\n|T|\n‚àë\ny‚ààT\n[\nd(lstm(x),lstm(y)) ‚â§r\n]\n(5)\nThe kMC algorithm partitions T on the new vector space into kclusters G1,G2,...,G k in which\neach vector belongs to the cluster with the nearest mean so as to minimize the within-cluster sum\nof squares. They are computed by Lloyd‚Äôs algorithm and converge quickly to a local optimum.\nThe minimum distance from each center of clusters ¬µi, h(x; k), is used to classify the new query\nsequence.\nh(x; k) = min\ni=1,¬∑¬∑¬∑,k\nd(lstm(x),¬µi) (6)\nThe two classiÔ¨Åers Cg and Ch are closely related in that the kMC classiÔ¨Åer is equivalent to the\n1-nearest neighbor classiÔ¨Åer on the set of centers. In both cases of kNN and kMC, we need to\nchoose parameter k empirically, depending on the distribution of vectors. In addition, we need to\nchoose a distance metric on the embedding space; we used the Euclidean distance measure in our\nexperiments.\n3 E XPERIMENTAL RESULTS AND DISCUSSION\n3.1 D ATASETS\nThough system call traces themselves might be easy to acquire, collecting or generating a sufÔ¨Åcient\namount of meaningful traces for the evaluation of intrusion detection systems is a nontrivial task. In\norder to aid researchers in this regard, the following datasets were made publicly available from prior\nwork: ADFA-LD (Creech & Hu, 2013), KDD98 (Lippmann et al., 2000) and UNM (of New Mexico,\n2012). The KDD98 and UNM datasets were released in 1998 and 2004, respectively. Although these\ntwo received continued criticism about their applicability to modern systems (Brown et al., 2009;\nMcHugh, 2000; Tan & Maxion, 2003), we include them as the results would show how our model\nfares against early works in the Ô¨Åeld, which were mostly evaluated on these datasets. As the ADFA-\nLD dataset was generated around 2012 to reÔ¨Çect contemporary systems and attacks, we have done\nour evaluation mainly on this dataset.\nThe ADFA-LD dataset was captured on an x86 machine running Ubuntu 11.04 and consists of three\ngroups: normal training traces, normal validation traces, and attack traces. The KDD98 dataset was\naudited on a Solaris 2.5.1 server. We processed the audit data into system call traces per session.\nEach session trace was marked as normal or attack depending on the information provided in the\naccompanied bsm.list Ô¨Åle, which is available alongside the dataset. Among the UNM process\nset, we tested our model with lpr that was collected from SunOS 4.1.4 machines. We merged\nthe live lpr set and the synthetic lpr set. This combined dataset is further categorized into two\ngroups: normal traces and attack traces. To maintain consistency with ADFA-LD, we divided the\nnormal data of KDD98 and UNM into training and validation data in a ratio of 1:5, which is the\nratio of the ADFA-LD dataset. The numbers of system-call sequences in each dataset we used are\nsummarized in Table 1.\nTable 1: Summary of datasets used for experiments\nNormal Attack\nBenchmark # training # validation # type # attack\nADFA-LD 833 4372 6 746\nKDD98 1364 5459 10 41\nUNM-lpr 627 3136 1 2002\n6\n0 0.2 0.4 0.6 0.8 1\nFalse Alarm Rate\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nDetection Rate kNN\nkMC\nLSTM-200\nLSTM-400\nLSTM-400*2\n0 0.2 0.4 0.6 0.8 1\nFalse Alarm Rate\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nDetection Rate\nEnsemble-averaging\nEnsemble-voting\nEnsemble-proposed\nFigure 3: ROC curves from the ADFA-LD. Left shows the result from our three system-call language\nmodels with different parameters and two baseline classiÔ¨Åers. Right illustrates the results from\ndifferent ensemble methods.\n3.2 P ERFORMANCE EVALUATION\nWe used ADFA-LD and built three independent system-call language models by changing the hyper-\nparameters of the LSTM layer: (1) one layer with 200 cells, (2) one layer with 400 cells, and (3)\ntwo layers with 400 cells. We matched the number of cells and the dimension of the embedding\nvector. Our parameters were uniformly initialized in [‚àí0.1,0.1].For computational efÔ¨Åciency, we\nadjusted all system-call sequences in a mini-batch to be of similar lengths. We used the Adam\noptimizer (Kingma & Ba, 2014) for stochastic gradient descent with a learning rate of 0.0001. The\nnormalized gradient was rescaled whenever its norm exceeded 5 (Pascanu et al., 2013), and we used\ndropout (Srivastava et al., 2014) with probability 0.5. We show the ROC curves obtained from the\nexperiment in Figure 3.\nFor the two baseline classiÔ¨Åers, we used the Euclidean distance measure. Changing the distance\nmeasure to another metric did not perform well on average. In case of kNN, using k= 11achieved\nthe best performance empirically. For kMC, using k= 1gave the best performance. Increasing the\nvalue of kproduced similar but poorer results. We speculate the reason why a single cluster sufÔ¨Åces\nas follows: learned representation vectors of normal training sequence are symmetrically distributed.\nThe kNN classiÔ¨Åer Cg and the kMC classiÔ¨Åer Ch achieved similar performance. Compared to\nLiao & Vemuri (2002); Xie et al. (2014), our baseline classiÔ¨Åers easily returned ‚Äòhighly normal‚Äô\ncalls. This result was leveraged by the better representation obtained from the proposed system-call\nlanguage modeling.\nAs shown in the left plot of Figure 3, three LSTM classiÔ¨Åers performed better than Cg and Ch.\nWe assume that the three LSTM classiÔ¨Åers we trained are strong enough by themselves, and their\nclassiÔ¨Åcation results would be different from each other. By applying ensemble methods, we would\nexpect to improve the performance. The Ô¨Årst one was averaging, the second one was voting, and\nlastly we used our ensemble method as we explained in Section 2.2. The proposed ensemble method\ngave a better AUC value ( 0.928) with a large margin than that of the averaging ensemble method\n(0.890) and the voting ensemble method ( 0.859). Moreover, the curve obtained from the proposed\nensemble method was placed above individual single curves, while other ensemble methods did not\nshow this property.\nIn the setting of anomaly detection where attack data are unavailable, learning ensemble parame-\nters is infeasible. If we exploit partial attack data, the assumption breaks down and the zero-day\nattack issue remains. Our ensemble method is appealing in that it performs remarkably well without\nlearning.\nTo be clear, we applied ensemble methods to three LSTM classiÔ¨Åers learned independently using\ndifferent hyper-parameters, not with the baseline classiÔ¨Åers, Cg or Ch. Applying ensemble methods\nto each type of baseline classiÔ¨Åer gave unsatisfactory results since changing parameters or initial-\nization did not result in complementary and reasonable classiÔ¨Åers that were essential for ensemble\nmethods. Alternatively, we could do ensemble our LSTM classiÔ¨Åers and baseline classiÔ¨Åers to-\n7\n0 0.2 0.4 0.6 0.8 1\nFalse Alarm Rate\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nDetection Rate\nKDD98\n0 0.2 0.4 0.6 0.8 1\nFalse Alarm Rate\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nDetection Rate\nUNM\nfrom KDD98\nFigure 4: ROC curves from the KDD dataset and UNM dataset. Left is the evaluation about the\nKDD dataset. Right is the evaluation about UNM dataset using the model trained with the KDD98\ndataset and the UNM dataset.\ngether. However, this would also be a wrong idea because theirf values differ in scale. The value of\nf in our LSTM classiÔ¨Åer is an average negative log-likelihood, whereas gand hindicate distances\nin a continuous space.\nAccording to Creech & Hu (2014), the extreme learning machine (ELM) model, sequence time-\ndelay embedding (STIDE), and the hidden Markov model (HMM) (Forrest et al., 1996; Warrender\net al., 1999) achieved about 13%,23%,and42% false alarm rates (FAR) for 90% detection rate\n(DR), respectively. We achieved 16% FAR for 90% DR, which is comparable result with the result\nof ELM and outperforms STIDE and HMM. The ROC curves for ELM, HMM, and STIDE can be\nfound, but we could not draw those curves on the same plot with ours because the authors provided\nno speciÔ¨Åc data on their results. Creech & Hu (2014) classiÔ¨Åed ELM as a semantic approach and\nother two as syntactic approaches which treat each call as a basic unit. To be fair, our proposed\nmethod should be compared with those approaches that use system calls only as a basic unit in that\nwe watch the sequence call-by-call. Furthermore, our method is end-to-end while ELM relies on\nhand-crafted features.\n3.3 P ORTABILITY EVALUATION\nWe carried out experiments similar to those presented in Section 3.2 using the KDD98 dataset and\nthe UNM dataset. First, we trained our system-call language model with LSTM having one layer\nof 200 cells and built our classiÔ¨Åer using the normal training traces of the KDD98 dataset. The\nsame model was used to evaluate the UNM dataset to examine the portability of the LSTM models\ntrained with data from a different but similar system. The results of our experiments are represented\nin Figure 4. For comparison, we display the ROC curve of the UNM dataset by using the model\nfrom training the normal traces therein. To examine portability, the system calls in test datasets\nneed to be included or matched to those of training datasets. UNM was generated using an earlier\nversion of OS than that of KDD98, but ADFA-LD was audited on a fairly different OS. This made\nour experiments with other combinations difÔ¨Åcult.\nThrough a quantitative analysis, for the KDD98 dataset, we earned an almost perfect ROC curve\nwith an AUC value of0.994 and achieved 2.3% FAR for 100% DR. With the same model, we tested\nthe UNM datset and obtained a ROC curve with an AUC value of 0.969 and 5.5% FAR for 99.8%\nDR. This result was close to the result earned by using the model trained on normal training traces\nof the UNM dataset itself, as shown in the right plot of Figure 4.\nThis result is intriguing because it indicates that system-call language models have a strong portabil-\nity. In other words, after training one robust and extensive model, the model can then be deployed to\nother similar host systems. By doing so, we can mitigate the burden of training cost. This paradigm\nis closely related to the concept of transfer learning, or zero-shot learning. It is well known that\nneural networks can learn abstract features and that they can be used successfully for unseen data.\n8\n(a) (c)\n(b)\nFigure 5: 2-D embedding of learned call representations. (a) shows the full representation space of\nsystem calls that appeared in training data. (b) and (c) show the zoomed-in view of speciÔ¨Åc regions.\n3.4 V ISUALIZATION OF LEARNED REPRESENTATIONS\nIt is well-known that neural network based-language models can learn semantically meaningful\nembeddings to continuous space (Bengio et al., 2003; Mikolov et al., 2013; Cho et al., 2014). We\nexpected to see a similar characteristic with the proposed system-call language model. The 2D\nprojection of the calls using the embedding matrix W learned from the system-call language model\nwas done by t-SNE (Van der Maaten & Hinton, 2008) and shown in Figure 5. Just as the natural\nlanguage model, we can expect that calls having similar co-occurrence patterns are positioned in\nsimilar locations in the embedded space after training the system call language model. We can\nclearly see that calls having alike functionality are clustered with each other.\nThe Ô¨Årst obvious cluster would be the read-write call pair and the open-close pair. The calls of each\npair were located in close proximity in the space, meaning that our model learned to associate them\ntogether. At the same time, the difference between the calls of each pair appears to be almost the\nsame in the space, which in turn would mean our model learned that the relationship of each pair\nsomewhat resembles.\nAnother notable cluster would be the group of select, pselect6, ppoll, epoll wait and nanosleep.\nThe calls select, pselect6 and ppoll all have nearly identical functions in that they wait for some\nÔ¨Åle descriptors to become ready for some class of I/O operation or for signals. The other two calls\nalso have similar characteristics in that they wait for a certain event or signal as well. This could be\ninterpreted as our model learning that these ‚Äòwaiting‚Äô calls share similar characteristics.\nOther interesting groups would be: readlink and lstat64 which are calls related to symbolic links;\nfstatat64 and fstat64 which are calls related to stat calls using Ô¨Åle descriptors; pipe and pipe2 which\nare nearly identical and appear almost as one on the embedding layer. These cases show that our\nmodel is capable of learning similar characteristics among the great many system calls.\nSimilarly to the call representations, we expected that attack sequences with the same type would\ncluster to each other, and we tried to visualize them. However, for various reasons including the\n9\nlack of data, we were not able to observe this phenomenon. Taking the fact that detecting abnormal\npatterns from normal patterns well would be sufÔ¨Åciently hard into consideration, learning repre-\nsentation to separate different abnormal patterns with only seen normal patterns would also be an\nextremely difÔ¨Åcult task.\n4 C ONCLUSION\nOur main contributions for designing intrusion detection systems as described in this paper have two\nparts: the introduction of a system-call language modeling approach and a new ensemble method.\nTo the best of the authors‚Äô knowledge, our method is the Ô¨Årst to introduce the concept of a language\nmodel, especially using LSTM, to anomaly-based IDS. The system-call language model can capture\nthe semantic meaning of each call and its relation to other system calls. Moreover, we proposed an\ninnovative and simple ensemble method that can better Ô¨Åt to IDS design by focusing on lowering\nfalse alarm rates. We showed its outstanding performance by comparing it with existing state-of-the-\nart methods and demonstrated its robustness and generality by experiments on diverse benchmarks.\nAs discussed earlier, the proposed method also has excellent portability. In contrast to alternative\nmethods, our proposed method incurs signiÔ¨Åcant smaller training overhead because it does not need\nto build databases or dictionaries to keep a potentially exponential amount of patterns. Our method\nis compact and light in that the size of the space required to save parameters is small. The overall\ntraining and inference processes are also efÔ¨Åcient and fast, as our methods can be implemented using\nefÔ¨Åcient sequential matrix multiplications.\nAs part of our future work, we are planning to tackle the task of detecting elaborate contemporary\nattacks including mimicry attacks by more advanced methods. In addition, we are considering\ndesigning a new framework to build a robust model in on-line settings by collecting large-scale data\ngenerated from distributed environments. For optimization of the present work, we would be able\nto alter the structure of RNNs used in our system-call language model and ensemble algorithm.\nFinally, we anticipate that a hybrid method that combines signature-based approaches and feature\nengineering will allow us to create more accurate intrusion detection systems.\nACKNOWLEDGMENTS\nThis work was supported by BK21 Plus Project in 2016 (Electrical and Computer Engineering,\nSeoul National University).\nREFERENCES\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\nlearning to align and translate. arXiv preprint arXiv:1409.0473, 2014.\nYoshua Bengio, Patrice Simard, and Paolo Frasconi. Learning long-term dependencies with gradient\ndescent is difÔ¨Åcult. Neural Networks, IEEE Transactions on, 5(2):157‚Äì166, 1994.\nYoshua Bengio, R ¬¥ejean Ducharme, Pascal Vincent, and Christian Jauvin. A neural probabilistic\nlanguage model. In Journal of Machine Learning Research, 2003.\nAndrew P Bradley. The use of the area under the roc curve in the evaluation of machine learning\nalgorithms. Pattern recognition, 30(7):1145‚Äì1159, 1997.\nCarson Brown, Alex Cowperthwaite, Abdulrahman Hijazi, and Anil Somayaji. Analysis of the\n1999 darpa/lincoln laboratory ids evaluation data with netadhict. In Computational Intelligence\nfor Security and Defense Applications, 2009. CISDA 2009. IEEE Symposium on, pp. 1‚Äì7. IEEE,\n2009.\nKyunghyun Cho, Bart Van Merri¬®enboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Hol-\nger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder\nfor statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.\nGideon Creech and Jiankun Hu. Generation of a new ids test dataset: Time to retire the kdd collec-\ntion. In Wireless Communications and Networking Conference (WCNC), 2013 IEEE, pp. 4487‚Äì\n4492. IEEE, 2013.\n10\nGideon Creech and Jiankun Hu. A semantic approach to host-based intrusion detection systems\nusing contiguousand discontiguous system call patterns. Computers, IEEE Transactions on, 63\n(4):807‚Äì819, 2014.\nStephanie Forrest, Steven A Hofmeyr, Aniln Somayaji, and Thomas A Longstaff. A sense of self\nfor unix processes. In Security and Privacy, 1996. Proceedings., 1996 IEEE Symposium on, pp.\n120‚Äì128. IEEE, 1996.\nStephanie Forrest, Steven Hofmeyr, and Anil Somayaji. The evolution of system-call monitoring.\nIn Computer Security Applications Conference, 2008. ACSAC 2008. Annual, pp. 418‚Äì430. IEEE,\n2008.\nAlan Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. Speech recognition with deep recur-\nrent neural networks. In Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE Interna-\ntional Conference on, pp. 6645‚Äì6649. IEEE, 2013.\nKarl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa\nSuleyman, and Phil Blunsom. Teaching machines to read and comprehend. In Advances in\nNeural Information Processing Systems, pp. 1684‚Äì1692, 2015.\nXuan Dau Hoang, Jiankun Hu, and Peter Bertok. A multi-layer model for anomaly intrusion detec-\ntion using program sequences of system calls. In Proc. 11th IEEE Intl. Conf. Citeseer, 2003.\nSepp Hochreiter and J ¬®urgen Schmidhuber. Long short-term memory. Neural computation, 9(8):\n1735‚Äì1780, 1997.\nSteven A Hofmeyr, Stephanie Forrest, and Anil Somayaji. Intrusion detection using sequences of\nsystem calls. Journal of computer security, 6(3):151‚Äì180, 1998.\nJiankun Hu, Xinghuo Yu, Dong Qiu, and Hsiao-Hwa Chen. A simple and efÔ¨Åcient hidden markov\nmodel scheme for host-based anomaly intrusion detection. Network, IEEE, 23(1):42‚Äì47, 2009.\nRafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring the\nlimits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\nV Jyothsna, VV Rama Prasad, and K Munivara Prasad. A review of anomaly based intrusion detec-\ntion systems. International Journal of Computer Applications, 28(7):26‚Äì35, 2011.\nDiederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint\narXiv:1412.6980, 2014.\nYihua Liao and V Rao Vemuri. Using text categorization techniques for intrusion detection. In\nUSENIX Security Symposium, volume 12, pp. 51‚Äì59, 2002.\nRichard P Lippmann, David J Fried, Isaac Graf, Joshua W Haines, Kristopher R Kendall, David\nMcClung, Dan Weber, Seth E Webster, Dan Wyschogrod, Robert K Cunningham, et al. Evaluating\nintrusion detection systems: The 1998 darpa off-line intrusion detection evaluation. In DARPA\nInformation Survivability Conference and Exposition, 2000. DISCEX‚Äô00. Proceedings, volume 2,\npp. 12‚Äì26. IEEE, 2000.\nAndrew L Maas, Awni Y Hannun, and Andrew Y Ng. RectiÔ¨Åer nonlinearities improve neural net-\nwork acoustic models. In Proc. ICML, volume 30, 2013.\nJohn McHugh. Testing intrusion detection systems: a critique of the 1998 and 1999 darpa intrusion\ndetection system evaluations as performed by lincoln laboratory. ACM transactions on Informa-\ntion and system Security, 3(4):262‚Äì294, 2000.\nTomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. Linguistic regularities in continuous space word\nrepresentations. In NAACL-HLT, pp. 746‚Äì751, 2013.\nUniversity of New Mexico. Computer Immune Systems Data Sets.http://www.cs.unm.edu/\nÀúimmsec/systemcalls.htm, 2012. [Online].\n11\nRazvan Pascanu, Tomas Mikolov, and Yoshua Bengio. On the difÔ¨Åculty of training recurrent neural\nnetworks. In Proceedings of The 30th International Conference on Machine Learning, pp. 1310‚Äì\n1318, 2013.\nAlexander M Rush, Sumit Chopra, and Jason Weston. A neural attention model for abstractive\nsentence summarization. arXiv preprint arXiv:1509.00685, 2015.\nNitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.\nDropout: A simple way to prevent neural networks from overÔ¨Åtting. The Journal of Machine\nLearning Research, 15(1):1929‚Äì1958, 2014.\nRalf C Staudemeyer and Christian W Omlin. Evaluating performance of long short-term memory\nrecurrent neural networks on intrusion detection data. In Proceedings of the South African In-\nstitute for Computer Scientists and Information Technologists Conference, pp. 218‚Äì224. ACM,\n2013.\nKymie Tan and Roy A Maxion. Determining the operational limits of an anomaly-based intrusion\ndetector. Selected Areas in Communications, IEEE Journal on, 21(1):96‚Äì110, 2003.\nLaurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of Machine\nLearning Research, 9(2579-2605):85, 2008.\nChristina Warrender, Stephanie Forrest, and Barak Pearlmutter. Detecting intrusions using system\ncalls: Alternative data models. In Security and Privacy, 1999. Proceedings of the 1999 IEEE\nSymposium on, pp. 133‚Äì145. IEEE, 1999.\nMiao Xie, Jiankun Hu, Xinghuo Yu, and Elizabeth Chang. Evaluating host-based anomaly detec-\ntion systems: Application of the frequency-based algorithms to adfa-ld. In Network and System\nSecurity, pp. 542‚Äì549. Springer, 2014.\nEsra N Yolacan, Jennifer G Dy, and David R Kaeli. System call anomaly detection using multi-\nhmms. In Software Security and Reliability-Companion (SERE-C), 2014 IEEE Eighth Interna-\ntional Conference on, pp. 25‚Äì30. IEEE, 2014.\nWojciech Zaremba, Ilya Sutskever, and Oriol Vinyals. Recurrent neural network regularization.\narXiv preprint arXiv:1409.2329, 2014.\n12",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8376786708831787
    },
    {
      "name": "Intrusion detection system",
      "score": 0.829308032989502
    },
    {
      "name": "Software portability",
      "score": 0.768458366394043
    },
    {
      "name": "System call",
      "score": 0.7279752492904663
    },
    {
      "name": "Host (biology)",
      "score": 0.6953511834144592
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.6103981137275696
    },
    {
      "name": "Key (lock)",
      "score": 0.5403241515159607
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4894324839115143
    },
    {
      "name": "Data mining",
      "score": 0.4849886894226074
    },
    {
      "name": "Thresholding",
      "score": 0.4832366406917572
    },
    {
      "name": "Machine learning",
      "score": 0.46213406324386597
    },
    {
      "name": "Generalization",
      "score": 0.4595652222633362
    },
    {
      "name": "Language model",
      "score": 0.4453490972518921
    },
    {
      "name": "Anomaly detection",
      "score": 0.4446048140525818
    },
    {
      "name": "Computer security",
      "score": 0.19298601150512695
    },
    {
      "name": "Image (mathematics)",
      "score": 0.10914266109466553
    },
    {
      "name": "Programming language",
      "score": 0.08130306005477905
    },
    {
      "name": "Ecology",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 89
}