{
  "title": "bitsa_nlp@LT-EDI-ACL2022: Leveraging Pretrained Language Models for Detecting Homophobia and Transphobia in Social Media Comments",
  "url": "https://openalex.org/W4285108790",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4320562145",
      "name": "Vitthal Bhandari",
      "affiliations": [
        "Birla Institute of Technology and Science, Pilani"
      ]
    },
    {
      "id": "https://openalex.org/A2157285698",
      "name": "Poonam Goyal",
      "affiliations": [
        "Birla Institute of Technology and Science, Pilani"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3129770472",
    "https://openalex.org/W3185909895",
    "https://openalex.org/W3197986154",
    "https://openalex.org/W2971296908",
    "https://openalex.org/W3162734203",
    "https://openalex.org/W4210393123",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W3146997200",
    "https://openalex.org/W3154077674",
    "https://openalex.org/W3176798216",
    "https://openalex.org/W3099919888",
    "https://openalex.org/W3124917515",
    "https://openalex.org/W3197853995",
    "https://openalex.org/W3115903740",
    "https://openalex.org/W3197959470",
    "https://openalex.org/W3129651031",
    "https://openalex.org/W4287064135",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3115404050"
  ],
  "abstract": "Online social networks are ubiquitous and user-friendly. Nevertheless, it is vital to detect and moderate offensive content to maintain decency and empathy. However, mining social media texts is a complex task since users don't adhere to any fixed patterns. Comments can be written in any combination of languages and many of them may be low-resource.In this paper, we present our system for the LT-EDI shared task on detecting homophobia and transphobia in social media comments. We experiment with a number of monolingual and multilingual transformer based models such as mBERT along with a data augmentation technique for tackling class imbalance. Such pretrained large models have recently shown tremendous success on a variety of benchmark tasks in natural language processing. We observe their performance on a carefully annotated, real life dataset of YouTube comments in English as well as Tamil.Our submission achieved ranks 9, 6 and 3 with a macro-averaged F1-score of 0.42, 0.64 and 0.58 in the English, Tamil and Tamil-English subtasks respectively. The code for the system has been open sourced.",
  "full_text": "Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion, pages 149 - 154\nMay 27, 2022 ©2022 Association for Computational Linguistics\nbitsa_nlp@LT-EDI-ACL2022: Leveraging Pretrained Language Models for\nDetecting Homophobia and Transphobia in Social Media Comments\nVitthal Bhandari and Poonam Goyal\nBirla Institute of Technology and Science, Pilani, India\nf20170136p@alumni.bits-pilani.ac.in\npoonam@pilani.bits-pilani.ac.in\nAbstract\nOnline social networks are ubiquitous and user-\nfriendly. Nevertheless, it is vital to detect and\nmoderate offensive content to maintain decency\nand empathy. However, mining social media\ntexts is a complex task since users don’t adhere\nto any fixed patterns. Comments can be written\nin any combination of languages and many of\nthem may be low-resource.\nIn this paper, we present our system for the LT-\nEDI shared task on detecting homophobia and\ntransphobia in social media comments. We ex-\nperiment with a number of monolingual and\nmultilingual transformer based models such\nas mBERT along with a data augmentation\ntechnique for tackling class imbalance. Such\npretrained large models have recently shown\ntremendous success on a variety of benchmark\ntasks in natural language processing. We ob-\nserve their performance on a carefully anno-\ntated, real life dataset of YouTube comments in\nEnglish as well as Tamil.\nOur submission achieved ranks 9, 6 and 3 with\na macro-averaged F1-score of 0.42, 0.64 and\n0.58 in the English, Tamil and Tamil-English\nsubtasks respectively. The code for the system\nhas been open sourced1.\n1 Introduction\nTwenty first century social media has become the\nepicenter of polarized opinions, arguments, and\nclaims. The ease of information access not only\nbenefits fruitful discussions but also facilitates phe-\nnomena such as hate speech and cyber bullying.\nRecently organized workshops and shared tasks\nhave fostered discussions around detection of hate\nspeech, toxicity, misogyny, sexism, racism and abu-\nsive content (Zampieri et al., 2020; Mandl et al.,\n2020). While research in processing and classi-\nfying offensive language in social media is vast\n(Pamungkas et al., 2021), there is very little work\n1The code for this task is available at github.com/vitthal-\nbhandari/Homophobia-Transphobia-Detection.\non detecting sexual orientation discrimination in\nparticular. More so, compared to resource-rich\nlanguages such as English and Japanese, Indic lan-\nguages such as Tamil and Malayalam are scarce\nin well-annotated data. Although advancements\nin large multilingual models have promoted cross-\nlingual transfer learning in Indic languages (Dowla-\ngar and Mamidi, 2021), there have not been any\nvisible attempts to censor homophobia and trans-\nphobia. The perception of the subject matter as\nbeing taboo prohibits advancements in data collec-\ntion, annotation and analysis.\nCurbing sensitive online content is imperative\nfor preventing harm to mental health of the commu-\nnity as well as avoiding divide between minorities.\nThese reasons have contributed towards the need of\nmoderating social media comments spreading any\nform of hatred towards the LGBTQIA+ population.\nWhile both - the detection of homopho-\nbia/transphobia and the corresponding research in\nIndic languages - is underserved and low-resource,\nanother factor contributing to the difficulty in pro-\ncessing social media texts is code-mixing - a phe-\nnomena in which multilingual speakers switch be-\ntween two or more languages in a conversation with\nthe aim to be more expressive. Popular language\nmodels tend to perform adversely when applied to\ncode-mixed text and hence newer techniques need\nto be adopted to handle this situation (Do ˘gruöz\net al., 2021).\nThe pretraining and fine-tuning paradigm has\ntaken extensive advantage of transformer based\nlarge multilingual models which perform well in\ncross-lingual scenarios. In this paper we explore\nthe performance of a number of such models when\nfine-tuned on a dataset for detecting homophobia\nand transphobia. Surprisingly, our experiments\nalso show that these multilingual models exhibit\nreasonably accurate performance on code-mixing\ntasks, even without any previous exposure to code-\nmixing during pretraining.\n149\nThe remainder of the paper is organized as fol-\nlows: Section 2 talks about the previous related\nwork in this domain. Section 3 gives a detailed\nexplanation of the methods used in the system and\nSection 4 describes the corresponding experimental\nsettings. We mention the detailed results in Sec-\ntion 5, conduct an ablation study in Section 6 and\nconclude our discussion with Section 7.\n2 Related Work\nTo the best of our knowledge no prior work iden-\ntifying either homophobia or transphobia directly\nexists in recent literature. However, offensive lan-\nguage detection, in general, in Dravidian languages\nhas been the focus of multiple research works in\nthe past (Chakravarthi et al., 2021a; Mandl et al.,\n2020).\nBaruah et al. (2021) at HASOC-Dravidian-\nCodeMix-FIRE2020 trained an SVM classifier us-\ning TF-IDF features on code-mixed Malayalam text\nand an XLM-RoBERTa based classifier on code-\nmixed Tamil text to detect offensive language in\nTwitter and YouTube comments. Sai and Sharma\n(2020) fine-tuned multilingual transformer models\nand used a bagging ensemble strategy to combine\npredictions on the same task.\nSaha et al. (2021) developed fusion models by\nensembling CNNs trained on skip-gram word vec-\ntors using FastText along with fine-tuned BERT\nmodels. A neural classification head was trained\non the concatenated output obtained from the en-\nsemble.\nA number of approaches have been deployed to\ntackle code mixing in Indic languages as well, since\nmultilingual transformer models lack the com-\nplexity to extract linguistic features directly from\ncode switched text. Vasantharajan and Thayasi-\nvam (2021) used a selective translation and translit-\neration technique to process Tamil code-mixed\nYouTube comments for offensive language iden-\ntification. They converted code-mixed text to na-\ntive Tamil script by translating English words and\ntransliterating romainzed Tamil words. Similar\ntechnique was used by Upadhyay et al. (2021) and\nSrinivasan (2020).\n3 Methodology\nThis shared task was formulated as a multiclass\nclassification problem where the model should be\nable to predict the existence of any form of homo-\nphobia or transphobia in a YouTube comment. The\nentire pipeline consists of two main components\n- a classification head on top of different popular\nmodels based on the transformer architecture, and\na data augmentation technique for oversampling\nthe English dataset. These components have been\nexplained in further detail ahead.\n3.1 Transformer-based Models\nSince its introduction in 2017, the Transformer ar-\nchitecture and its variants have set a new state of the\nart across several NLP tasks. Various pre-trained\nlanguage models (PLMs) based on the Transformer\narchitecture were experimented with in this task as\nmentioned below.\nBERT (bert-base-uncased) uses the en-\ncoder part of the Transformer architecture and\nhas been pretrained on the Book Corpus and En-\nglish Wikipedia using a masked language modeling\n(MLM) and next sentence prediction (NSP) objec-\ntive (Devlin et al., 2018).\nmBERT or multilingual BERT\n(bert-base-multilingual-cased) is\na BERT model that has been pretrained on 104\nlanguages across Wikipedia and has shown\nsurprisingly good cross-lingual performance on\nseveral NLP tasks.\nXLM-RoBERTa(xlm-roberta-base) has\nbeen pretrained on 2.5TB of massive multilingual\ndata using the MLM objective. It beat mBERT on\nvarious cross-lingual benchmarks (Conneau et al.,\n2019).\nIndicBERT is pretrained on a large-scale cor-\npora of 12 Indian languages. It outperforms\nmBERT and XLM-RoBERTa on a number of tasks,\nwhile having 10 times fewer parameters to train\n(Kakwani et al., 2020).\nHateBERT is obtained by re-training BERT on\nRAL-E, a large-scale dataset of reddit comments\nfrom banned communities. It outperforms BERT\non three English datasets for offensive, abusive\nlanguage and hate speech detection tasks. (Caselli\net al., 2021).\n3.2 Data Augmentation\nData augmentation is an important technique to\nbuild robust and more generalizable models. There\nare a number of techniques in NLP, each suitable\nto a certain task that can be used to augment the\ndata (Feng et al., 2021).\nFor this task (in English), Surface Form Alter-\nation as exhibited by Easy Data Augmentation\n(EDA) was utilized (Wei and Zou, 2019). EDA\n150\nClass English Tamil Tamil-English\nTrain Dev Test Train Dev Test Train Dev Test\nHomophobic 157 58 61 485 103 135 311 66 88\nTransphobic 6 2 5 155 37 41 112 38 34\nNon-anti-LGBT+ content 3001 732 924 2022 526 657 3438 862 1085\nTotal 4946 4161 6034\nTable 1: Detailed split of the multilingual dataset of YouTube comments\nproduces new data samples by randomly deleting,\ninserting or swapping the order of words in a sen-\ntence. It can also perform synonym replacement\nfor any word selected at random. These four sim-\nple, yet effective, operations make EDA easy to\nuse.\n4 Experimental Setup\nIn this section we review the setup needed to repro-\nduce the experiments.\n4.1 Datasets\nThe dataset for the task was provided by the orga-\nnizers (Chakravarthi et al., 2021b). It is a collection\nof 15,141 multilingual YouTube comments classi-\nfied as being one of Homophobic, Transphobic, or\nNon-anti-LGBT+ content. The split of the dataset\nis shown in Table 1.\n4.2 Preprocessing\nTwo different preprocessing methods were adopted.\nFirst, punctuation symbols were removed, since so-\ncial media comments are highly informal and tend\nto contain large number of punctuation symbols\nwhich may dilute the system performance.\nIn addition, de-emojification was carried out to\nreplace emojis in the text with corresponding En-\nglish expressions using the Python emoji pack-\nage. Table 2 displays a sample de-emojification\nexample.\nI love it\ni love it growing heart growing heart growing heart\nTable 2: Depiction of de-emojification on a sample\nEnglish YouTube comment\n4.3 EDA Parameters\nAs is visible from Table 1, the dataset is highly\nimbalanced in its split. The Homophobia class con-\nstitutes slightly less than 10% of the data, while\nonly 2.9% comments were labeled as being Trans-\nphobic. Hence both these classes were subject to\noversampling by means of EDA. The class Non-\nanti-LGBT+ content was downsampled to mitigate\nthe imbalance.\nAugmentation was only applied to English com-\nments.\nThe parameter α(indicating the percent of words\nin a sentence that are changed) was kept as default\n(= 0.1). However the argument naug (specifying\nthe number of augmentations to be produced for\neach sample) was chosen to be 16 and 32 for Ho-\nmophobia and Transphobia classes respectively.\nGT I have to experience like that. So sad\nRD i to experience like so sad\nSR i have to experience like that so pitiful\nRI i have to experience like that distressing so sad\nRS experience have to i like that so sad\nTable 3: Depiction of data augmentation on a sample\nEnglish YouTube comment. GT: ground truth, RD: ran-\ndom deletion, SR: synonym replacement, RI: random\ninsertion, RS: random swapping\nThe final classwise split of the training data is\nshown in Table 4.\nClass Final size\nHomophobic 2826\nTransphobic 204\nNon-anti-LGBT+ content 1500\nTable 4: Classwise split of the training data after EDA\naugmentation\n4.4 Baseline Methods\nWe provide baselines for all three tracks based on\na simple feature extraction approach.\nWe use the [CLS] token associated with the fi-\nnal hidden state of the transformer model as feature\nvector for a linear regression classifier.\nTo extract the hidden state from the checkpoint,\nwe use BERT base model for the English track and\nmBERT for the other tracks.\n151\n4.5 Setup\nThe experiments were run on a Google Colab Pro\nnotebook with Tesla P100 GPU.\nFor the all tasks, the maximum sequence length\nwas set to 128 and batch size to 32. The learning\nrate and the number of epochs were set to 2e−5\nand 3 respectively for the English and Tamil track\nand 3e−5 and 5 respectively for the code-mixed\ntrack. The choice of EDA parameters was based\non suggestions given in the original paper whereas\nthe model hyperparameters were selected based on\npopular successful configurations.\n5 Results\nThe metric used to rank system performances is\nmacro-averaged F1-score. It is calculated as the\n(unweighted) arithmetic mean of all the per-class\nF1-scores.\nMacro-averaged F1-score = 1\nN\nN∑\ni=1\nF1i\nwhere iis the class index and N is the number\nof classes\nTables 5, 7 and 9 list the macro-averaged Preci-\nsion, macro-averaged Recall and macro-averaged\nF1-score for various PLMs tested on English,\nTamil and code-mixed Tamil-English development\ndataset respectively.\nSimilarly Tables 6, 8 and 10 list the correspond-\ning metrics achieved by the final submissions on\nEnglish, Tamil and Tamil-English test dataset as\nreleased by the organizers.\nThe tables also provide baseline metrics for each\ntrack based on the method explained in Section 4.4.\n5.1 English\nModel P R F1\nBERT embeddings + LR 0.40 0.47 0.42\nBERT base cased 0.46 0.46 0.461\nXLM-RoBERTa 0.49 0.40 0.42\nhateBERT 0.50 0.44 0.461\nmBERT 0.48 0.45 0.462\nTable 5: Performance of various PLMs on augmented,\npreprocessed English development dataset\n5.2 Tamil\nHere we investigate the performance of some popu-\nlar multilingual models that were trained on Tamil\nlanguage.\nModel P R F1\nmBERT 0.43 0.42 0.42\nTable 6: Performance of best peforming system\n(mBERT) on preprocessed English test dataset\nModel P R F1\nmBERT embeddings + LR 0.71 0.59 0.63\nIndicBERT 0.48 0.47 0.47\nXLM-RoBERTa 0.47 0.55 0.50\nmBERT 0.77 0.71 0.72\nTable 7: Performance of various PLMs on preprocessed\nTamil development dataset\nModel P R F1\nmBERT 0.69 0.61 0.64\nTable 8: Performance of best peforming system\n(mBERT) on preprocessed Tamil test dataset\n5.3 Tamil-English\nFor the code-mixed task, we analyze the perfor-\nmance of the same set of multilingual models that\nwere experimented with on the Tamil task.\nModel P R F1\nmBERT embeddings + LR 0.61 0.47 0.51\nIndicBERT 0.39 0.41 0.40\nXLM-RoBERTa 0.40 0.43 0.41\nmBERT 0.67 0.52 0.54\nTable 9: Performance of various PLMs on preprocessed\nTamil-English development dataset\nModel P R F1\nmBERT 0.61 0.56 0.58\nTable 10: Performance of best peforming system\n(mBERT) on preprocessed Tamil-English test dataset\n6 Ablation Study\nIn this section we discuss the effect of preprocess-\ning and data augmentation (DA) on the model per-\nformance.\nThe dataset as described in Section 4.4 is highly\nskewed towards theNon-anti-LGBT+ contentclass.\nHence it makes sense to compare the performance\nof a majority classifier with that of the models sub-\nmitted for evaluation.\nWe train a dummy classifier based on most-\nfrequent strategy and tabulate the results (macro-\n152\naveraged Precision, Recall and F1-score) in Ta-\nble 11. We deliberately use the un-augmented ver-\nsion of preprocessed English dataset to show the\nshow the performance of the majority classifier\nwithout handling class imbalance.\nP R F1\nEnglish 0.31 0.33 0.32\nTamil 0.26 0.33 0.29\nCode-mixed 0.30 0.33 0.31\nTable 11: Performance of dummy majority classifier on\nthe dataset\nThe poor performance is a consequence of the\nextreme class imbalance which we aim to solve by\ndata augmentation. However, not all DA techniques\nprove to be effective for all NLP tasks. Thus we\nalso analyze the effect of preprocessing and DA on\nthe performance of transformer models.\nTable 12 analyzes the efficacy of EDA as a DA\ntechnique for handling class imbalance in our En-\nglish dataset. It also divides a line between the\nperformance of the model on the stock dataset v/s\none that has been preprocessed.\nSetting P R F1 Rel.\nEnglish\nbase 0.52 0.40 0.43\n+PRE 0.40 0.43 0.41 ↓\n+DA 0.52 0.37 0.39 ↓\nTamil\nbase 0.73 0.75 0.74\n+PRE 0.70 0.73 0.72 ↓\nCode-mixed\nbase 0.43 0.42 0.43\n+PRE 0.71 0.56 0.60 ↑\nTable 12: Performance of mBERT on the stock version\nof the dataset as it is (base), preprocessed dataset (+PRE)\nand augmented but non-preprocessed English dataset\n(+DA)\nWe observe that preprocessing (de-emojification\nin all three tracks and de-punctuation in the case of\nonly English) does not increase the macro-averaged\nF1 score for English and Tamil. Infact it reduces the\nscore by a small margin. However, we notice a sig-\nnificant improvement in the case of code-mixing.\nWe also observe that EDA is not an efficient DA\ntechnique as it fails to handle the class imbalance.\nTransformer models were able to successfully pre-\ndict with higher precision and recall in the absence\nof any augmentation and with limited samples.\n7 Conclusion and Future Work\nHomophobia and transphobia have not been the\nfocus of many umbrella hate speech detection\ntasks. We examined the ability of pretrained large\ntransformer-based models to detect homophobia\nand transphobia in a corpus of YouTube comments\nwritten in English and Tamil. Experimental results\ndemonstrated that multilingual BERT performed\nthe best on both language tasks, and the code-mixed\ntask as well, without being exposed to any code-\nmixing beforehand. This can be attributed to its\ncapability for zero-shot cross-lingual transfer when\nfine-tuned on downstream tasks.\nFrom Section 6 we also observed that the ef-\nfect of preprocessing was largely dependent on\nthe choice of language setting. This makes sense\nconsidering the difference in underlying language\nconstructs. Tamil, for instance, does not make use\nof standard English-based punctuation marks. On\nthe other hand, we conclude that the choice of an ef-\nfective DA techniqe depends on the underlying task\nand the data source. Social media data often lacks\nlinguistic purism and hence, token perturbations\nsuch as those introduced by EDA did not help.\nIn the future, we would like to adopt a more\naggressive DA technique such as that involving text\ngeneration (text In-filling, generating typos) or an\nauxilliary dataset (kNN, LM decoding). We would\nalso like to evaluate the effect of translation and\ntransliteration on code-mixed text classification.\nAcknowledgments\nWe would like to acknowledge the efforts of the\nworkshop organizers in effecting positive social\nchange through AI by conducting such shared tasks.\nWe also thank the reviewers for their time and in-\nsightful comments.\nReferences\nArup Baruah, Kaushik Amar Das, Ferdous Ahmed Barb-\nhuiya, and Kuntal Dey. 2021. Iiitg-adbu@ hasoc-\ndravidian-codemix-fire2020: Offensive content de-\ntection in code-mixed dravidian text. arXiv preprint\narXiv:2107.14336.\nTommaso Caselli, Valerio Basile, Jelena Mitrovi´c, and\nMichael Granitzer. 2021. HateBERT: Retraining\nBERT for abusive language detection in English. In\nProceedings of the 5th Workshop on Online Abuse\nand Harms (WOAH 2021), pages 17–25, Online. As-\nsociation for Computational Linguistics.\n153\nBharathi Raja Chakravarthi, Ruba Priyadharshini,\nNavya Jose, Anand Kumar M, Thomas Mandl,\nPrasanna Kumar Kumaresan, Rahul Ponnusamy, Har-\niharan R L, John P. McCrae, and Elizabeth Sherly.\n2021a. Findings of the shared task on offensive\nlanguage identification in Tamil, Malayalam, and\nKannada. In Proceedings of the First Workshop on\nSpeech and Language Technologies for Dravidian\nLanguages, pages 133–145, Kyiv. Association for\nComputational Linguistics.\nBharathi Raja Chakravarthi, Ruba Priyadharshini, Rahul\nPonnusamy, Prasanna Kumar Kumaresan, Kayalvizhi\nSampath, D. Thenmozhi, S. Thangasamy, Rajen-\ndran Nallathambi, and John P. McCrae. 2021b.\nDataset for identification of homophobia and tran-\nsophobia in multilingual youtube comments. ArXiv,\nabs/2109.00227.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2019. Unsupervised\ncross-lingual representation learning at scale. arXiv\npreprint arXiv:1911.02116.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. BERT: pre-training of\ndeep bidirectional transformers for language under-\nstanding. CoRR, abs/1810.04805.\nA. Seza Do ˘gruöz, Sunayana Sitaram, Barbara E. Bul-\nlock, and Almeida Jacqueline Toribio. 2021. A sur-\nvey of code-switching: Linguistic and social per-\nspectives for language technologies. In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 1654–1666, Online.\nAssociation for Computational Linguistics.\nSuman Dowlagar and Radhika Mamidi. 2021. A sur-\nvey of recent neural network models on code-mixed\nindian hate speech data. In Forum for Information\nRetrieval Evaluation, FIRE 2021, page 67–74, New\nYork, NY , USA. Association for Computing Machin-\nery.\nSteven Y Feng, Varun Gangal, Jason Wei, Sarath Chan-\ndar, Soroush V osoughi, Teruko Mitamura, and Ed-\nuard Hovy. 2021. A survey of data augmentation ap-\nproaches for nlp. arXiv preprint arXiv:2105.03075.\nDivyanshu Kakwani, Anoop Kunchukuttan, Satish\nGolla, Gokul N.C., Avik Bhattacharyya, Mitesh M.\nKhapra, and Pratyush Kumar. 2020. IndicNLPSuite:\nMonolingual corpora, evaluation benchmarks and\npre-trained multilingual language models for Indian\nlanguages. In Findings of the Association for Com-\nputational Linguistics: EMNLP 2020, pages 4948–\n4961, Online. Association for Computational Lin-\nguistics.\nThomas Mandl, Sandip Modha, Anand Kumar M, and\nBharathi Raja Chakravarthi. 2020. Overview of the\nhasoc track at fire 2020: Hate speech and offensive\nlanguage identification in tamil, malayalam, hindi,\nenglish and german. In Forum for Information Re-\ntrieval Evaluation, FIRE 2020, page 29–32, New\nYork, NY , USA. Association for Computing Machin-\nery.\nEndang Wahyu Pamungkas, Valerio Basile, and Viviana\nPatti. 2021. Towards multidomain and multilingual\nabusive language detection: a survey. Personal and\nUbiquitous Computing.\nDebjoy Saha, Naman Paharia, Debajit Chakraborty, Pun-\nyajoy Saha, and Animesh Mukherjee. 2021. Hate-\nalert@DravidianLangTech-EACL2021: Ensembling\nstrategies for transformer-based offensive language\ndetection. In Proceedings of the First Workshop on\nSpeech and Language Technologies for Dravidian\nLanguages, pages 270–276, Kyiv. Association for\nComputational Linguistics.\nSiva Sai and Yashvardhan Sharma. 2020. Siva@ hasoc-\ndravidian-codemix-fire-2020: Multilingual offensive\nspeech detection in code-mixed and romanized text.\nIn FIRE (Working Notes), pages 336–343.\nAnirudh Srinivasan. 2020. MSR India at SemEval-2020\ntask 9: Multilingual models can do code-mixing\ntoo. In Proceedings of the Fourteenth Workshop\non Semantic Evaluation, pages 951–956, Barcelona\n(online). International Committee for Computational\nLinguistics.\nIshan Sanjeev Upadhyay, Nikhil E, Anshul Wadhawan,\nand Radhika Mamidi. 2021. Hopeful men@LT-\nEDI-EACL2021: Hope speech detection using in-\ndic transliteration and transformers. In Proceedings\nof the First Workshop on Language Technology for\nEquality, Diversity and Inclusion, pages 157–163,\nKyiv. Association for Computational Linguistics.\nCharangan Vasantharajan and Uthayasanker Thayasi-\nvam. 2021. Towards offensive language identifica-\ntion for tamil code-mixed youtube comments and\nposts. SN Computer Science, 3(1).\nJason Wei and Kai Zou. 2019. EDA: Easy data augmen-\ntation techniques for boosting performance on text\nclassification tasks. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP), pages 6383–6389, Hong Kong, China. As-\nsociation for Computational Linguistics.\nMarcos Zampieri, Preslav Nakov, Sara Rosenthal, Pepa\nAtanasova, Georgi Karadzhov, Hamdy Mubarak,\nLeon Derczynski, Zeses Pitenis, and Ça˘grı Çöltekin.\n2020. SemEval-2020 task 12: Multilingual offensive\nlanguage identification in social media (OffensEval\n2020). In Proceedings of the Fourteenth Workshop on\nSemantic Evaluation, pages 1425–1447, Barcelona\n(online). International Committee for Computational\nLinguistics.\n154",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8011529445648193
    },
    {
      "name": "Tamil",
      "score": 0.6847148537635803
    },
    {
      "name": "Social media",
      "score": 0.6819454431533813
    },
    {
      "name": "Natural language processing",
      "score": 0.6563959121704102
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6527984142303467
    },
    {
      "name": "Task (project management)",
      "score": 0.4448089897632599
    },
    {
      "name": "Language model",
      "score": 0.41399139165878296
    },
    {
      "name": "World Wide Web",
      "score": 0.3474184274673462
    },
    {
      "name": "Linguistics",
      "score": 0.16846370697021484
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    }
  ]
}