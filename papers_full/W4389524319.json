{
  "title": "SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting",
  "url": "https://openalex.org/W4389524319",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2096489618",
      "name": "Xiaoying Zhang",
      "affiliations": [
        "Chinese University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2596235521",
      "name": "Peng Baolin",
      "affiliations": [
        "Tencent (China)",
        "Bellevue Hospital Center"
      ]
    },
    {
      "id": "https://openalex.org/A2108457298",
      "name": "Kun Li",
      "affiliations": [
        "Chinese University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2100485844",
      "name": "Jingyan Zhou",
      "affiliations": [
        "Chinese University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A2011510006",
      "name": "Helen Meng",
      "affiliations": [
        "Chinese University of Hong Kong"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4389009523",
    "https://openalex.org/W3167539758",
    "https://openalex.org/W4226226396",
    "https://openalex.org/W3173154122",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W4294092922",
    "https://openalex.org/W3209373246",
    "https://openalex.org/W4306803097",
    "https://openalex.org/W4287599851",
    "https://openalex.org/W4312609624",
    "https://openalex.org/W3037252712",
    "https://openalex.org/W3172943453",
    "https://openalex.org/W3189817881",
    "https://openalex.org/W3034284249",
    "https://openalex.org/W2951088751",
    "https://openalex.org/W4404782964",
    "https://openalex.org/W4321854923",
    "https://openalex.org/W4389009536",
    "https://openalex.org/W2945475330",
    "https://openalex.org/W2962934384",
    "https://openalex.org/W4385572953",
    "https://openalex.org/W4300513200",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W3206345746",
    "https://openalex.org/W2787291671",
    "https://openalex.org/W225503657",
    "https://openalex.org/W4385572845",
    "https://openalex.org/W4389009556",
    "https://openalex.org/W2964006684",
    "https://openalex.org/W2951980657",
    "https://openalex.org/W4365601361",
    "https://openalex.org/W3168491067",
    "https://openalex.org/W2997108628",
    "https://openalex.org/W4287795696",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3167277949",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4287084089",
    "https://openalex.org/W4322718421",
    "https://openalex.org/W3094447228",
    "https://openalex.org/W4389519177",
    "https://openalex.org/W3045703328",
    "https://openalex.org/W2997771882",
    "https://openalex.org/W4389523957",
    "https://openalex.org/W4206496297",
    "https://openalex.org/W4297783677",
    "https://openalex.org/W3177813494",
    "https://openalex.org/W3100995786",
    "https://openalex.org/W3122241445",
    "https://openalex.org/W4385574182",
    "https://openalex.org/W2936695845",
    "https://openalex.org/W4283026156",
    "https://openalex.org/W4388626886"
  ],
  "abstract": "Building and maintaining end-to-end task bots using minimal human effort is a long-standing challenge in dialog research. In this work, we introduce SGP-TOD, Schema-Guided Prompting for building Task-Oriented Dialog systems effortlessly based on large language models (LLMs). Utilizing the predefined task schema, i.e., belief instruction and dialog policy, we instruct fixed LLMs to generate appropriate responses on novel tasks, without the need for training data. Specifically, SGP-TOD comprises three components: an LLM for interacting with users, a Dialog State Tracking (DST) Prompter to aid the LLM in tracking dialog states with the given belief instruction, and a Policy Prompter to direct the LLM to generate proper responses adhering to the provided dialog policy. Experimental results on Multiwoz, RADDLE, and STAR datasets show that our training-free strategy, SGP-TOD, yields state-of-the-art (SOTA) zero-shot performance, significantly surpassing the few-shot approaches. In a domain-extension setting, SGP-TOD aptly adapts to new functionalities by merely adding supplementary schema rules. We make our code and data publicly available.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 13348–13369\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nSGP-TOD: Building Task Bots Effortlessly via\nSchema-Guided LLM Prompting\nXiaoying Zhang1, Baolin Peng2, Kun Li1, Jingyan Zhou1, Helen Meng1,3\n1The Chinese University of Hong Kong, Hong Kong\n2Tencent AI Lab, Bellevue\n3Centre for Perceptual and Interactive Intelligence, Hong Kong\n{zhangxy, kunli, jyzhou, hmmeng}@se.cuhk.edu.hk\n{baolinpeng}@global.tencent.com\nAbstract\nBuilding and maintaining end-to-end task\nbots using minimal human effort is a long-\nstanding challenge in dialog research. In\nthis work, we introduce SGP-TOD , S¯chema-\nG¯ uided P¯rompting for building T¯ ask-O¯ riented\nD¯ ialog systems effortlessly based on large lan-\nguage models (LLMs). Utilizing the predefined\ntask schema, i.e., belief instruction and dialog\npolicy, we instruct fixed LLMs to generate ap-\npropriate responses on novel tasks, without the\nneed for training data. Specifically, SGP-TOD\ncomprises three components: an LLM for in-\nteracting with users, a Dialog State Tracking\n(DST) Prompter to aid the LLM in tracking dia-\nlog states with the given belief instruction, and\na Policy Prompter to direct the LLM to generate\nproper responses adhering to the provided dia-\nlog policy. Experimental results on Multiwoz,\nRADDLE, and STAR datasets show that our\ntraining-free strategy, SGP-TOD , yields state-\nof-the-art (SOTA) zero-shot performance, sig-\nnificantly surpassing the few-shot approaches.\nIn a domain-extension setting,SGP-TOD aptly\nadapts to new functionalities by merely adding\nsupplementary schema rules. We make our\ncode and data publicly available.1\n1 Introduction\nBuilding task-oriented dialog (TOD) systems has\nbeen a long-standing challenge in artificial intelli-\ngence. The prevailing approach for creating task\nbots (Hosseini-Asl et al., 2020; Peng et al., 2021a;\nSun et al., 2022) is to fine-tune pre-trained language\nmodels (PLMs), such as T5 (Raffel et al., 2020) and\nGPT-2 (Radford et al., 2019). Despite their great\nsuccess, developing and maintaining such task bots\ngenerally requires adequate annotated data and ex-\ntensive fine-tuning/re-training.\nRecently, large Language Models (LLMs), such\nas ChatGPT (OpenAI, 2022) and GPT-4 (OpenAI,\n1https://github.com/zhangxy-2019/sgp-tod\nUser:  I am looking for a restaurant with moderate  price range\nserving modern European  food. \nLLM\nDialog  Policy\nDatabase\nSystem:  I have at least 2 choices, do you have a preferred area ? \nI need a restaurant that\nserves [value_food]\nfood.  \nRequest price range\nY es\nNo\nPreferred\narea?\nRecommend\nrestaurant\nRequest area\nY es\nPreferred\nprice range?\nNo\nDST  Prompter\nrestaurant  name = pizza hut city , golden wok,\netc.; food = dont care, chinese, british, etc.;\npricerange = dontcare, cheap, moderate,\nexpensive; area =  ...\nBelief Instruction\nT ask Schema\nPolicy Prompter\nSQL:  select *\nfrom restaurant where\npricerange = moderate;\nfood = modern\nEuropean\nDB:  Restaurant\ntwo match\nAction:  restaurant\n(inform (choices),\nrequest (area))\nFigure 1: The proposed SGP-TOD is depicted with a\ndialog example, where the prompters integrate the task\nschema (right) to assist the frozen LLM in generating\nan appropriate response (left).\n2023), have revolutionized natural language pro-\ncessing (NLP) applications (Wei et al., 2022; Wang\net al., 2023), owing to their remarkable conversa-\ntional skills (Qin et al., 2023), instruction-following\nabilities (Ouyang et al., 2022) and zero-shot gener-\nalization capabilities (Chowdhery et al., 2022a; Hu\net al., 2022). This raises a research question: can\nLLMs be effectively utilized for building task bots\nwith minimum human effort?\nA contemporary study (Hudecek and Dusek,\n2023) explores the potential of LLMs for rapidly\nbuilding task bots via few-shot prompting, a.k.a.\nin-context learning (ICL) paradigm (Brown et al.,\n2020; Madotto et al., 2021). Though demonstrably\neffective, the ICL performance is highly influenced\nby the quality of the in-context exemplars (Zhao\net al., 2021; Liu et al., 2022; Dong et al., 2023), as\nthey struggle to provide comprehensive informa-\ntion for dialog task completion.\n13348\nIn this work, we introduce symbolic knowledge\n(Nye et al., 2021; Cheng et al., 2023), i.e., the task\nschema into LLMs, for creating task bots. Task\nschema (Mosig et al., 2020; Mehri and Eskenazi,\n2021) encompasses a concise symbolic represen-\ntation of a task, supplying LLMs with a compre-\nhensive blueprint. It comprises (i) task-specific\nontology containing all slots and their appropri-\nate values (Budzianowski et al., 2018); and (ii) a\ndialog flow explicitly outlining fundamental inter-\naction patterns (Peng et al., 2021b). Specifically,\nwe propose SGP-TOD (as depicted in Figure 1), a\nschema-guided prompting method for rapidly build-\ning task bots. We integrate the predefined task\nschema and dialog context into prompts through\nthe use of two specifically-designed prompters,\nnamely a DST Prompter and a Policy Prompter.\nUtilizing these prompters, we adeptly guide fixed\nLLMs to track dialog states, retrieve database en-\ntries, and generate appropriate responses for novel\ntasks in a zero-shot manner, without the need for\nadditional training or fine-tuning. By incorporat-\ning task-specific symbolic knowledge into LLMs,\nSGP-TOD provides knowledge-based, coherent\nand human-like responses. Moreover, this training-\nfree design empowers developers to flexibly proto-\ntype dialog systems on new tasks, while seamlessly\nextending system functionalities through modify-\ning the task schema.\nWe perform empirical automatic evaluations on\ntwo multi-domain datasets, namely, Multiwoz 2.0\nand 2.2 (Budzianowski et al., 2018; Zang et al.,\n2020), as well as two single-domain/task datasets,\nRADDLE (Peng et al., 2021a) and STAR (Mosig\net al., 2020), within zero-shot scenarios. Addition-\nally, we complement these assessments with inter-\nactive human evaluations. The results indicate that\nSGP-TOD , employing merely task schema devoid\nof any training or fine-tuning, substantially boosts\nthe SOTA zero-shot results, markedly outperform-\ning few-shot prompting/fine-tuning methods, and\neven attaining competitive results cf. full-shot fine-\ntuning approaches. In a domain-extension context,\nSGP-TOD proficiently adapts to new functional-\nities by simply adding a handful of schema rules\nwithout necessitating further data collection, sig-\nnificantly exceeding the few-shot prompting/fine-\ntuning methods reinforced by machine teaching\n(Williams and Liden, 2017).\nIn summary, our contributions are three-fold:\n• We propose SGP-TOD , a schema-guided\nLLM prompting strategy that facilitates in ef-\nfortlessly creating task bots, eliminating the\nnecessity for task-specific data or fine-tuning.\n• We integrate symbolic knowledge – task\nschema into LLMs, allowing them to generate\nschema-compliant responses and adaptively\nexpand their functionalities to tackle new\ntasks by solely modifying the task schema.\n• We demonstrate the effectiveness of SGP-\nTOD on Multiwoz, RADDLE, STAR datasets\nin zero-shot settings using both automatic and\nhuman evaluations. SGP-TOD notably ele-\nvates the SOTA zero-shot performance.\n2 Related work\nZero-Shot Task-Oriented Dialog Modeling.\nZero-shot generalization is an essential yet chal-\nlenging task in TOD research. A comprehensive\nstudy is shown in Appendix A. In this paper, we\nfocus on zero-shot end-to-end dialog modeling, in-\ncluding policy management and dialog generation.\nThe works by Zhao and Eskenazi (2018) and\nQian and Yu (2019) utilize ontology and response\ntemplates to train dialog models, enabling the dis-\ncovery of shared dialog policies between the source\nand target domains. To enable broader adapta-\ntion to diverse dialog policies, Mosig et al. (2020);\nMehri and Eskenazi (2021) implement task-specific\npolicy skeletons, training dialog models to adhere\nto novel policies. Furthermore, Zhao et al. (2022)\nemploys a neural language model (LM) for tracking\ndialog states and user actions using slot and action\ndescriptions; subsequently, a policy program is de-\nployed to facilitate an LM in generating system\nactions and responses. Despite the effectiveness\nof previous approaches, they still require ample\nfine-tuning and copious annotated dialog corpora\non source or heterogeneous domains/tasks.\nA concurrent study to ours is Hudecek and\nDusek (2023), which employs a prompting strat-\negy – IG-TOD (instruction-guided TOD) to guide\nfrozen LLMs in generating suitable responses.\nSpecifically, IG-TOD first tracks belief states by\nutilizing slot descriptions as prompts, then retrieves\ndatabase entries, and generates responses. Our\nSGP-TOD differs in that: (i) we employ slot\nnames and value examples, rather than slot de-\nscriptions, as prompts to facilitate frozen LLMs\nin generating belief states, thereby reducing hu-\nman effort; (ii) we offer a policy skeleton to guide\n13349\nLLMs in producing appropriate responses. In addi-\ntion, experimental results indicate that SGP-TOD\nsubstantially outperforms IG-TOD.\nLeveraging LLMs for Dialog Tasks. LLMs\n(Chowdhery et al., 2022b; OpenAI, 2023) have\nexhibited unparalleled mastery of natural language\nunderstanding, reasoning and generation (Wei et al.,\n2022; Bubeck et al., 2023). Three primary re-\nsearch directions have obtained substantial success\nin numerous dialog tasks by utilizing LLMs. (i)\nFew-shot prompting (Brown et al., 2020) has show-\ncased remarkable performance in intent classifi-\ncation (Yu et al., 2021), semantic parsing (Shin\nand Van Durme, 2022), dialog state tracking (Hu\net al., 2022; Xie et al., 2022), and response gener-\nation (Madotto et al., 2021). (ii) Li et al. (2022);\nMehri et al. (2022); Dai et al. (2023) employ LLMs\nfor data augmentation, i.e., generating synthetic\ntask-oriented dialogs to train smaller models for\ninference. (iii) Recently, several studies endeavor\nto support LLMs in specialized tasks by incorpo-\nrating external knowledge. Peng et al. (2023) advo-\ncates for enhancing LLMs’ responses with external\nknowledge and automated feedback to reduce hal-\nlucination. Liang et al. (2023) suggests connecting\nLLMs with millions of APIs to accomplish diverse\ntasks. Different from the aforementioned works,\nwe aim to employ LLMs in building task bots in a\nzero-shot manner using pre-defined task schema.\n3 SGP-TOD\n3.1 Overview\nThe overall architecture of the proposed SGP-\nTOD (Figure 1) consists of three key components:\n(i) an LLM, responsible for adhering to instruc-\ntions, comprehending user queries, and generat-\ning coherent responses for user interaction; (ii) a\nDST Prompter, tasked with supporting the LLM\nin tracking dialogue states using the belief instruc-\ntion; (iii) a Policy Prompter, guiding the LLM to\nadhere to the predefined task policy for providing\nsuitable system actions and responses.\nAt each dialog turn t, the end-to-end generation\ntask is systematically divided into three subsequent\nsub-tasks: (i) Belief State Prediction– given the\ndialog history up to current dialog turn ht, which\nis a sequence of utterances alternating between the\nuser and the system ht = [u1, r1, u2, r2, . . . , ut]\n(where u and r denote user and system utterances,\nrespectively), the DST Prompter embeds the be-\nlief instruction BI to direct the frozen LLM (pa-\nrameterized by θ) in generating a belief state bt\n(Equation 1). The belief state is then used to query\na database and obtain the database (DB) state ct\n(Equation 2). (ii) System Action Determination–\nthe Policy Prompter incorporates a policy skeleton\nPS, assisting the LLM in generating a system ac-\ntion at, based on ht, bt, and ct (Equation 3). (iii)\nDialog Response Generation– grounded in the\ndialog history ht, belief state bt, DB state ct, sys-\ntem action at, the Policy Prompter aids the LLM in\ngenerating a delexicalized response by providing\nthe policy skeleton PS (Equation 4). Ultimately,\nthe delexicalized response is automatically post-\nprocessed to generate system response in natural\nlanguage. Detailed illustration with a dialog exam-\nple is shown in Appendix L.\nbt =LLMθ(ht, BI) (1)\nct =DB(bt) (2)\nat =LLMθ(ht, bt, ct, PS) (3)\nrt =LLMθ(ht, bt, ct, at, PS) (4)\n3.2 LLM\nAn LLM is responsible for following task-specific\ninstructions and generating appropriate responses.\nMany off-the-shelf LLMs, e.g., ChatGPT, Codex\n(Chen et al., 2021), are pre-trained on massive\ncorpora of text data and/or code data. In addi-\ntion, they are trained to follow instructions in the\nprompts (Ouyang et al., 2022) and provide perti-\nnent responses. Exhibiting remarkable proficien-\ncies in natural language processing, instruction\ncompliance, and zero-shot generalization across di-\nverse downstream dialog tasks, these LLMs serve\nas valuable foundation models for our approach.\n3.3 DST Prompter\nGiven the dialog history ht, the DST prompter\naims to guide the LLM in predicting the belief state\nbt at each turn t, using the belief instruction BI.\nThe belief state bt is defined as the concatenation\nof the domain/task ( i.e., user intent) dt and a set\nof slot-value pairs\n{\n(si\nt, vi\nt); i = 1, . . . , nt\n}\n, where\nnt is the total number of pairs in the set.\nAs shown in Figure 2, the proposed DST\nprompter contains four parts: (i) a task instruc-\ntion that offers general guidance on belief state\nprediction;2 (ii) belief instructions BI of all do-\nmains/tasks; (iii) a formatting example illustrating\n2We assess several task instructions written by different\nauthors, yielding minor performance disparities.\n13350\nDST Prompter\nT ask instruction\nFollowing the instructions, predict the belief state based on the\nhistory .\nBelief instructions\nrestaurant  name = pizza hut city , golden wok, etc.; food = dont\ncare, chinese, mediterranean, british, etc.; pricerange = dontcare,\ncheap, moderate, expensive; area = dont care, centre, east,\nnorth, south, west ; booking_day = monday , tuesday , wednesday ,\nthursday , friday , saturday , sunday; booking_people =\n1,2,3,4,5,6,7; booking_time = 12:15, 13:30, etc.\nattraction  type = swimmingpool, theatre, architecture, museum,\nnightclub, boat, park, college, concerthall, entertainment, multiple\nsports, cinema; area = dont care, centre, east, north, south,\nwest; ....\nFormatting example\nhistory  \nuser: W ould you be able to tell me whether there are any multiple\nsports  venues in the center  of town?\nSQL: select * from attraction where type = multiple sports; area =\ncentre\nT est (on target task/domain)\nhistory  \nuser:  I am looking for a restaurant in the moderate  price range\nserving modern European  food. system: I have at least 2\nchoices, do you have a preferred area in mind ? user: I’d like a\nrestaurant on the south  end of town, please.\nSQL: select * from restaurant where pricerange = moderate; food\n= modern European; area = south\n         LLM \nFigure 2: Illustration of belief state prediction utiliz-\ning DST Prompter. The predicted belief state is high-\nlighted.\nthe anticipated output format to direct the LLM, in\naddition, we follow Hu et al. (2022) and adopt SQL\nstate to represent the dialog state bt3; and (iv) the\ntest input, i.e., the given dialog history ht. Since\nthe prompt is fixed and no labeled data from the tar-\nget task or domain is used, we refer to this setting\nas \"zero-shot\", following Wang et al. (2022b).\nBelief Instruction. For each task/domain, the\nbelief instruction contains the task/domain name,\nall potential slot names, and their possible val-\nues (Figure 2). Regarding categorical slots, such\nas the \"price range\" in the restaurant domain, all\nplausible values are included, i.e., \"don’t care\",\n\"cheap\", \"moderate\", and \"expensive\"; whereas, for\nnon-categorical slots, such as \"name\", only a few\nvalue examples are injected, e.g., Pizza Hut City,\nGolden Wok, etc.4 Detailed belief instructions for\nall tasks/domains can be found in Appendix B.\n3SQL: select * from dt where s1\nt = v1\nt ; . . .; snt\nt = vnt\nt .\n4We assess belief instructions with diverse slot value ex-\namples, revealing minor performance variations.\nPolicy Prompter\nT ask instruction\nFollowing the instructions, generate appropriate response based\non the history .\nPolicy skeleton (on target task/domain)\n(1) user:  I'm looking for a restaurant that of fers [value_food] food\nin a [value_pricerange] price range. action:  restaurant (inform\n(choices), require (area)) system:  I have over [value_count]\nrestaurant -s to choose from, do you have a preferred area in\nmind? [eos]\n(2) user:  I need a restaurant that serves [value_food] food in a\n[value_pricerange] on the [value_area] side of town. action:\nrestaurant (recommend (name), inform (food, pricerange, area))\nsystem:  how about [restaurant_name]? It serves [value_food]\nfood in the [value_pricerange] price range in the [value_area].\n[eos]  ...\n( 17) DB: restaurant one match. action:  restaurant (recommend\n(name)) system:  How does [restaurant_name] sound?\nT est (on target task/domain)\nhistory  \nuser:  I am looking for a restaurant in the moderate  price range\nserving modern European  food. system: I have at least 2\nchoices, do you have a preferred area in mind?  user: I’d like a\nrestaurant on the south  end of town, please.\nSQL: select * from restaurant where pricerange = moderate; food\n= modern European; area = south  DB: Restaurant one match  \nFormatting example (from other task/domain)\n...\n         LLM \naction: restaurant (recommend (name), inform (food, pricerange,\narea))  system: How does [restaurant_name] sound? It serves\n[value_food] food in the [value_pricerange] price range on the\n[value_area] side of town. [eos]\nFigure 3: Illustration of system action determina-\ntion and response generation employing the Policy\nPrompter. The pertinent template turns , previously\npredicted belief state , retrieved DB state within the\ninput, alongside the generated system action and\ngenerated response in the output are accentuated.\n3.4 Policy Prompter\nDialog policy, governing the behavior of task bots,\nplays a crucial role in task-oriented dialogs. To rep-\nresent the dialog policy for a given task, we utilize\na policy skeleton, which delineates interaction pat-\nterns and encompasses business logic in the form\nof template dialog flows (Peng et al., 2021b). The\nPolicy Prompter is devised to guide the static LLM\nin adhering to the policy skeletonPS, enabling the\nsequential generation of appropriate system actions\nat and responses rt.\nAnalogous to the DST Prompter, the Policy\nPrompter (Figure 3) comprises four components:\n(i) a task instruction; (ii) a formatting example de-\nrived from another task/domain, consisting of a par-\n13351\ntial policy skeleton and its associated dialogue turn\nexemplar (in Appendix C); (iii) a policy skeleton\nfor the previously predicted domain/task; and (iv)\nthe test input, i.e., the dialog history ht, generated\nbelief state bt, and obtained DB state ct.\nPolicy Skeleton. Given that user behaviors and\nDB results jointly determine system actions and\nresponses, policy skeleton is designed to cover all\nfundamental user behaviors and characteristic DB\nresults, along with their corresponding system ac-\ntions and responses.5 Considering the infeasibility\nof developing a multi-task/domain policy skeleton\nfor every possible combination of tasks and do-\nmains, we opt to develop a distinct policy skeleton\ntailored to each specific task and domain.\nFollowing Mehri and Eskenazi (2021), our strat-\negy converts the established dialog policy into a\nseries of template dialog turns Xthat are logically\narranged and concentrate on task completion:\nX= {xi}N\ni=1 ,\nxi =(ui, ai, ri)or(ci, ai, ri)\n(5)\nwhere xi is a template dialog turn, which contains\na user utterance ui or a DB state ci, matching sys-\ntem action ai, and system response ri. N denotes\nthe total number of template turns within the pol-\nicy skeleton (around 10-20 template turns depend-\ning on the task complexity). In order to equip the\nfrozen LLM with new capabilities or modify cur-\nrent ones, we only need insert, amend, or eliminate\na few template turns within the policy skeleton.\n4 Experiments\n4.1 Experimental Setup\nDatasets. (i) Two multi-domain dialog datasets:\nMultiwoz 2.0 (Budzianowski et al., 2018) and\nMultiwoz 2.2 (Zang et al., 2020). (ii) Two\nsingle-domain/task datasets: RADDLE (Peng et al.,\n2021a,c) and STAR (Mosig et al., 2020) (single-\ntask dialogs from the corpus, following the \"happy\npath\"). Details are elaborated in Appendix D.\nAutomatic Evaluation Metrics.We evaluate the\nend-to-end dialog generation performance using\nthe same metrics as those listed in Budzianowski\net al. (2018): Inform(%), Success(%), BLEU(%)\n(Papineni et al., 2002) and Combined(%) judges\nthe overall quality, defined as Combined =\n5We do not enumerate every conceivable combination of\nuser behaviors or potential database results, as schema engi-\nneering is not the primary focus of this study.\n(Inform + Success) ×0.5 + BLEU. Additionally,\nwe utilize BERTScore(%) (Zhang* et al., 2020).\nFollowing Mehri and Eskenazi (2021), we per-\nform the next action prediction task on STAR\n(wherein the system actions and response templates\nare mapped one to one), which predicts next sys-\ntem action given the dialog history. We report the\nresults using F1score(%) and accuracy(%).\nHuman Evaluation Metrics.We conduct inter-\nactive human evaluations (by five student helpers),\nfollowing the evaluation protocol in the DSTC9\nTrack 1 challenge (Gunasekara et al., 2020). For\neach dialog session, students are mandated to in-\nteract with a dialog agent via natural language\nand assess the overall dialog quality employ-\ning these five metrics: (i) Success w/o g(%),\n(ii) Success w/ g(%), (iii) Understanding(1-5),\n(iv) Appropriateness(1-5) and (v) Turns. Full\ndetails are elaborated in Appendix D.\nCompared Methods.We compare the proposed\nSGP-TOD with SOTA zero-shot transfer methods\nand zero-shot/few-shot prompting strategies. (We\nreport the mean results of three different runs.)\nZero-shot transfer methods:\n• BERT+S (Mosig et al., 2020) augments a\nBERT-base classifier (Devlin et al., 2019) with\na system-side schema to predict system action.\n• SAM (Mehri and Eskenazi, 2021) is based on\nBERT-base, which uses a user-aware schema\nto predict the next system action.\n• ANYTOD-XXL (Zhao et al., 2022) adopts\nT5-XXL (Roberts et al., 2022) to generate sys-\ntem actions and responses utilizing slot/action\ndescriptions and a policy program. It is pre-\ntrained on SGD dataset (Rastogi et al., 2020a).\nPrompting methods:\n• IG-TOD-C HATGPT (Hudecek and Dusek,\n2023) is a prompting approach based on Chat-\nGPT, exploiting slot descriptions for tracking\ndialog states, fetching DB entries, and gener-\nating responses. IG-TOD-C HATGPT-ZS and\nIG-TOD-C HATGPT-FS are in the zero-shot\nand few-shot settings, respectively.\n• FEW-SHOT-CHATGPT is a few-shot prompt-\ning approach applied to ChatGPT, utilizing a\nfew (i.e., k) training dialog turns as prompts.\nOptimal results are achieved with k = 15on\nMultiwoz and k = 10on RADDLE.\n• SGP-TOD (Ours) is compatible with any off-\nthe-shelf LLMs. In this paper, we employ\n13352\nModel Multiwoz 2.0 Multiwoz 2.2\nInform Success BLEU Combined Inform Success BLEU Combined\nFull-shot fine-tuning (with 8.4k+ training dialogs):\nDAMD (Zhang et al., 2020) 76.33 60.40 16.60 84.97 - - - -\nSIMPLE TOD (Hosseini-Asl et al., 2020) 84.40 70.10 15.01 92.26 - - - -\nSOLOIST (Peng et al., 2021a) 85.50 72.90 16.54 95.74 81.70 67.10 13.60 88.00\nPPTOD (Su et al., 2022) 89.20 79.40 18.62 102.92 - - - -\nMARS (Sun et al., 2022) 88.90 78.00 19.90 103.35 88.90 78.00 19.60 103.05\nZero-shot transfer method (pre-trained on SGD):\nANYTOD-XXL - - - - 73.90 24.40 3.40 52.55\nFew-shot prompting:\nIG-TOD-C HATGPT-FS - - - - - 20.00 7.17 -\nFEW-SHOT-CHATGPT 44.74 24.32 7.88 42.41 45.40 24.50 7.72 42.67\nZero-shot prompting:\nIG-TOD-C HATGPT-ZS - - - - - 15.00 3.58 -\nSGP-TOD-C HATGPT (Ours) 64.56 54.05 7.17 66.48 64.70 54.70 6.96 66.66\nSGP-TOD-C ODEX (Ours) 71.67 52.55 7.91 70.02 75.50 52.30 6.62 70.53\nSGP-TOD-GPT3.5 (Ours) 83.88 69.87 9.09 85.97 82.00 72.50 9.22 86.47\nTable 1: End-to-end dialog generation evaluation results on Multiwoz. Results of SOLOIST , MARS , ANYTOD-\nXXL on Multiwoz 2.2 are cited from Zhao et al. (2022). Results of IG-TOD-C HATGPT are cited from Hudecek\nand Dusek (2023). Other results of the full-shot fine-tuning methods are cited from He et al. (2022) and Sun et al.\n(2022). (Difference in mean is significant with p<0.01.)\nModel Attraction Train Hotel Restaurant\nInfo. Succ. BLEU Comb . Info. Succ. BLEU Comb . Info. Succ. BLEU Comb . Info. Succ. BLEU Comb .\nFew-shot fine-tuning (with 50 training dialogs):\nSIMPLE TOD 65.66 46.97 5.85 62.17 59.00 44.00 7.07 58.57 62.50 40.00 7.70 58.95 75.50 44.50 11.00 71.00\nSOLOIST 86.00 65.00 12.90 88.40 80.81 64.65 9.96 82.69 74.50 43.50 8.12 67.12 81.00 55.50 12.80 81.50\nFew-shot prompting:\nFEW-SHOT-CHATGPT 75.00 67.00 8.22 79.23 79.80 65.66 8.12 80.85 51.00 26.50 5.80 44.55 80.00 55.50 7.71 75.46\nZero-shot prompting:\nSGP-TOD-C HATGPT 95.00 94.00 7.13 101.63 76.77 74.24 6.75 82.26 76.50 57.00 5.16 71.91 90.00 82.50 6.72 92.97\nSGP-TOD-C ODEX 98.00 93.00 10.45 105.95 78.79 70.20 8.56 83.06 83.50 69.50 7.86 84.36 91.00 85.00 10.50 98.50\nSGP-TOD-GPT3.5 96.00 93.00 9.53 104.03 82.83 77.27 8.72 88.77 82.50 71.50 7.05 84.05 91.50 84.00 12.90 100.65\nTable 2: End-to-end dialog generation evaluation results on RADDLE. The few-shot fine-tuning results are cited from\nPeng et al. (2021a). (Difference in mean is significant with p<0.01.)\nChatGPT, GPT-3.5 and Codex. Implementa-\ntion details are provided in Appendix E.\n4.2 End-to-End Evaluation onMultiwoz\nResults. We present the evaluation results in multi-\ndomain contexts on Multiwoz in Table 1. In addi-\ntion to the aforementioned methods, we include the\nresults of SOTA full-shot fine-tuning approaches to\nfacilitate a more comprehensive comparison. SGP-\nTOD obtains SOTA zero-shot performance, sub-\nstantially outperforming few-shot prompting ap-\nproaches across all metrics, while even exhibiting\ncompetitive results in comparison to full-shot fine-\ntuning methods concerning Success and Inform.\nThis confirms the effectiveness of integrating the\ntask schema with the LLMs’ proficient language\nprocessing capabilities.\nComparison with Prompting Methods. SGP-\nTOD-C HATGPT distinctly surpasses the zero-\nshot prompting approach IG-TOD-C HATGPT-ZS\nwith respect to Success (surpassing by 40%) and\nBLEU (exceeding by 3%). Moreover, SGP-TOD-\nCHATGPT , without requiring task-specific data ,\nconsiderably outperforms the few-shot prompting\nmethods, i.e., IG-TOD-C HATGPT-FS and FEW-\nSHOT-CHATGPT (e.g., about 30 points improve-\nment over Success). This suggests that provid-\ning explicit and concise task instructions via task\nschema is preferable to imparting implicit task guid-\nance through the selected dialog turns.\nComparison with Zero-Shot Transfer Methods.\nOur SGP-TOD demonstrates a substantial advan-\ntage over ANYTOD-XXL , which necessitates task-\nspecific pre-training and additional annotations,\ne.g., slot and action descriptions, over all the met-\nrics. This exemplifies the potency of SGP-TOD ,\nwhich markedly reduces the necessity for human\nlabor and computational resources.\nComparison with Full-Shot Fine-Tuning Meth-\nods. SGP-TOD exhibits competitive performance\nover Inform and Success. The lower BLEU is\ndue to a lack of linguistic variations of the tem-\nplate utterances, which is acceptable considering\nthe trade-off between human effort and efficacy.\n13353\nModel Task transfer Domain transfer\nF1 Accuracy F1 Accuracy\nZero-shot transfer\n(leave-one fune-tuning with 2.5k training dialogs):\nBERT+S 24.25 24.89 25.70 28.56\nSAM 49.82 51.30 55.91 57.92\nZero-shot prompting:\nSGP-TOD-C ODEX -INI 45.18 47.99 47.21 49.97\nSGP-TOD-GPT3.5 47.67 48.27 49.76 50.39\nSGP-TOD-C ODEX 49.78 51.01 52.72 53.66\nSGP-TOD-GPT3.5-E2E 50.84 50.74 53.50 53.21\nTable 3: Zero-shot end-to-end next action prediction\nevaluation results on STAR. (Difference in mean is sig-\nnificant with p<0.01.)\n4.3 End-to-End Evaluation onRADDLE\nResults. Table 2 reports the results in single-\ndomain settings on RADDLE. On all four dialog\ntasks, SGP-TOD demonstrates remarkable zero-\nshot performance that consistently surpasses both\nfew-shot prompting and fine-tuning approaches.\nThis results in substantial improvements of up to\n12% in Inform, 45% in Success, and 19% in\nCombined metrics, while maintaining competitive\nBLEU scores. This evidence further substantiates\nthe efficacy of SGP-TOD.\n4.4 End-to-End Evaluation onSTAR\nSetup. BERT+S , SAM are fine-tuned on source\ntasks/domains then zero-shot on the held-out\ntask/domain.6 SGP-TOD is presented with two\nformatting turns from the source tasks/domains.\nResults. Following Mehri and Eskenazi (2021), we\nreport the zero-shot evaluation results in two set-\ntings, i.e., task transfer and domain transfer in Table\n3. SGP-TOD , merely with two formatting sample\nturns, demonstrates exceptional performance, sur-\npassing or rivaling SOTA zero-shot transfer meth-\nods in both settings. This outcome signifies that,\neven when faced with complicated business logic\nand system actions in dialog policies, the proposed\nSGP-TOD continues to exhibit commendable per-\nformance. Additionally, we investigate the impact\nof changing the number of training dialogs and\nformatting example turns in Appendix F.\nImpact of Different LLMs and Prompting For-\nmats. SGP-TOD-C ODEX surpasses SGP-TOD-\nGPT3.5 while rivaling SGP-TOD-GPT3.5-E2E\n(with template responses affixed to action labels\nin the policy prompt, demonstrated in Figure 10\nin Appendix M). We conjecture that Codex, bene-\nfiting from extensive pre-training on copious code\n6ANYTOD-XXL requires additional annotations, e.g., be-\nlief descriptions, which makes it not suitable for STAR.\nModel FT/FS/ZS Restaurant-Ext\nInfo. Succ. BLEU BERTS .\nWithout domain-relevant knowledge\nChatGPT ZS 44.00 6.00 4.31 85.96\nGPT-3.5 ZS 34.00 16.00 8.70 84.31\nWith prior knowledge on Restaurant\nSOLOIST FT 78.00 0.00 10.62 87.24\nSGP-TOD-C HATGPT ZS 88.00 34.00 5.45 86.11\nSGP-TOD-GPT3.5 ZS 94.00 30.00 10.68 87.30\nWith knowledge on Restaurant-Ext\nSOLOIST +TEACH FT 82.00 38.00 10.99 87.66\nFEW-SHOT-GPT3.5+T EACH FS 88.00 54.00 12.95 88.90\nSGP-TOD-C HATGPT-E XT ZS 88.00 78.00 6.25 86.15\nSGP-TOD-GPT3.5-E XT ZS 96.00 86.00 14.57 89.01\nTable 4: End-to-end evaluation results on domain ex-\ntension. FT: fine-tuning, FS: few-shot prompting, ZS:\nzero-shot prompting, Info.: Inform, Succ.: Success,\nBERTS.: BERTScore. (Difference in mean is signifi-\ncant with p<0.01.)\ndata, demonstrates enhanced proficiency compared\nto GPT-3.5 in interpreting action labels. In addition,\nappending template responses is presumed to facil-\nitate the explication of action labels for GPT-3.5.\nImpact of Different Task Schemas. SGP-TOD-\nCODEX -INI , utilizing an identical task schema as\nemployed in training SAM , manifests commend-\nable performance. This result highlights that SGP-\nTOD as a flexible prompting strategy, compatible\nwith any manually-crafted task schema.\n4.5 End-to-End Evaluation on Domain\nExtension\nSetup. We conduct experiments in a domain exten-\nsion setting (Gasic et al., 2014; Lipton et al., 2018)\nto assess the efficacy of SGP-TOD in adapting\ndeployed task bots to incorporate novel function-\nalities. Following Zhang et al. (2022), we con-\nstruct the Restaurant-ext corpus by extending\nthe Restaurant in RADDLE with four new slots:\n[restaurant_dish], [value_price], [start_time], and\n[end_time]. Details are shown in Appendix J.\nCompared Methods.\n• ChatGPT, GPT-3.5 denote zero-shot prompt-\ning that receive two formatting examples.\n• SGP-TOD-C HATGPT, SGP-TOD-GPT3.5\nrepresent our SGP-TOD implementation,\nwith the Restaurant policy skeleton.\n• SOLOIST is trained with 50 training dialogs\nin Restaurant domain (reported in Table 2).\n• SOLOIST +TEACH is fine-tuning method en-\nhanced with machine teaching (Simard et al.,\n2017). We deploy SOLOIST to converse with\n13354\nreal users, then implement machine teach-\ning to obtain 10/50/50 annotated dialogs in\nRestaurant-ext for training, validating, and\ntesting. We fine-tune SOLOIST with the gath-\nered 10 training dialogs covering new slots.\n• FEW-SHOT-GPT3.5+T EACH is the few-shot\nprompting strategy augmented with machine\nteaching. We use 10 randomly selected dialog\nturns from the collected 10 training dialogs as\nprompts (with peak performance at 10).\n• SGP-TOD-C HATGPT-E XT, SGP-TOD-\nGP3.5-E XT refer to SGP-TOD with\nRestaurant-Ext policy skeleton, where we\nonly add four template turns about four new\nslots to the policy skeleton of Restaurant.\nResults. In Table 4, SGP-TOD-C HATGPT-E XT,\nand notably SGP-TOD-GPT3.5-E XT surpasses\nall other evaluated approaches by a substantial mar-\ngin over all the metrics. This demonstrates the\nstrong adaptability of our SGP-TOD in accommo-\ndating novel functionalities, revealing its immense\npotential for lifelong learning. Two interactive dia-\nlog examples are supplied in Appendix K.\nComparison with Approaches Augmented by Ma-\nchine Teaching. SOLOIST yields zero Success,\na predictable result given its lack of awareness\nregarding the new features. Augmented by ma-\nchine teaching, SOLOIST +TEACH substantially im-\nproves SOLOIST in terms of Inform and Success.\nNevertheless, relying solely on prior Restaurant\nknowledge, both SGP-TOD-C HATGPT and SGP-\nTOD-GP3.5 exhibit performance on par with\nSOLOIST +TEACH , demonstrating that SGP-TOD\nprovides enhanced robustness in zero-shot gen-\neralization. Moreover, SGP-TOD-GP3.5-E XT\nobtains substantially higher Success rates than\nSOLOIST +TEACH (a rise of 48%) and FEW-SHOT-\nGPT3.5+T EACH (an increase of 32%). Compared\nto fine-tuning/prompting strategies utilizing addi-\ntional dialogs corrected through machine teaching,\nSGP-TOD facilitates a more agile adaptation to\nnovel functionalities by merely modifying template\nturns within the task schema.\n4.6 Interactive Human Evaluation\nSetup. We conduct interactive human evalua-\ntions on Restaurant domain to evaluate the perfor-\nmance of SOLOIST , FEW-SHOT-CHATGPT, SGP-\nTOD-C HATGPT (reported in Table 2), with 50\ndialogs gathered for analysis, respectively. Details\ncan be found in Appendix H.\nModel Restaurant\nS w/o g↑ S w/ g ↑ Und. ↑ App. ↑ T. ↓\nSOLOIST 34.00 30.00 2.18 2.10 10.64\nFEW-SHOT-CHATGPT 94.00 74.00 4.58 4.72 8.32\nSGP-TOD-C HATGPT 100.00 92.00 4.86 4.88 7.28\nTable 5: Human evaluation results. S w/o g, S w/ g:\nSuccess without / with grounding; Und.: Understanding;\nApp.: Appropriateness; T.: Turns.\nModel Multiwoz 2.2\nInform Success BLEU Combined\nSP-TOD-GPT3.5 82.00 72.50 9.22 86.47\n-policy 81.80 56.20 6.63 75.63\n-policy -DB 81.40 52.30 6.57 73.42\n-policy -DB -belief 38.60 33.90 6.29 42.54\nTable 6: Ablation study results on the impact of the\nthree components in the proposed SGP-TOD and the\ndatabase expertise on Multiwoz 2.2 using GPT-3.5.\n-policy: removing Policy Prompter, -DB: removing\ndatabase expertise, -belief: removing DST Prompter.\nResults. In Table 5, our proposed SGP-TOD-\nCHATGPT attains a remarkably high performance\nin a zero-shot context, consistently outpacing\nSOLOIST and FEW-SHOT-CHATGPT across all\nmetrics. Particularly, regarding Success w/ g,\nSGP-TOD-C HATGPT significantly surpasses\nFEW-SHOT-CHATGPT (by 18%) and SOLOIST (by\n62%), illustrating its proficiency in accomplishing\ntasks within real-world scenarios. Furthermore,\nSGP-TOD-C HATGPT exhibits a more stable per-\nformance (demonstrated in Appendix I). A detailed\nanalysis is provided in Appendix I.\n4.7 Ablation Study\nIn Table 6, we study the impact of the three com-\nponents of SGP-TOD (namely, Policy Prompter,\nDST Prompter, and LLM) as well as the database\nexpertise, on Multiwoz 2.2 utlizing GPT-3.5. Com-\nbining the three elements in SGP-TOD with the\ndatabase expertise produces the optimal result, un-\nderscoring the value of enhancing the LLM with\nthe task schema and external database information.\nDetailed analyses are provided in Appendix G.\n5 Conclusion\nWe present SGP-TOD , a schema-guided prompt-\ning strategy aimed at the expeditious construction\nof end-to-end task bots, relying exclusively on\nLLMs and the corresponding task schema. Em-\nploying the symbolic knowledge – task schema,\nSGP-TOD guides fixed LLMs to generate suitable\nresponses for novel tasks in a zero-shot fashion.\nEmpirical findings on four well-studied datasets\n13355\nreveal that SGP-TOD attains remarkable SOTA\nzero-shot performance, using both automatic and\nhuman evaluations. For future work, we plan to ex-\nplore the use ofSGP-TOD to develop personalized\nchatbots by utilizing pertinent task schema.\nLimitations\nThis work is accompanied by two primary limita-\ntions. (i) Data contamination (Brown et al., 2020;\nMadotto et al., 2021) in prompt-based zero-shot\nlearning pertains to the potential presence of test\nsamples during the LLM pre-training phase. Given\nthat data utilized for pre-training LLMs, such as\nChatGPT and GPT-4, remains undisclosed and con-\ntinuously expands, verifying data contamination\npresents a formidable challenge. Consequently,\nour research cannot preclude data contamination\nin the experimental process, deferring a more com-\nprehensive investigation to future endeavors. Nev-\nertheless, we undertake domain-extension exper-\niments (Table 4 in Section 4.5), subjecting our\nproposed SGP-TOD to evaluation on a novel test\nset (currently not publicly available), encompass-\ning recently obtained and annotated human-bot di-\nalogs. The remarkable zero-shot performance of\nSGP-TOD demonstrates its substantial potential\nfor adeptly adapting to innovative functionalities,\nwithout reliance on task-specific data.\n(ii) We employ the manually-crafted task\nschema as prompts to steer the LLMs towards gen-\nerating suitable responses on novel tasks. As illus-\ntrated in Table 3 of Section 4.4,SGP-TOD exhibits\nminor performance discrepancies when implement-\ning disparate task schema formulated by various\nauthors. Notwithstanding such variations, our ob-\njective is to offer a foundational basis for schema-\nguided LLM prompting; future research may inves-\ntigate approaches to designing more efficient task\nschema, i.e., diverse formats and coverage.\nEthics Statement\nThroughout the interactive human evaluations and\ndomain-extension experiments, all participating\nstudent helpers were informed of the research ob-\njectives prior to the collection and annotation of\nhuman-bot dialog logs. Their privacy was ensured\nto remain protected and undisclosed during the re-\nsearch period. Each participant received equitable\nremuneration.\nThe Prompters utilized in this research incorpo-\nrate no language that discriminates against specific\nindividuals or groups (Zhou et al., 2022) and avoid\nany negative impact on users’ well-being (Bergman\net al., 2022). Instances of these Prompters are pro-\nvided in Appendix M. Furthermore, subsequent\nresearch endeavors may consider utilizing the Ope-\nnAI moderation API 7 in conjunction with other\nrelated APIs to systematically filter out unsuitable\nuser inputs and system responses.\nAcknowledgements\nThis Project is partially supported by the HKSARG\nGeneral Research Fund (Ref No. 14207619). We\nwould like to express our gratitude to Xiaohan Feng\nand Haohan Guo for their valuable comments.\n7https://platform.openai.com/docs/guides/\nmoderation/overview\n13356\nReferences\nA. Stevie Bergman, Gavin Abercrombie, Shannon\nSpruit, Dirk Hovy, Emily Dinan, Y-Lan Boureau,\nand Verena Rieser. 2022. Guiding the release of safer\nE2E conversational AI through value sensitive de-\nsign. In Proceedings of the 23rd Annual Meeting\nof the Special Interest Group on Discourse and Dia-\nlogue, pages 39–52, Edinburgh, UK. Association for\nComputational Linguistics.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems ,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nSébastien Bubeck, Varun Chandrasekaran, Ronen El-\ndan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Pe-\nter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,\nHarsha Nori, Hamid Palangi, Marco Tulio Ribeiro,\nand Yi Zhang. 2023. Sparks of artificial general in-\ntelligence: Early experiments with gpt-4.\nPaweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang\nTseng, Iñigo Casanueva, Ultes Stefan, Ramadan Os-\nman, and Milica Gaši ´c. 2018. Multiwoz - a large-\nscale multi-domain wizard-of-oz dataset for task-\noriented dialogue modelling. In Proceedings of the\n2018 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP).\nGiovanni Campagna, Agata Foryciarz, Mehrad Morad-\nshahi, and Monica Lam. 2020. Zero-shot transfer\nlearning with synthesized data for multi-domain dia-\nlogue state tracking. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics, pages 122–132, Online. Association for\nComputational Linguistics.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming\nYuan, Henrique Ponde de Oliveira Pinto, Jared Ka-\nplan, Harri Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, et al. 2021. Evaluating large\nlanguage models trained on code. arXiv preprint\narXiv:2107.03374.\nZhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu\nLi, Rahul Nadkarni, Yushi Hu, Caiming Xiong,\nDragomir Radev, Mari Ostendorf, Luke Zettlemoyer,\nNoah A. Smith, and Tao Yu. 2023. Binding\nlanguage models in symbolic languages. ICLR,\nabs/2210.02875.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, An-\ndrew M. Dai, Thanumalayan Sankaranarayana Pil-\nlai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,\nRewon Child, Oleksandr Polozov, Katherine Lee,\nZongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. 2022a. Palm: Scaling language\nmodeling with pathways.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, An-\ndrew M. Dai, Thanumalayan Sankaranarayana Pil-\nlai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,\nRewon Child, Oleksandr Polozov, Katherine Lee,\nZongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. 2022b. Palm: Scaling language\nmodeling with pathways. CoRR, abs/2204.02311.\nHaixing Dai, Zhengliang Liu, Wenxiong Liao, Xiaoke\nHuang, Yihan Cao, Zihao Wu, Lin Zhao, Shaochen\nXu, Wei Liu, Ninghao Liu, Sheng Li, Dajiang Zhu,\nHongmin Cai, Lichao Sun, Quanzheng Li, Dinggang\nShen, Tianming Liu, and Xiang Li. 2023. Auggpt:\nLeveraging chatgpt for text data augmentation.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, NAACL-HLT 2019, Minneapolis, MN, USA,\nJune 2-7, 2019, Volume 1 (Long and Short Papers),\npages 4171–4186. Association for Computational\nLinguistics.\nQingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong\n13357\nWu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and\nZhifang Sui. 2023. A survey on in-context learning.\nMilica Gasic, Dongho Kim, Pirros Tsiakoulis, Cather-\nine Breslin, Matthew Henderson, Martin Szummer,\nBlaise Thomson, and Steve J. Young. 2014. In-\ncremental on-line adaptation of pomdp-based dia-\nlogue managers to extended domains. In INTER-\nSPEECH 2014, 15th Annual Conference of the Inter-\nnational Speech Communication Association, Singa-\npore, September 14-18, 2014, pages 140–144. ISCA.\nChulaka Gunasekara, Seokhwan Kim, Luis Fernando\nD’Haro, Abhinav Rastogi, Yun-Nung Chen, Mihail\nEric, Behnam Hedayatnia, Karthik Gopalakrishnan,\nYang Liu, Chao-Wei Huang, et al. 2020. Overview of\nthe ninth dialog system technology challenge: Dstc9.\narXiv preprint arXiv:2011.06486.\nWanwei He, Yinpei Dai, Yinhe Zheng, Yuchuan Wu,\nZheng Cao, Dermot Liu, Peng Jiang, Min Yang, Fei\nHuang, Luo Si, et al. 2022. Galaxy: A generative\npre-trained model for task-oriented dialog with semi-\nsupervised learning and explicit policy injection.Pro-\nceedings of the AAAI Conference on Artificial Intelli-\ngence.\nEhsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu,\nSemih Yavuz, and Richard Socher. 2020. A simple\nlanguage model for task-oriented dialogue. Advances\nin Neural Information Processing Systems, 33:20179–\n20191.\nYushi Hu, Chia-Hsuan Lee, Tianbao Xie, Tao Yu,\nNoah A. Smith, and Mari Ostendorf. 2022. In-\ncontext learning for few-shot dialogue state tracking.\nIn Findings of the Association for Computational\nLinguistics: EMNLP 2022 , pages 2627–2643, Abu\nDhabi, United Arab Emirates. Association for Com-\nputational Linguistics.\nV ojtech Hudecek and Ondrej Dusek. 2023. Are llms\nall you need for task-oriented dialogue? CoRR,\nabs/2304.06556.\nMihir Kale and Abhinav Rastogi. 2020. Template\nguided text generation for task-oriented dialogue. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing, EMNLP\n2020, Online, November 16-20, 2020, pages 6505–\n6520. Association for Computational Linguistics.\nZekun Li, Wenhu Chen, Shiyang Li, Hong Wang, Jing\nQian, and Xifeng Yan. 2022. Controllable dialogue\nsimulation with in-context learning. In Findings\nof the Association for Computational Linguistics:\nEMNLP 2022, pages 4330–4347, Abu Dhabi, United\nArab Emirates. Association for Computational Lin-\nguistics.\nYaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu,\nYan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji,\nShaoguang Mao, Yun Wang, Linjun Shou, Ming\nGong, and Nan Duan. 2023. Taskmatrix.ai: Com-\npleting tasks by connecting foundation models with\nmillions of apis.\nZhaojiang Lin, Bing Liu, Andrea Madotto, Seungwhan\nMoon, Zhenpeng Zhou, Paul A Crook, Zhiguang\nWang, Zhou Yu, Eunjoon Cho, Rajen Subba, et al.\n2021a. Zero-shot dialogue state tracking via cross-\ntask transfer. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Process-\ning, pages 7890–7900.\nZhaojiang Lin, Bing Liu, Seungwhan Moon, Paul A\nCrook, Zhenpeng Zhou, Zhiguang Wang, Zhou Yu,\nAndrea Madotto, Eunjoon Cho, and Rajen Subba.\n2021b. Leveraging slot descriptions for zero-shot\ncross-domain dialogue statetracking. In Proceedings\nof the 2021 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 5640–5648.\nZachary Lipton, Xiujun Li, Jianfeng Gao, Lihong Li,\nFaisal Ahmed, and Li Deng. 2018. Bbq-networks:\nEfficient exploration in deep reinforcement learning\nfor task-oriented dialogue systems. In Proceedings\nof the AAAI Conference on Artificial Intelligence ,\nvolume 32.\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,\nLawrence Carin, and Weizhu Chen. 2022. What\nmakes good in-context examples for GPT-3? In\nProceedings of Deep Learning Inside Out (DeeLIO\n2022): The 3rd Workshop on Knowledge Extrac-\ntion and Integration for Deep Learning Architectures,\npages 100–114, Dublin, Ireland and Online. Associa-\ntion for Computational Linguistics.\nAndrea Madotto, Zhaojiang Lin, Genta Indra Winata,\nand Pascale Fung. 2021. Few-shot bot: Prompt-\nbased learning for dialogue systems. arXiv preprint\narXiv:2110.08118.\nShikib Mehri, Yasemin Altun, and Maxine Eskenazi.\n2022. LAD: Language models as data for zero-shot\ndialog. In Proceedings of the 23rd Annual Meeting\nof the Special Interest Group on Discourse and Dia-\nlogue, pages 595–604, Edinburgh, UK. Association\nfor Computational Linguistics.\nShikib Mehri and Maxine Eskenazi. 2021. Schema-\nguided paradigm for zero-shot dialog. arXiv preprint\narXiv:2106.07056.\nJohannes EM Mosig, Shikib Mehri, and Thomas Kober.\n2020. Star: A schema-guided dialog dataset for trans-\nfer learning. arXiv preprint arXiv:2010.11853.\nMaxwell I. Nye, Michael Henry Tessler, Joshua B.\nTenenbaum, and Brenden M. Lake. 2021. Improv-\ning coherence and consistency in neural sequence\nmodels with dual-system, neuro-symbolic reasoning.\nIn Advances in Neural Information Processing Sys-\ntems 34: Annual Conference on Neural Information\nProcessing Systems 2021, NeurIPS 2021, December\n6-14, 2021, virtual, pages 25192–25204.\nOpenAI. 2022. large-scale generative pre-training\nmodel for conversation. OpenAI blog.\nOpenAI. 2023. Gpt-4 technical report.\n13358\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, John\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,\nMaddie Simens, Amanda Askell, Peter Welinder,\nPaul F Christiano, Jan Leike, and Ryan Lowe. 2022.\nTraining language models to follow instructions with\nhuman feedback. In Advances in Neural Information\nProcessing Systems, volume 35, pages 27730–27744.\nCurran Associates, Inc.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic evalu-\nation of machine translation. In Proceedings of the\n40th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 311–318, Philadelphia,\nPennsylvania, USA. Association for Computational\nLinguistics.\nBaolin Peng, Michel Galley, Pengcheng He, Hao Cheng,\nYujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou\nYu, Weizhu Chen, et al. 2023. Check your facts and\ntry again: Improving large language models with\nexternal knowledge and automated feedback. arXiv\npreprint arXiv:2302.12813.\nBaolin Peng, Chunyuan Li, Jinchao Li, Shahin Shayan-\ndeh, Lars Liden, and Jianfeng Gao. 2021a. Soloist:\nBuilding task bots at scale with transfer learning and\nmachine teaching. Transactions of the Association\nfor Computational Linguistics, 9:807–824.\nBaolin Peng, Chunyuan Li, Zhu Zhang, Jinchao Li,\nChenguang Zhu, and Jianfeng Gao. 2021b. Syn-\nergy: Building task bots at scale using symbolic\nknowledge and machine teaching. arXiv preprint\narXiv:2110.11514.\nBaolin Peng, Chunyuan Li, Zhu Zhang, Chenguang Zhu,\nJinchao Li, and Jianfeng Gao. 2021c. RADDLE: an\nevaluation benchmark and analysis platform for ro-\nbust task-oriented dialog systems. In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing,\nACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual\nEvent, August 1-6, 2021, pages 4418–4429. Associa-\ntion for Computational Linguistics.\nKun Qian and Zhou Yu. 2019. Domain adaptive dialog\ngeneration via meta learning. In Proceedings of the\n57th Annual Meeting of the Association for Computa-\ntional Linguistics, pages 2639–2649, Florence, Italy.\nAssociation for Computational Linguistics.\nChengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao\nChen, Michihiro Yasunaga, and Diyi Yang. 2023. Is\nchatgpt a general-purpose natural language process-\ning task solver?\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nColin Raffel, Noam Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020. Exploring the\nlimits of transfer learning with a unified text-to-text\ntransformer. Journal of Machine Learning Research,\n21(140):1–67.\nAbhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara,\nRaghav Gupta, and Pranav Khaitan. 2020a. To-\nwards scalable multi-domain conversational agents:\nThe schema-guided dialogue dataset. In The Thirty-\nFourth AAAI Conference on Artificial Intelligence,\nAAAI 2020, The Thirty-Second Innovative Applica-\ntions of Artificial Intelligence Conference, IAAI 2020,\nThe Tenth AAAI Symposium on Educational Advances\nin Artificial Intelligence, EAAI 2020, New York, NY,\nUSA, February 7-12, 2020, pages 8689–8696. AAAI\nPress.\nAbhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara,\nRaghav Gupta, and Pranav Khaitan. 2020b. Towards\nscalable multi-domain conversational agents: The\nschema-guided dialogue dataset. In Proceedings of\nthe AAAI Conference on Artificial Intelligence, vol-\nume 34, pages 8689–8696.\nAdam Roberts, Hyung Won Chung, Anselm Levskaya,\nGaurav Mishra, James Bradbury, Daniel Andor, Sha-\nran Narang, Brian Lester, Colin Gaffney, Afroz\nMohiuddin, Curtis Hawthorne, Aitor Lewkowycz,\nAlex Salcianu, Marc van Zee, Jacob Austin, Sebas-\ntian Goodman, Livio Baldini Soares, Haitang Hu,\nSasha Tsvyashchenko, Aakanksha Chowdhery, Jas-\nmijn Bastings, Jannis Bulian, Xavier Garcia, Jianmo\nNi, Andrew Chen, Kathleen Kenealy, Jonathan H.\nClark, Stephan Lee, Dan Garrette, James Lee-Thorp,\nColin Raffel, Noam Shazeer, Marvin Ritter, Maarten\nBosma, Alexandre Passos, Jeremy Maitin-Shepard,\nNoah Fiedel, Mark Omernick, Brennan Saeta, Ryan\nSepassi, Alexander Spiridonov, Joshua Newlan, and\nAndrea Gesmundo. 2022. Scaling up models and\ndata with t5x and seqio.\nDarsh J Shah, Raghav Gupta, Amir A Fayazi, and Dilek\nHakkani-Tur. 2019. Robust zero-shot cross-domain\nslot filling with example values. arXiv preprint\narXiv:1906.06870.\nRichard Shin and Benjamin Van Durme. 2022. Few-\nshot semantic parsing with language models trained\non code. In Proceedings of the 2022 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, pages 5417–5425, Seattle, United States.\nAssociation for Computational Linguistics.\nSwadheen Shukla, Lars Liden, Shahin Shayandeh, Es-\nlam Kamal, Jinchao Li, Matt Mazzola, Thomas Park,\nBaolin Peng, and Jianfeng Gao. 2020. Conversa-\ntion Learner - a machine teaching tool for building\ndialog managers for task-oriented dialog systems.\nIn Proceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics: System\nDemonstrations, pages 343–349, Online. Association\nfor Computational Linguistics.\n13359\nPatrice Y . Simard, Saleema Amershi, David Maxwell\nChickering, Alicia Edelman Pelton, Soroush Gho-\nrashi, Christopher Meek, Gonzalo A. Ramos, Jina\nSuh, Johan Verwey, Mo Wang, and John Werns-\ning. 2017. Machine teaching: A new paradigm\nfor building machine learning systems. CoRR,\nabs/1707.06742.\nYixuan Su, Lei Shu, Elman Mansimov, Arshit Gupta,\nDeng Cai, Yi-An Lai, and Yi Zhang. 2022. Multi-task\npre-training for plug-and-play task-oriented dialogue\nsystem. Proceedings of the 60th Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nHaipeng Sun, Junwei Bao, Youzheng Wu, and Xi-\naodong He. 2022. Mars: Semantic-aware contrastive\nlearning for end-to-end task-oriented dialog. arXiv\npreprint arXiv:2210.08917.\nJindong Wang, Xixu Hu, Wenxin Hou, Hao Chen,\nRunkai Zheng, Yidong Wang, Linyi Yang, Haojun\nHuang, Wei Ye, Xiubo Geng, Binxin Jiao, Yue Zhang,\nand Xing Xie. 2023. On the robustness of chatgpt:\nAn adversarial and out-of-distribution perspective.\nQingyue Wang, Yanan Cao, Piji Li, Yanhe Fu, Zheng\nLin, and Li Guo. 2022a. Slot dependency model-\ning for zero-shot cross-domain dialogue state track-\ning. In Proceedings of the 29th International Confer-\nence on Computational Linguistics, pages 510–520,\nGyeongju, Republic of Korea. International Commit-\ntee on Computational Linguistics.\nYizhong Wang, Swaroop Mishra, Pegah Alipoormo-\nlabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva\nNaik, Arjun Ashok, Arut Selvan Dhanasekaran, An-\njana Arunkumar, David Stap, et al. 2022b. Super-\nnaturalinstructions: Generalization via declarative\ninstructions on 1600+ nlp tasks. In Proceedings of\nthe 2022 Conference on Empirical Methods in Natu-\nral Language Processing, pages 5085–5109.\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,\nBarret Zoph, Sebastian Borgeaud, Dani Yogatama,\nMaarten Bosma, Denny Zhou, Donald Metzler, Ed H.\nChi, Tatsunori Hashimoto, Oriol Vinyals, Percy\nLiang, Jeff Dean, and William Fedus. 2022. Emer-\ngent abilities of large language models.\nJason D. Williams and Lars Liden. 2017. Demonstra-\ntion of interactive teaching for end-to-end dialog con-\ntrol with hybrid code networks. In Proceedings of the\n18th Annual SIGdial Meeting on Discourse and Dia-\nlogue, Saarbrücken, Germany, August 15-17, 2017,\npages 82–85. Association for Computational Linguis-\ntics.\nChien-Sheng Wu, Andrea Madotto, Ehsan Hosseini-Asl,\nCaiming Xiong, Richard Socher, and Pascale Fung.\n2019. Transferable multi-domain state generator for\ntask-oriented dialogue systems. In Proceedings of the\n57th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 808–819, Florence, Italy.\nAssociation for Computational Linguistics.\nTianbao Xie, Chen Henry Wu, Peng Shi, Ruiqi Zhong,\nTorsten Scholak, Michihiro Yasunaga, Chien-Sheng\nWu, Ming Zhong, Pengcheng Yin, Sida I. Wang, Vic-\ntor Zhong, Bailin Wang, Chengzu Li, Connor Boyle,\nAnsong Ni, Ziyu Yao, Dragomir Radev, Caiming\nXiong, Lingpeng Kong, Rui Zhang, Noah A. Smith,\nLuke Zettlemoyer, and Tao Yu. 2022. UnifiedSKG:\nUnifying and multi-tasking structured knowledge\ngrounding with text-to-text language models. In Pro-\nceedings of the 2022 Conference on Empirical Meth-\nods in Natural Language Processing, pages 602–631,\nAbu Dhabi, United Arab Emirates. Association for\nComputational Linguistics.\nDian Yu, Luheng He, Yuan Zhang, Xinya Du, Panupong\nPasupat, and Qi Li. 2021. Few-shot intent classifi-\ncation and slot filling with retrieved examples. In\nProceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nNAACL-HLT 2021, Online, June 6-11, 2021, pages\n734–749. Association for Computational Linguistics.\nXiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara,\nRaghav Gupta, Jianguo Zhang, and Jindong Chen.\n2020. MultiWOZ 2.2 : A dialogue dataset with\nadditional annotation corrections and state tracking\nbaselines. In Proceedings of the 2nd Workshop on\nNatural Language Processing for Conversational AI,\npages 109–117, Online. Association for Computa-\ntional Linguistics.\nTianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore: Eval-\nuating text generation with bert. In International\nConference on Learning Representations.\nXiaoying Zhang, Baolin Peng, Jianfeng Gao, and He-\nlen Meng. 2022. Toward self-learning end-to-end\ntask-oriented dialog systems. In Proceedings of the\n23rd Annual Meeting of the Special Interest Group\non Discourse and Dialogue, pages 516–530.\nYichi Zhang, Zhijian Ou, and Zhou Yu. 2020. Task-\noriented dialog systems that consider multiple appro-\npriate responses under the same context. In Proceed-\nings of the AAAI Conference on Artificial Intelligence,\nvolume 34, pages 9604–9611.\nJeffrey Zhao, Yuan Cao, Raghav Gupta, Harrison Lee,\nAbhinav Rastogi, Mingqiu Wang, Hagen Soltau,\nIzhak Shafran, and Yonghui Wu. 2022. Anytod: A\nprogrammable task-oriented dialog system. arXiv\npreprint arXiv:2212.09939.\nTiancheng Zhao and Maxine Eskenazi. 2018. Zero-shot\ndialog generation with cross-domain latent actions.\nIn Proceedings of the 19th Annual SIGdial Meeting\non Discourse and Dialogue, pages 1–10, Melbourne,\nAustralia. Association for Computational Linguistics.\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and\nSameer Singh. 2021. Calibrate before use: Improv-\ning few-shot performance of language models. In\nProceedings of the 38th International Conference\n13360\non Machine Learning, volume 139 of Proceedings\nof Machine Learning Research, pages 12697–12706.\nPMLR.\nJingyan Zhou, Jiawen Deng, Fei Mi, Yitong Li, Yasheng\nWang, Minlie Huang, Xin Jiang, Qun Liu, and Helen\nMeng. 2022. Towards identifying social bias in di-\nalog systems: Framework, dataset, and benchmark.\nIn Findings of the Association for Computational\nLinguistics: EMNLP 2022 , pages 3576–3591, Abu\nDhabi, United Arab Emirates. Association for Com-\nputational Linguistics.\nDST Prompter\nT ask instruction\nFollowing the instructions, predict the belief state based on the\nhistory .\nBelief instructions\nrestaurant  name = pizza hut city , golden wok, etc.; food = dont\ncare, chinese, mediterranean, british, etc.; pricerange = dontcare,\ncheap, moderate, expensive; area = dont care, centre, east,\nnorth, south, west ; booking_day = monday , tuesday , wednesday ,\nthursday , friday , saturday , sunday; booking_people =\n1,2,3,4,5,6,7; booking_time = 12:15, 13:30, etc.\nattraction  attraction type = swimmingpool, theatre, architecture,\nmuseum, nightclub, boat, park, college, concerthall,\nentertainment, multiple sports, cinema; name = the cherry hinton\nvillage centre, soul tree nightclub, etc.; area = dont care, centre,\neast, north, south, west\nhotel  name = huntingdon marriott hotel, a and b guest house,\netc.; pricerange = dont care, cheap, moderate, expensive; area =\ndont care, centre, east, north, south, west; stars = dont care,\n0,1,2,3,4,5; parking = dont care, yes, no; internet = dont care,\nyes, no; type = hotel, guest house ; booking_day = monday ,\ntuesday , etc.; booking_people = 1,2,3,4,5,6,etc. ; booking_stay =\n1,2,3,4,etc.\ntrain  leaveat = 10:45, 12:06, etc. ; destination = norwich,\ncambridge, etc.; day = monday , tuesday , wednesday , thursday ,\nfriday , saturday , sunday ; arriveby = 21:00, 09:45, etc.; departure\n= cambridge, stansted airport, etc. ; booking_people =\n1,2,3,4,5,6, etc.\ntaxi  leaveat = 08:45, 16:15, etc. ; destination = saint john's\ncollege, kettle's yard, galleria, etc. ; departure = huntingdon\nmarriott taxi, cineworld cinema, bridge guest house, etc. ; arriveby\n= 17:15, 17:30, etc.\n...\nFigure 4: Detailed belief instructions in DST Prompter.\nA Zero-Shot Task-Oriented Dialog\nModeling.\nTable 7 summarizes four main research directions\nin zero-shot task-oriented dialog modeling: slot\nfilling (SF), dialog state tracking (DST), end-to-end\npolicy management (E2E policy) and end-to-end\ndialog generation (E2E dialog).\nB Detailed Belief Instructions in DST\nPrompter\nFigure 4 shows the detailed belief instructions in\nDST Prompter.\nC A Formatting Example in Policy\nPrompter\nFigure 5 presents a formatting example in Policy\nPrompter.\nD Experimental Setup\nDatasets.\n• Multiwoz 2.0 (Budzianowski et al., 2018) is\na multi-domain task-oriented dataset, which\n13361\nModel Task Schema types Training strategy\nFine-tuning Pre-training Prompting\nROBUST SF (Shah et al., 2019) SF slot names/value examples /enc-33\nTRADE (Wu et al., 2019) DST slot names/value examples /enc-33\nZSTL-SD (Campagna et al., 2020) DST ontology, dialog templates /enc-33(+synthesized data)\nS-DST (Rastogi et al., 2020b) DST slot names/descriptions /enc-33+service, intent names/descriptions\nT5DST (Lin et al., 2021b) DST slot names/descriptions /enc-33\nTRANSFER QA (Lin et al., 2021a) DST slot names/value examples /enc-33(QA tasks)\nIC-DST (Hu et al., 2022) DST slot names/value examples /enc-33\nSDM-DST (Wang et al., 2022a) DST slot names/value examples /enc-33\nBERT+S (Mosig et al., 2020) E2E policy system-side policy skeletons /enc-33\nSAM (Mehri and Eskenazi, 2021) E2E policy user-aware policy skeletons /enc-33\nZSDG (Zhao and Eskenazi, 2018) E2E dialog ontology, response templates /enc-33\nDAML (Qian and Yu, 2019) E2E dialog ontology, response templates /enc-33\nANYTOD (Zhao et al., 2022) E2E dialog\npolicy programs\n/enc-33 /enc-33(heterogeneous tasks)+slot names/value examples\n+slot descriptions\n+user action names/states/descriptions\nIG-TOD (Hudecek and Dusek, 2023) E2E dialog slot names /enc-33+slot descriptions\nSGP-TOD (ours) E2E dialog user-aware policy skeletons /enc-33(+slot names/value examples)\nTable 7: Zero-shot task-oriented dialog modeling. (Schema items enclosed in parentheses are required only when\naccessible.)\ncontains 8,438/1,000/1,000 dialogs for train-\ning/validating/testing, spanning seven do-\nmains: restaurant, attraction, train, hotel, taxi,\npolice, and hospital. Multiwoz 2.0 is anno-\ntated with belief states and system actions.\n• Multiwoz 2.2 (Zang et al., 2020) is a im-\nproved version of Multiwoz 2.0, encompass-\ning refined belief state annotations, slot de-\nscriptions, user action annotations, etc.\n• RADDLE (Peng et al., 2021a,c) consists of four\nsingle-domain dialog datasets derived from\nMultiwoz 2.0 (i.e., restaurant, train, hotel,\nattraction), reorganized by Peng et al. (2021a).\nEach corpus contains 50/50/200 dialogs for\ntraining/validating/testing, expect for 100 test-\ning dialogs in attraction domain.\n• STAR (Mosig et al., 2020) includes 24 tasks\nin 13 domains ( e.g., \"apartment\" domain\ncomprises \"apartment-search\" and \"apartment-\nschedule\"), requiring the dialog model to con-\nform to the provided task schema. We use\n2,688 single-task dialogs from the corpus,\nwhich follow a \"happy path\", i.e., the user\nis not instructed to execute any action exceed-\ning the schema’s expectations. Without ad-\nditional annotations, STAR only provides a\nflow chart diagram that outlines the dialog\npolicy for each task. The flow chart outlines\nthe task, including the sequence in which at-\ntributes should be asked (for example, ask for\nthe user’s name before asking for the hotel\nname), how to query a database, etc.\nAutomatic Evaluation Metrics. We evaluate the\nend-to-end dialog generation performance using\nthe same metrics as those listed in Budzianowski\net al. (2018): (i) Inform(%) assesses whether\nthe agent returns an acceptable entity. (ii)\nSuccess(%) determines if the agent appropriately\nresponds to each attribute request. (iii) BLEU(%)\n(Papineni et al., 2002) measures the word over-\nlap of the generated response against the human\nresponse in the corpus. (iv) Combined(%) judges\nthe overall quality, which is defined asCombined =\n(Inform + Success) ×0.5 + BLEU. Additionally,\nwe utilize BERTScore(%) (Zhang* et al., 2020),\nwhich focuses on computing semantic similarity\nbetween the generated responses and the ground\ntruth, and correlates better with human judgments.\nFollowing Mehri and Eskenazi (2021), we per-\nform the next action prediction task onSTAR, which\npredicts next system action based on the dialog his-\ntory. Since the system actions and deterministic\nresponse templates are mapped one to one in STAR\ncorpus, we believe the end-to-end next action pre-\ndiction task falls within end-to-end dialog model-\ning, following Mosig et al. (2020); Mehri and Eske-\nnazi (2021). In addition, we report the results using\nweighted F1score(%) and mean accuracy(%).\n13362\nPolicy Prompter\nT ask instruction\nFollowing the instructions, generate appropriate response based\non the history .\nFormatting example (from other task/domain)\nPolicy skeleton\n(1) user:  I'm looking for information on [attraction_name]. action:\nattraction (inform (name, address, area, entrance fee)) system:\n[attraction_name] is in the [value_area] and their address is\n[attraction_address], the entrance fee is [value_count] pounds.\n[eos] \n(2) user:  What is the phone number? action:  attraction (inform\n(phone), require (more)) system:  Their phone number is\n[attraction_phone]. is there anything else i can do for you? [eos]\n \n(3) user:  I need the area/location and the postcode. action:\nattraction (inform (area, postcode)) system:  The\n[attraction_name] is in the [value_area], their postal code is\n[attraction_postcode]. [eos] \n(4) user:  That is all i need today . thank you! action:  attraction\n(general (bye)) system:  Y ou are welcome , thank you for calling\nthe [value_place] town info [value_area]. have a great day . [eos]\n(5) DB:  attraction zero match. action:  attraction (inform\n(none)) system:  There are no results matching your query . Can i\ntry a dif ferent area or type? [eos]\n(6) DB:  attraction one match. action:  attraction (inform (name))\nsystem:  W e have [attraction_name]. [eos]\n(7) DB:  attraction five match. action:  attraction (inform (choices),\nrequest (area)) system:  T here are [value_count], which area\nwere you looking at? [eos]\nhistory\nuser: Hello, i'm looking for the museum of classical archaeology ,\ncould you tell me more about it? system: Certainly , the\n[attraction_name] is located at [attraction_address] and has free\nentrance, phone [attraction_phone] . do you also need the\npostcode ? user : Y es, i'd like that. thank you so much!\nSQL: select * from attraction where name = museum of classical\narchaeology DB: Attraction one match\naction: attraction (inform (postcode), require (more)) \nsystem : The postcode for the [attraction_name] is\n[attraction_postcode] . Is there anything else i can help you with ?\n...\n \nFigure 5: A formatting example in Policy Prompter.\nHuman Evaluation Metrics. We employ inter-\nactive human evaluations to assess the quality of\ndialog agents, following the evaluation protocol in\nthe DSTC9 Track 1 challenge (Gunasekara et al.,\n2020). We recruit student helpers to help with eval-\nuations. For each dialog session, student helpers\nare provided with a goal and accompanying in-\nstructions, subsequently necessitating a discourse\nwith the agent to achieve the goal via natural lan-\nguage. Upon the conclusion of each dialog ses-\nsion, students are mandated to assess the overall\ndialog quality employing these five metrics: (i)\nSuccess w/o g(%) evaluates whether the agent ac-\ncomplishes the task. (ii) Success w/ g(%) judges\nwhether the agent accomplishes the task and of-\nfers matched slot values compared to the database\nrecord. (iii) Understanding(1-5) quantifies the\naccuracy with which the agent comprehends user\nutterances. (iv) Appropriateness(1-5) signifies\nthe naturalness, appropriateness and fluency of an\nagent response. (v) Turns denotes the average\nnumber of dialog turns within successful dialog\nsessions.\nE Implementation Details\nRegarding SGP-TOD:\n• LLMs: We employ ChatGPT (\"gpt-3.5-\nturbo\"), GPT-3.5 (\"text-davinci-003\") and\nCodex (\"code-davinci-002\") as the fixed\nLLMs to implement the proposed SGP-TOD .\nThroughout the evaluation, we set temperature\nto 0.5.\n• DST Prompter – belief instruction: In the con-\ntext of multi-domain scenarios, the belief in-\nstructions encompassing all domains are incor-\nporated, while solely the target domain’s be-\nlief instruction is introduced in single-domain\nsettings.\n• Policy Prompter – policy skeleton: For the\nMultiwoz datasets, we manually construct the\npolicy skeleton through observing a few di-\nalogs in the training corpus, following Mosig\net al. (2020); Mehri and Eskenazi (2021). In\nthe case of the STAR corpus, we employ flow\nchart diagrams and several dialogs to develop\nthe policy skeleton, following the guidelines\nset forth by Mehri and Eskenazi (2021). We\nintegrate the relevant user template utterance\nand the system action into the policy skeleton,\nthereby augmenting the LLM’s understanding\nof directives, in the absence of belief anno-\ntations. The prompt examples for the STAR\ndataset are shown in Appendix M.\n• Formatting example: Following the zero-shot\nscenario in Wang et al. (2022b), we insert one\nformatting example from different tasks (fixed\nthrough the experimental procedure) into the\nprompt. The formatting example employed\nwithin DST Prompter/Policy Prompter is ran-\ndomly chosen from the training corpus of dif-\nferent tasks/domains, conforming to zero-shot\nscenario proposed by Wang et al. (2022b). We\nappraise multiple randomly selected format-\nting examples, the evaluation results reveal mi-\nnor deviations. In the experiments on domain\n13363\nextension (Section 4.5) and ablation analy-\nsis (Section 4.7), we employ the same (two)\nformatting exemplar turns originating from\nother domains within the RADDLE corpus for\nall prompting techniques.\nRegarding compared methods:\n(i) Zero-shot transfer methods:\n• BERT+S (Mosig et al., 2020) is a schema-\nguided method that augments a BERT-base\nclassifier (Devlin et al., 2019) with a provided\nsystem-side schema to predict the next system\naction.\n• SAM (Mehri and Eskenazi, 2021) represents\na schema-guided model based on BERT-base,\nwhich aligns the dialog context to a user-aware\nschema to predict the next system action.\n• ANYTOD-XXL (Zhao et al., 2022) adopts\na neural LM to track dialog states and user\nactions utilizing slot and action descriptions.\nThen a program that outlines a predefined task\npolicy is executed to recommend appropri-\nate system actions. Upon considering these\nsystem actions, an LM generates the ultimate\nsystem action and formulates the correspond-\ning template response using the approach pro-\nposed by Kale and Rastogi (2020).ANYTOD-\nXXL is implemented on T5-XXL (Roberts\net al., 2022) and pre-trained on SGD dataset\n(Rastogi et al., 2020a)8\n(ii) Prompting methods:\n• IG-TOD-C HATGPT (Hudecek and Dusek,\n2023) is a prompting approach based on\nChatGPT that leverages the dialog context\nand manually-crafted slot descriptions as the\nprompt, to track dialog states, fetch DB\nentries, and produce responses. IG-TOD-\nCHATGPT-ZS and IG-TOD-C HATGPT-FS\nare in the zero-shot and few-shot settings, re-\nspectively.\n• FEW-SHOT-CHATGPT is a few-shot prompt-\ning strategy implemented on ChatGPT, where\nwe use a few (i.e., k) dialog turns, randomly\nsampled from the training corpus to instruct\nChatGPT on task execution. Upon evaluating\n8The Schema-Guided Dialog (SGD) dataset constitutes a\ncomprehensive, large-scale, multi-domain corpus encompass-\ning over 16,000 dialogs that span across 16 distinct domains.\nvarious configurations of k, the optimal re-\nsults manifest with 15 on Multiwoz (2.0 and\n2.2), and 10 on RADDLE, exhibiting no further\nsubstantial enhancements.\n• SGP-TOD (Ours) is a schema-guided prompt-\ning strategy, which is compatible with any\noff-the-shelf LLMs. In this paper, we\nemploy ChatGPT (\"gpt-3.5-turbo\"), GPT-\n3.5 (\"text-davinci-003\") and Codex (\"code-\ndavinci-002\") as the fixed LLMs. Following\nthe zero-shot scenario in Wang et al. (2022b),\nwe insert one formatting example from dif-\nferent tasks (fixed through the experimental\nprocedure) into the prompt. More implemen-\ntation details are provided in Appendix E.\nF Zero-Shot End-to-End Evaluation\nResults onSTAR\nFigure 6 exhibits the zero-shot evaluation results\non STAR, utilizing varying amounts of training di-\nalogs (ranging from 1 to 1,000) and formatting\nexample turns (spanning from 1 to 10) from source\ndomains/tasks. SGP-TOD , merely with two for-\nmatting sample turns, achieves superior or compa-\nrable performance compared to BERT+S , SAM ,\nwhich are fine-tuned on adequate source data.\nWe observe thatSGP-TOD , employing only two\nformatting sample turns, attains superior or com-\nmensurate performance in terms of both F1score\nand Accuracy, when compared to SAM trained\nwith 1,000 dialogs. Given that a single dialog con-\ntains more than 10 dialog turns, this result suggests\nthat SGP-TOD diminishes labeling expenses by a\nminimum factor of 1,000. Furthermore, it is note-\nworthy that augmenting the quantity of formatting\nexemplar turns exerts a negligible influence on the\nperformance of SGP-TOD.\nG Ablation Study\nTable 8 exhibits the findings from an ablation in-\nvestigation, addressing the effects of the three inte-\ngral aspects of SGP-TOD in conjunction with the\ndatabase expertise, implemented on Multiwoz 2.0\nand 2.2, employing GPT-3.5.9 Combining the three\nelements in SGP-TOD with the database expertise\nproduces optimal results across both datasets. The\nremoval of the Policy Prompter, database knowl-\nedge, and DST Prompter leads to consistent de-\nclines in all evaluation metrics, underscoring the\n9We inject the same two formatting example turns into the\nprompt throughout the evaluation.\n13364\n1 10 100 1000\n# dialogs/example turns\n10\n20\n30\n40\n50Mean F1\nSAM\nBERT+S\nSGP-TOD-GPT3\nSGP-TOD-Codex\nSGP-TOD-GPT3-E2E\n(a) Task transfer\n1 10 100 1000\n# dialogs/example turns\n10\n20\n30\n40\n50Mean F1\nSAM\nBERT+S\nSGP-TOD-GPT3\nSGP-TOD-Codex\nSGP-TOD-GPT3-E2E (b) Domain transfer\n1 10 100 1000\n# dialogs/example turns\n15\n20\n25\n30\n35\n40\n45\n50Mean Accuracy\nSAM\nBERT+S\nSGP-TOD-GPT3\nSGP-TOD-Codex\nSGP-TOD-GPT3-E2E\n(c) Task transfer\n1 10 100 1000\n# dialogs/example turns\n20\n30\n40\n50Mean Accuracy\nSAM\nBERT+S\nSGP-TOD-GPT3\nSGP-TOD-Codex\nSGP-TOD-GPT3-E2E (d) Domain transfer\nFigure 6: Zero-shot end-to-end evaluation results on STAR with different numbers of training dialogs (1, 10, 100,\n1,000) / demonstration example turns (1, 10) from source domain/tasks.\nvalue of enhancing the fixed LLM with the task\nschema and external database information.\nSpecifically, GPT-3.5 (in the final row) exhibits\ncommendable zero-shot performance, highlighting\nthe need of exploiting its superior zero-shot gen-\neralization capabilities in dialog generation tasks.\nAdditionally, Disabling the Policy Prompterin-\ncurs a discernible decline in performance regarding\nSuccess (approximately 16%) and BLEU (roughly\n3%), as the Policy Prompter’s primary function is to\nprovide task completion guidelines and interaction\npatterns. Eliminating the database expertisepri-\nmarily reduces Success (by approximately 4%),\nimplying that incorporating database information\ncontributes to task completion. Lastly, excising the\nDST Prompterengenders a considerable diminu-\ntion in performance concerning Inform (around\n43%) and Success (nearly 18%), due to the DST\nPrompter’s intended purpose of assisting the frozen\nLLM in apprehending the dialog context.\nH Human Evaluation Details\nWe enlisted 5 student helpers (i.e., undergraduate\nstudents possessing basic proficiency in English\ncommunication) to participate in the evaluations.\nFor each dialog agent, we collected 50 dialogs for\nanalysis. Followed the methodology proposed by\nLi et al. (2022), we generated user goals through\nthe subsequent techniques: (i) Randomly selecting\nslots and slot values within the Restaurant do-\nmain from RADDLE corpus to construct a user goal;\n(ii) Replacing the slot values of the user goals in\nrandomly chosen dialogs from theRestaurant cor-\npus with corresponding new values from randomly\nsampled database entries, thus forming a new user\ngoal; (iii) Merging the user goals of several ran-\ndomly selected dialogs from the Restaurant cor-\npus to create a composite user goal. Lastly, we\nrandomly chose 50 distinct user goals from these\nnewly generated goals.\n13365\nModel Multiwoz 2.0 Multiwoz 2.2\nInform Success BLEU Combined Inform Success BLEU Combined\nSP-TOD-GPT3.5 83.88 69.87 9.09 85.97 82.00 72.50 9.22 86.47\n-policy 82.28 55.65 6.51 75.48 81.80 56.20 6.63 75.63\n-policy -DB 81.20 50.95 6.48 72.56 81.40 52.30 6.57 73.42\n-policy -DB -belief 38.74 33.13 6.18 42.12 38.60 33.90 6.29 42.54\nTable 8: Ablation study on the impact of the three components in the proposedSGP-TOD and the database expertise\non Multiwoz using GPT-3.5. -policy: removing Policy Prompter, -DB: removing database information, -belief:\nremoving DST Prompter.\nI Human Evaluation Results\nFigure 7 shows the interactive human evaluation\nresults. SGP-TOD-C HATGPT exhibits a more\nstable performance. In contrast to the automated\nevaluation results shown in Table 2, FEW-SHOT-\nCHATGPT significantly outperforms SOLOIST\nover all metrics. This indicates that corpus-based\nevaluations might be biased, given that real user\ninputs tend to be more dynamic, complex, even\nwith noise. Notably, SGP-TOD-C HATGPT con-\nsistently excels compared to the other methods in\nboth evaluations, implying its robustness in han-\ndling diverse user inputs.\nJ More Details and Results on Domain\nExtension\nSetup. Following Zhang et al. (2022), we con-\nstruct the Restaurant-ext corpus by extending\nthe pre-existing Restaurant in RADDLE (Peng\net al., 2021c) with additional functions. Specif-\nically, we introduce four new slots: [restau-\nrant_dish], [value_price], [start_time], and\n[end_time]. The initial slot pertains to recommen-\ndations for signature restaurant meals, while the\nfinal three concern delivery service details. All\ndatabase entries are updated with corresponding\nvalues. Table 10 exhibits a dialog example on do-\nmain extension. The associated Restaurant-Ext\ndatabase entry is illustrated in Table 9.\nCompared Methods.\n• ChatGPT, GPT-3.5 denote zero-shot prompt-\ning with base LLMs that receive merely two\nformatting example turns from other domains\nin RADDLE.10\n• SGP-TOD-C HATGPT, SGP-TOD-GPT3.5\nrepresent our SGP-TOD implementation,\nwith the Restaurant policy skeleton.\n10We utilize the same formatting example turns in all zero-\nshot prompting methods.\n• SOLOIST is trained with 50 training dialogs in\nthe Restaurant domain (previously reported\nin Table 2).\n• SOLOIST +TEACH is fine-tuning method en-\nhanced with machine teaching (Simard et al.,\n2017). Machine teaching is an efficient ap-\nproach to equip deployed task bots with the\nability to handle new functions by correct-\ning representative failed human-bot dialogs.\nWe deploy SOLOIST to converse with real\nusers, then implement machine teaching via\nConversational learner (Shukla et al., 2020),\nan effective machine teaching tool, to obtain\n10/50/50 examples in Restaurant-ext for\ntraining, validating, and testing. Finally, we\nfine-tune SOLOIST with gathered 10 training\ndialogs covering four new slots, resulting in\ndialog agent SOLOIST +TEACH .\n• FEW-SHOT-GPT3.5+T EACH is the few-shot\nprompting strategy augmented with machine\nteaching. Based on GPT-3.5, we utilize 10\nrandomly selected dialog turns from the col-\nlected 10 training dialogs as the prompt (with\npeak performance at 10), resulting in FEW-\nSHOT-GPT3.5+T EACH .\n• SGP-TOD-C HATGPT-E XT, SGP-TOD-\nGP3.5-E XT refer to SGP-TOD with\nRestaurant-Ext policy skeleton, where we\nonly add four template turns about four new\nslots to the policy skeleton of Restaurant.\nResults. Comparison with Base LLMs. The sub-\nstantial improvement of SGP-TOD-C HATGPT-\nEXT and SGP-TOD-GPT3.5-E XT over ChatGPT\nand GPT-3.5 illustrates SGP-TOD ’s efficiency in\nsupplying task-specific knowledge in a zero-shot\nway.\nImpact of Different LLMs. SGP-TOD-\nCHATGPT-E XT attains a lower BLEU yet a compa-\nrable BERTScore, suggesting that ChatGPT gener-\nates more diverse responses.\n13366\nSOLO. FS. SGP.\nModel\n0\n20\n40\n60\n80\n100Success w/o grounding (%)\n(a) Success w/o g ↑\nSOLO. FS. SGP.\nModel\n0\n20\n40\n60\n80\n100Success w/ grounding (%) (b) Success w/ g ↑\nSOLO. FS. SGP.\nModel\n0\n1\n2\n3\n4\n5Understanding (1-5) (c) Understanding ↑\nSOLO. FS. SGP.\nModel\n0\n1\n2\n3\n4\n5Appropriateness (1-5) (d) Appropriateness ↑\nSOLO. FS. SGP.\nModel\n0\n2\n4\n6\n8\n10\n12Turns (e) Turns ↓\nFigure 7: Interactive human evaluation results. SOLO.: SOLOIST , FS.: FEW-SHOT-CHATGPT, SGP.: SGP-TOD-\nCHATGPT.\nSlot Value\n\"address\" \"21 - 24 Northampton Street\"\n\"area\" \"west\"\n\"food\" \"british\"\n\"id\" \"14810\"\n\"location\" [52.21031, 0.11381]\n\"name\" \"saint johns chop house\"\n\"phone\" \"01223353110\"\n\"postcode\" \"cb30ad\"\n\"pricerange\" \"moderate\"\n\"type\" \"restaurant\"\n\"delivery\" \"yes\"\n\"delivery fee\" \"6 pounds\"\n\"dish\" \"Beef Wellington\"\n\"start_time\" \"10:30 am\"\n\"end_time\" \"22:40 pm\"\nTable 9: An example of Restaurant-Ext DB entry.\nThe newly introduced slot-value pairs relevant to the\nextended functionality are highlighted.\nK Case Study\nDespite the superior performance of the proposed\nSGP-TOD on GPT-3.5, we showcase interac-\ntive examples utilizing ChatGPT, a renowned and\npotent chatbot. In Table 11, a user engages\nwith ChatGPT (left) and SGP-TOD-C HATGPT-\nEXT (right) to complete the identical task on\nRestaurant-Ext.11 The user initiates the conver-\nsation by seeking recommendations for a Tuscan\nrestaurant with no price range preference. Lack-\ning external database information, ChatGPT con-\nveys inaccurate details (Turn 2), whereas SGP-\nTOD-C HATGPT-E XT informs users of the ab-\nsence of matching restaurants and proposes alter-\nnatives (Turn 2). This exemplifies the benefits of\nintegrating real-world expertise into the fixed LLM.\nFurthermore, ChatGPT persistently inquires about\n11ChatGPT and SGP-TOD-C HATGPT-E XT are previously\nreported in Table 4. The same two formatting example turns\nare incorporated into the prompt for both zero-shot strategies.\nthe desired price range despite the user’s indiffer-\nence. We argue that SGP-TOD assists the frozen\nLLM in discerning user intentions. In Turn 4, Chat-\nGPT continues to furnish fabricated details (i.e., the\nrestaurant name and phone number) concerning the\nnonexistent eatery, while SGP-TOD-C HATGPT-\nEXT identifies a suitable Korean restaurant and the\ncorresponding factual information. In contrast with\nChatGPT, SGP-TOD-C HATGPT-E XT adeptly ad-\ndresses inquiries about the delivery service (Turn\n6), indicating that SGP-TOD is capable of endow-\ning the frozen LLM with novel functionalities.\nL Our ProposedSGP-TOD with a Dialog\nExample\nFigure 8 illustrates the proposed SGP-TOD with a\ndialog example.\nM Prompt Examples forSTAR Dataset\nTwo exemplars of prompts for STAR dataset are\npresented in Figure 9 and Figure 10.\n13367\nTurn Utterance\n1 User: I want a restaurant on the west end of town.\n2 System: Ok. Are you looking for any particular type of food?\n3 User: I don’t care.\n4 System: Are you looking for a particular price range?\n5 User: A moderately priced restaurant would be good.\n6 System: How about Saint Johns Chop House? They serve moderately priced British food on the west side of town.\n7 User: Can i please have their address and phone number?\n8 System: Saint Johns Chop House’s address is 21-24 Northampton Street, their phone number is 01223353110.\n9 User: Does the restaurant offers delivery service? If it does, what’s the delivery fee?\n10 System: Yes, it does, and the delivery charges 6 pounds.\n11 User: Thank you, goodbye.\n12 System: Thank you for using our system. Goodbye.\nTable 10: A dialog example on domain extension. Task bots need learn to provide pertinent responses concerning\nthe expanded delivery service in subsequent interaction turns, adapting to the continually evolving user/enterprise\ndemands.\nTurn Interaction between a user and ChatGPT Turn Interaction between a user and SP-TOD-ChatGPT-Ext\n1 User: Hi, i’m looking for a place with Tuscan food\nin any price range. 1 User: Hi, i’m looking for a place with Tuscan food\nin any price range.\n2 System: Certainly, there are 3 Tuscan restaurants\nin town. What is your preferred price range? 2\nSystem: I am sorry, there are no Tuscan restaurants.\nHere are some other options: Korean, Italian, Chinese.\nWhich one would you like more information on?\n3 User: I don’t care about the price. Please recommend\none for me, i also need the phone number please. 3 User: How about any Korean restaurants?\nI also need the phone number please.\n4\nSystem: The phone number for Pizza Hut City Centre\nis 01223323737. Is there anything else i can help you\nwith today?\n4 System: Little Seoul is a Korean restaurant.\nTheir phone number is 01223308681.\n5 User: Does the restaurant offer delivery service?\nHow much does the delivery charge? 5 User: Does the restaurant offer delivery service?\nHow much does the delivery charge?\n6\nSystem: I’m sorry, but I could not find any information\non delivery fee in our database. You may want to contact\nthe restaurant directly to inquire about this. Is there\nanything else I can assist you with today?\n6 System: Yes, they offer delivery service and the delivery\ncharge is 4 pounds. Can I help you with anything else?\n7 User: No. Thank you, goodbye. 7 User: No. Thank you, goodbye.\n8 System: Glad i could assist you. Have a good day. 8 System: You’re welcome, have a great meal! Goodbye!\nTable 11: Illustration of two interactive examples between a user and CHATGPT (left), SGP-TOD-C HATGPT-E XT\n(right). Appropriate responses and inappropriate responses are highlighted.\nDialog History\nBelief State\nDB State\nSystem Action System Response\nDB\nLarge Language Model \nDST  Prompter Policy Prompter\nUser:  I am looking for a restaurant in\nthe moderate  price range serving\nmodern European  food. \nSystem :  I have at least 2 choices, do you have a\npreferred area in mind? \nUser: I’d like a restaurant on the south  end of\ntown, please.\nSQL: select * from Restaurant\nwhere pricerange = moderate;\nfood = modern European; area =\nsouth\nRestaurant 6 match\nRestaurant\n(recommend(name), \ninform (food, pricerange, area))\nSystem: How does [restaurant_name] sound? It\nserves [value_food] food in the\n[value_pricerange] price range on the\n[value_area] side of town.\nFigure 8: Illustration of the proposed SGP-TOD with a dialog example. Note that the belief state in the represented\nin the SQL format, the details of which are described in Section 3.3.\n13368\nPolicy Prompter\nT ask instruction\nGenerate appropriate system actions based on the history , following\nthe most relevant task rule.\nT est (on target task/domain)\nT ask schema\n(1) user:  hello [sep] system action:  hello [eos]\n(2) user:  what is the weather like? [sep] system action:\nweather_ask_day [eos]\n(3) user:  on [DA Y_OF_WEEK] [sep] system action:\nweather_ask_location [eos]\n......\nHistory\nuser: i want to know the weather for T uesday .\nFormatting example (from other task/domain)\nT ask schema\n(1) user:  Hello [sep] system action:  hello [eos]\n( 2) user:  I'd like to find out the status of my ride [sep] system\naction:  ask_name [eos]\n(3) user:  My name is [NAME] [sep] system action:\nride_ask_booking_number [eos]\n......\nHistory\nuser: Hi, i need to check my ride status.\nAnswer\n(2) user:  i'd like to find out the status of my ride [sep] system\naction:  ask_name [eos]\n         LLM \nAnswer\n(3) user:  on [DA Y_OF_WEEK] [sep]  system action: \nweather_ask_location [eos]\nFigure 9: Policy Prompter of SGP-TOD on STAR. The\nrelevant template turn within the input, the generated\nuser template utterance , and the system action in the\noutput are accentuated.\nPolicy Prompter\nT ask instruction\nGenerate appropriate system actions based on the history , following\nthe most relevant task rule.\nT est (on target task/domain)\nT ask schema\n(1) user:  hello [sep] system action:  hello system:  Hello, how can i\nhelp? [eos]\n(2) user:  what is the weather like? [sep] system action:\nweather_ask_day system:  For what day would you like the weather\nforecast? [eos]\n(3) user:  on [DA Y_OF_WEEK] [sep] system action:\nweather_ask_location system:  For what location would you like the\nweather forecast? [eos]\n......\nHistory\nuser: i want to know the weather for T uesday .\nFormatting example (from other task/domain)\nT ask schema\n(1) user:  Hello [sep] system action:  hello system:  Hello, how can i\nhelp? [eos]\n( 2) user:  I'd like to find out the status of my ride [sep] system\naction:  ask_name system:  Could you give me your name, please?\n[eos]\n(3) user:  My name is [NAME] [sep] system action:\nride_ask_booking_number system:  Can i get your booking ID,\nplease? [eos]\n......\nHistory\nuser: Hi, i need to check my ride status.\nAnswer\n(2) user:  i'd like to find out the status of my ride [sep] system\naction:  ask_name system:  Could you give me your name, please?\n[eos]\n         LLM \nAnswer\n(3) user:  on [DA Y_OF_WEEK] [sep]  system action: \nweather_ask_location  system:  For what location would you like the\nweather forecast? [eos]\nFigure 10: Policy Prompter ofSGP-TOD-E2E on STAR.\nThe relevant template turn in the input, the generated\nuser template utterance , the system action and the\nsystem response in the output are highlighted.\n13369",
  "topic": "Dialog box",
  "concepts": [
    {
      "name": "Dialog box",
      "score": 0.9359991550445557
    },
    {
      "name": "Computer science",
      "score": 0.7836306691169739
    },
    {
      "name": "Schema (genetic algorithms)",
      "score": 0.716924786567688
    },
    {
      "name": "Dialog system",
      "score": 0.6299700140953064
    },
    {
      "name": "Task (project management)",
      "score": 0.5301583409309387
    },
    {
      "name": "Human–computer interaction",
      "score": 0.5080959796905518
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4449020028114319
    },
    {
      "name": "Machine learning",
      "score": 0.25957995653152466
    },
    {
      "name": "World Wide Web",
      "score": 0.2105863094329834
    },
    {
      "name": "Engineering",
      "score": 0.10449400544166565
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I177725633",
      "name": "Chinese University of Hong Kong",
      "country": "HK"
    },
    {
      "id": "https://openalex.org/I2250653659",
      "name": "Tencent (China)",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210108985",
      "name": "Bellevue Hospital Center",
      "country": "US"
    }
  ],
  "cited_by": 12
}