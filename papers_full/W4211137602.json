{
  "title": "Language Model-Based Paired Variational Autoencoders for Robotic Language Learning",
  "url": "https://openalex.org/W4211137602",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5070488643",
      "name": "Ozan Ã–zdemir",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3125498464",
    "https://openalex.org/W3207832698",
    "https://openalex.org/W3100307207",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2962716343",
    "https://openalex.org/W2771461682",
    "https://openalex.org/W2293634267",
    "https://openalex.org/W3035695796",
    "https://openalex.org/W3176484337",
    "https://openalex.org/W3038033387",
    "https://openalex.org/W3102561192",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2142344747",
    "https://openalex.org/W2531409750",
    "https://openalex.org/W2984287396",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2862846329",
    "https://openalex.org/W3189104357",
    "https://openalex.org/W2998012869",
    "https://openalex.org/W3195535318",
    "https://openalex.org/W1959608418",
    "https://openalex.org/W2885804027",
    "https://openalex.org/W3211640812",
    "https://openalex.org/W2774441505",
    "https://openalex.org/W2963086650",
    "https://openalex.org/W3100675524"
  ],
  "abstract": "Human infants learn language while interacting with their environment in which their caregivers may describe the objects and actions they perform. Similar to human infants, artificial agents can learn language while interacting with their environment. In this work, first, we present a neural model that bidirectionally binds robot actions and their language descriptions in a simple object manipulation scenario. Building on our previous Paired Variational Autoencoders (PVAE) model, we demonstrate the superiority of the variational autoencoder over standard autoencoders by experimenting with cubes of different colours, and by enabling the production of alternative vocabularies. Additional experiments show that the model's channel-separated visual feature extraction module can cope with objects of different shapes. Next, we introduce PVAE-BERT, which equips the model with a pretrained large-scale language model, i.e., Bidirectional Encoder Representations from Transformers (BERT), enabling the model to go beyond comprehending only the predefined descriptions that the network has been trained on; the recognition of action descriptions generalises to unconstrained natural language as the model becomes capable of understanding unlimited variations of the same descriptions. Our experiments suggest that using a pretrained language model as the language encoder allows our approach to scale up for real-world scenarios with instructions from human users.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7848097085952759
    },
    {
      "name": "Autoencoder",
      "score": 0.7587720155715942
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6629015207290649
    },
    {
      "name": "Language model",
      "score": 0.6377566456794739
    },
    {
      "name": "Transformer",
      "score": 0.6320792436599731
    },
    {
      "name": "Encoder",
      "score": 0.5331605672836304
    },
    {
      "name": "Object (grammar)",
      "score": 0.5161731839179993
    },
    {
      "name": "Natural language",
      "score": 0.4817102551460266
    },
    {
      "name": "Robot",
      "score": 0.4448356032371521
    },
    {
      "name": "Artificial neural network",
      "score": 0.4311472177505493
    },
    {
      "name": "Visual reasoning",
      "score": 0.4142785370349884
    },
    {
      "name": "Natural language processing",
      "score": 0.4084756076335907
    },
    {
      "name": "Engineering",
      "score": 0.06999117136001587
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": []
}