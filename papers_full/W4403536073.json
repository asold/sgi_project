{
    "title": "AgoneTest: Automated creation and assessment of Unit tests leveraging Large Language Models",
    "url": "https://openalex.org/W4403536073",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5107178972",
            "name": "Andrea Lops",
            "affiliations": [
                "Polytechnic University of Bari"
            ]
        },
        {
            "id": "https://openalex.org/A1959280910",
            "name": "Fedelucio Narducci",
            "affiliations": [
                "Polytechnic University of Bari"
            ]
        },
        {
            "id": "https://openalex.org/A2166987554",
            "name": "Azzurra Ragone",
            "affiliations": [
                "University of Bari Aldo Moro"
            ]
        },
        {
            "id": "https://openalex.org/A2513199837",
            "name": "Michelantonio Trizio",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4387711873",
        "https://openalex.org/W2395052532",
        "https://openalex.org/W4220852596"
    ],
    "abstract": "Software correctness is crucial, with unit testing playing an indispensable role in the software development lifecycle. However, creating unit tests is time-consuming and costly, underlining the need for automation. Leveraging Large Language Models (LLMs) for unit test generation is a promising solution, but existing studies focus on simple, small-scale scenarios, leaving a gap in understanding LLMs' performance in real-world applications, particularly regarding integration and assessment efficacy at scale. Here, we present AgoneTest, a system focused on automatically generating and evaluating complex class-level test suites. Our contributions include a scalable automated system, a newly developed dataset for rigorous evaluation, and a detailed methodology for test quality assessment.",
    "full_text": null
}