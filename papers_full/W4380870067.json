{
  "title": "A scoping review on quality assessment tools used in systematic reviews and meta-analysis of real-world studies",
  "url": "https://openalex.org/W4380870067",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5052653928",
      "name": "Tadesse Gebrye",
      "affiliations": [
        "Manchester Metropolitan University"
      ]
    },
    {
      "id": "https://openalex.org/A5035648630",
      "name": "Francis Fatoye",
      "affiliations": [
        "Manchester Metropolitan University"
      ]
    },
    {
      "id": "https://openalex.org/A5042630495",
      "name": "Chidozie Emmanuel Mbada",
      "affiliations": [
        "Manchester Metropolitan University"
      ]
    },
    {
      "id": "https://openalex.org/A5028834947",
      "name": "Zalmaï Hakimi",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2255222715",
    "https://openalex.org/W1558699142",
    "https://openalex.org/W3156775206",
    "https://openalex.org/W1974032447",
    "https://openalex.org/W2538488284",
    "https://openalex.org/W1505397543",
    "https://openalex.org/W2070745918",
    "https://openalex.org/W1709885097",
    "https://openalex.org/W3178749987",
    "https://openalex.org/W2543818161",
    "https://openalex.org/W3122836130",
    "https://openalex.org/W2762375226",
    "https://openalex.org/W2990713345",
    "https://openalex.org/W2940867124",
    "https://openalex.org/W2075950485",
    "https://openalex.org/W4210336301",
    "https://openalex.org/W3206999035",
    "https://openalex.org/W3131633398",
    "https://openalex.org/W3063829097",
    "https://openalex.org/W2947802790",
    "https://openalex.org/W3174840106",
    "https://openalex.org/W2339595738",
    "https://openalex.org/W3043144970",
    "https://openalex.org/W4281733293",
    "https://openalex.org/W4224004781",
    "https://openalex.org/W2920828889",
    "https://openalex.org/W4280580866",
    "https://openalex.org/W2346262725",
    "https://openalex.org/W2073644162",
    "https://openalex.org/W2013293270",
    "https://openalex.org/W3023503681",
    "https://openalex.org/W2079212138",
    "https://openalex.org/W2171251365",
    "https://openalex.org/W2136899564",
    "https://openalex.org/W2969341057",
    "https://openalex.org/W3082377467"
  ],
  "abstract": null,
  "full_text": "Vol.:(0123456789)1 3\nRheumatology International (2023) 43:1573–1581 \nhttps://doi.org/10.1007/s00296-023-05354-x\nREVIEW\nRheumatology\nINTERNATIONAL \nA scoping review on quality assessment tools used in systematic \nreviews and meta‑analysis of real‑world studies\nTadesse Gebrye1  · Francis Fatoye1,2  · Chidozie Mbada1  · Zalmai Hakimi3 \nReceived: 26 April 2023 / Accepted: 26 May 2023 / Published online: 16 June 2023 \n© Crown 2023\nAbstract\nRisk of bias tools is important in identifying inherent methodical flaws and for generating evidence in studies involving \nsystematic reviews (SRs) and meta-analyses (MAs), hence the need for sensitive and study-specific tools. This study aimed \nto review quality assessment (QA) tools used in SRs and MAs involving real-world data. Electronic databases involving \nPubMed, Allied and Complementary Medicine Database, Cumulated Index to Nursing and Allied Health Literature, and \nMEDLINE were searched for SRs and MAs involving real-world data. Search was delimited to articles published in English, \nand between inception to 20 of November 2022 following the SRs and MAs extension for scoping checklist. Sixteen articles \non real-world data published between 2016 and 2021 that reported their methodological quality met the inclusion criteria. \nSeven of these articles were observational studies, while the others were of interventional type. Overall, 16 QA tools were \nidentified. Except one, all the QA tools employed in SRs and MAs involving real-world data are generic, and only three of \nthese were validated. Generic QA tools are mostly used for real-world data SRs and MAs, while no validated and reliable \nspecific tool currently exist. Thus, there is need for a standardized and specific QA tool of SRs and MAs for real-world data.\nKeywords Quality assessment tool · Real-world data · Systematic review · Meta-analysis\nIntroduction\nSystematic Reviews (SRs), evidence-based medicine, and \nclinical guidelines bring together trustworthy information \nby systematically acquiring, analysing, and transferring \nresearch findings into clinical, management, and policy \narenas [ 1]. As such, findings of different work in medical \nliterature on related topics are evaluated using SRs and \nmeta-analyses (MAs), through the application of scientific \nstrategies that limit bias and errors that occur by chance \n[2]. Availability of the best evidence obtained though SRs \nand MAs is necessary to help clinicians, policy makers and \npatients reach the best health care decisions [3 ]. However, \nSRs and MAs require resources, take time, and are labour-\nintensive, as well, they may not always be warranted or pos-\nsible. For example, a study estimated the expense of SRs for \nacademic institutions and pharmaceutical companies to cost \napproximately $141,194.80, and on average, the total cost of \nall SRs per year to academic institutions and pharmaceutical \ncompanies amounts to $18,660,304.77 and $16,761,234.71 \n[4]. Therefore, unnecessary duplication of SRs should be \navoided for cost, as well as given the large unmet need \nfor SRs of a wide range of questions and the need to keep \nreviews up-to-date [5].\nTo use the results of SRs and MAs, it is important to \nassess the methodological quality of the primary studies \n[6]. Methodological quality assessment (QA) is the pro-\ncess of assessing the design and conduct of the included \nstudies, and it is useful to establish transparency of evi-\ndence synthesis and to guarantee the certainty of the body \n * Tadesse Gebrye \n t.gebrye@mmu.ac.uk\n Francis Fatoye \n f.fatoye@mmu.ac.uk\n Chidozie Mbada \n c.mbada@mmu.ac.uk\n Zalmai Hakimi \n zalmai.hakimi@sobi.com\n1 Department of Health Professions, Faculty of Health, \nPsychology, and Social Care, Manchester Metropolitan \nUniversity, Brooks Building, Birley Fields Campus, Bonsall \nStreet, 53 Bonsall Street, Manchester M15 6GX, UK\n2 Lifestyle Diseases, Faculty of Health Sciences, North-West \nUniversity, Mahikeng, South Africa\n3 Apellis Pharmaceuticals, Zug, Switzerland\n1574 Rheumatology International (2023) 43:1573–1581\n1 3\nof evidence of the review objective [7, 8]. The main reason \nfor assessing methodological quality of primary studies \nis to identify risks of bias [ 9] which may be due to poor \nreporting and several design features that are dependent on \nthe research question. Poor reporting may prevent assess-\nment of key features of design, making it difficult to eval-\nuate whether the study methodology has been adequate \n[10]. According to National Health and Medical Research \nCouncil [11], “risks of bias refer to the likelihood that \nfeatures of the study design or conduct of the study will \ngive misleading results”, and thus bring about misused \nresources, un-thriftiness for effective interventions or harm \nto consumers [11].\nA systematic review of methodological assessment tools \nfor preclinical and clinical studies, and clinical practice \nguidelines show that there are a variety of methodological \nassessment tools for different types of study design [12]. \nThus, it is critical to identify the study type before choos-\ning the corresponding QA tool. In accordance, Zeng and \ncolleagues [12] submit that further efforts in the develop-\nment of critical appraisal tools are warranted for areas that \ncurrently lack such tools. However, there is an apparent \ndearth of specific QA tool for real-world evidence (RWE) \nstudies. According to Food and Drugs Administrations \n[13], “RWE is the clinical evidence about the usage and \npotential benefits, or risks of a medical product derived \nfrom analysis of real-world data (RWD)”. Whereas RWD \nare routinely collected data pertaining to health status and/\nor health care delivery of the patient which are collected \nfrom a range of sources” [14] including claims, clinical \nstudies, clinical setting, pharmaceuticals, and patient-\npowered platforms [15, 16].\nThe increasing use of electronic health records, and \nhealth information systems has led to repositories of large \nvolumes of complex longitudinal RWD [17]. Thus, RWD \nare mostly diversified, but generally are medical records, \nprescription data and lifestyle-related information from \nhealth care providers, hospitals, and pharmacies [18]. \nFor primary studies based on RWD, the quality of their \ndata should be defined in context, clearly represented, and \naccessible [15, 19]. For example, Hyrich [20] concludes \nthat RWD plays significant role in rheumatology because \nit helps to better understand disease progression and treat -\nment outcomes beyond the conclusions of a clinical trial, \nas it provides a platform to \"test\" outcomes in an uncon-\ntrolled, real-life environment. Furthermore, the author \nposits that there is need to generate trustworthy conclu-\nsions from RWD by ensuring appropriate methodological \nand ethical considerations for handling RWD. Given the \nimportance of RWD in research, population health, quality \nimprovement, clinical decision support, and personalised \nmedicine [21], it is necessary to explore the existing QA \ntools that have been used for SRs and MAs that involved \nRWD. Hence, this scoping review of QA tools used for \nSRs and MAs that involved RWD.\nMethods\nScoping review\nWe conducted a scoping review, a type of literature review \nthat is used when it is difficult to identify a narrow review \nquestion; no prior synthesis has been undertaken on the \ntopic; studies in the review sources are likely to have \nemployed a range of data collection and analysis tech-\nniques; and a quality assessment of reviewed sources is \nnot going to be conducted [22].\nSearch strategy\nAn electronic database search was carried out by the \nreviewers through November 2022 using the following \ndatabases: PubMed, Allied and Complementary Medi-\ncine Database (AMED), Cumulated Index to Nursing and \nAllied Health Literature (CINAHL), and MEDLINE. The \nkeywords used in the search included a combination of \nRWE, RWD, routinely collected data, electronic health \nrecords, claims and billing activities, registries, meta‐\nanalysis, and systematic review (Appendix 2). Further, a \nmanual search of reference sections of the included studies \nwas also checked for additional studies. The search was \ndelimited to articles published in English language.\nStudy selection and data extraction\nOne reviewer screened the abstracts of all publications \nobtained by the search strategies. Studies meeting the \nfollowing inclusion criteria were selected for further \nreview: interventional or observational studies, using real-\nworld data, employed methodological QA tools. SRs or \nMAs not based on RWD and not methodological quality \nassessed were excluded. The potential eligible papers were \nretrieved, and the full articles were obtained and assessed \nfor their relevance by two reviewers (TG & CEM) based \non the preplanned criteria for inclusion. Any disagreement \nin study selection was resolved through discussion and \nconsultation with a third reviewer (FF) where necessary.\nA summary table was used to display the extracted \ndata. The following data were extracted: authors and date, \ntype of study, type of QA tool, number of items, domains, \nwhether the tool is generic or specific, time to complete \nthe tool, psychometric properties (validity and reliability), \npopulation/studies used to validate the tool, and name of \n1575Rheumatology International (2023) 43:1573–1581 \n1 3\nthe unit that developed the tool. The reviewers resolved \ndifferences through discussion to achieve consensus.\nData synthesis\nStudy data were extracted by three reviewers into a tem-\nplate. Findings for each study focusing on the QA tools used \nin SRs and MAs of RWD were then summarized by one \nreviewer, and the summaries discussed and modified by the \nresearch team as necessary, to generate an overall conclusion \nabout the quality assessment (QA) tools used in SRs and \nMAs involving real-world data.\nResults\nThe search strategy retrieved 4,954 (PubMed = 4369; \nAMED = 5; CINHAL = 182; Medline = 398) articles from \nfour databases (Fig. 1). After duplicates removal, the tittles, \nand abstracts of 4,153 publications were screened. From this, \nonly 75 studies were included for full-text screening and 16 \narticles met the inclusion criteria.\nCharacteristics of included studies\nThe characteristics of the included studies are presented \nin Table  1. The included studies were published between \n2016 and December 2021. Seven of the included studies \nwere observational type and the remaining were interven-\ntional and observational type of studies. The included stud-\nies applied various QA tools. The number of items used for \nQA within the included studies ranged from 4 to 22. Seven \nof the included studies comprised core domains that con-\ntains different questions employed for quality assessment. \nOnly one [23] of the included studies utilised very specific \ntools for methodological quality assessment. Three [24–26] \nof the included studies employed validated QA tools. In \norder to validate the tools used in the included studies, they \nemployed 39 non-randomised studies [24], 131 cohort stud-\nies [25] and 30 cost-effectiveness studies [26]. On the other \nhand, the QA tools utilised to the remaining thirteen of the \nincluded studies were not validated.\nNon‑summative four‑point system\nNon-summative four-point system is one of the included \nstudies used a QA tool specific to real-world data [23]. \nThe tool was developed by Wylde and colleagues, it is \nFig. 1  Flow diagram of publica-\ntions included and excluded in \nthe review\nRecords identified through database searching\n(n=4,954) \nPubMed, (n=4369); AMED, (n=5); \nCINHAL, (n=182); Medline (n=398)\nScreeningIncluded Eligibility Identification\nRecords excluded after screening \nby title & abstract \n(n=4078)                      \nFull-text articles assessed for eligibility\n(n=75)\nFull-text articles excluded (n=59)\nStudies included in data synthesis \n(n=16)\nRecords after duplicates removed                 \n(n=4,153)\n1576 Rheumatology International (2023) 43:1573–1581\n1 3\nTable 1  Characteristics of the tools used in the included studies\nAuthors (years) Type of \nstudy\nType of tool Number \nof items\nScale Domains Generic/specific Validity/reliability Population/\nstudies \nused for \nvalidation\nDevelopmental \nunit\nHalling et al. [27] Interven-\ntion and \nobser-\nvational \nstudies\nQA Tool for obser-\nvational cohort \nand cross-sectional \nStudies\n14 Good, fair, \nor poor\nN/A Generic Not validated The tool \nis still \ndevelop-\ning\nNational Insti-\ntutes of Health; \nBethesda, \n USAΩ\nCoratti et al. [24] Interven-\ntion and \nobser-\nvational \nstudies\nA risk of bias assess-\nment tool for non-\nrandomized studies\n6 Low, high, \nor unclear\nN/A Generic Validated 39 nonran-\ndomised \nstudies\nNational \nEvidence-Based \nHealthcare \nCollaborating \nAgency and the \nHealth Insur-\nance Review \nand Assessment \nService of the \nRe-public of \nKorea\nHidayat et al. [28] Interven-\ntion and \nobser-\nvational \nstudies\nThe Newcastle Ottawa \nScale (NOS): nonran-\ndomised studies\n9 Low, mod-\nerate or \nhigh\nYes (n = 3) Generic Validated 131 cohort \nstudies \nincluded \nin eight \nmeta-\nanalyses\nOngoing collabo-\nration between \nthe Universities \nof Newcastle, \nAustralia and \nOttawa, Canada\nKolmos et al. [29] Observa-\ntional \nstudies\nCASP checklist for \ncohort studies, \nprospective—or \nretrospective registry \nstudies\n12 Yes, can't \ntell, no\nYes (n = 11) Generic Not validated NA CASP checklists \nwere developed \nin 1993\nAlipour et al. [25] Observa-\ntional \nstudies\nThe Newcastle Ottawa \nScale (NOS): ran-\ndomised controlled \ntrials and studies\nreporting non-ran-\ndomised controlled \ncomparisons\n9 Low, \nmoderate, \nor high \nquality\nYes\n(n = 3)\nGeneric Validated 131 cohort \nstudies \nincluded \nin eight \nmeta-\nanalyses\nOngoing collabo-\nration between \nthe Universities \nof Newcastle, \nAustralia and \nOttawa, Canada\n1577Rheumatology International (2023) 43:1573–1581 \n1 3Table 1  (continued)\nAuthors (years) Type of \nstudy\nType of tool Number \nof items\nScale Domains Generic/specific Validity/reliability Population/\nstudies \nused for \nvalidation\nDevelopmental \nunit\nEvans et al. \n[23]\nObservational studies Non-summative \nfour-point \nsystem \nfor large \ndatabases and \nregistries\n4 Adequate, not adequate \nor not reported\nN/A Specific Not validated N/A Wylde and col-\nleagues\nvan der List \net al. [30]\nIntervention and obser-\nvational studies\nGRADE: retro-\nspective and \nprospective \ncohort studies\n12 Low risk, some concerns, \nhigh risk\nN/A Generic Not validated N/A The GRADE \nWorking \nGroup\nRahhal et al. \n[31]\nIntervention and obser-\nvational studies\nROBINS-I: \nobservational\nnon-rand-\nomized \nstudies\n7 Low, moderate, serious, \ncritical risk of bias and \nno information\nN/A Generic Not validated N/A Members of \nthe Cochrane \nBias Methods \nGroup and \nthe Cochrane \nNon-Ran-\ndomised \nStudies of \nInterventions \nMethods \nGroup\nLu et al. [26] Intervention and obser-\nvational studies\nThe Quality of \nHealth Eco-\nnomic Studies \n(QHES) \ninstrument: \ndecision-ana-\nlytic models\n16 Extremely poor quality, \npoor quality, fair qual-\nity, and high quality\nN/A Generic Validated 30 cost-effectiveness \nstudies\nJoshua and col-\nleagues\n1578 Rheumatology International (2023) 43:1573–1581\n1 3\nTable 1  (continued)\nAuthors (years) Type of \nstudy\nType of tool Number \nof items\nScale Domains Generic/specific Validity/reliability Population/\nstudies \nused for \nvalidation\nDevelopmental \nunit\nNicholas et al. \n[32]\nObservational studies Modified ver-\nsion of NOS: \ncohort and \ncase–control \nstudies\n6 Full-quality score, \npartial-quality score, \nand poor-quality score\nYes\n(n = 2)\nGeneric Not available N/A Zeng and col-\nleagues\nOmarini \net al. \n[33]\nIntervention and \nobservational \nstudies\nSTROBE: \ncohort, case–\ncontrol, and \ncross-sectional \nstudies\n22 Suitable or poor Yes\n(n = 4)\nGeneric Not validated N/A N/A\nTahra \net al. \n[34]\nObservational \nstudies\nAssessing risk \nof bias in \nprevalence \nstudies\n10 low risk; moderate \nrisk; high risk\nYes Generic Not validated N/A N/A\nFatoye \net al. \n[35]\nObservational \nstudies\nAssessing risk \nof bias in \nprevalence \nstudies:\n11 low risk; moderate \nrisk; high risk \n(Modified ver-\nsion)\nYes Generic Not validated N/A Hoy and \ncol-\nleagues\nLin \net al. \n[36]\nIntervention and \nobservational \nstudies\nThe modi-\nfied version \nof NOS: \nretrospective \ncohort studies \nand case series\n7 low, moderate, or \nhigh\nquality\nYes\n(n = 2)\nGeneric Not validated N/A Wells and \ncol-\nleagues\nAlsad-\nhan \net al. \n[37]\nObservational \nstudies\nThe Joanna \nBriggs Insti-\ntute Critical \nAppraisal tool \nfor prevalence \nstudies:\n10 High, moderate, \nor low\nN/A Generic Not validated N/A Joanna \nBriggs \nInstitute\nErdos \nand \nWild \n[38]\nIntervention and \nobservational \nstudies\nThe Institute of \nHealth Eco-\nnomics (IHE) \nRisk of Bias \nchecklist\n20 Low, moderate, or \nhigh\nYes\n(n = 8)\nGeneric Not validated N/A IHE\nGRADE The Grades of Recommendation, Assessment, Development, and Evaluation, ROBINS-I The Risk of Bias in Non-randomized Studies of Interventions, N/A Not Available, STROBE The \nStrengthening the Reporting of Observational Studies in Epidemiology Statement, CASP Critical Appraisal Skills Program\nΩ These tools have not been independently published\n1579Rheumatology International (2023) 43:1573–1581 \n1 3\nnon-summative four-point system [19]. The tool consisted \nof four items used to assess selection bias (inclusion of \nconsecutive patients and representativeness), bias due to \nmissing data (follow-up rates) and bias due to inadequate \nconsideration of confounding (multivariable or univariable \nanalysis). Each item was rated as adequate, not adequate or \nnot reported.\nDiscussion\nIn this paper, we reviewed the methodological QA tools \nfor SRs and MAs used in RWE studies. The included stud-\nies in our review were published between 2016 and 2021, \nthis finding aligns with the period of recent surge of use of \nmethodological QA tools in real-world data studies. How -\never, there is inadequate use of QA tool in RWD compared \nto other SRs and MA using randomised clinical trial [39]. \nThe use of appropriate QA tools in SRs and MAs involv -\ning RWD is needed to generate trustworthy conclusions \nand acceptable evidence and recommendations to be used \nin health care [40]. The key point that is considered in \nthe process of utilising evidence from SRs and MAs is \nwhether critical appraisal is carried out or not [41]. For \nexample, the findings of a study [42] that assessed the \nmethodological, reporting and evidence quality of SRs and \nMAs of total glucosides of paeony for rheumatoid arthritis \nindicated that although included studies summarised that \nglucoside of paeony was effective and safe in the treatment \nof rheumatoid arthritis, the methodological and reporting \nquality and the quality of evidence was poor. As a result, \nthe study recommended that decision-makers should \nbe prudent when using glucosides of paeony in treating \nrheumatoid arthritis. Hyrich [20] in highlighting the key \nrole of RWD in rheumatology, noted that methodological \nchallenges in analysing RWD is a significant challenge to \ngenerating reliable scientific output using RWD.\nVariation was observed within the QA tools used in the \nSRs and MAs with regard to content of domains, checklist, \nand scales. For example, some of the QA criteria such as \ninclusion of consecutive patients, representativeness, and \nfollow-up were frequently reported in QA tools. Thus, the \nabsence of a specific QA tool can restrict the process of \nconsistent and reliable appraisal for SRs and MAs studies \nthat have used RWD. In the current review, the authors \nobserved that some of the QA tools were adapted or mod-\nified [23, 32, 34, 36], whereas others used generic QA \ntools. Overall, little consensus was observed around the \nQA tools of the SRs and MAs for RWE studies.\nThe absence of a standard and specific QA tool for \nSRs and MAs involving RWE studies have resulted in the \nuse of different types of QA tools that have been devel-\noped for other studies with a different methodology such \nas randomised controlled studies, cross-sectional stud-\nies. Except one [23], all the included studies for the cur -\nrent review have used different sets of QA tools that are \ngeneric. The tool developed by Evans and colleagues [23] \nwas specific and consists of four items including inclusion \nof consecutive patients, representativeness, percentage of \nfollow-up and minimisation of potential confounding. \nHowever, this QA tool was not validated, as its psycho-\nmetric properties are lacking. Psychometric properties of \na test are tests that identify and define critical aspects of \nan instrument that include its adequacy, relevance, and \nusefulness (or its validity) [43]. Other authors argued that \nthere should be a QA tool which is specific to SRs and \nMAs for RWE that have been psychometrically tested for \ntheir feasibility, reliability, and validity [44].\nThe criteria to be used for QA in each type of tools are \ndifferent and no specific tool covers all the methodological \naspects. It is due to these methodological differences that \nrelevant evaluation tools are developed based on the char -\nacteristics of different types of study. Some evaluation tools \nare, for example, used without recommendations for criti-\ncal appraisal of evidence [45]. There are also many types of \nresearch methods such as before-after study (time series) and \nnested case–control study that do not have QA tools [46]. It is \nimportant that efforts should be made on developing QA tools \nfor SRs and MAs of RWD.\nThis scoping review has certain strength and limitations. In \nthis review, we used a systematic approach such as the screen-\ning of numerous data bases, and the involvement of multiple \nreviewers. Only studies conducted in English language were \nincluded, therefore, there is the possibility that some other \nrelevant studies in other languages could have been excluded. \nNevertheless, this review serves as a foundation for further \nwork on QA tools in SRs and MA using RWD. Identifica-\ntion of appropriate QA tool for a specific type of study should \nbe the priority for those utilising evidence from them. This \nis because it will be useful to increase the transparency and \nreproducibility of scientific work in real-world evidence. This \nstudy could be a foundation by way of summarising the QA \ntools while pointing out potential improvements to be adopted \nin the future.\nConclusions\nThe findings of the present scoping review indicated that many \ndifferent types of QA tools are currently used for RWD of SRs \nand MAs studies, while no validated and reliable specific tool \ncurrently exist. Thus, there is a need for a standardized and \nspecific QA tool of SRs and MAs for RWD.\nSupplementary Information The online version contains supplemen-\ntary material available at https:// doi. org/ 10. 1007/ s00296- 023- 05354-x.\n1580 Rheumatology International (2023) 43:1573–1581\n1 3\nAuthor Contributions TG participated in the design of the study, car -\nried out the literature search and selection process, charted and mod-\nelled the data and drafted the paper. FF, CEM and ZH also partici-\npated in the design of the study, the literature selection process and \nthe modelling of the data and helped to draft the paper. All the authors \nparticipated in modelling the data, drafting the paper and reading and \napproving the final version of this manuscript.\nFunding This research did not receive any specific grant from funding \nagencies in the public, commercial, or not-for-profit sectors.\nData availability All results from our analyses are published in the Sup-\nplementary Material, available at Rheumatology International online. \nItems/domains employed to the included studies and extracted by our \ninvestigators are available upon reasonable request.\nDeclarations \nConflict of Interest The authors have no conflict of interests to declare.\nEthical Approval For this study ethical approval is not required.\nInformed Consent The patient’s written informed consent was not \nmade, as this was a systematic review study.\nDisclaimer No part of this review is copied or published elsewhere \nin whole or in part in any languages. The information in Appendix 1 \nare Items/domains employed to the included studies. They are specific \ncriteria developed to be used for quality assessment.\nData Sharing All data related to this work are available in this research \narticle.\nOpen Access  This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article's Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article's Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nReferences\n 1. Manchikanti L (2008) Evidence-based medicine, systematic \nreviews, and guidelines in interventional pain management, part I: \nintroduction and general considerations. Pain Physician 11(2):161\n 2. Oxman AD, Schünemann HJ, Fretheim A (2006) Improving the \nuse of research evidence in guideline development: 8. Synthesis \nand presentation of evidence. Health Res Policy Syst 4(1):1–10\n 3. Moosapour H, Saeidifard F, Aalaa M, Soltani A, Larijani B (2021) \nThe rationale behind systematic reviews in clinical medicine: a \nconceptual framework. J Diabetes Metab Disord 20:919–929\n 4. Michelson M, Reuter K (2019) The significant cost of system-\natic reviews and meta-analyses: a call for greater involvement of \nmachine learning to assess the promise of clinical trials. Contemp \nClin Trials Commun 16:100443\n 5. Chinnock P, Siegfried N, Clarke M (2005) Is evidence-based \nmedicine relevant to the developing world? PLoS Med 2(5):e107\n 6. Ma LL, Wang YY, Yang ZH, Huang D, Weng H, Zeng XT (2020) \nMethodological quality (risk of bias) assessment tools for primary \nand secondary medical studies: what are they and which is better? \nMil Med Res 7:1–11\n 7. Reitsma JB, Rutjes AW, Whiting P, Vlassov VV, Leeflang MM, \nDeeks JJ (2009) Assessing methodological quality. Cochrane \nHandb Syst Rev Diagn Test Accuracy Version 1:1–28\n 8. Drucker AM, Fleming P, Chan AW (2016) Research techniques \nmade simple: assessing risk of bias in systematic reviews. J Inves-\ntig Dermatol 136(11):e109–e114\n 9. Shea BJ, Grimshaw JM, Wells GA, Boers M, Andersson N, Hamel \nC, Bouter LM (2007) Development of AMSTAR: a measurement \ntool to assess the methodological quality of systematic reviews. \nBMC Med Res Methodol 7(1):1–7\n 10. Smidt N, Rutjes AW, Van Der Windt DA, Ostelo RW, Reitsma JB, \nBossuyt PM, De Vet HC (2005) Quality of reporting of diagnostic \naccuracy studies. Radiology 235(2):347–353\n 11. NHMRC. Guidelines for Guidelines: Assessing risk of bias. \nhttps:// nhmrc. gov. au/ guide lines forgu ideli nes/ devel op/ asses sing- \nrisk- bias. Last published 29 August 2019\n 12. Zeng X, Zhang Y, Kwong JS, Zhang C, Li S, Sun F, Du L (2015) \nThe methodological quality assessment tools for preclinical and \nclinical studies, systematic review and meta-analysis, and clini-\ncal practice guideline: a systematic review. J Evid Based Med \n8(1):2–10\n 13. US Food and Drug Administration (2018) Framework for FDA’s \nreal-world evidence program. US Food and Drug Administra-\ntion, Silver Spring\n 14. Chodankar D (2021) Introduction to real-world evidence stud-\nies. Perspect Clin Res 12(3):171\n 15. Makady A, de Boer A, Hillege H, Klungel O, Goettsch W (2017) \nWhat is real-world data? A review of definitions based on litera-\nture and stakeholder interviews. Value Health 20(7):858–865\n 16. US Food and Drug's Administration Real-World Evidence [Last \naccessed on 2023 May 22]. Available from: https:// www. fda.  \ngov/ scien ce- resea rch/ scien ce- and- resea rch- speci al- topics/ real- \nworld- evide nce\n 17. Liaw ST, Guo JGN, Ansari S, Jonnagaddala J, Godinho MA, \nBorelli AJ Jr, Kahn MG (2021) Quality assessment of real-\nworld data repositories across the data life cycle: a literature \nreview. J Am Med Inform Assoc 28(7):1591–1599\n 18. European Medicines Agency (2017) Observational Data (Real \nWorld Data). European Medicines Agency.\n 19. Wylde V, Beswick AD, Dennis J, Gooberman-Hill R (2017) \nPost-operative patient-related risk factors for chronic pain \nafter total knee replacement: a systematic review. BMJ Open \n7(11):e018105\n 20. Hyrich KL (2019) Real world data in rheumatology. In: Seminars \nin arthritis and rheumatism. WB Saunders, 49(3), S22-S24.\n 21. Liyanage H, Liaw ST, Jonnagaddala J, Schreiber R, Kuziemsky \nC, Terry AL, de Lusignan S (2019) Artificial intelligence in pri-\nmary health care: perceptions, issues, and challenges. Yearb Med \nInform 28(01):041–046\n 22. Arksey H, O’Malley L (2005) Scoping studies: towards a meth-\nodological framework. Int J Soc Res Methodol 8(1):19–32\n 23. Evans JT, Evans JP, Walker RW, Blom AW, Whitehouse MR, \nSayers A (2019) How long does a hip replacement last? A sys-\ntematic review and meta-analysis of case series and national reg-\nistry reports with more than 15 years of follow-up. The Lancet \n393(10172):647–654\n 24. Coratti G, Cutrona C, Pera MC, Bovis F, Ponzano M, Chieppa F, \nMercuri E (2021) Motor function in type 2 and 3 SMA patients \ntreated with Nusinersen: a critical review and meta-analysis. \nOrphanet J Rare Dis 16(1):1–12\n1581Rheumatology International (2023) 43:1573–1581 \n1 3\n 25. Alipour O, Gualti A, Shao L, Zhang B (2021) Systematic review \nand meta-analysis: real-world data rates of deep remission with \nanti-TNFα in inflammatory bowel disease. BMC Gastroenterol \n21(1):1–11\n 26. Lu ZK, Xiong X, Lee T, Wu J, Yuan J, Jiang B (2021) Big data \nand real-world data based cost-effectiveness studies and decision-\nmaking models: a systematic review and analysis. Front Pharma-\ncol 12:2\n 27. Halling AS, Loft N, Silverberg JI, Guttman-Yassky E, Thyssen \nJP (2021) Real-world evidence of dupilumab efficacy and risk of \nadverse events: a systematic review and meta-analysis. J Am Acad \nDermatol 84(1):139–147\n 28. Hidayat K, Du X, Shi BM (2019) Risk of fracture with dipeptidyl \npeptidase-4 inhibitors, glucagon-like peptide-1 receptor agonists, \nor sodium-glucose cotransporter-2 inhibitors in real-world use: \nsystematic review and meta-analysis of observational studies. \nOsteoporos Int 30(10):1923–1940\n 29. Kolmos M, Christoffersen L, Kruuse C (2021) Recurrent ischemic \nstroke–a systematic review and meta-analysis. J Stroke Cerebro-\nvasc Dis 30(8):105935\n 30. van der List JP, Chawla H, Zuiderbaan HA, Pearle AD (2016) \nThe role of preoperative patient characteristics on outcomes of \nunicompartmental knee arthroplasty: a meta-analysis critique. J \nArthroplasty 31(11):2617–2627\n 31. Rahhal A, Kasem M, Orabi B, Hamou F, Abuyousef S, Mahfouz \nA, Ahmed E (2022) Effectiveness of sacubitril/valsartan in heart \nfailure with reduced ejection fraction using real-world data: an \nupdated systematic review and meta-analysis. Curr Problems Car-\ndiol 2:101412\n 32. Nicholas JA, Edwards NC, Edwards RA, Dellarole A, Grosso M, \nPhillips AL (2020) Real-world adherence to, and persistence with, \nonce-and twice-daily oral disease-modifying drugs in patients \nwith multiple sclerosis: a systematic review and meta-analysis. \nBMC Neurol 20(1):1–15\n 33. Omarini C, Piacentini F, Sperduti I, Cerma K, Barbolini M, \nCanino F, Moscetti L (2022) T-DM1 efficacy in trastuzumab-\npertuzumab pre-treated HER2 positive metastatic breast cancer \npatients: a meta-analysis. BMC Cancer 22(1):1–7\n 34. Tahra A, Bayrak O, Dmochowski R (2022) The Epidemiology \nand population-based studies of women with lower urinary tract \nsymptoms: a systematic review. Turk J Urol 48(2):155–165\n 35. Fatoye F, Gebrye T, Odeyemi I (2019) Real-world incidence and \nprevalence of low back pain using routinely collected data. Rheu-\nmatol Int 39(4):619–626\n 36. Lin SQ, Vo NP, Yen YC, Tam KW (2022) Outcomes of senti-\nnel node biopsy for women with breast cancer after neoadjuvant \ntherapy: systematic review and meta-analysis of real-world data. \nAnn Surg Oncol 2:1–12\n 37. Alsadhan N, Almaiman A, Pujades-Rodriguez M, Brennan C, \nShuweihdi F, Alhurishi SA, West RM (2022) A systematic review \nof methods to estimate colorectal cancer incidence using popula-\ntion-based cancer registries. BMC Med Res Methodol 22(1):1–15\n 38. Erdos J, Wild C (2022) Mid-and long-term (at least 12 months) \nfollow-up of patients with spinal muscular atrophy (SMA) treated \nwith nusinersen, onasemnogene abeparvovec, risdiplam or com-\nbination therapies: a systematic review of real-world study data. \nEur J Paediatr Neurol. 2:2\n 39. Jørgensen L, Paludan-Müller AS, Laursen DR, Savović J, Boutron \nI, Sterne JA, Hróbjartsson A (2016) Evaluation of the Cochrane \ntool for assessing risk of bias in randomized clinical trials: over -\nview of published comments and analysis of user practice in \nCochrane and non-Cochrane reviews. Syst Rev 5:1–13\n 40. Shea B, Hamel C, Wells GA, Bouter LM, Kristjansson E, Grimsha \nJ, Boers M (2009) AMSTAR is a reliable and valid measurement \ntool to assess the methodological quality of systematic reviews. J \nClin Epidemiol 62(10):1013–1020\n 41. Tunguy-Desmarais GP, Muckart DJ (2013) Evidence-based \nmedicine should be based on science. SAMJ South Afr Med J \n103(10):700–701\n 42. Zhu X, Shen X, Hou X, Luo Y, Fu X, Cao M, Feng Z (2020) Total \nglucosides of paeony for the treatment of rheumatoid arthritis: \na methodological and reporting quality evaluation of systematic \nreviews and meta-analyses. Int Immunopharmacol 88:106920\n 43. Licona-Chávez AL, Velázquez-Liaño LR (2020) Quality assess-\nment of a multiple choice test through psychometric properties. \nMedEdPublish 9(91):91\n 44. Kim SY, Park JE, Lee YJ, Seo HJ, Sheen SS, Hahn S, Son HJ \n(2013) Testing a tool for assessing the risk of bias for nonrand-\nomized studies showed moderate reliability and promising valid-\nity. J Clin Epidemiol 66(4):408–414\n 45. Sanderson S, Tatt ID, Higgins JP (2007) Tools for assessing qual-\nity and susceptibility to bias in observational studies in epide-\nmiology: a systematic review and annotated bibliography. Int J \nEpidemiol 36(3):666–676\n 46. Grimes DA, Schulz KF (2002) Cohort studies: marching towards \noutcomes. Lancet 359(9303):341–345\nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.",
  "topic": "Checklist",
  "concepts": [
    {
      "name": "Checklist",
      "score": 0.7091062664985657
    },
    {
      "name": "Systematic review",
      "score": 0.692940354347229
    },
    {
      "name": "Medicine",
      "score": 0.6316795349121094
    },
    {
      "name": "Observational study",
      "score": 0.5891755819320679
    },
    {
      "name": "MEDLINE",
      "score": 0.5616567134857178
    },
    {
      "name": "Meta-analysis",
      "score": 0.4701298177242279
    },
    {
      "name": "Medical physics",
      "score": 0.4621255099773407
    },
    {
      "name": "Real world data",
      "score": 0.4380509853363037
    },
    {
      "name": "Quality assessment",
      "score": 0.4373947083950043
    },
    {
      "name": "Data science",
      "score": 0.31448665261268616
    },
    {
      "name": "Computer science",
      "score": 0.28787925839424133
    },
    {
      "name": "Internal medicine",
      "score": 0.1373874843120575
    },
    {
      "name": "Pathology",
      "score": 0.12510856986045837
    },
    {
      "name": "Psychology",
      "score": 0.112548828125
    },
    {
      "name": "External quality assessment",
      "score": 0.08596712350845337
    },
    {
      "name": "Cognitive psychology",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I11983389",
      "name": "Manchester Metropolitan University",
      "country": "GB"
    }
  ],
  "cited_by": 9
}