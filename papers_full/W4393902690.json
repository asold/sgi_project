{
    "title": "Perspectives on the application of large language models in healthcare",
    "url": "https://openalex.org/W4393902690",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A4307687599",
            "name": "A.E. Andreychenko",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2067989555",
            "name": "A. V. Gusev",
            "affiliations": [
                "Federal Research Institute for Health Organization and Informatics"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4385227045",
        "https://openalex.org/W4384561707",
        "https://openalex.org/W4383346782",
        "https://openalex.org/W4385065380",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W4385597618",
        "https://openalex.org/W4386407038",
        "https://openalex.org/W4384071683",
        "https://openalex.org/W4319062614",
        "https://openalex.org/W4386117070",
        "https://openalex.org/W4386196128",
        "https://openalex.org/W4379769651",
        "https://openalex.org/W4385910049",
        "https://openalex.org/W4385741595"
    ],
    "abstract": "Large language models have become a new significant breakthrough in the field of artificial intelligence. They are changing approaches to machine learning from models that solve narrow problems and require large amounts of data with the known answers for training, to generative models that are fine tunable to solve specific problems using a small number of examples with the known answers or even none at all. Medicine is one of the areas in which the use of large language models can become extremely useful. The review presents data on the latest achievements in the use of large language models for medical tasks, prospects for using these models as the basis for the digital assistants for doctors and patients, as well as existing regulatory and ethical barriers to the development of this breakthrough technology for addressing healthcare challenges.",
    "full_text": "National Health Care (Russia). V. 4, No. 4, 2023\n48\nинфор МаТизация здравоохранения\nОбзор\nУДК [61:004.9](048)\nhttps://doi.org/10.47093/2713-069X.2023.4.4.48-55\nПерспективы применения больших языковых моделей \nв здравоохранении\nА.Е. Андрейченко1, А.В. Гусев2,3,*\n1ООО «К-Скай», набережная Варкауса, д. 17, г. Петрозаводск, 185031, Россия\n2ФГБУ «Центральный научно-исследовательский институт организации и информатизации \nздравоохранения» Министерства здравоохранения Российской Федерации, ул. Добролюбова, д. 11,  \nг. Москва, 127254, Россия\n3ГБУЗ г. Москвы «Научно-практический клинический центр диагностики и телемедицинских \nтехнологий Департамента здравоохранения Москвы», ул. Петровка, д. 24, г. Москва, 127051, Россия\nАннотация\nБольшие языковые модели стали новым значимым прорывом в области искусственного интеллекта, меняющим \nподходы от применения моделей машинного обучения в узких задачах, требующих больших объемов данных \nс готовыми ответами для обучения, к генеративным моделям, способным к дообучению на небольшом количе -\nстве примеров или вообще без примеров с готовыми ответами и при этом имеющих более широкие возможности \nприменения. Медицина является одной из областей, в которой внедрение больших языковых моделей может \nстать крайне востребованным. В обзоре представлены данные о последних достижениях применения больших \nязыковых моделей для медицинских задач, перспективы использования этих моделей как основы цифровых асси -\nстентов для врачей и пациентов, а также существующие регуляторные и этические барьеры на пути развития этой \nпрорывной технологии для решения задач здравоохранения.\nКлючевые слова: большие языковые модели; генеративный искусственный интеллект; здравоохранение; машин -\nное обучение; медицинский чат-бот\nДля цитирования:  Андрейченко А.Е., Гусев А.В. Перспективы применения больших языковых моделей в здра -\nвоохранении. Национальное здравоохранение. 2023; 4  (4): 48–55. https://doi.org/10.47093/2713-069X.2023.4.4.48-55\nКонтактная информация:\n* Автор, ответственный за переписку: Гусев Александр Владимирович. E-mail: agusev@webiomed.ai\nСтатья поступила в редакцию: 22.09.23  Статья принята к печати: 01.11.23  Дата публикации: 20.12.23\n \nAbstract\nLarge language models have become a new significant breakthrough in the field of artificial intelligence. They are changing \napproaches to machine learning from models that solve narrow problems and require large amounts of data with the \nknown answers for training, to generative models that are fine tunable to solve specific problems using a small number \nof examples with the known answers or even none at all. Medicine is one of the areas in which the use of large language \nmodels can become extremely useful. The review presents data on the latest achievements in the use of large language \nmodels for medical tasks, prospects for using these models as the basis for the digital assistants for doctors and patients, \nas well as existing regulatory and ethical barriers to the development of this breakthrough technology for addressing \nhealthcare challenges.\nKeywords: large language models; generative artificial intelligence; healthcare; machine learning; medical chatbot\nPerspectives on the application of large language models \nin healthcare\nAnna E. Andreychenko1, Aleksandr V. Gusev2,3,*\n1K-Skai LLC, Varkaus Embankment, 17, Petrozavodsk, 185031, Russia\n2Federal Research Institute for Health Organization and Informatics, Dobrolyubova str., 11, Moscow, 127254, \nRussia\n3Research and Practical Clinical Center for Diagnostics and Telemedicine Technologies, Petrovka str., 24/1, \nMoscow, 127051, Russia\nНациональное здравоохранение. Т. 4, №4, 2023 г.\n49\nинфор МаТизация здравоохранения\nFor citation: Andreychenko A.E., Gusev A.V. Perspectives on the application of large language models in healthcare. \nNational Health Care (Russia). 2023; 4 (4): 48–55. https://doi.org/10.47093/2713-069X.2023.4.4.48-55\nContacts: \n* Corresponding author: Aleksandr V. Gusev. E-mail: agusev@webiomed.ai\nThe article received: 22.09.23  The article approved for publication: 01.11.23  Date of publication: 20.12.23\n \nСписок сокращений:\nLLM – Large Language Models, большие языковые мо -\nдели\nИИ – искусственный интеллект\nСППВР – система поддержки принятия врачебных ре -\nшений\nТехнология больших языковых моделей (Large \nLanguage Models, LLM) стала в последнее время одним \nиз самых перспективных направлений для исследова-\nний и разработок в сфере искусственного интеллек -\nта (ИИ) для обработки естественного языка (Natural \nLanguage Processing, NLP) [1–3] и последующего реше-\nния широкого спектра прикладных задач.\nКак правило, для создания LLM используются ар -\nхитектура искусственной нейронной сети (artificial \nneural network, ANN) и глубокое обучение ( deep \nlearning, DL), которое осуществляется на очень \nбольших корпусах текстов, содержащих миллиарды \nслов  – например статей, книг и других публикаций \nв сети Интернет. Это позволяет получить модель ма -\nшинного обучения, содержащую миллиарды пара -\nметров, которые формируют довольно подробное \nпредставление сложных ассоциативных отношений \nмежду словами в текстах (рис. 1). Например, 2-я \nверсия большой языковой модели GPT ( Generative \nPretrained Transformer), выпущенная в 2019  г., имела \n1,5 млрд параметров, а GPT-3.5, выпущенная осенью \n2022 г. – уже 175 млрд параметров [ 2].\nПрименение LLM позволяет существенно повы -\nсить точность решения самых разнообразных задач \nобработки естественного языка, включая интерпрета-\nцию и классификацию, обобщение текстовой инфор -\nмации, создание чат-ботов и иных диалоговых систем, \nгенерацию текстов по запросам и т.д. Более того, при-\nменение предварительно обученных LLM позволяет \nсоздать прикладные модели для решения узких задач \nс минимальным набором для дообучения (‘few-shot’) \nили даже вовсе без обучающего набора (‘zero-shot’), \nчто позволяет существенно ускорить и одновременно \nудешевить создание прикладных ИИ-систем [4].\nМодель\nПараметры (млрд)0,117 \n0,34 \n1,5 \n0,114 \n1,63 \n0,374 \n530 \n3,9 \n175 \n0,632 \n12 \n1 \n0,197 \n1,75 \n178 \n530 \n52 \n1,2 \n3,5 \n280 \n13 \n137 \n70 \n280 \n3,5 \n80 \n540 \n1,2 \n175 \n2 \n540 \n176 \n130 \n70 \n200 \n65 \nGPT\nBERT\nGPT-2\nERNIE\nCTRL\nBART\nTuring-NLG\nMegatron\nGPT-3\nVIT\nDALL-E\nSwitch\nSwin transformer\nWu Dao 2.0\nJurassic-1\nMT-NLG\nAnthropic-LM\nGLaM\nGLIDE\nGopher\nCM3\nLaMDA\nChinchilla\nGopherCite\nDALL-E-2\nFlamingo\nPaLM\nGato\nOPT\nImagen\nMinerva\nBLOOM\nGLM\nSparrow\nLuminous\nLLaMA\nРис. 1. Различные большие языковые модели с указанием количества параметров и их разработчиков, Thirunavukarasu, 2023 [2]\nFig. 1. Various large language models with number of parameters and their developers, Thirunavukarasu, 2023 [2]\nNational Health Care (Russia). V. 4, No. 4, 2023\n50\nинфор МаТизация здравоохранения\nПо мере развития методов глубокого обучения, \nмощных вычислительных ресурсов и больших на -\nборов данных для обучения начали появляться мно -\nжество LLM, которые могут выполнять когнитивную \nработу на довольно высоком уровне, достигающем \nвозможностей человека.\nОдним из самых известных в мире примеров \nуспешного применения LLM является чат-бот ChatGPT \nкомпании OpenAI, который может принимать на вход \nлюбой произвольный запрос и давать на него ответ, \nпоразительно точно имитирующий ответ человека. \nТехнологической основой ChatGPT являются большие \nязыковые модели GPT-3.5 и GPT-4. Успех и глобальное \nвлияние ChatGPT на рост спроса на решения в области \nгенеративного ИИ проистекают из его доступности, \nуниверсальности, диалоговой интерактивности и про-\nизводительности, близкой или равной человеческому \nуровню.\nНеобходимо обратить внимание, что применение \nLLM было лишь одним из этапов создания ChatGPT, \nхотя и имеющим фундаментальное значение. После \nтого как LLM была получена, потребовалась дальней -\nшая доработка и тонкая настройка, а также постоян -\nное дообучение во время эксплуатации (рис. 2) [2].\nИсходная модель GPT-3 была предобучена на да -\nтасете с готовыми запросами и ответами до GPT-3.5. \nДалее было проведено «обучение с подкреплением \nна основе обратной связи от человека» (Reinforcement \nLearning from Human Feedback, RLHF) с использова -\nнием модели вознаграждения, созданной на данных, \nсгенерированных людьми, которым было поручено \nранжировать ответы GPT-3.5 на набор запросов. Этот \nподход позволил реализовать LLM в гораздо больших \nмасштабах, чем это можно было бы сделать при руч -\nном оценивании человеком каждого отдельного отве-\nта модели. Для повышения надежности и безопасно -\nсти было проведено дальнейшее автоматизированное \nсостязательное обучение с использованием генери -\nруемых моделью входных запросов и выходных отве -\nтов. При эксплуатации модель GPT-3.5 продолжила не-\nпрерывное самообучение, используя обратную связь \nот быстро растущей базы пользователей.\nВ России также проводятся аналогичные иссле -\nдования и разработки в области LLM. В частности, \nмодель ruGPT-3.5, насчитывающую 13 млрд параме -\nтров, создали в Сбере. Аналогичную большую язы -\nковую модель YandexGPT-2 (100 млрд параметров) \nразвивает Яндекс. Эти модели являются подходящей \nбазой для независимого развития технологий LLM \nв Российской Федерации.\nПрименение технологии LLM \nв здравоохранении\nChatGPT привлек к себе особое внимание в меди -\nцине благодаря тому, что получил проходной балл \nна экзаменах по лицензированию медицинской дея -\nтельности в США, а производительность GPT-4 стала \nзаметно выше, чем у его предшественника GPT-3.5 [5]. \nСхожий результат был недавно продемонстрирован \nи для экзамена медсестер в Японии [6], а также GPT-4 \nпревзошел результаты студентов-медиков на государ-\nственном экзамене в Германии [7].\nУспех ChatGPT породил целую волну аналогич -\nных разработок для задач здравоохранения у других \nкомпаний, например Google запустила проект соз -\nдания медицинского чат-бота Med-PaLM 2, который \nЗ ап ро с ы   \nР ез ультат ы  \nА вто ма ти зиро ва н н о е \nобуч ен и е \nс о с тяз а тел ьн о с ти  \nДа н н ы е дл я обуч ен и я \no Common Crowl web   \narchive \no Web Text2 \no Books \no Books2 \no Wikipedia \nGPT-3 GPT-3.5 ChatGPT \nПредварительное \nобучение\n Тонкая настройка  \nО б у ч е н и е   \nс по д к р е пл е н и е м   \nн а  о с н о в е обратно й  с в я з и  \nс ч е л ове ком  (RLHF) \nЗапросы Результаты  \nМодель\nвознаграждения\n \nЗ а пр о с ы Р е зуль та ты \nЧеловек  Ручная оценка ответов  \nЗ ап ро с ы  Chat\nGPT \nР езул ьтат ы \nП рак ти чес ки е да н н ы е o То чн о с ть \no П о л ез н о с ть \no С ц ен арий  \no С о с тяз а тел ьные \nс тратег и и \nпользователь  \nР А З В ЕР Т ЫВАН И Е  \nРис. 2. Алгоритм обучения больших языковых моделей для решения прикладных задач, Thirunavukarasu, 2023 [2]\nFig. 2. Algorithm for training large language models for solving applied problems, Thirunavukarasu, 2023 [2]\nНациональное здравоохранение. Т. 4, №4, 2023 г.\n51\nинфор МаТизация здравоохранения\nспособен на уровне врача-эксперта отвечать на ме -\nдицинские вопросы [8]. В настоящее время решение \nпроходит тестирование в исследовательском госпита-\nле Mayo Clinic [1].\nКогда ответы ChatGPT на запросы пациентов срав -\nниваются с ответами врачей (отвечающих в свободное \nвремя в социальной сети), результат LLM оказывается \nпредпочтительнее с точки зрения качества и эмпатии, \nесли использовать ее в качестве качественной ме -\nтрики на основе оценок врачами-судьями. Это дало \nповод говорить о том, что ИИ готов заменить врачей, \nно в реальности это не так. Даже на экзаменах для сту-\nдентов-медиков результаты модели далеки от иде -\nальных. Было показано, что ChatGPT не справляется \nс экзаменами для врачей-специалистов и дает неточ -\nную информацию в ответ на реальные вопросы паци -\nентов о профилактике сердечно-сосудистых заболе -\nваний [9], лечении онкологических заболеваний [1 0], \nа Bing Chatbot давал неправильные советы первой \nпомощи при неотложных состояниях [11]. Несмотря \nна способность интерпретировать клинические за -\nметки и отвечать на соответствующие вопросы, LLM \nчасто не могут предоставить информацию в соответ -\nствии с индивидуальными особенностями пациента. \nТекущие результаты пока исключают возможность \nавтономного развертывания системы для принятия \nклинических решений или общения с пациентами, \nтем более что пациенты часто не могут отличить ин -\nформацию, предоставленную LLM, от информации, \nполученной от человека-клинициста. В связи с этим \nВсемирная организация здравоохранения призывает \nк осторожному и ответственному развитию и приме -\nнению столь популярных сейчас технологий больших \nязыковых моделей в медицине1.\nВ Российской Федерации также активно запуска -\nются проекты по развитию LLM в медицинских целях. \nНапример, Сеченовский университет совместно со \nСбером набирает ИИ-тренеров для обучения мульти -\nмодальной нейронной сети для медицины и здраво -\nохранения “GigaChat”2. В результате такой инициативы \nмогут быть созданы русскоязычные базы для дона -\nстройки ( fine-tuning) больших языковых моделей \nпод медицинские задачи. Преимуществом таких баз \nявляется учет национальных подходов и особенно -\nстей в медицине и здравоохранении. Однако открыты-\nми остаются вопросы безопасности LLM, обеспечения \nотсутствия «галлюцинаций» при решении медицин -\nских задач, а также своевременной и экономичной \nактуализации «знаний» модели. Например, разработ -\nчики Яндекс предупреждают, что информация и дан -\nные, которыми владеет модель YaGPT 2.0, датируются \nне позднее марта 2023. При необходимости база зна -\nний, на основе которой LLM генерирует ответ, может \nбыть ограничена с помощью технологии retrieval-\naugmented generation. При этом дорогостоящего \nпредобучения базовой LLM модели не требуется. Это \nтакже актуально для задач медицины и здравоохра -\nнения, так как база знаний должна постоянно попол -\nняться новым клиническими случаями, рекомендаци -\nями и т.п.\nПерспективы применения LLM для создания \nцифровых ассистентов для врачей\nВ настоящее время применение LLM при создании \nспециализированных ИИ-продуктов для клиническо -\nго применения и поддержки принятия врачебных \nрешений выглядит более обоснованным подходом, \nчем создание универсального ИИ, способного отве -\nчать на любые вопросы и темы и уж тем более  – за -\nменить врача [1]. Более того, применение LLM демон-\nстрирует гораздо лучшую эффективность в задачах, \nгде не требуется специальных знаний, или заданиях, \nкоторые предоставляются в виде развернутых поль -\nзовательских запросов (promt). Это открывает доволь-\nно большие возможности для ускорения внедрения \nИИ в медицинскую практику, бросая, по сути, вызов \nтрадиционным подходам, применяемым при созда -\nнии систем поддержки принятия врачебных решений \n(СППВР).\nТак, модель Foresight, созданная на основе архитек-\nтуры LLM и неструктурированных текстовых медицин-\nских записей, извлеченных из 811  тыс. электронных \nмедицинских карт, продемонстрировала высокую эф -\nфективность в прогнозировании и предсказании в ва-\nлидационных исследованиях [ 12]. Данный проект на -\nглядно показал, что модели общего риска могут стать \nмощной альтернативой многочисленным инструмен -\nтам, используемым в настоящее время для стратифи -\nкации и сортировки пациентов.\nОбобщая исследования и разработки в сфере LLM \nдля клинического применения, можно выделить сле -\nдующие наиболее перспективные направления [1–3]:\n•\tформирование медицинской документации;\n•\tформирование выписных эпикризов;\n•\tгенерация клинических заметок;\n•\tпредварительное подтверждение страховых случаев;\n•\tкраткое содержание научно-исследовательских \nработ;\n•\tинтерпретация диагностических исследований;\n•\tпредложение способов лечения;\n•\tразработка планов лечения;\n•\tдиагностическая помощь;\n•\tмедицинский триаж.\nПоявляющиеся LLM будут расширять свои воз -\nможности и совместимость с разными типами ис -\nточников данных; даже почерк врача может быть \n1 ВОЗ. ВОЗ призывает к безопасному и этичному использованию ИИ в интересах здоровья. 16 мая 2023 г. URL: https://www.who.int/news/\nitem/16-05-2023-who-calls-for-safe-and-ethical-ai-for-health (дата обращения: 05.07.2023).\n2 https://student.sechenov.ru/info/39305115 (дата обращения: 05.07.2023).\nNational Health Care (Russia). V. 4, No. 4, 2023\n52\nинфор МаТизация здравоохранения\nинтерпретирован автоматически и точно. Компании \nMicrosoft и Google стремятся интегрировать ChatGPT \nи PaLM 2, соответственно, в административный рабо -\nчий процесс, позволяя беспрепятственно и автомати -\nчески интегрировать информацию из видеозвонков, \nдокументов, электронных таблиц, презентаций и элек-\nтронной почты.\nВместе с этим следует обратить особое внимание, \nчто применение LLM в клинических условиях, когда \nбезопасность пациента не гарантируется безусловно, \nтребует всесторонней валидации. Для обеспечения \nбезопасности пациентов и административной эффек -\nтивности необходима всесторонняя оценка качества, \nа для распределения ответственности требуются спе -\nциальные структуры управления [1].\nПерспективы применения LLM для создания \nцифровых ассистентов для пациентов\nИИ-решения на основе LLM способны очень бы -\nстро анализировать, обобщать и перефразировать \nлюбую информацию на естественном языке, в том \nчисле собранную со слов пациента. Это открывает \nдействительно впечатляющие перспективы для уско -\nрения и повышения эффективности проектов цифро -\nвой трансформации здравоохранения, направленных \nна создание новых инновационных сервисов для па -\nциентов.\nРазличные чат-боты, интегрированные в мобиль -\nные приложения, сайты клиник или органов управ -\nления здравоохранения, страховых компаний и т.д. \nпозволяют существенно сократить нагрузку на call-\nцентры, регистратуры и даже первичные приемы, \nв конечном счете даже отказаться от участия чело -\nвека в процессе первичного общения с пациентом. \nВ довольно большом количестве случаев, особенно \nдля наиболее распространенных и неопасных (подда-\nющихся лечению в домашних условиях) заболеваний \nи состояний, чат-боты на основе LLM действительно \nспособны полностью заменить (исключить) визит па -\nциента на очный прием путем автоматического сбора, \nдиалога и интерпретации информации с подбором ре-\nкомендаций по сохранению здоровья.\nНаиболее перспективными задачами цифровых ас-\nсистентов для пациентов, которые могут быть решены \nс помощью LLM, являются [1–3]:\n•\tанализ лабораторных результатов;\n•\tописание заболеваний;\n•\tинтерпретация заметок врача;\n•\tперсонализированные рекомендации по поводу \nздоровья;\n•\tпрогнозирование состояния здоровья;\n•\tоценка симптомов;\n•\tанализ данных с носимых устройств;\n•\tчат-боты по психическому здоровью;\n•\tсоблюдение плана лечения;\n•\tгиды по реабилитации.\nПерспективы применения LLM в клинических \nисследованиях\nУскорение и сокращение стоимости клинических \nисследований является одной из самых перспективных \nниш для применения технологий LLM, которым можно \nпоручить краткое изложение информации, формиро -\nвание описания предоставленных результатов или ге-\nнерацию фрагментов текстов для конкретного читателя \nили аудитории. Модели, прошедшие тонкую настройку \nна основе информации, специфичной для конкретной \nобласти, могут демонстрировать более высокую про -\nизводительность, чему уже есть конкретные приме -\nры, включая модели PubMedBERT и BioBERT. Это может \nснизить бремя критической оценки, написания отчетов \nоб исследованиях и рецензирования, что составляет \nзначительную часть рабочей нагрузки исследователей. \nВопросы, связанные с ответственностью за коррект -\nность информации и выводов, будут решены за счет \nтого, что клиницисты и исследователи, использующие \nэти инструменты, будут нести полную ответственность \nза их результаты. Однако широкое применение LLM \nв исследованиях будет возможно только после того, \nкак разработчиками будет обеспечено отсутствие «гал-\nлюцинаций» и несуществующих источников в результа-\nтах работы моделей [13].\nLLM могут способствовать проведению новых ис -\nследований, таких как анализ языка в бóльших мас -\nштабах, чем это было возможно ранее. В качестве \nнаглядных примеров можно привести ClinicalBERT, \nGPT-3.5 и GatorTron, которые позволяют исследовате -\nлям эффективно анализировать большие объемы кли-\nнических текстовых данных. LLM могут также стиму -\nлировать исследования в менее очевидных смежных \nобластях, поскольку текстовая информация включает \nв себя не только человеческий язык. Например, гене -\nтические данные и данные о структуре белков обычно \nпредставлены в текстовой форме и поддаются обра -\nботке на естественном языке, чему способствуют LLM. \nМодели уже дают впечатляющие результаты: AlphaFold \nвыводит структуру белка из аминокислотных после -\nдовательностей; ProGen генерирует белковые по -\nследовательности с предсказуемой биологической \nфункцией; TSSNote-CyaPromBERT идентифицирует \nпромоторные области в бактериальной ДНК.\nДругие потенциальные возможности использова -\nния LLM включают контрфактическое моделирование \nи виртуальные клинические испытания. Такое направ-\nление может ускорить клинические исследования \nза счет получения ценных выводов о соотношении ри-\nска и пользы с целью информирования ученых и вра -\nчей о том, какие исследования с наибольшей вероят -\nностью принесут пользу пациентам.\nНовые архитектуры, такие как Hybrid Value-Aware \nTransformer ( HVAT), могут еще больше повысить про -\nизводительность LLM за счет интеграции продольных, \nмультимодальных клинических данных.\nНациональное здравоохранение. Т. 4, №4, 2023 г.\n53\nинфор МаТизация здравоохранения\nНаконец, генеративные приложения на основе \nLLM, применяемые для анализа данных пациентов, \nмогут быть использованы для получения синтетиче -\nских данных; при соответствующей оценке качества \nэто может способствовать развитию клинических ис -\nследований, увеличивая масштаб обучающих выбо -\nрок, доступных для разработки LLM и других инстру -\nментов ИИ.\nПерспективы применения LLM в медицинском \nобразовании\nВысокие результаты GPT-4 и Med-PaLM 2 в меди -\nцинских тестированиях позволяют предположить, \nчто LLM могут стать полезным инструментом обучения \nдля студентов, которые в настоящее время показыва -\nют более низкие результаты в таких тестах. Функция \nмета-запроса в GPT-4 позволяет пользователям явно \nописать желаемую роль чат-бота в разговоре; полез -\nным примером может служить «режим сократовского \nнаставника», который побуждает студентов думать \nсамостоятельно, задавая вопросы с понижающимся \nуровнем сложности, пока студенты не смогут найти \nрешение более полного вопроса. Журналы бесед по -\nзволят преподавателям отслеживать прогресс и кор -\nректировать обучение с учетом слабых сторон уча -\nщихся [14].\nТаким образом, применение LLM является одним \nиз перспективных подходов к повышению эффектив -\nности образования и последипломного образования, \nв частности  – при изучении или обобщении нового \nматериала, для повышения мотивации и вовлечен -\nности студентов в учебный процесс, как метод более \nуглубленного получения знаний.\nНормативное и техническое \nрегулирование LLM\nУчитывая потенциальные последствия для резуль -\nтатов лечения пациентов и общественного здраво -\nохранения, необходимо рассмотреть вопрос о том, \nкак следует регулировать эти новые инструменты \nна основе ИИ и возникающие в связи с этим пробле -\nмы (табл.). Регулирование LLM в медицине и здра -\nвоохранении без ущерба для их многообещающего \nпрогресса является своевременной и важной задачей \nдля обеспечения безопасности, соблюдения этиче -\nских стандартов, предотвращения несправедливости \nи предвзятости и защиты конфиденциальности па -\nциентов. Какие бы опасения ни вызывал ИИ, теперь \nони заметно усиливаются благодаря огромному и раз-\nнообразному потенциалу приложений на основе LLM.\nБольшинство LLM глобальны, у них нет версий \nдля конкретных стран, а значит, они требуют особого \nподхода со стороны регулирующих органов. Также \nнеясно, к какой технической категории попадут LLM \nс точки зрения регулирования. Однако из-за разли -\nчий между LLM и предыдущими методами глубокого \nобучения может потребоваться новая нормативная \nкатегория для решения проблем и рисков, связанных \nс LLM.\nРегулирующий орган должен разрабатывать пра -\nвила для LLM только в том случае, если разработчики \nLLM заявляют, что их модель предназначена для ис -\nпользования в медицинских целях. В эту категорию \nтакже целесообразно отнести медицинские альтер -\nнативы LLM общего назначения, которые были специ-\nально дообучены на медицинских базах данных.\nЗАКЛЮЧЕНИЕ\nLLM произвели революцию в обработке естествен-\nного языка, и современные модели, такие как GPT-4 \nи PaLM 2, занимают сегодня центральное место в ин -\nновациях ИИ в медицине. Аналогичные исследования \nи разработки ведутся в России, преимущественно \nкрупнейшими технологическими компаниями, такими \nкак Сбер и Яндекс. Новые технологии открывают ши -\nрокие возможности для применения в клинической, \nобразовательной и исследовательской деятельности, \nособенно в связи с развитием мультимодальности \nи интеграции в уже существующие цифровые инстру -\nменты в сфере здравоохранения. Однако потенци -\nальные риски вызывают серьезную озабоченность \nв отношении безопасности, этики и потенциальной за-\nмены человека в определенных ситуациях. Применяя \nупреждающий подход к регулированию, можно ис -\nпользовать потенциал технологий на основе ИИ, та -\nких как LLM, сводя к минимуму потенциальный вред \nи сохраняя доверие как пациентов, так и медицинских \nработников и организаторов здравоохранения.\nМы можем ожидать от регулирующих органов \nв отношении внедрения LLM в медицинскую практику \nследующего:\n•\tзапуск и стимулирование пилотных проектов раз -\nработок и внедрения LLM с целью как можно более \nраннего и всестороннего анализа практического \nопыта применения данной технологии, включая \nоценку преимуществ и потенциальных опасностей;\n•\tразработку отдельного технического и, возможно \nв будущем, нормативного регулирования для про -\nдуктов на основе LLM, в том числе с точки зрения их \nприменения в лечебно-диагностических процессах;\n•\tразработку нормативных рекомендаций для компа -\nний и организаций здравоохранения о том, как они  \nмогут внедрять LLM в свои существующие продукты \nи услуги на основе риск-ориентированного подхода \nи ответственного отношения к ИИ;\n•\tвыработку регуляторных подходов и рекомендаций \nдля проведения различия между LLM, специально \nобученными на медицинских данных, и LLM, обучен-\nными для немедицинских целей;\n•\tотнесение медицинских цифровых приложений \nдля пациентов, использующих технологии LLM и обе-\nспечивающих анализ медицинских данных и реко -\nмендации по здоровью к категории программных \nмедицинских изделий.\nNational Health Care (Russia). V. 4, No. 4, 2023\n54\nинфор МаТизация здравоохранения\nТаблица. Список регуляторных проблем, связанных с развитием LLM\nTable. List of regulatory issues associated with LLM development\nЗадача регулирования Краткое описание\nОбеспечение \nнационального \nсуверенитета\nСогласно национальной стратегии развития ИИ3 при внедрении любых ИИ-систем должен соблюдаться прин-\nцип технологического суверенитета, включая преимущественное использование отечественных разработок. \nЭто означает, что следует рассмотреть возможность ограничения LLM, созданных иностранными компания-\nми, или даже запрет на их применение в здравоохранении. \nДоступность мощных \nвычислительных \nресурсов для создания \nLLM\nИзвестно, что для создания LLM требуются очень мощные вычислительные ресурсы, которые в настоящее \nвремя в России доступны лишь ограниченному списку крупных технологических компаний, таких как Сбер \nи Яндекс. Эта особенность существенно ограничивает возможности исследований и разработок в сфере LLM \nв небольших компаниях, стартапах и научных коллективах. Целесообразно рассмотреть возможность выделе-\nния финансовой поддержки для таких коллективов, чтобы они могли покупать необходимые серверные мощ-\nности или через API обращаться к имеющимся LLM и тем самым участвовать в исследованиях применения \nтехнологий LLM для решения задач здравоохранения. Кроме этого, стоит рассмотреть вопрос о создании от -\nкрытых и общедоступных LLM, созданных для русского языка.\nКонфиденциальность \nданных пациентов\nОбеспечение того, чтобы данные пациентов, используемые для обучения больших языковых моделей, были \nполностью обезличенными и защищенными от возможных взломов. Это создает большую нормативную про-\nблему, поскольку любое нарушение может привести к серьезным последствиям в соответствии с законом \nо защите персональных данных. Для обеспечения конфиденциальности и безопасности данных должны быть \nиспользованы технологии шифрования данных при хранении и передаче, защищенные сервера. При сборе и объ-\nединении мультимодальных данных могут быть использованы технологии дифференциальной приватности, \nкоторые добавляют шум к агрегированным данным для предотвращения идентификации отдельного пациен-\nта, при этом ценность объединенных данных сохраняется, а также протоколы конфиденциального вычисления \n(Secure multiparty computation SMC), обеспечивающие сохранность персональных данных при объединении дан-\nных из нескольких источников. Кроме этого, активно развиваются технологии федеративного обучения, когда \nне требуется централизованный сбор набора данных для обучения моделей. Соответственно, исходя из степени \nразнообразия данных, уровня решаемой с помощью LLM задачи в медицине и здравоохранении, могут быть \nприменены те или иные технологии для обеспечения конфиденциальности и безопасности медицинских данных.\nИнтеллектуальная \nсобственность\nЕсли LLM создает контент, аналогичный проприетарным медицинским исследованиям или литературе, это \nможет привести к проблемам с правами на интеллектуальную собственность.\nИспользование LLM \nв системах поддержки \nпринятия врачебных \nрешений\nПри использовании технологий ИИ в СППВР вероятность потенциального причинения вреда имеет максималь-\nно высокий уровень риска. Применение LLM может привести к еще большему риску, который может превы -\nшать потенциальный положительный эффект, в силу особенностей создания LLM и наличия риска «галлюцина-\nций». Целесообразно рассмотреть вопрос о допустимости применения LLM в СППВР , включая анализ данных \nэлектронных медицинских карт. Возможно, на период становления отечественных исследований и разрабо -\nток в этой сфере будет целесообразно ограничить применение LLM в некоторых наиболее рискованных сце -\nнариях использования СППВР , например в госпитальных условиях, отделениях реанимации, при назначении \nлекарственного лечения или медицинских вмешательств и т.д. Альтернативным решением для минимизации \nриска «галлюцинаций» может быть создание отраслевой LLM, изначально предобученной исключительно \nна валидированных медицинских и биомедицинских текстах и данных. Однако сбор, оцифровка и чистка всех \nмедицинских знаний является трудоемкой и долгосрочной задачей.\nКонтроль качества \nи стандартизация\nРегулирование необходимо для обеспечения надежности и сохранения качества ИИ-систем на основе LLM, т.к. \nони обучаются на неконтролируемо большом и не всегда валидированном контенте.\nИнформированное \nсогласие\nПациенты должны быть проинформированы и давать согласие при использовании цифровых продуктов на ос-\nнове LLM. Это сложно, потому что пациентам может быть трудно полностью понять все последствия исполь-\nзования ИИ.\nИнтерпретируемость \nи прозрачность\nПравила должны обеспечивать прозрачность того, как ИИ принимает решения. Это особенно сложно с LLM, \nкоторые являются «черными ящиками» из-за их сложных алгоритмов, большого количества параметров \nи огромных объемов обучающих наборов данных.\nСправедливость \nи предвзятость\nРегулирование необходимо для предотвращения предвзятости в LLM, которые могут быть применены в ле -\nчебно-диагностических процессах с использованием данных пациентов. Это может привести к различиям \nв результатах лечения.\nВладение данными Может быть сложно определить и отрегулировать, кому принадлежат данные, на которых учатся LLM, особен-\nно когда речь идет о данных пациентов.\nЧрезмерная \nзависимость \nот моделей ИИ\nЧрезмерная зависимость от LLM, например в задачах обобщения данных медицинской литературы или ис -\nпользовании диалоговых систем для поиска медицинской информации, может привести к снижению качества \nэкспертизы у специалистов и потенциальным ошибкам, если LLM даст сбой или предоставит неверную инфор-\nмацию (т.н. «галлюцинации» – характерная проблема современных LLM). Существуют подходы к устранению \n«галлюцинаций» с помощью retrieval-augmented generation (RAG), когда «база знаний» модели для генерации \nответа ограничена. Однако у такого подхода есть технические ограничения по размеру документов в базе \nзнаний и тем самым ограничения по полноте и точности ответа модели. Кроме этого, недавнее исследование \nпоказало, что LLM могут быть использованы для генерации несуществующих, но правдоподобных данных \nклинических исследований для подтверждения той или иной гипотезы. Необходимы правила, чтобы сбаланси-\nровать использование LLM и человеческий опыт и знания.\nНепрерывный \nмониторинг и проверка\nОбеспечение непрерывной безопасности, качества и достоверности ИИ-систем на основе LLM с течением вре-\nмени и для разных групп населения является важной нормативно-правовой задачей.\n3 Указ Президента РФ от 10.10.2019 № 490 «О развитии искусственного интеллекта в Российской Федерации» (вместе с «Национальной стра -\nтегией развития искусственного интеллекта на период до 2030 года»). http://www.consultant.ru/document/cons_doc_LAW_335184/ (дата об -\nращения: 05.07.2023).\nНациональное здравоохранение. Т. 4, №4, 2023 г.\n55\nинфор МаТизация здравоохранения\nПри условии решения этических, технических \nи регуляторных вопросов проверенные приложе -\nния на основе LLM могут стать ценным инструментом \nв проектах цифровой трансформации здравоохра -\nнения для улучшения медицинского обслуживания \nпациентов и практикующих врачей. Проверка при -\nложений на основе LLM предполагает проведение \nнезависимых клинических испытаний, оценивающих \nреальные преимущества при минимизации предвзя -\nтости и прозрачности отчетности.\nКонфликт интересов. Авторы заявляют об отсут-\nствии конфликта интересов.\nConflict of interests. The authors declare that there is \nno conflict of interests.\nФинансирование. Исследование не имело спон -\nсорской поддержки (собственные ресурсы).\nFinancial support. The study was not sponsored (own \nresources).\nВКЛАД АВТОРОВ\nА.Е. Андрейченко  – обзор литературы, описание существую -\nщих разработок, анализ и описание подходов к созданию и при-\nменению технологий LLM.\nА.В. Гусев – идея исследования, направления для обзора литера-\nтуры, обзор нормативных проблем и выводы по исследованию.\nВсе авторы утвердили окончательную версию статьи.\nAUTHOR CONTRIBUTIONS\nAnna E. Andreychenko – literature review, description of existing \ndevelopments, analysis and description of approaches to the \ncreation and application of LLM technologies.\nAleksandr V. Gusev – research idea, history of market development, \nanalysis of regulatory development.\nAll the authors approved the final version of the article.\nЛИТЕРАТУРА/REFERENCES\n1. Yang R., Tan T.F ., Lu W., et al. Large language models in health care: development, \napplications, and challenges. Health Care Science. 2023; 2(4): 255–263. https://doi.\norg/10.1002/hcs2.61 \n2. Thirunavukarasu A.J., Ting D.S.J., Elangovan K., et al. Large language models in medi -\ncine. Nat Med. 2023; 29: 1930–1940. https://doi.org/10.1038/s41591-023-02448-8 \n3. Meskó B., Topol E.J. The imperative for regulatory oversight of large language models (or \ngenerative AI) in healthcare. npj Digit. Med. 2023; 6(1): 120. https://doi.org/10.1038/\ns41746-023-00873-0 \n4. Language models and linguistic theories beyond words. Nat Mach Intell. 2023; 5: 677–\n678. https://doi.org/10.1038/s42256-023-00703-8 \n5. Kung T.H., Cheatham M., Medenilla A., et al. Performance of ChatGPT on USMLE: Poten-\ntial for AI-assisted medical education using large language models. PLOS Digital Health. \n2023; 2(2): e0000198. https://doi.org/10.1371/journal.pdig.0000198 \n6. Kaneda Y ., Takahashi R., Kaneda U., et al. Assessing the Performance of GPT-3.5 and GPT-\n4 on the 2023 Japanese Nursing Examination. Cureus. 2023; 15(8): e42924. https://doi.\norg/doi:10.7759/cureus.42924 \n7. Roos J., Kasapovic A., Jansen T., Kaczmarczyk R. Artificial Intelligence in Medical Educa-\ntion: Comparative Analysis of ChatGPT, Bing, and Medical Students in Germany. JMIR \nMed Educ. 2023; 9: e46482. https://doi.org/10.2196/46482 \n8. Singhal K., Aziz S., Tu T., et al. Large language models encode clinical knowledge. Na -\nture. 2023; 620: 172–180. https://doi.org/10.1038/s41586-023-06291-2 \n9. Sarraju A., Bruemmer D., Van Iterson E., et al. Appropriateness of Cardiovascular Di-\nsease Prevention Recommendations Obtained From a Popular Online Chat-Based Ar -\ntificial Intelligence Model. JAMA. 2023; 329(10): 842–844. https://doi.org/10.1001/\njama.2023.1044 \n10. Chen S., Kann B.H., Foote M.B., et al. Use of Artificial Intelligence Chatbots for Cancer \nTreatment Information. JAMA Oncol. Published online. 2023. https://doi.org/10.1001/\njamaoncol.2023.2954 \n11. Birkun A., Gautam A. Large language model-based chatbot as a source of advice on first \naid in heart attack. Current Problems in Cardiology. 2023: 1(49): 102048. https://doi.\norg/10.1016/j.cpcardiol.2023.102048 \n12. Jiang L.Y ., Liu X.C., Nejatian N.P ., et al. Health system-scale language models are all-\npurpose prediction engines. Nature. 2023; 619: 357–362. https://doi.org/10.1038/\ns41586-023-06160-y\n13. Moskatel L.S., Niushen Z. The utility of ChatGPT in the assessment of literature on the \nprevention of migraine: an observational, qualitative study. Frontiers in Neurology, \n2023, 14: 1225223. https://doi.org/10.3389/fneur.2023.1225223\n14. Lower K., Seth I., Lim B., Seth N. ChatGPT-4: Transforming Medical Education and Ad -\ndressing Clinical Exposure Challenges in the Post-pandemic Era. Indian J Orthop. 2023; \n57: 1527–1544. https://doi.org/10.1007/s43465-023-00967-7\nИнформация об авторах\nАндрейченко Анна Евгеньевна – канд. физ.-мат. наук, руководитель направления искусственного интеллекта ООО «К-Скай».\nORCID: https://orcid.org/0000-0001-6359-0763 \nГусев Александр Владимирович – канд. техн. наук, старший научный сотрудник отдела научных основ организации здравоохранения ФГБУ «Центральный научно-\nисследовательский институт организации и информатизации здравоохранения» Минздрава России; старший научный сотрудник ГБУЗ г. Москвы «Научно-практический \nклинический центр диагностики и телемедицинских технологий Департамента здравоохранения города Москвы».\nORCID: https://orcid.org/0000-0002-7380-8460 \nInformation about the authors\nAnna E. Andreychenko – Cand. of Sci. (Physics and Mathematics), Head of Artificial Intelligence, K-Skai LLC.\nORCID: https://orcid.org/0000-0001-6359-0763\nAleksandr V. Gusev – Cand. of Sci. (Technology), Senior Researcher, Department of Scientific Foundations of Healthcare Organization, Federal Research Institute for Health \nOrganization and Informatics; Senior Researcher, Scientific and Practical Clinical Center for Diagnostics and Telemedicine Technologies.\nORCID: https://orcid.org/0000-0002-7380-8460"
}