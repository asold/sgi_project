{
  "title": "Democratizing Protein Language Models with Parameter-Efficient Fine-Tuning",
  "url": "https://openalex.org/W4388583690",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3194097210",
      "name": "Samuel Sledzieski",
      "affiliations": [
        "Microsoft (United States)",
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2004269926",
      "name": "Meghana Kshirsagar",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2472350544",
      "name": "Minkyung Baek",
      "affiliations": [
        "Seoul National University"
      ]
    },
    {
      "id": "https://openalex.org/A2315546843",
      "name": "Bonnie Berger",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A1995994163",
      "name": "Rahul Dodhia",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2183540531",
      "name": "Juan Lavista Ferres",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A3194097210",
      "name": "Samuel Sledzieski",
      "affiliations": [
        "Microsoft (United States)",
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2004269926",
      "name": "Meghana Kshirsagar",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2472350544",
      "name": "Minkyung Baek",
      "affiliations": [
        "Seoul National University"
      ]
    },
    {
      "id": "https://openalex.org/A2315546843",
      "name": "Bonnie Berger",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A1995994163",
      "name": "Rahul Dodhia",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2183540531",
      "name": "Juan Lavista Ferres",
      "affiliations": [
        "Microsoft (United States)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3177323791",
    "https://openalex.org/W2980789587",
    "https://openalex.org/W4362508790",
    "https://openalex.org/W3186179742",
    "https://openalex.org/W3166142427",
    "https://openalex.org/W2130479394",
    "https://openalex.org/W4387507180",
    "https://openalex.org/W4317802023",
    "https://openalex.org/W2957436444",
    "https://openalex.org/W4367602258",
    "https://openalex.org/W3177500196",
    "https://openalex.org/W3202105508",
    "https://openalex.org/W6600991396",
    "https://openalex.org/W6826116265",
    "https://openalex.org/W3177828909",
    "https://openalex.org/W2128674962",
    "https://openalex.org/W4327550249",
    "https://openalex.org/W3015964336",
    "https://openalex.org/W4388024559",
    "https://openalex.org/W2008840001",
    "https://openalex.org/W3146944767",
    "https://openalex.org/W4280491631",
    "https://openalex.org/W4380272022",
    "https://openalex.org/W4226343290",
    "https://openalex.org/W4313197536",
    "https://openalex.org/W4394567450",
    "https://openalex.org/W4388007030",
    "https://openalex.org/W3199468887",
    "https://openalex.org/W2950954328",
    "https://openalex.org/W4283716699",
    "https://openalex.org/W4286669150",
    "https://openalex.org/W4383216409",
    "https://openalex.org/W4394579747",
    "https://openalex.org/W4391563878",
    "https://openalex.org/W4392500220",
    "https://openalex.org/W4388656332",
    "https://openalex.org/W4392168151",
    "https://openalex.org/W4384071683"
  ],
  "abstract": "Abstract Proteomics has been revolutionized by large pre-trained protein language models, which learn unsupervised representations from large corpora of sequences. The parameters of these models are then fine-tuned in a supervised setting to tailor the model to a specific downstream task. However, as model size increases, the computational and memory footprint of fine-tuning becomes a barrier for many research groups. In the field of natural language processing, which has seen a similar explosion in the size of models, these challenges have been addressed by methods for parameter-efficient fine-tuning (PEFT). In this work, we newly bring parameter-efficient fine-tuning methods to proteomics. Using the parameter-efficient method LoRA, we train new models for two important proteomic tasks: predicting protein-protein interactions (PPI) and predicting the symmetry of homooligomers. We show that for homooligomer symmetry prediction, these approaches achieve performance competitive with traditional fine-tuning while requiring reduced memory and using three orders of magnitude fewer parameters. On the PPI prediction task, we surprisingly find that PEFT models actually outperform traditional fine-tuning while using two orders of magnitude fewer parameters. Here, we go even further to show that freezing the parameters of the language model and training only a classification head also outperforms fine-tuning, using five orders of magnitude fewer parameters, and that both of these models outperform state-of-the-art PPI prediction methods with substantially reduced compute. We also demonstrate that PEFT is robust to variations in training hyper-parameters, and elucidate where best practices for PEFT in proteomics differ from in natural language processing. Thus, we provide a blueprint to democratize the power of protein language model tuning to groups which have limited computational resources.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5031136870384216
    },
    {
      "name": "Fine-tuning",
      "score": 0.4568941593170166
    },
    {
      "name": "Language model",
      "score": 0.4419785141944885
    },
    {
      "name": "Natural language processing",
      "score": 0.30801743268966675
    },
    {
      "name": "Physics",
      "score": 0.18571317195892334
    },
    {
      "name": "Particle physics",
      "score": 0.1488567292690277
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I63966007",
      "name": "Massachusetts Institute of Technology",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1290206253",
      "name": "Microsoft (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I139264467",
      "name": "Seoul National University",
      "country": "KR"
    }
  ],
  "cited_by": 14
}