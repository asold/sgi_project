{
  "title": "T-Gram: A Time-Aware Language Model to Predict Human Mobility",
  "url": "https://openalex.org/W2212251814",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A4224518833",
      "name": "Hsun-Ping Hsieh",
      "affiliations": [
        "National Taiwan University"
      ]
    },
    {
      "id": "https://openalex.org/A4222653774",
      "name": "Cheng-Te Li",
      "affiliations": [
        "Academia Sinica"
      ]
    },
    {
      "id": "https://openalex.org/A2111557507",
      "name": "Xiaoqing Gao",
      "affiliations": [
        "Xidian University"
      ]
    },
    {
      "id": "https://openalex.org/A4224518833",
      "name": "Hsun-Ping Hsieh",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4222653774",
      "name": "Cheng-Te Li",
      "affiliations": [
        "Research Center for Information Technology Innovation, Academia Sinica"
      ]
    },
    {
      "id": "https://openalex.org/A2111557507",
      "name": "Xiaoqing Gao",
      "affiliations": [
        "Xidian University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2044337911",
    "https://openalex.org/W2009779426",
    "https://openalex.org/W2072609015",
    "https://openalex.org/W2063718055",
    "https://openalex.org/W2069090820",
    "https://openalex.org/W2087692915",
    "https://openalex.org/W2077451659",
    "https://openalex.org/W6668440036",
    "https://openalex.org/W2073013176",
    "https://openalex.org/W2110953678"
  ],
  "abstract": "This paper presents a novel time-aware language model, T-gram, to predict the human mobility using location check-in data. While the conventional n-gram language model, which use the contextual co-occurrence to estimate the probability of a sequence of items, are often employed to predict human mobility, the time information of items is merely considered. T-gram exploits the time information associated at each location, and aims to estimate the probability of visiting satisfaction for a given sequence of locations. For a location sequence, if locations are visited at right times and the transitions between locations are proper as well, the T-gram probability gets higher. We also devise a T-gram Search algorithm to predict future locations. Experiments of human mobility prediction conducted on Gowalla check-in data significantly outperform a series of n-gram-based methods and encourage the future usage of T-gram.",
  "full_text": " \n \nT-Gram: A Time-Aware Language Mode l to Predict Human Mobility \nHsun-Ping Hsieh\n\u0002\u0002\n, Cheng-Te Li2, Xiaoqing Gao3 \n1Graduate Institute of Network and Multimedia, National Taiwan University, Taipei, Taiwan \n2Research Center for Information Technology I nnovation, Academia Sini ca, Taipei, Taiwan \n3 School of Computer Science and Technology, Xidian University, China \nd98944006@csie.ntu.edu.tw, ctli@citi.sinica.edu.tw, gaoxq@stu.xidian.edu.cn \n \nAbstract \nThis paper presents a novel time-aware language model, T-\ngram, to predict the human mobility using location check-in \ndata. While the conventional n-gram language model, which \nuse the contextual co-occurrence to estimate the probability \nof a sequence of items, are often employed to predict human \nmobility, the time information of items is merely consid-\nered. T-gram exploits the tim e information associated at \neach location, and aims to estimate the probability of visit-\ning satisfaction for a given sequence of locations. For a lo-\ncation sequence, if locations are visited at right times and \nthe transitions between locations are proper as well, the T-\ngram probability gets higher. We also devise a T-gram \nSearch algorithm to predict future locations. Experiments of \nhuman mobility prediction conducted on Gowalla check-in \ndata significantly outperform a series of n-gram-based \nmethods and encourage the future usage of T-gram. \u0001\n1 \n Introduction \n\u0003ocation-based services (LBS), such as Foursquare and \nGowalla, keep track of personal geospatial journeys \nthrough check-in actions. With smart phones, users can \neasily perform check-in actions, and the geographical in-\nformation of locations with timestamps is stored in LBS. A \nlarge-scaled user-generated lo cation sequences (i.e., routes) \ndata are derived. Such location sequence data can not only \ncollectively represent the real-world human geo-activities, \nbut also serve as a handy resource for constructing loca-\ntion-based recommendation systems. Since the user-\nmoving records implicitly reveal how people travel around \nan area with rich spatial and temporal information, includ-\ning longitude, latitude, and recording timestamp, one can \nuse such data to model human mobility by inferring the \nnext locations of users. \n Existing work on modeling human mobility has two di-\nrections. One is location recommendation  (e.g. Ye et al. \n2011), which is to recommend new locations that users \nhave never visited before. The other is location prediction  \n(e.g. Monreale et al. 2009), which is to predict the next ex-\nisting locations that users had ever visited. The approach to \n                                                \nCopyright © 2015, Association for the Advancement of Artificial Intelli-\ngence (www.aaai.org). All rights reserved. \nthese tasks is using n-gram language models with the con-\nsideration of the historical lo cations visited by users. How-\never, the visiting time informa tion hidden in locations and \nthe time duration transit between locations are merely in-\nvestigated. \nWe think the time information is important for predict-\ning human mobility. First, the reasonability and pleasure of \nvisiting a place are significantly  affected by the visiting \ntime. The user satisfaction woul d be diminished if going at \ninappropriate time. To either enjoy better experiences, \npeople might be believed to move and stay at places with \nthe right time. Second, the time spent on transitions be-\ntween locations limit the human mobility. It is impossible \nfor people to use a short time to transit between places dis-\ntant to each other, and unreasonable to take lots of hours to \ntransit between locations with a few city blocks to one an-\nother. \nThis paper proposes a novel time-aware language model, \nT-gram, to model and predict the human mobility using lo-\ncation check-in data. Comparing to conventional language \nmodels, which capture the contextual correlation between \nconsecutively visited locations , T-gram uses the time in-\nformation associated at each location, and aims to estimate \nthe probability of visiting satisfaction for a given sequence \nof locations associated with  visiting time stamps. The idea \nis that for a location sequence, if its locations are visited at \ntheir right times and the transitions between locations are \nproper as well, the T-gram probability gets higher. In other \nwords, T-gram can be regarded as a measure that deter-\nmines how well the locations along a location sequence are \nvisited in terms of the visiting time and transition time. \nBased on T-gram, we develop a predictive method, T-gram \nSearch, to predict the human mobility whose goal is to \npredict the future locations of a user. \nRelated Work \nThe relevant studies on predicting human mobility using \nhistorical location sequences can be divided into two cate-\ngories: location prediction  and location recommendation . \nLocation prediction focuses on predicting the next existing \nProceedings of the Ninth International AAAI Conference on Web and Social Media\n614\nlocations that the user had ever visited while location rec-\nommendation is to recommend new locations that the user \nhas never visited before. The general consideration of loca-\ntion prediction and recommendati on is the historically geo-\nlocations visited by users, and the common solution is us-\ning probabilistic language models or Markov models to \ncapture the spatio-temporal correlation between locations \nso that the locations can be predicted successively. \nLocation Prediction \nMonreale et al. (2009) predict the next location of a mov-\ning object with mined frequent  trajectory patterns that cap-\nture the common paths. They construct a decision tree-like \nstructure, T-pattern Tree, as a predictor of the next location \nof a new trajectory finding the best matching path in the \ntree. Ying et al. (2011) further leverage the semantic in-\nformation, which describes the activities (in the form of \ntags and types) of locations. Then given the recent moves \nof a user, they define and compute the matching score geo-\ngraphically and semantically between mined frequent sub-\ntrajectories and the given moves to find the best matched \ntrajectory for the next location prediction. Sadilek et al. \n(2012) predict the most likely location of an individual, \ngiven the historical trajectorie s of his/her friends. They ex-\nploit the discrete dynamic Bayesian network  to model the \nmotion patterns of Twitter users from their friends, in \nwhich there is a hidden target user node and a number of \nobserved information nodes of locations in each time slice. \nIn addition to the query tim e, Chiang (2013) further con-\nsider the current time to predict locations. They construct a \nTime-constrained Mobility Graph  that captures a user’s \nmoving behavior within a certain time interval, and com-\npute the reachability between locations to infer next one. \nLocation Recommendation \nYe et al. (2011) point out the importance of geographical \ninfluence, which refers to that people tend to visit (a) near-\nby locations and (b) may be interested in farther locations \nthat they are in favor of, to predict check-in locations. Liu \nand Liu et al. (2013) perform personalized point-of-interest \nrecommendation. Their main advantage lies in using ma-\ntrix factorization to mine the transition patterns of user \npreferences over location categories to enhance the predic-\ntion accuracy. Yuan et al. (2013) further propose a time-\naware POI recommendation to recommend suitable loca-\ntions for a certain user at a specified time in a day, using a \ntemporal-enhance collaborating filtering. Noulas et al. \n(2012) predict the next check-in venue that a mobile user \nwill visit by formulating it as a ranking task: given a user \nwith his/her current check-in venue, ranking all the venues \nso that the predicted one is at the highest position. They \ndevise the ranking measure cons idering transitions between \ntypes of places and flows of movement between places. \nT-gram Model \nWe devise a novel time-aware language model, T-gram, to \nestimate the probability of a location sequence with time \nstamps. T-gram consists of tw o parts: (a) measuring the us-\ner satisfaction of visiting a location at a given time, and (b) \nmeasuring the reasonability when using a particular transi-\ntion time between locations. We  define the location time \ndistribution of a location and transition time distribution  \nbetween locations, which can be derived using the check-in \ntime in the location sequences containing location l\ni. \nDefinition 1. (Location Time Distribution ). A Visiting \nTime Distribution  (LTD) of location li is a probability dis-\ntribution over time labels in hour, denoted by LTDli(t) = \n<(t0, p0), (t1, p1),\u0001..., (t23, p23)>, where p0 + p1 + ... + p23 = \n1.0. \nDefinition 2.  (Transition Time Distribution ). A Transi-\ntion Time Distribution (TTD) between location li and lj is \ndefined as the probability distribution over time duration /g1 \nin hour, TTDli,lj(/g1) = <( /g11, p1), ( /g12, p2), ..., ( /g123, p23)>, \nwhere p1 + p2 + ... + p23 = 1.0. \nT-gram Language Model \nThe proposed T-gram language model consists of two parts: \nmeasuring the goodness of the visiting time of locations \nand the transition time between locations using LTD and \nTTD respectively. We elaborate the details of LTD pleasant \nmeasure. Note that the pleasant measure of TTD follows \nthe same settings. Assuming we want to know how well a \ndecision is to visit a place at time /g1, given the location’s \nLTD, we propose to first generate a thin Gaussian distribu-\ntion /g1/g1/g1/g1/g1/g1/g1\n/g1/g1 whose mean value /g1 is at time /g1 with a \nvery small variance /g1/g1 (e.g. standard deviation is 1). And \nthen we can transform the original task into measuring the \ndifference between the Gaussi an distribution with the \nlearnt LTD of such location. We use the symmetric Kull-\nback-Leibler (KL) Divergence  between /g1/g1/g1/g1/g1/g1/g1\n/g1/g1 and \n/g2/g3/g1/g1/g1/g1/g1 to represent the fitness of the assignment. The \nformal mathematical definition of a fitness score between a \nplace l and a time t can be defined as: \n/g1/g1/g2/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g2/g3/g1/g1/g1/g1/g1 \n/g1 /g1/g1/g1/g1/g1/g1/g1\n/g1\n/g2/g3/g1/g1/g1/g1/g1/g1/g1/g1\n/g2/g3/g1/g1/g1 /g1 /g2/g3/g1/g1/g1/g1/g1\n/g1\n/g2/g3/g1/g2/g3/g1/g1/g1/g1/g1\n/g1/g1/g1/g1/g1/g1/g1/g1/g1 \nConceivably, a smaller KL value indicates better match be-\ntween the assignment and the di stribution learned from da-\nta. Consequently, we formally define the T-gram probabil-\nity, ProbT(s), of a location sequence s=<(l1,t1), ( l2,t2), ..., \n(ln,tn)>, as a combination of the popularity of places to-\ngether with the fitness of each location over time, in the \nfollowing equation. \n/g1/g4/g3/g2/g1/g1/g1 \n/g1/g1 /g1/g1/g2/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g2/g3/g1/g1/g1/g1/g1/g1/g1 /g1\n/g2/g1/g2/g1/g1\n/g1\n/g1/g1/g1\n/g1/g1\n/g1\n/g1 \n615\n/g1/g1/g1/g1/g1/g1 /g1/g1/g2/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g2/g2/g1/g1/g1/g1/g1/g1/g1/g1\n/g1/g1/g1\n/g1/g1/g1\n/g1/g1\n/g1/g1/g1\n \nwhere /g2/g1/g2/g1/g1 /g1/g1/g1/g1/g1/g1/g1/g1/g2/g1/g3, /g1/g1/g1/g1/g1 is the number of re-\ncording actions performed on location /g1/g1, and /g1/g2/g1/g3 is the \nmaximum number of recording actions among all the loca-\ntions in the location sequence dataset. In addition, the pa-\nrameter /g1 is used to control the preference or importance \non either visiting time or transition time. Higher /g1 values \nrefer to prefer the visiting quality on locations while lower \n/g1 values indicate the human mobility should be strictly \nscheduled based on regular transportations. If the places in \na location sequence s are visited during the proper time pe-\nriod, the /g1/g4/g3/g2\n/g1/g1/g1value would become higher. \nApplication to Predict Human Mobility \nWe aim to use the proposed T-gram language model to \npredict human mobility in check-in data. Given the source-\ndestination query Q\nd = ( ls, ts, ld) that depicts the clue of \nhuman mobility to be predicted, where ls is the initial loca-\ntion, ts is the starting timestamp, ld is the destination loca-\ntion, and/or the preferred number of locations k if any, the \ngoal of the mobility prediction is to predict the location se-\nquence in response to Qs or Qd. We propose a T-gram \nSearch algorithm to predict mobility. The basic idea is to \nfind a path s = <( l1=ls,t1=ts), (l2,t2), ..., ( lk=ld,tk)> among lo-\ncations such that the value of  /g1/g4/g3/g2/g1/g1 is maximized. \nFigure 1: T-gram Search Algorithm. \nT-gram Search  consists of three steps, and the detailed \nalgorithm is described in Figur e 1. We first construct the \ninitial location sequence /g1/g1 by including the initial location \n/g1/g1 (line 1). A /g1/g6/g4/g5/g6/g4/g7/g9/g2/g8/g3/g8/g3 is used to maintain the loca-\ntion sequence with the highest T-gram score (line 2). Each \nelement in /g1/g6/g4/g5/g6/g4/g7/g9/g2/g8/g3/g8/g3 consists of a location sequence \n/g1 and the corresponding T-gram score. /g1/g6/g4/g5/g6/g4/g7/g9/g2/g8/g3/g8/g3 au-\ntomatically sorts its elements  according to their T-gram \nscores. We add /g1/g1 to initialize /g1/g6/g4/g5/g6/g4/g7/g9/g2/g8/g3/g8/g3. After set-\nting the final location sequence /g1/g1 as the initial one /g1/g1 (line \n3), we perform the iterative expansion search process until \nthe location sequence /g1 is constructed up to length /g1 (line \n5-13). Each iteration the last location /g1/g2/g1/g3/g4 in the location \nsequence /g1 with the highest T-gram probability is identi-\nfied (line 6 and line 13) and each possible next visiting lo-\ncation /g1/g2/g1/g4/g3 from the location sequence data is put into a \ncandidate set /g1 (line 7). Then for each candidate next loca-\ntion /g1/g1, and for each time label /g1/g1 in the time label set /g1/g1/g1 of \n/g1/g1, we can derive the score /g1/g4/g3/g2/g1/g1/g1/g3/g1/g2/g1/g1/g1 /g1/g1/g1/g1/g1 /g1e. \nWe put /g1/g4/g3/g2/g1/g1/g1/g3/g1/g2/g1 together with the corresponding loca-\ntion sequence /g1/g1/g1/g2 into /g1/g6/g4/g5/g6/g4/g7/g9/g2/g8/g3/g8/g3 (line 8-12). \n/g1/g6/g4/g5/g6/g4/g7/g9/g2/g8/g3/g8/g3 will then pick the next best location se-\nquence and location to conduct the further expansions (line \n13). Finally (line 14), the location sequence /g1 is reported as \nthe predicted one. \nExperiments \nWe use a large-scale check-in data from Gowalla (Cho et \nal. 2011) for the experiments. This Gowalla dataset con-\ntains 6,442,890 check-in records from Feb. 2009 to Oct. \n2010. The total number of check-in locations is 1,280,969. \nBy constraining a location sequence as consecutive check-\nin locations of a user within  a day, we can obtain 1,136,737 \nlocation sequences whose lengths are more than one and \nthe average length of  location sequence is 4.09. We extract \ntwo check-in subsets falling into the urban areas of New \nYork and San Francisco. Some statistics are reported in \nTable 1. \nTable 1: Statistics of two check-in data subsets. \nExperiment 1 : Location Sequence Ranking.  We aim to \nverify if the proposed T-gram model can rank the location \nsequences higher than the fake ones. We first randomly \nchoose one thousand real location sequences. For each lo-\ncation sequence, we replace a portion of locations with \nother locations in the same city to generate a pseudo se-\nquence. Each selected location sequence is paired with a \npseudo one. To make the task non-trivial, we adopt a re-\nplacing strategy to replace a lo cation with a plausible one \ninstead of a randomly selected one. That is, to replace a lo-\ncation at position i of a location sequence, we only choose \nfrom candidate locations that have ever appear right after \nthe location at position i-1 (e.g. the bigram probability of \nthem is non-zero). We use T- gram model to examine each \npair of the real location sequence and its pseudo sequence, \nand record how frequently our method ranks the correct \none higher. We report the accuracy of our method and \ncompare it with baselines. The accuracy is defined as the \nnumber of correctly ranked pairs (i.e. an algorithm assigns \nInput: (a) the location sequence data /g1/g2; (b) the mobility query /g1/g1/g1\n/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1; (c) /g1: the number of locations. \nOutput: the predicted /g1/g1/g1/g1/g1/g1/g1/g1 /g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1  \n1: /g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1. \n2: /g1/g6/g4/g5/g6/g4/g7/g9/g2/g8/g3/g8/g3/g1/g1/g1/g1/g1/g1/g1/g1/g1. \n3: /g1/g1/g1/g1. \n4: /g1/g2/g1/g3/g4/g1/g2/g3/g1/g1/g1 \n5: while /g1/g1/g1/g1 do: \n6: /g1/g2/g1/g3/g4/g1/g1/g1/g1/g5/g7/g4/g1/g8/g3/g2/g9/g6/g8/g7.  \n7: /g1/g1/g1/g2/g1/g4/g3/g1/g1/g2/g1/g3/g4/g1/g1/g2/g1/g4/g3/g1/g1/g2/g1/g1/g2.  \n8: for each /g1/g1/g1/g1 do:  \n9: for each /g1/g1/g1/g1/g1/g1 do: \n10: /g1/g3/g1/g2/g1/g1/g1 /g1/g1/g1/g1/g1 .   \n11: /g5/g1/g3/g4/g2/g1/g1/g4/g3/g2/g1/g1/g3/g1/g2.   \n12: /g1/g6/g4/g5/g6/g4/g7/g9/g2/g8/g3/g8/g3/g1/g1/g3/g5/g2/g4/g6/g1/g1/g1/g3/g1/g2/g1/g5/g1/g3/g4/g2/g1/g1.  \n13: /g1/g1/g1/g1/g6/g4/g5/g6/g4/g7/g9/g2/g8/g3/g8/g3/g1/g1/g3/g2/g2/g1/g1.  \n14: return /g1. \n Total Number  \nof Check-ins \nAvg. Seq  \nLength \nNumber of Lo-\ncations \nNew York 103,174 4.46 21,973 \nSan Francisco 187,568 4.09 15,406 \n616\nhigher score to the real location sequence than the pseudo \nsequence) divided by the total number of pairs. \nBaseline Methods.  We also design the following base-\nline competitors, which search in the check-in database in a \ngreedy manner to find the location sequence that not only \nsatisfies query requirement, but also maximize a certain \nobjective function /g1\n/g1. (a) Distance-based Approach  \nchooses the closest location to the current spot as the next \nspot to move to. It measures the quality a location se-\nquence by using the objective \ntion\n/g1/g1/g1/g2/g3/g4/g1/g1 /g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1\n/g1/g1/g1\n/g1\n, where /g1/g1/g1/g1/g1/g1/g1/g1 is the \ngeographical distance between locations. (b) Popularity-\nbased Approach  chooses the most popular spot of a given \ntime to be the next spot. It rates the location sequence us-\ning the goodness function /g1/g2/g1/g2/g1/g1 /g1/g1/g1/g1/g1/g1/g1/g1/g2/g1/g3/g1/g1\n/g1/g1/g1\n/g1\n. (c) \nForward Heuristic Approach  chooses location li possessing \nthe largest bi-gram probability with the previous location \n/g1/g1/g1\n/g1/g1/g1/g1/g1/g1/g1  as the next: \n/g1/g1/g2/g3/g4/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1\n/g1\n. (d) Backward \nHeuristic Approach chooses li that possesses the largest bi-\ngram probability with the next location /g1/g1/g1/g1/g1/g1/g1/g1/g1/g1 as the \nnext location. The goodness function is designed \nas/g1/g2/g1/g3/g4/g5/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1/g1\n/g1\n. \nWe vary the number of replaced locations from 10% to \n50%. We set the parameter /g1 in T-gram as 0.5. Figure 2(a) \nshows the results for San Francisco. T-gram model \nachieves around 98% accuracy in distinguishing the real \nlocation sequences from fake ones. The forward and back-\nward heuristics reaches about 80% accuracy. The popular-\nbased and distance-based me thods do not do a good job as \nthey only reach 50% or lower in accuracy. Similar trend \nhappens in New York (Figure 2(b)). The results are not \nsurprising because T-gram considers the location prefer-\nence over time.\n \nExperiment 2:  Mobility Cloze Test.  Given a set of lo-\ncation sequences with time stamp in each location, through \nrandomly removing m consecutive locations in each loca-\ntion sequence, we aim to te st whether a method can suc-\ncessfully recover the missing locations. With the increasing \nof m, consecutive removal of lo cations does impose decent \nlevel of difficulty to this cloze test. It is because that when \nm increases, the information that can be utilized becomes \nsparse, and mistakes in the earlier position can lead to fol-\nlow-up errors in the next positions to be predicted. We use \nHit Rate as the accuracy measure for the cloze test. Given \nthere are totally N removals of locations over all location \nsequences, and assumed M places out of N is successfully \npredicted, the hit rate is defined as M/N. Higher hit rate in-\ndicates better quality of recommendation. Note that when \nthere are multiple missing places in the cloze test, we only \nconsider the fully-recovered sequences as hits. By varying \nthe number of missing instances per location sequence and \nreport the hit rates. The results are shown in Figure 3. In \ngeneral, the hit rates are decreasing while the number of \nmissing instance increases. Such results encourage the us-\nage of T-gram with the pred ictive method to model human \nmobility. \n \nConclusion \nIn this paper, we propose a novel time-aware language \nmodel, T-gram, to measure the probability of visiting satis-\nfaction for a given time-stamped location sequence. We al-\nso develop a T-gram Search algorithm to predict the hu-\nman mobility. Experiment results show that T-gram out-\nperforms a series of n-gram -based methods on location se-\nquence ranking and mobility cloze test.  \n Figure 2: Accuracy by varying the number of replaced lo-\ncations in San Francisco (left) and New York (right). \nFigure 3: Hit rate by varying the number of guessing instance \nper sequence in San Francisco (left) and New York (right).  \nReferences \nM.-F. Chiang, Y.-H. Lin, W.-C. Peng, and P. S. Yu. Inferring distant-time \nlocation in low-sampling-rate trajectories. In ACM KDD 2013. \nE. Cho, S. A. Myers, and J. Leskovec. Friendship and mobility: User \nmovement in location-based social networks. In ACM KDD 2011. \nB. Liu, Y. Fu, Z. Yao, and H. Xiong. Learning Geographical Preferences \nfor Point-of-Interest Recommendation. In ACM KDD 2013. \nX. Liu, Y. Liu, K. Aberer, and C.  Miao. Personalized point-of-interest \nrecommendation by mining users’ preference transition. In ACM CIKM  \n2013. \nA. Monreale, F. Pinelli, R. Trasarti, and F. Giannotti. Where next: a loca-\ntion predictor on trajectory pattern mining. In ACM KDD 2009. \nA. Noulas, S. Scellato, N. Lathia, and C. Masolo. Mining User Mobility \nFeatures for Next Place Prediction in Location-based Services. In IEEE \nICDM 2012.  \nA. Sadilek, H. Kautz, and J. P. Bigham. Finding your friends and follow-\ning them to where you are. In ACM WSDM 2012. \nM. Ye, P. Yin, W.-C. Lee, and D.-L . Lee. Exploiting geographical influ-\nence for collaborative point-of-interest recommendation. In ACM SIGIR  \n2011. \nJ.-C. Ying, W.-C. Lee, T.-C. Weng, a nd V. S. Tseng. Semantic trajectory \nmining for location prediction. In ACM GIS 2011. \nQ. Yuan, G. Cong, Z. Ma, A. Sun,  and N. M. Thalmann. Time-aware \npoint-of-interest recommendation. In ACM SIGIR 2013. \n\u0001\u0001\u0001\u0001  \n \n\u0001\u0001\u0001\u0001\u0001   \n617",
  "topic": "n-gram",
  "concepts": [
    {
      "name": "n-gram",
      "score": 0.8748534917831421
    },
    {
      "name": "Gram",
      "score": 0.767634391784668
    },
    {
      "name": "Computer science",
      "score": 0.7139086723327637
    },
    {
      "name": "Sequence (biology)",
      "score": 0.6929202675819397
    },
    {
      "name": "Key (lock)",
      "score": 0.46951812505722046
    },
    {
      "name": "Language model",
      "score": 0.46473076939582825
    },
    {
      "name": "Exploit",
      "score": 0.42414945363998413
    },
    {
      "name": "Data mining",
      "score": 0.3873225152492523
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3271949291229248
    },
    {
      "name": "Computer security",
      "score": 0.0801057517528534
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Genetics",
      "score": 0.0
    },
    {
      "name": "Bacteria",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I16733864",
      "name": "National Taiwan University",
      "country": "TW"
    },
    {
      "id": "https://openalex.org/I84653119",
      "name": "Academia Sinica",
      "country": "TW"
    },
    {
      "id": "https://openalex.org/I149594827",
      "name": "Xidian University",
      "country": "CN"
    }
  ],
  "cited_by": 11
}