{
  "title": "Innovative Applications of Large Language Models for Medical Record Access Audits",
  "url": "https://openalex.org/W4393084305",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2274286819",
      "name": "陳文意",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5094221643",
      "name": "黃兆明",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3199544889",
    "https://openalex.org/W4392956768",
    "https://openalex.org/W3010611814",
    "https://openalex.org/W4392861741",
    "https://openalex.org/W4385227045",
    "https://openalex.org/W4386583873",
    "https://openalex.org/W7018787370",
    "https://openalex.org/W6990236461",
    "https://openalex.org/W3186301578",
    "https://openalex.org/W3082445426",
    "https://openalex.org/W4383816185",
    "https://openalex.org/W3089687642",
    "https://openalex.org/W3133848105",
    "https://openalex.org/W4307268950",
    "https://openalex.org/W3006558576",
    "https://openalex.org/W3137923936",
    "https://openalex.org/W3024437525",
    "https://openalex.org/W3001584199",
    "https://openalex.org/W4285060979",
    "https://openalex.org/W3034537023",
    "https://openalex.org/W4303943912",
    "https://openalex.org/W6780542855",
    "https://openalex.org/W3158616732",
    "https://openalex.org/W4244029011",
    "https://openalex.org/W3046918297",
    "https://openalex.org/W3197340673"
  ],
  "abstract": "This study explores the application of Mistral 8x7b, a state-of-the-art Large Language Model (LLM) with a mixture of experts architecture, in auditing access to medical records. By conducting a comprehensive evaluation, including both quantitative and qualitative analyses, we demonstrate that Mistral 8x7b significantly outperforms traditional audit methods in detecting unauthorized access, showcasing superior accuracy, precision, recall, and F1 score metrics. Additionally, our findings reveal notable improvements in computational efficiency, indicating the model's potential to enhance the privacy and security of healthcare data systems significantly. The research addresses the broader implications for healthcare privacy, AI ethics, and the responsible integration of AI technologies in sensitive domains. Despite acknowledging certain limitations and the necessity for further validation in real-world settings, this study underscores the transformative potential of advanced AI models like Mistral 8x7b in improving data security protocols and contributing to the safeguarding of patient information in an increasingly digital healthcare landscape.",
  "full_text": "1\nInnovative Applications of Large Language Models\nfor Medical Record Access Audits\nMan-Yee Chan, and Siu-Ming Wong\nAbstract—This study explores the application of Mistral 8x7b,\na state-of-the-art Large Language Model (LLM) with a mixture\nof experts architecture, in auditing access to medical records. By\nconducting a comprehensive evaluation, including both quantita-\ntive and qualitative analyses, we demonstrate that Mistral 8x7b\nsignificantly outperforms traditional audit methods in detecting\nunauthorized access, showcasing superior accuracy, precision,\nrecall, and F1 score metrics. Additionally, our findings reveal\nnotable improvements in computational efficiency, indicating\nthe model’s potential to enhance the privacy and security of\nhealthcare data systems significantly. The research addresses the\nbroader implications for healthcare privacy, AI ethics, and the\nresponsible integration of AI technologies in sensitive domains.\nDespite acknowledging certain limitations and the necessity for\nfurther validation in real-world settings, this study underscores\nthe transformative potential of advanced AI models like Mistral\n8x7b in improving data security protocols and contributing to\nthe safeguarding of patient information in an increasingly digital\nhealthcare landscape.\nIndex Terms—Large Language Models, Healthcare Data Se-\ncurity, Unauthorized Access Detection, AI Ethics in Healthcare,\nData Audits\nI. I NTRODUCTION\nThe modern healthcare industry is increasingly reliant on\ndigital records, making the security and privacy of medical\ndata a paramount concern for patients, providers, and regula-\ntors alike [1]–[3]. The transition from paper-based to digital\nmedical records has undoubtedly enhanced the efficiency of\nhealthcare delivery and improved patient outcomes [1]. How-\never, it has also introduced complex challenges in ensuring the\nprivacy and security of sensitive health information. Unautho-\nrized access to medical records not only compromises patient\nprivacy but also poses significant legal and ethical dilemmas\n[1], [4]. In response to these challenges, the application\nof Large Language Models (LLMs) in auditing access logs\npresents an innovative solution, as they offer the potential\nto revolutionize the way healthcare providers monitor and\ncontrol access to medical records, ensuring compliance with\nlegal standards and ethical norms [5]. This section provides\nan overview of the critical problem of medical record privacy\nand introduces the novel application of LLMs in enhancing\nthe security protocols through efficient access audits.\nA. Background\nThe foundation of patient trust in the healthcare system is\npredicated on the assurance of confidentiality and privacy of\nManuscript submitted on the date of March 22, 2024. Corresponding author:\nMan-Yee Chan (email: Chan-Man-Yee-HK@hotmail.com)\ntheir medical records [1], [3]. The sensitivity of the infor-\nmation contained within these records, ranging from personal\nidentifiers to detailed medical histories, warrants rigorous\nprotocols to prevent unauthorized access and breaches [1], [3].\nRegulatory frameworks like the Health Insurance Portability\nand Accountability Act (HIPAA) in the United States have\nbeen established to mandate the safeguarding of patient in-\nformation. Despite these efforts, the increasing sophistication\nof cyber threats and the complexities of managing access in\nlarge healthcare systems pose ongoing risks [3]. Traditional\nmethods of auditing access logs are often labor-intensive and\nmay not effectively identify unauthorized access in real-time\n[6]. The advent of LLMs, with their capacity to process\nand analyze vast datasets swiftly, offers a groundbreaking\napproach to auditing [5]. By leveraging the capabilities of\nLLMs, healthcare providers can implement more dynamic\nand effective strategies to monitor access to medical records,\nthereby enhancing the overall security posture of healthcare\ninformation systems.\nB. Contribution\nThis paper introduces a novel application of Large Language\nModels (LLMs) in the realm of healthcare data security,\nspecifically in the auditing of access to medical records. Our\nresearch leverages the Mistral 8x7b model, a cutting-edge\nLLM, to process and analyze access logs to synthetic de-\nidentified patient medical records. Through careful prompt\nengineering and comprehensive analysis, we demonstrate the\nmodel’s exceptional ability to identify patterns indicative of\nunauthorized access with high accuracy and efficiency. This\nstudy not only provides a detailed examination of the appli-\ncation of LLMs in a critical area of healthcare privacy but\nalso proposes a scalable and effective solution to enhance the\nauditing processes. By doing so, we contribute significantly\nto the field of healthcare cybersecurity, offering insights that\ncould inform future developments in policy, practice, and\ntechnology. The implications of our work extend beyond the\nimmediate context, suggesting potential applications of LLMs\nin other areas of data security and privacy.\nA list of our major contributions:\n1) Demonstrated the superior performance of Mistral 8x7b,\na state-of-the-art LLM, over traditional methods in accu-\nrately detecting unauthorized access to medical records,\nthrough rigorous quantitative benchmarks.\n2) Highlighted significant improvements in computational\nefficiency, including faster processing times and reduced\nresource utilization, made possible by the advanced\narchitecture of Mistral 8x7b.\n2\n3) Explored the broader implications of employing ad-\nvanced AI technologies in healthcare privacy and ethics,\ncontributing to the discourse on responsible AI use in\nsensitive domains.\n4) Identified limitations and proposed future research direc-\ntions, emphasizing the need for real-world validation,\nmodel adaptability, and ethical considerations in AI\napplications within healthcare data security.\nII. L ITERATURE SURVEY\nThis section surveys existing approaches to access audits\nand the use of AI/ML in healthcare privacy.\nA. Access Audit Mechanisms in Healthcare\nRecent studies in the domain of healthcare data privacy\nhave unveiled a variety of innovative access audit mecha-\nnisms. The effectiveness of role-based access controls can\nbe enhanced by machine learning algorithms to predict and\nprevent unauthorized access, suggesting a significant reduction\nin privacy breaches [7]–[9]. Another research outcome high-\nlighted the use of anomaly detection techniques in auditing,\nwhere unusual access patterns were automatically flagged for\nreview, indicating an improvement in early detection of data\nmisuse [6], [8], [10], [11]. Some explored the integration of\nblockchain technology for immutable access logs, ensuring\ntamper-proof record-keeping and enhancing trust in audit\nprocesses [12]. Further, the application of natural language\nprocessing (NLP) techniques to interpret access logs and iden-\ntify unauthorized access scenarios was found to increase the\nefficiency of audit reviews [13]–[15]. Additionally, research\ninto the use of federated learning models for access audits\npromises to uphold data privacy while enabling collaborative\nanalysis across multiple healthcare institutions [11], [16]–[18].\nThe development of predictive access control systems, using\nhistorical access data to anticipate and prevent unauthorized\naccess before it occurs, marks a significant advancement in\nproactive data privacy measures [6], [19]. Lastly, the adoption\nof AI-driven user behavior analytics for continuous monitoring\nof access patterns was shown to significantly enhance the\ncapability to detect and respond to potential data breaches in\nreal time [20].\nB. AI/ML in Enhancing Healthcare Privacy\nThe intersection of artificial intelligence (AI) and machine\nlearning (ML) with healthcare privacy has led to signifi-\ncant advancements in protecting sensitive patient information.\nSome studies revealed how AI algorithms could be trained\nto automatically redact sensitive information from healthcare\nrecords, thereby reducing the risk of data exposure [21], [22].\nML models could effectively classify data access as either\nlegitimate or suspicious, thus streamlining the audit process\n[23], [24]. The use of deep learning for the automatic detec-\ntion of privacy breaches in electronic health records (EHRs)\nshowed promise in identifying complex breach patterns that\nelude traditional detection methods [25], [25], [26]. Research\ninto the application of unsupervised learning algorithms for\ndiscovering hidden patterns in access logs has opened new\navenues for understanding and mitigating privacy risks [27],\n[28]. The efficacy of neural network-based systems in sim-\nulating user access behaviors to predict potential breaches\nbefore they occur has been demonstrated, offering a proactive\napproach to healthcare data security [29]–[31]. Moreover, the\ndeployment of AI for real-time monitoring and alerting on\nprivacy-intrusive actions within EHR systems has been found\nto significantly improve response times to potential breaches\n[32]. Studies focusing on the ethical use of AI in managing\npatient consent and data sharing preferences suggest a pathway\nto more personalized and secure data handling practices [33],\n[34].\nIII. M ETHODOLOGY\nThe methodology section outlines the comprehensive re-\nsearch design, data collection processes, and analytical tech-\nniques employed in this study to investigate the application of\nLarge Language Models (LLMs) for auditing access to med-\nical records. Emphasizing the use of synthetic de-identified\npatient records and the rationale behind selecting the Mistral\n8x7b model, this section provides a detailed account of the\npreparatory work, model architecture, and prompt engineering\nstrategies devised to maximize the model’s efficacy in identi-\nfying unauthorized access patterns.\nA. Data Preparation\nThe foundational step in our research involved the careful\npreparation of synthetic de-identified patient records. This pro-\ncess entailed generating a comprehensive dataset that mirrors\nthe complexity and diversity of real-world medical records\nwhile ensuring complete anonymization to eliminate any pri-\nvacy concerns. Techniques such as data scrambling and the use\nof synthetic data generation tools were employed to create a\ndataset that includes a wide array of medical scenarios and\naccess patterns. Subsequently, these records were systemat-\nically categorized and tagged to facilitate the training and\ntesting phases of the model. The preparation process also\ninvolved the normalization and standardization of data formats\nto ensure consistency and reliability in the model’s input,\nthereby enhancing the accuracy of the audit analysis. This\nphase was critical in simulating a realistic environment for\nevaluating the model’s performance in detecting and analyzing\naccess log anomalies.\nIn this algorithm, Draw represents the collection of data\nattributes used as the basis for synthetic data generation, and\nFsynth is the function employed to generate synthetic records.\nThe process involves generating N synthetic records, each\nundergoing data scrambling for anonymization, normalization\nto standard formats, and finally categorization and tagging to\nfacilitate subsequent phases of model training and testing. This\nalgorithmic representation succinctly encapsulates the complex\nprocess of data preparation, highlighting the mathematical and\nprocedural rigor underlying our approach to creating a realistic\nand comprehensive dataset for auditing access logs.\n3\nAlgorithm 1 Process of Preparing Synthetic De-identified\nPatient Records\nRequire: Draw, set of raw data attributes\nRequire: Fsynth, synthetic data generation function\nRequire: N, number of synthetic records to generate\nDsynth ← ∅ ▷ Initialize synthetic dataset\nfor i = 1 to N do\nr ← Fsynth(Draw)\nr ← Scramble(r) ▷ Data scrambling for anonymization\nr ← Normalize(r) ▷ Normalize data format\nDsynth ← Dsynth ∪ {r}\nend for\nDprepared ← CategorizeAndTag(Dsynth) ▷ Categorize and\ntag for model training/testing return Dprepared\nB. Model Description\nMistral 8x7b, a state-of-the-art Large Language Model\n(LLM) featuring a mixture of experts architecture with eight\n”experts” of seven billion parameters each, was chosen for its\nexceptional ability to understand and generate human-like text.\nThis model’s architecture allows for specialized processing by\ndifferent subsets of the model, depending on the task at hand,\nmaking it uniquely suited for the complex analysis required\nin auditing access logs of medical records. The ”mixture of\nexperts” approach enables the model to efficiently handle a\nvariety of tasks by leveraging the specialized knowledge em-\nbedded within each expert, thereby offering nuanced insights\ninto the access patterns. The selection of Mistral 8x7b was\ndriven by its proven track record in processing large datasets,\nits ability to discern subtle patterns and anomalies in data,\nand its flexibility in adapting to the specific requirements\nof medical record audit tasks. Table I summarizes the main\nfeatures, characteristics, and benefits of Mistral 8x7b for this\nstudy. This subsection elucidates the technical underpinnings\nof Mistral 8x7b, highlighting how its design and capabilities\nalign with the objectives of this study, as evidenced by the\nattributes listed in Table I.\nAdditional justification for the selection of Mistral 8x7b\nincludes its scalable architecture, which facilitates the process-\ning of extensive healthcare datasets without compromising on\nanalysis speed or accuracy. Furthermore, the ability of Mistral\n8x7b to be fine-tuned for specific analytical tasks allows for the\ncustomization of the model to better recognize and interpret\nthe intricacies of medical record access logs. The employment\nof this LLM in our study not only enhances the robustness of\nthe audit process but also introduces a level of precision in\nanomaly detection that is difficult to achieve with traditional\nmethods.\nC. Prompt Engineering\nPrompt engineering emerged as a critical technique in\nharnessing the full potential of Mistral 8x7b for our auditing\nobjectives. This process involved the strategic formulation of\nprompts that guide the model in analyzing access logs, identi-\nfying unauthorized access incidents, and extracting meaningful\ninsights from the data. By crafting prompts that encapsulate\nthe nuances of healthcare data access and privacy concerns, we\nwere able to direct the model’s attention to specific patterns of\ninterest, such as anomalous access events or deviations from\ntypical access behaviors. The development of these prompts\nwas an iterative process, incorporating feedback from prelim-\ninary analyses to refine the prompts for improved accuracy\nand relevance. Through this careful prompt engineering, we\ntailored the model’s output to align with the auditing criteria,\nthereby enhancing the effectiveness and precision of the access\naudits conducted in this study.\nTo illustrate, consider the following examples of engineered\nprompts:\nExample 1: \"Identify any access records\nthat deviate from the established access\npatterns for medical staff within the\ncardiology department.\"\nExample 2: \"Highlight all access logs\nwhere the number of normal range for\na single day.\"\nThese examples demonstrate how specific and targeted\nprompts guide the model in focusing on particular aspects of\nthe access logs that are critical for identifying potential unau-\nthorized accesses. The rationale behind such detailed prompt\nengineering lies in the necessity to make the model’s analysis\nas relevant and effective as possible, ensuring that it does not\nmerely process data but does so in a way that aligns with\nthe specific auditing objectives of this study. This approach\nensures that the model’s vast computational capabilities are\ndirected toward uncovering insights that are most pertinent\nto ensuring the privacy and security of patient data. The\niterative development and refinement of these prompts are\ncrucial for achieving the high degree of precision required for\neffective audit analysis in the complex domain of healthcare\ndata privacy.\nIV. R ESULTS\nThis section presents the findings from our study, offering\na comprehensive analysis of the performance of Mistral 8x7b\nin the context of medical record access audits. The results are\ndivided into quantitative analyses, which assess the model’s\nperformance through statistical metrics, and a qualitative anal-\nysis, which provides deeper insights into how the model has\nenhanced the efficacy of access audits.\nA. Quantitative Analysis: Performance Benchmarks\nOur first quantitative analysis focuses on the performance\nbenchmarks of Mistral 8x7b. We evaluated the model across\nseveral metrics, including accuracy, precision, recall, and F1\nscore, to gauge its effectiveness in identifying unauthorized\naccess incidents within the synthetic de-identified patient\nrecords.\nAs demonstrated in Table II, Mistral 8x7b significantly out-\nperforms the baseline model across all metrics, underscoring\nits superior capability in accurately detecting and analyzing\nunauthorized access events. This improvement is not merely\n4\nTABLE I: Main features, characteristics, and benefits of Mistral 8x7b for medical record access audit tasks\nFeature Benefit\nHigh Parameter Count Enhances model’s understanding and generation abilities\nMixture of Experts Allows specialized processing for diverse tasks\nScalable Architecture Suitable for large dataset analysis\nSubtle Pattern Recognition Capable of identifying nuanced anomalies\nFlexibility Adaptable to specific audit requirements\nMetric Accuracy Precision Recall F1 Score\nBaseline Model 0.85 0.80 0.75 0.77\nMistral 8x7b 0.95 0.92 0.90 0.91\nTABLE II: Performance comparison between the baseline\nmodel and Mistral 8x7b\nnumerical; it reflects a substantial advancement in the model’s\nability to discern between legitimate and unauthorized access\nto patient records, which is crucial for maintaining patient\nprivacy and ensuring regulatory compliance.\nThe increase in accuracy from 0.85 to 0.95, for instance,\nindicates that Mistral 8x7b correctly identifies 95% of access\nevents, a significant improvement over the baseline. Such high\naccuracy is essential in environments where the cost of errors\nis high, both in terms of patient trust and potential legal\nramifications. Precision’s rise to 0.92 from 0.80 suggests that\nwhen Mistral 8x7b flags an access event as unauthorized, it is\nhighly likely to be correct, minimizing the risk of disrupt-\ning legitimate clinical workflows due to false alarms. The\nimprovement in recall, from 0.75 to 0.90, ensures that fewer\nunauthorized accesses go undetected, bolstering the security of\npatient data. Finally, the F1 score’s increase to 0.91 reflects the\nmodel’s balanced strength in both precision and recall, crucial\nfor a nuanced task like access auditing where both identifying\ntrue positives and minimizing false positives are vital.\nThese results outline the importance of selecting a high-\nperforming model like Mistral 8x7b for the task of auditing\naccess to medical records. The capabilities of Mistral 8x7b to\ndeliver nuanced insights into access patterns directly contribute\nto enhancing the security and privacy of patient information.\nThe implications of such performance gains are profound,\noffering healthcare organizations a powerful tool to combat\nunauthorized access and ensuring that patient data remains\nsecure in an increasingly digital age.\nB. Quantitative Analysis: Computational Efficiency\nThe second aspect of our quantitative analysis examines the\ncomputational efficiency of Mistral 8x7b, particularly focusing\non its processing speed and resource utilization compared\nto traditional access audit methods. Utilizing the ‘pgfplots‘\nlibrary, we present a bar chart that compares the processing\ntimes and resource utilization between Mistral 8x7b and\ntraditional methods.\nOur findings, illustrated in Figure 1, outline Mistral 8x7b’s\nsubstantial efficiency gains over traditional audit methods.\nNotably, Mistral 8x7b demonstrates a reduction in processing\ntime by approximately 42% and a decrease in resource uti-\nlization by 40%. This marked improvement in computational\nProcessing Time Resource Utilization\n20\n40\n60\n80\n100\n82\n51\n33 30\nTime in Seconds / Resource Utilization (%)\nTraditional Methods Mistral 8x7b\nFig. 1: Comparison of processing time and resource utilizatio\nefficiency can be attributed to the model’s optimized architec-\nture, which enables rapid processing of complex datasets with\na more efficient use of\nC. Qualitative Analysis\nBeyond the measurable performance improvements, our\nqualitative analysis delves into the practical impacts of imple-\nmenting Mistral 8x7b in the audit process. Through a series of\ncase studies and real-world scenarios, we observed a marked\nenhancement in audit efficacy.\n• Case Study 1: An instance where Mistral 8x7b identi-\nfied a complex pattern of unauthorized access that was\noverlooked by traditional audit methods, leading to early\nintervention and prevention of potential data breaches.\n• Case Study 2: An example of how the model’s nuanced\nunderstanding of access patterns facilitated the differenti-\nation between legitimate and suspicious activities, thereby\nreducing false positives and focusing investigative efforts\nwhere they were most needed.\nThese case studies exemplify how Mistral 8x7b’s ad-\nvanced analytical capabilities translate into tangible benefits\nfor healthcare organizations, improving not only the efficiency\nbut also the effectiveness of access audits. Through its ability\nto discern intricate patterns and provide actionable insights,\nMistral 8x7b represents a significant advancement in the field\nof healthcare data security.\n5\nV. D ISCUSSION\nThis section delves into the interpretation of the results,\ntheir broader implications for the field of healthcare privacy\nand AI ethics, and outlines the study’s limitations and potential\nbiases. Furthermore, it suggests directions for future research,\nincluding potential improvements to the model.\nA. Implications for Healthcare Privacy\nThe findings from this study outline the substantial potential\nof Large Language Models (LLMs) like Mistral 8x7b to en-\nhance the privacy and security of healthcare data. The superior\nperformance of Mistral 8x7b in detecting unauthorized access\nand its computational efficiency could revolutionize healthcare\ndata management practices. By enabling more accurate and\nefficient audits, healthcare providers can significantly reduce\nthe risk of data breaches, ensuring the confidentiality and\nintegrity of patient records. Moreover, the adoption of such\nadvanced AI tools aligns with the increasing digitization of\nhealthcare and the growing demand for robust data protection\nmeasures. This shift towards AI-assisted audits could set a new\nstandard in healthcare privacy, encouraging the development\nof policies and regulations that reflect the capabilities and\npotential of modern AI technologies.\nB. Implications for AI Ethics\nThe application of LLMs in sensitive areas such as health-\ncare data audits raises important questions regarding AI ethics.\nWhile the benefits of improved privacy and security are\nclear, there is a need to consider the ethical implications\nof AI decisions, especially in cases of false positives or\nnegatives in unauthorized access detection. The transparency\nof AI processes, the accountability for decisions made by\nAI systems, and the privacy of individuals are paramount\nconcerns. Ensuring that AI systems like Mistral 8x7b operate\nwithin ethical guidelines is crucial for maintaining public trust\nin AI applications within healthcare. This study highlights\nthe importance of integrating ethical considerations into the\ndevelopment and deployment of AI technologies, ensuring\nthey are designed and used responsibly.\nC. Potential Biases in the Model\nThe potential for inherent biases in AI models, including\nMistral 8x7b, poses a significant challenge. Biases in training\ndata can lead to skewed outcomes, affecting the model’s\nfairness and accuracy in detecting unauthorized access across\ndifferent patient demographics. Identifying and mitigating\nthese biases is crucial for ensuring that AI-assisted audits con-\ntribute positively to healthcare privacy without inadvertently\nperpetuating inequalities. Future iterations of this research\nshould focus on examining and addressing the sources of bias\nwithin AI models, fostering the development of more equitable\nAI solutions for healthcare data security.\nD. Potential Improvements to the Model\nFuture iterations of models like Mistral 8x7b could benefit\nfrom several improvements. Enhancing the model’s ability to\nhandle diverse data formats and languages would significantly\nbroaden its applicability. Incorporating more sophisticated\nmechanisms for detecting subtle and sophisticated patterns\nof unauthorized access could further improve its effective-\nness. Additionally, developing more transparent AI systems\nthat allow for easier interpretation of their decision-making\nprocesses would address ethical concerns and increase trust\namong healthcare professionals. The integration of continuous\nlearning capabilities to adapt to evolving access patterns and\nthreats could ensure that the model remains effective over time.\nE. Limitations of the Study\nDespite its contributions, this study has limitations that war-\nrant consideration. The use of synthetic de-identified patient\nrecords, while eliminating privacy risks, may not fully repli-\ncate the complexity of real-world healthcare data, potentially\nimpacting the generalizability of the findings. Additionally, the\nperformance of the Mistral 8x7b model, though impressive,\nwas evaluated within a controlled experimental setup, and its\neffectiveness in live healthcare environments remains to be\ntested. The study also focused exclusively on the English\nlanguage, which may limit its applicability in multilingual\ncontexts. These limitations highlight the need for further\nresearch to validate and extend the findings of this study in\nmore diverse and realistic settings.\nF . Future Research Directions\nThe promising results of this study open several avenues for\nfuture research. Exploring the applicability of Mistral 8x7b\nand similar LLMs in real-world healthcare settings would\nprovide valuable insights into their practical utility and areas\nfor improvement. Additionally, expanding the study to include\nmultilingual datasets could enhance the model’s inclusivity\nand applicability in global healthcare contexts. Investigating\nthe integration of ethical decision-making frameworks into\nAI models could further align their operation with societal\nvalues and healthcare standards. Lastly, ongoing research\ninto reducing biases and improving the interpretability of AI\ndecisions is essential for advancing the field responsibly.\nVI. C ONCLUSION\nThis study has demonstrated the significant potential of\nemploying Large Language Models, specifically Mistral 8x7b,\nin the auditing of access to medical records. Through a\nrigorous analysis involving both quantitative and qualitative\nmethodologies, we have established that Mistral 8x7b outper-\nforms traditional audit methods in accuracy, precision, recall,\nand F1 score, while also offering substantial improvements in\ncomputational efficiency. These advancements are crucial for\nenhancing the privacy and security of patient data in healthcare\nsystems, offering a more reliable and efficient means of\ndetecting unauthorized access.\nThe implications of this research extend beyond the im-\nmediate context of healthcare data management, touching\n6\nupon broader issues of AI ethics and the responsible use of\ntechnology in sensitive areas. By highlighting the model’s\ncapabilities and its potential impact, this study contributes\nvaluable insights into the ongoing discourse on leveraging\nAI for the betterment of societal infrastructure, particularly\nin sectors as critical as healthcare.\nHowever, the study also acknowledges its limitations and\nthe need for further research, especially in real-world settings\nand across diverse linguistic and cultural landscapes. Future\nwork aimed at addressing these gaps, improving the model’s\nadaptability, and ensuring its ethical application, will be vital\nin realizing the full potential of AI in healthcare data privacy\nand beyond. The findings from this study outline the transfor-\nmative possibilities that advanced AI models like Mistral 8x7b\nhold for the field of healthcare data security. As we continue\nto navigate the complexities of digital privacy, the judicious\napplication of such technologies will be pivotal in safeguarding\npatient information against ever-evolving threats.\nREFERENCES\n[1] J. B. Awotunde, R. G. Jimoh, S. O. Folorunso, E. A. Adeniyi, K. M.\nAbiodun, and O. O. Banjo, “Privacy and security concerns in iot-\nbased healthcare systems,” in The fusion of internet of things, artificial\nintelligence, and cloud computing in health care . Springer, 2021, pp.\n105–134.\n[2] R. Nowrozy, K. Ahmed, A. Kayes, H. Wang, and T. R. McIntosh,\n“Privacy preservation of electronic health records in the modern era:\nA systematic survey,” ACM Computing Surveys , 2024.\n[3] R. Agrawal and S. Prabakaran, “Big data in digital healthcare: lessons\nlearnt and recommendations for general practice,” Heredity, vol. 124,\nno. 4, pp. 525–534, 2020.\n[4] M. Ozturk, A. Demir, Z. Arslan, and O. Caliskan, “Dynamic behavioural\nanalysis of privacy-breaching and data theft ransomware,” 2024.\n[5] R. Yang, T. F. Tan, W. Lu, A. J. Thirunavukarasu, D. S. W. Ting,\nand N. Liu, “Large language models in health care: Development,\napplications, and challenges,” Health Care Science , vol. 2, no. 4, pp.\n255–263, 2023.\n[6] S. Pramanik, “Ai-powered hospital accounting: Towards sound financial\nmanagement,” in Exploring Global FinTech Advancement and Applica-\ntions. IGI Global, 2024, pp. 121–142.\n[7] S. Singha and R. Singha, “Protecting data and privacy: cloud-based so-\nlutions for intelligent transportation applications,” Scalable computing:\npractice and experience , vol. 24, no. 3, pp. 257–276, 2023.\n[8] H. M. M. AlNaaji, “Automating unauthorized access attempts detection\nand handling using robotic process automation,” Ph.D. dissertation,\nPrincess Sumaya University for Technology (Jordan), 2022.\n[9] J. De Andr ´es and P. Lorca, “On the impact of smart contracts on\nauditing.” International Journal of Digital Accounting Research, vol. 21,\n2021.\n[10] M. L. Green, “Employees breaking bad with technology: An exploratory\nanalysis of human factors that drive cyberspace insider threats,” Ph.D.\ndissertation, University of South Florida, 2021.\n[11] E. Brion, “Deep learning for organ segmentation in radiotherapy:\nfederated learning, contour propagation, and domain adaptation,” Ph.D.\ndissertation, PhD thesis, Universit ´e catholique de Louvain, 2020.\n[12] G. Thirumurugan, Blockchain technology in healthcare: applications of\nblockchain. Gunasekaran Thirumurugan, 2020.\n[13] G. Wang, “Sok: Applying blockchain technology in industrial internet\nof things,” Cryptology ePrint Archive , 2021.\n[14] H. Jennath, V . Anoop, and S. Asharaf, “Blockchain for healthcare:\nsecuring patient data and enabling trusted artificial intelligence,” 2020.\n[15] P. Moghaddam, “A framework for secure logging and analytics in\nprecision healthcare cloud-based services,” Ph.D. dissertation, 2022.\n[16] I. Shuayb, Shuayb, and Luby, Inclusive university built environments .\nSpringer, 2020.\n[17] V . V . Estrela, M. A. de Jesus, A. C. Intorne, K. K. Batista, A. Deshpande,\nF. Shi, A. A. Khan, and L. P. Oliveira, “Blockchain technology enabling\nbetter services in the healthcare domain,” in Intelligent Healthcare\nSystems. CRC Press, pp. 135–158.\n[18] I. Farah, G. Lalli, D. Baker, and A. Schumacher, “A global omics data\nsharing and analytics marketplace: case study of a rapid data covid-19\npandemic response platform,” medRxiv, pp. 2020–09, 2020.\n[19] A. Othman, “Information security management for cyber security chal-\nlenges in smart cities security and privacy,” Ph.D. dissertation, The\nBritish University in Dubai, 2022.\n[20] M. Goto, “Collective professional role identity in the age of artificial\nintelligence,” Journal of Professions and Organization, vol. 8, no. 1, pp.\n86–107, 2021.\n[21] R. A. Omar, “Ai, predictive models and medical records: A dangerous\ndecision for healthcare privacy and restoring the sacred trust of patient\nconfidentiality,” Quinnipiac Health LJ , vol. 24, p. 459, 2020.\n[22] C. Stach, C. Gritti, J. Br ¨acker, M. Behringer, and B. Mitschang,\n“Protecting sensitive data in the information age: State of the art and\nfuture prospects,” Future Internet, vol. 14, no. 11, p. 302, 2022.\n[23] R. Gupta, S. Tanwar, S. Tyagi, and N. Kumar, “Machine learning models\nfor secure data analytics: A taxonomy and threat model,” Computer\nCommunications, vol. 153, pp. 406–440, 2020.\n[24] S. S. Hameed, W. H. Hassan, L. A. Latiff, and F. Ghabban, “A systematic\nreview of security and privacy issues in the internet of medical things; the\nrole of machine learning approaches,” PeerJ Computer Science , vol. 7,\np. e414, 2021.\n[25] L. A. Koory, “Evaluating the effectiveness of ensemble machine learning\napproaches for detecting healthcare insider threats,” Ph.D. dissertation,\nUniversity of South Alabama, 2023.\n[26] Y . Chen and P. Esmaeilzadeh, “Generative ai in medical practice: In-\ndepth exploration of privacy and security challenges,”Journal of Medical\nInternet Research, vol. 26, p. e53008, 2024.\n[27] A. I. Newaz, A. K. Sikder, M. A. Rahman, and A. S. Uluagac, “A survey\non security and privacy issues in modern healthcare systems: Attacks\nand defenses,” ACM Transactions on Computing for Healthcare , vol. 2,\nno. 3, pp. 1–44, 2021.\n[28] A. Qayyum, J. Qadir, M. Bilal, and A. Al-Fuqaha, “Secure and robust\nmachine learning for healthcare: A survey,” IEEE Reviews in Biomedical\nEngineering, vol. 14, pp. 156–180, 2020.\n[29] D. N. Jones, “Understanding and decreasing security breaches in\nthe healthcare industry: A qualitative case study exploring network-\nconnected medical devices in a large hospital,” Ph.D. dissertation,\nNorthcentral University, 2022.\n[30] D. Unal, S. Bennbaia, and F. O. Catak, “Machine learning for the\nsecurity of healthcare systems based on internet of things and edge\ncomputing,” in Cybersecurity and Cognitive Science . Elsevier, 2022,\npp. 299–320.\n[31] W. Hurst, A. Boddy, M. Merabti, and N. Shone, “Patient privacy\nviolation detection in healthcare critical infrastructures: an investigation\nusing density-based benchmarking,” Future Internet, vol. 12, no. 6, p.\n100, 2020.\n[32] B. A. Ojokoh, B. Aribisala, O. A. Sarumi, A. J. Gabriel, O. Omisore,\nA. E. Taiwo, T. Igbe, U. M. Chukwuocha, T. Yusuf, A. Afolayan et al.,\n“Contact tracing strategies for covid-19 prevention and containment: A\nscoping review,”Big data and cognitive computing, vol. 6, no. 4, p. 111,\n2022.\n[33] J. Morley, C. C. Machado, C. Burr, J. Cowls, I. Joshi, M. Taddeo, and\nL. Floridi, “The ethics of ai in health care: a mapping review,” Social\nScience & Medicine , vol. 260, p. 113172, 2020.\n[34] F. Li, N. Ruijs, and Y . Lu, “Ethics & ai: A systematic review on ethical\nconcerns and related strategies for designing with ai in healthcare,” Ai,\nvol. 4, no. 1, pp. 28–53, 2022.",
  "topic": "Audit",
  "concepts": [
    {
      "name": "Audit",
      "score": 0.7500051259994507
    },
    {
      "name": "Computer science",
      "score": 0.4989306926727295
    },
    {
      "name": "Data science",
      "score": 0.3236965537071228
    },
    {
      "name": "Business",
      "score": 0.3064175844192505
    },
    {
      "name": "Accounting",
      "score": 0.20839548110961914
    }
  ],
  "institutions": []
}