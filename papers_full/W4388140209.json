{
  "title": "Development of meta-prompts for Large Language Models to screen titles and abstracts for diagnostic test accuracy reviews",
  "url": "https://openalex.org/W4388140209",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2117040864",
      "name": "Yuki Kataoka",
      "affiliations": [
        "Santen (Japan)",
        "Kyoto University",
        "Scientific Research WorkS Peer Support Group",
        "Kyoto Min-iren Asukai Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2097281339",
      "name": "Ryuhei So",
      "affiliations": [
        "Scientific Research WorkS Peer Support Group",
        "Okayama Psychiatric Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A1972273353",
      "name": "Masahiro Banno",
      "affiliations": [
        "Scientific Research WorkS Peer Support Group",
        "Nagoya University"
      ]
    },
    {
      "id": "https://openalex.org/A2035419361",
      "name": "Junji Kumasawa",
      "affiliations": [
        "Kyoto University",
        "Sakai Municipal Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2258349809",
      "name": "Hidehiro Someko",
      "affiliations": [
        "Asahi Hospital",
        "Scientific Research WorkS Peer Support Group"
      ]
    },
    {
      "id": "https://openalex.org/A2142765945",
      "name": "Shunsuke Taito",
      "affiliations": [
        "Hiroshima University Hospital",
        "Scientific Research WorkS Peer Support Group"
      ]
    },
    {
      "id": "https://openalex.org/A2170182670",
      "name": "Teruhiko Terasawa",
      "affiliations": [
        "Fujita Health University"
      ]
    },
    {
      "id": "https://openalex.org/A2206083003",
      "name": "Yasushi Tsujimoto",
      "affiliations": [
        "Kyoto University",
        "Scientific Research WorkS Peer Support Group"
      ]
    },
    {
      "id": "https://openalex.org/A1926177472",
      "name": "Yusuke Tsutsumi",
      "affiliations": [
        "Kyoto University",
        "Scientific Research WorkS Peer Support Group",
        "National Hospital Organization Mito Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2137326515",
      "name": "Yoshitaka Wada",
      "affiliations": [
        "Scientific Research WorkS Peer Support Group",
        "Fujita Health University"
      ]
    },
    {
      "id": "https://openalex.org/A2141614136",
      "name": "Toshi A. Furukawa",
      "affiliations": [
        "Kyoto University"
      ]
    },
    {
      "id": "https://openalex.org/A2117040864",
      "name": "Yuki Kataoka",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097281339",
      "name": "Ryuhei So",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1972273353",
      "name": "Masahiro Banno",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2035419361",
      "name": "Junji Kumasawa",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2258349809",
      "name": "Hidehiro Someko",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2142765945",
      "name": "Shunsuke Taito",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2170182670",
      "name": "Teruhiko Terasawa",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2206083003",
      "name": "Yasushi Tsujimoto",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1926177472",
      "name": "Yusuke Tsutsumi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2137326515",
      "name": "Yoshitaka Wada",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2141614136",
      "name": "Toshi A. Furukawa",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3111278950",
    "https://openalex.org/W3014512586",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4381308085",
    "https://openalex.org/W4387617694",
    "https://openalex.org/W4385356790",
    "https://openalex.org/W2554140915",
    "https://openalex.org/W2078271269",
    "https://openalex.org/W2758745155",
    "https://openalex.org/W4310894732",
    "https://openalex.org/W3090625318",
    "https://openalex.org/W3118501777",
    "https://openalex.org/W4385681252",
    "https://openalex.org/W4381480578",
    "https://openalex.org/W4229658977",
    "https://openalex.org/W1999236124",
    "https://openalex.org/W2134007960",
    "https://openalex.org/W2215854794",
    "https://openalex.org/W2893300601",
    "https://openalex.org/W2522333602"
  ],
  "abstract": "Abstract Systematic reviews (SRs) are a critical component of evidence-based medicine, but the process of screening titles and abstracts is time-consuming. This study aimed to develop and externally validate a method using large language models to classify abstracts for diagnostic test accuracy (DTA) systematic reviews, thereby reducing the human workload. We used a previously collected dataset for developing DTA abstract classifiers and applied prompt engineering. We developed an optimized meta-prompt for Generative Pre-trained Transformer (GPT)-3.5-turbo and GPT-4 to classify abstracts. In the external validation dataset 1, the prompt with GPT-3.5 turbo showed a sensitivity of 0.988, and a specificity of 0.298. GPT-4 showed a sensitivity of 0.982, and a specificity of 0.677. In the external validation dataset 2, GPT-3.5 turbo showed a sensitivity of 0.919, and a specificity of 0.434. GPT-4 showed a sensitivity of 0.806, and a specificity of 0.740. If we included eligible studies from among the references of the identified studies, GPT-3.5 turbo had no critical misses, while GPT-4 had some misses. Our study indicates that GPT-3.5 turbo can be effectively used to classify abstracts for DTA systematic reviews. Further studies using other dataset are warranted to confirm our results. Additionally, we encourage the use of our framework and publicly available dataset for further exploration of more effective classifiers using other LLMs and prompts ( https://github.com/youkiti/ARE/ ). Hightlights What is already known - Title and abstract screening in systematic reviews (SRs) consumes significant time. - Several attempts using machine learning to reduce this process in diagnostic test accuracy (DTA) SRs exist, but they have not yielded positive results in external validation. What is new - We aimed to develop and externally validate optimized meta-prompt for GPT-3.5-turbo and GPT-4 to classify abstracts for DTA SRs. - Through an iterative approach across three training datasets, an optimal meta-prompt capable of identifying DTA studies with remarkable sensitivity and specificity was developed. - The accuracy reproduced in the external validation datasets. Potential Impact for Readers - The developed meta-prompt can lessen the need for humans to read abstracts for DTA SRs, saving significant time and resources.",
  "full_text": "1 \n \nTitle:  1 \nDevelopment of meta-prompts for Large Language Models to screen titles and abstracts for 2 \ndiagnostic test accuracy reviews 3 \n 4 \nAuthors: 5 \nYuki Kataoka, Ryuhei So, Masahiro Banno, Junji Kumasawa, Hidehiro Someko, Shunsuke 6 \nTaito, Teruhiko Terasawa, Yasushi Tsujimoto, Yusuke Tsutsumi, Yoshitaka Wada, Toshi 7 \nA. Furukawa 8 \n 9 \nYuki Kataoka 10 \nORCID 0000-0001-7982-5213 11 \nDepartment of Internal Medicine, Kyoto Min-iren Asukai Hospital, Kyoto, Japan 12 \nScientific Research Works Peer Support Group (SRWS-PSG), Osaka, Japan 13 \nSection of Clinical Epidemiology, Department of Community Medicine, Kyoto University 14 \nGraduate School of Medicine, Kyoto, Japan 15 \nDepartment of Healthcare Epidemiology, Kyoto University Graduate School of Medicine / 16 \nSchool of Public Health, Kyoto, Japan 17 \n 18 \nRyuhei So 19 \nORCID 0002-9838-350X 20 \nDepartment of Psychiatry, Okayama Psychiatric Medical Center, Okayama, Japan 21 \nCureApp, Inc., Tokyo, Japan 22 \nScientific Research WorkS Peer Support Group (SRWS-PSG), Osaka, Japan 23 \n 24 \nMasahiro Banno 25 \nORCID 0002-2539-1031 26 \nDepartment of Psychiatry, Seichiryo Hospital, Nagoya, Japan 27 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n2 \n \nDepartment of Psychiatry, Nagoya University Graduate School of Medicine, Nagoya, Japan 1 \nScientific Research WorkS Peer Support Group (SRWS-PSG), Osaka, Japan 2 \n 3 \nJunji Kumasawa 4 \nORCID 0000-0003-4619-945X 5 \nHuman Health Sciences, Kyoto University Graduate School of Medicine 6 \nDepartment of Critical Care Medicine, Sakai City Medical Center 7 \n 8 \nHidehiro Someko 9 \nORCID 0000-0002-7195-2055 10 \nDepartment of General Internal Medicine, Asahi General Hospital, I 1326, Asahi, Chiba, 11 \n289-2511, Japan 12 \nScientific Research WorkS Peer Support Group (SRWS-PSG), Osaka, Japan 13 \n 14 \nShunsuke Taito 15 \nORCID 0000-0003-1218-4225 16 \nDivision of Rehabilitation, Department of Clinical Practice and Support, Hiroshima 17 \nUniversity Hospital, Kasumi 1-2-3, Minami-ku, Hiroshima, 734-8551, Japan 18 \nScientific Research Works Peer Support Group (SRWS-PSG), Osaka, Japan 19 \n 20 \nTeruhiko Terasawa 21 \nSection of General Internal Medicine, Department of Emergency and General Internal 22 \nMedicine, Fujita Health University School of Medicine, Toyoake, Aichi, Japan 23 \n 24 \nYasushi Tsujimoto 25 \nORCID 0002-7214-5589 26 \nOku medical clinic, Osaka, Japan 27 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n3 \n \nDepartment of Health Promotion and Human Behavior, Kyoto University Graduate School 1 \nof Medicine / School of Public Health, Kyoto University, Kyoto, Japan. 2 \nScientific Research WorkS Peer Support Group (SRWS-PSG), Osaka, Japan 3 \n 4 \nYusuke Tsutsumi 5 \nORCID 0002-9160-0241 6 \nDepartment of Emergency Medicine, National Hospital Organization Mito Medical Center, 7 \n280 Sakuranosato Ibarakimachi Higashiibarakigun, Ibaraki, 311-3117, Japan 8 \nHuman Health Science, Kyoto University Graduate School of Medicine, Kyoto, Japan 9 \nScientific Research WorkS Peer Support Group (SRWS-PSG), Osaka, Japan 10 \n 11 \nYoshitaka Wada 12 \nORCID 0003-2191-3629 13 \nDepartment of Rehabilitation Medicine I, School of Medicine, Fujita Health University, 14 \nAichi, Japan 15 \nScientific Research WorkS Peer Support Group (SRWS-PSG), Osaka, Japan 16 \n 17 \nToshi A. Furukawa 18 \nORCID 0000-0003-2159-3776 19 \nDepartment of Health Promotion and Human Behavior, Kyoto University Graduate School 20 \nof Medicine/School of Public Health, Kyoto, Japan 21 \n 22 \nCorresponding author: 23 \nToshi A. Furukawa 24 \nORCID 0000-0003-2159-3776 25 \nDepartment of Health Promotion and Human Behavior, Kyoto University Graduate School 26 \nof Medicine/School of Public Health, Kyoto, Japan 27 \nPhone: +81-75-753-9491 28 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n4 \n \nFax: +81-75-753-4641 1 \nEmail: furukawa@kuhp.kyoto-u.ac.jp 2 \n 3 \nAcknowledgment 4 \nThe authors underwent editing using GPT-0614. All authors reviewed and edited the final 5 \nmanuscript. The responsibility for the content of this article rests solely with the authors. 6 \n 7 \nFunding 8 \nThe application programming interface fee was supported by a JSPS Grant-in-Aid for 9 \nScientific Research (Grant Number 22K15664) provided to YK. The funder played no role 10 \nin the study design, data collection and analysis, publication decisions, or manuscript 11 \npreparation. 12 \n 13 \nConflict of interest 14 \nYuki Kataoka: none known 15 \nRyuhei So: grants from Osake-no-Kagaku Foundation, speaker’s honoraria from Otsuka 16 \nPharmaceutical Co., Ltd., Nippon Shinyaku Co., Ltd., and Takeda Pharmaceutical Co., Ltd., 17 \noutside the submitted work. 18 \nMasahiro Banno: none known 19 \nJunji Kumasawa: none known 20 \nHidehiro Someko: none known 21 \nShunsuke Taito: none known 22 \nTeruhiko Terasawa: none known 23 \nYasushi Tsujimoto: none known 24 \nYusuke Tsutsumi: none known 25 \nYoshitaka Wada: none known 26 \nToshi A. Furukawa: TAF reports personal fees from DT Axis, Kyoto University Original, 27 \nMSD, SONY and UpToDate, and a grant from Shionogi, outside the submitted work; In 28 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n5 \n \naddition, TAF has patents 2020-548587 and 2022-082495 pending, and intellectual 1 \nproperties for Kokoro-app licensed to Mitsubishi-Tanabe. 2 \n 3 \nAuthor Contributions:  4 \nYK had full access to all the data in the study and took responsibility for the integrity of the 5 \ndata and the accuracy of the data analysis. Study concept and design: YK, RS, MB, JK, ST, 6 \nTT, YT, YT, YW, and TAF. Acquisition of data: YK. Drafting of the manuscript: YK. All 7 \nauthors gave final approval of the version to be published and agreed to be accountable for 8 \nall aspects of this work. 9 \n 10 \nData Availability Statement: 11 \nThe data that support the findings of this study are openly available at 12 \n(https://github.com/youkiti/ARE/).  13 \n  14 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n6 \n \nHightlights 1 \nWhat is already known 2 \n- Title and abstract screening in systematic reviews (SRs) consumes significant time.  3 \n- Several attempts using machine learning to reduce this process in diagnostic test accuracy 4 \n(DTA) SRs exist, but they have not yielded positive results in external validation. 5 \n 6 \nWhat is new 7 \n- We aimed to develop and externally validate optimized meta-prompt for GPT-3.5-turbo 8 \nand GPT-4 to classify abstracts for DTA SRs.  9 \n- Through an iterative approach across three training datasets, an optimal meta-prompt 10 \ncapable of identifying DTA studies with remarkable sensitivity and specificity was 11 \ndeveloped. 12 \n- The accuracy reproduced in the external validation datasets. 13 \n 14 \nPotential Impact for Readers 15 \n- The developed meta-prompt can lessen the need for humans to read abstracts for DTA 16 \nSRs, saving significant time and resources. 17 \n  18 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n7 \n \nAbstract 1 \nSystematic reviews (SRs) are a critical component of evidence-based medicine, but the 2 \nprocess of screening titles and abstracts is time-consuming. This study aimed to develop 3 \nand externally validate a method using large language models to classify abstracts for 4 \ndiagnostic test accuracy (DTA) systematic reviews, thereby reducing the human workload. 5 \nWe used a previously collected dataset for developing DTA abstract classifiers and applied 6 \nprompt engineering. We developed an optimized meta-prompt for Generative Pre-trained 7 \nTransformer (GPT)-3.5-turbo and GPT-4 to classify abstracts. In the external validation 8 \ndataset 1, the prompt with GPT-3.5 turbo showed a sensitivity of 0.988, and a specificity of 9 \n0.298. GPT-4 showed a sensitivity of 0.982, and a specificity of 0.677. In the external 10 \nvalidation dataset 2, GPT-3.5 turbo showed a sensitivity of 0.919, and a specificity of 0.434. 11 \nGPT-4 showed a sensitivity of 0.806, and a specificity of 0.740. If we included eligible 12 \nstudies from among the references of the identified studies, GPT-3.5 turbo had no critical 13 \nmisses, while GPT-4 had some misses. Our study indicates that GPT-3.5 turbo can be 14 \neffectively used to classify abstracts for DTA systematic reviews. Further studies using 15 \nother dataset are warranted to confirm our results. Additionally, we encourage the use of 16 \nour framework and publicly available dataset for further exploration of more effective 17 \nclassifiers using other LLMs and prompts (https://github.com/youkiti/ARE/). 18 \n 19 \nKeywords: 20 \nSystematic review, Machine learning, Search filter, Diagnostic test accuracy, Large 21 \nlanguage models. 22 \n 23 \n 24 \nWord counts: 2612 words 25 \n  26 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n8 \n \n1. Introduction 1 \nTitle and abstract screening in systematic reviews (SRs) requires much time and efforts. 2 \nSeveral attempts using machine learning to facilitate this process exist (1,2). Some machine 3 \nlearning models succeeded in intervention and update SRs, but no cases in diagnostic test 4 \naccuracy (DTA) SRs. In our own previous study, we used the Bidirectional Encoder 5 \nRepresentations from Transformers (BERT), which was released in 2018 (3), to develop a 6 \nmodel to classify abstracts in DTA SRs. The results were unsatisfactory in the external 7 \nvalidation (4). 8 \nThe launch of Chat Generative Pre-trained Transformer (ChatGPT) in November 9 \n2022 has boosted the already high interest in large language models (LLMs) (5). LLMs are 10 \nmachine learning models specifically trained on text data to process and generate human-11 \nlike text (6). When applying LLMs, there are two techniques: fine tuning and prompt 12 \nengineering (7). Fine tuning involves training an existing LLM on a new dataset to improve 13 \nit for a specific task. While this technique is less expensive than creating a new LLM from 14 \nscratch, it still requires significant time and computational resources. Therefore, more 15 \nresearch efforts have been expended on prompt engineering (8–10). Prompt engineering 16 \nallows for better results from a LLM without additional training by adding what is known 17 \nas a meta-prompt—a task-specific instruction—in the input. We are aware of one 18 \napplication of prompt engineering to screen references for intervention reviews (11) so far. 19 \nHowever, the accuracy of LLM as a DTA abstract classifier remains uncertain. Our 20 \nstudy aimed to develop and externally validate optimized meta-prompts for GPT-3.5-turbo 21 \nand GPT-4 to classify abstracts for DTA SRs. GPT-3.5-turbo is a version of the GPT model 22 \ndeveloped by OpenAI. It powers the freely accessible ChatGPT. GPT-4 follows GPT-3.5-23 \nturbo as a more advanced model. 24 \n  25 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n9 \n \n2. Methods 1 \n2.1 Preparation of datasets 2 \nWe used the previously collected dataset for developing the DTA abstract classifier (11). 3 \nWe defined a DTA study as an original study that evaluated a test against a clinical 4 \nreference standard for humans (13). We classified multivariable diagnostic prediction 5 \nmodel studies as DTA studies, but prognostic prediction model studies, that measured 6 \npredictors and outcomes at different time points as non-DTA studies (14). We classified 7 \nmodeling studies, studies that assessed diagnostic training for medical professionals, and 8 \ncase series (e.g., studies without controls, such as following polymerase chain reaction 9 \nresults of specific patients) as non-DTA studies.  10 \nWe retrieved various DTA systematic reviews (SRs) from the EPPI-Centre COVID-11 \n19: a living systematic map of the evidence (12) . These systematic reviews addressed 12 \nmalignancy, gastrointestinal disorders, respiratory disorders, emergency care, neurology, 13 \nand infectious disease. 14 \nThe dataset consisted of Microsoft Excel files, including serial numbers, titles, 15 \nabstracts, and binary reference labels of true (DTA) and false (non-DTA) values. As the 16 \nreference standard, we used the abstract lists that required manual full-text review when the 17 \noriginal DTA SR was conducted. As an additional analysis, we used the included articles 18 \nafter the full-text review as the reference standard in the external validation dataset 2. We 19 \nused titles and abstracts as predictors. 20 \nFrom 67,979 abstracts used in our previous study (4), which contained 1,575 DTA 21 \nstudy abstracts, we conducted stratified sampling for the train dataset 1 (n = 100, 25 DTA 22 \nabstracts, and 75 non-DTA abstracts). (Figure 1) In addition, we randomly sampled the 23 \ntrain dataset 2 (n = 500), and the train dataset 3 (n = 1,000) from among the 1575 DTA 24 \nstudies. These three datasets were used for the development of a meta-prompt to select 25 \nDTA abstracts. We limited the number of abstracts in the train datasets to decrease data 26 \nprocessing time and cost. For external validation of the meta-prompt, we used the same 27 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n10 \n \ndataset including 7,721 abstracts, including 166 DTA abstracts as used in the previous 1 \nstudy (external validation dataset 1) (15). In addition, we used another dataset including 2 \n1023 abstracts and 124 DTA abstracts from a DTA SR (external validation dataset 2) (16).  3 \n 4 \n2.2 Overview of four-step approach for abstract screening enhancement  5 \nIn this study, we undertook a four-step approach for abstract review enhancement of 6 \ndiagnostic test accuracy (DTA) abstracts. First, we began by developing a meta-prompt 7 \nusing the Azure OpenAI application programming interface (API), optimizing it for 8 \naccurate labeling of DTA abstracts (17). Second, we explored the optimal temperature 9 \nsetting for the meta-prompt to achieve the desired outputs. The temperature is the parameter 10 \nthat controls the randomness of the GPT (15). Third, we conducted an external validation 11 \nusing two datasets. Fourthly, we assessed the reproducibility of the model's outputs and 12 \niterative accuracy enhancement (Figure 2). 13 \n 14 \n2.3 Step 1: Development of a meta-prompt for selecting DTA abstracts 15 \nWe used Azure OpenAI API which provides access to GPT-3.5 turbo and GPT-4. The input 16 \nincluded a meta-prompt, a title and an abstract, and the temperature parameter. The meta-17 \nprompt was to label whether the inputted abstracts were DTA abstracts or not. One title-18 \nand-abstract was retrieved from each line of dataset. The temperature is the parameter that 19 \ncontrols the randomness of the GPT (18). The temperature has a valid range from 0.0 20 \ninclusive to 2.0 exclusive. Higher values will make output more random while lower values 21 \nwill make results more focused and deterministic. We set the temperature as 0 for the 22 \naccurate labeling. The output was a label of true or false. We used GPT-3.5 turbo to 23 \ndevelop a meta-prompt (Figure 2 and 3). 24 \nFrom the predicted label, we calculated the sensitivity and the specificity and the 25 \nproportion of error as performance measures. Then we asked the GPT-3.5 turbo to improve 26 \nthe meta-prompt (Figure 2). The improvement meta-prompt was as follows:  27 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n11 \n \nPlease become my prompt engineer. Your goal is to help me create the best prompts 1 \nfor systematic review of diagnostic test accuracy. The prompts will be used by you, 2 \nChatGPT. Please rewrite inputted meta-prompt to achieve sensitivity > 0.9 and 3 \nspecificity > 0.4 and error proportion < 0.1. 4 \nWe selected  the above cutoffs based on a previous study that investigated the 5 \nsearch filters for systematic reviews (19). The error meant that when a response other than 6 \ntrue or false occurs three times in an abstract, which included communication errors. 7 \nFirstly, we ran the experiment 10 times with the train dataset 1 and chose the best 8 \none. Secondly, we ran the experiment 10 times with the train dataset 2 and chose the best 9 \none. Thirdly, we tested with the train dataset 3.  10 \n 11 \n2.4 Step 2: Explore the optimal temperature 12 \nAs mentioned above, the temperature was set to 0 in the Step 1. To explore the optimal 13 \ntemperature, we used the optimal meta-prompt and changed temperature as 0,0.4,0.8, 1.2, 14 \nand 1.6. We evaluated the results with sensitivity, specificity, and error proportion (Figure 15 \n2). 16 \n 17 \n2.5 Step 3: External validation 18 \nFor the external validation, we used the optimal meta-prompt developed in the step 1 with 19 \nthe external validation dataset 1 and 2. We used GPT-3.5 turbo and GPT-4. We evaluated 20 \nthe results with sensitivity, specificity, error proportion, and number needed to screen 21 \n(Figure 2). Number needed to screen is the number to identify 1 reference to undergo full-22 \ntext screening during title and abstract screening (20). For the external validation dataset 2, 23 \nwe assessed the accuracy using abstracts deemed 'true' after a full-text review by human 24 \nexperts as the reference standard (RS2). Additionally, we examined the characteristics of 25 \nabstracts that turned out to be false negatives for the RS2. 26 \n 27 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n12 \n \n2.6 Step 4: Check for reproducibility 1 \nLarge language models like GPT have inherent non-determinism (21,22). Outputs remain 2 \nnon-deterministic, even at a temperature of 0 (23). Hence, we checked the reproducibility 3 \nof GPT-3.5 turbo and GPT-4 using the same meta-prompt ten times for the external 4 \nvalidation dataset 1 and 2 (Figure 2).  5 \nFor the external validation dataset 2, we evaluated the performance enhancement 6 \nwhen combining results by considering an abstract as 'true' if it was deemed 'true' in at least 7 \none of the ten trials.  8 \n 9 \n2.7 Development environment 10 \nWe used Google Collaboratory, a Python-based data analysis and machine learning tool 11 \nthat can be executed in a web browser (24). We used the Azure OpenAI API version \"2023-12 \n07-01-preview\". We used \"gpt-35-turbo-0613\" as GPT-3.5 turbo, \"gpt4-0613\" as GPT-4. 13 \nOur code and datasets are made available at GitHub (https://github.com/youkiti/ARE/).  14 \n  15 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n13 \n \n3. Results \n3.1 Step 1: Development of a meta-prompt for selecting DTA abstracts \nWe developed the first meta-prompt and improved the meta-prompt ten times with the \ntraining dataset 1 (n = 100). Then selected the #8 prompt based on the balance of sensitivity \nand specificity (Table 1, Supplemental table 1).  \nUsing the #8 meta-prompt, we improved the meta-prompt with the training dataset 2 \n(n = 500) (Table 2). The #3 prompt achieved a sensitivity of 0.917, a specificity of 0.527, \nand an error proportion of 0.010. \nWe tested the #3 meta-prompt with the training dataset 3 (n = 1000). The prompt achieved \na sensitivity of 0.913, a specificity of 0.416, and an error proportion of 0.000. To enhance \nthe prompt, we omitted the numbers for the thresholds of sensitivity and specificity. The \nfinal meta-prompt was as follows:  \nPlease determine if an abstract is a Diagnostic Test Accuracy (DTA) study based on \nthe following criteria:  \n1. A DTA study evaluates a test against a clinical reference standard \nspecifically for humans, with very high sensitivity and reasonable specificity. \n2. Include multivariable diagnostic prediction model studies. \n3. Exclude the following:     \n- Prognostic prediction model studies where predictors and outcomes \nare measured at different time points.     \n- Modeling studies.     \n- Studies assessing diagnostic training for medical professionals.  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n14 \n \nReply with 'True' if the abstract is a DTA study or if there is insufficient information \nto judge (e.g., when only a title is available). Reply with 'False' if you are certain \nthat the abstract is not a DTA study. \nIn the training dataset 3, the prompt achieved a sensitivity of 0.938, a specificity of 0.514, \nand an error proportion of 0.010 (Table 3). \n \n3.2 Step 2: Explore the optimal temperature \nWe observed a decrease in sensitivity as the temperature increased (Table 3). \n \n3.3 Step 3: External validation \nFor the final meta-prompt tested on the external validation dataset 1, GPT-3.5 turbo showed \na sensitivity of 0.988, a specificity of 0.298, and an error rate of 0.008, while GPT-4 \nshowed a sensitivity of 0.982, a specificity of 0.677, and an error proportion of 0.008. For \nthe final meta-prompt tested on the external validation dataset 2, GPT-3.5 turbo showed a \nsensitivity of 0.919, a specificity of 0.434, and an error proportion of 0.005, while GPT-4 \nshowed a sensitivity of 0.806, a specificity of 0.740, and an error proportion of 0.008 \n(Table 4). \nOn the external validation dataset 1, the baseline number needed to screen was 46.5. \nThe number reduced to 33.3 with GPT-3.5 turbo, and to 16.0 with GPT-4. In external \nvalidation dataset 2, the number needed to screen reduced from 8.25 to 5.45 with GPT-3.5 \nturbo, and to 3.34 with GPT-4. \nWhen we used the included articles after the full-text review as the reference \nstandard (RS2), in the external validation dataset 2, GPT-3.5 turbo showed a sensitivity of \n0.963 and a specificity of 0.406, while GPT-4 showed a sensitivity of 0.889 and a \nspecificity of 0.689. In other words, GPT-3.5 missed one abstract from 27 abstracts \nincluded in the reviews and GPT-4 missed three abstracts. The one abstract that GPT-3.5 \nturbo missed (25) was referenced in another included article (26). Two of three abstracts \nthat GPT-4 missed were not detectable by citation search of included articles (27,28). \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n15 \n \n3.4 Step 4: Check for reproducibility \nWe observed no remarkable differences in sensitivity, specificity, and error proportion \nbetween GPT-4 and GPT-3.5 in both external validation datasets during the ten \nexperiments (Table 4 and 5).  \nAs a result of combining multiple evaluations for one abstract, we observed the \nminimal improvement in the external validation dataset 2 using GPT-3.5 turbo and GPT-4 \n(Table 6). \n \n4. Discussion \nWe developed and externally validated the meta-prompt to classify abstracts for new DTA \nsystematic reviews. Through an iterative approach across three training datasets, we \ndeveloped an optimal meta-prompt capable of identifying DTA studies with remarkable \nsensitivity and specificity. The temperature parameter, when set to 0, demonstrated the best \nperformance. In the external validation dataset 1, using the same meta-prompt, GPT-3.5 \nturbo and GPT-4 showed almost the same sensitivity and error proportion. In the external \nvalidation dataset 2, GPT-3.5 and GPT-4 showed worse sensitivity. However, combining \ncitation search, GPT-3.5 turbo had no substantive misses. GPT-4 had some misses. As a \nresult of the check for reproducibility, we observed no remarkable differences in results \nacross the 10 serial experiments. Combining multiple evaluations for one abstract did not \nnotably improve performance. \nOur results are better than in our previous study that used machine learning. In our \nresearch using the fine-tuned model of BERT, the sensitivity in the external validation set \nwas less than 0.4 (26). In this study, both GPT-3.5 turbo and GPT-4 achieved a sensitivity \nexceeding 0.96. The performance is equivalent to existing RCT search filters (19). GPT-3.5 \nturbo had similar or better sensitivity, while GPT-4 demonstrated better specificity. \nRegarding time and cost, as of October 2023, using GPT-3.5 turbo API on the fastest \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n16 \n \nsetting of S0 Standard Azure took 1 min 18 seconds to process 100 abstracts and 0.09 \ndollars cost. In contrast, GPT-4 API took 2 min 44 seconds and 1.7 dollars cost.  \nOur results indicate a lack of strict reproducibility in outputs of LLMs, even with \nzero temperature settings in binary labeling tasks. In other words, occasionally, LLMs \nproduce different outputs from the same input. However, the lack of reproducibility is the \nsame even when a human makes the abstract review. In fact, if the same person classifies \nabstracts one week later, the results do not necessarily match (29). Drawing parallels to \nepidemiological studies, it's worth noting that LLMs inherently involve measurement errors \n(30). The precise nature of the inconsistency of LLMs, be it systematic or random, remains \nunclear. To effectively assess the performance of LLMs, understanding the non-\ndeterministic nature will help address this issue. Reflecting on our research objectives, the \nvariability in judgment did not substantially affect the sensitivity.  \nWe position our study as a type of prompt engineering by the LLM itself. \nResearchers are exploring a framework to enhance meta-prompts by presenting specific \ntasks and meta-prompts and their scores to the LLM. Researchers have applied this \nframework to mathematical problems (31) and simple natural language processing tasks \n(32,33). In systematic reviews, the potential exists to implement appropriate prompt \nengineering using LLM for tasks where the dataset can provide correct answers. \nOur study has several limitations. Firstly, we have yet to validate our findings on \nother datasets. Future studies are warranted to test our results on alternative datasets to \nascertain the generalizability of our conclusions. Secondly, there remains an unanswered \nquestion regarding the efficacy of the meta-prompts in relation to other LLMs. The best \nmeta-prompts might be different for each LLM (34). \"Closed” OpenAI LLMs can only be \naccessed through the API and cannot be downloaded to run on a researchers’ computer. \nTherefore, there is a risk they may change or even become inaccessible in the future. \nResearchers should have alternative open LLMs that can be run on their own server. Lastly, \nour current study has scoped its focus predominantly on the study design. For abstract \nreview enhancement, further studies are warranted to determine if a meta-prompt \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n17 \n \nconsidering other DTA study elements, such as participants and index tests, can reduce the \nnumber needed to screen in new reviews (11). \n5. Conclusions \nIn conclusion, we developed and externally validated the meta-prompt to reduce the burden \nfor humans to read abstracts when conducting DTA SRs. Considering situations where cost \nand sensitivity are prioritized, we recommend systematic reviewers to use GPT-3.5 turbo \nand our meta-prompt for title and abstract screening of DTA reviews. Further studies using \nother dataset are warranted to confirm our results. \n  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n18 \n \nFigure and table legends \nFigure 1 Preparation of datasets \n \nn = number of abstracts (number of diagnostic test accuracy abstracts)\n \n \n  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n19 \n \nFigure 2 Each step to develop, externally validate, and checking for reproducibility of the \nmeta-prompts. \n \nGPT: Generative Pre-trained Transformer \n \n \n  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n20 \n \nFigure 3 Schema of input and output for large language models \n \nGPT: Generative Pre-trained Transformer \nThe square below shows an example input and output. \n \n \n  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n21 \n \nTable 1. Accuracy of meta-prompts for selecting DTA abstracts in the training dataset 1 \nSerial Meta-prompt Sensitivity Specificity Error  \nproportion \n#1 You are a systematic reviewer reviewing \ndiagnostic test accuracy (DTA) studies. Given \nan abstract, determine if it is a DTA study based \non the following criteria: \n \n1. A DTA study evaluates a test against a \nclinical reference standard specifically for \nhumans. \n2. Accept multivariable diagnostic prediction \nmodel studies. \n3. Exclude the following: \n- Prognostic prediction model studies where \npredictors and outcomes are measured at \ndifferent time points. \n- Modeling studies. \n- Studies assessing diagnostic training for \nmedical professionals. \n \nYour response should be 'True' if the abstract is \na DTA study or if there is insufficient \ninformation to make a judgment (e.g., when only \na title is provided). Avoid any oversight. If you \nare certain that the abstract is not a DTA study, \nrespond with 'False'.\n \n1.000 0.067 0.020 \n#8* You are a systematic reviewer reviewing \ndiagnostic test accuracy (DTA) studies. \nDetermine if an abstract is a DTA study based \non the following criteria: \n \n1. A DTA study evaluates a test against a \nclinical reference standard specifically for \nhumans. \n2. Accept multivariable diagnostic prediction \nmodel studies. \n3. Do NOT include: \n- Prognostic prediction model studies where \npredictors and outcomes are measured at \ndifferent time points. \n- Modeling studies. \n- Studies assessing diagnostic training for \nmedical professionals. \n \nRespond with 'True' if the abstract is a DTA \nstudy or if there is not enough information to \n0.960\n 0.413 0.040 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n22 \n \njudge (e.g., when only a title is entered). \nRespond with 'False' if you are certain that the \nabstract is not a DTA study. \n* The meta-prompt passed for the step 2 \n† Details of each iteration is shown in the Supplemental table 1 \nDTA: Diagnostic Test Accuracy \n \n  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n23 \n \nTable 2. Accuracy of meta-prompts for selecting DTA abstracts in the training dataset 2 \nSerial Meta-prompt Sensitivity  Specificity Error  \nproportion \n#1 Please assess if an abstract is a Diagnostic \nTest Accuracy (DTA) study based on the \nfollowing criteria: \n1. A DTA study evaluates a test against a \nclinical reference standard specifically for \nhumans. \n2. Include multivariable diagnostic \nprediction model studies. \n3. Exclude: - Prognostic prediction model \nstudies where predictors and outcomes are \nmeasured at different time points. - \nModeling studies. - Studies assessing \ndiagnostic training for medical \nprofessionals. \nDetermine if the abstract is a DTA study. \nReply with 'True' if the abstract is a DTA \nstudy or if there is insufficient information \nto judge (e.g., when only a title is available). \nReply with 'False' if you are certain that the \nabstract is not a DTA study. \n0.750 0.547 0.002 \n#2 Please determine if an abstract is a \nDiagnostic Test Accuracy (DTA) study \nbased on the following criteria:  \n1. A DTA study evaluates a test against a \nclinical reference standard specifically for \nhumans. \n2. Include multivariable diagnostic \nprediction model studies. \n3. Exclude the following:  \n- Prognostic prediction model studies where \npredictors and outcomes are measured at \ndifferent time points. \n- Modeling studies. \n- Studies assessing diagnostic training for \nmedical professionals. \n \nReply with 'True' if the abstract is a DTA \nstudy or if there is insufficient information \nto judge (e.g., when only a title is available). \nReply with 'False' if you are certain that the \n0.833 0.537 0.012 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n24 \n \nabstract is not a DTA study. \n#3* Please determine if an abstract is a \nDiagnostic Test Accuracy (DTA) study \nbased on the following criteria: 1. A DTA \nstudy evaluates a test against a clinical \nreference standard specifically for humans, \nwith high sensitivity (\n≥ 0.9) and moderate \nspecificity (≥ 0.4). 2. Include multivariable \ndiagnostic prediction model studies. 3. \nExclude the following: - Prognostic \nprediction model studies where predictors \nand outcomes are measured at different time \npoints. - Modeling studies. - Studies \nassessing diagnostic training for medical \nprofessionals. Reply with 'True' if the \nabstract is a DTA study or if there is \ninsufficient information to judge (e.g., when \nonly a title is available). Reply with 'False' if \nyou are certain that the abstract is not a DTA \nstudy. \n0.917 0.527 0.010 \n* The meta-prompt passed for the step 3 \nDTA: Diagnostic Test Accuracy \n \n \n \n \nTable 3. Accuracy of the final meta-prompt at different temperatures with GPT-3.5 turbo in \nthe training dataset 3 \nTemperature Sensitivity Specificity Error  \nproportion \n0 0.938 0.514 0.010 \n0.4 0.875 0.518 0.006 \n0.8 0.813 0.491 0.009 \n1.2 0.813 0.480 0.025 \n1.6 0.688 0.449 0.109 \nGPT: Generative Pre-trained Transformer \n \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n25 \n \nTable 4. Reproducibility test from 10 experiments for the external validation dataset 1 \nSerial model Sensitivity Specificity Error proportion \n#1 GPT-3.5 0.988 0.298 0.008 \n#2 GPT-3.5 0.988 0.297 0.005 \n#3 GPT-3.5 0.994 0.286 0.008 \n#4 GPT-3.5 0.982 0.288 0.009 \n#5 GPT-3.5 0.988 0.288 0.009 \n#6 GPT-3.5 0.988 0.292 0.011 \n#7 GPT-3.5 0.994 0.289 0.011 \n#8 GPT-3.5 0.988 0.292 0.010 \n#9 GPT-3.5 0.988 0.294 0.010 \n#10 GPT-3.5 0.994 0.295 0.010 \n#1 GPT-4 0.982 0.677 0.000 \n#2 GPT-4 0.976 0.678 0.002 \n#3 GPT-4 0.976 0.677 0.002 \n#4 GPT-4 0.976 0.678 0.002 \n#5 GPT-4 0.982 0.677 0.001 \n#6 GPT-4 0.988 0.679 0.000 \n#7 GPT-4 0.994 0.679 0.000 \n#8 GPT-4 0.994 0.678 0.000 \n#9 GPT-4 0.982 0.678 0.000 \n#10 GPT-4 0.988 0.681 0.000 \nGPT: Generative Pre-trained Transformer \n \n  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n26 \n \nTable 5. Reproducibility test from 10 experiments for the external validation dataset 2 \nSerial model Sensitivity Specificity Error proportion \n#1 GPT-3.5 0.919 0.436 0.009 \n#2 GPT-3.5 0.919 0.437 0.009 \n#3 GPT-3.5 0.927 0.438 0.011 \n#4 GPT-3.5 0.919 0.433 0.009 \n#5 GPT-3.5 0.919 0.442 0.008 \n#6 GPT-3.5 0.919 0.438 0.008 \n#7 GPT-3.5 0.919 0.440 0.009 \n#8 GPT-3.5 0.919 0.439 0.008 \n#9 GPT-3.5 0.919 0.435 0.009 \n#10 GPT-3.5 0.927 0.435 0.008 \n#1 GPT-4 0.806 0.740 0.000 \n#2 GPT-4 0.782 0.749 0.000 \n#3 GPT-4 0.798 0.735 0.000 \n#4 GPT-4 0.790 0.746 0.000 \n#5 GPT-4 0.798 0.742 0.000 \n#6 GPT-4 0.806 0.744 0.000 \n#7 GPT-4 0.806 0.750 0.000 \n#8 GPT-4 0.806 0.744 0.000 \n#9 GPT-4 0.790 0.749 0.000 \n#10 GPT-4 0.806 0.742 0.000 \nGPT: Generative Pre-trained Transformer \n \n  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n27 \n \nTable 6. Accuracy of the final meta-prompt when combining the results with GPT-3.5 turbo \nand GPT-4 in the external validation dataset 2 \n GPT-3.5 turbo GPT-4 \nCombined experiments \ncount \nSensitivity Specificity Sensitivity Specificity \n1 0.919 0.446 0.806  0.740 \n2 0.919 0.439 0.815  0.734 \n3 0.927 0.437 0.815  0.722 \n4 0.927 0.434 0.815  0.721 \n5 0.927 0.430 0.815  0.720 \n6 0.927 0.427 0.815  0.719 \n7 0.927 0.427 0.823  0.717 \n8 0.927 0.426 0.823  0.716 \n9 0.927 0.420 0.823  0.714 \n10 0.935 0.419 0.823  0.714 \nGPT: Generative Pre-trained Transformer \n \n \n  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n28 \n \nReferences \n1.  van de Schoot R, de Bruin J, Schram R, Zahedi P, de Boer J, Weijdema F, et al. An \nopen source machine learning framework for efficient and transparent systematic \nreviews. Nat Mach Intell. 2021 Feb 1;3(2):125–33. \n2.  Tsou AY, Treadwell JR, Erinoff E, Schoelles K. Machine learning for screening \nprioritization in systematic reviews: comparative performance of Abstrackr and EPPI-\nReviewer. Syst Rev [Internet]. 2020 Dec;9(1). Available from: \nhttp://dx.doi.org/10.1186/s13643-020-01324-7 \n3.  Devlin J, Chang M-W, Lee K, Toutanova K. BERT: Pre-training of deep bidirectional \nTransformers for language understanding. 2018; Available from: \nhttp://dx.doi.org/10.48550/ARXIV.1810.04805 \n4.  Kataoka Y, Taito S, Yamamoto N, So R, Tsutsumi Y, Anan K, et al. An open \ncompetition involving thousands of competitors failed to construct useful abstract \nclassifiers for new diagnostic test accuracy systematic reviews. Res Synth Methods \n[Internet]. 2023 Jun 20; Available from: http://dx.doi.org/10.1002/jrsm.1649 \n5.  OpenAI. GPT-4 Technical Report [Internet]. arXiv [cs.CL]. 2023. Available from: \nhttp://arxiv.org/abs/2303.08774 \n6.  Zhao WX, Zhou K, Li J, Tang T, Wang X, Hou Y, et al. A survey of large language \nmodels [Internet]. arXiv [cs.CL]. 2023 [cited 2023 Oct 27]. Available from: \nhttp://arxiv.org/abs/2303.18223 \n7.  Demszky D, Yang D, Yeager DS, Bryan CJ, Clapper M, Chandhok S, et al. Using \nlarge language models in psychology. Nat Rev Psychol [Internet]. 2023 Oct 13; \nAvailable from: http://dx.doi.org/10.1038/s44159-023-00241-5 \n8.  Wei J, Wang X, Schuurmans D, Bosma M, Ichter B, Xia F, et al. Chain-of-thought \nprompting elicits reasoning in large language models [Internet]. arXiv [cs.CL]. 2022. \nAvailable from: http://arxiv.org/abs/2201.11903 \n9.  Kojima T, Gu SS, Reid M, Matsuo Y, Iwasawa Y. Large Language Models are Zero-\nShot Reasoners [Internet]. arXiv [cs.CL]. 2022. Available from: \nhttp://arxiv.org/abs/2205.11916 \n10.  Yu F, Zhang H, Tiwari P, Wang B. Natural language reasoning, A survey [Internet]. \narXiv [cs.CL]. 2023. Available from: http://arxiv.org/abs/2303.14725 \n11.  Matsui K, Utsumi T, Aoki Y, Maruki T, Takeshima M, Yoshikazu T. Large language \nmodel demonstrates human-comparable sensitivity in initial screening of systematic \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n29 \n \nreviews: A semi-automated strategy using GPT-3.5 [Internet]. 2023. Available from: \nhttp://dx.doi.org/10.2139/ssrn.4520426 \n12.  Cohen JF, Korevaar DA, Altman DG, Bruns DE, Gatsonis CA, Hooft L, et al. STARD \n2015 guidelines for reporting diagnostic accuracy studies: explanation and elaboration. \nBMJ Open. 2016 Nov;6(11):e012799. \n13.  Collins GS, Reitsma JB, Altman DG, Moons KGM. Transparent Reporting of a \nmultivariable prediction model for Individual Prognosis or Diagnosis (TRIPOD): the \nTRIPOD statement. Ann Intern Med. 2015 Jan 6;162(1):55–63. \n14.  COVID-19: Living systematic map of the evidence [Internet]. [cited 2023 Oct 26]. \nAvailable from: \nhttps://eppi.ioe.ac.uk/cms/Projects/DepartmentofHealthandSocialCare/Publishedrevie\nws/COVID-19Livingsystematicmapoftheevidence/tabid/3765/Default.aspx \n15.  Tsujimoto Y, Kumasawa J, Shimizu S, Nakano Y, Kataoka Y, Tsujimoto H, et al. \nDoppler trans-thoracic echocardiography for detection of pulmonary hypertension in \nadults. Cochrane Database Syst Rev. 2022 May 9;5(5):CD012809. \n16.  Someko H, Okazaki Y, Tsujimoto Y, Ishikane M, Kubo K, Kakehashi T. Diagnostic \naccuracy of rapid antigen tests in cerebrospinal fluid for pneumococcal meningitis: a \nsystematic review and meta-analysis. Clin Microbiol Infect. 2023 Mar;29(3):310–9. \n17.  Azure OpenAI Service [Internet]. [cited 2023 Oct 10]. Available from: \nhttps://learn.microsoft.com/ja-jp/azure/ai-services/openai/overview \n18.  azure-sdk. CompletionsOptions.Temperature property [Internet]. [cited 2023 Oct 10]. \nAvailable from: https://learn.microsoft.com/en-\nus/dotnet/api/azure.ai.openai.completionsoptions.temperature?view=azure-dotnet-\npreview \n19.  Glanville J, Kotas E, Featherstone R, Dooley G. Which are the most sensitive search \nfilters to identify randomized controlled trials in MEDLINE? J Med Libr Assoc. 2020 \nOct 1;108(4):556–63. \n20.  Bethel AC, Rogers M, Abbott R. Use of a search summary table to improve systematic \nreview search methods, results, and efficiency. J Med Libr Assoc. 2021 Jan \n1;109(1):97–106. \n21.  Ouyang S, Zhang JM, Harman M, Wang M. LLM is like a box of chocolates: The non-\ndeterminism of ChatGPT in code generation. 2023; Available from: \nhttp://dx.doi.org/10.48550/ARXIV.2308.02828 \n22.  Kataoka Y, So R. Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine. N \nEngl J Med. 2023 Jun 22;388(25):2399. \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n30 \n \n23.  OpenAI platform [Internet]. [cited 2023 Oct 10]. Available from: \nhttps://platform.openai.com/docs/guides/gpt/why-are-model-outputs-inconsistent \n24.  Bisong E. Google Colaboratory. In: Building Machine Learning and Deep Learning \nModels on Google Cloud Platform. Berkeley, CA: Apress; 2019. p. 59–64. \n25.  Clinical usefulness of cerebrospinal fluid bacterial antigen studies. J Pediatr [Internet]. \nAvailable from: https://doi.org/10.1016/s0022-3476(94)70201-2 \n26.  Study of bacterial meningitis in children below 5 years with comparative evaluation of \ngram staining, culture and bacterial antigen detection. J Clin Diagn Res [Internet]. \nAvailable from: https://doi.org/10.7860/JCDR/2014/6767.4215 \n27.  Matubu A, Rusakaniko S, Robertson V, Gwanzura L. Etiology and risk factors of \nmeningitis in patients admitted at a Central Hospital in Harare. Cent Afr J Med. 2015 \nJan;61(1–4):5–11. \n28.  Ramachandran P, Fitzwater SP, Aneja S, Verghese VP, Kumar V, Nedunchelian K, et \nal. Prospective multi-centre sentinel surveillance for Haemophilus influenzae type b & \nother bacterial meningitis in Indian children. Indian J Med Res. 2013 Apr;137(4):712–\n20. \n29.  Belur J, Tompson L, Thornton A, Simon M. Interrater reliability in systematic review \nmethodology: Exploring variation in coder decision-making. Sociol Methods Res. \n2021 May;50(2):837–65. \n30.  Suzuki E, Tsuda T, Mitsuhashi T, Mansournia MA, Yamamoto E. Errors in causal \ninference: an organizational schema for systematic error and random error. Ann \nEpidemiol. 2016 Nov;26(11):788-793.e1. \n31.  Yang C, Wang X, Lu Y, Liu H, Le QV, Zhou D, et al. Large Language Models as \nOptimizers [Internet]. arXiv [cs.LG]. 2023. Available from: \nhttp://arxiv.org/abs/2309.03409 \n32.  Zhou Y, Muresanu AI, Han Z, Paster K, Pitis S, Chan H, et al. Large language models \nare human-level prompt engineers [Internet]. arXiv [cs.LG]. 2022. Available from: \nhttp://arxiv.org/abs/2211.01910 \n33.  Chen L, Chen J, Goldstein T, Huang H, Zhou T. InstructZero: Efficient instruction \noptimization for black-box large language models [Internet]. arXiv [cs.AI]. 2023. \nAvailable from: http://arxiv.org/abs/2306.03082 \n34.  Chen J, Chen L, Huang H, Zhou T. When do you need Chain-of-Thought Prompting \nfor ChatGPT? [Internet]. arXiv [cs.AI]. 2023. Available from: \nhttp://arxiv.org/abs/2304.03262 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted November 1, 2023. ; https://doi.org/10.1101/2023.10.31.23297818doi: medRxiv preprint ",
  "topic": "Workload",
  "concepts": [
    {
      "name": "Workload",
      "score": 0.6960461139678955
    },
    {
      "name": "Computer science",
      "score": 0.6398608684539795
    },
    {
      "name": "Sensitivity (control systems)",
      "score": 0.563958466053009
    },
    {
      "name": "Machine learning",
      "score": 0.5305153727531433
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4858381450176239
    },
    {
      "name": "Systematic review",
      "score": 0.45884594321250916
    },
    {
      "name": "Data mining",
      "score": 0.3415874242782593
    },
    {
      "name": "Natural language processing",
      "score": 0.3262477517127991
    },
    {
      "name": "MEDLINE",
      "score": 0.23737475275993347
    },
    {
      "name": "Engineering",
      "score": 0.11631697416305542
    },
    {
      "name": "Biology",
      "score": 0.07810094952583313
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Electronic engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4396570538",
      "name": "Kyoto Min-iren Asukai Hospital",
      "country": null
    },
    {
      "id": "https://openalex.org/I4396570521",
      "name": "Scientific Research WorkS Peer Support Group",
      "country": null
    },
    {
      "id": "https://openalex.org/I22299242",
      "name": "Kyoto University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I149737975",
      "name": "Santen (Japan)",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I4210117955",
      "name": "Okayama Psychiatric Medical Center",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I60134161",
      "name": "Nagoya University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I4210104391",
      "name": "Sakai Municipal Hospital",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I4210142853",
      "name": "Asahi General Hospital",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I4210125056",
      "name": "Hiroshima University Hospital",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I145673806",
      "name": "Fujita Health University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I4210096268",
      "name": "National Hospital Organization Mito Medical Center",
      "country": "JP"
    }
  ]
}