{
  "title": "An Article Language Model for BBS Search",
  "url": "https://openalex.org/W1483642010",
  "year": 2005,
  "authors": [
    {
      "id": "https://openalex.org/A2146806579",
      "name": "Jingfang Xu",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2137894504",
      "name": "Yangbo Zhu",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2097478336",
      "name": "Xing Li",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2146806579",
      "name": "Jingfang Xu",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2137894504",
      "name": "Yangbo Zhu",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2097478336",
      "name": "Xing Li",
      "affiliations": [
        "Tsinghua University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2071692409",
    "https://openalex.org/W2118425947",
    "https://openalex.org/W1524901546",
    "https://openalex.org/W2066636486",
    "https://openalex.org/W2171161922",
    "https://openalex.org/W2151734548",
    "https://openalex.org/W2131746181",
    "https://openalex.org/W4206765718",
    "https://openalex.org/W2021986193",
    "https://openalex.org/W2136583886",
    "https://openalex.org/W4246858749",
    "https://openalex.org/W1993972354",
    "https://openalex.org/W2095683564",
    "https://openalex.org/W4256046779",
    "https://openalex.org/W2093390569",
    "https://openalex.org/W2138621811",
    "https://openalex.org/W2099437808",
    "https://openalex.org/W2027752285",
    "https://openalex.org/W2169213601",
    "https://openalex.org/W2162618434"
  ],
  "abstract": null,
  "full_text": "An Article Language Model for BBS Search\nJingfang Xu, Yangbo Zhu, and Xing Li\nDepartment of Electronic Engineering, Tsinghua University\nBeijing 100084, P.R. China\n{xjf02,zhuyangbo99}@mails.tsinghua.edu.cn, xing@cernet.edu.cn\nAbstract. Bulletin Board Systems (BBS), similar to blogs, newsgroups,\nonline forums, etc., are online broadcasting spaces where people can ex-\nchange ideas and make announcements. As BBS are becoming valuable\nrepositories of knowledge and information, eﬀective BBS search engines\nare required to make the information universally accessible and useful.\nHowever, the techniques that have been proven successful for web search\nare not suitable for searching BBS articles due to the nature of BBS. In\nthis paper, we propose a novel article language model (LM) to build an\neﬀective BBS search engine. We investigate the diﬀerences between BBS\narticles and web pages, then extend the traditional LM to author LM and\ncategory LM. The article LM is powerful in the sense that it can combine\nthe three LMs into a single framework. Experimental results shows that\nour article LM substantially outperforms both INQUERY algorithm and\nthe traditional LM.\n1 Introduction\nBulletin Board System(BBS) are online broadcasting spaces where people can\nexchange ideas and make announcements. Unlike web site, where users only\nbrowse web pages, BBS are virtual places where, besides browsing, people carry\non discussion with others. Some users post articles on BBS to ask questions, an-\nswer questions or share information with others, while others browse the articles\nin BBS for information they need. As BBS are valuable repositories of knowledge\nand information, there is a tremendous need for BBS search techniques.\nBBS search can be simply deﬁned as the search engine speciﬁc to BBS.\nUnfortunately, the techniques that have been proven successful for web search\nare not suitable to BBS search due to the nature of BBS. In this paper, BBS\narticles are deﬁned as messages in BBS which contain documents, authors and\ncategories. We investigate the diﬀerences between BBS articles and web pages\nto discover the nature of BBS which aﬀ ects search perform ance. Comparing\nBBS articles and web pages, there are th ree primary diﬀerences. First, BBS\narticles consist of documents, authors who wrote it, and categories which them\nbelong to. While web pages usually only contain documents; the authors and the\ncategories of them are not available. Second, as users sometimes post articles to\nask questions or answer questions, the articles are often shorter than web pages.\nFinally, there are no links between BBS articles while web pages are closely\nconnected by hypertext links. Consequently, on the one hand many techniques\nD. Lowe and M. Gaedke (Eds.): ICWE 2005, LNCS 3579, pp. 152– 160, 2005.\nc⃝ Springer-Verlag Berlin Heidelberg 2005\nAn Article Language Model for BBS Search 153\napplied in web search, e.g., link analysis and anchor text, are not suitable for\nBBS search; one the other hand, the authors and categories of BBS articles may\nbe helpful for ranking retrieved articles. However, to our best knowledge, there\nis no eﬀort devoted to building special models for BBS search.\nIn this paper, we explore the problem of building an eﬀective BBS search with\nthe article language model(LM). According to the nature of BBS, we apply the\ntraditional document LM to the documents belong to an author or a category,\nand propose the author LM and the category LM. Combining the document,\nauthor and category LMs, the article LM is used to rank the retrieved articles\naccording to the probability that the article LM produces the query. To improve\nthe retrieval performance, we propose a smoothing method to address the prob-\nlem that BBS articles are usually short, which aﬀects the precision of sampling.\nExperimental results show that the article LM achieves signiﬁcantly better per-\nformance than both INQUERY ranking algorithm and the traditional LM.\nThe rest of the paper is organized as follows. First we brieﬂy review the re-\nlated work in section 2. Then the traditional LM, the article LM, and a smoothing\nmethod for BBS search are described in section 3. Section 4 presents the exper-\niments and results, which shows the eﬀectiveness of the article LM empirically.\nFinally we conclude with future work in section 5.\n2 Related Work\nAs BBS becomes more and more popular, considerable eﬀort has been devoted\nto investigate the special phenomenon in BBS, such as its complex network\nmodel[1], its aliasing users[2], and its relationship of interests [3]. Many informa-\ntion retrieval(IR) techniques such as PageRank[ 4], HITS[5] and anchor text[ 6]\nare designed for web search, but they are not suitable for other applications.\nTherefore, many research have been do ne to improve IR performance in other\ncontext, e.g., web site[7], newsgroup[8], workplace[9], etc. In this paper we focus\non improving the retrieval performance in BBS.\nIn the mean time, LMs, successfully used for speech recognition, have been\napplied to various IR systems, e.g., web search[ 10], resource selection[ 11], etc.\nGenerally, IR systems can be classiﬁed by the underlying conceptual models,\nsuch as Boolean model, vector-space model, probabilistic model and LM. Ponte\nand Croft originally proposed LM for IR [ 10], then Song put emphasis on data\nsmoothing techniques in LM[ 12]. Recently, many variations of traditional LM\nhave been developed to improve IR performance, such as relevance-based lan-\nguage model[13], time-based language model[ 14] and title language model[ 15].\nIn this paper, we extend the traditional document LM to the author LM and\nthe category LM according to the nature of BBS articles.\n3 Language Model\n3.1 Document Language Model\nAs described by Ponte and Croft[10], in document LM each document is viewed\nas a language sample and a query is treated as a generation process, sampled\n154 Jingfang Xu, Yangbo Zhu, and Xing Li\nfrom the language model. Then the retrieved documents are ranked based on the\nprobabilities of producing the query from the corresponding language models of\nthem. Given the language model Md of document d, the maximum likelihood\nestimate of the probability of termt produced by the corresponding LM is com-\nputed by Equation 1:\np(t|Md) = tf(t,d)\nNd\n(1)\nwhere tft,d is the raw term frequency of term t in document d,a n dNd is the\ntotal number of tokens in documentd. We treat a query as a sequence of terms.\nThen each term is viewed as an independent event, and the query is viewed as the\njoined event[12]. Consequently, the query probability is computed by multiplying\nthe individual term probabilities, as shown in Equation 2:\np(Q|Md) =\n∏\nt∈Q\np(t|Md) (2)\nwhere t is the term in the query sequence Q. Notice that, in this paper, ﬁrst\nwe use Boolean model to get the documents that contain the whole query, then\napply LMs to rank them. So the zero probability problem does not exist in our\nresearch.\n3.2 Author Language Model and Category Language Model\nAs mentioned above, each BBS article contains an author and a category, which\ncan be used to improve the performance of BBS search. The traditional document\nLM infers a LM for each document and views the document as a sample of the\nmodel. Similarly, we infer an author LM for each author and a category LM\nfor each category. That is to say, all the articles of an author are viewed as a\nhuge document, a sample from the corresponding LM. Like probability in the\ndocument LM, we compute the probability of term t produced by the author\nLM Ma. We also get the category LM Mc, corresponding to all the articles\nbelonging to a category, and compute the probability of producing the query\nterm, as shown in Equantion 3, 4:\np(t|Ma) = tf(t,a)\nNa\n(3)\np(t|Mc) = tf(t,c)\nNc\n(4)\nwhere tft,a and Na are the raw term frequency of term t and the total number\nof tokens in all articles written by author a,a n dtft,c and Nc are the raw term\nfrequency of termt and total number of tokens in all articles belong to categoryc.\n3.3 Article Language Model\nIn order to improve the BBS search performance, we combine three LMs: docu-\nment, author, and category LMs into the article LM. Each BBS article is viewed\nAn Article Language Model for BBS Search 155\nas a trigram ( d, a, c), where d is the document text, a is the author and c is\nthe category. Then the retrieved articles are ranked according to the probability\np(Q|article) that the query is sampled form the article LM.\np(Q|article) = p(Q|d,a,c) =\n∏\nt∈Q\np(t|d,a,c) (5)\nAssuming that the three LMs are independent, p(t|d,a,c) is calculated as follows:\np(t|d,a,c) = p(d,a,c|t)p(t)\np(d,a,c)\n(6)\n= p(d|t)p(a|t)p(c|t)p(t)\np(d,a,c)\n=\np(t|d)p(d)\np(t)\np(t|a) p(a)\np(t)\np(t|c)p(c)\np(t)\np(t)\np(d)p(a)p(c)\n= p(t|d)p(t|a)p(t|c)\np2\n(t)\nwhere p(t|d) is the probability that the document LM produces the query term,\np(t|a) is the probability of the author LM and p(t|c) is the probability of the\ncategory model. Therefore, p(Q|article) is the product of the probabilities in three\nLMs, as shown in Equation 7:\np(Q|article) =\n∏\nt∈Q\np(t|d)p(t|a)p(t|c)\np2\n(t)\n=\n∏\nt∈Q\np(t|Md)p(t|Ma)p(t|Mc)\np2\n(t)\n(7)\nwhere p(t|Md), p(t|Ma) and p(t|Mc) are computed according to Equation 2, 3, 4\nand p(t) can be computed according to Equation 8:\np(t) = tf(t,corpus)\nNcorpus\n(8)\nwhere tf(t, corpus) is the term frequency of term t and Ncorpus is the total\nnumber of tokens in the corpus.\n3.4 Data Smoothing\nSome articles in BBS are too short, e.g., less than 15 words, as users post them\nonly to ask or answer questions. The small length aﬀects the precision of maxi-\nmum likelihood estimate as the sparse sampling data can not reﬂect the under-\nlying LM exactly. Moreover, the probability is biased towards short articles. To\naddress this problem, we smooth the length by adding the average sample length\nof the LM to the original length. That is to say, in document LMNd is replaced\nby Nd + avegNd ,w h e r eavegNd is the average length of all the documents. Sim-\nilarly, some authors post few articles and some categories contain few articles,\nwhich lead to sparse sampling data in both the author LM and the category LM.\nWe apply similar smoothing methods on the author LM Ma and the category\nLM Mc,a sp r e s e n t e di nE q u a t i o n9:\n156 Jingfang Xu, Yangbo Zhu, and Xing Li\np(t|Md) = tf(t,d)\nNd + avegNd\np(t|Ma) = tf(t,a)\nNa + avegNa\n(9)\np(t|Mc) = tf(t,c)\nNc + avegNc\n4 Experimental Results\n4.1 Data\nTo demonstrate the eﬀectiveness of the article LM, we conducted experiments\non a Chinese BBS site, Tsinghua University BBS (SMTH) 1,w h i c hi st h em o s t\nfamous and most large BBS site in China. The BBS search engine that we build\nfor SMTH is accessible on line2.A st a b l e1 lists, in SMTH there are 1, 954, 689\narticles, totally 11 gigabytes information, belongs to 85 , 062 authors and 424\ncategories. And the average lengthes of document, author and category are 150,\n3, 447 and 691, 517.\nTable 1. Statistics of SMTH BBS Data\nData Size\n 11G\n#Articles\n 1,954,689\n#Author\n 85,062\n#Category\n 424\nAverage length of documents\n 150\nAverage length of author\n 3,447\nAverage length of category\n 691,517\n4.2 Implementation\nThree diﬀerent ranking algorithms are used in our experiments. The article LM\nis compared with INQUERY ranking formula and the traditional document LM.\nINQUERY ranking formula, which uses Robertson’stf score and a standard idf\nscore, is lists as follows:\npt,d =0 .4+0 .6 × tft,d\ntft,d +0 .5+1 .5 Nd\narvgNd\n×\nlog(N+0.5\ndft\n)\nlog(N +1 ) (10)\nwhere pt,d is that probability that documentd is relevant to termt,Ni sn u m b e r\nof documents in collection, and dft is the document frequency in collection. In\nINQUERY system, documents are ranked by the probability pt,d.\nTraditional LM is described as the document LM above, and the retrieved\ndocuments are ranked based on the probability p(t|Md).I nt h ea r t i c l eL M ,r e -\ntrieved articles are ranked based on the probability p(Q|article).\n1 http://www.smth.org\n2 http://bbs.compass.edu.cn\nAn Article Language Model for BBS Search 157\n4.3 Evaluation Metrics\nThe recall/precision and minimizing Kendall’sτ distance [16] are chosen to mea-\nsure the performance of various models. Recall measures how many relevant ar-\nticles are retrieved, while precision measures how highly the retrieved articles\nare relevant to the query. In recall/precision metric, relevant articles are un-\nordered, which is opposite to the fact that users review the result lists orderly.\nTo evaluate the order of result lists, minimizing Kendall’sτ distance is adopted\nto measure the similarity between the ground truth and the top-k lists produced\nby the models.\nThe minimizing Kendall’s τ distance is deﬁned as follows. Given two top k\nlists τ1 and τ2 with result domains Dτ1 and Dτ2, we deﬁne P(τ1,τ 2) to be the\nset of all unordered pairs of distinct elements in Dτ1 ∪ Dτ2. The minimizing\nKendall’s τ distance is calculated according to Equation 11:\nKmin(τ1,τ2)=\n∑\n{i,j}∈P(τ1 ,τ2)\nKmin\n{i,j}(τ1,τ2)\nk × (k − 1)/2 (11)\nLet r1,i denote the rank of result i in list τ1,a n dr e s u l ti is ahead of result j in\nτ1 if r1,i <r 1,j.T h e nKmin\n{i,j} is calculated according to Equation 12:\nKmin\n{i,j} = sign{(r1,i − r1,j)(r2,i − r2,j)} (12)\n4.4 Results and Discussions\nSeveral volunteers are required to pose 50 queries, which are the top frequent\nqueries in the log of BBS search engine that we build, to three systems in our\nexperiment. For each query, volunteers evaluate the relevance of the top 50 ar-\nticles returned by each system. Then they list the top 20 relevant articles based\non the relevance, which referred to as the ground truth.\nOnly considering the articles in the ground truth as relevant results, we cal-\nculate the eleven point recall/precison of the three systems, as shown in Table2\nand Figure 1.I nt a b l e2, column 2,3,4 compare the article LM to INQUERY, and\ncolumn 5,6,7 compare the article LM to the traditional document LM. As we\ncan see, the article LM outperforms INQ UERY ranking algorithm at all levels\nof recall, and the article LM achieves better precision than the document LM\nexpect at 0.9 level of recall. In addition, the eleven point average precision of\nthree systems are 0.310, 0.356 and 0.449, and the article LM do 44 .84% better\nthan INQUERY and 26.12% better than the document LM.\nThe minimizing Kendall’s τ distance is computed between the ground truth\nand the top 20 list of each system’s search results. As Table 3 presents, the\nKendall’s τ distance of three systems and the ground truth are 0.461100, 0.446451\nand 0.401906, among which the article LM has the shortest distance to the\nground truth. It indicates that the order of the result list in article LM is most\nsimilar to the ground truth.\nExperimental results shows that the article LM outperforms INQUERY rank-\ning algorithm and the traditional LM. Not only the recall/precision of the article\n158 Jingfang Xu, Yangbo Zhu, and Xing Li\nTable 2. Comparing eleven point recall/precison of INQUERY, document LM and\narticle LM\nPrecision\nRecall\n INQUERY\n Article LM\n %chg\n Document LM\n Article LM\n %chg\n0.0\n -\n -\n -\n -\n -\n -\n0.1\n 0.576\n 0.740\n +28%\n 0.610\n 0.740\n +21%\n0.2\n 0.473\n 0.707\n +49%\n 0.555\n 0.707\n +27%\n0.3\n 0.463\n 0.666\n +44%\n 0.525\n 0.666\n +27%\n0.4\n 0.442\n 0.613\n +39%\n 0.484\n 0.613\n +27%\n0.5\n 0.376\n 0.552\n +47%\n 0.419\n 0.552\n +32%\n0.6\n 0.318\n 0.507\n +59%\n 0.348\n 0.507\n +46%\n0.7\n 0.233\n 0.394\n +69%\n 0.282\n 0.394\n +40%\n0.8\n 0.180\n 0.240\n +33%\n 0.218\n 0.280\n +10%\n0.9\n 0.040\n 0.063\n +57%\n 0.111\n 0.063\n -43%\n1.0\n 0.003\n 0.003\n 0\n 0.003\n 0.003\n 0\nAvg\n 0.310\n 0.449\n +44.84%\n 0.356\n 0.449\n +26.12%\n 0\n 0.1\n 0.2\n 0.3\n 0.4\n 0.5\n 0.6\n 0.7\n 0.8\n 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1\nPrecision\nRecall\nArticle LM\nDocument LM\nInquery\nFig. 1. Comparing eleven point recall/precison of INQUERY, document LM and article\nLM\nLM is better than the others, but also the order of the relevant results in article\nLM is more close to the gr ound truth. The success is due to that the article\nLM makes use of the information from the author and the category. Each user\nor category has particular interests and diﬀerent ﬁelds of knowledge. Obviously\nit will be helpful to improve IR performance that exploring diﬀerences between\nusers or categories. Consequently, combing document, author and category LMs\ninto the article LM would achieve signiﬁcant improvement in BBS search.\nAn Article Language Model for BBS Search 159\nTable 3. Minimizing Kendall’s τ Distance Results\nlist τ1\n list τ2\n Kendall’s τ distance\nGround Truth\n INQUERY\n 0.461100\nGround Truth\n Traditional Document LM\n 0.446451\nGround Truth\n Article LM\n 0.401906\n5 Conclusions and Future Work\nIn this paper, we propose a novel article LM for BBS search to improve the re-\ntrieval performance. According to the nature of BBS, we extend the traditional\ndocument LM to the author LM and the category LM. The article LM combines\ndocument, author, and category LMs into a single framework. Our experimen-\ntal results show that the article LM outperforms signiﬁcantly both INUQERY\nranking algorithm and the traditional LM. It indicates that the information of\nthe authors and the categories of the BBS articles are helpful to improve the\nretrieval performance in BBS search. The article LM can be easily applied in\nother similar systems such as blogs, newsgroups and forums.\nFor the future work we are planning to explore various smoothing method\nto improve retrieval performance. Mo reover, we will explore to build an blogs\nsearch engine with our article LM. Making use of user informaion, personalized\nsearch in BBS or blogs is also planed to do.\nReferences\n1. Kou, Z., Zhang, C.: Reply networks on a bulletin board system. Physical Review\nE 67 (2003)\n2. Novak, J., Raghavan, P., Tomkins, A.: Anti-aliasing on the web. Proceedings of\nthe 13th international conference on World Wide Web (2004) 30–39\n3. Kou, Z., , Bao, T., Zhang, C.: Discovery of relationships between intereswts from\nbulletin board system by dissimilarity reconstruction. Proceedings Lecture Notes\nin Artiﬁcial Intelligent 2843 (2003) 328–335\n4. Brin, S., Page, L.: The anatomy of a large-scale hypertextual web search engine.\nProceedings of the seventh international conference on World Wide Web 7 (1998)\n107–117\n5. Kraft, R., J.Zien: Authoritative sources in a hyperlinked environment. Proceedings\nof the ninth annual ACM-SIAM symposium on Discrete algorithms (1998) 668–677\n6. Kraft, R., J.Zien: Mining anchor text for query reﬁnement. Proceedings of the\n13th international conference on World Wide Web (2004) 666–674\n7. G.Xue, H.Zeng, Chen, Z., Ma, W., Lu, C.: Log mining to improve the perfor-\nmance of site search. Third International Conference on Web Information Systems\nEngineering (2002)\n8. Xi, W., Lind, J., Brill, E.: Learning eﬀective ranking functions for newsgroup\nsearch. Proceedings of the ACM SIGIR Conference on Research and Development\nin Information Retrieval (2004) 394–401\n9. Fagin, R., Kumar, R., McCurley, K.: Searching the workplace web. Proceedings\nof the twelfth international conference on World Wide Web (2003) 366–375\n160 Jingfang Xu, Yangbo Zhu, and Xing Li\n10. Ponte, J., Croft, W.: A language modeling approach to information retrieval.\nProceedings of the ACM SIGIR Conference on Research and Development in In-\nformation Retrieval (1998) 275–281\n11. Si, L., Jin, R., Callan, J., Ogilvie, P.: A language modeling framework for resource\nselection and results merging. Proceedings of the eleventh international conference\non Information and knowledge management (2002) 391–397\n12. Song, F., Croft, W.: A general language model for information retrieval. Proceed-\nings of the ACM SIGIR Conference on Research and Development in Information\nRetrieval (1999) 279–280\n13. Lavrenko, V., Croft, W.: Relevance-based language models. Proceedings of the\n24th annual international ACM SIGIR conference on Research and development\nin information retrieval (2001) 120–127\n14. Li, X., Croft, W.: Time-based language models. Proceedings of the twelfth inter-\nnational conference on Information and knowledge management (2003) 469–475\n15. R. Jin, A.G. Hauptmann, C.Z.: Title language model for information retrieval.\nProceedings of the 24th annual international ACM SIGIR conference on Research\nand development in information retrieval (2002) 42–48\n16. Fagin, R., Kumar, R., Sivakumar, D.: Comparing top k lists. Proceedings of the\nfourteenth annual ACM-SIAM symposium on Discrete algorithms (2003) 28–36",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8502765893936157
    },
    {
      "name": "Search engine",
      "score": 0.6482176184654236
    },
    {
      "name": "World Wide Web",
      "score": 0.629056990146637
    },
    {
      "name": "Bulletin board system",
      "score": 0.5412676930427551
    },
    {
      "name": "Information retrieval",
      "score": 0.5238142609596252
    },
    {
      "name": "Broadcasting (networking)",
      "score": 0.46895831823349
    },
    {
      "name": "The Internet",
      "score": 0.3471633195877075
    },
    {
      "name": "Computer security",
      "score": 0.08359742164611816
    }
  ]
}