{
    "title": "Assessing the performance of large language models (LLMs) in answering medical questions regarding breast cancer in the Chinese context",
    "url": "https://openalex.org/W4403203111",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2132699279",
            "name": "Ying Piao",
            "affiliations": [
                "Southern University of Science and Technology",
                "Jinan University"
            ]
        },
        {
            "id": "https://openalex.org/A2103567780",
            "name": "Hongtao Chen",
            "affiliations": [
                "Southern University of Science and Technology",
                "Jinan University"
            ]
        },
        {
            "id": "https://openalex.org/A2499637321",
            "name": "Shihai Wu",
            "affiliations": [
                "Southern University of Science and Technology",
                "Jinan University"
            ]
        },
        {
            "id": "https://openalex.org/A2120336634",
            "name": "Xianming Li",
            "affiliations": [
                "Jinan University",
                "Southern University of Science and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2108050624",
            "name": "Zihuang Li",
            "affiliations": [
                "Southern University of Science and Technology",
                "Jinan University"
            ]
        },
        {
            "id": "https://openalex.org/A2106255158",
            "name": "Dong Yang",
            "affiliations": [
                "Jinan University",
                "Southern University of Science and Technology"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4362608470",
        "https://openalex.org/W4381469233",
        "https://openalex.org/W4380423243",
        "https://openalex.org/W4362521774",
        "https://openalex.org/W4382929886",
        "https://openalex.org/W4386117408",
        "https://openalex.org/W4384944902",
        "https://openalex.org/W4353016766",
        "https://openalex.org/W4381611207",
        "https://openalex.org/W4385568225",
        "https://openalex.org/W4385299173",
        "https://openalex.org/W4300690596",
        "https://openalex.org/W4211038303",
        "https://openalex.org/W2797197823",
        "https://openalex.org/W4211247697",
        "https://openalex.org/W3092895260",
        "https://openalex.org/W2977727370",
        "https://openalex.org/W4384558920",
        "https://openalex.org/W4389577293",
        "https://openalex.org/W4388110208",
        "https://openalex.org/W2962735233",
        "https://openalex.org/W4380997513",
        "https://openalex.org/W2156324477",
        "https://openalex.org/W4382399943",
        "https://openalex.org/W2995059508",
        "https://openalex.org/W2990323914",
        "https://openalex.org/W4367310920",
        "https://openalex.org/W4385330587",
        "https://openalex.org/W4386423073",
        "https://openalex.org/W4225845169"
    ],
    "abstract": "Purpose Large language models (LLMs) are deep learning models designed to comprehend and generate meaningful responses, which have gained public attention in recent years. The purpose of this study is to evaluate and compare the performance of LLMs in answering questions regarding breast cancer in the Chinese context. Material and Methods ChatGPT, ERNIE Bot, and ChatGLM were chosen to answer 60 questions related to breast cancer posed by two oncologists. Responses were scored as comprehensive, correct but inadequate, mixed with correct and incorrect data, completely incorrect, or unanswered. The accuracy, length, and readability among answers from different models were evaluated using statistical software. Results ChatGPT answered 60 questions, with 40 (66.7%) comprehensive answers and six (10.0%) correct but inadequate answers. ERNIE Bot answered 60 questions, with 34 (56.7%) comprehensive answers and seven (11.7%) correct but inadequate answers. ChatGLM generated 60 answers, with 35 (58.3%) comprehensive answers and six (10.0%) correct but inadequate answers. The differences for chosen accuracy metrics among the three LLMs did not reach statistical significance, but only ChatGPT demonstrated a sense of human compassion. The accuracy of the three models in answering questions regarding breast cancer treatment was the lowest, with an average of 44.4%. ERNIE Bot's responses were significantly shorter compared to ChatGPT and ChatGLM ( p &lt; .001 for both). The readability scores of the three models showed no statistical significance. Conclusions In the Chinese context, the capabilities of ChatGPT, ERNIE Bot, and ChatGLM are similar in answering breast cancer-related questions at present. These three LLMs may serve as adjunct informational tools for breast cancer patients in the Chinese context, offering guidance for general inquiries. However, for highly specialized issues, particularly in the realm of breast cancer treatment, LLMs cannot deliver reliable performance. It is necessary to utilize them under the supervision of healthcare professionals.",
    "full_text": null
}