{
  "title": "A comprehensive review of large language models: issues and solutions in learning environments",
  "url": "https://openalex.org/W4406343535",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2810457731",
      "name": "Tariq Shahzad",
      "affiliations": [
        "University of Johannesburg"
      ]
    },
    {
      "id": "https://openalex.org/A3112859879",
      "name": "Tehseen Mazhar",
      "affiliations": [
        "Government of Pakistan",
        "National College of Business Administration and Economics"
      ]
    },
    {
      "id": "https://openalex.org/A2148491781",
      "name": "Muhammad Usman Tariq",
      "affiliations": [
        "University of Glasgow",
        "Abu Dhabi University"
      ]
    },
    {
      "id": "https://openalex.org/A2110979750",
      "name": "Wasim Ahmad",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096578595",
      "name": "Khmaies Ouahada",
      "affiliations": [
        "University of Johannesburg"
      ]
    },
    {
      "id": "https://openalex.org/A1237972934",
      "name": "Habib Hamam",
      "affiliations": [
        "University of Johannesburg",
        "Université de Moncton"
      ]
    },
    {
      "id": "https://openalex.org/A2810457731",
      "name": "Tariq Shahzad",
      "affiliations": [
        "University of Johannesburg"
      ]
    },
    {
      "id": "https://openalex.org/A3112859879",
      "name": "Tehseen Mazhar",
      "affiliations": [
        "Government of Pakistan",
        "National College of Business Administration and Economics",
        "Government College of Science"
      ]
    },
    {
      "id": "https://openalex.org/A2148491781",
      "name": "Muhammad Usman Tariq",
      "affiliations": [
        "University of Glasgow",
        "Abu Dhabi University"
      ]
    },
    {
      "id": "https://openalex.org/A2110979750",
      "name": "Wasim Ahmad",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096578595",
      "name": "Khmaies Ouahada",
      "affiliations": [
        "University of Johannesburg"
      ]
    },
    {
      "id": "https://openalex.org/A1237972934",
      "name": "Habib Hamam",
      "affiliations": [
        "Université de Moncton",
        "University of Johannesburg",
        "Omar Bongo University",
        "Spectrum Research (United States)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4220993274",
    "https://openalex.org/W3011920570",
    "https://openalex.org/W3185181255",
    "https://openalex.org/W4398242747",
    "https://openalex.org/W3171587117",
    "https://openalex.org/W4225808286",
    "https://openalex.org/W3177920269",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4297253404",
    "https://openalex.org/W4322743583",
    "https://openalex.org/W4367595583",
    "https://openalex.org/W4324304837",
    "https://openalex.org/W4200453904",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W4379279977",
    "https://openalex.org/W4362584541",
    "https://openalex.org/W3197315056",
    "https://openalex.org/W4293222331",
    "https://openalex.org/W4385395702",
    "https://openalex.org/W4322730935",
    "https://openalex.org/W4377231151",
    "https://openalex.org/W3200565935",
    "https://openalex.org/W4360584537",
    "https://openalex.org/W2981863007",
    "https://openalex.org/W4362653932",
    "https://openalex.org/W4385231779",
    "https://openalex.org/W4322757547",
    "https://openalex.org/W4365512576",
    "https://openalex.org/W4285140393",
    "https://openalex.org/W4220931862",
    "https://openalex.org/W2890116734",
    "https://openalex.org/W4288066876",
    "https://openalex.org/W1979290264",
    "https://openalex.org/W4404518472",
    "https://openalex.org/W4385443772",
    "https://openalex.org/W6891809357",
    "https://openalex.org/W2995664964",
    "https://openalex.org/W3095319910",
    "https://openalex.org/W4383346782",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W6628082049",
    "https://openalex.org/W4389520163",
    "https://openalex.org/W4385822836",
    "https://openalex.org/W4382678522",
    "https://openalex.org/W4368367885",
    "https://openalex.org/W4206637810",
    "https://openalex.org/W2783378158",
    "https://openalex.org/W4382680318",
    "https://openalex.org/W4320495408",
    "https://openalex.org/W3105220303",
    "https://openalex.org/W4225353277",
    "https://openalex.org/W2950813464",
    "https://openalex.org/W3058517477",
    "https://openalex.org/W4367669558",
    "https://openalex.org/W4382240029",
    "https://openalex.org/W4315779850",
    "https://openalex.org/W3205734318",
    "https://openalex.org/W3028754898",
    "https://openalex.org/W3096485810",
    "https://openalex.org/W2560622264",
    "https://openalex.org/W3195784889",
    "https://openalex.org/W4282940578",
    "https://openalex.org/W4243640523",
    "https://openalex.org/W4220759704",
    "https://openalex.org/W6850135255",
    "https://openalex.org/W4322718832",
    "https://openalex.org/W4393902165",
    "https://openalex.org/W4324387439",
    "https://openalex.org/W4364378150",
    "https://openalex.org/W4361204578",
    "https://openalex.org/W4323313947",
    "https://openalex.org/W4381924932",
    "https://openalex.org/W4324007137",
    "https://openalex.org/W4360615722",
    "https://openalex.org/W4319083882",
    "https://openalex.org/W4379010216",
    "https://openalex.org/W4361285259",
    "https://openalex.org/W2955088691",
    "https://openalex.org/W2936922813",
    "https://openalex.org/W4379646617",
    "https://openalex.org/W2937671419",
    "https://openalex.org/W4375862891",
    "https://openalex.org/W4313445999",
    "https://openalex.org/W3164721408",
    "https://openalex.org/W4366420437",
    "https://openalex.org/W4315498228",
    "https://openalex.org/W4313564799",
    "https://openalex.org/W4362559957",
    "https://openalex.org/W4367053831",
    "https://openalex.org/W4383483317",
    "https://openalex.org/W3126041111"
  ],
  "abstract": "Abstract A significant advancement in artificial intelligence is the development of large language models (LLMs). Despite opposition and explicit bans by some authorities, LLMs continue to play a transformative role, particularly in education, by improving language understanding and generation capabilities. This study explores LLMs’ types, history, and training processes, alongside their application in education, including digital and higher education settings. A novel theoretical framework is proposed to guide the integration of LLMs into education, addressing key challenges such as personalization, ethical concerns, and adaptability. Furthermore, the study presents practical case studies and solutions to barriers, such as data privacy and bias, offering insights into their role in enhancing the teaching–learning process. By providing a systematic analysis and proposing a structured framework, this study advances current knowledge and highlights the significant potential of LLMs in revolutionizing education.",
  "full_text": "Vol.:(0123456789)\n Discover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\nDiscover Sustainability\nReview\nA comprehensive review of large language models: issues \nand solutions in learning environments\nTariq Shahzad1 · Tehseen Mazhar2,9 · Muhammad Usman Tariq3,4 · Wasim Ahmad5 · Khmaies Ouahada1 · \nHabib Hamam1,6,7,8\nReceived: 15 November 2024 / Accepted: 7 January 2025\n© The Author(s) 2025  OPEN\nAbstract\nA significant advancement in artificial intelligence is the development of large language models (LLMs). Despite oppo -\nsition and explicit bans by some authorities, LLMs continue to play a transformative role, particularly in education, by \nimproving language understanding and generation capabilities. This study explores LLMs’ types, history, and training \nprocesses, alongside their application in education, including digital and higher education settings. A novel theoretical \nframework is proposed to guide the integration of LLMs into education, addressing key challenges such as personaliza-\ntion, ethical concerns, and adaptability. Furthermore, the study presents practical case studies and solutions to barriers, \nsuch as data privacy and bias, offering insights into their role in enhancing the teaching–learning process. By providing \na systematic analysis and proposing a structured framework, this study advances current knowledge and highlights the \nsignificant potential of LLMs in revolutionizing education.\nKeywords Natural language processing systems · Large language models · Neural networks · Artificial intelligence · \nEducation · Learning systems\n1 Introduction\n1.1  Context\nArtificial intelligence and LLMs are now widely used in every field. Their powerful language understanding and com-\nputational capabilities open the door to innovative AI applications. A notable example is ChatGPT-4, which represents \nthe state-of-the-art in LLM development [1]. These models rely on deep learning and extensive training with big data to \nanalyze patterns in human language, respond to questions, and perform complex tasks [2 , 3].\n * Tariq Shahzad, tariqshahzadd@gmail.com;  * Tehseen Mazhar, tehseenmazhar719@gmail.com; Muhammad Usman Tariq, \nMuhammad.kazi@adu.ac.ae; Wasim Ahmad, wasimahmadits@gmail.com; Khmaies Ouahada, kouahada@uj.ac.za; Habib Hamam, \nhabib.hamam@umoncton.ca | 1Department of Electrical and Electronic Engineering Science, University of Johannesburg, \nJohannesburg 2006, South Africa. 2School of Computer Science, National College of Business Administration and Economics, \nLahore 54000, Pakistan. 3Abu Dhabi University, Abu Dhabi, UAE. 4University of Glasgow, Glasgow, UK. 5Department of Computing, \nSchool of Arts and Creative Technology, University of Greater Manchester, Manchester BL15AB, UK. 6Faculty of Engineering, Uni de \nMoncton, Moncton, NB E1A3E9, Canada. 7International Institute of Technology and Management (IITG), Av. Grandes Ecoles, Libreville, \nGabon. 8Bridges for Academic Excellence, Spectrum, Tunis, Tunisia. 9Department of Computer Science and Information Technology, School \nEducation Department Government of Punjab, Layyah 31200, Pakistan.\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\nThe education sector is experiencing significant transformations, as LLMs offer opportunities to automate processes \nlike content creation, grading, and personalized learning [4 –7]. However, these advancements also raise critical ethical \nand practical challenges, such as data privacy, bias, overreliance on AI, and pedagogical concerns [8 –10]. Addressing \nthese challenges requires a structured approach to ensure that LLMs enhance, rather than hinder, educational systems. \nFigure 1 illustrates the architecture of LLM in education.\nSeveral existing studies have explored the technical capabilities and ethical implications of LLMs [8 , 11], yet critical \ngaps remain. Specifically, there is a lack of theoretical frameworks that outline how LLMs can be effectively integrated \ninto education while addressing personalization, scalability, and ethical concerns. Additionally, previous studies tend to \nfocus on individual applications rather than providing a systematic analysis of real-world educational use cases [12, 13]. \nFigure 2 illustrates the building block of LLMs.\nTo address these limitations, this study makes the following contributions:\n• Proposing a novel theoretical framework for integrating LLMs in education, focusing on three key pillars: personalized \nlearning, ethical and pedagogical balance, and learning adaptability.\n• Conducting a systematic review of LLM capabilities, training processes, and applications in educational settings [14, \n15].\n• Providing practical case studies to illustrate real-world challenges, opportunities, and solutions in implementing LLMs.\nBy systematically bridging the existing gaps and offering a structured framework, this study highlights the potential \nof LLMs to transform teaching and learning while addressing key challenges.\n1.2  Motivation of the study\nThis study is motivated by the transformative impact of ChatGPT and LLMs across disciplines, particularly in education, \nhealthcare, finance, coding, and the job market.\nIn education, LLMs like ChatGPT revolutionize learning by virtualizing processes, expanding opportunities, and reshap-\ning pedagogical approaches. Their potential to automate tasks, enhance personalized learning, and improve accessibility \nhighlights their significance.\nOther sectors also demonstrate their impact:\n• Healthcare: Assisting in medical diagnosis, research, and knowledge dissemination [8 ].\nFig. 1  Architecture of LLMs for \neducation\n\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\n• Finance: Supporting financial analysis, market predictions, and investment guidance [3 ].\n• Coding Proficiency: Improving code generation, debugging, and enhancing developer productivity [6 ].\n• Labor Market: Digitizing labor processes and reshaping job requirements [7 ].\nDespite these advancements, challenges remain, such as understanding the ethical, practical, and technical implica-\ntions of integrating LLMs. This study focuses on educational applications of LLMs, evaluating their capabilities, addressing \nchallenges, and proposing solutions to optimize their role in teaching, learning, and administrative tasks.\n1.3  Contribution of the study\nThe main contributions of this article are as follows:\n• Comprehensive Background and Theoretical Foundation: The study begins by providing an extensive background \non the evolution of educational systems, LLMs, and the concept of intelligent education. It clarifies the relationship \nbetween LLMs and education and explores the notion of “Smart Education” as a transformative paradigm, setting the \nstage for the practical and theoretical insights presented.\n• Novel Theoretical Framework for LLM Integration: A proposed theoretical framework is introduced to guide the ethi-\ncal and effective integration of LLMs, such as ChatGPT, into educational systems. The framework provides actionable \nguidance by focusing on three interdependent pillars:\no Personalized Learning Models: Offering tailored educational content to meet individual student needs through \nadaptive systems.\no Ethical and Pedagogical Balance: Developing strategies to address challenges like AI bias, data privacy, and over-\nreliance on AI, while enhancing critical thinking and human oversight.\no Learning Adaptability Framework: Ensuring LLM flexibility across diverse educational contexts, such as K-12 \nclassrooms, higher education, and online learning.\n• Systematic Review of LLMs: The article conducts a structured and comprehensive review of LLMs, including their his-\ntory, training processes, and evaluation methods. This systematic review identifies underexplored areas in educational \napplications, such as the need for bias mitigation, privacy protections, and energy-efficient deployments.\nFig. 2  LLMs buildings blocks\n\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\n• Comparative Analysis with Practical Insights: To ensure actionable implications, the study presents real-world case \nstudies demonstrating LLM applications in education. These include:\no Automated content creation: Reducing the workload of educators.\no Intelligent tutoring systems: Providing students with personalized feedback and tailored learning experiences.\no Language support tools: Enhancing accessibility for non-native speakers.\no A comparative analysis evaluates these applications across primary education, higher education, and digital \nlearning, offering actionable insights for educators, policymakers, and institutions.\n• Challenges and Actionable Solutions: The study identifies key challenges in the adoption of LLMs, including data \nprivacy, ethical considerations, algorithmic bias, and pedagogical limitations. To address these challenges, the article \nproposes practical solutions, such as:\no Implementing robust data protection frameworks (e.g., encryption, anonymization).\no Developing bias mitigation strategies to ensure fairness and inclusivity.\no Promoting teacher-AI collaboration to balance automation with human oversight.\no Encouraging sustainable deployment of LLMs with energy-efficient practices.\n• Practical Recommendations for Higher Education: The study highlights actionable recommendations for implement-\ning LLMs in higher education, including:\no Enhancing personalized feedback mechanisms to improve student learning outcomes.\no Supporting remote learning environments through AI-powered tools.\no Addressing academic integrity concerns with ethical monitoring frameworks to ensure responsible LLM use.\nBy combining a novel theoretical framework, a systematic review, and practical case studies, this article provides \nboth theoretical advancements and actionable recommendations. It bridges existing research gaps and offers con-\ncrete solutions for educators, policymakers, and researchers to guide the ethical and effective integration of LLMs \nin education.\n1.4  Organization of paper\nThe remaining sections of the paper follow this structure: Section II explains the research methodology and the \nresearch methodology, in which protocol, research questions, keyword selections, paper selections, formulation of \nstrings, database selections and inclusion and exclusion criteria are discussed. Section III explains the results of the \nresearch questions and Section IV concludes the conclusion and future work. A list of abbreviations is given in Table  1.\nTable 1  List of abbreviations\nAbbreviation Description Abbreviation Description\nLM Large Language Model AI Artificial Intelligence\nNLP Natural Language Processing DL Deep Learning\nNN Neural Network LM Language Model\nRNN Recurrent Neural Network RNNLM Recurrent Neural Network Language Model\nGPT Generative Pre-trained Transformer VAEs Variable Auto encoders\nHEIs Higher Education Institutions BERT Bidirectional Encoder Representations from \nTrans-formers\nMLM Multi-layer masking NSP Next Sentence Prediction\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\n2  Literature review\nLLMs are significant in multidisciplinary areas like artificial intelligence and data science. They play a significant role in \nAI research because they try to imitate human language skills and find solutions for issues with NLP . We can achieve this \nthrough techniques based on deep learning and training with large volumes of data [16]. These LLMs are widely used \nin the field of data science. Their applications include machine translation, sentiment analysis, text mining [ 17], and \nextracting relevant information from textual data. LLMs also have connections to cognitive science, machine learning \n(ML), and computer science, which encourages interdisciplinary research and cooperation [18].\nLLMs like GPT-3 have recently been introduced, and many people are interested in them and have strong opinions \nabout their transformative potential. Deep learning-powered LLMs have excellent language generation and under -\nstanding capabilities, significantly advancing the field of artificial intelligence [18]. These advances are primarily driven \nby architectures like Transformers, which rely on self-attention mechanisms to process sequential data efficiently [3 , 6]. \nPre-training on vast amounts of textual data enables LLMs to perform well on downstream tasks like sentiment analysis, \ntranslation, and summarization [14, 15, 19].\nThe education sector faces a multitude of opportunities and challenges. Traditional teaching struggles with issues like \ndifferentiated education, unequal access to resources, and effectiveness measurement [20]. Advances in EduLLMs can \naddress these challenges by offering tailored learning materials, personalized feedback, and improved engagement [7 , \n10, 12]. However, practical implementation raises concerns about ethical usage, data privacy, and algorithmic bias [8, 9, \n21, 22]. Addressing these concerns is crucial to leveraging LLMs in education effectively.\nFigure 3 illustrates the significance and several steps to the development of LLMs.\n2.1  Applications of LLMs in education\nIf teachers follow a prescribed curriculum, traditional learning will remain the most common and publicly recognized \nform of education [23]. Conversely, the widespread use of digital technology has given rise to new paradigms in educa-\ntion. Online courses, distance learning, and digital tools provide alternatives to traditional classrooms [24], enabling \npersonalized and independent learning.\nEduLLMs (educational LLMs) are fundamental to these paradigms, as they enable tasks like semantic understanding, \nsentiment analysis, and text comprehension [3, 25]. By analyzing large datasets, EduLLMs can provide real-time question \nanswering and extract meaningful insights to aid learning. Deep learning techniques like Convolutional Neural Networks \n(CNNs) and Recurrent Neural Networks (RNNs) further enhance their output quality [26, 27]. Hybrid deep learning tech-\nniques have been used to analyze student academic performance [28] as well as exam supervision [29].\nIncorporating Reinforcement Learning into EduLLMs enables models to adapt to student feedback dynami-\ncally, improving performance over time [30]. RL models can optimize recommendations, train learning agents, and \nFig. 3  Steps of evolution \nTowards ChatGPT\n\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\nautomate responses to student inputs [19]. Additionally, Data Mining (DM) techniques help identify learning patterns, \nbehavioral trends, and knowledge gaps, facilitating personalized learning environments [31, 32].\nTo improve engagement, EduLLMs integrate multimodal technologies, such as:\n• Computer Vision (CV): Analyzing students’ facial expressions and body language for real-time feedback [42].\n• Voice Recognition: Supporting oral practice, speech evaluation, and pronunciation correction in language learning \nenvironments [33].\nThese technologies allow EduLLMs to provide a flexible, real-time learning experience tailored to individual stu-\ndent needs. Chatbots and intelligent tutoring systems powered by LLMs offer 24/7 personalized assistance, reducing \neducators’ workload and enhancing learning efficiency [34– 36].\nHowever, challenges persist regarding the ethical deployment of LLMs in education. Issues like data bias, student \nprivacy, and algorithm transparency must be addressed to ensure equitable and inclusive learning experiences [9 , \n37, 38].\n2.2  Evolution of LLMs\nThe evolution of LLMs demonstrates their increasing capacity to handle complex NLP tasks. Early models like GPT-1 \nshowed flexibility in tasks such as language translation, sentiment analysis, and text categorization [3 ].\nThe release of GPT-2 marked a turning point, as it introduced significant enhancements over GPT-1. GPT-2, with \n1.5 billion parameters, generated longer and more coherent text sequences, showcasing the ability to adapt to vari-\nous domains [7 , 39]. GPT-2’s versatility enabled downstream tasks, including text summarization, classification, and \nquestion answering [40, 41].\nBuilding on GPT-2, GPT-3 significantly expanded the parameter count to 175 billion, leading to substantial improve -\nments in text generation accuracy and logical consistency [42]. GPT-3’s architecture also introduced transfer learning \nstrategies, where pre-trained models were fine-tuned for specific tasks with minimal labeled data [19].\nThe development of Instruct GPT further advanced GPT models by integrating reinforcement learning with human \nfeedback (RLHF). Unlike GPT-3, Instruct GPT uses smaller, curated datasets to refine its outputs iteratively, improving \nreliability and alignment with user goals [43– 45].\nFigure 4 highlights the evolution of LLMs, showcasing their advancements in parameters, training processes, and \ntask performance.\nFig. 4  Evolution of LLMs\n\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\n2.3  Proposed theoretical framework\nTo address the challenges and gaps identified in existing literature regarding the integration of LLMs in education, \nthis study proposes a novel theoretical framework. The framework is built on three interdependent pillars aimed at \nenhancing personalized learning, ethical AI integration, and adaptability within educational systems.\n1. Personalized Learning Models\n2. LLMs analyze student-specific data (e.g., learning pace, performance) to deliver tailored materials.\n3. A dynamic feedback loop ensures continuous improvement in learning outcomes [10, 15].\n4. Ethical and Pedagogical Balance\n5. Ethical concerns, such as bias and overreliance, are addressed through transparent deployment strategies [21, 22].\n6. Human-in-the-loop approaches ensure AI complements critical thinking instead of replacing it [38, 40].\n7. Learning Adaptability Framework\n8. The framework advocates for flexible AI systems capable of adapting to diverse educational environments, such as \nK-12 and higher education [46, 47].\n9. Integration of multimodal learning tools like AR/VR ensures inclusivity and scalability [48].\n2.4  Research gap\nDespite the significant advancements in LLMs, their integration into educational systems remains fragmented, with \nseveral critical gaps in the current literature:\n• Lack of Structured Frameworks for Integration: Existing studies primarily focus on isolated applications of LLMs, \nsuch as automated content creation, language tutoring, and intelligent tutoring systems [25, 34, 35]. However, \nthese studies fail to provide a structured, theoretical framework to guide the integration of LLMs into education \nwhile addressing scalability, adaptability, and ethical challenges.\n• Limited Research on Ethical and Pedagogical Challenges: While LLMs offer opportunities for personalized learn-\ning, significant concerns remain about data privacy, algorithmic bias, and ethical deployment [9 , 22, 37]. Current \nliterature lacks a comprehensive approach to balancing the pedagogical benefits of LLMs with the need to ensure \nethical AI usage in education.\n• Insufficient Exploration of Multi-Contextual Adaptability: Most existing studies focus on specific educational \nsettings (e.g., higher education) or particular tasks (e.g., grading automation or question answering) [7 , 10, 12]. \nThere is limited exploration of how LLMs can adapt to diverse learning environments, including K-12 education, \ndistance learning, and blended classrooms.\n• Absence of Comparative Analysis and Real-World Applications: Few studies offer real-world case studies or com-\nparative analyses of LLM implementations across educational contexts. This limits the practical understanding of \nhow LLMs can address challenges like student engagement, learning personalization, and content accessibility \nin varying academic settings [6 , 8, 36].\n• Addressing Educational Inequities: While LLMs have the potential to transform education, there is insufficient \nresearch on how these models can bridge educational inequities, such as access to high-quality learning resources \nfor underprivileged or marginalized communities [10, 15, 21].\n3  Methods and materials\n3.1  Research protocol\nThe study protocol refers to a plan and method to guide the analysis process. It provides a detailed analysis pro -\ncess, including the research questions to be addressed, a search strategy to identify relevant studies, inclusion and \nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\nexclusion criteria for study selection, methods for data extraction and synthesis, and methods for assessing the quality \nof selected studies Fig.  5 illustrates the proposed methodology.\n3.2  Planning the review\nThis phase lays the foundation for the systematic and structured approach of the SLR. During this phase, comprehensive \nguidelines are established to select the primary studies. By carefully planning the review, researchers can ensure that \nthe review process is well-structured, systematic, and methodologically sound, leading to reliable and valuable insights. \nThe critical aspects of this phase are defined below.\n3.3  Identification of the research questions\nThe primary objective of this study is to conduct an SLR that identifies, analyzes, and summarizes empirical evidence \nrelated to the use of LLM in education. The review focuses on using LLM in education for teachers, students, and par -\nticular types of learners.\nIt also focuses on issues and their solutions for LLM in education. The research questions and the motivation behind \neach question have been formulated to guide the review process to achieve this goal. Table  2 illustrates the research \nquestions.\nFig. 5  Flow of work\nTable 2  Research questions and motivation\nResearch questions Motivation\nRQ1: What is the history of LLMs? To know about the history of LLMs and evaluation of the LLMs model\nRQ2: What is the training and working process of LLMs? To know about the model of LLMs, their training process, and work-\ning\nRQ3: What is the role of LLMs in education and digital learning To know about the role of LLMs in education and the digital learning \nprocess\nRQ4: What is the process of implementing LLMs in higher education? To know about LLMs’ opportunities, challenges, barriers, and mitiga-\ntion techniques in higher education\nRQ5: what are the real-time education applications based on LLMs To know about some case studies of LLMs in education\nRQ6: What are the Key challenges and risks of applying LLMs in \neducation?\nTo know about the challenges related to the application of LLMs in \neducation\nRQ7: What are the solutions to the key challenges and risks of apply-\ning LLMs in education?\nTo know about different types of suggestions and methods that are \nused to prevent information\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\n3.4  Data sources selection\nData sources are the libraries from which the research studies should be retrieved. Four digital libraries have been \nchosen to extract the primary analyses. These digital librariesare IEEE Explore, Science Direct, the ACM Digital \nLibrary, and Springer Link [49]. The full text of the documents is searched to identify the prior studies. There are \nvarious options available to search each digital library for pertinent information. To find the most relevant literature, \nthe search strategy is modified to satisfy the needs of the respective data source. Selected data sources and the \nnumber of studies produced by search queries are illustrated in Fig.  6 and Table  3.\n3.5  Keywords searching\nA combination of keywords and search operators is used to identify relevant studies that address the research ques-\ntion or topic of the review. This step focuses on specific keywords and their synonyms chosen from the identified \nresearch questions, as indicated in Table  2, to create the search string. These keywords are combined using the’AND \nand’OR’ conditions in the order listed to complete the following search string [50]. Figure  7 and Table  4 illustrate \nthe process of formulating keywords.\nFig. 6  Query results\nTable 3  Query results from \ndata sources Data source Initial Title and Keywords Abstract Full Text Result\nIEEE Xplore 90 80 45 25\nScience Direct 80 65 50 35\nACM Digital Library, 200 120 50 30\nSpringer Link 120 50 45 35\nWiley 60 35 30 35\nResults 550 350 220 150\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\n3.6  Define inclusion and exclusion criteria\nInclusion and exclusion criteria are essential for ensuring objectivity and consistency in selecting studies for this \nsystematic literature review (SLR). These criteria were carefully designed to align with the study’s research objectives \nand ensure the quality and relevance of the included studies.\n3.6.1  Inclusion criteria\nThe following inclusion criteria were applied to select studies:\n• Time Frame (2018–2023): Studies published within this period were included to reflect recent advancements and \ntrends in the use of LLMs in education. This ensures the review captures up-to-date research and emerging insights.\n• Language (English): Only studies written in English were included to maintain consistency in interpretation and \nanalysis.\n• Focus on LLMs in Education: The selected studies must specifically address the application of LLMs, including \nChatGPT, in the educational domain. This criterion ensures alignment with the research questions and objectives.\n• Empirical Research: Studies involving practical experiments or empirical evaluations using specific datasets were \nprioritized to emphasize evidence-based findings.\n• Comprehensive Evaluation: Each chosen study must provide a detailed evaluation of the performance, opportuni-\nties, and challenges of LLMs in education.\n• Source Quality: The scope was limited to reputable journals, conferences, or books to ensure reliability and schol-\narly rigor.\nFig. 7  Keywords searching \nprocess\nTable 4  Search string \nformulation Keyword Synonym/Alternative word\nEducation (“program” OR “system”)\nChatGpt (“AI” OR “ML ”)\nApplication (“metrics” OR “classification”)\nMethods (“Techniques” OR “Framework”)\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\n3.6.2  Exclusion criteria\nStudies meeting the following criteria were excluded from the review:\n• Published Before 2018: Older studies were excluded to limit the scope to recent developments, given the rapid evolu-\ntion of LLM technology.\n• Irrelevant Focus: Studies that did not focus on LLMs or their applications in education were excluded to maintain \nrelevance to the research questions.\n• Lack of Empirical Analysis: Studies without empirical results, such as theoretical discussions or opinion pieces, were \nexcluded to prioritize measurable insights.\n• Absence of Performance Evaluation: Studies that failed to evaluate the performance or effectiveness of LLMs in edu-\ncation were excluded to ensure the findings contribute to actionable insights.\n3.6.3  Justification for criteria\nThe inclusion and exclusion criteria were designed to ensure that the selected studies:\n• Provide evidence-based insights relevant to the application of LLMs in education.\n• Align with the study’s focus on practical, empirical findings rather than theoretical or speculative discussions.\n• Reflect recent developments and emerging trends, ensuring the review’s relevance and significance.\n3.6.4  Quality assessment\nThe selected studies were further evaluated using the Modified CASP Checklist to assess their methodological rigor and \nrelevance. Table 5 illustrates the quality assessment criteria, focusing on critical aspects such as clarity of objectives, \nrelevance to LLM applications in education, and empirical robustness.\nThese criteria ensured consistency and objectivity in study selection, enhancing the reliability of the review process.\n3.7  Primary study selection\nThe primary studies selected for this review were curated using the tollgate approach, a structured five-phase method-\nology [50]. This approach ensured a systematic, transparent, and rigorous selection of studies aligned with the PRISMA \nguidelines.\n• Phase 1 (Identification): A comprehensive search was conducted across academic databases, including PubMed, IEEE \nXplore, Scopus, and Web of Science, using specific keywords and Boolean operators. The search focused on studies \npublished between 2016 and 2023 that explored LLM applications in education.\n• Phase 2 (Screening): Duplicates were removed, and titles and abstracts were screened based on the following inclu-\nsion criteria:\no Studies must focus on the application of LLMs (e.g., GPT models) in educational systems.\no Articles must be peer-reviewed and written in English.\no Only articles addressing LLM benefits, challenges, or implementation case studies were considered.\nTable 5  Quality assessment \ncriteria Sr# Quality assessment questions\nC1 Does the study provide enough information about the history of LLMs?\nC2 Does the study provide enough information about the model and training of LLMs?\nC3 Does the study provide enough information about LLM’s role in education?\nC4 Does the study provide enough information about LLM’s role in higher education?\nC5 Does the study provide enough information about LLMs’ challenges and their solu-\ntions in education?\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\no Exclusion criteria included non-peer-reviewed work, opinion articles, and studies unrelated to educational appli-\ncations.\n• Phase 3 (Eligibility): Full-text screening of the remaining articles was conducted to ensure alignment with the research \nobjectives. Reasons for exclusion (e.g., lack of relevance, insufficient methodological rigor) were recorded for transpar-\nency.\n• Phase 4 (Quality Assessment): The quality of selected articles was evaluated using the Modified CASP Checklist, focus-\ning on research design, clarity of objectives, validity, and relevance to the review. Articles scoring below a specified \nthreshold were excluded. A table summarizing quality scores can be included in supplementary materials if needed.\n• Phase 5 (Final Selection): Following quality assessment, 150 primary studies were selected for synthesis. Table 6 and \nFig. 8 provide a breakdown of studies by year, and the PRISMA flow diagram (Fig. 9) illustrates the overall process.\n3.8  Thematic analysis framework\nTo identify and synthesize recurring patterns and themes in the selected studies, this research employs the six-step \nthematic analysis framework proposed by Braun and Clarke [51]. This structured approach ensures a rigorous examina-\ntion of qualitative data. The process began with an in-depth familiarization stage, where the full-text articles of all 150 \nprimary studies were reviewed to gain a thorough understanding of their content. Repeated readings helped identify \nkey concepts and patterns related to the research questions.\nFollowing this, the data was systematically coded using qualitative data analysis software, focusing on identifying \nkey phrases and ideas relevant to LLMs in education. Initial codes included concepts such as “bias mitigation, ” “adaptive \nTable 6  Final paper selection Year Final selection\n2016 2\n2017 4\n2018 3\n2019 7\n2020 6\n2021 6\n2022 16\n2023 82\nFig. 8  Final paper selection\n\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\nlearning, ” “privacy concerns, ” and “teacher-AI collaboration. ” These codes were subsequently organized into broader \nthemes by grouping related concepts. For instance, themes like “ethical dilemmas, ” “pedagogical impacts, ” and “cultural \nconsiderations” were identified as central to the research objectives.\nThe identified themes underwent iterative review to ensure consistency and alignment with the data. Overlapping \nthemes, such as “bias detection” and “bias mitigation, ” were consolidated under the broader theme of “bias and fairness. ” \nEach theme was then clearly defined and scoped to capture its unique aspects. For example, the theme “cultural consid-\nerations” was defined as addressing the potential for LLMs to perpetuate dominant cultural norms while marginalizing \ndiverse perspectives.\nFinally, the themes were synthesized into actionable insights, which are presented in the Results (Sect.  4) and Dis-\ncussion (Sect. 5) sections. This synthesis provides a structured narrative of the opportunities, challenges, and solutions \nrelated to integrating LLMs into education. By following this rigorous thematic analysis framework, the study ensures \nthat its findings are both valid and methodologically sound.\n4  Result\n4.1  History of LLMs\nLLMs are subsets of AI models [52] that are capable of deciphering and analyzing human-created language and using \nthat knowledge to produce new text [53, 54]. LLMs are another term for language models. These models may be iden-\ntified by examining large amounts of text [55]. The first LLM was developed in the 1950s and 1960s. The idea of LLM \nwas initially put forward simultaneously. However, the models’ developers needed help handling the complex natural \nlanguage processing processes [56]. These models needed to improve their ability to understand English because of the \nrules and language characteristics that were put into them. These models also made use of language characteristics. The \ndevelopment of mathematical models reached its peak in the 1980s and 1990s. These models may calculate the prob -\nability of word sequences in a given context using probabilistic modeling approaches [57]. Even though ML algorithms \nhave proven to be capable of effectively analyzing large datasets, there have been challenges in interpreting language, \nparticularly contextual and semantic components [58].\nThe area of language modeling has grown significantly since the introduction of LLMs in the middle of the 2010s. The \nalgorithms used deep learning techniques to evaluate vast amounts of textual data to identify structures and patterns \nin language usage [59]. A significant advancement was made in 2010 with the release of the recurrent neural network \nFig. 9  PRISMA diagram\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\nlanguage model, which produced clearer text by effectively predicting context [60]. Following the 2015 release of Google \nNeural Machine Translation, the first neural machine translation application used globally, improved performance on \ntext samples from several countries was shown [33, 61].\nIn 2017, release of the Transformer model enabled language interactions and parallel training on many GPUs. In 2018, \nthe OpenAI-created GPT-1 model demonstrated its ability to produce appropriate comments for the context.\nGPT-3-LLM, the most powerful model ever built, was developed in 2020 using a two-phase technique that includes \nunsupervised pre-training and supervised tuning. As OpenAI continues to refine its GPT-4 model, there are significant \nimprovements in the system’s processing power and size [62].LLMs frequently raise the issue of bias and unintended \neffects. These factors highlight several difficulties, including the size and structure of the model, the quantity and quality \nof the training dataset, and other problems [62, 63]. Performance depends on the tasks and environments in which they \nare utilized, and LLMs are currently being developed. Programmers create software with human-like thought and behav-\nior patterns using ML and NN methods. Due to these techniques [64], they can offer enormous amounts of information to \nLLMs. Since the first applications of LLM techniques, NLP has made significant progress [65, 66]. These advancements have \nmade computers better at understanding human speech. LLMs might produce an instructional resource by gathering \ntextual information from many sources. A few applications that machine language can enable are chatbots, emotional \ndetection, translation, summarization, and advances in various industries, including banking, healthcare, and education.\nOne advantage of LLM is that one can work in various language-related businesses without completing further train-\ning. However, they are less useful in data analysis and evaluation because of their associations with several problems, \nsuch as biases and ethics issues [67]. Information systems [68], which include a variety of sources such as Wikipedia, \nnewspapers, documents, and social media, are frequently used as the subject of the LLM. Recognizing language pat -\nterns and relationships is essential for individuals to complete tasks, participate in conversations, and write effectively. \nThe LLM training process usually takes weeks or months and requires computing resources such as efficient GPUs and \nsufficient memory. Language interpretation [69], chatbots [70], summarization [71], and cognitive reasoning [72] rep -\nresent a group of many applications to which LLM can contribute. Moreover, this technology is also used to improve \nand speed up various language-related activities in fields such as banking [73], healthcare [74], and education [67]. LLM \nhas many advantages, including the ability to perform NLP-related tasks without special training. It can be attributed to \nthe experimental results because there are no clear instructions for performing specific tasks. In contrast, children can \nrecognize and use many forms of conversation and cooperation [75, 76]. However, LLM shows some limitations and prob-\nlems in its use, including ethics and injustice. In some cases, the scale and complexity of the LLM may create problems in \nunderstanding and evaluating the information contained, thus reducing its usefulness [67, 77]. Despite these difficulties, \nthe LLM has become essential in artificial intelligence. These developments can change our understanding of language \nand how we interact with others. The constant evolution of the LLM will make it more attractive in many areas [78]. Over \ntime, teachers have grown in size and complexity, allowing them to demonstrate an amazing ability to produce and \nunderstand language [79]. In addition, these techniques, such as language interpretation and question answering, are \nused in many NLP projects. However, as these structures become more complex, social and cultural problems such as \nunfairness and restrictions arise and require appropriate attention and solutions [76, 80]. Figure 10 illustrates different \nmodels of LLMs, and Table 7 presents a comparison of LLMs.\nModels with multiple variables provide a deeper understanding of the connections between words and concepts \n[65, 82]. It is also recommended that the structure of the model be considered. Some jobs can be done more efficiently \nFig. 10  Traning of LLMs\n\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\nTable 7  Comparison of various GPTs\nReferences Model Use Objective Year\n[47] GPT-1 General 12-level, 12-headed Transformer decoder (no encoder), followed by linear-softmax with Book Corpus: 4.5 GB of text 2018\n[22] GPT-2 General GPT-1, but with modified normalization with Web Text: 40 GB of text 2019\n[19] GPT-3 General GPT-2, but with modification to allow more extensive scaling with 570 GB plaintext 2020\n[81] InstructGPT Conversation GPT-3 fine-tuned to follow instructions using human feedback model 2022\n[48] ProtGPT2 Protein Sequences As GPT-2 large (36 layers) with Protein sequences from UniRef50 of a total of 44.88 million 2022\n[16] BioGPT Biomedical Content As GPT-2 medium (24 layers, 16 heads) with non-empty items from Pub-Med total 1.5 million 2020\n[17] ChatGPT Dialogue UsesGPT-3.5, and finetuned with both supervised learning and reinforcement learning from human feedback (RLHF) 2022\n[18] GPT-4 General Trained with both text prediction and RLHF and accepts both text and images as input, third-party data 2023\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\nusing one particular architectural style rather than another [83]. It is essential to consider the following parameters to \nevaluate LLM development effectiveness [84, 85].\n• Size of training data.\n• Good educational materials.\n• Number of parameters\n• Complexity of the model architecture.\n• Task evaluation model.\nIt is also important to note that LLMs are still under development, and their performancecan vary depending on the \nspecific task and the environment in which they are used.\n4.2  Training of LLMs\nLLM must be trained to be successful. The first phase usually involves collecting and creating a large amount of infor -\nmation gathered from a variety of sources. The main source of LLM education is carefully reviewed and recorded [86]. \nUnsupervised learning is a method commonly used in educational institutions. The model is trained to use past reports \nas a base for predicting future reports in a given sequence. This phenomenon is widely recognized and is called” language \nmodeling [87]. Modern neural network architectures (such as Transformer) create relationships between words and \nsentences in a language [84, 88]. To increase the probability that the model will be selected in the next sentence in the \ncontext, the training process tries to identify negative aspects of the model [88]. It is common practice to use stochastic \ngradient descent (SGD) to achieve this goal. Backpropagation is then used to update the parameters of the model con-\ntaining the back computation gradients. LLM Learns from multiple objective feedbacks at every level of training. The first \nlevel of this study is initial training, which includes LLM training on a mix of unsigned and private objects without human \nsupervision. The second stage is fine-tuning, which introduces narrower information and human feedback as access to \nsimple models [90]. The fine-tuned model can go to another level where people use techniques to turn the LLM into an \nexpanded model for doing the job.\n4.2.1  GPT‑3\nOne of the most advanced and well-known language models developed by OpenAI is GPT-3 [91]. This success generated \nsignificant interest and led to success in NLP [1 ]. The ability of GPT-3 to analyze complex networks and structures can \nbe attributed to its foundation in transformer-based architecture [86]. The use of transformers makes GPT-3 possible. \nDue to its multilayer transformers, the model can understand and reduce text at many levels of abstraction. GPT-3 has \nan amazing 175 billion elements, making it one of the most comprehensive LMs ever created. GPT-3’s training method \nmainly uses unsupervised learning using a lot of publicly available data. GPT-3 has a general understanding of English \ndue to its small size and large training data. These systems can create cross-topic articles that display human-authored \ncontent. This work is done by optimizing the size of GPT-3.\n4.2.2  Bidirectional\nBERT, or “Encoder Representation of Transformer, ” is a popular LLM model for solving complex NLP problems. Pre-training, \ntraining, and modification represent different aspects of the training process [92]. In pre-learning, BERT identifies many \nredundant words to complete the representation. The tasks adopted in this study include multilayer masking (MLM) and \nnext-sentence prediction (NSP). MLM improves the understanding of past and future content by clarifying a set of input \ntokens and training a model to predict the original tokens [93]. BERT influences NSP technology to improve understand-\ning of relationships by analyzing whether the second expression follows the first expression. The BERT system uses data \nannotations to focus on specific tasks later in the initial training session. BERT’s trained agents are designed for specific \npurposes, such as sentiment analysis and site recognition. Inverse processing and gradient descent are used to change \nthe properties of the model. Field Programmable Gate Array (FPGA), Tensor Processing Unit (TPU), and Graphics Process-\ning Unit (GPU) are required during BERT training [94]. The architecture of the BERT Transformer includes a sound input, \nresidual connection, and normalization layer. This shows that the system can exhibit the ability to describe relationships \nand large-scale interactions between elements [95].\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\n4.2.3  XLNet\nAn efficient method for resolving issues with conventional language modeling is to use the autoregressive pre-\ntraining technique that XLNet offers. Compared to traditional autoregressive models, XLNet is learned via switching \n[96]. Rather than relying on words found during training to generate predictions, XLNet analyzes all possible variants \nof the input and automatically predicts each variation’s probability. XLNet overcomes the limitations of sequential \nmodels, which are limited to continuous evolution from left to right. This is achieved due to the ability to display \nrelationships in both directions [79]. Unsupervised training is the first stage of XLNet training, and then there is a \nmaintenance phase [97]. XLNet can predict a word by considering all input points without human supervision in the \npre-training phase. The BERT model represents a change in design but contains significant changes. Using variables \nin XLNet training goals increases the complexity of some tasks. Compared to traditional auto-regressive models, \nXLNet requires a larger training size to cover more scenarios [98]. A set of multivariate auto regressive models can \nproduce predictions using the underlying concepts of source and effect. Completing the training process on the \ncomputer increases costs and requires techniques such as factorization sampling to constrain the evaluation of the \nlimited parameters of each training session. Another issue related to XLNet training is the huge demand for financial \nresources [99]. Due to its size and potential, it is essential to utilize additional memory and processing power. Training \non XLNet requires multiple GPUs or TPUs, resulting in longer processing times [89].\n4.2.4  T5\nDeveloped and trained by Google, T5-LM is very easy to teach. During the training, T5 published a lot of content \nthrough public announcements on its website. The goal is to create a simple way to teach words that can be used \nin different contexts. The thing about T5 is that it knows all the hard work of creating text. Converting text from one \nformat to another has been modified to simplify text-to-text conversion. Examples of these tasks include classify -\ning text, writing, interpreting, and analyzing questions. For example, S5 does not need to give specific answers to \nthe questions. However, users are advised to use all available information to complete the answer to the question. \nT5 was trained using a unique version of the Transformer architecture during initial training. Using the Transformer \nmodel [100] in T5 helps to accurately characterize the connection points at the entry, thus ensuring the stability of \nthe connection between parts. The primary purpose of pre-training in maximum possibility estimation is to guide \nT5 to identify important text information based on the input [101]. After initial training, T5 will receive further modi-\nfications in subsequent tasks [61]. One of the challenges in T5 training is the limited availability of all the necessary \ndocumentation for the various applications. The effectiveness of this model is affected by the quality and quantity \nof data [90]. Gathering job-specific information is necessary for accurate correction. T5 training can require a signifi-\ncant investment of time and resources. The computational complexity of the model increases due to the presence \nof transformers and a large number of pre-learning parameters in the model architecture.\n4.2.5  CTRL\nCTRL-LLM can convert user instructions and control codes into text format. The training process for this model \nconsists of two components: pre-training and validation. CTRL ’s initial training phase includes extensive knowledge \nthat is freely available [102]. Pre-training aims to give the model the necessary skills to understand and generate \nmeaningful  textual content according to various control codes or signals [103]. Transformer designs similar to BERT \n[104] and GPT models are used for educational purposes. A model’s predictive ability can be improved through train-\ning to analyze statistical patterns in language and grammatical structures to predict the following phrase in a given \nsentence. It is essential to perform this task in an organized environment. An important feature of CTRL is the ability \nto configure control messages and codes. The control code provided to the model acts as instructions and controls \nthe text generation process [ 105] based on user-selected parameters, such as styles and other text components. The \ncontrol code acts as a set of instructions that control the desired behavior of the model during both the training and \ninference processes [102]. The fine-tuning steps in the CTRL phase are the most important because they allow you \nto modify the model to adapt to a specific task or domain. The CTRL model is re-trained using a task-specific dataset \nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\ncontaining control code as part of the fine-tuning process. This model is trained to generate text that accurately \nrepresents the expected outcome after being provided with task-specific 531 inputs [106].\n4.3  Role of LLM’s in education\nThe impact of AI on institutions has been extensively examined in recent years. AI is essential in various domains, such \nas homework, assignments, course materials, and projects, and has seen significant changes following the release of \nChatGPT [107] by OpenAI. During the conducted tests [108], it was observed that it showed an efficiency rate of less \nthan 70%, indicating its potential failure to meet the requirements for AHA certification examinations. Nevertheless, the \nlimited availability of a single response by ChatGPT resulted in a biased outcome, leading to a significant estimation of \nits capabilities. The way the investigation was conducted proved to be a critical flaw in judgment. The current accuracy \nof ChatGPT in BLS and ACLS is 96% and 92.1%, respectively.\nTherefore, ChatGPT achieved good results in both tests, with 92 score. One of the advantages of integrating ChatGPT \nand AI agents into schools is their ability to get students to complete the task [109]. ChatGPT can save students time \nand energy by answering many questions while working. ChatGPT is recommended as it can provide guidance; bots \ncan also play a role in completing the grading process, thus reducing teachers’ workload and providing students with \npersonalized and unique feedback. Another advantage of using ChatGPT and AI bots in the classroom is their ability to \nfacilitate personalized learning. AI algorithms can analyze students’ past performance on assignments and tests to provide \nrecommendations for the future. Students can focus their efforts on these specific areas to maximize their performance \n[110]. Figure 11 shows the role of LLM in education. The non-profit organization, Khan Academy has expressed interest in \nexploring potential applications of ChatGPT within the framework of its daily operations. The technologically advanced \ntrade machine “Khanmigo” with artificial intelligence has been successfully implemented. Digital formats of teaching \nmaterials are useful for classroom teachers [111]. ChatGPT can promote personal relationships between teachers and \nstudents, thereby improving the quality of teaching and education.AI can reduce misconceptions about its use in teach-\ning and learning. Although AI is in the early stages of development, it can help students and meet their needs [112]. Using \nChatGPT and AI class teachers may lead to negative consequences. Questions have been raised regarding the impact of \nthese tools on children’s cognitive abilities to think critically and creatively. Overreliance on AI robots to complete tasks \nand experiments can prevent the development of skills such as critical thinking and problem-solving, which are critical \nfor success in the field of education. ChatGPT can provide valuable assistance in organizing classroom activities. The \nability of AI chatbots to be an excellent tool for creating educational content is essential and can be explored in many \nways. Course objectives, topics, syllabus, curriculum, assessment methods, learning engagement, and effective planning \ncan be communicated quickly and effectively. Because ChatGPT provides feedback after each session, courses can be \nimproved and modified based on input and observations from the model. The importance of ChatGPT as an additional \ntool that supports teachers’ ability to support and educate students cannot be ignored. The collaboration of humans \nand AI in curriculum design is very beneficial as it reduces the creation of efficient and effective. \nFig. 11  Role of LLMs in educa-\ntion\n\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\n4.4  Role of LLM’s in higher education\nThe use of LLM can help professionals, students and teachers in schools. Seven options are available for the LLMs. Two \nprograms are designed for professionals and teachers, and the remaining five are designed for students. The LLM under-\nstands itself as a tool that provides personalized lessons, explanations, and advice personalized to students’ specific \nquestions to help them learn independently. According to statistics, LLM can be considered an effective teaching tool \nthat provides personal feedback on students’ writing and encourages discussion by encouraging individuals to share \ntheir thoughts. Research on the previously mentioned subject backs up this claim [113]. Similarly, besides the usual \nclassroom equipment, LLM will be an additional tool to improve students’ knowledge retention and thinking skills. \nTherefore, research LLM can be an additional tool to provide theoretical answers and formulate published recommen-\ndations [114]. These components continue the work of the LLM and include communication skills, language therapy, \nand writing and language support. Incorporating these tools into the LLM can reduce enrollment by reducing barriers \nto entry into higher education.\nThe authors of [115] explain that LLM translation and remediation programs can increase the integrity of education by \nsupporting students who do not speak English. This is especially helpful for students whose families lack English skills. \nUsing appropriate keywords and descriptions will help organize the content to ensure no spelling or grammatical errors. \nFigure 12 illustrates the role of LLMs in students learning.\nAlso, LLM agrees to maintain ongoing support for students. People participating in remote or international research \nin countries with different opportunities may find this a helpful tool [67]. In existing studies, little attention is paid to the \nbenefits of the LLM. Integrated LLM into the curriculum can bring new, interactive learning to the benefit of students. \nAlthough possible, some exciting documentation exists on using LLM in developing digital learning ecosystems [116].\nInitially, the tool was designed to assist teachers and educators by providing timely advice, answers to everyday ques-\ntions, and guidance on frequently asked questions. Based on existing research, the LLM has many benefits for teachers. \nIn particular, it provides personalized learning support by allowing students to adapt resources and activities to meet \ntheir needs. Also, teachers can use LLM to match course objectives, learning outcomes, and standards [117]. Figure  13 \nillustrates the opportunities for using LLMs in higher education.\n4.4.1  Opportunities\nLLM has been used to create personalised learning materials since its development. Although it is still early, the above \nconclusions appear mostly theoretical or hypothetical. Until further empirical studies confirm the validity of these con-\ncepts, attention is advised in current practices. This strategy must be tested in the real world to verify its effectiveness. \nFinally, LLM students say they can contribute to science education through their ability to help generate ideas, analyze \ndata, and conduct reviews. This approach is supported by previous research showing that using LLM can improve the writ-\ning of training [115], promote collaboration, facilitate the organization of activities, and develop an environment helpful \nto creating good results [118]. Despite this concern, the negative impact of education on self-efficacy and independence \nis still a concern [ 119]. More education is needed on intellectual skills in research and writing. However, some authors \nFig. 12  LLM’s in students \nlearning\n\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\nhave begun to give general advice about the potential benefits of the LLM, which can lead to the writing process [27]. \nAccording to [119], it is essential to manage the risks sensibly, leading to research and significant results such as inquiry, \ncreativity, and discovery. However, the authors also emphasize the importance of ensuring the best results from AI. The \nauthors recognize that providing a link between the necessary human resources—education, training, and creativity—is \nessential for advancing scientific knowledge.\n4.4.2  Challenges\nLLM inaccuracy and lack of trust in data produced by artificial intelligence such as GenAI and its impact on higher educa-\ntion. Another question arises about how students use it. The teachers of Law face four main challenges: quality control, \ninformation and policy, formal education and communication, and collaboration. LLM strives to provide accurate and \nhelpful information; however, sometimes, it can give wrong or incorrect answers. It demonstrates the potential impact of \nbias in LLM and other GenAI systems on the reliability and quality of the information they provide [120]. For the benefit \nof all, the LLM recommends ongoing monitoring, bias awareness, and ongoing training in common sense skills as strate-\ngies to further reduce bias. LLM students often understand the limitations of their specific knowledge and experience \nprovided by professionally trained professors and teachers.\nUniversity education is limited to LLM and cannot provide students with depth of knowledge, rigorous analysis, and \nfocused learning. According to LLM, it is recommended that schools emphasize the role of teachers and teaching staff  \nin guiding students, and ensuring. Figure 14 shows the LLM’s opportunities in higher education.\nThe knowledge is built from intelligence, and providing necessary background knowledge, especially regarding qual-\nity control [121]. Previous research has not paid sufficient attention to two critical aspects: self-directed learning, com-\nmunication, and collaboration. Despite initial comments regarding its ability to enhance personal learning [122], the \nLLM is banned but has not yet been discovered. LLM only hopes for a customized education; some aspects of students’ \nneeds, such as their learning preferences, standards, and specific problems, may be ignored. This cannot communicate \neffectively about the small characteristics that distinguish one student from another. This example demonstrates the \nimportance of key faculty members in monitoring the use and implementation of LLMs in an academic environment. The \nthird problem is the barrier to cooperation and communication between university students. The need for collaboration \nin group work and other learning activities will reduce their overall effectiveness. Individual responses to the teachers \nshow that although technology has its advantages, it has not yet reached a level that could fundamentally change the \nhuman condition. For this reason, those who want to use it in education should provide the necessary training to teachers \nto use it effectively and reduce the harmful effects listed above. LLM raises another concern regarding the abuse of their \npowers, particularly their lack of integrity in education. According to the master’s thesis, students may use the model \nto copy content from other sources or engage in dishonest learning by cheating on assignments and exams. Whether \nuniversities should ban this technology entirely is a matter of ongoing debate, mainly because it has many aspects in \nthe educational process [123]. Figure 15 shows the challenges faced by higher education using LLM Plagiarism and other \nforms of academic dishonesty are problems in higher education and have led to extensive research on this topic [124]. \nFig. 13  Role of LLMs in digital \neducation\n\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\nHowever, due to the novelty of ChatGPT and the lack of working methods, the risk associated with ChatGPT is high. Recent \nresearch shows that schools may not know how to manage the best strategies for students using AI applications. It is \nobserved that from 142 schools reviewed in May 2023, only one was found to have implemented a policy prohibiting the \nuse of artificial intelligence [125]. This decision is important because it contradicts previous research [126] showing that \nlearning unfairness is reduced when people are aware of and follow the principles of fairness theory. This demonstrates \nthe potential impact of following academic integrity principles in reducing cheating in education.\nUniversities must establish a clear policy to prepare them to use the Master’s degree as a teaching method and assess-\nment tool. The need to update the code of ethics stops he need to resolve problems caused by Gen-AI tools. Students \nneed to evaluate the changes in the use of artificial intelligence technology and the consequences that may arise if the \ncontent they use is not followed [125]. The nature of artificial intelligence creates severe challenges in developing general \nlaws to address the changing problems arising from artificial intelligence. Consistent with existing research, it has been \nshown that students are more likely to engage in immoral behavior, such as lying, when they see that they are less likely to \nbe detected [126]. Therefore, a cultural environment thatrejects unfair learning can be fostered through the use of GenAI.\n4.4.3  Barriers\nLLM analyzed the challenges that universities face when using GenAI technology. The impact of factors such as \nethical and privacy concerns, collaborative governance, resource constraints, complex legal and regulatory environ-\nment navigation, and general misunderstanding is significant. LLM provided valuable insight into the challenges \nFig. 14  LLM’s opportunities in \nhigher education\nFig. 15  Challenges in higher \neducation using LLM\n\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\nuniversities may face during deployment [127]. However, many of these challenges remain unexplored, providing \ntime for further analysis. These measures should improve teachers’ and students’ understanding of integrating ethi -\ncal AI into education. Many of the challenges to be aware of include confidentiality, ethical considerations, and the \nquality and consistency of the study. According to [127, 128], expanding the right to self-determination should take \ninto account how crucial it is to redefine what responsibility means. Responsibility and control of intellectual property \nultimately rest with the user. Therefore, it is essential to conduct timely research on intelligence ethics in education. \nUltimately, the outcome of this effort should be the eventual establishment of laws regarding the fair use of intel-\nlectual property in schools. Therefore, more research on the ethics of quick intellectual property rights in education \nis urgently needed, as are efforts to promote the exchange of information and provide rapid training [129]. Schools \nwith limited budgets or short staff might face challenges in taking advantage of the resources offered through Chat -\nGPT. Similarly, using Gen-AI will require new tools, such as efficient processing systems and reliable internet connec -\ntions. This means that universities that do not have sufficient resources cannot benefit from the advantages of LLM. \nAlthough universities have the opportunity to do this, they may still face resistance when implementing changes. \nEmployers, managers, and academic staff may prefer traditional courses. Recent research suggests that ChatGPT in \nclassroom planning and assessment can yield significant improvements [130].\nAdditionally, efforts will be made to provide training and facilitate information sharing among key stakehold-\ners, such as teachers and students, to improve their understanding and knowledge of female students. According \nto LLM’s review, schools with limited financial resources or inadequate staff may face difficulties using the current \nsystem. Similarly, effective use of Gen-AI technology will require robust network connectivity and high-performance \nhardware. This means that universities that do not have the necessary resources cannot benefit from the quality \nof the LLM. It was thought that universities could be successful with financial constraints by acting unfairly. In this \ncase, they will encounter resistance when using the changes. Employees, managers, and professionals may prefer \ntraditional methods or resist integrating ChatGPT into their operations. Recent research shows that using ChatGPT \nin lesson planning and evaluation can increase effectiveness [130]. As we increase the use of ChatGPT in educational \nenvironments, publishing research studies on ChatGPT is essential. A limitation is that proving its quality may lead \nto more problems in the real world. According to a recent study, it was found that students have a positive attitude \ntowards Gen-AI technology and consider using it regularly as a habit pattern [127]. Most of the research focuses on \nthe LLMs, an Internet-based platform designed to enable students to engage in peer-to-peer discussions beyond \nthe boundaries of traditional education. Universities, therefore, have a unique opportunity to reflect on the ethical \nfoundations of AI research and teach students behaviors that support these values. This is important to ensure that \nAI models such as LLM promote ethical standards, protect student rights, and enhance educational opportunities. \nFigure 16 shows the constraints in higher education.\nFig. 16  Constraints in higher \neducation\n\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\n4.5  Key challenges and risks related to the application of LLMs in education\n4.5.1  Difficulty to distinguish model‑generated from student‑generated answers\nTeachers now have a particular job to find who wrote something on paper. They must deal with growing difficulty in telling \nif it was made by a computer or human [131]. So, the New York City Department of Education stopped using ChatGPT. They \nwon’t let it into schools or networks anymore [132]. The writer of [131] has suggested many ways to find and sort text made \nby LLMs, like ChatGPT. People will also expect how helpful new tools like GPTZero can be. This tool uses confusion to find out \nif the language came from AI. It’s a way of measuring how good an agent is at understanding different things. A common \ngoal of modern methods is to use watermarks for content created by LMs [133]. A way to do this is by pushing material that \nuses unusual mixes of words.\n4.5.2  Cost of training and maintenance\nSome educational institutions may have financial constraints that prevent them from administering the existing LLMs [67]. \nA potential way to overcome this challenge is through the joint use of advanced education models, cloud technology, and \nrecommendations developed in collaboration with businesses and schools.\n4.5.3  Data privacy and security\nThe use of LLMs Changes in the learning environment raises concerns about the protection and privacy of student informa-\ntion [134]. This is because student information is generally considered confidential. The report addresses issues such as data \nbreaches, un-authorised access to student information, or misuse of student information for financial growth [133, 134].\n4.5.4  Sustainable usage\nTo make great efforts, spending a lot of money is necessary. Schools must use energy-efficient technologies to ensure envi-\nronmental sustainability and integrate systems based on renewable energy sources [135], such as cloud computing. This \napproach is essential for the school’s success and future growth [136]. Standard training and correction materials should be \nlimited to legal, ethical, and adequate information. Therefore, a management structure that includes policies, procedures, \nand controls must be in place to ensure that the implementation of these standards is successful. Likewise, for the model \nto be used in a reliable, ethical, and stable manner in the long term, it must have features such as openness, objectivity, and \ncontinuous evaluation.\n4.5.5  Cost to verify the information and maintain the integrity\nThe data model must be monitored with approval from a reliable external source to ensure the originality and accuracy of the \nmodel. Also, consider the costs associated with regularly updating and maintaining the model to ensure it always provides \naccurateresults. This protection is taken to ensure that the model performs its planned function.\n4.5.6  Difficulty in distinguishing between actual writing and model output\nThe writing ability of the LLM resembles human writing, which allows students to distinguish between suggestions and \nunreliable information. As a result, students are more likely to accept false or misleading information without inquiring \nabout its accuracy. In addition to recent debates about the accuracy and completeness of data, student’s ways of research-\ning, examining, and evaluating data for identification, verification, and uttering their opinions are essential for reducing the \nrisk of this gender.\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\n4.5.7  Lack of adaptability\nBecause master’s degrees cannot meet different needs, they may not provide students and faculty with the flexibility \nneeded for effective learning. Future data may be more flexible, although current technology prevents them from \nbeing flexible [137]. Figure  17 shows the main challenges of LLMs in education.\n4.6  Solution of challenges\n4.6.1  Teachers may rely too heavily on the model solution\nThere are many ways to solve these problems.\n• Teachers have access to modern technology that will encourage children to think and create original solutions.\n• Educational activities that use technology to develop children’s thinking and problem-solving skills. Students should \nparticipate in independent, creative activities that allow them to develop and apply their ideas and methods.\n• Monitor the use of LLMs in the classroom through assessment and evaluation to ensure they do not interfere with \nstudent learning.\n• To encourage teachers and schools to develop the teaching of group work. It involves using models and other meth-\nods to find and evaluate the information needed for a resource project.\n4.6.2  Lack of understanding and expertise solution\nBelow are different approaches to addressing these issues and accepting this risk.\n• LLMs in educational institutions that require assessment and case-based supportfor teachers and students to use \nthe LLM safely and ethically. The introduction and use of MLM in the classroom should be introduced to teachers and \nschools through training and continuing education. Training and continuing education programs allow educators to \nlearn more about the benefits and uses of LLMs in the classroom.\n• Teachers and schools can learn more about using LLMs in the classroom using open educational resources such as \ntutorials, research, use cases, etc.\n• Encourages educators and teachers to participate in active groups (such as professional learning communities). LLMs \nallow them to share resources and benefitfrom each other.\n• LLMs require continuous analysis and feedback on their applications to ensure correct use and change courses as \nnecessary.\nFig. 17  Key challenges\n\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\n4.6.3  Difficulty to distinguish model‑generated from student‑generated answers solution\nTherefore, to ease the impact of this situation, you should prioritize the following in your strategy:\n• Professionals must review issues such as transparency, interpretation, measurement, and analysis to differentiate \nbetween human and computer-generated data.\n• To support and encourage the creation of courses and instruction for the new and effective use of teachers.\n4.6.4  Cost of training and maintenance solution\nThe following points should be considered when trying to reduce this risk. The graphical representation of the solution \nis illustrated in Fig. 18:\n• It uses previously studied, publicly available models that can be adapted to a variety of specifications.\n• The aim is to create and explore partnerships with various organizations, cluding businesses, schools, governments, \nand charities. These collaborations 851 focus on financial support, resources, and expertise to facilitate the imple -\nmentation of LLMs in education.\n• Use scalable computing services (such as cloud)\n4.6.5  Data privacy and security solution\nThe following points are needed to solve this issue:\n• The General Data Protection Regulation, the Health Insurance Portability and Accountability Act, and the Family \nEducational Rights and Privacy Act are just a few examples of the legal and moral guidelines that must be followed \nwhile gathering, storing, and using student data.\n• The students’ relatives must communicate and accept the rules regarding collecting, storing, and using student data.\n• Privacy-protecting analysis approaches, current encryption and federation techniques, and other measures should \nbe implemented to prevent hacking, unauthorized access, and unethical use of gathered data.\n4.6.6  Sustainable usage\nSome examples of materials and equipment that improve energy use are.\n• Hardware and electrical equipment that use renewable energy, low training, andresearch to reduce maintenance \ncosts (such as simplified algorithms, data representation, and storage),\n• Ethics and exposes, processing and storage, evaluating legal documents and identifying bias, and using transparent \nand interpretive processes to prevent bias.\nFig. 18  Solution of challenges\n\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\n4.6.7  Cost to verify the information and maintain the integrity of the solution\nWhen addressing this risk, a risk management plan should include the following:\n• The model must be regularly updated with new written information to ensure consistency in producing current and \naccurate results. Ensure the accuracy and reliability of data by verifying data with multiple reliable sources. Improve \nassessment and authorization by combining the insights and expertise of teachers or experts with established stand-\nards.\n• The user points out the development of a combined process and method for evaluating the accuracy of predictive \nmodels [138].\n• Provide clear and precise information about the model’s performance, highlight its strengths and weaknesses, and \nidentify insights and practical applications.\n• Regular monitoring is essential. It is important to identify errors and other potential problems. These resources can \nhelp teachers and students implement strategies, understand research results, and evaluate the collected data [138].\n4.6.8  Lack of adaptability solution\nThe following steps are taken to overcome this issue:\n• Adaptive learning technologies influence student data, including their learning styles and prior knowledge, to per -\nsonalize the model’s output to provide for the unique needs of each student.\n• The customization of learning and teaching extends to various media, including text, audio, video, and practical \nexperimentation, ensuring engagement and effectiveness.\n• Customization of the language model’s output is achievable by aligning it with the instructor’s teaching style and the \nspecific course topic, utilizing insights provided by the teacher.\n• Learning materials that are both individualized and targeted become feasible through hybrid approaches. These \napproaches merge the advantages of human instructors with those of language models, taking into account teach-\ners’ feedback, guidance, and support.\n• Regular evaluation and standard development are essential, especially in classroom applications. This ensures that \nthe model delivers an accurate and efficient learning experience.\n• Continuous research and development aims to create more flexible models that meet the needs of students and \nteachers. This constant change is designed to improve learning skills.\n5  Discussion\nThe integration of LLMs, such as ChatGPT, into education represents a transformative opportunity but also raises mul-\ntifaceted challenges that must be carefully considered. This section provides a critical analysis of the benefits, risks, and \nactionable strategies related to LLM deployment, incorporating ethical dilemmas, cultural considerations, and pedagogi-\ncal impacts to ensure a balanced perspective.\n5.1  Opportunities for education stakeholders\nThe opportunities provided by LLMs extend to educators, students, institutions, and policymakers, with far-reaching \nimplications for improving educational systems:\n• For Educators:\no Enhanced Curriculum Development: LLMs streamline curriculum creation by generating tailored content, exer -\ncises, and lesson plans aligned with diverse student needs [34]. This allows educators to focus on higher-order \ntasks, such as fostering critical thinking.\no Time Efficiency through Automation: Automating grading and feedback processes enables teachers to dedicate \nmore time to mentorship, classroom interaction, and personalized guidance.\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\no Personalized Tutoring: LLM-powered tools support real-time, adaptive tutoring for individual learners, addressing \ngaps in knowledge and engagement. However, it remains critical that educators oversee these tools to ensure \npedagogical alignment.\n• For Students:\n• Individualized Learning Paths: By adapting to students’ learning paces, styles, and preferences, LLMs facilitate inclusive \nand personalized learning experiences [9 ]. This is particularly valuable for students in underserved or remote areas.\n• Language and Accessibility Support: Tools such as real-time translators and speech recognition systems improve \naccess for non-native speakers and students with disabilities, fostering equity in education [33].\n• Improved Engagement: Intelligent tutoring systems and AI-powered simulations promote interactive and immersive \nlearning experiences, increasing motivation and retention.\n• For Policymakers and Institutions:\n• Administrative Optimization: LLMs automate processes like student performance analysis, feedback aggregation, \nand course recommendations, enabling data-driven decision-making.\n• Policy Development: Policymakers can leverage AI insights to create policies addressing digital education challenges, \nsuch as accessibility, data privacy, and ethical use.\n• Cost Efficiency: Institutions can reduce operational costs through AI automation while enhancing resource allocation \nfor targeted improvements.\n5.2  Challenges and mitigation strategies\nDespite their promise, LLMs present critical challenges that must be addressed to ensure ethical, responsible, and effec-\ntive deployment in education.\n5.2.1  Ethical and pedagogical considerations\n• Overreliance on AI Tools: Excessive dependence on LLMs may undermine teachers’ roles as mentors and students’ \ndevelopment of critical thinking and problem-solving skills [8 , 38].\nMitigation: Encourage teacher-AI collaboration where educators use LLMs as assistive tools rather than replacements. \nProfessional development programs can train teachers to integrate AI responsibly.\n• Bias in AI Outputs: LLMs may reflect societal, cultural, or linguistic biases present in training datasets, leading to dis-\ncriminatory outcomes [21, 37].\nMitigation: Implement bias detection and mitigation frameworks, such as regular audits, diverse training datasets, \nand algorithm transparency, to ensure fairness and inclusivity.\nWhile previous studies [21, 37] have underscored the risks of algorithmic bias in AI-driven tools, our findings contrib-\nute to this discussion by emphasizing the importance of culturally diverse datasets and proposing specific mitigation \nstrategies, such as bias audits and inclusive training frameworks.\n• Cultural Sensitivity: LLMs risk perpetuating dominant cultural norms at the expense of local or marginalized perspec-\ntives.\nMitigation: Promote the development of context-aware AI tools that accommodate linguistic diversity and cultural \nnuances to foster inclusive education.\n5.2.2  Data privacy and security\nHandling sensitive student data raises concerns about privacy breaches and misuse. Institutions must:\n• Adopt robust encryption and anonymization techniques to protect personal data.\n• Ensure compliance with global regulations (e.g., GDPR, FERPA) through clear governance policies.\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\n• Provide regular training for educators and administrators on privacy standards.\n5.2.3  Sustainability and environmental concerns\nLLM deployment consumes substantial energy, contributing to environmental impact. Strategies to address this include:\n• Utilizing energy-efficient AI models optimized for educational use.\n• Collaborating with technology providers to integrate renewable energy solutions for data centers.\n• Supporting research into sustainable scaling practices for AI technologies.\n5.2.4  Regulatory and governance challenges\nThe lack of clear governance frameworks complicates the ethical and legal implementation of LLMs in education. Insti-\ntutions must:\n• Collaborate with policymakers and legal experts to develop regulatory guidelines for AI use.\n• Establish ethical oversight committees to monitor LLM deployments and ensure transparency.\n5.3  Critical pedagogical impacts\nLLMs have far-reaching implications for pedagogical practices. While they enhance automation and personalization, \nthey also require critical reflection on their role in teaching and learning:\n• Maintaining Human-Centric Learning: Teachers remain indispensable in fostering creativity, emotional intelligence, \nand higher-order thinking, which cannot be replaced by AI tools.\n• Promoting Critical Thinking: LLMs should supplement teaching by enabling students to question and evaluate AI-\ngenerated outputs, developing critical digital literacy.\n• Balancing Equity and Access: Institutions must ensure that LLM deployment does not widen the digital divide by \npromoting accessibility for all learners, particularly in low-resource environments [21].\n5.4  Practical recommendations\nTo ensure the responsible and effective use of LLMs, this study proposes actionable recommendations for key \nstakeholders:\nFor educators:\n• Integrate LLMs as tools for lesson planning, content personalization, and automated feedback while preserving human \noversight.\n• Participate in professional development programs to learn effective collaboration with AI systems.\nFor policymakers:\n• Develop regulatory frameworks for ethical AI deployment, data privacy, and fairness.\n• Provide funding for research into energy-efficient, inclusive, and bias-aware AI models.\nFor researchers:\n• Explore bias detection algorithms and strategies for fairness in LLMs.\n• Develop energy-efficient AI architectures to minimize environmental impact.\n• Investigate contextual adaptations of LLMs to ensure cultural and pedagogical relevance.\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\n5.5  Summary of key insights\nThe integration of LLMs in education offers significant opportunities, including enhanced personalization, adminis-\ntrative optimization, and accessibility improvements. However, the deployment of these tools raises complex ethical, \ncultural, and pedagogical challenges that require proactive strategies.\nBy addressing data privacy, mitigating biases, promoting human-AI collaboration, and supporting sustainability, \nLLMs can be effectively integrated into education to create a balanced, inclusive, and adaptive learning environment.\nThis study contributes to the existing literature by not only identifying the challenges and opportunities of LLMs \nin education but also proposing a structured theoretical framework and actionable strategies that address underex -\nplored areas such as ethical dilemmas, cultural inclusivity, and the role of LLMs in specific learner populations. These \ncontributions provide a foundation for future research and real-world implementation.\n6  Conclusion\n6.1  Recapitulation\nThis study explored the transformative potential of LLMs like ChatGPT in education, highlighting their role in enhanc -\ning personalized learning, supporting educators, and improving accessibility. The article proposed a novel theoretical \nframework for integrating LLMs in educational settings, focusing on personalized learning models, ethical considera-\ntions, and adaptability across diverse contexts.\nWhile LLMs offer significant opportunities, the study also identified key challenges, including privacy concerns, \nethical biases, energy consumption, and regulatory compliance. By adopting ethical deployment practices, sustain-\nable scaling solutions, and teacher-AI collaboration strategies, these challenges can be mitigated.\n6.2  Future directions\nTo ensure the responsible and effective integration of LLMs into education, future research should address the fol-\nlowing key areas:\n• Best Practices for Integration\no Develop comprehensive frameworks to guide educators on the optimal use of LLMs in classrooms while aligning \ntheir deployment with learning objectives and curricula.\no Explore methods for integrating LLMs into blended learning environments, ensuring they complement human-\nled instruction without compromising pedagogical standards.\no Investigate effective training programs for educators, enabling them to leverage LLMs to enhance teaching qual-\nity and student engagement.\n• Bias Detection and Mitigation\no Design and implement bias-detection algorithms to monitor and reduce biases in LLM outputs, particularly in \ndiverse educational contexts.\no Explore techniques for creating fair and diverse training datasets to minimize systemic biases and ensure equity \nacross student groups.\no Study the impact of bias on educational outcomes and develop strategies to address unintended consequences \nin LLM-driven applications.\n• Privacy and Security Enhancements\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\no Investigate advanced data encryption techniques and anonymization protocols to safeguard sensitive student \ninformation during LLM deployment.\no Develop privacy-preserving frameworks that comply with evolving data protection regulations (e.g., GDPR, \nFERPA).\no Study the risks associated with data storage and sharing in AI-powered educational tools and propose secure \nimplementation practices for institutions.\n• Energy Efficiency and Sustainability\no Promote research on low-energy LLM architectures optimized for educational tasks, reducing computational \nand environmental costs.\no Explore the integration of renewable energy solutions and energy-efficient hardware for AI infrastructure in \neducational settings.\no Develop frameworks for sustainable AI scaling, ensuring that LLM adoption aligns with global environmental \npriorities.\n• Human-Centered AI Collaboration\no Study how LLMs can best support teachers in curriculum design, content generation, assessment automation, \nand personalized student feedback.\no Investigate strategies to maintain the critical role of teachers in fostering human interaction, mentorship, and \ncritical thinking.\no Examine the professional development needs of educators to ensure effective collaboration between human \nteachers and AI tools.\n• Regulatory and Ethical Compliance\no Focus on developing clear guidelines for policymakers to regulate LLM use in educational institutions, including \nethical AI deployment, accessibility standards, and legal compliance.\no Explore frameworks to ensure transparency and accountability in LLM implementation, addressing concerns \nabout fairness, bias, and ethical use.\no Promote cross-disciplinary collaboration among educators, policymakers, and legal experts to address regulatory \nchallenges.\nBy addressing these future directions, researchers, educators, and policymakers can ensure the responsible, ethi-\ncal, and sustainable integration of LLMs in education. These efforts will enable LLMs to enhance learning experiences, \nempower teachers, and address systemic challenges while minimizing potential risks and unintended consequences.\nAcknowledgements The researchers would like to University of Johannesburg, South Africa, for funding support.\nAuthor contributions All authors have equally contributed. Tariq Shahzad and Tehseen Mazhar perform the Original Writing Part, Software, and \nMethodology, Muhammad Usman Tariq and Tehseen Mazhar perform Rewriting, investigation, design Methodology, and Conceptualization, \nHabib Hamam, Wasim Ahmad and Tehseen Mazhar perform related work part and manage results and discussions, Habib Hamam, Khmaies \nOuahada and Tehseen Mazhar perform related work part and manage results and discussion, Khmaies Ouahada, Tariq Shahzad, Muhammad \nUsman Tariq  and Wasim Ahmad perform Rewriting, design Methodology, and Visualization, Tehseen Mazhar and Wasim Ahmad performs \nRewriting, design Methodology, and Visualization.\nFunding The research work is supported by research fund from University of Johannesburg, South Africa.\nData availability No datasets were generated or analysed during the current study.\nDeclarations \nEthics approval and consent to participate Not applicable.\nCompeting interests The authors declare no competing interests.\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\nOpen Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which \npermits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to \nthe original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You \ndo not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party \nmaterial in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If \nmaterial is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds \nthe permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco \nmmons. org/ licen ses/ by- nc- nd/4. 0/.\nReferences\n 1. Sha L, et al. Assessing algorithmic fairness in automatic classifiers of educational forum posts, in Artificial Intelligence in Education: 22nd \nInternational Conference, AIED 2021, Utrecht, The Netherlands, June 14–18, 2021, Proceedings, Part I 22. 2021 Springer.\n 2. Schramowski P , et al. Large pre-trained language models contain human-like biases of what is right and wrong to do. Nat Mach Intell. \n2022;4(3):258–68.\n 3. Liu S, Huang X. A Chinese question answering system based on gpt. in 2019 IEEE 10th International Conference on Software Engineering \nand Service Science (ICSESS). 2019. IEEE.\n 4. Wollny S, et al. Are we there yet? A systematic literature review on chatbots in education. Front Artif Intell. 2021;4: 654924.\n 5. Mallek F, et al. A review on cultivating effective learning: synthesizing educational theories and virtual reality for enhanced educational \nexperiences. PeerJ Comput Sci. 2024;10: e2000. https:// doi. org/ 10. 7717/ peerj- cs. 2000.\n 6. Analytica O. GPT-4 underlines mismatch on AI policy and innovation. Emerald Expert Briefings, 2023(oxan-es).\n 7. Shrivastava A, Pupale R, Singh P . Enhancing aggression detection using GPT-2 based data balancing technique. in 2021 5th International \nConference on Intelligent Computing and control systems (ICICCS). 2021. IEEE.\n 8. Zheng X, Zhang C, Woodland PC. Adapting GPT, GPT-2 and BERT lan- guage models for speech recognition. in 2021 IEEE Automatic \nSpeech Recognition and Understanding Workshop (ASRU). 2021. IEEE.\n 9. Devlin J, et al. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv: 1810. 04805, 2018.\n 10. Olney AM. Generating multiple choice questions from a textbook: LLMs match human performance on most metrics. in AIED Workshops. \n2023.\n 11. Pathak A. Exploring Chatgpt: an extensive examination of its background, applications, key challenges, bias, ethics, limitations, and \nfuture prospects. Applications, Key Challenges, Bias, Ethics, Limitations, and Future Prospects.\n 12. Schneider ETR, et al. A GPT-2 language model for biomedical texts in Por- tuguese. in 2021 IEEE 34th international symposium on \ncomputer-based medical systems (CBMS). 2021. IEEE.\n 13. Brown T, et al. Language models are few-shot learners. Adv Neural Inf Process Syst. 2020;33:1877–901.\n 14. Vaswani A, et al. Attention is all you need. Advances in neural information processing systems, 2017. 30.\n 15. Sridhar P , et al. Harnessing llms in curricular design: using gpt-4 to support authoring of learning objectives. arXiv preprint arXiv: 2306. \n17459, 2023.\n 16. Luo R, et al. BioGPT: generative pre-trained transformer for biomedical text generation and mining. Brief Bioinf. 2022;23(6):bbac409.\n 17. Hill-Yardin EL, et al. A Chat (GPT) about the future of scientific publishing. Brain Behav Immun. 2023;110:152–4.\n 18. Nori H, et al. Capabilities of gpt-4 on medical challenge problems. arXiv preprint arXiv: 2303. 13375, 2023.\n 19. Wu T, et al. A brief overview of ChatGPT: the history, status quo and potential future development. IEEE/CAA J Automatica Sinica. \n2023;10(5):1122–36.\n 20. Biswas SS. Role of chat gpt in public health. Ann Biomed Eng. 2023;51(5):868–9.\n 21. Ahmad I, et al. Analysis of security attacks and taxonomy in underwater wireless sensor networks. Wirel Commun Mob Comput. \n2021;2021:1–15.\n 22. Zhou C, et al. A comprehensive survey on pretrained foundation models: A history from bert to chatgpt. arXiv preprint arXiv: 2302. 09419, \n2023.\n 23. Lee P , Bubeck S, Petro J. Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine. N Engl J Med. 2023;388(13):1233–9.\n 24. Lancaster T. Artificial intelligence, text generation tools and ChatGPT–does digital watermarking offer a solution? Int J Educ Integr. \n2023;19(1):10.\n 25. Huang X, Zou D, Cheng G, Chen X, Xie H. Trends, research issues and applications of artificial intelligence in language education. Educ \nTechnol Soc. 2023;26(1):112–31.\n 26. Tan Y, et al. Evaluation of ChatGPT as a question answering system for answering complex questions. arXiv preprint arXiv: 2303. 07992, \n2023.\n 27. Kohnke L, Moorhouse BL, Zou D. ChatGPT for language teaching and learning. RELC J. 2023: p. 00336882231162868.\n 28. Yousafzai BK, et al. Student-performulator: student academic performance using hybrid deep neural network. Sustainability. 2021. \nhttps:// doi. org/ 10. 3390/ su131 79775.\n 29. Mahmood F, et al. Implementation of an intelligent exam supervision system using deep learning algorithms. Sensors. 2022. https://  \ndoi. org/ 10. 3390/ s2217 6389.\n 30. Sudirjo F, et al. Application of ChatGPT in improving customer sentiment analysis for businesses. Jurnal Teknologi Dan Sistem Informasi \nBisnis. 2023;5(3):283–8.\n 31. Wang F-Y, et al. What does ChatGPT say: the DAO from algorithmic intelligence to linguistic intelligence. IEEE/CAA J Automatica Sinica. \n2023;10(3):575–9.\n 32. Suri G, et al. Do large language models show decision heuristics similar to humans? A case study using GPT-3.5. arXiv preprint arXiv:  \n2305. 04400, 2023.\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\n 33. Akbar NA, et al. Deep learning of a pre-trained language model’s joke classifier using GPT-2. J Hunan Univ Nat Sci. 2021; 48(8).\n 34. Hagendorff T, Fabi S, Kosinski M. Machine intuition: uncovering human- like intuitive decision-making in GPT-3.5. arXiv preprint arXiv:  \n2212. 05206, 2022.\n 35. Motlagh NY, et al. The impact of artificial intelligence on the evolution of digital education: a comparative study of OpenAI text genera-\ntion tools including ChatGPT, Bing Chat, Bard, and Ernie. arXiv preprint arXiv: 2309. 02029, 2023.\n 36. Peng K, et al. Towards making the most of chatgpt for machine translation. arXiv preprint arXiv: 2303. 13780, 2023.\n 37. Caines A, et al. On the application of Large Language Models for language teaching and assessment technology. arXiv preprint arXiv:  \n2307. 08393, 2023.\n 38. Zawacki-Richter O, et al. Systematic review of research on artificial intelligence applications in higher education–where are the educa-\ntors? Int J Educ Technol High Educ. 2019;16(1):1–27.\n 39. Lund BD. A brief review of ChatGPT: its value and the underlying GPT technology. Prepr. Univ. North Texas. Proj. ChatGPT Its Impact Acad. \nDoi, 2023. 10.\n 40. Cheng SW, et al. The now and future of ChatGPT and GPT in psychiatry. Psychiatry Clin Neurosci. 2023.\n 41. Jain V, et al. The prospects and challenges of ChatGPT on marketing re- search and practices. Emmanuel, The Prospects and Challenges \nof ChatGPT on Marketing Research and Practices (March 23, 2023), 2023.\n 42. Petrovic N. ChatGPT-based design-time DevSecOps. preprint, 2023.\n 43. Lecler A, Duron L, Soyer P . Revolutionizing radiology with GPT-based models: current applications, future possibilities and limitations \nof ChatGPT. Diagn Interv Imaging. 2023;104(6):269–74.\n 44. Ray PP . ChatGPT: a comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope. Internet \nof Things and Cyber-Physical Systems, 2023.\n 45. Shaik T, et al. A review of the trends and challenges in adopting natural language processing methods for education feedback analysis. \nIEEE Access. 2022;10:56720–39.\n 46. Ferruz, N., S. Schmidt, and B. H¨ocker, A deep unsupervised language model for protein design. BioRxiv, 2022: p. 2022.03. 09.483666.\n 47. Trajtenberg M. Artificial intelligence as the next GPT: a political-economy perspective. In: The economics of artificial intelligence: an \nagenda. University of Chicago Press; 2018. p. 175–86.\n 48. Ferruz N, Schmidt S, Hocker B. ProtGPT2 is a deep unsupervised language model for protein design. Nat Commun. 2022;13(1):4348.\n 49. Kitchenham B. Procedures for performing systematic reviews. Keele, UK, Keele University, 2004; 33(2004): 1–26.\n 50. Keele S. Guidelines for performing systematic literature reviews in software engineering. 2007, Technical report, ver. 2.3 ebse technical \nreport. ebse.\n 51. Braun V, Clarke V. Using thematic analysis in psychology. Qual Res Psychol. 2006;3(2):77–101. https:// doi. org/ 10. 1191/ 14780 88706 qp063 \noa.\n 52. Iqbal U, Kohno T, Roesner F. LLM platform security: applying a systematic evaluation framework to OpenAI’s ChatGPT Plugins. 2023. arXiv \npreprint arXiv: 2309. 10254.\n 53. Dao XQ. Which large language model should you use in Vietnamese education: ChatGPT, Bing Chat, or Bard?. Bing Chat, or Bard. 2023.\n 54. Lund BD, et al. ChatGPT and a new academic reality: artificial Intelligence- written research papers and the ethics of the large language \nmodels in scholarly publishing. J Am Soc Inf Sci. 2023;74(5):570–81.\n 55. Du M, et al. Shortcut learning of large language models in natural language understanding: a survey. arXiv preprint arXiv: 2208. 11857, \n2022.\n 56. Zhao L, et al. Classification of natural language processing techniques for requirements engineering. arXiv preprint arXiv: 2204. 04282, \n2022.\n 57. Zhu Y, et al. Large language models for information retrieval: a survey. arXiv preprint arXiv: 2308. 07107, 2023.\n 58. Bispham M, Agrafiotis I, Goldsmith M. The speech interface as an attack surface: an overview. Int J Adv Secur. 2019; 12(1 and 2).\n 59. Azunre P . Transfer learning for natural language processing. 2021: Simon and Schuster.\n 60. Chien Y-W, et al. An automatic assessment system for Alzheimer’s disease based on speech using feature sequence generator and recur-\nrent neural network. Sci Rep. 2019;9(1):19597.\n 61. Wu Y, et al. Google’s neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv: \n1609. 08144, 2016.\n 62. Floridi L, Chiriatti M. GPT-3: its nature, scope, limits, and consequences. Mind Mach. 2020;30:681–94.\n 63. Peng B, et al. Instruction tuning with GPT-4. arXiv preprint arXiv: 2304. 03277, 2023.\n 64. Glukhov D, et al. LLM Censorship: a machine learning challenge or a computer security problem? arXiv preprint arXiv: 2307. 10719, 2023.\n 65. Mesko B, Topol EJ. The imperative for regulatory oversight of large language models (or generative AI) in healthcare. npj Dig Med. \n2023;6(1):120.\n 66. Denny P , et al. Robosourcing educational resources–leveraging large language models for learnersourcing. arXiv preprint arXiv: 2211. \n04715, 2022.\n 67. Kasneci E, et al. ChatGPT for good? On opportunities and challenges of large language models for education. Learn Individ Differ. \n2023;103: 102274.\n 68. Tang R, Chuang Y-N, Hu X. The science of detecting LLM-generated texts. arXiv preprint arXiv: 2303. 07205, 2023.\n 69. Xie Y, et al. Translating natural language to planning goals with large-language models. arXiv preprint arXiv: 2302. 05128, 2023.\n 70. Adamopoulou E, Moussiades L. Chatbots: history, technology, and applications. Mach Learn Appl. 2020;2: 100006.\n 71. Shen C, et al. Are large language models good evaluators for abstractive summarization? arXiv preprint arXiv: 2305. 13091, 2023.\n 72. Gong T, et al. LanSER: language-model supported speech emotion recognition. arXiv preprint arXiv: 2309. 03978, 2023.\n 73. Jackson R. Understanding (and using) ChatGPT in banking. Am Bankers Assoc ABA Banking J. 2023;115(3):16–7.\n 74. Gilbert S, et al. Large language model AI chatbots require approval as medical devices. Nat Med. 2023;29:2396.\n 75. Dave T, Athaluri SA, Singh S. ChatGPT in medicine: an overview of its applications, advantages, limitations, future prospects, and ethical \nconsiderations. Front Artif Intell. 2023;6:1169595.\n 76. Welbl J, et al. Challenges in detoxifying language models. arXiv preprint arXiv: 2109. 07445, 2021.\nVol.:(0123456789)\nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8 \n \n Review\n 77. Trajtenberg M. AI as the next GPT: a Political-Economy Perspective. 2018, National Bureau of Economic Research.\n 78. Mujahid M, et al. Arabic ChatGPT tweets classification using RoBERTa and BERT ensemble model. ACM Trans Asian Low-Resour Lang Inf \nProc. 2023;22(8):1–23.\n 79. Lund BD, Wang T. Chatting about ChatGPT: how may AI and GPT impact academia and libraries? Library Hi Tech News. 2023;40(3):26–9.\n 80. Delobelle P , Winters T, Berendt B. Robbert: a Dutch Roberta-based language model. arXiv preprint arXiv: 2001. 06286, 2020.\n 81. Chan A. GPT-3 and InstructGPT: technological dystopianism, utopianism, and “Contextual” perspectives in AI ethics and industry. AI \nEthics. 2023;3(1):53–64.\n 82. Scao TL, et al. Bloom: A 176b-parameter open-access multilingual language model. arXiv preprint arXiv: 2211. 05100, 2022.\n 83. FitzGerald J, et al. Alexa teacher model: Pretraining and distilling multi-billionparameter encoders for natural language understanding \nsystems. in Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.\n 84. Touvron H, et al. Llama: open and efficient foundation language models. arXiv preprint arXiv: 2302. 13971, 2023.\n 85. Sanh V, et al. DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. arXiv preprint arXiv: 1910. 01108, 2019.\n 86. Straka M, Hajic J, Strakova J. UDPipe: a trainable pipeline for processing CoNLL-U files performing tokenization, morphological analysis, \npos tagging, and parsing. in Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16). 2016.\n 87. Yang Z, et al. Xlnet: generalized autoregressive pretraining for language under- standing. Advances in neural information processing \nsystems. 2019. 32.\n 88. Hoffmann, J., et al., Training compute-optimal large language models. arXiv preprint arXiv: 2203. 15556, 2022.\n 89. Zhao WX, et al. A survey of large language models. arXiv preprint arXiv: 2303. 18223, 2023.\n 90. Carlini N, et al. Extracting training data from large language models. in  30th USENIX Security Symposium (USENIX Security 21). 2021.\n 91. Lee J-S, Hsiang J. Patent claim generation by fine-tuning OpenAI GPT-2. World Patent Inf. 2020;62: 101983.\n 92. Praveen S, Vajrobol V. Understanding the perceptions of healthcare researchers regarding ChatGPT: a study based on bidirectional \nencoder representation from transformers (BERT) sentiment analysis and topic modeling. Ann Biomed Eng. 2023: 1–3.\n 93. Zhao W, et al. BEST: BERT Pre-Training for Sign Language Recognition with Coupling Tokenization. arXiv preprint arXiv: 2302. 05075, 2023.\n 94. Jiarong L, et al. Knowledge Enhanced BERT Based on Corpus Associate Generation. in International Conference on Machine Learning \nfor Cyber Security. 2022. Springer.\n 95. Irfan M, et al. Reconfigurable content-addressable memory (CAM) on FPGAs: a tutorial and survey. Futur Gener Comput Syst. \n2022;128:451–65.\n 96. Su J, Yu S, Luo D. Enhancing aspect-based sentiment analysis with capsule network. IEEE Access. 2020;8:100551–61.\n 97. Song X, et al. Speech-XLNet: unsupervised acoustic model pretraining for self attention networks. arXiv preprint arXiv: 1910. 10387, 2019.\n 98. Qamar A, et al. High-level synthesis for semi-global matching: is the juice worth the squeeze? IEEE Access. 2016;5:8419–32.\n 99. Ahmad W, Ayrancioglu B, Hamzaoglu I. Low error efficient approximate adders for FPGAs. IEEE Access. 2021;9:117232–43.\n 100. Raffel C, et al. Exploring the limits of transfer learning with a unified textto-text transformer. J Mach Learn Res. 2020;21(1):5485–551.\n 101. Ciosici MR, Derczynski L. Training a T5 Using Lab-sized Resources. arXiv preprint arXiv: 2208. 12097, 2022.\n 102. Keskar NS, et al. Ctrl: a conditional transformer language model for controllable generation. arXiv preprint arXiv: 1909. 05858, 2019.\n 103. Li P , et al. Conditional embedding pre-training language model for image captioning. Neural Process Lett. 2022;54(6):4987–5003.\n 104. Ghojogh B, Ghodsi A. Attention mechanism, transformers, BERT, and GPT: tutorial and survey. 2020.\n 105. Chan A, et al. Cocon: a self-supervised approach for controlled text generation. arXiv preprint arXiv: 2006. 03535, 2020.\n 106. Khadhraoui M, et al. Survey of BERT-base models for scientific text classification: COVID-19 case study. Appl Sci. 2022;12(6):2891.\n 107. Surameery NMS, Shakor MY. Use chat GPT to solve programming bugs. Int J Inf Technol Comput Eng (IJITC). 2023;3(01):17–22.\n 108. Asch DA. An interview with ChatGPT about health care. NEJM Catalyst Innovations in Care Delivery, 2023; 4(2).\n 109. Xue VW, Lei P , Cho WC. The potential impact of ChatGPT in clinical and translational medicine. Clin Transl Med. 2023; 13(3).\n 110. Al Shloul T, et al. Role of activity-based learning and ChatGPT on students’ performance in education. Comput Educ Artif Intell. 2024. \nhttps:// doi. org/ 10. 1016/j. caeai. 2024. 100219.\n 111. Vaishya R, Misra A, Vaish A. ChatGPT: is this version good for healthcare and research? Diabetes Metab Syndr Clin Res Rev. 2023;17(4): \n102744.\n 112. Mich L, Garigliano R. ChatGPT for e-Tourism: a technological perspective. Inf Technol Tour. 2023;25:1–12.\n 113. Farrokhnia M, et al. A SWOT analysis of ChatGPT: implications for educational practice and research. Innov Educ Teach Int. 2023: 1–15.\n 114. AlAfnan MA, et al. Chatgpt as an educational tool: opportunities, challenges, and recommendations for communication, business writ-\ning, and composition courses. J Artif Intell Technol. 2023;3(2):60–8.\n 115. Lim WM, et al. Generative AI and the future of education: RagnarÅNok or reformation? A paradoxical perspective from management \neducators. Int J Manag Educ. 2023;21(2): 100790.\n 116. Sånchez-Ruiz LM, et al. ChatGPT challenges blended learning methodologies in engineering education: a case study in mathematics. \nAppl Sci. 2023;13(10):6039.\n 117. Gupta P , Raturi S, Venkateswarlu P . Chatgpt for designing course outlines: a boon or bane to modern technology. Available at SSRN \n4386113, 2023.\n 118. Kooli C. Chatbots in education and research: a critical examination of ethical implications and solutions. Sustainability. 2023;15(7):5614.\n 119. Van Dis EA, et al. ChatGPT: five priorities for research. Nature. 2023;614(7947):224–6.\n 120. Yu H. Reflection on whether Chat GPT should be banned by academia from the perspective of education and teaching. Front Psychol. \n2023;14:1181712.\n 121. Benuyenah V. Commentary: ChatGPT use in higher education assessment: prospects and epistemic threats. J Res Innov Teach Learn. \n2023;16(1):134–5.\n 122. Guzman AL, Lewis SC. Artificial intelligence and communication: a human–machine communication research agenda. New Media Soc. \n2020;22(1):70–86.\n 123. Sullivan M, Kelly A, McLaughlan P . ChatGPT in higher education: considerations for academic integrity and student learning. 2023.\n 124. Awasthi S. Plagiarism and academic misconduct: a systematic review. DESIDOC J Lib Inf Technol. 2019;39(2):94.\n 125. Perkins M, Roe J. Decoding academic integrity policies: a corpus linguistics investigation of AI and other technological threats. 2023.\nVol:.(1234567890)\nReview  \nDiscover Sustainability            (2025) 6:27  | https://doi.org/10.1007/s43621-025-00815-8\n 126. Ramberg J, Modin B. School effectiveness and student cheating: do students’ grades and moral standards matter for this relationship? \nSoc Psychol Educ. 2019;22(3):517–38.\n 127. Strzelecki A. To use or not to use ChatGPT in higher education? A study of students’ acceptance and use of technology. Interactive Learn \nEnviron. 2023;32:5142.\n 128. Dignum V. Responsible Artificial Intelligence: recommendations and Lessons Learned, in Responsible AI in Africa: Challenges and Oppor-\ntunities. 2023, Springer International Publishing Cham. p. 195–214.\n 129. Ahmad I, et al. Efficient algorithms for E-healthcare to solve multiobject fuse detection problem. J Healthc Eng. 2021;2021:1–16.\n 130. Lo CK. What is the impact of ChatGPT on education? A rapid review of the literature. Educ Sci. 2023;13(4):410.\n 131. Cotton DR, Cotton PA, Shipway JR. Chatting and cheating: ensuring academic integrity in the era of ChatGPT. Innovations in Education \nand Teaching International, 2023: p. 1–12.\n 132. Zhai X. ChatGPT user experience: implications for education. Available at SSRN 4312418, 2022.\n 133. Gu C, et al. Watermarking pre-trained language models with backdooring. arXiv preprint arXiv: 2210. 07543, 2022.\n 134. Haq I, et al. Impact of 3G and 4G technology performance on customer satisfaction in the telecommunication industry. Electronics. \n2023;12(7):1697.\n 135. Shafiq M, et al. The rise of “Internet of Things”: review and open research issues related to detection and prevention of IoT-based security \nattacks. Wirel Commun Mob Comput. 2022;2022:1–12.\n 136. Khowaja SA, Khuwaja P , Dev K. ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) evaluation: a review. arXiv \npreprint arXiv: 2305. 03123, 2023.\n 137. Mishra A, et al. Exploring the intersection of artificial intelligence and neurosurgery: Let us be cautious with ChatGPT. Neurosurgery. \n2022: 10.1227.\n 138. Yousafzai BK, et al. Student-performulator: student academic performance using hybrid deep neural network. Sustainability. \n2021;13(17):9775.\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.4631326496601105
    },
    {
      "name": "Management science",
      "score": 0.34089821577072144
    },
    {
      "name": "Engineering",
      "score": 0.21808043122291565
    }
  ]
}