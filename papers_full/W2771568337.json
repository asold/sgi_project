{
  "title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
  "url": "https://openalex.org/W2771568337",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4221665348",
      "name": "Tuor, Aaron",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4304075102",
      "name": "Baerwolf, Ryan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4304075103",
      "name": "Knowles, Nicolas",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4287193310",
      "name": "Hutchinson, Brian",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2748488071",
      "name": "Nichols, Nicole",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4304075106",
      "name": "Jasper, Rob",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2108142795",
    "https://openalex.org/W2584408238",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W2131970275",
    "https://openalex.org/W2123528936",
    "https://openalex.org/W2949563612",
    "https://openalex.org/W1985987493",
    "https://openalex.org/W2585284559",
    "https://openalex.org/W2342408547",
    "https://openalex.org/W2296719434",
    "https://openalex.org/W1530215515",
    "https://openalex.org/W2466206609",
    "https://openalex.org/W2554388950",
    "https://openalex.org/W2220350356",
    "https://openalex.org/W2953061907",
    "https://openalex.org/W2952276042",
    "https://openalex.org/W2518756966",
    "https://openalex.org/W574004345",
    "https://openalex.org/W2476891002",
    "https://openalex.org/W2761599262",
    "https://openalex.org/W1899794420",
    "https://openalex.org/W2131774270"
  ],
  "abstract": "Automated analysis methods are crucial aids for monitoring and defending a network to protect the sensitive or confidential data it hosts. This work introduces a flexible, powerful, and unsupervised approach to detecting anomalous behavior in computer and network logs, one that largely eliminates domain-dependent feature engineering employed by existing methods. By treating system logs as threads of interleaved \"sentences\" (event log lines) to train online unsupervised neural network language models, our approach provides an adaptive model of normal network behavior. We compare the effectiveness of both standard and bidirectional recurrent neural network language models at detecting malicious activity within network log data. Extending these models, we introduce a tiered recurrent architecture, which provides context by modeling sequences of users' actions over time. Compared to Isolation Forest and Principal Components Analysis, two popular anomaly detection algorithms, we observe superior performance on the Los Alamos National Laboratory Cyber Security dataset. For log-line-level red team detection, our best performing character-based model provides test set area under the receiver operator characteristic curve of 0.98, demonstrating the strong fine-grained anomaly detection performance of this approach on open vocabulary logging sources.",
  "full_text": "Recurrent Neural Network Language Models for\nOpen Vocabulary Event-Level Cyber Anomaly Detection\nAaron Tuor,1 Ryan Baerwolf,2 Nicolas Knowles,2\nBrian Hutchinson,1,2 Nicole Nichols1 and Robert Jasper1\n1Paciﬁc Northwest National Laboratory\nRichland, Washington\n2Western Washington University\nBellingham, Washington\nAbstract\nAutomated analysis methods are crucial aids for monitoring\nand defending a network to protect the sensitive or conﬁden-\ntial data it hosts. This work introduces a ﬂexible, powerful,\nand unsupervised approach to detecting anomalous behav-\nior in computer and network logs; one that largely eliminates\ndomain-dependent feature engineering employed by existing\nmethods. By treating system logs as threads of interleaved\n“sentences” (event log lines) to train online unsupervised neu-\nral network language models, our approach provides an adap-\ntive model of normal network behavior. We compare the ef-\nfectiveness of both standard and bidirectional recurrent neu-\nral network language models at detecting malicious activity\nwithin network log data. Extending these models, we intro-\nduce a tiered recurrent architecture, which provides context\nby modeling sequences of users’ actions over time. Com-\npared to Isolation Forest and Principal Components Analy-\nsis, two popular anomaly detection algorithms, we observe\nsuperior performance on the Los Alamos National Labora-\ntory Cyber Security dataset. For log-line-level red team de-\ntection, our best performing character-based model provides\ntest set area under the receiver operator characteristic curve\nof 0.98, demonstrating the strong ﬁne-grained anomaly de-\ntection performance of this approach on open vocabulary log-\nging sources.\n1 Introduction\nTo minimize cyber security risks, it is essential that orga-\nnizations be able to rapidly detect and mitigate malicious\nactivity on their computer networks. These threats can orig-\ninate from a variety of sources including malware, phishing,\nport scanning, etc. Attacks can lead to unauthorized network\naccess to perpetrate further damage such as theft of creden-\ntials, intellectual property, and other business sensitive infor-\nmation. In a typical scenario, cyber defenders and network\nadministrators are tasked with sifting through vast amounts\nof data from various logging sources to assess potential se-\ncurity risks. Unfortunately, the amount of data for even a\nmodestly-sized network can quickly grow beyond the abil-\nity of a single person or team to assess, leading to delayed\nresponse. The desire for automated assistance has and con-\ntinues to encourage inter-domain research in cyber security\nand machine learning.\nSignature-based approaches for automated detection can\nbe highly effective for characterizing individual threats. De-\nspite their high precision, they suffer from low recall and\nmay fail to detect subtle mutations or novel attacks. Alterna-\ntively, given an unlabeled training set of typically benign ac-\ntivity logs, one can build a model of “normal behavior”. Dur-\ning online joint training and evaluation of this model, pat-\nterns of normal usage will be reinforced and atypical mali-\ncious activity will stand out as anomalous. The features used\nto identify unusual behavior are typically statistical feature\nvectors associated with time slices, e.g., vectors of counts for\ntypes of activities taking place in a 24-hour window. Such\nsystems developed in research have been criticized as brittle\nto differences in site-speciﬁc properties of real-world oper-\national networks such as security constraints and variable\nusage patterns (Sommer and Paxson 2010).\nThe approach we introduce aims to minimize site-speciﬁc\nassumptions implicit in feature engineering, and effectively\nmodel variability in network usage by direct online learn-\ning of language models over log lines. Language models\nassign probabilities to sequences of tokens and are a core\ncomponent of speech recognition, machine translation, and\nother language processing systems. Speciﬁcally, we explore\nthe effectiveness of several recurrent neural network (RNN)\nlanguage models for use in a network anomaly detection sys-\ntem. Our system dynamically updates the network language\nmodel each day based on the previous day’s events. When\nthe language model assigns a low probability to a log-line it\nis ﬂagged as anomalous. There are several advantages to this\napproach:\n1. Reduced feature engineering:Our model acts directly\non raw string tokens, rather than hand-designed domain-\nspeciﬁc statistics. This dramatically reduces the time to\ndeployment, and makes it agnostic to the speciﬁc network\nor logging source conﬁguration. It also removes the “blind\nspots” introduced when tens of thousands of log-lines are\ndistilled down to a single aggregated feature vector, al-\nlowing our model to capture patterns that would have oth-\nerwise been lost.\n2. Fine grained assessment:The response time for analysts\ncan be improved by providing more speciﬁc and relevant\nevents of interest. Baseline systems that alert to a user’s\nday aggregate require sifting through tens of thousands of\nactions. Our approach can provide log-line-level or even\ntoken-level scores to the analyst, helping them quickly lo-\ncate the suspicious activity.\n3. Real time processing:With the ability to process events\nin real time and ﬁxed bounds on memory usage which\ndo not grow over time, our approach is suitable for the\ncommon scenario in which log-line events are appearing\nin a high-volume, high-velocity log stream.\nWe assess our models using the publicly available\nLos Alamos National Laboratory (LANL) Cyber Security\nDataset, which contains real (de-identiﬁed) data with ground\ntruth red team attacks, and demonstrate language models\ndeﬁnitively outperforming standard unsupervised anomaly\ndetection approaches.\n2 Prior work\nMachine learning has been widely explored for network\nanomaly detection, with techniques such as isolation for-\nest (Gavai et al. 2015; Liu, Ting, and Zhou 2008) and prin-\ncipal component analysis (Novakov et al. 2013; Ringberg\net al. 2007) attracting signiﬁcant interest. Machine learn-\ning classiﬁers ranging from decision trees to Na ¨ıve Bayes\nhave been used for cyber security tasks such as malware de-\ntection, network intrusion, and insider threat detection. Ex-\ntensive discussion of machine learning applications in cy-\nber security is presented in (Bhattacharyya and Kalita 2013;\nBuczak and Guven 2016; Dua and Du 2016; Kumar, Kumar,\nand Sachdeva 2010; Zuech, Khoshgoftaar, and Wald 2015;\nRubin-Delanchy, Lawson, and Heard 2016).\nDeep learning approaches are also gaining adoption for\nspecialized cyber defense tasks. In an early use of recurrent\nneural networks, Debar, Becker, and Siboni (1992) model\nsequences of Unix shell commands for network intrusion\ndetection. Anomaly detection has been demonstrated using\ndeep belief networks on the KDD Cup 1999 dataset (Al-\nrawashdeh and Purdy 2016), and Bivens et al. (2002) use\nmulti-layer perceptrons for the DARPA 1999 dataset. Both\napproaches use aggregated features and synthetic network\ndata. Tuor et al. (2017) and Veeramachaneni et al. (2016)\nboth employ deep neural network autoencoders for unsu-\npervised network anomaly detection using time aggregated\nstatistics as features.\nSome works of note have been previously published on\nthe LANL data. Turcotte, Heard and Kent (2016) develop\nan online statistical model for anomaly detection in network\nactivity using Multinomial-Dirichlet models. Similarly, Tur-\ncotte et al. (2016) use Poission Factorization (Gopalan, Hof-\nman, and Blei 2013) on the LANL authentication logs. A\nuser/computer authentication count matrix is constructed by\nassuming each count comes from a Poisson distribution pa-\nrameterized by latent factors for users and computers. The\nlearned distributions are then used to predict unlikely au-\nthentication behavior.\nSeveral variants of tiered recurrent networks have been\nexplored in the machine learning and natural language pro-\ncessing communities (Koutnik et al. 2014; Ling et al. 2015b;\nLing et al. 2015a; Chung et al. 2015). They are often real-\nized by a lower tier pre-processing network, whose output is\nfed to an upper tier network and the separate tiers are jointly\ntrained. Ling et al. (2015b) use a character-level convolu-\ntional neural network to feed a word level long short-term\nmemory (LSTM) RNN for machine translation, with predic-\ntions made at the word-level. Both Hwang and Sung (2016)\nand Ling et al. (2015a) use a character-based LSTM to feed\na second word or utterance-based LSTM for language mod-\neling. Pascanu et al. (2015) create activity models from real\nworld data on a per-event (command) basis and sequences of\nsystem calls are then modeled using RNN and echo state net-\nworks. The learned features are used to independently train\nneural network and logistic regression classiﬁers. Max pool-\ning is applied to hidden layers of the unsupervised RNN for\neach time step in a session and the result is concatenated to\nthe ﬁnal hidden state to produce feature vectors for the clas-\nsiﬁer. This is similar to our tiered approach, in which we use\nthe average of all hidden states concatenated with the ﬁnal\nhidden state as input to the upper-tier RNN. In contrast, our\nmodel is completely unsupervised and all components are\njointly trained.\n3 Approach\nOur approach learns normal behavior for users, processing\na stream of computer and network log-lines as follows:\n1. Initialize model weights randomly\n2. For each day kin chronological order:\n(a) Given model Mk−1, produce log-line-level anomaly\nscores for all events in day k\n(b) Optionally, produce an aggregated anomaly score each\nuser for day k(from the log-line-level scores)\n(c) Send per-user-day or per-user-event anomaly scores in\nrank order to analysts for inspection\n(d) Update model weights to minimize loss on all log-lines\nin day k, yielding model Mk\nThis methodology interleaves detection and training in an\nonline fashion. In this section we detail the components of\nour approach.\n3.1 Log-Line Tokenization\nTo work directly from arbitrary log formats, we treat log-\nlines as sequences of tokens. For this work, we consider two\ntokenization granularities: word-level and character-level.\nFor word tokenization, we assume that tokens in the log-\nline are delimited by a known character (e.g., space or\ncomma). After splitting the log-lines on this delimiter, we\ndeﬁne a shared vocabulary of “words” over all log ﬁelds,\nconsisting of the sufﬁciently-frequent tokens appearing in\nthe training set. To allow our model to handle previously\nunseen tokens, we add an “out of vocbulary” token to our\nvocabulary, <oov>. (For instance, not every IP address will\nbe represented in a training set; likewise, new PCs and users\nare continually being added to large networks.) To ensure\nthat <oov> has non-zero probability, we replace sufﬁciently\ninfrequent tokens in the training data with <oov>. During\nevaluation, tokens not seen before are labeled<oov>. In or-\nder to accommodate shifting word distributions in an online\nenvironment, a ﬁxed size vocabulary could be periodically\nupdated using a sliding window of word frequency statis-\ntics. For simplicity, we assume we have a ﬁxed training set\nfrom which we produce a ﬁxed vocabulary.\nTo avoid the challenges of managing a word-level vocab-\nulary, we also develop language models using a character-\nlevel tokenization. In this case our primitive vocabulary,\nthe alphabet of printable ASCII characters, circumvents the\nopen vocabulary issue by its ability to represent any log en-\ntry irrespective of the network, logging source, or log ﬁeld.\nWith character-level tokenization, we keep the delimiter to-\nken in the sequence, to provide our models with cues to tran-\nsitions between log-line ﬁelds.\n3.2 Recurrent Neural Network Language Models\nTo produce log-line-level anomaly scores, we use recurrent\nneural networks in two ways: 1) as a language model over\nindividual log-lines, and 2) to model the state of a user over\ntime. We ﬁrst present two recurrent models that focus only\non (1), and then a tiered model that accomplishes both (1)\nand (2). Both were implemented1 for our experiments using\nTensorFlow (Abadi et al. 2015).\nEvent Model (EM). First we consider a simple RNN\nmodel that operates on the token (e.g., word) sequences\nof individual log-lines (events). Speciﬁcally, we consider\na Long Short-Term Memory (LSTM) (Hochreiter and\nSchmidhuber 1997) network whose inputs are token embed-\ndings and from whose output we predict distributions over\nthe next token.\nFor a log-line with K tokens, each drawn from a shared\nvocabulary of size C, let X(1:K) = x(1),x(2),..., x(K) de-\nnote a sequence of one-hot representations of the tokens\n(each x(t) ∈RC).\nIn this model, the hidden representation at token t, h(t),\nfrom which we make our predictions, is a function of\nx(1),x(2),..., x(t) according to the usual LSTM equations:\nh(t) = o(t) ◦ tanh(c(t)) (1)\nc(t) = f(t) ◦ c(t−1) + i(t) ◦ g(t) (2)\ng(t) = tanh\n(\nx(t)W(g,x) + h(t−1)W(g,h) + b(g)\n)\n(3)\nf(t) = σ\n(\nx(t)W(f,x) + h(t−1)W(f,h) + b(f)\n)\n(4)\ni(t) = σ\n(\nx(t)W(i,x) + h(t−1)W(i,h) + b(i)\n)\n(5)\no(t) = σ\n(\nx(t)W(o,x) + h(t−1)W(o,h) + b(o)\n)\n, (6)\nwhere the initial hidden and cell states, c(0) and h(0), are\nset to zero vectors, and ◦and σ denote element-wise mul-\ntiplication and logistic sigmoid, respectively. Vector g(t) is\na hidden representation based on the current input and pre-\nvious hidden state, while vectors f(t), i(t), and o(t), are the\nstandard LSTM gates. The matrices ( W) and bias vectors\n(b) are the model parameters. We use each h(t−1) to pro-\nduce a probability distribution p(t) over the token at time t,\nas follows:\np(t) = softmax\n(\nh(t−1)W(p) + b(p)\n)\n(7)\n1Code will soon be available at https://github.com/pnnl/safekit\nLSTM LSTM\n… \nsoftmax softmax\nLSTM \nx(K-1)\nsoftmax \np(2) p(K)\nLSTM LSTM LSTM \nx(1)\nx(3)x(2) <eos>\nLSTM\nsoftmax\np(K-1)\nLSTM\nx(K-2)\nx(K)\np(1)\n<sos>\nFigure 1: Event Models. Set of black bordered nodes and\nconnections illustrate the EM model while set of all nodes\nand connections illustrate the BEM model.\nWe use cross-entropy loss,\n1\nK\nK∑\nt=1\nH(x(t),p(t)), (8)\nfor two important purposes: ﬁrst, as per-log-line anomaly\nscore and second, as the training objective to update model\nweights. We train this model using stochastic mini-batch\n(non-truncated) back-propagation through time.\nBidirectional Event Model (BEM). Following the lan-\nguage model formulation suggested in (Schuster and Paliwal\n1997), we alternatively model the structure of log lines with\na bidirectional LSTM. We deﬁne a new set of hidden vec-\ntors hb\n(K+1),hb\n(K),..., hb\n(1) by running the LSTM equations\nbackwards in time (starting with initial zero cell and hidden\nstates at time K+ 1set to zero). The weights W and biases\nb for the backward LSTM are denoted with superscript b.\nThe probability distribution p(t) over the token at time t\nis then:\np(t) = softmax\n(\nh(t−1)W(p) + hb\n(t+1)Wb\n(p) + b(p)\n)\n(9)\nTiered Event Models (T-EM, T-BEM). To incorporate\ninter-log-line context, we propose a two-tiered recurrent\nneural network. The lower-tier can be either event model\n(EM or BEM), but with the additional input of a context vector\n(generated by the upper-tier) concatenated to the token em-\nbedding at each time step. The input to the upper-tier model\nis the hidden states of the lower-tier model. This upper tier\nmodels the dynamics of user behavior over time, produc-\ning the context vectors provided to the lower-tier RNN. This\nmodel is illustrated in Fig. 2.\nIn this model, x(u,j) denotes user u’sjth log line, which\nconsists of a sequence of tokens as described in the previous\nsubsections. The upper-tier models a sequence of user log\nlines, x(u,1),x(u,2),...,x (u,Tu), using an LSTM. For each\nuser uand each log line j in the user’s log line sequence, a\nlower-tier LSTM is applied to the tokens ofx(u,j). The input\nto the upper-tier model at log-line jis the concatenation of:\n1) the ﬁnal lower-tier hidden state(s) and 2) the average of\nthe lower-tier hidden states. In the case of a lower-tier EM,\nLSTM\nLSTM\nLSTM\nLSTM\nLSTM\nLSTM\nMean\nFinal\nContext\nLSTM\nFinal\nContext\nLSTM\nMean\n<\nsos\n>\n<\ne\nos\n>\n<\nsos\n>\n<\ne\nos\n>\n…\n…\nFigure 2: Tiered Event Model (T-EM)\n(1) refers to the hidden state at time K; for the BEM, (1)\nis the concatenation of the forward hidden state at time K\nand the backward hidden state at time 1. For (2), we aver-\nage over hidden states primarily to provide many short-cut\nconnections in the LSTM, which aids trainability. The out-\nput of the upper-tier LSTM at log-line j is a hidden state\nˆh(u,j). This hidden vector serves to provide context for the\nlower-tier model at the next time step: speciﬁcally, ˆh(u,j−1)\nis concatenated to each of the inputs of the lower-tier model\noperating on the jth log-line. Note that the upper-tier model\nserves only to propagate context information across individ-\nual log-lines; no loss is computed directly on the values pro-\nduced by the upper-tier model.\nThe upper- and lower-tier models are trained jointly to\nminimize the cross-entropy loss of the lower-tier model. We\nunroll the two-tier model for a ﬁxed number of log-lines,\nfully unrolling each of the lower-tier models within that win-\ndow. The lower-tier model’s cross-entropy loss is also used\nto detect anomalous behavior, as is described further in Sec-\ntion 4.2.\nMinibatching becomes more challenging for the tiered\nmodel, as the number of log-lines per day can vary dramati-\ncally between users. This poses two problems: ﬁrst, it intro-\nduces the possibility that the most active users may have a\ndisproportionate impact on model weights; second, it means\nthat toward the end of the day, there may not be enough users\nto ﬁll the minibatch. To counteract the ﬁrst problem, we ﬁx\nthe number of log-lines per user per day that the model will\ntrain on. The remaining log-lines are not used in any gradi-\nent updates. We leave compensating for the inefﬁciency that\nresults from the second to future work.\n3.3 Baselines\nAnomaly detection in streaming network logs often relies\nupon computing statistics over windows of time and apply-\ning anomaly detection techniques to those vectors. Below\nwe describe the aggregate features and two anomaly detec-\ntion techniques that are typical of prior work.\nAggregate Features We ﬁrst deﬁne the set of per-user-\nday features, which summarize users’ activities in the day.\nTo aggregate the features that have a small number of dis-\ntinct values (e.g. success/failure, logon orientation) we count\nthe number of occurrences for each distinct value for the\nuser-day. For ﬁelds that have a larger number of distinct val-\nues (pcs, users, domains), we count the number of common\nand uncommon events that occurred, rather than the number\nof occurrences of each distinct value (this approach avoids\nhigh dimensional sparse features). Furthermore, we deﬁne\ntwo categories of common/uncommon; to the individual en-\ntity/user, and relative to all users. A value is deﬁned as un-\ncommon for the user if it accounts for fewer than 5% of the\nvalues observed in that ﬁeld (up to that point in time), and\ncommon otherwise. A value is deﬁned as uncommon for all\nusers if it occurs fewer times than the average value for the\nﬁeld, and common otherwise.\nFor the LANL dataset, the prior featurization strategy\nyields a 108-dimensional aggregate feature vector per user-\nday. These feature vectors then serve as the input to the base-\nline models described next.\nModels We consider two baseline models. The ﬁrst uses\nPrincipal Components Analysis (pca) to learn a low dimen-\nsional representation of the aggregate features; the anomaly\nscore is proportional to the reconstruction error after map-\nping the compressed representation back into the original di-\nmension (Shyu et al. 2003). The second is an isolation forest\n(iso) based approach (Liu, Ting, and Zhou 2008) as imple-\nmented in scikit-learn’s outlier detection tools (Pedregosa et\nal. 2011). This was noted as the best performing anomaly\ndetection algorithm in the recent DARPA insider threat de-\ntection program, (Gavai et al. 2015).\n4 Experiments\nIn this section we describe experiments to evaluate the ef-\nfectiveness of the proposed event modeling algorithms.\n4.1 Data\nThe Los Alamos National Laboratory (LANL) Cyber Secu-\nrity Dataset (Kent 2016) consists of event logs from LANL’s\ninternal computer network collected over a period of 58 con-\nsecutive days. The data set contains over one billion log-\nlines from authentication, process, network ﬂow, and DNS\nlogging sources. Identifying ﬁelds (e.g., users, computers,\nand processes) have been anonymized.\nThe recorded network activities included both normal op-\nerational network activity as well as a series of red team ac-\ntivities that compromised account credentials over the ﬁrst\n30 days of data. Information about known red team attack\nevents is used only for evaluation; our approach is strictly\nunsupervised.\nFor the experiments presented in this paper, we rely only\non the authentication event logs, whose ﬁelds and statistics\nare summarized in Figure 3a. We ﬁlter these events to only\nthose log-lines linked to an actual user, removing computer-\ncomputer interaction events. Events on weekends and holi-\ndays contain drastically different frequencies and distribu-\ntions of activities. In a real deployment a separate model\nwould be trained for use on those days, but because no ma-\nlicious events were in that data it was also withheld.\nTable 3b has statistics of our data split; the ﬁrst 12 days\nserve as the development set, while the remaining 18 days\nare the independent test set.\n4.2 Assessment Granularity\nOur model learns normal behavior and assigns relatively\nhigh loss to events that are unexpected. A principal advan-\ntage of our approach is this ability to score the anomaly of\nField Example # unique labels\ntime 1 5011198\nsource user C625@DOM1 80553\ndest. user U147@DOM1 98563\nsource pc C625 16230\ndest. pc C625 15895\nauth. type Negotiate 29\nlogon type Batch 10\nauth. orient LogOn 7\nsuccess Success 2\n(a)\nDev Test\nDays 1-12 13-58\n# Events 133M 918M\n# Attacks 316 385\n# User-days 57 79\n(b)\nFigure 3: Dataset statistics: (a) Authentication log ﬁelds and\nstatistics and (b) dataset splits.\nindividual events, allowing us to ﬂag at the event-level or\naggregate anomalies over any larger timescale.\nFor this work, we consider two timescales. First, we as-\nsess based on individual events; a list of events would be pre-\nsented to the analyst, sorted descending by anomaly score.\nSecond, to facilitate comparison with traditional aggregation\nmethods, we aggregate anomaly scores over all of a user’s\nevents for the day (speciﬁcally, taking the max), producing\na single anomaly score per-user, per-day. In this scenario,\na list of user-days would be provided to the analyst, sorted\ndescending by anomaly score. We refer to this approach as\nmax, because the anomaly scores provided to the analyst are\nproduced by taking the maximum score over the event scores\nin the window for that user (where event-level scoring is just\ntaking the max over a singleton set of one event).\nIn order to counter systematic offsets in users’ anomaly\nscores for a day we also consider a simple normalization\nstrategy, which we refer to as diff, by which every raw\nscore is ﬁrst normalized by subtracting the user’s average\nevent-level anomaly score for the day.\n4.3 Metrics\nWe consider two performance metrics. First, we assess re-\nsults using the standard area under the receiver operator\ncharacteristic curve (AUC) which characterizes the trade-off\nin model detection performance between true positives and\nfalse positives, effectively sweeping through all possible an-\nalyst budgets. False positives are detections that are not truly\nred team events, while true positives are detections that are.\nTo quantify the proportion of the data the analyst must\nsift through to diagnose malicious behavior on the network,\nwe use the Average Percentile (AP) metric. Speciﬁcally, for\neach red team event or user-day, we note the percentile of its\nanomaly amongst all anomaly scores for the day. We then\naverage these percentiles for all of the malicious events or\nModel Tokenization AUC AP\npca - 0.754 73.9\niso - 0.763 75.0\nEM Word 0.802 79.3\nBEM Word 0.876 87.0\nT-EM Word 0.782 77.5\nT-BEM Word 0.864 85.7\nEM Char 0.750 70.9\nBEM Char 0.843 82.9\nT-EM Char 0.772 76.2\nT-BEM Char 0.837 82.9\nTable 1: User-day granularity test set AUC and AP. Lan-\nguage model anomaly scores calculated with average user-\nday normalization (diff).\nLOG DAY\ndiff max diff max\nW EM 0.964 0.932 0.802 0.794\nW BEM 0.974 0.895 0.876 0.811\nW T-EM 0.959 0.948 0.782 0.803\nW T-BEM 0.959 0.902 0.864 0.838\nC EM 0.940 0.935 0.751 0.754\nC BEM 0.973 0.979 0.843 0.846\nC T-EM 0.859 0.927 0.772 0.809\nC T-BEM 0.945 0.969 0.837 0.854\nTable 2: Comparison of AUC for day-level and log-line-level\nanalysis with and without user-day normalization. Figures 4\nand 5 provide a visualization of these results.\nuser-days. Note that if all true malicious events or user-days\nare ﬂagged as the most anomalous on the respective days,\nthen AP ≈100, while if all malicious events or user-days\nare ranked as the least anomalous on their respective days,\nAP ≈0. For both AUC and AP, a higher score is better.\nOur model hyperparameters were manually tuned to max-\nimize AP for day-leveldiff scores on the development set.\nNo separate training set is needed as our approach is unsu-\npervised and trained online.\n4.4 Results and Analysis\nWe begin by exploring the user-day granularity perfor-\nmance. Table 1 summarizes model detection performance\nat this granularity on the test set for the AUC and AP met-\nrics using the diff method to produce day level scores\nfrom the language models. A few trends are evident from\nthese results. First, the aggregate feature baselines have near-\nequivalent performance by both metrics, with the isolation\nforest approach having a slight edge. We hypothesize the\nfeature representation, which is common to these methods,\ncould be a bottleneck in performance. This highlights the\n“blind spot” issue feature engineering introduces. Second,\ndespite having only the context of a single log-line at a\ntime, as opposed to features aggregated over an entire day,\nthe event model ( EM) performs comparably to the baseline\nmodels when a forward pass LSTM network is used with\nLOG | DAY\nW EM\nLOG | DAY\nW BEM\nLOG | DAY\nW T-EM\nLOG | DAY\nW T-BEM\n20\n40\n60\n80\n100AUC\n96 97 95 9593\n89\n94\n90\n80\n87\n78\n86\n79 81 80 83\ndiff\nmax\nFigure 4: Word model comparison of AUC at day-level and\nlog-line-level granularities.\nLOG | DAY\nW EM\nLOG | DAY\nW BEM\nLOG | DAY\nW T-EM\nLOG | DAY\nW T-BEM\n20\n40\n60\n80\n100AUC\n93 97\n85\n9493\n97\n92\n96\n75\n84\n77\n83\n75\n84\n80\n85\ndiff\nmax\nFigure 5: Character model comparison of AUC at day-level\nand log-line-level granularities.\na character tokenization and outperforms the baselines with\nword tokenization. The most pronounced performance gain\nresults from using bidirectional models. Finally, word-level\ntokenization performs better than character-level; however,\neven the bidirectional character models perform apprecia-\nbly better than the baselines.\nIt is clear from these results that the tiered models perform\ncomparably to, but not better than, the event-level models.\nThis suggests that the event level model is able to charac-\nterize normal user behavior from information stored in the\nmodel weights of the network, which are trained each day to\nmodel user activity. Given the context of the past day’s ac-\ntivity stored in the model weights, the categorical variables\nrepresented by the ﬁelds in an individual log line may elim-\ninate the need for explicit event context modeling. We leave\ntracking the state of individual computers, rather than users,\nto future work, but hypothesize that it may make the tiered\napproach more effective.\nNext, we broaden our analysis of language modeling ap-\nproaches, comparing performance across all language mod-\nels, tokenization strategies, anomaly granularity, and nor-\nmalization techniques. Figure 4 plots AUC for all language\nmodel types using word tokenization, contrasting max and\ndiff normalization modes. Figure 5 compares the same\nvariations for character tokenization. Table 2 presents these\nresults in tabular form. With few exceptions, log-line-level\ngranularity vastly outperforms day-level; this is true for both\nthe character-level and word-level tokenization strategies,\nwith an average gain of 0.1 AUC. The most interesting out-\ncome of these comparisons is that word tokenization perfor-\nmance gains are heavily reliant on the diff normalization,\nwhereas for character tokenization the diff normalization\nhas a minor detrimental effect for some models. This sug-\ngests that the character-level model could be used to provide\na more immediate response time, not having to wait until the\nday is done to obtain the day statistics used in diff mode.\nThe two tokenization strategies may in fact be complemen-\ntary as the versatility and response time gains of a charac-\nter tokenization come at the expense of easy interpretibil-\nity of a word tokenization: the word tokenization allows\nanomaly scores to be decomposed into individual log-line\nﬁelds, enabling analysts to pinpoint features of the event that\nmost contributed to it being ﬂagged. Since we tuned hyper-\nparameters using diff mode, the character-level model has\npotential to do better with additional tuning.\nNext, Figures 6 and 7 visualize the average percentiles of\nred team detections for the subset of the test set with the\nmost red-team activity. Anomaly scores for both word and\ncharacter tokenizations are computed without average user-\nday offset normalization. Red team log-line-level scores are\nplotted as purple x’s with the x coordinate being the sec-\nond in time at which the event occurred and y coordinate\nthe anomaly score for that event. Percentile ranges are col-\nored to provide context for the red-team anomaly scores\nagainst the backdrop of other network activity. The spread\nof non-normalized anomaly scores is much greater for the\nword-level tokenizations (Fig. 7) than character-level (Fig.\n6), which could explain the different sensitivity of word level\ntokenization to normalization. Also notice that there is an\nexpected bump in percentiles for windows of frequent red-\nteam activity. Curiously, at the end of day 14 there are mas-\nsive bumps for the 99th percentile, which suggest unplanned\nand un-annotated anomalous events on the LANL network\nfor those hours. Notice that for the character tokenization al-\nmost all non-normalized red team anomaly scores are above\nthe 95th percentile, with a large proportion above the 99th\npercentile.\nFinally, Figure 8 plots the ROC curves for the best ag-\ngregate baseline ( iso), the best user-day granularity lan-\nguage model (word BEM), and the best event-level granular-\nity model (character BEM). It illustrates the qualitatively dif-\nferent curves obtained with the baselines, the user-day gran-\nularity, and the event-level granularity.\nSince the proportion of red-team to normal events is van-\nishingly low in the data-set ( < 0.001%), the false-positive\nrate is effectively the proportion of data ﬂagged to achieve a\nparticular recall. From this observation, Figure 8 shows the\ncharacter event model can achieve 100% recall from only\n12% of the data whereas the other models considered only\nachieve 100% recall when nearly all of the data has been\nDay 126 am12 pm6 pmDay 136 am12 pm6 pmDay 146 am12 pm6 pmDay 15\nDay/Time\n0.00\n0.25\n0.50\n0.75\n1.00\n1.25\n1.50\n1.75\n2.00Anomaly Score\n75-95 Percentile\n95-99 Percentile\nRed-event\nFigure 6: Character-level red-team log-line anomaly scores\nin relation to percentiles over time.\nFigure 7: Word-level red-team log-line anomaly scores in\nrelation to percentiles over time.\n0.0 0.2 0.4 0.6 0.8 1.0\nFalse positive\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0True positive\niso agg 0.76 AUC\nW BEM day 0.88 AUC\nC BEM log-line 0.98 AUC\nFigure 8: ROC curves for best performing baseline, word\nlanguage model evaluated at day-granularity, and character\nlanguage model evaluated at log-line-granularity.\nhanded to the analyst. Further, the character event model can\nachieve 80% recall by ﬂagging only 3% of the data whereas\nthe word day language model needs 14% of the data and the\naggregate isolation forest model needs 55% of the data to\nachieve the same result.\n5 Conclusion\nThis work builds upon advances in language modeling to\naddress computer security log analysis, proposing an unsu-\npervised, online anomaly detection approach. We eliminate\nthe usual effort-intensive feature engineering stage, making\nour approach fast to deploy and agnostic to the system con-\nﬁguration and monitoring tools. It further confers the key\nadvantage of event-level detection which allows for a near\nimmediate alert response following anomalous activity.\nIn experiments using the Los Alamos National Labora-\ntory Cyber Security Dataset, bidirectional language mod-\nels signiﬁcantly outperformed standard methods at day-level\ndetection. The best log-line-level detection performance\nwas achieved with a bidirectional character-based language\nmodel, obtaining a 0.98 area under the ROC curve, showing\nthat for the constrained language domain of network logs,\ncharacter based language modeling can achieve comparable\naccuracy to word based modeling for event level detection.\nWe have therefore demonstrated a simple and effective ap-\nproach to modeling dynamic networks with open vocabulary\nlogs (e.g. with new users, PCs, or IP addresses).\nWe propose to extend this work in several ways. First,\npotential modeling advantages of tiered architectures merit\nfurther investigation. The use of tiered architectures to track\nPCs instead of network users, or from a richer set of logging\nsources other than simply authentication logs may take bet-\nter advantage of their modeling power. Next, we anticipate\ninterpretability can become lost with such detailed granu-\nlarity provided by log-line-level detection from a character-\nbased model, therefore future work will explore alternate\nmethods of providing context to an analyst. Finally, we are\ninterested in exploring the robustness of this approach to\nadversarial tampering. Similarly performing models could\nhave different levels of resilience that would lead to selec-\ntion of one over another.\nAcknowledgments The research described in this paper is\npart of the Analysis in Motion Initiative at Paciﬁc Northwest\nNational Laboratory. It was conducted under the Laboratory\nDirected Research and Development Program at PNNL, a\nmulti-program national laboratory operated by Battelle for\nthe U.S. Department of Energy. The authors would also like\nto thank the Nvidia corporation for their donations of Titan\nX and Titan Xp GPUs used in this research.\nReferences\n[Abadi et al. 2015] Abadi, M.; Agarwal, A.; Barham, P.;\nBrevdo, E.; Chen, Z.; Citro, C.; Corrado, G. S.; Davis, A.;\nDean, J.; Devin, M.; Ghemawat, S.; Goodfellow, I.; Harp,\nA.; Irving, G.; Isard, M.; Jia, Y .; Jozefowicz, R.; Kaiser, L.;\nKudlur, M.; Levenberg, J.; Man´e, D.; Monga, R.; Moore, S.;\nMurray, D.; Olah, C.; Schuster, M.; Shlens, J.; Steiner, B.;\nSutskever, I.; Talwar, K.; Tucker, P.; Vanhoucke, V .; Vasude-\nvan, V .; Vi´egas, F.; Vinyals, O.; Warden, P.; Wattenberg, M.;\nWicke, M.; Yu, Y .; and Zheng, X. 2015. TensorFlow: Large-\nscale machine learning on heterogeneous systems. Software\navailable from tensorﬂow.org.\n[Alrawashdeh and Purdy 2016] Alrawashdeh, K., and Purdy,\nC. 2016. Toward an online anomaly intrusion detection\nsystem based on deep learning. In Machine Learning and\nApplications (ICMLA), 2016 15th IEEE International Con-\nference on, 195–200. IEEE.\n[Bhattacharyya and Kalita 2013] Bhattacharyya, D. K., and\nKalita, J. K. 2013. Network anomaly detection: A machine\nlearning perspective. CRC Press.\n[Bivens et al. 2002] Bivens, A.; Palagiri, C.; Smith, R.; Szy-\nmanski, B.; Embrechts, M.; et al. 2002. Network-\nbased intrusion detection using neural networks. Intelli-\ngent Engineering Systems through Artiﬁcial Neural Net-\nworks 12(1):579–584.\n[Buczak and Guven 2016] Buczak, A. L., and Guven, E.\n2016. A survey of data mining and machine learning meth-\nods for cyber security intrusion detection. IEEE Communi-\ncations Surveys & Tutorials 18(2):1153–1176.\n[Chung et al. 2015] Chung, J.; Gulcehre, C.; Cho, K.; and\nBengio, Y . 2015. Gated feedback recurrent neural networks.\nIn International Conference on Machine Learning , 2067–\n2075.\n[Debar, Becker, and Siboni 1992] Debar, H.; Becker, M.;\nand Siboni, D. 1992. A neural network component for an\nintrusion detection system. In Proc. IEEE Symposium on\nResearch in Security and Privacy, 240–250.\n[Dua and Du 2016] Dua, S., and Du, X. 2016. Data mining\nand machine learning in cybersecurity. CRC press.\n[Gavai et al. 2015] Gavai, G.; Sricharan, K.; Gunning, D.;\nHanley, J.; Singhal, M.; and Rolleston, R. 2015. Supervised\nand unsupervised methods to detect insider threat from en-\nterprise social and online activity data. Journal of Wireless\nMobile Networks, Ubiquitous Computing, and Dependable\nApplications 6(4):47–63.\n[Gopalan, Hofman, and Blei 2013] Gopalan, P.; Hofman,\nJ. M.; and Blei, D. M. 2013. Scalable recommendation with\nPoisson factorization. arXiv preprint arXiv:1311.1704.\n[Hochreiter and Schmidhuber 1997] Hochreiter, S., and\nSchmidhuber, J. 1997. Long short-term memory. Neural\ncomputation 9(8):1735–1780.\n[Hwang and Sung 2016] Hwang, K., and Sung, W. 2016.\nCharacter-level language modeling with hierarchical recur-\nrent neural networks. arXiv preprint arXiv:1609.03777.\n[Kent 2016] Kent, A. D. 2016. Cyber security data sources\nfor dynamic network research. Dynamic Networks and\nCyber-Security 1:37.\n[Koutnik et al. 2014] Koutnik, J.; Greff, K.; Gomez, F.; and\nSchmidhuber, J. 2014. A clockwork RNN. arXiv preprint\narXiv:1402.3511.\n[Kumar, Kumar, and Sachdeva 2010] Kumar, G.; Kumar, K.;\nand Sachdeva, M. 2010. The use of artiﬁcial intelligence\nbased techniques for intrusion detection: a review. Artiﬁcial\nIntelligence Review 34(4):369–387.\n[Ling et al. 2015a] Ling, W.; Lu ´ıs, T.; Marujo, L.; Astudillo,\nR. F.; Amir, S.; Dyer, C.; Black, A. W.; and Trancoso, I.\n2015a. Finding function in form: Compositional charac-\nter models for open vocabulary word representation. arXiv\npreprint arXiv:1508.02096.\n[Ling et al. 2015b] Ling, W.; Trancoso, I.; Dyer, C.; and\nBlack, A. W. 2015b. Character-based neural machine trans-\nlation. arXiv preprint arXiv:1511.04586.\n[Liu, Ting, and Zhou 2008] Liu, F. T.; Ting, K. M.; and\nZhou, Z.-H. 2008. Isolation forest. In Proc. ICDM.\n[Novakov et al. 2013] Novakov, S.; Lung, C.-H.; Lam-\nbadaris, I.; and Seddigh, N. 2013. Studies in applying\nPCA and wavelet algorithms for network trafﬁc anomaly\ndetection. In High Performance Switching and Routing\n(HPSR), 2013 IEEE 14th International Conference on, 185–\n190. IEEE.\n[Pascanu et al. 2015] Pascanu, R.; Stokes, J. W.; Sanossian,\nH.; Marinescu, M.; and Thomas, A. 2015. Malware classi-\nﬁcation with recurrent networks. In Acoustics, Speech and\nSignal Processing (ICASSP), 2015 IEEE International Con-\nference on, 1916–1920. IEEE.\n[Pedregosa et al. 2011] Pedregosa, F.; Varoquaux, G.; Gram-\nfort, A.; Michel, V .; Thirion, B.; Grisel, O.; Blondel, M.;\nPrettenhofer, P.; Weiss, R.; Dubourg, V .; Vanderplas, J.; Pas-\nsos, A.; Cournapeau, D.; Brucher, M.; Perrot, M.; and Duch-\nesnay, E. 2011. Scikit-learn: Machine learning in Python.\nJournal of Machine Learning Research 12:2825–2830.\n[Ringberg et al. 2007] Ringberg, H.; Soule, A.; Rexford, J.;\nand Diot, C. 2007. Sensitivity of PCA for trafﬁc anomaly\ndetection. In SIGMETRICS.\n[Rubin-Delanchy, Lawson, and Heard 2016] Rubin-\nDelanchy, P.; Lawson, D. J.; and Heard, N. A. 2016.\nAnomaly detection for cyber security applications. Dy-\nnamic Networks and Cyber-Security 1:137.\n[Schuster and Paliwal 1997] Schuster, M., and Paliwal, K. K.\n1997. Bidirectional recurrent neural networks. IEEE Trans-\nactions on Signal Processing 45(11):2673–2681.\n[Shyu et al. 2003] Shyu, M.-L.; Chen, S.-C.; Sarinnapakorn,\nK.; and Chang, L. 2003. A novel anomaly detection scheme\nbased on principal component classiﬁer. In Proc. ICDM.\n[Sommer and Paxson 2010] Sommer, R., and Paxson, V .\n2010. Outside the closed world: On using machine learn-\ning for network intrusion detection. In Proc. Symposium on\nSecurity and Privacy.\n[Tuor et al. 2017] Tuor, A.; Kaplan, S.; Hutchinson, B.;\nNichols, N.; and Robinson, S. 2017. Deep learning for un-\nsupervised insider threat detection in structured cybersecu-\nrity data streams. In Artiﬁcial Intelligence for Cybersecurity\nWorkshop at AAAI.\n[Turcotte et al. 2016] Turcotte, M.; Moore, J.; Heard, N.; and\nMcPhall, A. 2016. Poisson factorization for peer-based\nanomaly detection. In Intelligence and Security Informat-\nics (ISI), 2016 IEEE Conference on, 208–210. IEEE.\n[Turcotte, Heard, and Kent 2016] Turcotte, M. J.; Heard,\nN. A.; and Kent, A. D. 2016. Modelling user behavior in\na network using computer event logs. Dynamic Networks\nand Cyber-Security 1:67.\n[Veeramachaneni et al. 2016] Veeramachaneni, K.; Arnaldo,\nI.; Korrapati, V .; Bassias, C.; and Li, K. 2016.AI2: Training\na big data machine to defend. In Proc. HPSC and IDS.\n[Zuech, Khoshgoftaar, and Wald 2015] Zuech, R.; Khosh-\ngoftaar, T. M.; and Wald, R. 2015. Intrusion detection\nand big heterogeneous data: a survey. Journal of Big Data\n2(1):3.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7926980257034302
    },
    {
      "name": "Anomaly detection",
      "score": 0.68522047996521
    },
    {
      "name": "Artificial neural network",
      "score": 0.6610178351402283
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5756054520606995
    },
    {
      "name": "Vocabulary",
      "score": 0.557336688041687
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5206767320632935
    },
    {
      "name": "Language model",
      "score": 0.5050593018531799
    },
    {
      "name": "Data mining",
      "score": 0.4824976921081543
    },
    {
      "name": "Feature engineering",
      "score": 0.47372546792030334
    },
    {
      "name": "Recurrent neural network",
      "score": 0.4280608594417572
    },
    {
      "name": "Machine learning",
      "score": 0.41474467515945435
    },
    {
      "name": "Anomaly (physics)",
      "score": 0.4144873023033142
    },
    {
      "name": "Deep learning",
      "score": 0.2985808551311493
    },
    {
      "name": "Condensed matter physics",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Linguistics",
      "score": 0.0
    }
  ]
}