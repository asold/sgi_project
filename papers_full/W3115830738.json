{
  "title": "Debunking Rumors on Twitter with Tree Transformer",
  "url": "https://openalex.org/W3115830738",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2010371457",
      "name": "Jing Ma",
      "affiliations": [
        "Hong Kong Baptist University"
      ]
    },
    {
      "id": "https://openalex.org/A1980296962",
      "name": "Wei Gao",
      "affiliations": [
        "Singapore Management University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2971351900",
    "https://openalex.org/W2188594517",
    "https://openalex.org/W2807880213",
    "https://openalex.org/W2897757923",
    "https://openalex.org/W2032897813",
    "https://openalex.org/W3125491592",
    "https://openalex.org/W2741930413",
    "https://openalex.org/W2970550739",
    "https://openalex.org/W2158899491",
    "https://openalex.org/W2142869398",
    "https://openalex.org/W2952802110",
    "https://openalex.org/W2424495361",
    "https://openalex.org/W2952230511",
    "https://openalex.org/W2577888896",
    "https://openalex.org/W2267186426",
    "https://openalex.org/W2742144412",
    "https://openalex.org/W2950720493",
    "https://openalex.org/W2997976265",
    "https://openalex.org/W1975594555",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2971270287",
    "https://openalex.org/W2146502635",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2798787718",
    "https://openalex.org/W2051405935",
    "https://openalex.org/W1638051351",
    "https://openalex.org/W4394232863",
    "https://openalex.org/W2281420995",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2963627077",
    "https://openalex.org/W2951288507",
    "https://openalex.org/W2084591134",
    "https://openalex.org/W1546111015",
    "https://openalex.org/W2962788148"
  ],
  "abstract": "Rumors are manufactured with no respect for accuracy, but can circulate quickly and widely by “word-of-post” through social media conversations. Conversation tree encodes important information indicative of the credibility of rumor. Existing conversation-based techniques for rumor detection either just strictly follow tree edges or treat all the posts fully-connected during feature learning. In this paper, we propose a novel detection model based on tree transformer to better utilize user interactions in the dialogue where post-level self-attention plays the key role for aggregating the intra-/inter-subtree stances. Experimental results on the TWITTER and PHEME datasets show that the proposed approach consistently improves rumor detection performance.",
  "full_text": "Proceedings of the 28th International Conference on Computational Linguistics, pages 5455–5466\nBarcelona, Spain (Online), December 8-13, 2020\n5455\nDebunking Rumors on Twitter with Tree Transformer\nJing Ma\nDept. of Computer Science\nHong Kong Baptist University\nHong Kong\nmajing@comp.hkbu.edu.hk\nWei Gao\nSchool of Information Systems\nSingapore Management University\nSingapore\nweigao@smu.edu.sg\nAbstract\nRumors are manufactured with no respect for accuracy, but can circulate quickly and widely\nby “word-of-post” through social media conversations. Conversation tree encodes important\ninformation indicative of the credibility of rumor. Existing conversation-based techniques for\nrumor detection either just strictly follow tree edges or treat all the posts fully-connected during\nfeature learning. In this paper, we propose a novel detection model based on tree transformer to\nbetter utilize user interactions in the dialogue where post-level self-attention plays the key role for\naggregating the intra-/inter-subtree stances. Experimental results on the TWITTER and PHEME\ndatasets show that the proposed approach consistently improves rumor detection performance.\n1 Introduction\nOnline rumor perhaps is one of the most prevalent social diseases in the era of social media. An immediate\nexample we are witnessing is the unprecedented information disorder represented by various rumors,\nconspiracy theories, hoaxes, fake news, etc. in parallel with the worldwide pandemic of COVID19. In\ndifferent places, a number of people were hospitalized or even died for drinking bootleg alcohol to prevent\ncoronavirous infection, resulting from a false rumor attack on gullible public claiming that “smoking,\nmethanol or cocaine can cure for the virus”1. Automatic rumor debunking is at the core of battle against\nsuch massive disorder of information especially in the midst of crisis.\nRumor debunking aims to determine the veracity of a given topic or a claim. Fact-checking websites,\nsuch as snopes.com and politifact.com, employ manual veriﬁcation and investigative journalism,\nwhich is prone to low efﬁciency and poor coverage. For automated approaches, prior studies focus on\nengineering or learning features from sequential microblog streams (Castillo et al., 2011; Yang et al.,\n2012; Kwon et al., 2013; Liu et al., 2015; Ma et al., 2015; Ma et al., 2016; Yu et al., 2017). More recently,\nstructure-based learning based on structured neural networks are proposed to capture the interactive\ncharacteristics of rumor diffusion, such as tree kernel (Ma et al., 2017), recursive neural network (Ma\net al., 2018) and tree LSTM model (Kumar and Carley, 2019). Khoo et al. (2020) proposed to model\npotential dependencies between any two microblog posts with the post-level self-attention networks\n(PLAN), which has achieved the state-of-the-art detection performance.\nThe PLAN model essentially treats the input tweets as a fully connected graph, by assuming that a\nuser may not be directed solely at the tweet being replied considering the content created could also\nbe applicable to other tweets in the thread (Khoo et al., 2020). Also, the representation of posts is\nenhanced by leveraging the strength of transformer’s encoding architecture. Nevertheless, we argue that\nsuch full connection which ignores the speciﬁc targets of replies in the hierarchy could create salient\nissues on post representation learning, especially in the vein of relatively deep conversation or argument.\nMeanwhile, other existing tree-structured models based on propagation trees (Wu et al., 2015; Ma et al.,\n2017) or recursive trees (Ma et al., 2018; Kumar and Carley, 2019) tend to oversimplify user interaction\nby genuinely following the tree edges for post matching or encoding.\nThis work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: http://\ncreativecommons.org/licenses/by/4.0/.\n1https://time.com/5828047/methanol-poisoning-iran/\n5456\n(a) Propagation tree of a false rumor\n (b) Relative stance and underlying veracity patterns\nFigure 1: A motivating example: A false rumor about “Mike Pence delivering empty boxes of PPE for PR\nstunt” widely spread on Twitter and the stances relative to parent nodes implying the underlying credibility\nof the claim.\nTo illustrate our intuition, Figure 1 exempliﬁes the propagation structure of a (rumor) claim “Mike\nPence caught on hot mic delivering empty boxes of PPE for a PR stunt”. The PLAN model basically\nassumes each user directed at all the tweets in the thread, which may be true for a shallow tree where\nmost of nodes respond to the root node. However, this is not the case when it comes to a tree hierarchy\nas Figure 1 shows. It can be seen that accurate viewpoints is generally associated with the context of\nparent posts, e.g., x21 support x2, but x2 refute the source claim r, therefore x21 believe that the claim is\nfalse even though it contains a non-rumor-indicative patten “be right”. On the other hand, x21 even has no\ncontext correlation with the nodes from another branch such as x12. But the PLAN model might brought\nunexpected errors in this case when linking x21 with r(or x12) when making fully pairwise comparison.\nTo this end, we propose to enhance the representation by exploring the stances towards the same target\nutilizing the associated contextual information. The starting point of our approach is an observation: each\npost in the propagation tree may trigger a set of responsive tweets (such as x1 →[x11,x12] in Figure 1),\nwe deﬁne such unit as a subtree, which eventually compose the whole tree hierarchy. Accordingly, we\nextend the conventional transformer’s encoder into three variants, i.e., a bottom-up transformer, a top-down\ntransformer, and a hybrid transformer model. More speciﬁcally, our models selectively attend over tweets\nin the same subtree. As a result, it can be expected that user‘s viewpoint can be fully captured based on\nthe context of propagation path. Meanwhile, inaccurate information in a subtree can be cross-checked as\nusers share opinions towards the same target (i.e., the subtree root). We construct two shallow tree datasets\nand two deep tree datasets referring from two publicly benchmarks TWITTER and PHEME. Extensive\nexperimental results demonstrate that our approach consistently improve over the state-of-the-art rumor\ndetection and early detection baselines, particularly performing well on the deep trees.\n2 Related Work\nThis section ﬁrstly reviews the recent progress about rumor detection. Most previous automatic approaches\nfor rumor detection (Castillo et al., 2011; Yang et al., 2012; Liu et al., 2015) intended to learn a supervised\nclassiﬁer by utilizing a wide range of features crafted from post contents, user proﬁles and propagation\npatterns. Subsequent studies were then conducted to engineer new features such as those representing\nrumor diffusion and cascades (Kwon et al., 2013; Friggeri et al., 2014; Hannak et al., 2014). Ma et\nal. (2015) extended their model with a large set of chronological social context features. These approaches\ntypically require heavy preprocessing and feature engineering.\nZhao et al. (2015) alleviated the engineering effort by using a set of regular expressions (such as\n“really?”, “not true”, etc) to ﬁnd questing and denying tweets, but the approach was oversimpliﬁed and\nsuffered from very low recall. Ma et al. (2016) and Yu et al. (2017) respectively used recurrent neural\nnetworks (RNNs) and convolutional neural networks (CNNs) to learn automatically the representations\nfrom tweets content based on time series. Guo et al. (2018) proposed a hierarchical attention model which\ncaptures important clues from social context of a rumorous event at the post and sub-event levels. Jin et\nal. (2016) exploited the conﬂicting viewpoints in a credibility propagation network for verifying news\n5457\nstories propagated among the tweets. However, these approaches cannot embed features reﬂecting how\nthe posts are propagated and requires careful data segmentation to prepare for the time sequence.\nSome kernel-based methods were exploited to model the propagation structure. Wu et al. (2015)\nproposed a hybrid SVM classiﬁer which combines a RBF kernel and a random-walk-based graph kernel\nto capture both ﬂat and propagation patterns for detecting rumors on Sina Weibo. Ma et al. (2017) used\ntree kernel to capture the similarity of propagation trees by counting their similar substructures in order to\nidentify different types of rumors on Twitter. Ma et al. (2018) presented tree-structured recursive neural\nnetworks (RvNN) to jointly generate the representation of a propagation tree based on the posts content\nand their propagation structure.\nIn recent years, transformer (Vaswani et al., 2017) have demonstrates state-of-the-art performance in a\nvariety of NLP tasks such as machine translation (Vaswani et al., 2017), sentence representation (Devlin\net al., 2019), generative dialog (Tao et al., 2018), machine reading (Cheng et al., 2016), semantic\nlabeling (Strubell et al., 2018), and rumor detection (Khoo et al., 2020). Transformer produce strong\npower of representations by applying attention to each pair of elements from an input sequence, regardless\nof their distance. Khoo et al. (2020) propose a rumor veriﬁcation model that allows direct modeling of\ndependencies between any two posts without regarding to their responsive relation, thus it essentially treats\nthe propagation as a fully connected graph instead of a tree. Our work is inspired by the idea of improving\nthe representation power of transformer to model structured objects such as syntactic parse tree. In these\nworks, a straightforward strategy is to augment the conventional transformer with structural positional\nembeddings (Wang et al., 2019a; Shiv and Quirk, 2019). On the other hand, Tree Transformer is proposed\nto attend over nearer neighbor nodes (Ahmed et al., 2019; Wang et al., 2019b). Our proposed method is a\nsubstantial extension of Tree Transformer for modeling propagation tree structures for detecting rumors\non microblogging websites.\n3 Problem Statement and Notations\nOn microblogging platforms such as Twitter, the follower/friend relationship embeds shared interests\namong the users. Once a user has posted a tweet, all his followers will receive it. Twitter allows a user to\nretweet or comment on another user‘s post, so that the information could reach beyond the followers of\nthe original creator. Therefore, we model the propagation of each claim as a tree structure T(r) = ⟨V,E⟩,\nwhere ris tree root representing the source tweet that states the claim, V refers to a set of nodes each\nrepresenting a responding post of r in the thread of the circulation, and E is a set of directed edges\ncorresponding to the response relation among the nodes in V. Inspired by (Ma et al., 2018), here we\nconsider two different propagation trees with distinct edge directions: (1) Bottom-Up tree where the\nresponsive nodes point to their responded nodes, similar to a citation network; and (2) Top-Down tree\nwhere the edge follows the direction of information diffusion by reversing the Bottom-up tree.\nWe formulate this task as a supervised classiﬁcation problem, which learns a classiﬁer f from the\nlabeled claims, that is, f : Ci →Yi, where Yi takes one of the four categories: Non-rumor, True rumor,\nFalse rumor and Unveriﬁed rumor (NTFU), that are introduced in previous literature (Zubiaga et al.,\n2016b; Ma et al., 2017).\n4 Tree Transformer Model for Rumor Detection\nRumor indicative features can be captured from propagation structures, e.g., the stances expressed in\nresponsive tweets can further reinforce the stances of that tweet is replying to (Ma et al., 2018; Kumar and\nCarley, 2019), the posts with strong stance based on the tree branch is more important when determining\nthe rumor veracity (Li et al., 2019), and inaccurate information might be “self-checked” by making\ncomparison with correlative tweets (Zubiaga et al., 2018). However, such relation is not fully exploited\nby previous work. Our core idea is to enhance representation learning of rumor indicative features by\nselectively attending over the corresponding tweets, that deeply explore user opinions and reﬁne inaccurate\ninformation following the propagation tree structure.\nUnlike the PLAN model that rawly handcraft 5 types of responsive relation as an additional consideration\nwhen attending over all the other tweets, our idea and the adopted mechanisms are signiﬁcantly different.\n5458\n(a) An example of Bottom-Up/Top-Down tree\n(b) Subtree Attention\n (c) Bottom-up Transformer\n (d) Top-down Transformer\nFigure 2: Illustration of a propagation tree and the corresponding tree transformer models. In Figure 2(a),\nT(·) denote a subtree rooted by the node in green, that we put at the ﬁrst line of the subtree. The edges in\nred and blue apply the Bottom-Up and Top-Down tree respectively.\nFigure 2 gives an overview of our transformer-based framework respectively based on Bottom-Up tree\nand Top-Down tree, which will be depicted in detail in the subsections.\n4.1 Token-Level Tweet Representation\nGiven a tweet represented as a word sequencexi = (w1 ···wt ···w|xi|), each wt ∈Rd is a d-dimensional\nvector which can be initialized with pre-trained word embeddings. We map each wt into a ﬁxed-sized\nhidden vector using Multi-Head Self-Attention networks( MH-SAN), which are the defaults setting in\nTransformer encoder (Vaswani et al., 2017). The core idea of MH-SAN is to jointly attend to words from\ndifferent representation subspaces at different positions. More speciﬁcally, MH-SAN ﬁrstly transform the\ninput word sequence xi into multiple subspaces with different linear projections:\nQh\ni ,Kh\ni ,V h\ni = xi ·Wh\nQ, x i ·Wh\nK, x i ·Wh\nV (1)\nwhere {Qh\ni ,Kh\ni ,V h\ni }are respectively the query, key and value representations, and {Wh\nQ,Wh\nK,Wh\nV }\ndenote parameter matrices associated with the hth head. Then, attention functions are applied to generate\nthe output states.\nOh\ni = softmax(Qh\ni ·Kh\ni\n⊤\n√dh\n) ·Vh\ni (2)\nHere √dh is the scaling factor and dh represent the dimensionality of the hth head subspace. Finally, the\noutput of representation could be regard as a concatenation of all the heads Oi = [O1\ni ,O2\ni ,··· ,On\ni ] ∈\nR|xi|×d with n as the number of heads, which followed by a normalization layer (layerNorm) and a\n5459\nfeed-forward network (FFN) consistant with the usage of Transformer.\nBi = layerNorm(Oi ·WB + Oi)\nHi = FFN(Bi ·WS + Bi) (3)\nwhere Hi = [h1; ... ; h|xi|] ∈R|xi|×d is the matrix representing all words in tweet xi, and WB and Wh\ncontain the weights of the transformation. Finally, we obtain the representation of xi by maxpooling the\nvectors of all involved words:\nsi = max-pooling(h1,...,h |xi|) (4)\nwhere si ∈R1×d is a d-dimensional vector, and |·| denotes the number of words.\n4.2 Post-Level Tweet Representation\nPrevious literature has generally found that each node in the tree can trigger a set of responsive posts, i.e.,\na subtree, which contain distinct rumor-indicative pattens (Ma et al., 2017). Our goal is to cross-check all\nthe posts in the same subtree to enhance the representation learning, because: (1) posts are generally short\nin nature thus the stance expressed in each node is closely correlated with the responsive context; and\n(2) posts in the same subtree direct at the individual opinion expressed in the root of the subtree. Thus\ncoherent opinions can be captured by comparing ALL responsive posts in the same subtree, that lower\nweight the incorrect information (e.g., the supportive posts towards a false claim).\nTo this end, we propose to utilize transformer-based network to make pairwise comparison within a\nsubtree, that capture users‘ opinions and enhance the representation for each node. In this paper, we\ndevelop two structures respectively based on Bottom-Up tree and Top-Down tree:\nBottom-Up Transformer. In Bottom-Up tree, we visit the root of each subtree from the leaf node\nhierarchically until reaching the source tweet. We propose a Bottom-Up transformer to capture coherent\nattitudes towards each tree node, by making pairwise comparison among its responsive tweets.\nFigure 2(c) illustrated the structure of our tree transformer that cross-check all the posts from the bottom\nsubtree to the upper subtrees. Speciﬁcally, given a subtree rooted at xj, Let V(j) = {xj,...,x k}denote\nthe set of node in the subtree, i.e., xj and its direct response nodes. Then we apply a post-level subtree\nattention (i.e., a transformer-based block as shown in Figure 2(b)) onV(j) to get the reﬁned representation\nfor each node in V(j):\n[s′\nj; ... ; s′\nk] = TRANS ([sj; ... ; sk],ΘT ) (5)\nwhere TRANS (·) is the transform function that has similar forms as shown in Eq. 2-4, and ΘT contains\nthe transformer parameters. Thus s′\n∗is the reﬁned representation of s∗obtained based on the context\nof subtree. Note that each node can be treated as either parent or child in different subtrees, e.g., in\nFigure 2(a), x2 can either be the parent node of T(x2), or a child node of T(r). As a result, a part of\nnodes in our model are reﬁned twice hierarchically from bottom subtree to upper subtree, that: (1) capture\nstances by comparing with parent node, and (2) lower-weight inaccurate information by attending over\nneighbor nodes, e.g., a parent that support a false claim might be reﬁned if the majority responses refute\nthe parent node.\nTop-Down Transformer.This model is designed to leverage the structure of Top-Down tree, which\nis shown in Figure 2(d). Since Top-Down tree models how the information ﬂows from source post\nto the current node, our model visits each subtree hierarchically from the source node until the leaf\nnodes. The transformer mechanism shares the similar intuition as the Bottom-Up transformer, thus node\nrepresentation is enhanced by capturing stances and self-corrected context information.\n5460\n4.3 The overall Model\nTo jointly capture the opinions expressed in the whole tree, we utilize an attention layer to select important\nposts with accurate information, which is obtained based on the reﬁned node representation. This yields:\nαi = exp(s′\ni ·µ⊤)∑\nj exp(s′\nj ·µ⊤)\n˜s=\n∑\ni\nαi ·s′\ni\n(6)\nwhere s′\ni is obtained from either Bottom-Up Transformer or Top-Down Transformer 2, and µ ∈R1×d\ncontains the weights of the transformation. Here αi is the attention weight of node xi which is used to\nproduce the representation ˜sof an entire tree. Lastly, we use a fully connected output layer to predict the\nprobability distribution over the rumor classes.\nˆy= softmax(Vo ·˜s+ bo) (7)\nwhere Vo and bo are the weights and bias in the output layer.\nFurthermore, there is a straightforward way to concatenate the tree representation from the Bottom-Up\ntransformer, with that from the Top-Down transformer to obtain a richer tree representation, which is then\nfed into the above softmax(·) function to make rumor predictions.\nModel Training. All our models are trained to minimize the squared error between the probability\ndistribution of the prediction and that of the ground truth:\nL(y,ˆy) =\nN∑\nn=1\nC∑\nc=1\n(yc −ˆyc)2 + λ||Θ||2\n2 (8)\nwhere yc is the ground-truth label and ˆyc is the predicted probability of class c, N is the number of trees\nfor training, Cis the number of classes, ||.||2 is the L2 regularization term over all the model parameters\nΘ, and λis the trade-off coefﬁcient.\nDuring training, parameters are updated through back-propagation (Collobert et al., 2011) with Ada-\nGrad (Duchi et al., 2011) for speeding up convergence. The training process ends when the model\nconverges or the maximum epoch number is met. We represent input words using pre-trained GloVe\nWikipedia 6B word embeddings (Pennington et al., 2014). We set model dimension dto 300 and the\ndimension for feedforward network is 600. We used 1 and 6 layers of transformer encoder for token-level\nrepresentation and post-level representation respectively, and set the head numbernas 12. The learning\nrate is initialized as 0.01, and the dropout rate is 0.2.\n5 Experiments and Results\n5.1 Datasets\nFor experimental evaluation, we refer two publicly available tree datasets released by (Ma et al., 2017)\nand (Kochkina et al., 2018), namely TWITTER and PHEME. In each dataset, a group of source tweets,\nwhich form the tree roots, together with their replies are provided in the form of tree structure. Each tree is\nannotated with one of the four class labels, i.e., non-rumor, true rumor, unveriﬁed rumor and false rumor.\nTo evaluate the robustness of our tree structured detection methods, we consider two types of datasets:\npropagation trees with shallow depth and trees with deep depth (i.e., complex responsive relations). There-\nfore, we regroup the trees in each of the datasets into TWO according to the tree depth. Speciﬁcally, we\nsplit Twitter (PHEME) dataset into TWITTER-S (PHEME-S) and TWITTER-D (PHEME-D), comprised\nby shallow trees and deep trees respectively. Table 1 displays the basic statistics of the four datasets.\n2It can be s′′\ni if the node is reﬁned twice, e.g., s′′\n2 in Figure 2(c) and 2(d).\n5461\nTable 1: Statistics of the datasets\nStatistic TWITTER-S TWITTER-D PHEME-S PHEME-D\n# of source tweets 1,293 813 1,946 1,842\n# of tree nodes 29,142 72,365 28,550 60,943\n# of non-rumors 334 244 1,231 1,248\n# of false 326 231 167 134\n# of true 389 183 310 277\n# of unveriﬁed 244 155 238 183\nAvg. time length / tree 212 Hours 628 Hours 15 Hours 25 Hours\nAvg. depth / tree 1.82 8.02 2.39 7.71\nMax depth / tree 3 84 3 47\nMin depth / tree 1 4 2 4\nAvg. # of posts / tree 22 89 14 33\nMax # of posts / tree 203 788 51 346\nMin # of posts / tree 2 7 3 5\n5.2 Experimental Setup\nFor evaluation, we will make comprehensive comparisons between our proposed models and state-of-the-\nart baselines on rumor classiﬁcation and early detection tasks.\n- DT-Rank: (Zhao et al., 2015) proposed a Decision-Tree-based Ranking model to identify trending\nrumors by searching for inquiry phrases.\n- DTC: An information credibility model using a Decision-Tree Classiﬁer (Castillo et al., 2011) using\nhand-crafted features that are based on the overall statistics of the posts without temporal information.\n- RFC: A Random Forest Classﬁer which used three ﬁtting parameters as temporal properties and a set\nof hand-crafted features based on user, linguistic and structural properties (Kwon et al., 2013).\n- SVM-TK: A SVM classiﬁer that uses aTree Kernel (Ma et al., 2017) which try to capture propagation\nstructure via kernel learning.\n- GRU-RNN: A rumor detection model based on recurrent neural networks (Ma et al., 2016) with GRU\nfor learning rumor representations by modeling sequential structure of relevant posts.\n- BU-RvNN and TD-RvNN: The rumor detection models respectively based on bottom-up and top-\ndown RvNN models (Ma et al., 2018) for integrating tweet contents and structure clues.\n- PLAN: A rumor detection model based on transformer networks (Khoo et al., 2020) to model long\ndistance interactions between any pair of tweets that oversimpliﬁes responsive relations.\n- BU-TRANS , TD-TRANS and HD-TRANS : Our proposed tree transformer models respectively with\nBottom-Up, Top-Down and Hybrid manner (see Section. 4).\nWe implement DT-Rank, DTC and RFC using Weka3, SVM-TK using LibSVM4 and all neural-\nnetwork-based models with pytorch5. We use micro-averaged and macro-averaged F1 score, and class-\nspeciﬁc F-measure as evaluation metrics. We hold out 10% of the datasets for tuning the hyper parameters,\nand conduct 5-fold cross-validation on the rest of the datasets.\n5.3 Rumor Classiﬁcation Performance\nTable 2 demonstrate the performance of all the compared methods respectively based on the shallow trees\nand deep trees from TWITTER and PHEME datasets. The results indicate that our proposed methods\noutperform all the baselines6, conﬁrming the advantages of Tree transformer for rumor detection task.\nIt is observed that the performances of the three baselines in the ﬁrst group based on handcrafted\nfeatures are obviously poor. RFC perform relatively better because of the usage of additional temporal\ntraits. Among the baselines without feature engineering in the second group, the sequential neural model\nGRU-RNN without considering structural information performs slightly worse than SVM-TK, because\nSVM-TK is an integrated kernel that utilize the propagation structure by comparing the trees based on\n3www.cs.waikato.ac.nz/ml/weka\n4www.csie.ntu.edu.tw/˜cjlin/libsvm\n5pytorch.org\n6We use micF to evaluate TWITTER-S (D) datasets, but macF for PHEME-S (D) datasets owing to the imbalanced class\nprevalence (see Table 1), to capture competitive performance beyond the majority class (Zubiaga et al., 2016a)\n5462\nTable 2: Results of comparison among different models. (NR: non-rumor; FR: false rumor; TR: true\nrumor; UR: unveriﬁed rumor)\n(a) TWITTER-S (-D) dataset\nDataset TWITTER-S TWITTER-D\nMethod NR FR TR UR NR FR TR UR\nmicF macF F1 F1 F1 F1 micF macF F1 F1 F1 F1\nDT-Rank 0.467 0.443 0.622 0.329 0.520 0.299 0.566 0.516 0.447 0.577 0.555 0.484\nDTC 0.523 0.502 0.728 0.418 0.512 0.349 0.538 0.497 0.758 0.516 0.332 0.381\nRFC 0.599 0.550 0.782 0.470 0.561 0.385 0.582 0.533 0.774 0.501 0.461 0.395\nSVM-TK 0.719 0.714 0.705 0.683 0.785 0.682 0.669 0.663 0.698 0.649 0.689 0.615\nGRU-RNN 0.715 0.701 0.700 0.697 0.780 0.620 0.646 0.645 0.645 0.624 0.714 0.598\nBU-RvNN 0.738 0.728 0.734 0.672 0.825 0.681 0.698 0.699 0.674 0.693 0.741 0.687\nTD-RvNN 0.749 0.738 0.724 0.729 0.830 0.684 0.705 0.704 0.725 0.677 0.759 0.656\nPLAN 0.764 0.757 0.742 0.744 0.840 0.699 0.719 0.715 0.746 0.708 0.760 0.646\nBU-TRANS 0.774 0.729 0.750 0.772 0.821 0.753 0.753 0.745 0.771 0.772 0.767 0.670\nTD-TRANS 0.776 0.772 0.739 0.780 0.826 0.742 0.755 0.748 0.778 0.773 0.740 0.701\nHD-TRANS 0.789 0.787 0.749 0.784 0.837 0.776 0.768 0.764 0.773 0.781 0.783 0.721\n(b) PHEME dataset\nDataset PHEME-S PHEME-D\nMethod NR FR TR UR NR FR TR UR\nmicF macF F1 F1 F1 F1 micF macF F1 F1 F1 F1\nDT-Rank 0.557 0.319 0.722 0.194 0.323 0.037 0.543 0.303 0.710 0.136 0.187 0.177\nDTC 0.614 0.424 0.763 0.308 0.341 0.286 0.695 0.465 0.819 0.271 0.442 0.328\nRFC 0.701 0.482 0.825 0.304 0.486 0.332 0.708 0.515 0.820 0.231 0.528 0.484\nSVM-TK 0.771 0.656 0.864 0.610 0.629 0.523 0.776 0.639 0.862 0.578 0.572 0.578\nGRU-RNN 0.765 0.632 0.872 0.698 0.574 0.384 0.781 0.610 0.868 0.629 0.510 0.393\nBU-RvNN 0.775 0.649 0.862 0.622 0.592 0.523 0.789 0.651 0.877 0.606 0.583 0.546\nTD-RvNN 0.783 0.668 0.874 0.607 0.631 0.561 0.786 0.667 0.881 0.634 0.648 0.508\nPLAN 0.800 0.688 0.872 0.645 0.629 0.605 0.798 0.681 0.879 0.689 0.602 0.551\nBU-TRANS 0.794 0.704 0.875 0.683 0.621 0.636 0.831 0.731 0.908 0.652 0.708 0.656\nTD-TRANS 0.790 0.701 0.881 0.730 0.620 0.570 0.825 0.722 0.904 0.681 0.667 0.635\nHD-TRANS 0.793 0.710 0.872 0.728 0.600 0.644 0.839 0.745 0.806 0.715 0.755 0.702\nboth textual and structural similarities. Tree-structured neural models, i.e., BU-RVNN and TD-RvNN,\nmake further improvements since it deeply bridge the content semantics and propagation clues.\nAmong all the baselines, PLAN perform best since it leverage the representation power of transformer by\nmodeling dependencies between any two tweets, but this may under-utilize the structural information. In\ncontrast, our proposed TRANS -based models (in the third group), not only inherently leverage propagation\nstructure but also take advantages of the representation power of transformer, thus beat PLAN on the\nfour datasets. Among our three TRANS -based models, BU-TRANS and TD-TRANS perform comparable\nbecause both explore tree structure utilizing Transformer. And combing them makes further improvements\nas HD-TRANS did, suggesting that the learned pattens from the two models are complementary.\nFurthermore, when drilling down to the performance of our TRANS -based models on speciﬁc datasets,\nwe ﬁnd that there are distinct observations of model performance between the shallow tree and deep\ntree. Speciﬁcally, on TWITTER-D and PHEME-D datasets, we observe the tree-based baselines (e.g.,\nBU-RvNN and TD-RvNN) perform comparable to PLAN, and the improvements of our models over\nPLAN range from 5.31%−6.82% (7.34%−9.40%) accuracy (macroF score) on Twitter-D (PHEME-D).\nThe reason is that PLAN is originally proposed and experimented on shallow trees (Khoo et al., 2020),\nwhich may not be generalize well on trees with deep and/or complex responsive relationships.\nIn comparison, on TWITTER-S and PHEME-S dataset, PLAN perform better than TD-RvNN (i.e.,\nthe best tree-structured baseline) in a larger margin, and our TRANS -based models improve over PLAN\nby 1.31%−3.27% (2.33%−3.20%) in terms of accuracy (macroF score) on TWITTER-S (PHEME-S)\ndataset, which is relatively lower than the improvements made on TWITTER-D and PHEME-D datasets.\nThis is because the homogeneous edges (e.g., majority responsive nodes straightforwardly direct at the\nsource post) in shallow trees have limited identical structure clues for rumor detection. This also veriﬁes\nthe hypothesis we made in Section 1 that tree-structured methods is more effective for deep trees.\n5463\n5.4 Early Rumor Detection Performance\n(a) TWITTER-S\n (b) TWITTER-D\n (c) PHEME-S\n (d) PHEME-D\nFigure 3: Early rumor detection accuracy at different checkpoints in terms of elapsed time.\nDebunking rumors at early stage of their propagation is very important so that preventive measures can\nbe taken in a timely manner. In early rumor detection task, we compare different detection methods at\na series of elapsed time checkpoints. Figure 3 shows the performance of our HD-TRANS model versus\nPLAN (the best performed baseline), TD-RvNN (the best tree-structured neural model), RFC (the best\nsystem based on feature engineering), and DT-Rank (an algorithm proposed for early rumor detection).\nWe observe that within the ﬁrst few hours, the performance of our HD- TRANS model grows more\nquickly and starts to supersede the other models at the early stage of propagation. Particularly, HD-TRANS\nachieves 75.0% (72.3%) accuracy on TWITTER-S (-D) and 65.9% (69.5%) macF score on PHEME-S\n(-D) within 12 hours. Although all the methods are getting saturated as time goes by, HD-TRANS only\nneed around 14 (12) hours on TWITTER-S (-D) and about 15 (10) hours on PHEME-S (-D), to achieve\nthe comparable performance of the best baseline model (i.e., PLAN), indicating superior early detection\nperformance of our method especially when comes to more complex or deeper propagation pattens.\n(a) A deep (false rumor) tree\n(b) A shallow (false rumor) tree\nFigure 4: Examples of correctly detected false rumors at early stage of our model.\nTo get an intuitive understanding of what is happening when we use HD-TRANS model, we design an\nexperiment to highlight the nodes with higher attention scores (i.e., “αi” in Eq. 6) at the tree representation\nlayer. Speciﬁcally, we sample two trees from TWITTER dataset, i.e., a shallow tree and a deep tree, at the\nearly stage of propagation, that both have been correctly classiﬁed as false rumors by our HD-TRANS .\nIn Figure 4, we observe that: 1) the highly ranked nodes with higher attention scores by HD-TRANS (in\nyellow), illustrated obvious structured rumor-indicative pattens, e.g., denial post spark afﬁrmative replies\nas x11 →[x111,x112] shows in the deep tree; 2) the nodes attended by PLAN (in green) are generally\n5464\nindependent of structure but taking coherent stances or semantics; and 3) the results of HD-TRANS and\nPLAN are signiﬁcantly different on the deep tree, but similar results can be found on the shallow tree,\nimplying that more complex propagation pattens can be better captured by our proposed model.\n6 Conclusions and Future Work\nIn this paper, with the analysis that modeling propagation structure is an essential factor for detecting\nrumors, we propose three variants of transformer to further enhance the representation learning directed at\ntree-structured modeling: a Bottom-up transformer, a Top-down tranformer, and a Hybrid model. The\nresults on four benchmark datasets conﬁrm the advantages of our methods as compared to state-of-the-art\nbaselines, especially well-generalized on trees with more complex responsive contexts. For future work,\nit is promising to include other types of edges/relationships besides the responsive relation to enhance\nrumor detection, such as friends/followers, quotation, mention, etc. We also plan to investigate the role of\nnon-textual media such as images or videos on the effectiveness of detecting rumors.\nReferences\nMahtab Ahmed, Muhammad Rifayat Samee, and Robert E Mercer. 2019. You only need attention to traverse trees.\nIn Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 316–322.\nCarlos Castillo, Marcelo Mendoza, and Barbara Poblete. 2011. Information credibility on twitter. In Proceedings\nof WWW, pages 675–684.\nJianpeng Cheng, Li Dong, and Mirella Lapata. 2016. Long short-term memory-networks for machine reading. In\nProceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 551–561.\nRonan Collobert, Jason Weston, L ´eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011.\nNatural language processing (almost) from scratch. Journal of Machine Learning Research , 12(Aug):2493–\n2537.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirec-\ntional transformers for language understanding. In Proceedings of the 2019 Conference of the North American\nChapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and\nShort Papers), pages 4171–4186.\nJohn Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochas-\ntic optimization. Journal of Machine Learning Research, 12(Jul):2121–2159.\nAdrien Friggeri, Lada A Adamic, Dean Eckles, and Justin Cheng. 2014. Rumor cascades. In Proceedings of\nICWSM.\nHan Guo, Juan Cao, Yazi Zhang, Junbo Guo, and Jintao Li. 2018. Rumor detection with hierarchical social\nattention network. In Proceedings of the 27th ACM International Conference on Information and Knowledge\nManagement, pages 943–951. ACM.\nAniko Hannak, Drew Margolin, Brian Keegan, and Ingmar Weber. 2014. Get back! you don’t know me like that:\nThe social mediation of fact checking interventions in twitter conversations. In Proceedings of ICWSM.\nZhiwei Jin, Juan Cao, Yongdong Zhang, and Jiebo Luo. 2016. News veriﬁcation by exploiting conﬂicting social\nviewpoints in microblogs. In Proceedings of the Thirtieth AAAI Conference on Artiﬁcial Intelligence , pages\n2972–2978. AAAI Press.\nLing Min Serena Khoo, Hai Leong Chieu, Zhong Qian, and Jing Jiang. 2020. Interpretable rumor detection in\nmicroblogs by attending to user interactions.\nElena Kochkina, Maria Liakata, and Arkaitz Zubiaga. 2018. PHEME dataset for Rumour Detection and Veracity\nClassiﬁcation. 6.\nSumeet Kumar and Kathleen M Carley. 2019. Tree lstms with convolution units to predict stance and rumor\nveracity in social media conversations. In Proceedings of the 57th Annual Meeting of the Association for\nComputational Linguistics, pages 5047–5058.\nSejeong Kwon, Meeyoung Cha, Kyomin Jung, Wei Chen, and Yajun Wang. 2013. Prominent features of rumor\npropagation in online social media. In Proceedings of ICDM, pages 1103–1108.\n5465\nQuanzhi Li, Qiong Zhang, and Luo Si. 2019. Rumor detection by exploiting user credibility information, attention\nand multi-task learning. In Proceedings of the 57th Annual Meeting of the Association for Computational\nLinguistics, pages 1173–1179.\nXiaomo Liu, Armineh Nourbakhsh, Quanzhi Li, Rui Fang, and Sameena Shah. 2015. Real-time rumor debunk-\ning on twitter. In Proceedings of the 24th ACM International on Conference on Information and Knowledge\nManagement, CIKM ’15, pages 1867–1870.\nJing Ma, Wei Gao, Zhongyu Wei, Yueming Lu, and Kam-Fai Wong. 2015. Detect rumors using time series\nof social context information on microblogging websites. In Proceedings of the 24th ACM International on\nConference on Information and Knowledge Management, CIKM ’15, pages 1751–1754.\nJing Ma, Wei Gao, Prasenjit Mitra, Sejeong Kwon, Bernard J Jansen, Kam-Fai Wong, and Meeyoung Cha. 2016.\nDetecting rumors from microblogs with recurrent neural networks. In Proceedings of the Twenty-Fifth Interna-\ntional Joint Conference on Artiﬁcial Intelligence, IJCAI’16, pages 3818–3824.\nJing Ma, Wei Gao, and Kam-Fai Wong. 2017. Detect rumors in microblog posts using propagation structure via\nkernel learning. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics\n(Volume 1: Long Papers), volume 1, pages 708–717.\nJing Ma, Wei Gao, and Kam-Fai Wong. 2018. Rumor detection on twitter with tree-structured recursive neural\nnetworks. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume\n1: Long Papers), volume 1, pages 1980–1989.\nJeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word represen-\ntation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP),\npages 1532–1543.\nVighnesh Shiv and Chris Quirk. 2019. Novel positional encodings to enable tree-based transformers. In Advances\nin Neural Information Processing Systems, pages 12058–12068.\nEmma Strubell, Patrick Verga, Daniel Andor, David Weiss, and Andrew McCallum. 2018. Linguistically-\ninformed self-attention for semantic role labeling. InProceedings of the 2018 Conference on Empirical Methods\nin Natural Language Processing, pages 5027–5038.\nChongyang Tao, Shen Gao, Mingyue Shang, Wei Wu, Dongyan Zhao, and Rui Yan. 2018. Get the point of my\nutterance! learning towards effective responses with multi-head attention mechanism. In Proceedings of the\n27th International Joint Conference on Artiﬁcial Intelligence, pages 4418–4424.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and\nIllia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems, pages\n5998–6008.\nXing Wang, Zhaopeng Tu, Longyue Wang, and Shuming Shi. 2019a. Self-attention with structural position\nrepresentations. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) , pages 1403–\n1409.\nYaushian Wang, Hung-Yi Lee, and Yun-Nung Chen. 2019b. Tree transformer: Integrating tree structures into self-\nattention. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and\nthe 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 1060–1070.\nKe Wu, Song Yang, and Kenny Q Zhu. 2015. False rumors detection on sina weibo by propagation structures. In\nData Engineering (ICDE), 2015 IEEE 31st International Conference on, pages 651–662. IEEE.\nFan Yang, Yang Liu, Xiaohui Yu, and Min Yang. 2012. Automatic detection of rumor on sina weibo. In Proceed-\nings of the ACM SIGKDD Workshop on Mining Data Semantics, MDS ’12, pages 13:1–13:7.\nFeng Yu, Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2017. A convolutional approach for misinformation\nidentiﬁcation. In Proceedings of the 26th International Joint Conference on Artiﬁcial Intelligence, pages 3901–\n3907. AAAI Press.\nZhe Zhao, Paul Resnick, and Qiaozhu Mei. 2015. Enquiring minds: Early detection of rumors in social media\nfrom enquiry posts. In Proceedings of the 24th International Conference on World Wide Web, WWW ’15, pages\n1395–1405.\n5466\nArkaitz Zubiaga, Elena Kochkina, Maria Liakata, Rob Procter, and Michal Lukasik. 2016a. Stance classiﬁcation\nin rumours as a sequential task exploiting the tree structure of social media conversations. In Proceedings\nof COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers , pages\n2438–2448.\nArkaitz Zubiaga, Maria Liakata, Rob Procter, Geraldine Wong Sak Hoi, and Peter Tolmie. 2016b. Analysing\nhow people orient to and spread rumours in social media by looking at conversational threads. PloS one ,\n11(3):e0150989.\nArkaitz Zubiaga, Ahmet Aker, Kalina Bontcheva, Maria Liakata, and Rob Procter. 2018. Detection and resolution\nof rumours in social media: A survey. ACM Computing Surveys (CSUR), 51(2):32.",
  "topic": "Rumor",
  "concepts": [
    {
      "name": "Rumor",
      "score": 0.9368159174919128
    },
    {
      "name": "Conversation",
      "score": 0.7776158452033997
    },
    {
      "name": "Computer science",
      "score": 0.7553743124008179
    },
    {
      "name": "Credibility",
      "score": 0.7518467903137207
    },
    {
      "name": "Transformer",
      "score": 0.5487495064735413
    },
    {
      "name": "Social media",
      "score": 0.5216717720031738
    },
    {
      "name": "Tree (set theory)",
      "score": 0.49809741973876953
    },
    {
      "name": "Key (lock)",
      "score": 0.42700421810150146
    },
    {
      "name": "Artificial intelligence",
      "score": 0.41362935304641724
    },
    {
      "name": "Machine learning",
      "score": 0.369811475276947
    },
    {
      "name": "Natural language processing",
      "score": 0.353232741355896
    },
    {
      "name": "World Wide Web",
      "score": 0.23778864741325378
    },
    {
      "name": "Computer security",
      "score": 0.2072087824344635
    },
    {
      "name": "Communication",
      "score": 0.09764373302459717
    },
    {
      "name": "Engineering",
      "score": 0.09756851196289062
    },
    {
      "name": "Psychology",
      "score": 0.08459174633026123
    },
    {
      "name": "Mathematics",
      "score": 0.07628849148750305
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Public relations",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ]
}