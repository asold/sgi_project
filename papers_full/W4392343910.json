{
    "title": "Speaker Attribution in German Parliamentary Debates with QLoRA-adapted Large Language Models",
    "url": "https://openalex.org/W4392343910",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5038913954",
            "name": "Tobias Bornheim",
            "affiliations": [
                "FH Aachen"
            ]
        },
        {
            "id": "https://openalex.org/A5037699337",
            "name": "Niklas Grieger",
            "affiliations": [
                "FH Aachen",
                "Utrecht University"
            ]
        },
        {
            "id": "https://openalex.org/A5059924404",
            "name": "Patrick Gustav Blaneck",
            "affiliations": [
                "FH Aachen"
            ]
        },
        {
            "id": "https://openalex.org/A5073225370",
            "name": "Stephan Bialonski",
            "affiliations": [
                "FH Aachen"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6810283822",
        "https://openalex.org/W4311991106",
        "https://openalex.org/W2806437774",
        "https://openalex.org/W2806295175",
        "https://openalex.org/W2997617958",
        "https://openalex.org/W4378509449",
        "https://openalex.org/W4385573388",
        "https://openalex.org/W2151170651",
        "https://openalex.org/W2965142815",
        "https://openalex.org/W2095655043",
        "https://openalex.org/W4376312587",
        "https://openalex.org/W1638000437",
        "https://openalex.org/W2990164998",
        "https://openalex.org/W1978620866",
        "https://openalex.org/W4404783137",
        "https://openalex.org/W4327810158",
        "https://openalex.org/W4398387079",
        "https://openalex.org/W2936215830",
        "https://openalex.org/W4322718191",
        "https://openalex.org/W4384918448",
        "https://openalex.org/W3194924193",
        "https://openalex.org/W2979826702",
        "https://openalex.org/W4288373939",
        "https://openalex.org/W3098458047",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W4224439994"
    ],
    "abstract": "The growing body of political texts opens up new opportunities for rich insights into political dynamics and ideologies but also increases the workload for manual analysis. Automated speaker attribution, which detects who said what to whom in a speech event and is closely related to semantic role labeling, is an important processing step for computational text analysis. We study the potential of the large language model family Llama 2 to automate speaker attribution in German parliamentary debates from 2017-2021. We fine-tune Llama 2 with QLoRA, an efficient training strategy, and observe our approach to achieve competitive performance in the GermEval 2023 Shared Task On Speaker Attribution in German News Articles and Parliamentary Debates. Our results shed light on the capabilities of large language models in automating speaker attribution, revealing a promising avenue for computational analysis of political discourse and the development of semantic role labeling systems.",
    "full_text": "Tobias Bornheim, Niklas Grieger, Patrick Gustav Blaneck, Stephan Bialonski\nSpeaker Attribution in German Parliamentary Debates with QLoRA-\nadapted Large Language Models\nAbstract\nThe growing body of political texts opens up new opportunities for rich insights into political\ndynamics and ideologies but also increases the workload for manual analysis. Automated speaker\nattribution, which detects who said what to whom in a speech event and is closely related to\nsemantic role labeling, is an important processing step for computational text analysis. We study\nthe potential of the large language model family Llama 2 to automate speaker attribution in German\nparliamentary debates from 2017–2021. We fine-tune Llama 2 with QLoRA, an efficient training\nstrategy, and observe our approach to achieve competitive performance in the GermEval 2023\nShared Task On Speaker Attribution in German News Articles and Parliamentary Debates. Our\nresults shed light on the capabilities of large language models in automating speaker attribution,\nrevealing a promising avenue for computational analysis of political discourse and the development\nof semantic role labeling systems.\n1 Introduction\nLanguage is central to the study of politics, as it forms the basis for political speech and debates\n(Grimmer & Stewart, 2013). These textual sources offer rich insights into political dynamics\nand ideologies, yet the analysis of even moderately sized collections has been impeded by pro-\nhibitive costs. Recent innovations from natural language processing (NLP) have the potential to\nsignificantly reduce the financial burden of scrutinizing extensive text corpora (Glavaš, Nanni, &\nPonzetto, 2019; Abercrombie & Batista-Navarro, 2020). This development coincides with the\navailability of a growing body of political texts, including German Parliamentary data (Barbaresi,\n2018; Blätte & Blessing, 2018; Walter et al., 2021; Rauh & Schwalbach, 2020; Abrami, Bagci,\nHammerla, & Mehler, 2022; Rehbein et al., 2023), thus opening new avenues for political research.\nPolitical texts are usually unstructured, presenting challenges for automated analyses. An\napproach towards this challenge is automated speaker attribution (Rehbein et al., 2023), which\ndetects who said what to whom in a speech event. This process involves detecting cue words that\ninitiate a speech event and discerning the different roles (e.g., source, message, and addressee)\nassociated with each event. This task is closely related to semantic role labeling (SRL) that\ndelineates the specific semantic relationships among a predicate and its corresponding arguments,\nsuch as “who” did “what” to “whom”, “where”, “when”, and “why” (Gildea & Jurafsky, 2002;\nMàrquez, Carreras, Litkowski, & Stevenson, 2008). Semantic role labeling is considered a key\ncomponent for natural language understanding and has been demonstrated to enhance systems for\nvarious applications including question answering, machine translation, and video understanding\n(Navigli, Barba, Conia, & Blloshmi, 2022).\nJLCL 2024 – Band 37 (1) – 1–13\nBornheim, Grieger, Blaneck, Bialonski\nEarly approaches to SRL relied on syntactic features (Navigli et al., 2022; Larionov, Shelmanov,\nChistova, & Smirnov, 2019). More recently, the field has seen a significant transition from such\nengineered features to features learned in an end-to-end fashion by models that operate on raw-\nlevel input or tokens (Collobert et al., 2011). However, such end-to-end models necessitate large\nannotated training sets, available for English but scarce for low-resource languages. This problem\ncan be mitigated by pretraining on unannotated data. Indeed, the emergence of pretrained large\nlanguage models (LLMs) inspired by the transformer architecture(Vaswani et al., 2017) led to new\nstate-of-the-art results across various NLP tasks. Among these, encoder-only models like BERT\nwere demonstrated to improve existing SRL benchmarks (Shi & Lin, 2019). More recently, the\nadvent of decoder-only models, such as GPT (Radford & Narasimhan, 2018) and larger models\nlike GPT-4 (OpenAI, 2023), Claude 2 (Bai et al., 2022), and Llama 2 (Touvron, Martin, et al.,\n2023), has further propelled the field. These models, with their ability to comprehend and execute\ninstructions in natural language for a wide array of tasks, hold potential for SRL and automated\nspeaker attribution that is, to the best of our knowledge, largely unexplored.\nIn this contribution, we study the potential of Llama 2 70B, a model from a recently introduced\nfamily of large language models, to automatically detect speech events and attribute speakers in\nGerman parliamentary debates. We instruct and fine-tune Llama 2 to extract cues and roles using\nQLoRA (Dettmers, Pagnoni, Holtzman, & Zettlemoyer, 2023), a parameter- and computationally\nefficient training strategy. Our approach achieves competitive performance (quantified by F1\nscores for cues and roles) on the SpkAtt-2023 dataset of the GermEval 2023 Shared Task on\nSpeaker Attribution in German News Articles and Parliamentary Debates(Rehbein et al., 2023).\nThe implementation details of our experiments (Team “CPAa”) are available online1.\n2 Data and tasks\nThe dataset of the GermEval 2023 Shared Task on Speaker Attribution in German News Articles\nand Parliamentary Debates consisted of 267 speeches from the German Bundestag (Rehbein et al.,\n2023). This dataset included speeches from all seven parliamentary groups (including independent\nmembers of parliament as a separate group) of the 19th legislative period of the German Bundestag\n(see Table 1 for details). To facilitate analysis, each speech was automatically separated into\nsentence-like structures using spaCy, hereafter referred to as samples (units of analysis). Each\nsample was then further split into elements, i.e., words and punctuation marks.\nHuman annotators followed annotation guidelines 2 to assign none, one, or multiple annotations\nto each sample. These annotations consisted of cue words that invoke speech events and roles\n(Addr, Evidence, Medium, Message, Source, Topic, PTC) associated with that event. While the\ncue is mandatory for each annotation, roles are context-dependent and may be absent. Figure 1\nshows example annotations.\nThe Shared Task consisted of two subtasks: Full Annotation (Subtask 1) and Role Detection\n(Subtask 2) (Rehbein et al., 2023). In the Full Annotation subtask, the goal was to predict all cues\n1https://github.com/dslaborg/germeval2023\n2https://github.com/umanlp/SpkAtt-2023/blob/master/doc/Guidelines\n_SpeakerAttribution_in_Parliamentary_Debates-SpkAtt-2023_Task1.pdf\n2 JLCL\nSpeaker Attribution in German Parliamentary Debates with QLoRA-adapted Large\nLanguage Models\nParliamentary group Speeches Samples\nCDU/CSU 77 4305\nSPD 57 2887\nAfD 39 1827\nFDP 34 1435\nDIE LINKE 29 1356\nB’90 / DIE GRÜNEN 27 1152\nindependent 4 125\nTotal 267 13087\nTable 1:Number of speeches and samples per parliamentary group in the combinedTrain, Dev, and Eval\ndatasets.\nSplit Speeches Samples Annotations\nDev 18 927 515\nTrain 177 9093 5399\nEval 72 3067 1792\nTotal 267 13087 7706\nTable 2:Number of speeches, samples (units of analysis), and annotations for each dataset. TheTrial dataset is\ncompletely contained within theTrain dataset and is therefore not shown. TheEval dataset here refers\nto the test sets of bothSubtask 1and Subtask 2, since they only differ in the provided annotations.\nand roles for each sample. In the Role Detection subtask, the gold cues were given, and the goal\nwas to predict only the roles for each sample.\nThe dataset was provided as five sets, namely Trial, Train, Dev, and two Eval sets (see Table 2).\nWe omitted the Trial set in our experiments, since it was included in the Train set. For training\nand tuning the final models, we used the Train and Dev sets. The two Eval sets were used by the\nGermEval 2023 organizers to compute the final scores for Subtask 1 (Eval set 1) and Subtask 2\n(Eval set 2). While the two Eval sets contained the same samples, the organizers provided gold\ncues with Eval set 2.\n3 Methods\n3.1 Models\nWe used the Llama 2 model family (Touvron, Martin, et al., 2023), a set of large language models\npretrained on a corpus of two trillion tokens with a context length of 4096 tokens. The Llama 2\nmodel family includes both pretrained models and fine-tuned versions optimized for conversational\ntasks. Since our approach did not require the conversational capabilities of the fine-tuned models,\nwe chose to use the base pretrained versions of Llama 2 in our experiments. These base models\nJLCL 2024 – Band 37 (1) 3\nBornheim, Grieger, Blaneck, Bialonski\nAnnotation 1\nV on der AfD wollen wir hier lieber nicht reden;‡ denn wir(Source) wissen(Cue): Neben ihren rassistischen\nPositionen ‡ haben die Rechtsradikalen nicht nur Klimawandelleugnung im Angebot, sie haben auch\ndie rechtspopulistischen Positionen eines Donald Trump gepachtet(Message).\nAnnotation 2\nV on der AfD wollen wir hier lieber nicht reden; ‡ denn wir wissen: Neben ihren rassistischen\nPositionen(Cue) ‡ haben die Rechtsradikalen nicht nur Klimawandelleugnung im Angebot, sie haben\nauch die rechtspopulistischen Positionen eines Donald Trump gepachtet.\nAnnotation 3\nV on der AfD wollen wir hier lieber nicht reden;‡ denn wir(Source) wissen: Neben ihren rassistischen\nPositionen ‡ haben die Rechtsradikalen nicht nur Klimawandelleugnung im Angebot, sie haben auch\ndie rechtspopulistischen Positionen(Cue) eines Donald Trump gepachtet(Message).\nFigure 1: Sentence from theTraindataset with three annotations. The sentence was split into three samples by\nspaCy (splitting points are indicated by‡). This segmentation also occurs at not-punctuated positions,\nas seen in the example sentence (“. . . rassistischen Positionen‡ haben die Rechtsradikalen . . . ”).\nThis behavior is due to the data provided by “Open Bundestag”, where comments from other members\nof parliament during an otherwise coherent paragraph force this unintuitive segmentation into two\nseparate paragraphs(Rehbein et al., 2023). As seen inAnnotation 2, there can be annotations\nconsisting of only cue word(s).Annotation 1and Annotation 3show that annotated roles can span\nmultiple samples.\nwere trained without a specific prompt format and are therefore not biased toward any particular\nprompt strategy, allowing us to freely choose our own prompt format.\nWhile the Llama 2 model family contains models of various sizes, we chose to fine-tune the\nlargest available model with 70 billion parameters (Llama 2 70B). The weights of this model can\nbe obtained upon request using the official GitHub repository3. Once downloaded, we followed\nthe provided instructions4 to convert the model to the HuggingFace Transformers format (Wolf et\nal., 2020). This conversion allowed us to load the model using the HuggingFace Transformers\nlibrary, which facilitated the fine-tuning and inference steps.\n3.2 Preprocessing\nFor effective training (see section 3.3) and inference (see section 3.4) we preprocessed each sample.\nWe parsed each annotation into its respective lists of elements. Next, we joined all elements of a\nsample with space characters in between to get each sample’s text. Since roles can be contained in\nsamples different from the one containing the cue, we concatenated the sample with the next two\nsamples of the same speech, if possible.\nDuring our experiments, we noticed that our models ignored their instructions and generated\nrandom text if the text of a given sample ended with a colon. To counteract this behavior, we\nreplaced this trailing colon with a period.\n3https://github.com/facebookresearch/llama\n4https://github.com/facebookresearch/llama-recipes\n4 JLCL\nSpeaker Attribution in German Parliamentary Debates with QLoRA-adapted Large\nLanguage Models\nInput:\nUser: A cue is the lexical items in a sentence that indicate that speech, writing, or thought is being\nreproduced.\nI want you to extract all cues in the text below.\nIf you find multiple words for one cue, you output them separated by commas.\nIf no cue can be found in the given text, you output the string #UNK# as cue.\nNow extract all cues from the following sentence.\nUse the prefix “Cues: ”.\nSentence: denn wir wissen: Neben ihren rassistischen Positionen\nAssistant:\nOutput:\nCues: [wissen], [Positionen]</s>\nFigure 2:Example cue prompt and desired model response for the sample “denn wir wissen: Neben ihren\nrassistischen Positionen” with the cues “wissen” and “Positionen”. Shaded in gray are the parts of\nthe prompt and response that are sample dependent. The prompt is used as theInput sequence for\ntraining and inference, while theOutput sequence contains the desired response with the cues. The\nend-of-sentence token “</s>” is used to indicate the end of theOutput sequence.\nInput:\nUser: Now I give you again the sentence only in addition with the two following sentences, because the\nroles can be partially contained in the following sentences.\nText: denn wir wissen : Neben ihren rassistischen Positionen ‡ haben die Rechtsradikalen nicht nur\nKlimawandelleugnung im Angebot , sie haben auch die rechtspopulistischen Positionen eines Donald\nTrump gepachtet . ‡ Als Linke übernehmen wir Verantwortung .\nNow find all roles in the sentence associated with the cue ‘wissen’ you found in the beginning sentence.\nAssistant:\nOutput:\ncue: wissen\nptc: #UNK#\nevidence: #UNK#\nmedium: #UNK#\ntopic: #UNK#\naddr: #UNK#\nmessage: Neben, ihren, rassistischen, Positionen, haben, die, Rechtsradikalen, nicht, nur, Klimawan-\ndelleugnung, im, Angebot, „ sie, haben, auch, die, rechtspopulistischen, Positionen, eines, Donald,\nTrump, gepachtet\nsource: wir</s>\nFigure 3:Example role prompt and desired model response for the sample “denn wir wissen: Neben ihren\nrassistischen Positionen” with the cue “wissen”. Since roles can be contained in samples different\nfrom the one containing the cue, we concatenated the sample with the next two samples of the same\nspeech (transitions between samples are indicated by‡). Shaded in gray are the parts of the prompt\nand response that are sample dependent. Similar to the cue prompt, the role prompt is used as the\nInput sequence for training and inference, while theOutput sequence contains the desired response.\nWe append the end-of-sentence token “</s>” to theOutput.\nJLCL 2024 – Band 37 (1) 5\nBornheim, Grieger, Blaneck, Bialonski\nWe designed prompts for cue prompting (see Figure 2) and role prompting (see Figure 3).\nWe wrote the instructions in our prompt templates in English, because it was observed that the\nperformance of multilingual models such as Llama 2 is improved when English prompts are used\n(Fu, Ng, & Liu, 2022; Huang et al., 2023). Also, since a sample may not contain a cue, or a role\nmay be missing, we used “#UNK#” to mark such cases.\n3.3 Training\nFor our final submission, we fine-tuned two Llama 2 70B models to identify cues and roles,\nrespectively, using QLoRA (Quantized Low-Rank Adaptation) (Dettmers et al., 2023). QLoRA is\na highly efficient fine-tuning technique for large language models that achieves similar performance\nto full fine-tuning while using only a fraction of the memory. This memory reduction is achieved\nby quantizing the model weights of an LLM to four bits and adding Low Rank Adapters (LoRA\nlayers) to all linear transformer blocks of the model. During fine-tuning, only these LoRA layers\nare trained and the rest of the pretrained model weights remain unaltered. By employing this\nstrategy, QLoRA achieves a significant reduction in memory usage during fine-tuning, while still\nallowing the model to adapt to downstream tasks through the trainable LoRA layers.\nAs described in Section 3.2, we parsed the training samples into cue prompts (see Figure 2)\nthat served as input to the cue model and role prompts (see Figure 3) that served as input to\nthe role model. Utilizing these input prompts, the respective models were trained to predict the\ndesired assistant responses (defined as Output in Figures 2 and 3). This approach is consistent\nwith previous research that has shown improved performance when fine-tuning only on the target\nresponse of an instruction set, rather than both the instructions and the desired response (Dettmers\net al., 2023). By treating the input and output separately, we can process the two sequences with\ndifferent maximum sequence lengths. Specifically, for the model used to identify cues, we set the\nmaximum length of the input to 256 tokens (with seven samples of the training data truncated)\nand the maximum length of the output to 64 tokens (no samples truncated). For the model used to\nidentify roles, we truncated the input to 640 tokens (with six samples of the training data truncated)\nand the output to 256 tokens (with one sample truncated).\nExcept for the maximum number of tokens in the input and output sequences, we largely fol-\nlowed the training strategy proposed in Dettmers et al. (2023). Although their specific experiments\ndid not involve a Llama 2 70B model, they successfully fine-tuned a similarly sized LLaMA model\n(predecessor to Llama 2) with 65 billion parameters (Touvron, Lavril, et al., 2023). We adopted\nmost parameters from this 65B model fine-tuning, such as a constant learning rate of η= 0.0001\nwith linear warmup over the first 3% of training steps and a dropout of 0.05 for the LoRA layers.\nThe main hyperparameter we adjusted was the number of training steps to prevent overfitting. For\nthe cues model, we trained for 2000 steps with a batch size of 16 and no gradient accumulation.\nFor the roles model, we used 2500 steps with a batch size of eight and gradient accumulation over\ntwo steps, i.e., an effective batch size of 16.\nFine-tuning was carried out on a DGX A100 server, with a total training time of about seven\nhours for the cues model and 17 hours for the roles model. To optimize memory usage, we\nexperimented with reducing the batch size to one while increasing the gradient accumulation steps\n6 JLCL\nSpeaker Attribution in German Parliamentary Debates with QLoRA-adapted Large\nLanguage Models\nto 16 (i.e., maintaining the same effective batch size). With these parameters, both models were\nable to operate within a GPU memory limit of less than 60 GB.\n3.4 Inference\nPrompting our fine-tuned models was a two-step process. In the first step, we prompted our cue\nmodel for all cues in a sample using our prompt template for cues (see Figure 2). We postprocessed\nthe output of the model (see section 3.5) into a list of cues. In the second step, for each cue, we\nprompted for the roles with our role model. To do this, we prepended the complete cue prompt\nand its output to the role prompt template before querying the model (see Figure 3).\nTo ensure reproducibility of results, we configured our models to generate output deterministi-\ncally. For a given input sequence, large language models obtain a probability distribution over all\npossible tokens. We chose to always select the token with the highest assigned probability as the\nnext output token, thereby fixing the output for a given input sequence.\n3.5 Postprocessing and evaluation metrics\nSeveral postprocessing steps were necessary to evaluate the models’ output in a structured way.\nEnforcing the output format. If the models’ output did not follow our strict output format (see\nFigures 2 and 3), we mapped the output to the marker #UNK# (unknown).\nPreventing overlapping cues. If our cue model detected multiple but overlapping cues, we\ncombined them into a single cue.\nIgnoring made-up words. If the output of the model contained words for cues or roles that\nwere not in the given sample, and no other word with a Levenshtein distance of 1 was found in\nthe sample, we ignored those words. Then, if the output was empty, we mapped the output to the\nmarker #UNK# (unknown).\nResolving ambiguities. A word may occur more than once in a sample. When a model outputs\nsuch a word as a cue or a role, it is unclear to which occurrence of the word in the sample it should\nbe attributed. To resolve this ambiguity, for each occurrence of the word, we counted how many\nelements around that word (in the range of two elements to the left and right) were part of the cue\nor role, and chose the occurrence with the highest count.\nIncluding surrounded punctuation. Roles often contained punctuation marks such as colons\nor commas. We observed that our models ignored these punctuation marks most of the time.\nIf a punctuation mark was surrounded by words that were selected for this role, we added that\npunctuation mark to the role as well.\nJLCL 2024 – Band 37 (1) 7\nBornheim, Grieger, Blaneck, Bialonski\nPrecision Recall F1\nSubtask 1\nCues 0.889 0.889 0.889\nRoles 0.787 0.822 0.804\nCues & Roles 0.798 0.829 0.813\nSubtask 2\nRoles 0.910 0.873 0.891\nTable 3:Proportional precision, recall, and F1 scores obtained for predicting cues and roles on theEval dataset.\nThe joint scores for predicting both cues and roles (Subtask 1 of GermEval 2023 Shared Task 1) are\nshown in the third row. The last row shows the results obtained for predicting roles on theEval dataset\nwhen the true cues were given (Subtask 2).\nEvaluating metrics. To evaluate the performance of our models, we used the proportional\nF1 score as proposed for opinion role labeling (Johansson & Moschitti, 2010). This score is\ndefined as the harmonic mean of the proportional precision and recall. Proportional precision\nquantifies the proportion of overlap between a predicted cue (role) and an overlapping true cue\n(role). Proportional recall quantifies the proportion of overlap between a true cue (role) and\nan overlapping predicted cue (role; see Rehbein et al. (2023) for further details on how the\nproportional F1 score is calculated).\n4 Results\nWe used the same fine-tuned Llama 2 70B models for both Subtask 1 and Subtask 2 of GermEval\n2023 Shared Task 1 – a cues model to identify cues in a given sentence and a roles model to\npredict the roles associated with the identified cues. While the cues model was used exclusively in\nSubtask 1, as the cues were provided in Subtask 2, the roles model was used in both subtasks. It\nleveraged either the predicted cues from Subtask 1 or the gold cues from Subtask 2 to predict the\nroles associated with each cue, as described in section 3.4. By using the same fine-tuned roles\nmodel for both subtasks, we were able to analyze the impact of using gold cues versus predicted\ncues on role identification performance.\nTable 3 shows the final results of our submissions on the Eval dataset, as reported by the\norganizers of the GermEval 2023 Shared Task. For Subtask 1, the fine-tuned cues model achieved\nan F1 score of 0.889 for predicting cues. Using the predicted cues from this model, the fine-tuned\nroles model achieved an F1 score of 0.804 for predicting roles. Combining both predictions, our\nmodels achieved an overall F1 score of 0.813 for predicting cues and roles in Subtask 1. In Subtask\n2, where gold cues were provided, the same roles model used in Subtask 1 achieved a higher\nF1 score of 0.891 for predicting roles. Interestingly, the improvement of the roles model using\ngold cues was greater in precision, which increased from 0.787 to 0.910, than in recall, which\nincreased from 0.822 to 0.873. This increase in precision suggests that the cues model in Subtask\n1 overpredicted sentences as containing cues when they actually had no cues, resulting in too many\nfalse positive role predictions.\n8 JLCL\nSpeaker Attribution in German Parliamentary Debates with QLoRA-adapted Large\nLanguage Models\nIn summary, our results demonstrate that our fine-tuned models are effective at reliably predict-\ning cues and roles. Additionally, the results highlight the importance of accurate cue prediction, as\nerrors of the cues model propagate to the roles model, reducing its performance.\n5 Conclusion\nWe demonstrated that fine-tuned Llama 2 language models can successfully predict cues and\nroles in German parliamentary debates, achieving competitive performance on the GermEval2023\nShared Task without relying on traditional linguistic features. These results highlight the feasibility\nof automated speaker attribution by fine-tuning models on prompt templates that task them with\nidentifying cues and roles. The similarity between automated speaker attribution and semantic role\nlabeling suggests that this strategy may pave the way for new state-of-the-art results in various\nsemantic role labeling tasks.\nLimitations\nWe did not study risks that may or may not arise when our fine-tuned large language models are\nused for other application scenarios than ours. In our approach, users can neither manipulate the\nprompts nor read the generated texts produced by our models. Instead, the generated outputs are\nprocessed and mapped back to the words from the parliamentary speeches used as input. Therefore,\nwe consider the risks associated with our approach to be limited. We recommend security testing\nif our trained models are to be used in other scenarios.\nAcknowledgements\nWe are grateful to M. Reißel and V . Sander for providing us with computing resources.\nReferences\nAbercrombie, G., & Batista-Navarro, R. (2020, January). Sentiment and position-taking analysis\nof parliamentary debates: A systematic literature review. Journal of Computational Social\nScience, 3(1), 245–270. Retrieved from https://doi.org/10.1007/s42001-019\n-00060-w doi: 10.1007/s42001-019-00060-w\nAbrami, G., Bagci, M., Hammerla, L., & Mehler, A. (2022). German parliamentary corpus\n(GerParCor). In N. Calzolari et al. (Eds.), Proceedings of the thirteenth language resources\nand evaluation conference, LREC 2022, marseille, france, 20-25 june 2022(pp. 1900–1906).\nEuropean Language Resources Association. Retrieved from https://aclanthology\n.org/2022.lrec-1.202\nBai, Y ., Kadavath, S., Kundu, S., Askell, A., Kernion, J., Jones, A., . . . Kaplan, J. (2022).\nConstitutional AI: Harmlessness from AI feedback. CoRR, abs/2212.08073. Retrieved from\nhttps://doi.org/10.48550/arXiv.2212.08073 doi: 10.48550/arXiv.2212\n.08073\nJLCL 2024 – Band 37 (1) 9\nBornheim, Grieger, Blaneck, Bialonski\nBarbaresi, A. (2018, May). A corpus of German political speeches from the 21st century. In\nProceedings of the eleventh international conference on language resources and evaluation\n(LREC 2018). Miyazaki, Japan: European Language Resources Association (ELRA).\nRetrieved from https://aclanthology.org/L18-1127\nBlätte, A., & Blessing, A. (2018). The GermaParl corpus of parliamentary protocols. In N. Cal-\nzolari et al. (Eds.), Proceedings of the eleventh international conference on language re-\nsources and evaluation, LREC 2018, miyazaki, japan, may 7-12, 2018. European Language\nResources Association (ELRA). Retrieved from http://www.lrec-conf.org/\nproceedings/lrec2018/summaries/1024.html\nCollobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. P. (2011).\nNatural language processing (almost) from scratch. J. Mach. Learn. Res., 12, 2493–2537.\nRetrieved from https://dl.acm.org/doi/10.5555/1953048.2078186 doi:\n10.5555/1953048.2078186\nDettmers, T., Pagnoni, A., Holtzman, A., & Zettlemoyer, L. (2023). QLoRA: Efficient finetuning\nof quantized LLMs. CoRR, abs/2305.14314. Retrieved from https://doi.org/\n10.48550/arXiv.2305.14314 doi: 10.48550/arXiv.2305.14314\nFu, J., Ng, S.-K., & Liu, P. (2022, December). Polyglot Prompt: Multilingual multitask\nprompt training. In Proceedings of the 2022 conference on empirical methods in nat-\nural language processing (pp. 9919–9935). Abu Dhabi, United Arab Emirates: Associa-\ntion for Computational Linguistics. Retrieved from https://aclanthology.org/\n2022.emnlp-main.674 doi: 10.18653/v1/2022.emnlp-main.674\nGildea, D., & Jurafsky, D. (2002). Automatic labeling of semantic roles. Com-\nput. Linguistics , 28(3), 245–288. Retrieved from https://doi.org/10.1162/\n089120102760275983 doi: 10.1162/089120102760275983\nGlavaš, G., Nanni, F., & Ponzetto, S. P. (2019). Computational analysis of political texts: Bridging\nresearch efforts across communities. In Proceedings of the 57th annual meeting of the\nassociation for computational linguistics: Tutorial abstracts.Association for Computational\nLinguistics. Retrieved from https://doi.org/10.18653/v1/p19-4004 doi:\n10.18653/v1/p19-4004\nGrimmer, J., & Stewart, B. M. (2013). Text as data: The promise and pitfalls of automatic content\nanalysis methods for political texts. Political Analysis, 21(3), 267–297. Retrieved from\nhttps://doi.org/10.1093/pan/mps028 doi: 10.1093/pan/mps028\nHuang, H., Tang, T., Zhang, D., Zhao, W. X., Song, T., Xia, Y ., & Wei, F. (2023). Not all languages\nare created equal in LLMs: Improving multilingual capability by cross-lingual-thought\nprompting. CoRR, abs/2305.07004. Retrieved from https://doi.org/10.48550/\narXiv.2305.07004 doi: 10.48550/arXiv.2305.07004\nJohansson, R., & Moschitti, A. (2010, July). Syntactic and semantic structure for opinion expres-\nsion detection. In Proceedings of the fourteenth conference on computational natural lan-\nguage learning (pp. 67–76). Uppsala, Sweden: Association for Computational Linguistics.\nRetrieved from https://aclanthology.org/W10-2910\nLarionov, D., Shelmanov, A., Chistova, E., & Smirnov, I. V . (2019). Semantic role labeling with\npretrained language models for known and unknown predicates. In R. Mitkov & G. Angelova\n(Eds.), Proceedings of the international conference on recent advances in natural language\n10 JLCL\nSpeaker Attribution in German Parliamentary Debates with QLoRA-adapted Large\nLanguage Models\nprocessing, RANLP 2019, varna, bulgaria, september 2-4, 2019 (pp. 619–628). INCOMA\nLtd. Retrieved from https://doi.org/10.26615/978-954-452-056-4_073\ndoi: 10.26615/978-954-452-056-4\\_073\nMàrquez, L., Carreras, X., Litkowski, K. C., & Stevenson, S. (2008). Semantic role labeling:\nAn introduction to the special issue. Comput. Linguistics, 34(2), 145–159. Retrieved from\nhttps://doi.org/10.1162/coli.2008.34.2.145 doi: 10.1162/coli.2008.34\n.2.145\nNavigli, R., Barba, E., Conia, S., & Blloshmi, R. (2022, November). A tour of explicit multilingual\nsemantics: Word sense disambiguation, semantic role labeling and semantic parsing. In\nProceedings of the 2nd conference of the asia-pacific chapter of the association for com-\nputational linguistics and the 12th international joint conference on natural language pro-\ncessing: Tutorial abstracts (pp. 35–43). Taipei: Association for Computational Linguistics.\nRetrieved from https://aclanthology.org/2022.aacl-tutorials.6\nOpenAI. (2023). GPT-4 technical report. CoRR, abs/2303.08774. Retrieved from https://\ndoi.org/10.48550/arXiv.2303.08774 doi: 10.48550/arXiv.2303.08774\nRadford, A., & Narasimhan, K. (2018). Improving language understanding by generative\npre-training.. Retrieved from https://cdn.openai.com/research-covers/\nlanguage-unsupervised/language_understanding_paper.pdf\nRauh, C., & Schwalbach, J. (2020). The ParlSpeech V2 data set: Full-text corpora of 6.3 million\nparliamentary speeches in the key legislative chambers of nine representative democracies.\nHarvard Dataverse. Retrieved fromhttps://doi.org/10.7910/DVN/L4OAKN doi:\n10.7910/DVN/L4OAKN\nRehbein, I., Petersen-Frey, F., Brunner, A., Ruppenhofer, J., Biemann, C., & Ponzetto, S. P. (2023).\nOverview of the GermEval 2023 Shared Task on Speaker Attribution in Newswire and\nParliamentary Debates. In The GermEval 2023 Shared Task at KONVENS 2023. Ingolstadt,\nGermany.\nShi, P., & Lin, J. (2019). Simple BERT models for relation extraction and semantic role labeling.\nCoRR, abs/1904.05255. Retrieved from http://arxiv.org/abs/1904.05255\nTouvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M., Lacroix, T., . . . Lample, G. (2023).\nLLaMA: Open and efficient foundation language models.CoRR, abs/2302.13971. Retrieved\nfrom https://doi.org/10.48550/arXiv.2302.13971 doi: 10.48550/arXiv\n.2302.13971\nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y ., . . . Scialom, T. (2023).\nLlama 2: Open foundation and fine-tuned chat models. CoRR, abs/2307.09288. Retrieved\nfrom https://doi.org/10.48550/arXiv.2307.09288 doi: 10.48550/arXiv\n.2307.09288\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., . . . Polosukhin, I.\n(2017, dec). Attention is all you need. InAnnual conf. neural information processing systems\n2017 (pp. 5998–6008). Long Beach, CA, USA. Retrieved from https://arxiv.org/\nabs/1706.03762\nWalter, T., Kirschner, C., Eger, S., Glavas, G., Lauscher, A., & Ponzetto, S. P. (2021). Diachronic\nanalysis of German parliamentary proceedings: Ideological shifts through the lens of\npolitical biases. In J. S. Downie, D. McKay, H. Suleman, D. M. Nichols, & F. Poursardar\nJLCL 2024 – Band 37 (1) 11\nBornheim, Grieger, Blaneck, Bialonski\n(Eds.), ACM/IEEE joint conference on digital libraries, JCDL 2021, champaign, il, usa,\nseptember 27-30, 2021 (pp. 51–60). IEEE. Retrieved from https://doi.org/10\n.1109/JCDL52503.2021.00017 doi: 10.1109/JCDL52503.2021.00017\nWolf, T., Debut, L., Sanh, V ., Chaumond, J., Delangue, C., Moi, A., . . . Rush, A. M. (2020,\noct). Transformers: State-of-the-art natural language processing. In Proc. 2020 conf.\non empirical methods in natural language processing: System demonstrations (pp. 38–\n45). Online: Association for Computational Linguistics. Retrieved from https://\nwww.aclweb.org/anthology/2020.emnlp-demos.6\n12 JLCL\nSpeaker Attribution in German Parliamentary Debates with QLoRA-adapted Large\nLanguage Models\nCorrespondence\nTobias Bornheim\nDepartment of Medical Engineering and Technomathematics\nFH Aachen University of Applied Sciences, Jülich, Germany\nNiklas Grieger\nDepartment of Medical Engineering and Technomathematics/\nInstitute for Data-Driven Technologies\nFH Aachen University of Applied Sciences, Jülich, Germany\nDepartment of Information and Computing Sciences\nUtrecht University, Utrecht, The Netherlands\nPatrick Gustav Blaneck\nDepartment of Medical Engineering and Technomathematics\nFH Aachen University of Applied Sciences, Jülich, Germany\nStephan Bialonski\nDepartment of Medical Engineering and Technomathematics/\nInstitute for Data-Driven Technologies\nFH Aachen University of Applied Sciences, Jülich, Germany\nbialonski@fh-aachen.de\nJLCL 2024 – Band 37 (1) 13"
}