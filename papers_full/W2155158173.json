{
  "title": "The Ease of Language Understanding (ELU) model: theoretical, empirical, and clinical advances",
  "url": "https://openalex.org/W2155158173",
  "year": 2013,
  "authors": [
    {
      "id": "https://openalex.org/A1993838233",
      "name": "Jerker Rönnberg",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A11862657",
      "name": "Thomas Lunner",
      "affiliations": [
        "Linköping University",
        "Linnaeus University",
        "Oticon Medical (Denmark)",
        "Swedish Institute"
      ]
    },
    {
      "id": null,
      "name": "Adriana Zekveld",
      "affiliations": [
        "Swedish Institute",
        "Linnaeus University"
      ]
    },
    {
      "id": "https://openalex.org/A23160626",
      "name": "Patrik Sorqvist",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2141280133",
      "name": "Henrik Danielsson",
      "affiliations": [
        "Linnaeus University",
        "Linköping University",
        "Swedish Institute"
      ]
    },
    {
      "id": "https://openalex.org/A232376101",
      "name": "Björn Lyxell",
      "affiliations": [
        "Linnaeus University",
        "Swedish Institute",
        "Linköping University"
      ]
    },
    {
      "id": "https://openalex.org/A151055851",
      "name": "Örjan Dahlström",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1891596271",
      "name": "Carine Signoret",
      "affiliations": [
        "Swedish Institute",
        "Linköping University",
        "Linnaeus University"
      ]
    },
    {
      "id": "https://openalex.org/A2151658563",
      "name": "Stefan Stenfelt",
      "affiliations": [
        "Linköping University",
        "Linnaeus University",
        "Swedish Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2583535108",
      "name": "M Kathleen Pichora-Fuller",
      "affiliations": [
        "Swedish Institute",
        "Baycrest Hospital",
        "University of Toronto",
        "Linnaeus University"
      ]
    },
    {
      "id": "https://openalex.org/A2138837518",
      "name": "Mary Rudner",
      "affiliations": [
        "Swedish Institute",
        "Linköping University",
        "Linnaeus University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2031229177",
    "https://openalex.org/W2093146363",
    "https://openalex.org/W1995829800",
    "https://openalex.org/W2142934908",
    "https://openalex.org/W6648063249",
    "https://openalex.org/W2019815181",
    "https://openalex.org/W1985228146",
    "https://openalex.org/W6680211572",
    "https://openalex.org/W2096707172",
    "https://openalex.org/W2069332743",
    "https://openalex.org/W2142360036",
    "https://openalex.org/W3124666641",
    "https://openalex.org/W2125081437",
    "https://openalex.org/W1987894488",
    "https://openalex.org/W2161646307",
    "https://openalex.org/W2142950303",
    "https://openalex.org/W2069326425",
    "https://openalex.org/W2022667221",
    "https://openalex.org/W2045385178",
    "https://openalex.org/W2079716579",
    "https://openalex.org/W2044145313",
    "https://openalex.org/W2147843279",
    "https://openalex.org/W2059217179",
    "https://openalex.org/W6682408960",
    "https://openalex.org/W2096575147",
    "https://openalex.org/W6666707771",
    "https://openalex.org/W2091766358",
    "https://openalex.org/W2031446465",
    "https://openalex.org/W4288400169",
    "https://openalex.org/W1985558471",
    "https://openalex.org/W4298191902",
    "https://openalex.org/W4241287469",
    "https://openalex.org/W2003330516",
    "https://openalex.org/W1964267588",
    "https://openalex.org/W2133906864",
    "https://openalex.org/W2141910269",
    "https://openalex.org/W1965248225",
    "https://openalex.org/W2061288491",
    "https://openalex.org/W1968501305",
    "https://openalex.org/W2129594711",
    "https://openalex.org/W2072875864",
    "https://openalex.org/W2033101906",
    "https://openalex.org/W2048613949",
    "https://openalex.org/W2061099699",
    "https://openalex.org/W2155469905",
    "https://openalex.org/W2115826198",
    "https://openalex.org/W1723026724",
    "https://openalex.org/W2106371802",
    "https://openalex.org/W6685054597",
    "https://openalex.org/W2122522567",
    "https://openalex.org/W2094782527",
    "https://openalex.org/W2105402598",
    "https://openalex.org/W2026992087",
    "https://openalex.org/W2119131192",
    "https://openalex.org/W6665347297",
    "https://openalex.org/W6675725330",
    "https://openalex.org/W2110628236",
    "https://openalex.org/W1999013545",
    "https://openalex.org/W2038200146",
    "https://openalex.org/W2073051784",
    "https://openalex.org/W2166696789",
    "https://openalex.org/W1972655577",
    "https://openalex.org/W2032832443",
    "https://openalex.org/W2082183045",
    "https://openalex.org/W4412287171",
    "https://openalex.org/W2103082677",
    "https://openalex.org/W2039665007",
    "https://openalex.org/W2158541002",
    "https://openalex.org/W1987690347",
    "https://openalex.org/W3147310958",
    "https://openalex.org/W2167124036",
    "https://openalex.org/W2042701078",
    "https://openalex.org/W2037534576",
    "https://openalex.org/W2171316976",
    "https://openalex.org/W2094896521",
    "https://openalex.org/W2167685324",
    "https://openalex.org/W2120603653",
    "https://openalex.org/W2129218624",
    "https://openalex.org/W2020231959",
    "https://openalex.org/W2149659168",
    "https://openalex.org/W2045386661",
    "https://openalex.org/W2023325795",
    "https://openalex.org/W1981220086",
    "https://openalex.org/W296428098",
    "https://openalex.org/W2033846147",
    "https://openalex.org/W2040522665",
    "https://openalex.org/W399640809",
    "https://openalex.org/W2071572390",
    "https://openalex.org/W2127667726",
    "https://openalex.org/W2060414815",
    "https://openalex.org/W2177749939",
    "https://openalex.org/W4232948727",
    "https://openalex.org/W2001197020",
    "https://openalex.org/W196286962",
    "https://openalex.org/W6921809926",
    "https://openalex.org/W1549441414",
    "https://openalex.org/W1986177399",
    "https://openalex.org/W2101227557",
    "https://openalex.org/W2043847879",
    "https://openalex.org/W2082600983",
    "https://openalex.org/W2085309870",
    "https://openalex.org/W2178773024",
    "https://openalex.org/W2006649002",
    "https://openalex.org/W298187031",
    "https://openalex.org/W2009092532",
    "https://openalex.org/W2047774548",
    "https://openalex.org/W2039001218",
    "https://openalex.org/W6884512585",
    "https://openalex.org/W2045595208",
    "https://openalex.org/W6631143843",
    "https://openalex.org/W1967895886",
    "https://openalex.org/W2027701650",
    "https://openalex.org/W2160932740",
    "https://openalex.org/W2042957170",
    "https://openalex.org/W2162488555",
    "https://openalex.org/W2127158460",
    "https://openalex.org/W1981984600",
    "https://openalex.org/W2051850587",
    "https://openalex.org/W1534443974",
    "https://openalex.org/W1972325554",
    "https://openalex.org/W2113600002",
    "https://openalex.org/W2045669853",
    "https://openalex.org/W418318901",
    "https://openalex.org/W2118980133",
    "https://openalex.org/W2161220328",
    "https://openalex.org/W2326062166",
    "https://openalex.org/W2019485352",
    "https://openalex.org/W2058639087",
    "https://openalex.org/W1990784680",
    "https://openalex.org/W2115431590",
    "https://openalex.org/W4232219046",
    "https://openalex.org/W2106074455",
    "https://openalex.org/W2154253638",
    "https://openalex.org/W1519522181",
    "https://openalex.org/W2078079955",
    "https://openalex.org/W2171600170",
    "https://openalex.org/W1969316884",
    "https://openalex.org/W2041048573",
    "https://openalex.org/W2040492483",
    "https://openalex.org/W2132344070",
    "https://openalex.org/W2133109360",
    "https://openalex.org/W4388365896",
    "https://openalex.org/W1990905343",
    "https://openalex.org/W2110920486",
    "https://openalex.org/W2050147511",
    "https://openalex.org/W2171158526",
    "https://openalex.org/W2117039246",
    "https://openalex.org/W1980632783",
    "https://openalex.org/W2012813782",
    "https://openalex.org/W2107649856",
    "https://openalex.org/W290696508",
    "https://openalex.org/W2155659454",
    "https://openalex.org/W2156284662",
    "https://openalex.org/W1977841176",
    "https://openalex.org/W1986771495",
    "https://openalex.org/W2150326901",
    "https://openalex.org/W2071932093",
    "https://openalex.org/W4256297751",
    "https://openalex.org/W2151867154",
    "https://openalex.org/W4249934679",
    "https://openalex.org/W2137145004",
    "https://openalex.org/W2027263442",
    "https://openalex.org/W2065096279",
    "https://openalex.org/W1992111950",
    "https://openalex.org/W2109046660",
    "https://openalex.org/W2166613464",
    "https://openalex.org/W2153749840",
    "https://openalex.org/W2112638956",
    "https://openalex.org/W2103685082",
    "https://openalex.org/W2087666832",
    "https://openalex.org/W1985070088",
    "https://openalex.org/W2065837193",
    "https://openalex.org/W2006586657",
    "https://openalex.org/W2046518259",
    "https://openalex.org/W2102278044",
    "https://openalex.org/W2052539752",
    "https://openalex.org/W2135704565",
    "https://openalex.org/W4234192145",
    "https://openalex.org/W2321611628",
    "https://openalex.org/W4252878812",
    "https://openalex.org/W2076296628",
    "https://openalex.org/W1999107674",
    "https://openalex.org/W2046975818",
    "https://openalex.org/W2123719421",
    "https://openalex.org/W1980909626",
    "https://openalex.org/W2003755151",
    "https://openalex.org/W2153432403",
    "https://openalex.org/W2168700874",
    "https://openalex.org/W2101328273",
    "https://openalex.org/W2059628657",
    "https://openalex.org/W4388365887",
    "https://openalex.org/W1994372749",
    "https://openalex.org/W2017057152",
    "https://openalex.org/W1995876390"
  ],
  "abstract": "Working memory is important for online language processing during conversation. We use it to maintain relevant information, to inhibit or ignore irrelevant information, and to attend to conversation selectively. Working memory helps us to keep track of and actively participate in conversation, including taking turns and following the gist. This paper examines the Ease of Language Understanding model (i.e., the ELU model, Rönnberg, 2003; Rönnberg et al., 2008) in light of new behavioral and neural findings concerning the role of working memory capacity (WMC) in uni-modal and bimodal language processing. The new ELU model is a meaning prediction system that depends on phonological and semantic interactions in rapid implicit and slower explicit processing mechanisms that both depend on WMC albeit in different ways. It is based on findings that address the relationship between WMC and (a) early attention processes in listening to speech, (b) signal processing in hearing aids and its effects on short-term memory, (c) inhibition of speech maskers and its effect on episodic long-term memory, (d) the effects of hearing impairment on episodic and semantic long-term memory, and finally, (e) listening effort. New predictions and clinical implications are outlined. Comparisons with other WMC and speech perception models are made.",
  "full_text": "REVIEW ARTICLE\npublished: 13 July 2013\ndoi: 10.3389/fnsys.2013.00031\nThe Ease of Language Understanding (ELU) model:\ntheoretical, empirical, and clinical advances\nJerker Rönnberg1,2*, Thomas Lunner1,2,3,4, Adriana Zekveld2,5, Patrik Sörqvist2,6, Henrik Danielsson1,2,\nBjörn Lyxell1,2, Örjan Dahlström1,2, Carine Signoret1,2, Stefan Stenfelt2,3,\nM. Kathleen Pichora-Fuller2,7 ,8,9and Mary Rudner1,2\n1 Department of Behavioural Sciences and Learning, Linköping University, Linköping, Sweden\n2 Linnaeus Centre HEAD, Swedish Institute for Disability Research, Linköping University, Linköping, Sweden\n3 Department of Clinical and Experimental Medicine, Linköping University, Linköping, Sweden\n4 Eriksholm Research Centre, Oticon A/S, Snekkersten, Denmark\n5 Department of Audiology/ENT and EMGO+ Institute for Health and Care Research, VU University Medical Center, Amsterdam, Netherlands\n6 Department of Building, Energy and Environmental Engineering, University of Gävle, Gävle, Sweden\n7 Department of Psychology, University of Toronto, Toronto, ON, Canada\n8 The Toronto Rehabilitation Institute, University Health Network, Toronto, ON, Canada\n9 The Rotman Research Institute, Baycrest Hospital, Toronto, ON, Canada\nEdited by:\nArthur Wingﬁeld, Brandeis\nUniversity, USA\nReviewed by:\nNatasha Sigala, University of\nSussex, UK\nBegoña Díaz, University Pompeu\nFabra, Spain\n*Correspondence:\nJerker Rönnberg, Department of\nBehavioural Sciences and Learning,\nLinköping University, SE-581 83\nLinköping, Sweden\ne-mail: jerker.ronnberg@liu.se\nWorking memory is important for online la nguage processing during conversation. We\nuse it to maintain relevant information, to inhibit or ignore irrelevant information, and\nto attend to conversation selectively. Working memory helps us to keep track of and\nactively participate in conversation, including taking turns and following the gist. This paper\nexamines the Ease of Language Understanding model (i.e., the ELU model, Rönnberg,\n2003; Rönnberg et al., 2008 ) in light of new behavioral and neural ﬁndings concerning the\nrole of working memory capacity (WMC) in uni-modal and bimodal language processing.\nThe new ELU model is a meaning prediction system that depends on phonological and\nsemantic interactions in rapid implicit and slower explicit processing mechanisms that\nboth depend on WMC albeit in different ways. It is based on ﬁndings that address the\nrelationship between WMC and (a) early attention processes in listening to speech, (b)\nsignal processing in hearing aids and its effects on short-term memory, (c) inhibition of\nspeech maskers and its effect on episodic long-term memory, (d) the effects of hearing\nimpairment on episodic and semantic long-term memory, and ﬁnally, (e) listening effort.\nNew predictions and clinical implications are outlined. Comparisons with other WMC and\nspeech perception models are made.\nKeywords: working memory capacity, speech in noise, attention, long-term memory, hearing loss, brain imaging\nanalysis, oscillations, language understanding\nBACKGROUND\nOVERVIEW\nSome 30 years ago, we began a program of research to investi-\ngate the factors related to individual differences in speechreaders’\nability to understand language. The ﬁndings underscored the\nimportance of working memory capacity (WMC) for explaining\nthose individual differences. In subsequent research, we extended\nour investigations to examine the associations between WMC and\nlanguage understanding in other conditions, with the most recent\nfocusing on audio-only speech understanding in adverse listening\nconditions by listeners using hearing aids.\nThe Ease of Language Understanding model (i.e., the ELU\nmodel, Rönnberg, 2003; Rönnberg et al., 2008) was developed,\ntested, and reﬁned in an attempt to specify the role of work-\ning memory (WM) in a wide range of conditions in which\npeople with normal or impaired hearing understand language.\nT h el a n g u a g es i g n a lm a yb eu n i - m o d a lo rb i - m o d a ls p e e c ho r\nsign language and background conditions are realistic but pro-\nvide contextual support or environmental challenge to differing\ndegrees.\nSPEECHREADING AS COMPENSATION FOR HEARING LOSS\nHearing loss leads to poorer perception of auditory speech sig-\nnals and greater reliance on visual information available from the\ntalker’s face. Thus, we hypothesized, initially, that daily practice\nin visual speechreading by individuals with profound hearing loss\no rd e a f n e s sw o u l dl e a dt os u p e r i o r ,compensatory speechreading\nor speech understanding skills in comparison to normally hear-\ning peers. One of the ﬁndings that motivated this hypothesis was\nthat visual speechreading ability varies enormously between indi-\nviduals (see Rönnberg, 1995 for a review). To test this hypothesis,\nwe conducted several studies of speechreading in well-matched\ngroups of individuals with normal hearing, moderate hearing\nloss and profound hearing loss. Contrary to the prediction, there\nwere no signiﬁcant group differences and thus no evidence of\ncompensation for hearing loss by better use of visual speech\ninformation. Results were similar irrespective of type of presen-\ntation (video vs. real-life audiovisual; Rönnberg et al., 1983),\ntype of materials (digits vs. discourse; Rönnberg et al., 1983),\nfor just-follow conversation tasks ( Hygge et al., 1992 ), for differ-\nent durations of impairment, and for different degrees of hearing\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 1\nSYSTEMS NEUROSCIENCE\nRönnberg et al. ELU: theory, data, and clinical implications\nloss (e.g., Lyxell and Rönnberg, 1989; Rönnberg, 1990; Rönnberg\net al., 1982, 1983 ). Spontaneous compensation for hearing loss\nthrough speechreading seemed, therefore, to be a cherished myth\n(Rönnberg, 1995).\nPERCEPTUAL AND COGNITIVE SKILLS\nThese data prompted us to look for other ways to try to explain\nat least parts of the large variability in speech understand-\ning observed across individuals ( Rönnberg et al., 1998a ,f o ra n\noverview). In a set of studies, we identiﬁed the following pre-\ndictor variables: verbal inference-making (sentence completion,\nLyxell and Rönnberg, 1987, 1989 ), context-free word decoding\n(Lyxell and Rönnberg, 1991 ), and information processing speed\nthat relies on semantic long-term memory (LTM; e.g., lexical\naccess speed, Rönnberg, 1990 ; as well as rhyme decision speed;\nLyxell et al., 1994; Rönnberg et al., 1998b ). Indirect predictors\nof sentence-based speechreading performance included the VN\n130/P200 peak-to-peak amplitude measure in the visual evoked\npotential (Rönnberg et al., 1989 ); WMC measured by the reading\nspan test ( Lyxell and Rönnberg, 1989; Pichora-Fuller, 1996 ); and\nverbal ability ( Lyxell and Rönnberg, 1992 ). Overall, the indirect\npredictors were found to be related to sentence-based speechread-\ning via their relationships with the direct predictors. This set\nof results demonstrated that WMC is strongly related to verbal\ninference-making, which in its turn is related to speechreading\nskill ( Lyxell and Rönnberg, 1989 ); the amplitude of the visual\nevoked potential is related to speechreading via word decoding\n(Rönnberg et al., 1989 ); and verbal ability is related to speechread-\ning via its relation to lexical access speed ( Lyxell and Rönnberg,\n1992).\nOTHER MODALITIES OF COMMUNICATION\nA more general picture emerged as evidence accumulated that\nmany of the predictor variables also related to other forms of\ncommunication. Successful visual -tactile speech communication\nand cued speech (i.e., a phonemic-based system which uses hand\nshapes to supplement speechreading) are predicted by phono-\nlogical skills (e.g., Leybaert and Charlier, 1996; Bernstein et al.,\n1998; Leybaert, 1998 ). The precision of a phonological represen-\ntation assessed by text-based rhyme tests has been shown to be\nan important predictor of the rate of visual-tactile ( Rönnberg\net al., 1998b; Andersson et al., 2001a,b ), and visual speech track-\ning ( Andersson et al., 2001a,b ). In the same vein, audio-visual\nspeech understanding in cochlear implant (CI) users is pre-\ndicted by both phonological ability and individual differences in\nWMC measured using a reading span test ( Lyxell et al., 1996,\n1998).\nIMPORTANCE OF WM\nThus, about a decade ago, the data were pointing to an impor-\ntant role for WMC in predicting, directly or indirectly, the\nindividual differences in speech understanding in one or more\nmodalities. Testing participants who were hard-of-hearing or deaf\nprovided clues as to how to re-conceptualize theories concern-\ning speech understanding in individuals with normal hearing to\ntake into account how their performance varies across a con-\ntinuum from ideal to adverse perceptual conditions. However,\nmore direct tests of the hypothesis concerning the importance of\nWMC for speech understanding in atypical cases and conditions\nwere needed.\nSPECIFYING THE ROLE OF WMC IN EASE OF LANGUAGE\nUNDERSTANDING\nDEFINING WM\nWM is a limited capacity system for temporarily storing and pro-\ncessing the information required to carry out complex cognitive\ntasks such as comprehension, learning, and reasoning. An indi-\nvidual’s WMC, or span, is measured in terms of their ability to\nsimultaneously store and process information. Importantly, com-\nplex WMC is the crucial ability when it comes to understanding\nlanguage, viz being able to store and process information rela-\ntively simultaneously. Simple span tests, such as digit span, mainly\ntap storage functions in short-term memory, and tend not to be\nsuch good predictors of language comprehension, reading ability\nand speechreading ability [for an early review see Daneman and\nMerikle (1996) ;b u ts e e Unsworth and Engle (2007) ]. We have\nusually assessed WMC using a reading span test ( Daneman and\nCarpenter, 1980; Rönnberg et al., 1989; Just and Carpenter, 1992 ).\nIn the reading span test procedure, the participant reads a sen-\ntence as quickly as possible and then performs a task to ensure\nthat the sentence has been fully processed. After a small set of\nsentences has been presented, read and understood, the partici-\npant is asked to recall either the ﬁrst or last word of each of the\ns e n t e n c e si nt h es e ti nt h eo r d e ri nw h i c ht h e yw e r ep r e s e n t e d .\nSet size gradually increases and the WM span is determined to\nbe the largest set size for which the individual can correctly recall\na minimum speciﬁed proportion of the words. We have found\nin our research that the total number of words correctly recalled\nin any order, is a more sensitive predictor variable than set size\n(Rönnberg et al., 1989; Lunner, 2003; Rönnberg, 2003 ). The basic\nassumption is that, as the processing demands of the reading span\ntask increase, there will be a corresponding decrease in how much\ncan be stored in the limited capacity WM system. Total reading\nspan score is used to gauge this trade-off between WM processing\nand storage.\nThere is a strong cross-modal relationship between reading\nspan scores (visual-verbal) and spoken communication skills\n(auditory-verbal), implying that it is supported by a modality-\ngeneral ability (cf. Daneman and Carpenter, 1980; Just and\nCarpenter, 1992; Kane et al., 2004 ). This may explain why WMC\nhas a predictive power that applies to several communicative\nforms (e.g., Ibertsson et al., 2009 ). Moreover, the reading span\ntest (and other similar complex span tests) seems to tap into\nsemantic processes such as inhibition of irrelevant information (in\nparticular inhibition of context-irrelevant word-meaning; Gunter\net al., 2003 ), the ability to selectively attend to one channel of\ninformation ( Conway et al., 2001 ), the ability to divide atten-\ntion between channels ( Colﬂesh and Conway, 2007 ), and the\nability to store and integrate signal-relevant prior semantic cues\n(Zekveld et al., 2011a, 2012 ). The similiarity of results across\nthe wide range of conditions applied in these studies supports\nthe role of WMC in on-line language processing. Our research\nassessed the role of WMC during language understanding in var-\nious conditions such as when speech is processed visually by\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 2\nRönnberg et al. ELU: theory, data, and clinical implications\nspeechreaders, when auditory speech is heard in noise, by lis-\nteners with hearing impairment, when hearing aids are used,\nand when sign rather than speech is the signal used to convey\nlanguage.\nEXTREME SPEECHREADING SKILL\nCase studies of extremely skilled speechreaders ( Rönnberg, 1993;\nLyxell, 1994; Rönnberg et al., 1999 ) demonstrated that bottom-\nup processing skills (e.g., lexical access speed and phonology)\nare only important up to a certain threshold,o rl e v e lo fl a n -\nguage understanding. The threshold is assumed to be due to the\nefﬁciency of phonologically mediated lexical access, constrained\nby neural speed at different levels in the perceptual-cognitive\nsystem ( Pichora-Fuller, 2003 ). We showed that to surpass this\nthreshold, and to become speechreading experts, the individual\nhas to be equipped with large complex WMC and related ver-\nbal inference-making and/or executive skills (see also Andersson\nand Lidestam, 2005 ). This seemed to be true irrespective of\ncommunicative habit—participant GS used tactile speechread-\ning ( Rönnberg, 1993 ), participant MM was bilingual in sign and\nspeech ( Rönnberg et al., 1999 ), and participant SJ used visual\nspeechreading strategies only ( Lyxell, 1994). The effects could not\nbe explained in terms of age, degree of hearing loss, or even onset\nof the loss.\nNOISE, HEARING LOSS, AND HEARING AIDS\nThe importance of predictions of individual differences in speech\nunderstanding based on reading span was crucially demonstrated\nwhen a strong association was found with spoken sentence recog-\nnition in noise by individuals with hearing loss irrespective of\nwhether they were tested with or without hearing aids ( Lunner,\n2003). During conversation, the individual who has impaired\nhearing must orchestrate the interplay between distorted percep-\ntual input, LTM, and contextual cues. We argue that the storage\nand processing abilities reﬂected in complex WMC tasks are\nessential for such compensatory interactions in people with hear-\ning loss. WMC also seems to play an important role when people\nwith normal hearing must understand language spoken in acous-\ntically adverse conditions (for discussions see Mattys et al., 2012;\nPichora-Fuller et al., 1995; McKellin et al., 2007 ).\nSIGN LANGUAGE\nInsight into the role of WM in sign language communication also\nled to a series of studies at our lab investigating the neurocogni-\ntive mechanisms of WM for sign language ( Rönnberg et al., 2004;\nRudner et al., 2007, 2010, 2013; Rudner and Rönnberg, 2008a,b ).\nThese studies demonstrate similar neurocognitive mechanisms\nacross language modalities with some modality-speciﬁc aspects.\nThese language modality-speciﬁc differences include a greater\ninvolvement of superior parietal regions in WM for sign language\nand a de-emphasis of temporal processing mechanisms.\nTaken together, the speech understanding and sign language\nﬁndings set the stage for formulating the Ease of Language\nUnderstanding model (ELU, see Rönnberg, 2003; Rönnberg\net al., 2008 ) to extend existing more general models of WM\nin order to account for a wide range of communication\nconditions.\nTHE ORIGINAL WM SYSTEM FOREASE OFLANGUAGE\nUNDERSTANDING (ELU)\nThe broader context of the ELU model is that of cognitive hear-\ning science. Cognitive Hearing Science is the new ﬁeld that\nhas emerged in response to general acknowledgement of the\ncritical role of cognition in communication ( Arlinger et al.,\n2009). Characteristic of cognitive hearing science models is that\nthey emphasize the subtle balancing act, or interplay between\nbottom-up and top-down aspects of language processing (e.g.,\nSchneider et al., 2002; Scott and Johnsrude, 2003; Tun et al.,\n2009; Mattys et al., 2012 ). The ELU model describes how and\nwhen WM is engaged to support listening in adverse conditions,\nand how it interacts with LTM. In the original version we did\nnot distinguish between episodic and semantic LTM but sub-\nsequent research and theoretical development have proven that\nthis is an important distinction (see under EXTENDING THE\nELU APPROACH:.). Episodic memory is memory of person-\nally experienced events (tagged by time, place, space, emotion\nand context, see Tulving, 1983). Semantic memory refers to gen-\neral knowledge, without personal reference (e.g., vocabulary and\nphonology).\nIn the original model (see Figure 1; Rönnberg, 2003; Rönnberg\net al., 2008; Stenfelt and Rönnberg, 2009 ), we assumed that\nmultimodal speech information is Rapidly, Automatically, and\nMultimodally Bound into a PHOnological representation in an\nepisodic buffer (cf. Baddeley, 2000, 2012 ) called RAMBPHO.\nRAMBPHO is assumed to operate with syllables that feed forward\nin rapid succession (cf. Poeppel et al., 2008; Bendixen et al., 2009 ).\nIf the RAMBPHO-delivered sub-lexical information matches a\ncorresponding syllabic phonological representation in semantic\nLTM, then lexical access will be successful and there is no need\nfor top-down processing. And, if RAMBPHO continues to pro-\nvide matching syllabic information, lexical retrieval will continue\nto occur implicitly and at a rapid rate. The time-window for\nthe assembly of the RAMBPHO information and for success-\nful lexical retrieval is assumed to start when activation begins at\na cortical level [superior temporal gyrus (STG)/posterior supe-\nrior temporal sulcus; ( Poeppel et al., 2008 )], where the neural\nbinding of syllabic auditory and visual speech seems to occur\n(around 150 ms after speech onset, Campbell, 2008 ), and then\nit generally takes another 100–250 ms before lexical access pre-\nsumably occurs supported by neural mechanisms in the left\nmiddle temporal gyrus(MTG)/inferior temporal gyrus ( Poeppel\net al., 2008 ;s e ea l s o Stenfelt and Rönnberg, 2009 ). If, however,\nthe RAMBPHO information cannot be immediately related to\nphonological representations in semantic LTM or is not precise\nenough to match them unambiguously, lexical access is delayed,\ntemporarily disrupting the feed-forward cycle of information\nﬂow. Explicit and deliberate WM processes are assumed to be\ninvoked to compensate for this mismatch between RAMBPHO\noutput and LTM representation. These explicit processes typi-\ncally operate on another time scale, measured in seconds rather\nthan milliseconds ( Rönnberg et al., 2008 ). Examples of such pro-\ncesses include inference-making, semantic integration, switching\nof attention, storing of information, and inhibiting irrelevant\ninformation. While the source of the mismatch is at the lexi-\ncal level, later explicit compensation may involve other linguistic\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 3\nRönnberg et al. ELU: theory, data, and clinical implications\nFIGURE 1 | The working memory model for Ease of Language Understanding (ELU, adapted fromRönnberg et al., 2008).\nlevels. WMC is assumed to be required for most explicit process-\ning aspects/subskills.\nGenerally then, depending on the conditions under which the\nincoming speech signal unfolds (ambient noise, hearing impair-\nment, signal processing in the hearing aid, etc.), as well as the pre-\ncision and quality of the semantic LTM representation, the relative\ncontributions of explicit and implicit processes will continuously\nﬂuctuate during a dialogue.\nINITIAL TESTS OF THE MODEL\nThe experimental studies performed to test the model have prin-\ncipally used two types of manipulation, one based on hearing aid\nsignal processing and one based on presentation of text cues in\norder to induce a mismatch between RAMBPHO and semantic\nLTM. Initial testing was done primarily with spoken language pre-\nsented in auditory noise, but the model is also likely to be appli-\ncable to signed languages presented in visual noise (cf. Speranza\net al., 2000 ). Brain imaging studies (e.g., Söderfeldt et al., 1994;\nRönnberg et al., 2004; Rudner et al., 2007, 2013; Cardin et al.,\n2013) suggest that similar but not identical neural networks are\nactive for processing sign language and speech, and that the close\nrelation between semantics and phonology in sign language may\ninﬂuence the mismatch mechanism ( Rudner et al., 2013 ).\nUSING AUDITORY SIGNAL PROCESSING MANIPULATIONS TO INDUCE\nPHONOLOGICAL MISMATCH\nWide Dynamic Range Compression (WDRC) is one of the\ntechnologies used in modern digital hearing aids to increase\nspeech intelligibility by applying non-linear ampliﬁcation of the\nincoming signal such that soft sounds become audible without\nloud sounds becoming uncomfortable. However, this non-linear\nsignal processing can also have side-effects that distort the\nphonological properties of speech, especially when compres-\nsion release is fast. We used this phenomenon to investigate\nthe main prediction of WM-dependence in the ELU model in\nexperienced hearing-aid users. Hearing aids were experimentally\nmanipulated such that participants received WDRC for the ﬁrst\ntime. According to the model, given that a syllabic segment\nin the speech stream is processed with a new algorithm, the\nsound may seem different compared to the one delivered by the\nhabitual algorithm, thus causing a relative RAMBPHO-induced\nmismatch with the phonological-lexical representation in LTM.\nResults showed that individual differences in WMC accounted\nfor most of the variance in the threshold for 50% correct word\nrecognition on speech-in-noise tests, irrespective of whether sta-\ntionary or modulated noise backgrounds were applied ( Foo\net al., 2007 ;c f . Desjardins and Doherty, 2013 ). This means\nthat as long as we disrupt the habitual processing mode, WMC\nis invoked.\nA follow-up intervention study was conducted to investigate\nhow the relationship between WMC and mismatch might change\nas the individual acclimatized to a new hearing aid algorithm.\nAgain, participants who were habitual hearing aid users were\nswitched to a new fast or slow signal processing algorithm in the\nhearing aid. After nine weeks of experience with one kind of hear-\ning aid compression, participants were tested either with the same\nkind of compression (“matching” conditions), or with the other\nkind of compression of which they had no experience (“mis-\nmatching” conditions). As predicted, in one study conducted in\nSwedish ( Rudner et al., 2009a,b ) and in another conducted in\nDanish ( Rudner et al., 2008 ), thresholds for 50% correct word\nrecognition on speech-in-noise tests for mismatching compres-\nsion conditions were correlated with WMC. WMC was not the\nmain predictor of speech-in-noise thresholds for matching con-\nditions. Independent studies support the notion that WMC is\ncrucial to speech understanding in adverse conditions by hearing\naid users ( Gatehouse et al., 2003, 2006; Lunner, 2003; Akeroyd,\n2008; Rudner et al., 2011; Mattys et al., 2012 ).\nUsing the visual letter monitoring task as an index of\nWMC, Lunner and Sundewall Thorén (2007) showed that WMC\naccounted for about 40% of the variance in the ability to perceive\nspeech in modulated background noise with FAST compression.\nPure-tone average hearing loss, on the other hand, accounted for\nless than 5% of the variance. Importantly, the pattern was reversed\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 4\nRönnberg et al. ELU: theory, data, and clinical implications\nwhen compression by the hearing aid was SLOW and tests were\nconducted in steady-state noise conditions: WMC explained only\n5 %o ft h ev a r i a n c ew h i l ep u r e - t o n eh e a r i n gl o s se x p l a i n e d3 0 % .\nLunner and Sundewall Thorén (2007) suggested that FAST com-\npression in modulated noise backgrounds better reﬂects the more\nrapid changes in the signal and noise characteristics of every-\nday listening conditions. Hence, using SLOW compression in\nsteady-state noise conditions may underestimate everyday cog-\nnitive demands (cf. Festen and Plomp, 1990 ). The conclusions\ndrawn in the studies using WDRC are consistent with recent\nﬁndings in which other advanced hearing aid signal processing\nalgorithms were used: Arehart et al. (2013) found that a high\ndegree of frequency compression reduced intelligibility more for\nindividuals with low WMC compared to individuals with high\nWMC, especially for older adults.\nThe emerging picture seems to be that advanced signal pro-\ncessing algorithms designed to improve intelligibility and listen-\ning comfort may also generate RAMBPHO-dependent mismatch\ndue to distortions at the syllable level caused by unfamiliar ampli-\ntude or frequency compression. Thus, there is a beneﬁt and a cost\nfrom such signal processing. Mismatches, or costs, are overcome\nmore successfully by individuals with high WMC.\nUSING TEXTUAL MANIPULATIONS TO CREATE PHONOLOGICAL\nMISMATCH\nSevere hearing loss can lead to phonological deterioration in\nsemantic LTM ( Andersson, 2002; Lazard et al., 2010; Rönnberg\net al., 2011b ). Classon et al. (2013a) undertook a study that tested\nthe hypothesis that high WMC can compensate for poor phono-\nlogical skills in individuals with hearing impairment. To avoid\naudibility problems, phonological mismatch was manipulated\nusing text rather than speech. Classon et al. (2013a) showed that\nhearing impairment negatively affected performance on a text-\nbased task in which participants decide if two words rhyme or not\nin RAMBPHO-dependent, mismatching conditions. Mismatch\nwas created in conditions where the two test words rhymed\nbut were orthographically dissimilar, or alternatively, did not\nrhyme but were orthographically similar ( Lyxell et al., 1993, 1998;\nAndersson and Lyxell, 1998; Andersson, 2002 ). In the latter case,\northographic similarity may induce an incorrect “yes” response\nwhen words do not rhyme, if the phonological precision of rep-\nresentations in semantic LTM is compromised. The prediction\nbased on the ELU model is that participants who have a high\nWMC will be able to compensate for poor phonological repre-\nsentations because they can keep representations in mind and\ndouble-check back and forth to ensure that the words really do\nnot rhyme before they decide. The data conﬁrmed this predic-\ntion. Hearing impaired participants with high WMC performed\non a par with normal hearing participants, whereas hearing\nimpaired participants with low WMC displayed higher error\nrates than the normal hearing subgroups with low WMC. Note\nthat hearing impairment did not confound the results since the\nlevel of WMC was matched across groups with normal hearing\nand hearing impaired participants, and there was no difference\nin the degree of hearing impairment between the high vs. low\nWMC subgroups.\nSEMANTIC STRATEGY IN RHYME TASKS\nThe effects of hearing impairment on the mismatching condi-\ntions in the yes/no rhyme task may be attributed to imprecise\nphonological representations in semantic LTM. This may lead\nautomatically to a non-phonological orthographic bias, and per-\nhaps even a semantic bias, when written words are presented in\na rhyme task, especially for individuals with hearing impairment\nwho have a low WMC. The plausibility of such an explanation\nwas reinforced by the ﬁnding that participants with low WMC\noutperformed participants with high WMC on subsequent inci-\ndental recognition of items that had been correctly identiﬁed in\nthe initial rhyme testing phase. Since semantic processing has\nbeen shown to promote episodic LTM (e.g., Craik and Tulving,\n1975), a semantic interpretation of this seemingly paradoxical\nresult may fall into place.\nConnected to this semantic interpretation of the rhyming data,\nis the fact that the test of WMC that we have been discussing\nso far, the reading span test, also measures important semantic\ninterpretation processes. Although the semantic absurdity judg-\nments typically demanded in this task ( Rönnberg et al., 1989 )\nwere initially introduced to ascertain that the participants actually\nprocessed the whole sentence rather than strategically focusing\nonly on the ﬁrst or ﬁnal words, semantic processing may in itself\nbe an important component of the test. Indeed, sentence comple-\ntion ability (tapping semantic integration and grammar) under\ntime pressure is signiﬁcantly correlated to performance in the\nreading span test ( Lyxell and Rönnberg, 1989). Although the read-\ning span test taps into several storage and processing components\nsummarized by one measured variable, a semantic perspective on\nreading span may cast new light on old data in that rapid sense-\nmaking and semantic judgment is demanded in the reading span\ntest as well as in the sentence-completion task.\nNEURAL SIGNATURES OF TEXT-SPEECH SEMANTIC MISMATCH\nWMC, again measured with the reading span task, has in recent\nstudies been shown to modulate the ability to use semantically\nrelated cues and to suppress unrelated, “mismatching” cues to\nhelp understand speech in noise ( Zekveld et al., 2011a, 2012 ).\nInterestingly, both the WMC of the participants and the lexicality\nof text cues modulated neural activation in the left inferior frontal\ngyrus (LIFG) and the STG during speech perception. Presumably,\nthese areas are related to compensatory processes in semantic cue\nutilization. Independent data also suggest that LIFG is involved in\nsemantic and syntactic processing networks ( Rodd et al., 2010 ).\nCortical areas beyond the temporal lobe are engaged in the pro-\ncessing of intelligible but degraded speech ( Davis and Johnsrude,\n2007). It is quite plausible that there is a functional connectivity\nbetween LIFG and STG, and that LIFG modulates STG via top-\ndown connections when semantic processing is involved ( Obleser\nand Kotz, 2011 ). In fact, the general picture is that there are ven-\ntral and dorsal pathways that connect pre-frontal and temporal\nlanguage-relevant regions which support semantic and syntactic\nprocesses (Friederici and Gierhan, 2013 ).\nINTERIM SUMMARY\nThus far, we can infer the architecture of a WM system (i.e.,\nthe ELU model) that is invoked when there is some kind of\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 5\nRönnberg et al. ELU: theory, data, and clinical implications\nsignal processing that changes the phonological structure of the\nspeech signal, or when there is a combination of signal process-\ning and ﬂuctuating background noise that puts large demands on\nphonological processing. In addition, there is also new evidence\nto suggest that a semantic mismatch requires WM resources to\nhelp focus on the target-speech signal while inhibiting distracting\nsemantic cue information as will be discussed further below.\nEXTENDING THE ELU APPROACH: WMC RELATED TO\nATTENTION, MEMORY SYSTEMS, AND EFFORT\nIn the following sections, evidence is reviewed indicating that\nWMC plays a part in (a) “early” attention processes, (b) short-\nterm retention of spoken information when the signal is pro-\ncessed by hearing aids, (c) inhibition and episodic LTM of masked\nspeech, (d) the effects of hearing impairment on episodic and\nsemantic LTM, and (e) listening effort. These data—behavioral\nand physiological—have shaped a new version of the ELU model,\nwhich will be presented subsequently.\nWMC INFLUENCES EARLY ATTENTIONAL PROCESSES\nThis section suggests that high WMC is associated with neural\ninteractions that facilitate attention and which are important for\nfurther speech signal processing ( Peelle and Davis, 2012 ). This\nkind of cognitive tuning of the brain does not seem to involve\nany explicit processing component, although it is dependent\non WMC.\nWMC is related to the ability to inhibit processing of irrelevant\ninformation and overrule undesired but pre-potent responses\n(e.g., Kane et al., 2001; Engle, 2002 ). More precisely, high-WMC\nindividuals appear to have a superior ability to modulate atten-\ntion span (i.e., how much information that has access to cognitive\nprocessing). Where in the processing chain ﬁltering out of irrele-\nvant information takes place is still a subject of debate. Relations\nbetween WMC and early cortical auditory processing (as reﬂected\nin the amplitude of the N1 component of event-related poten-\ntial measures) have been demonstrated with greater amplitudes\nfor attended sound and lesser amplitudes for ignored sound in\nhigh-WMC individuals ( Tsuchida et al., 2012 ). However, a recent\nexperiment in our lab ( Sörqvist et al., 2012a ) suggests that WMC\nis involved in ﬁltering processes at even earlier (sub-cortical)\nstages. Normally-hearing participants visual-verbal performed a\nvisual n-back (1-, 2-, 3-back) task ( Braver et al., 1997 )w h i l e\nbeing presented with to-be-ignored background sound. In a con-\ntrol condition, the participants just heard the sound and did not\nperform any task. In the n-back task, WM load increased with\nincreasing n and the control condition represented least load. The\nmagnitude of the auditory brain stem response (ABR, wave V , on\naverage 7 ms post-stimulus onset) was negatively associated with\nWM load. Moreover, higher WMC scores were related to a greater\ndifference of the ABR between conditions. Thus, both the exper-\nimental load manipulation and correlational evidence converge\non the same conclusion: early attentional processes interact with\nWM. Our interpretation is that cognitive load reduces resources\nat the peripheral level, and the relation with WMC suggests a\nrelationship between central and peripheral capacity.\nOne mechanism underpinning this relation might be the\nalpha rhythm. Alpha rhythms reﬂects the cognitive system’s\npre-stimulus preparation for incoming stimuli, enabling efﬁcient\nprocessing ( Babiloni et al., 2006 ), and have been associated with\nboth WM load and processing of acoustically degraded stimuli\n(Obleser et al., 2011 ). Moreover, in a recent focused review of\nbrain oscillations and WM, it was suggested that the alpha rhythm\nserves as an attentional gate-keeper to optimize the signal-to-\nnoise ratio for WM-based processing, and that the number of\ngamma cycles that ﬁt within one theta cycle may index WMC\n(Freunberger et al., 2011 ).\nHowever, single indices may only tell part of the story of how\nbrain oscillations relate to WM. In a recent review, it has been\nargued that the correlations between oscillatory phases in dif-\nferent brain regions, so called phase synchronization, affect the\nrelative timing of action potentials. This is important for a mem-\nory system such as WM, which in turn depends on the interaction\nbetween different storage and executive processing components\n(and their corresponding phases), for example, phase correlations\nbetween pre-frontal and temporal regions ( Fell and Axmacher,\n2011).\nThus, a high WMC may facilitate neural ﬁne-tuning at\nan early level of auditory processing (cf. Pichora-Fuller, 2003;\nSörqvist et al., 2012a ) but may also reﬂect a highly synchro-\nnized brain network ( Fell and Axmacher, 2011 ). The conclu-\nsion about some kind of ﬁne-tuning is further reinforced by\nthe ﬁnding that WM processes are interconnected with the\neffects of practice on auditory skills ( Kraus and Chandrasakaren,\n2010) and their corresponding neural signatures ( Kraus et al.,\n2012).\nAll in all then, data from independent labs suggest that WMC\nis related to several brain oscillation indices, and that WMC is\nrelated to early attention processes. This WMC-based top-down\ninﬂuence on speech-relevant attention processes may be part of\nthe explanation as to why attending to a speaker in a multi-\ntalker situation gives rise to dedicated neural representations\n(Mesgarani and Chang, 2012 ).\nWMC INTERACTS WITH SIGNAL PROCESSING AND SHORT-TERM\nRETENTION\nThis section presents data showing for the ﬁrst time that hearing\naid signal processing can improve short-term memory in hearing-\nimpaired individuals, and that this effect is modulated by WMC\n(Ng et al., 2013a,b ). This may prove to have important clinical\nconsequences (Piquado et al., 2012 ).\nEven when audibility is controlled (e.g., by amplifying speech\nwith hearing aids), individuals with hearing impairment still\nperform worse than young normal-hearing subjects, with cog-\nnitive factors accounting for residual variance in performance\n(e.g., Humes, 2007 ). Attentional resources may contribute to\nspeech understanding, especially in effortful or divided attention\ntasks ( Tun et al., 2009; Rönnberg et al., 2011a,b ). For example,\nTun et al. (2009) have shown poorer delayed recall for audi-\nble auditory stimuli in participants with impaired compared to\nnormal hearing when encoding took place under divided atten-\ntion conditions. Rönnberg et al. (2011a,b) also demonstrated that\nshort-term memory performance under divided attention encod-\ning conditions correlated with degree of hearing impairment (cf.\nHumes et al., 2006 ).\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 6\nRönnberg et al. ELU: theory, data, and clinical implications\nHearing aid signal processing schemes may reduce attention\ncosts while listening to speech in noise and thus improve speech\nunderstanding. It has been demonstrated that noise reduction\nsignal processing reduces listening effort for people with nor-\nmal hearing ( Sarampalis et al., 2009 ). In a recent study ( Ng\net al., 2013a,b ), we examined how hearing aid signal processing\ninﬂuences word recall in people with hearing impairment.T h e\nscheme under investigation was binary time-frequency masking\nnoise reduction ( Wang et al., 2009 ). Each participant listened to\nsets of eight sentences from the Swedish Hearing-In-Noise-Test\n(HINT) materials ( Hällgren et al., 2006 ) in 4-talker babble or\nstationary noise, with and without noise reduction. To control\naudibility, SNRs were individualized such that performance lev-\nels were around 95% for word recognition in stationary noise\nwith individual linear ampliﬁcation and individually prescribed\nfrequency response. Typical SNRs for 95% correct were around\n+5 dB. Each participant recalled as many sentence-ﬁnal words as\npossible after each set of sentences had been presented. We found\nthat participants performed worse in noise than in quiet and that\nthis effect was partially restored by noise reduction. In particu-\nlar, individuals with high WMC recalled signiﬁcantly more of the\nitems from the end of the lists (recency position) presented in\nn o i s ew h e nn o i s er e d u c t i o nw a su s e d .\nThus, WMC interacts with signal processing in hearing aids\nand facilitates short-term memory. There is obviously room for\nimprovement even when the audibility of the signal is good, a\nfact that offers a new perspective on how to conceptualize beneﬁts\nfrom different kinds of signal processing in hearing aids.\nWMC—ESPECIALLY THE INHIBITORY ASPECTS—DETERMINE\nEPISODIC LTM FOR PROSE MASKED BY SPEECH\nThis section is about how WMC relates to inhibition of an inter-\nfering talker during listening to sentences and to later long-term\nepisodic recall.\nWe have recently shown that WMC seems to be related to\nlong-term retention of information that is conveyed by masked\nspeech (Sörqvist et al., 2012b ). Y oung, normally-hearing students\nlistened to invented stories (each about 7.5 min long) about fake\npopulations and afterwards answered questions about their con-\ntent (e.g., what did the lobiks wear in the kingdom of death?). The\ns t o r i e sw e r es p o k e ni nam a l ev o i c ea n dm a s k e db ya n o t h e rm a l e\nvoice (normal or spectrally-rotated; Scott et al., 2009 ).\nTwo types of complex WMC tests were administered sep-\narately: the reading span and the size-comparison (SIC) span\ntest ( Sörqvist et al., 2010 ). The SIC span is a WMC test that\ntargets the ability to resist semantic confusion. It involves com-\nparing the size of objects while simultaneously maintaining and\nrecalling words taken from the same semantic category as the to-\nbe-compared words. The distinguishing feature of the test is that\nthe semantic interference between the comparison words and the\nto-be-recalled words must be resolved by inhibiting the potential\nsemantic intrusions from the comparison words.\nAbility to answer content questions was superior when the\nstory was masked by a rotated as compared with a non-rotated\nspeech signal. More importantly, SIC span was a better predic-\ntor variable than reading span of the magnitude of this difference\n(Sörqvist et al., 2012b ). We argue that the inhibition ability\ntapped by SIC span is involved during resolution of the confusion\nbetween competing and target speech and that better resolution\nenhances episodic encoding and retrieval. This will, at least in\npart, determine an individual’s ability to remember the important\nparts of a conversation.\nSpeech-in-speech processing studies have typically addressed\nspeech perception as such (e.g., Bronkhorst, 2000 ). Our contri-\nbution is that we associate WMC—and the inhibition component\nin particular—with the encoding carried out during speech-\nin-speech comprehension, and how this type of WMC encod-\ning relates to episodic LTM (cf. Hannon and Daneman, 2001;\nSchneider et al., 2010 ) .T h e r ei ss o m ee v i d e n c eo far e l a t i o n\nbetween episodic LTM and cognitive spare capacity ( Rudner et al.,\n2011; Mishra et al., 2013 ).\nDEGREE OF HEARING IMPAIRMENT IN HEARING AID USERS IS\nASSOCIATED WITH EPISODIC LTM\nThis section summarizes a recent cross-sectional study on a sam-\nple of hearing aid users and how their hearing thresholds are\nassociated with the efﬁciency of different memory systems.\nDespite the possibility of using hearing aids, hearing problems\ncontinue to occur in everyday listening conditions. Many people\nwho own hearing aids do not use them on a regular basis. For\nthose who do wear them regularly, signal processing algorithms\nin hearing aids cannot generally provide an optimal listening sit-\nuation in noisy and challenging conditions ( Lunner et al., 2009 ).\nBy including hearing aid users ( n = 160) from the longitudinal\nBetula study of cognitive aging ( Nilsson et al., 1997 ), we made\na conservative test of the hypothesis that hearing impairment is\nnegatively related to episodic LTM deﬁcits. The basis of the pre-\ndiction from the ELU model ( Rönnberg et al., 2011a,b )i st h a t\nmismatches will remain despite the use of a hearing aid, and\nhence fewer items will be encoded and retrieved from episodic\nLTM. Therefore, we assume a disuse effect on episodic LTM,\nleading to a less efﬁcient episodic memory system. However,\nshort-term memory (STM, here operationalized by Tulving and\nColotla, 1970; the Tulving and Colotla lag measure) and WM (not\nexplicitly measured in this study) should be increasingly active\nin mismatching conditions because both systems would be con-\nstantly occupied during retrospective disambiguation of what had\nbeen said in a conversation. Thus, both STM and WM would be\nrelatively less vulnerable to disuse.I ti sa l s op r e d i c t e dt h a ts e m a n t i c\nLTM should be highly correlated with episodic LTM because the\nstatus of phonological representations in semantic LTM should\nbe tightly related to the success of encoding into episodic LTM.\nThese predictions have recently been conﬁrmed by structural\nequation modeling. Episodic LTM decline is related to long-term\nhearing impairment, despite the use of existing hearing aid tech-\nnology ( Rönnberg et al., 2011a,b ). One note of caution though is\nthat exact measures of every-day hearing aid use were not avail-\nable. Hence, any potential dose-response relationship among the\nhearing aid wearers could not be assessed.\nThus, hearing loss was independently related to episodic LTM\n(verbal recall tasks) and semantic LTM (initial letter ﬂuency and\nvocabulary) but unrelated to STM, even when age was accounted\nfor. Visual acuity alone, or in combination with auditory acuity,\ndid not contribute to any acceptable structural equation model; it\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 7\nRönnberg et al. ELU: theory, data, and clinical implications\nonly made the prediction of episodic LTM decline worse by stan-\ndard goodness-of-ﬁt criteria (see also Lindenberger and Ghisletta,\n2009). And ﬁnally, even when the episodic LTM tasks were of non-\nauditory nature (i.e., motor encoding of lists of imperatives and\nsubsequent free recall of these actions, Nilsson et al., 1997 )t h e\nassociation with hearing loss persisted ( Rönnberg et al., 2011a,b ).\nAlthough the participants wore their hearing aids whilst com-\npleting the auditory episodic me mory tasks, this negative result\nmay be accounted for in terms of perceptual stress, or infor-\nmation degradation (cf. Pichora-Fuller et al., 1995 ). It has been\nargued and empirically demonstrated that once perceptual stress\nis equated for example among different age groups, differences\nin performance on WM, associative memory and comprehension\ntasks (e.g., Schneider et al., 2002 ) tend to vanish. Nevertheless,\nthe decreased performance in the non-auditory tasks reported\nin Rönnberg et al. (2011a,b) c a n n o tb ee x p l a i n e do nt h eb a s i s\nof information degradation and it is possible that there are\nboth information degradation and long-term deprivation effects.\nCentral mechanisms involving attentional resources could also\nbe affected by hearing impairment, which in turn would predict\nproblems with memory encoding ( Tun et al., 2009; Majerus et al.,\n2012; Peelle and Davis, 2012 ;c f . Sörqvist et al., 2012a )a n dp o s -\nsibly WMC (see also Schneider et al., 2010 ). Before we can reach\ndeﬁnite conclusions about the selective effects of hearing impair-\nment on memory systems, a broader spectrum of tasks assessing\ndifferent memory systems must be employed.\nFrom a more general and clinical perspective, we suggest that\nfuture longitudinal studies should evaluate the effects of the use of\nthe hearing aids on cognition and memory systems, and in partic-\nular, the effects of certain kinds of signal processing on different\ntasks assumed to index different memory systems.\nWMC AND EFFORT\nIn this section, we discuss recent work related to the ELU pre-\ndiction about WMC and effort (cf. Hervais-Adelman et al., 2012;\nAmichetti et al., 2013 ). In particular, we focus on predictions\nbased on recent data using pupillometry that contrast with the\nELU prediction.\nApart from taxing cognitive capacity, listening under adverse\nconditions is often associated with subjectively experienced effort,\nespecially in individuals with hearing impairment ( Pichora-\nFuller, 2006 ). The ELU prediction about effort, or the inverse\nnotion of “ease” (Rönnberg, 2003) is that in effort-demanding lis-\ntening situations, an individual with a high WMC will be better\nable to compensate for the distorted signal, without exhausting\nWMC and therefore experience less effort in comparison to an\nindividual with small WMC (cf. the neural efﬁciency hypothesis;\ne.g., Pichora-Fuller, 2003; Heitz et al., 2008 ), given that the task\ndoes not hit ceiling/ﬂoor ( Rönnberg, 2003 ). Intermediate difﬁ-\nculty levels provide the best opportunity for explicit processes to\noperate in a compensatory fashion. Recent work by our group has\nconﬁrmed that higher WMC is associated with lower perceived\nand rated listening effort for intermediate levels of difﬁculty, or\n“ease” of processing ( Rudner et al., 2012 ). We suggest that sub-\njective effort ratings may be useful for understanding the relative\ncontributions of explicit WM processes to speech understanding\nin challenging conditions ( Rudner et al., 2012; Ng et al., 2013b ).\nSome researchers have proposed that the pupillary response\nreﬂects cognitive processing load during the processing of sen-\ntences of different grammatical complexity ( Piquado et al., 2010;\nZekveld et al., 2010 ). This response is also sensitive to age, hearing\nloss, and the extra effort required to perceive speech in compet-\ning talker conditions compared to noise maskers ( Zekveld et al.,\n2011b; Koelewijn et al., 2012a ). Koelewijn et al. (2012b) observed\nthat people with high SIC spans demonstrated larger pupil size,\nand that higher SIC span performance, in turn, was related\nto lower signal-to-noise ratios needed to perform at a certain\nthreshold level in the competing talker condition. This pattern\nof ﬁndings may suggest that cognitive load is actually increased\nby high WMC, which can be viewed as a paradoxical result, but\nh a ss u p p o r ti nt h el i t e r a t u r e(Van der Meer et al., 2010; Zekveld\net al., 2011b ). Another interpretation of these data is that indi-\nviduals with a high capacity solve difﬁcult stimulus conditions by\nconsuming more cognitive brain resources (more extensively or\nmore intensively), thus exercising greater task engagement, and\nthis is what is reﬂected in the pupil size variations ( Koelewijn\net al., 2012b ;s e e Grady, 2012).\nPupil size seems to reliably capture cognitive load and asso-\nciated effort under certain semantic or informational masking\nconditions. The exact mechanisms behind the empirical ﬁnd-\nings so far remain to be elucidated. But clinically, irrespective of\nexplanatory mechanism, pupil size may become a complementary\nmeasure to subjective ratings of effort.\nGENERAL DISCUSSION AND A NEW ELU-MODEL\nPhonological and semantic mismatches increase the dependence\non WMC in speech-in-noise tasks. However, as we have seen\nin the current review of recent ELU-related WMC studies, the\nrole of WMC is extended to include early attention mechanisms,\ninteractions with memory systems under different multi-talker\nconditions, both for short-term and LTM, and a relationship to\neffort via subjective and objective measures.\nBelow we present the new empirical extensions that emerge\nfrom our recent data inspired by the old ELU model ( Rönnberg\net al., 2008 ). Then, we describe the new ELU model, based on\nthese new empirical patterns, emphasizing in general and in detail\nthe new features that differ from the old model. A section on\npredictions will close the presentation of the new model. In the\nfollowing section, the new ELU model is compared to other\nrelevant WM and speech perception models. The paper ends\nby addressing some important clinical consequences that follow\nfrom the model.\nNEW EMPIRICAL EXTENSIONS\nFirst, the data we have presented and discussed suggest that\nseveral kinds of signal processing in hearing aids ( i.e., fast ampli-\ntude compression, frequency compression, and binary masking ),\ndesigned to facilitate speech perception, are handled best by\nindividuals with high WMC. This is the ﬁrst extension from\nthe original studies that informed the development of the ELU\nmodel ( Rönnberg et al., 2008 ). At that time, we did not know\nwhether WMC was important for just one kind of distortion\ninduced by signal processing (i.e., fast amplitude compression)\nor not. Importantly, when some kind of distortion of the signal\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 8\nRönnberg et al. ELU: theory, data, and clinical implications\nis introduced, the feed-forward mechanism (cf. Bendixen et al.,\n2009) of RAMBPHO that predicts yet-to-be-experienced (syl-\nlabic) elements in the unfolding sound sequence (cf. Poeppel\net al., 2008; Bendixen et al., 2009 ) seems to be temporarily inter-\nrupted, allowing ambiguous information to enter an explicit\nprocessing loop before understanding can be achieved.\nA second extension is related to the pre-tuning or synchroniza-\ntion by WMC, directly or indirectly, prior to or early on during\nstimulus presentation. One type of prior inﬂuence mediated by\nWMC relates to “early” attention processes ( Fell and Axmacher,\n2011; Freunberger et al., 2011; Sörqvist et al., 2012a ), another is\nrelated to priming, or pop-out (e.g., Davis et al., 2005 ). Recent\ndata suggest that the magnitude of the pop-out effect may be\nmediated by WMC ( Signoret et al., 2012 ). A third kind of inﬂu-\nence exerted by WMC relates to memory encoding operations\n(Sörqvist and Rönnberg, 2012 ), and subsequent inﬂuences on\nunderstanding, including turn-taking in a dialogue ( Ibertsson\net al., 2009 ). This kind of continuous feedback was not part of the\nold ELU model ( Rönnberg et al., 2008 ). This means that the new\nmodel also acknowledges a post-dictive, explicit feedback loop,\nfeeding into predictive RAMBPHO processing. This mechanism\nis akin to the hypothesis testing, analysis-by-synthesis aspect of\nthe Poeppel et al. (2008) framework (see below under Relation to\nother models).\nA third extension has to do with the role of WMC in process-\ning text cues that generate explicit semantic expectations of what\nwill come in the unfolding speech stream. WMC is particularly\nimportant when expectations are violated by the content of the\nspeech signal ( Zekveld et al., 2011a ). This may be because indi-\nviduals with high WMC have a superior ability to inhibit the\ncue-activated, mismatched representation in semantic memory\n(cf. Nöstl et al., 2012; Sörqvist et al., 2012b ). The discovery of\na semantic inﬂuence on RAMBPHO processing means that the\ntheoretical assumption of the model must be revised (see fur-\nther below). Further, research suggests that older people more\nfrequently rely on semantic context. For older people, incon-\ngruent semantic context seems to impair identiﬁcation of words\nin noise, although conﬁdence levels are higher than in younger\nadults ( Rogers et al., 2012 ). Older people have a smaller WMC\nthan younger individuals while frontal-lobe based executive func-\ntions may remain intact and this may account for the false hearing\neffects ( Rogers et al., 2012 ). Also, over many decades of greater\nreliance on context in the face of gradual age-related declines\nin sensory processing, there may be changes in brain organiza-\ntion with an anterior-posterior shift in the brain areas engaged in\ncomplex tasks ( Davis et al., 2008 ).\nA fourth extension is that high WMC individuals can deploy\nmore resources to both semantic and phonological aspectsof a task,\ndepending on instruction. The versatility in types of processing\n(phonological and semantic) of high WMC people represents a\nfeature that was lacking in the old model. For example, in the\nSörqvist and Rönnberg (2012) study WMC contributed to inhibi-\ntion of a competing talker while focusing on the semantic content\nof the target talker. A consequence of this is enhanced, or deeper,\nunderstanding (Craik and Tulving, 1975). The by-product is more\ndurable episodic memory traces ( Classon et al., 2013a ). In a recent\nERP study\nClasson et al. (2013b) showed that hearing impaired,\nbut not normal hearing individuals, demonstrate an ampliﬁed\nN2-like response in non-rhyming, orthographically mismatch-\ning conditions. This ERP signature of hearing impairment is\nsuggested to involve increased reliance on explicit compensatory\nmechanisms such as articulatory recoding and grapheme-to-\nphoneme conversion and may prove to tap into some phonologi-\ncal WM function.\nA ﬁfth important extension encompasses the negative relation-\nships between hearing loss and episodic and semantic L TM.T h e s e\noccur despite the use of hearing aids. However, STM is relatively\nunaffected, presumably because the demand to resolve speech\nunderstanding under mismatching, adverse conditions keeps this\nmemory system in a more active state. Therefore, the overall selec-\ntive effects on different memory systems are couched in terms\nof use/disuse ( Rönnberg et al., 2011a,b ). It should be noted that\nalthough the ELU prediction is in terms of relative effects of\nuse/disuse, it does not exclude the possibility that either STM or\nWM may be affected by hearing impairment (cf. Van Boxtel et al.,\n2000; Cervera et al., 2009 ); it only predicts a relatively larger LTM\nimpairment.\nAs i x t hg e n e r a lf a c tt on o t ei st h emodality-generality of mem-\nory systems in relation to language understanding. Reading span\nobviously taps modality-general verbal WMC as it predicts vari-\nance in the speech-in-noise tasks ( Akeroyd, 2008 ;c f . Daneman\nand Carpenter, 1980; Just and Carpenter, 1992 ). Generality is\nalso a key feature of the modulation of auditory attention (ABR)\nby manipulating visual-verbal WM load ( Sörqvist et al., 2012a ).\nFinally, a striking ﬁnding in the ( Rönnberg et al., 2011a,b )s t u d y\nis that the negative memory consequences that may be attributed\nto hearing loss also show an independence of encoding format,\nand is not uniquely related to auditory encoding: At the level\nof simple correlations, hearing loss showed the highest nega-\ntive correlation to free recall performance on tasks which not\nonly involved auditory encoding but also encoding of motor and\ntextual representations—and the effects were still manifest after\nstatistically correcting for age.\nSeventhly, and ﬁnally, the effect of WMC on stimulus process-\ning is pervasive in terms of the time window: from early brain stem\nresponses to encoding into episodic LTM. Thus, the above gen-\neralizations have set the stage for a more analytical and general\nformulation of the ELU model.\nTHEORETICAL CONSEQUENCES\nThe new extensions result in a better speciﬁed ELU model that\npresents WM as the arena for interpretating the meaning of an\nongoing dialogue. An individual with high WMC is more capable\nof using different levels/kinds of information and implicit/explicit\nstrategies for extracting meaning from a message. The storage\nand processing operations that are performed by a high-capacity\nsystem are modality-general and ﬂexible during multi-tasking.\nImplicit and explicit processes are assumed to run in parallel and\ninteractively, but under different time windows (cf. Poeppel et al.,\n2008).\nThe successful listener disambiguates the signals on-line over\ntime, due to successive semantic and lexical retrieval attempts,\ncombined with contextual and dialogical constraints to narrow\ndown the set of lexical candidates cued in the speech stream.\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 9\nRönnberg et al. ELU: theory, data, and clinical implications\nB e c a u s eo ft i m ec o n s t r a i n t si nd i a l o g u e s ,t h el i s t e n e rm a yo f t e n\nsettle for the gist without resolving all of the details of the signal-\nmeaning mapping. It may even be the case that the context is so\nstrongly predictive that very little if any information delivered by\nRAMBPHO is needed for successful recognition to occur ( Moradi\net al., 2013 ).\nWe now further assume that the information delivered by\nRAMBPHO is relayed by a fast-forward, matching mechanism\nthat is nested under a slow, explicit feedback loop (cf. Poeppel\net al., 2008; Stenfelt and Rönnberg, 2009 ). The mismatch in itself\nis determined either by poor RAMBPHO information and/or\npoor phonological representations in semantic LTM. We concep-\ntualize the phonological representations in LTM in terms of mul-\ntiple attributes. A minimum number of attributes are required for\naccess to a certain lexical item. Above a certain threshold there is\na sufﬁcient number of attributes to trigger the lexical representa-\ntion. Below threshold, we can expect a number of qualitatively\ndifferent outcomes: (a) if the number of attributes is close to\nthreshold, then some phonological neighbors may be retrieved\n(Luce and Pisoni, 1998 ); (b) if too few attributes match the\nintended target item, the matching process could be led astray by\ncontextual constraints induced by “mismatching” semantic cues\n(Zekveld et al., 2011a ); and (c), if no phonological attributes are\npresent at the RAMBPHO level, it could still be the case that a\nsentence context is so predictive that an upcoming target word is\nvery likely to be activated anyhow ( Moradi et al., 2013 ).\nThe matching process is ultimately determined by the ﬁdelity\nof the input and phonological representation. Fidelity is affected\nby external noise but also by internal noise (e.g., by poor phono-\nlogical representations due to long-term hearing impairment;\nClasson et al., 2013a,b ). These phonological attributes are primar-\nily constrained at a syllabic level of representation. RAMBPHO\ninformation is based on rapid phonological extraction from the\nsignal by means of a mix of visual, sound-based and motoric pre-\ndictions (cf. Hickok, 2012). We still propose that the bottleneck of\nthe system is the connection between RAMBPHO delivered infor-\nmation and the phonological-lexical representation. However, we\nnow also assume that the phonological attributes are embedded\nwithin domains of semantically related attributes; i.e., relations\nbetween the two types of attributes are assumed to be stored\nand represented together (cf. Hickok, 2012). Thus, these synergis-\ntic representations allow lexical access both via RAMBPHO and\nsemantic cueing ( Zekveld et al., 2011a, 2012 ), and give ground\nfor a conceptualization of a versatile, multi-code capacity usage\nof high WMC participants. Furthermore, in the new ELU model,\nthe implicit as well as the explicit processing mechanisms rely on\nphonological and semantic interactions. Semantic LTM can be\nused either for explicit “repair” of a distorted signal, for inference-\nmaking, or for implicit and rapid semantic priming. Mismatch\nwill determine how time is shared between the explicit and\nimplicit operations: the fast (implicit) RAMBPHO mechanism is\nalways running until it is temporarily interrupted. When inter-\nrupted, the default situation is that it re-starts the analysis of the\nspeech signal with whatever information is available (phonolog-\nical/semantic). At the same time, mismatch will tune the system\nto use the explicit slow loop to repair violated expectations, again\nvia semantic and phonological cues.\nUnder time pressure, and given that the listener is happy to\nsettle for the gist of the message (see Pichora-Fuller et al., 1998 ),\nlow-level RAMBPHO processing may be overruled by explicit\nfunctions. RAMBPHO is in principle “blind” to the overall mean-\ning of a message, in the sense that its sole function is to “unlock”\nthe lexicon. But it is conceivable that it can be modiﬁed in terms\nof attention to certain attributes depending on semantic knowl-\nedge about speaker identity and topic ( Mesgarani and Chang,\n2012). The crucial aspect is therefore not the speciﬁc kind of\nsignal processing that temporarily interrupts RAMBPHO, but\nthe modality-general explicit capacity to use and combine the\navailable perceptual evidence and quality of the LTM knowledge.\nThis takes place via different WMC-dependent executive mech-\nanisms such as inhibition, focusing of attention, and retrieval of\ncontextual and semantic information. The sooner the brain can\nconstruct an interpretation of the message, the easier language\nprocessing becomes, and the content of a dialogue is more rapidly\ncommitted to more permanent memory encodings.\nIn short, the new ELU model is a WMC-based model of\na meaning prediction system (cf. Samuelsson and Rönnberg,\n1993; Federmeier, 2007; Hickok, 2012 ). Speciﬁcally, the settings\nof the system are regulated either explicitly (by some seman-\ntic/contextual instruction or explicit feedback) or by the neural\nconsequences of high WMC (in terms of, e.g., brain oscilla-\ntions). Attention manipulations—seen as one way of pre-tuning\nthe system—have recently proven to have cortical consequences\nin speech in noise tasks ( Mesgarani and Chang, 2012; Wild et al.,\n2012).\nIn Figure 2, we illustrate how explicit/implicit processes inter-\nact over time. Each explicit “loop” is activated by a mismatch.\nThe number of times the listener passes through an explicit loop\ndepends generally on for example turn taking, competing speech,\nattention manipulations, or to distortions from signal processing\nin the hearing aid.\nNEW ELU PREDICTIONS\nWe outline some new predictions that follow from the revised and\nupdated ELU model.\n(1) Signal distortion will tax WMC during speech understand-\ning. This applies to different kinds of signal compression\nalgorithms used in hearing aids, and to other kinds of dis-\ntortion (cf. Foo et al., 2007; Arehart et al., 2013 ). Even at\nfavorable SNRs, WMC modulates the effect of signal process-\ning on short-term retention of spoken materials ( Ng et al.,\n2013a). Still, effects relating to intended distortion of the\ntarget signal per se and the unwanted artifacts of signal pro-\ncessing (e.g., “musical noise” during binary masking) need to\nbe teased apart.\n(2) WMC is predicted to modulate early attention mechanisms\n(Sörqvist et al., 2012a ;c f . Kraus and Chandrasakaren, 2010;\nKraus et al., 2012 ) and semantic framing (priming).\n(3) Classon et al. (2013a,b) demonstrated that WMC can com-\npensate for phonological deﬁcits. It also modulates the\nuse of semantic cues during speech-in-noise understand-\ning ( Zekveld et al., 2012 ). It addition, it predicts facilita-\ntion of encoding operations (and subsequent episodic LTM)\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 10\nRönnberg et al. ELU: theory, data, and clinical implications\nFIGURE 2 | The new Ease of Language Understanding (ELU) model.In\nideal listening conditions, multimodal RAMBPHO input matches a sufﬁcient\nnumber of phonological attributes (i.e., above threshold) in the mental\nlexicon and lexical access proceeds rapidly and automatically. RAMBPHO\nmay be preset by expectations—modulated by WM—concerning the\nphonological characteristics of the communicative signal, e.g., the language\nor regional accent of the communicative partner or by semantic or\ncontextual constraints. When there is a mismatch (as in suboptimal\nlistening conditions), WM “kicks in” to support listening ( Rönnberg et al.,\n2010). The explicit, WMC-dependent, processing loop uses both\nphonological and semantic LTM information to attempt to ﬁll in or infer\nmissing information, which also feeds back to RAMBPHO. The output of\nthe system is some level of understanding or gist, which in turn induces a\nsemantic framing of the next explicit loop. Another output from the\nsystem is episodic LTM, where information encoded into LTM is\ndependent on the type of processing carried out in WM. Explicit and\nimplicit processes run in parallel, the implicit being rapid, the explicit is a\nrelatively slow feedback loop.\nin conditions of speech-in-speech maskers ( Sörqvist and\nRönnberg, 2012 ). In short, participants with high WMC are\npredicted to better adapt to different task demands than par-\nticipants with low WMC, and hence are more versatile in\ntheir use of semantic and phonological coding and re-coding\nafter mismatch.\n(4) STM, and by inference, WM, is predicted to be more robust\nthan LTM systems in response to impairment-related decline\n(Rönnberg et al., 2011a,b ). This prediction should be further\ntested with different tasks assessing different memory systems\nbefore deﬁnite conclusions can be made.\n(5) WMC is related to effort ( Koelewijn et al., 2012a,b ), espe-\ncially to intermediate levels of effort ( Rudner et al., 2012 ).\nFurther work is needed to uncover underlying mechanisms.\n(6) Predictions for sign language understanding should focus\non visual noise manipulations and on semantic maskers to\nassess the role of WMC in understanding sign language\nunder challenging conditions ( Rönnberg et al., 2004; Rudner\net al., 2007; Cardin et al., 2013 ). By testing whether WMC is\nalso invoked in conditions with visual noise, the analogous\nmechanism to mismatch in the spoken modality could be\nevaluated.\nRELATION TO OTHER MODELS\nThe new ELU model differs from models of speech percep-\ntion (e.g., the TRACE model, McClelland and Elman, 1986 ;t h e\nCohort model, Marslen-Wilson, 1987;a n dt h eN A Mm o d e l ,Luce\nand Pisoni, 1998 ) and also from the original notion of mis-\nmatch negativity ( Näätänen and Escera, 2000 ) in its assumption\nthat explicit WMC is called for whenever there is mismatch\nbetween language input and LTM representations. In this way, the\nmismatch mechanism—and the demand on WMC—is related\nto communication. Nevertheless, the ELU model is similar to\nthe earlier speech perception models in that all acknowledge the\nimportance of an interaction with LTM representations and that\nlexical access proceeds via some kind of model-speciﬁc retrieval\nmode. The ELU model especially focuses on how the perceptual\nsystems interact with different memory systems. The cognitive\nhearing science aspect and the historical context of the ELU model\nhas recently been reviewed elsewhere ( Pichora-Fuller and Singh,\n2006; Arlinger et al., 2009 ).\nRAMBPHO focuses on the integration of phonological infor-\nmation from different sources and thus shares similarities with\nthe episodic buffer introduced by Baddeley (2000) .H o w e v e r ,\nunlike Baddeley’s model, the ELU model is geared toward the\ncommunicative outcome, i.e., language understanding, rather\nthan WMC as such ( Rudner and Rönnberg, 2008a,b ). The fact\nthat the need for explicit resources such as WMC is restricted to\nmismatch situations also represents a unique processing economy\naspect of the ELU model.\nThe ELU model is inspired by the notions and models of WM\nfor read text presented by Daneman and Carpenter (1980) and\nJust and Carpenter (1992) in that it emphasizes both storage and\nprocessing components of WM. This is why we originally adopted\nthe reading span task as a potentially important predictor variable\nof speech-in-noise performance, without introducing audibility\nproblems. The trade-off between storage and processing is par-\nticularly relevant for the ELU model in that hearing impairment\ntypically puts extra pressure on the processing and inference-\nmaking that is needed to comprehend a sentence. Less storage\nand less encoding into episodic LTM are expected for partici-\npants with hearing impairment compared to participants without\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 11\nRönnberg et al. ELU: theory, data, and clinical implications\nhearing impairment unless they have a high WMC. Of particu-\nlar relevance is the fact that Just and Carpenter (1992) showed\nthat WMC constrains sentence comprehension during reading\nsuch that individuals with high WMC are better than individuals\nwith low WMC at coping with more complex syntactic structures\n(e.g., object-relative clauses), maintaining ambiguous representa-\ntions of sentences, and resolving anaphora. Dealing with semantic\nor syntactic complexity is presumably very important for partic-\nipants who are “mismatching” frequently during conversation.\nHere, the attention, inference-making, inhibition and storage\nabilities of individuals with high WMC play a crucial role.\nThe ELU has some interesting similarities with the speech\nperception model by Poeppel et al. (2008) in that both models\nassume parallel processes (streams) that operate within differ-\nent time-windows (cf. Hickok and Poeppel, 2004, 2007 ). For\nELU the ﬁrst time window is when phonological representations\nare formed in RAMBPHO to match representations in semantic\nLTM; the second is the slower explicit loop function. RAMPBHO\nseems to be a concept very similar to the phonological primal\nsketch suggested by Poeppel et al., where syllables mediate lex-\nical access. Also, audiovisual integration seems to occur around\n250 ms, where visual information typically leads and affects the\nintegration ( van Wassenhove et al., 2007 ). We have speculated\nabout the earlier (than syllabic) spectral-segmental kinds of anal-\nyses discussed in the Poeppel et al. (2008) paper (see Stenfelt\nand Rönnberg, 2009 ), primarily in terms of how different types\nof hearing impairment might affect perception of segmental\nfeatures.\nThe explicit, slow processing loop, is postdictive in the sense\nthat mismatch, error-induced, signals may invoke some kind of\nWM-based inference-making. This was the main function for\nre-construction and inference-making in the old ELU model\n(Rönnberg, 2003; Rönnberg et al., 2008 ). However, as we have\nemphasized with the new ELU model, its predictive potential is\nnow clearly spelled out in terms of the re-settings explicit pro-\ncesses may invoke, phonologically and semantically, and also\nbecause of the ﬁne-tuning or synchronization by WM itself\n(Hickok, 2012 ). In keeping with Poeppel et al. (2008) ,t h en e u -\nral basis of syllabic processing is likely to involve STS, lexical\naccess supposedly involves MTG, while our recent study ( Zekveld\net al., 2012 ) is a ﬁrst indication of a frontal (LIFG) WMC-\nbased compensation for the explicit effort involved in decoding\nwords/sentences in noise. Poeppel et al. (2008) advocate an anal-\nysis by synthesis framework whereby initial segments of a spoken\nsignal are matched against a hypothesis, “an internal forward\nmodel.” The internal model is then updated against new seg-\nments of speech approximately at every 30 ms, feeding back to\nseveral levels of representation including the phonological pri-\nmal sketch. One way of conceptualizing the hypothesis-driven,\nanalysis-by-synthesis framework by Poeppel et al. (2008) may in\nfact be understood in terms of WMC. A high WMC helps keep\nseveral hypotheses alive, allowing for top-down feed-back at sev-\neral points in time and at segmental, syllabic, lexical and semantic\nlevels of representation (cf. Figure 4 in Poeppel et al., 2008 ,c f .\nPoeppel and Monahan, 2011 ). The probability of entertaining\nor maintaining a hypothesis in WM may then in part be deter-\nmined by Bayesian logic, “The quantity p(H|E) represents the\nlikelihood of the hypothesis, given the sensory analysis; p(E|H) is\nthe likelihood of the synthesis of the sensory data given the analy-\nsis” (p. 1080, Poeppel et al., 2008 ), where H represents the forward\nhypothesis and E the perceptual evidence. With an ELU perspec-\ntive, this will also be modulated by the WMC to hold several\nhypotheses, at different levels in the cognitive system, in mind.\nIn the general context of dual stream models, addressing\nthe interaction between ventral and dorsal attention networks,\nAsplund et al. (2010) found that so called surprise blindness, i.e.,\nwhere a profound deﬁcit in the detection of a goal-relevant target\n(a letter) as a result of the presentation of an unexpected and task-\nirrelevant stimulus (a face), causes activity in the inferior frontal\njunction. This manipulation represents an interaction between\nstimulus-driven and goal-directed, hypothesis-driven attention\nand may be compared to the cueing manipulations by Zekveld\net al. (2011a, 2012) . Resolutions of ambiguity also involve inter-\nactions between stimulus-driven and knowledge-driven processes\n(Rodd et al., 2012 ), which demand the integrative functions of\nLIFG. These examples may in fact be related to the new predic-\ntive and postdictive (feedback) interactions postulated in the new\nELU model.\nAs discussed by Arnal and Giraud (2012) ,i m p l i c i tt e m p o -\nral predictions of spoken stimuli represent one mechanism that\nmay be modulated by slow delta-theta oscillations, whereas in\nthe case of top-down, hypothesis-driven transmission of content\nspeciﬁc information, beta oscillations may index a complemen-\ntary mechanism in speech comprehension. Similar kinds of dual\nmechanisms have been proposed by Golumbic et al. (2012)\nwhen tracking selective attention to a target voice while ignoring\nanother voice in a cocktail party situation. Low frequency activ-\nity typically corresponds to the speech envelope at lower auditory\ncortex levels, whereas high gamma power activity is reﬂected in\nthe entrainment to the attended target voice only at later stages of\nprocessing, which also were cortically spread out to, e.g., inferior\nfrontal cortex and anterior temporal cortex. This general result\nconnects nicely with the Zekveld et al. (2012) data of WMC based\ncompensation localized in LIFG and MTG.\nFinally, Andersson and colleagues demonstrated in a recent\nstudy ( Anderson et al., 2013a ), using structural equation\nmodeling, that auditory WM, in combination with central audi-\ntory functions such as brain stem responses (e.g., pitch encoding),\ncontributes to understanding speech in noise. Peripheral auditory\nmeasures did not account for any variance but musical experi-\nence reinforced the effect of auditory WM. This is in line with\nour research ascribing a central role to WM for speech under-\nstanding under adverse conditions. Interestingly, Anderson et al.\n(2013b) have also been able to show that brain stem responses\nto complex sounds, rather than hearing thresholds, predict self-\nreported speech-in-noise performance. These data agree with the\nSörqvist et al. (2012a,b) data on the relationship between brain\nstem responses and WMC. Since WM is by deﬁnition an explicit\nprocessing and storage system, the data also ﬁt with the fact that\nself-report—which taps into explicit awareness of speech process-\ning (cf. Ng et al., 2013b )—has the capacity to reﬂect brain stem\nresponses.\nIn sum: although the ELU model shares underlying notions\nwith other speech perception and WM models, its uniqueness\nlies in the connection between mismatch and WMC (explic-\nitly and postdictively), and implicitly and predictively, between\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 12\nRönnberg et al. ELU: theory, data, and clinical implications\nWM and RAMBPHO, and the roles played by the interaction\nbetween WM and other memory systems such as episodic and\nsemantic LTM.\nLIMITATIONS\nOne limitation of the new ELU model concerns the more exact\ndeﬁnition of when a mismatch condition is at hand. We have seen\na picture of results that suggests that many kinds of signal pro-\ncessing actually demand a higher dependence of WMC, at least\ninitially, before some learning or acclimatization has occurred\n(cf. the ﬁrst prediction). This of course also holds true for the\ncase when a person has acclimatized to a certain kind of signal\nprocessing, and then is tested with another, thus breaking, the\nhabitual phonological coding schemes. However, a critique that\nc a nb el a u n c h e di st h a tw eap r i o r im a yh a v ep r o b l e m sd e t e r -\nmining the exact parameters for the mismatch induction. The\nproblem of circularity is apparent. More empirical investigations\ninto, e.g., determining whether it is the kind of signal processing\nor the artifacts caused by signal processing that determine mis-\nmatch and WM dependence will help clarify this issue. Another\nproblem relates to the (so far) relatively few studies involving the\nneural correlates of WMC and speech understanding in noise.\nFuture studies will also have to address the neural consequences of\nhigh vs. low WMC and how it modulates predictions at different\nlinguistic levels (syllabic, lexical, semantic, and syntactic).\nCLINICAL IMPLICATIONS\nGiven that WMC is crucially important for on-line processing of\nspeech under adverse conditions as well as the ability to maintain\nits content for shorter or longer periods, then hearing aid man-\nufacturers, speech-language pathologists and hearing health care\nprofessionals must take that into account. First, clinically relevant\nWMC tests need to be developed; tests that tap into the processes\nthat have proven to be modality-general and optimal for both on-\nline processing of speech as well as for episodic LTM. This means\nnormative data needs to be collected to determine age-dependent\nand impairment-speciﬁc performance levels and provide a clin-\nical instrument for assessing WMC. By using visual-verbal tests\naudibility problems are avoided, thus disentangling potential per-\nceptual degradation effects from WM performance. However, it\nis important to collect norms for different age-groups and lev-\nels of hearing impairment in combination, because there is also\nthe possibility of more central, or cognitive side-effects of age and\nimpairment.\nSecond, individuals with low WMC seem to be initially\nsusceptible to signal processing distortions from “aggressive”\nsignal processing (fast amplitude compression, severe frequency\ncompression, binary masking), although this susceptibility may\ndecline after a period of familiarization ( Rudner et al., 2011 ). For\nall individuals, concrete options are at hand for manipulations of\nthe signal in the hearing aid: to increase ampliﬁcation, alter input\ndynamics, to remove some information ( = noise reduction) to\nget a beneﬁt. But these manipulations come at a cost that is dif-\nferent for different individuals. Thus, we advocate that the “dose\nof the medicine” (=the active ingredient), the intended beneﬁt of\nsignal processing and its side-effects (by-product of the medicine)\nmust be tailored to the individual, such that the high WMC can\nhave a more active ingredient ( = more aggressive signal process-\ning, compared to the low WMC who may be more susceptible to\nside-effects). This reasoning could in principle also be applied to\nacoustic design of other technologies.\nThird, the data we have presented suggest that many kinds of\nmore advanced signal processing in hearing instruments demand\nWMC. The down-side of using advanced signal processing on a\ndaily basis is that it demands effort and for any given individual\nwith hearing loss, this may outweigh the beneﬁt. Therefore, there\nis a need to develop new methods that assess effortful brain-work\nwith more precision. Here, reaction time measures, pupil dila-\ntion indices or measures of evoked response potentials may prove\nto be useful signals for on-line adjustment of signal processing\nparameters in hearing instruments.\nFourth, with a new cognitive hearing science perspective, it\nwould be equally important to evaluate memory and compre-\nhension of the contents of a conversation in noise, as functional\noutcome measures, rather than only focusing on word recog-\nnition accuracy per se ( Pichora-Fuller, 2007; Rönnberg et al.,\n2011a). This can actually be seen as an indirect measure of cogni-\ntive spare capacity, or the residual cognitive capacity that remains\nonce successful listening has taken place ( Pichora-Fuller, 2007,\n2013; Mishra et al., 2013 ).\nFifth, it is quite possible that to properly evaluate the effects\nof hearing aids and other interventions, a longitudinal study\nthat also systematically manipulated the kind of signal processing\nwould be quite informative. We know very little about the long-\nterm effects of signal processing on cognition and how this may\nrelate to or reduce the risk of dementia ( Lin et al., 2011, 2013 ).\nFinally, an intervention study that evaluated the effects of WM\ntraining on speech in noise understanding would put the causal\nnature of WMC to the test (cf. McNab et al., 2009 ). Additionally,\nif one could study the neural correlates of this putative plastic\nchange that would shed further light on the neural mechanisms\ninvolved.\nREFERENCES\nAkeroyd, M. A. (2008). Are individ-\nual differences in speech reception\nthreshold related to individual dif-\nferences in cognitive ability. A sur-\nvey of twenty experimental studies\nwith normal and hearing-impaired\nadults. Int. J. Audiol. 47(Suppl. 2),\nS53–S71.\nAmichetti, N. M., Stanley, R. S., White,\nA. G., and Wingﬁeld, A. (2013).\nMonitoring the capacity of working\nmemory: executive control and lis-\ntening effort. Mem. Cognit. doi\n10.3758/s13421-013-0302-0. [Epub\nahead of print].\nAnderson, S., White-Schwoch, T.,\nParbery-Clark, A., and Kraus, N.\n(2013a). A dynamic auditory-\ncognitive system supports\nspeech-in-noise perception in\nolder adults. Hear. Res.300, 18–32.\nAnderson, S., Parbery-Clark, A.,\nWhite-Schwoch, T., and Kraus,\nN. (2013b). Auditory brain stem\nresponses to complex sounds pre-\ndicts self-reported speech-in-noise\nperformance. J. Speech Lang. Hear.\nRes. 56, 31–43.\nAndersson, U. (2002). Deterioration of\nthe phonological processing skills in\nadults with an acquired severe hear-\ning loss. Eur. J. Cogn. Psychol. 14,\n335–352.\nAndersson, U., and Lidestam, B. (2005).\nBottom–up driven speechreading in\na speechreading expert: The case of\nAA (JK023). Ear Hear.26, 214–224.\nAndersson, U., and Lyxell, B. (1998).\nPhonological deterioration in\nadults with an acquired severe\nhearing impairment. Scand. Audiol.\n27(Suppl. 49), 93–100.\nAndersson, U., Lyxell, B., Rönnberg, J.,\nand Spens, K.-E. (2001a). Cognitive\npredictors of visual speech under-\nstanding. J. Deaf Stud. Deaf Educ.6,\n103–115.\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 13\nRönnberg et al. ELU: theory, data, and clinical implications\nAndersson, U., Lyxell, B., Rönnberg,\nJ., and Spens, K.-E. (2001b). A\nfollow-up study on the effects of\nspeech tracking training on visual\nspeechreading of sentences and\nwords: cognitive prerequisites and\nchronological age. J. Deaf Stud. Deaf\nEduc. 6, 116–129.\nArehart, K., Souza, P ., Baca, R., and\nKates, J. M. (2013). Working mem-\nory and hearing loss: susceptibility\nto hearing distortion. Ear Hear. 34,\n251–260.\nArlinger, S., Lunner, T., Lyxell, B.,\nand Pichora-Fuller, K. (2009). The\nemergence of cognitive hearing sci-\nence. Scand. J. Psychol.50, 371–384.\nArnal, L. H., and Giraud, A.-L. (2012).\nCortical oscillations and sensory\npredictions. Trends Cogn. Sci. 16,\n390–398. doi: 10.1016/j.tics.2012.\n05.003\nAsplund, C. L., Todd, J. J., Snyder, A.\nP ., and Marois, R. (2010). A central\nrole for the lateral prefrontal cor-\ntex in goal-directed and stimulus-\ndriven attention. Nat. Neurosci. 13,\n507–512. doi: 10.1038/nn.2509\nBabiloni, G., Binetti, E., Cassetta, G.,\nDal Forno, C., Del Percio, F., Ferreri,\nR., K et al. (2006). Sources of corti-\ncal rhythms change as a function of\ncognitive impairment in pathologi-\ncal aging: a multicenter study. Clin.\nNeurophysiol. 117, 252–268.\nBaddeley, A. D. (2000). The episodic\nbuffer: a new component of work-\ning memory. Trends Cogn. Sci. 4,\n417–423.\nBaddeley, A. D. (2012). Working mem-\nory: theories, models, and contro-\nversies. Annu. Rev. Psychol.63, 1–29.\nBendixen, A., Schröger, E., and Winkler,\nI. (2009). I heard that coming: ERP\nevidence for stimulus driven pre-\ndiction in the auditory system .J .\nNeurosci. 29, 8447–8451.\nBernstein, L. E., Tucker, P . E., and Auer,\nE. T. (1998). Potential perceptual\nbases for successful use of a vibro-\ntactile speech perception aid. Scand.\nJ. Psychol.39, 181–186.\nBraver, T. S., Cohen, J. D., Nystrom,\nL. E., Jonides, J., Smith, E. E., and\nNoll, D. C. (1997). A parametric\nstudy of prefrontal cortex involve-\nment in human working memory.\nNeuroimage 5, 49–62.\nBronkhorst, A. W. (2000). The cock-\ntail party phenomenon: a review\nof research on speech intelligibil-\nity in multiple-talker conditions.\nACUSTICA 86, 117–128.\nCampbell, R. (2008). The processing of\naudio-visual speech: empirical and\nneural bases. Philos. Trans. R. Soc.\nLond. B Biol. Sci.363, 1001–1010.\nCardin, V ., Orfanidou, E., Rönnberg,\nJ., Capek, C. M., Rudner, M., and\nWoll, B. (2013). Dissociating cog-\nnitive and sensory neural plasticity\nin human superior temporal cortex.\nNat. Commun.4:1473. doi: 10.1038/\nncomms2463\nCervera, T. C., Soler, M. J., Dasi, C.,\nand Ruiz, J. C. (2009). Speech recog-\nnition and working memory capac-\nity in young-elderly listeners: effects\nof hearing sensitivity. Can. J. Exp.\nPsychol. 63, 216–226.\nClasson, E., Rudner, M., Johansson,\nM., and Rönnberg, J. (2013a). Early\nERP signature of hearing impair-\nment in visual rhyme judgment.\nFront. Psychol. 4:241. doi: 10.3389/\nfpsyg.2013.00241\nClasson, E., Rudner, M., and Rönnberg,\nJ. (2013b). Working memory\ncompensates for hearing related\nphonological processing deﬁcit.\nJ. Commun. Disord.46, 17–29. doi:\n10.1016/j.jcomdis.2012.10.001\nColﬂesh, G. J. H., and Conway, A.\nR. A. (2007). Individual differences\nin working memory capacity and\ndivided attention in dichotic listen-\ning. Psychon. Bull. Rev.14, 699–703.\nC o n w a y ,A .R .A . ,C o w a n ,N . ,a n d\nBunting, M. F. (2001). The cock-\ntail party phenomenon revisited:\nthe importance of WM capacity.\nPsychon. Bull. Rev.8, 331–335.\nCraik, F. I. M., and Tulving, E. (1975).\nDepth of processing and the reten-\ntion of words in episodic memory.\nJ. Exp. Psychol. Gen.104, 268–294.\nDaneman, M., and Carpenter, P . A.\n(1980). Individual differences in\nintegrating information between\nand within sentences. J. Exp.\nPsychol. Learn . Mem. Cognit. 9,\n561–584.\nDaneman, M., and Merikle, P . M.\n(1996). Working memory and\nlanguage comprehension: a meta-\nanalysis. Psychon. Bull. Rev. 3,\n422–433.\nDavis, M. H., and Johnsrude, I. S.\n(2007). Hearing speech sounds: top-\ndown inﬂuences on the interface\nbetween audition and speech per-\nception. Hear. Res.229, 132–147.\nDavis, M. H., Johnsrude, I. S., Hervais-\nAdeman, A., Taylor, K., and\nMcGettigan, C. (2005). Lexical\ninformation drives perceptual\nlearning of distorted speech: evi-\ndence from the comprehension of\nnoise-vocoded sentences. J. Exp.\nPsychol. Gen.13, 222–241.\nDavis, S. W., Dennis, N. A., Daselaar,\nS .M . ,F l e c k ,M .S . ,a n dC a b e z a ,R .\n(2008). Que PASA. The posterior-\nanterior shift in aging. Cereb. Cortex\n18, 1201–1209.\nDesjardins, J. L., and Doherty, K.\nA. (2013). Age-related changes\nin listening effort for various\ntypes of masker noises. Ear Hear.\n34, 261–272. doi: 10.1097/AUD.\n0b013e31826d0ba4\nEngle, R. W. (2002). Working mem-\nory capacity as executive attention.\nC u r r .D i r .P s y c h o l .S c i .11, 19–23.\nFedermeier, K. D. (2007). Thinking\nahead: the role and roots of pre-\ndiction in language comprehension.\nPsychophysiology 44, 491–505.\nFell, J., and Axmacher, N. (2011).\nThe role of phase synchronization\nin memory processes. Nat. Rev.\nNeurosci. 12, 106–118.\nFesten, J. M., and Plomp, R. (1990).\nEffects of ﬂuctuating noise and\ninterfering speech on the speech-\nreception threshold for impaired\nand normal hearing. J. Acoust. Soc.\nAm. 88, 1725–1736.\nFoo, C., Rudner, M., Rönnberg, J., and\nLunner, T. (2007). Recognition of\nspeech in noise with new hearing\ninstrument compression release set-\ntings requires explicit cognitive stor-\nage and processing capacity. J. Am.\nAcad. Audiol.18, 553–566.\nFreunberger, R., Werkle-Bergner, M.,\nGriesmayr, B., Lindenberger, U.,\nand Klimesch, W. (2011). Brain\noscillatory correlates of working\nmemory constraints. Brain Res.\n1375, 93–102. doi : 10.1016/j.\nbrainres.2010.12.048\nFriederici, A. D., and Gierhan, S. M.\n(2013). The language network. Curr.\nOpin. Neurobiol. 23, 250–254. doi:\n10.1016/j.conb.2012.10.002\nGatehouse, S., Naylor, G., Elberling, C.\n(2003). Beneﬁts from hearing aids\nin relation to the between the user\nand the environment. Int. J. Audiol.\n45, 130–152.\nGatehouse, S., Naylor, G., and\nElberling, C. (2006). Linear and\nnonlinear hearing aid ﬁttings–2.\nPatterns of candidature. Int. J.\nAudiol. 45, 153–171.\nGolumbic, E. M. Z., Ding, D., Bickel,\nS., Lakatos, P ., Schevon, C. A.,\nMcKhann, G. M., et al. (2012).\nMechanisms underlying selective\nneuronal tracking of attended\nspeech at a “cocktail party” . Neuron\n77, 980–991. doi: 10.1016/j.neuron.\n2012.12.037\nGrady, C. (2012). The cognitive\nneuroscience of aging. Nat. Rev.\nNeurosci.13, 491–505.\nGunter, T. C., Wagner, S., and\nFriederici, A. D. (2003). Working\nmemory and lexical ambiguity\nresolution as revealed by ERPs: a\ndifﬁcult case for activation theories.\nJ. Cogn. Neurosci.15, 643–657. doi:\n10.1162/jocn.2003.15.5.643\nHällgren, M., Larsby, B., and Arlinger,\nS. (2006). A Swedish version of\nthe hearing in noise test (HINT)\nfor measurement of speech recogni-\ntion. Int. J. Audiol.45, 227–237. doi:\n10.1080/14992020500429583\nHannon, B., and Daneman, M. (2001).\nA new tool for measuring and\nunderstanding individual differ-\nences in the component processes\nof reading comprehension. J. Educ.\nPsychol. 93, 103–128. doi: 10.1037/\n0022-0663.93.1.103\nH e i t z ,R .P . ,S c h r o c k ,J .C . ,P a y n e ,T .\nW., and Engle, R. W. (2008). Effects\nof incentive on working memory\ncapacity: behavioral and pupillo-\nmetric data. Psychophysiology 45,\n119–129.\nHervais-Adelman, A. G., Carlyon, R.\nP ., Johnsrude, I. S., and Davis, M.\nH. (2012). Brain regions recruited\nfor the effortful comprehension\nof noise-vocoded words. Lang.\nCogn. Process. 27, 1145–1166. doi:\n10.1080/01690965.2012.662280\nHickok, G. (2012). The cortical orga-\nnization of speech processing:\nfeedback control and predictive\ncoding the context of a dual-stream\nmodel. J. Commun. Disord . 45,\n393–402. doi: 10.1016/j.jcomdis.\n2012.06.004\nHickok, G., and Poeppel, D. (2004).\nDorsal and ventral streams: a frame-\nwork for understanding aspects of\nthe functional anatomy of language\nCognition 92, 67–99. doi: 10.1016/j.\ncognition.2003.10.011\nHickok, G., and Poeppel, D. (2007).\nThe cortical organization of speech\nprocessing. Nat. Rev. Neurosci. 8,\n393–402. doi: 10.1038/nrn2113\nHumes, L. E. (2007). The contributions\nof audibility and cognitive factors\nto the beneﬁt provided by ampliﬁed\nspeech to older adults. J. Am. Acad.\nAudiol. 18, 590–603. doi: 10.3766/\njaaa.18.7.6\nHumes, L. E., Lee, J. H., and Coughlin,\nM. P . (2006). Auditory measures of\nselective and divided attention in\nyoung and older adults using single-\ntalker competition. J. Acoust. Soc.\nAm. 120, 2926–2937.\nHygge, S., Rönnberg, J., Larsby, B.,\nand Arlinger, S. (1992). Normal and\nhearing-impaired subjects’ ability to\njust follow conversation in com-\npeting speech, reversed speech, and\nnoise backgrounds. J. Speech Hear.\nRes. 35, 208–215.\nIbertsson, T., Hansson, K., Mäki\nTorkko, E., Willstedt Svensson,\nU., and Sahlén, B. (2009). Deaf\nteenagers with cochlear implants\nin conversation with hearing\npeers. Int. J. Lang. Commun.\nDisord. 44, 319–337 . doi: 10.1080/\n13682820802052067\nJust, M. A., and Carpenter, P . A.\n(1992). A capacity theory of\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 14\nRönnberg et al. ELU: theory, data, and clinical implications\ncomprehension—individual differ-\nences in working memory. Psychol.\nRev. 99, 122–149. doi: 10.1037/\n0033-295X.99.1.122\nKane, M. J., Bleckley, M. K., Conway,\nA. R., Engle, R. W. (2001). A\ncontrolled-attention view of\nworking-memory capacity. J. Exp.\nPsychol. Gen. 130, 169–183. doi:\n10.1037/0096-3445.130.2.169\nK a n e ,M .J . ,H a m b r i c k ,D .Z . ,T u h o l s k i ,\nS. W., Wilhelm, O., Payne, T. W.,\nand Engle, R. W. (2004). The gen-\nerality of working memory capacity:\na latent-variable approach to verbal\nand visuospatial memory span and\nreasoning. J. Exp. Psychol. Gen.133,\n189–217.\nKoelewijn, T., Zekveld, A. A., Festen,\nJ. M., and Kramer, S. E. (2012a).\nPupil dilation uncovers extra lis-\ntening effort in the presence of a\nsingle-talker masker. Ear Hear. 32,\n291–300.\nKoelewijn, T., Zekveld, A. A., Festen,\nJ. M., Rönnberg, J., and Kramer,\nS. E. (2012b). Processing load\ninduced by informational masking\nis related to linguistic abilities. Int.\nJ. Otolaryngol. 2012:865731. doi:\n10.1155/2012/865731\nKraus, N., and Chandrasakaren, B.\n(2010). Music training for the\ndevelopment of auditory skills. Nat.\nRev. Neurosci. 11, 599–605. doi:\n10.1038/nrn2882\nKraus, N., Parbery-Clark, A., and Strait,\nD. L. (2012). Cognitive factors\nshape brain networks for auditory\nskills: spotlight on auditory working\nmemory. Ann. N.Y. Acad. Sci.1252,\n100–107.\nLazard, D. S., Lee, H. J., Gaebler, M.,\nKell, C. A., Truy, E., and Giraud, A.\nL. (2010). Phonological processing\nin postlingual deafness and cochlear\nimplant outcome. Neuroimage\n49, 3443–3451. doi: 10.1016/j.\nneuroimage.2009.11.013\nLeybaert, J. (1998). Phonological\nrepresentations in deaf children:\nthe importance of early linguistic\nexperience. S c a n d .J .P s y c h o l .39,\n169–173. doi: 10.1111/1467-9450.\n393074\nLeybaert, J., and Charlier, B. L. (1996).\nVisual speech in the head: the effect\nof cued speech on rhyming, remem-\nbering and spelling. J. Deaf Stud.\nDeaf Educ.1, 234–248. doi: 10.1093/\noxfordjournals.deafed.a014299\nLin, F. R., Metter, E. J., O’Brien, R.\nJ., Resnick, S. M., Zonderman,\nA. B., and Ferrucci, L. (2011).\nHearing loss and incident\ndementia. Arch. Neurol. 68,\n14–20.\nLin, F. R., Yaffe, K., Xia, J., Xue, Q.-L.,\nHarris, T. B., Purchase-Helzner, E.,\net al. (2013). Hearing loss and cog-\nnitive decline in older adults. JAMA\nIntern. Med. 173, 293–299. doi:\n10.1001/jamainternmed.2013.1868\nLindenberger, U., and Ghisletta, P .\n(2009). Cognitive and sensory\ndeclines in old age: gauging the evi-\nd e n c ef o rac o m m o nc a u s e .Psychol.\nAging 24, 1–16. doi: 10.1037/\na0014986\nLuce, P . A., and Pisoni, D. A. (1998).\nRecognizing spoken words: he\nneighborhood activation model.\nEar Hear. 19, 1–36. doi: 10.1097/\n00003446-199802000-00001\nLunner, T. (2003). Cognitive function\nin relation to hearing aid use. Int.\nJ. Audiol. 42, 49–58. doi: 10.3109/\n14992020309074624\nLunner, T., Rudner, M. and Rönnberg,\nJ. (2009). Cognition and hear-\ning aids . Scand. J. Psychol. 50,\n395–403. doi: 10.1111/j.1467-9450.\n2009.00742.x\nLunner, T., and Sundewall Thorén,\nE. (2007). Interactions between\ncognition, compression, and\nlistening conditions: effects on\nspeech-in-noise performance in a\n2-channel hearing aid. J. Am. Acad.\nAudiol. 18, 604–617. doi: 10.3766/\njaaa.18.7.7\nLyxell, B. (1994). Skilled speechreading:\nas i n g l ec a s es t u d y .S c a n d .J .P s y c h o l .\n35, 212–219.\nLyxell, B., Arlinger, S., Andersson,\nJ . ,B r e d b e r g ,G . ,H a r d e r ,H . ,a n d\nRönnberg, J. (1998). Phonological\nrepresentation and speech under-\nstanding with cochlear implants in\ndeafened adults. Scand. J. Psychol.\n39, 175–179. doi: 10.1111/1467-\n9450.393075\nLyxell, B., Arlinger, S., Andersson, J.,\nHarder, H., Näsström, E., Svensson,\nH., et al. (1996). Information-\nprocessing capabilities and cochlear\nimplants: Pre-operative predictors\nfor speech understanding. J. Deaf\nStud. Deaf Educ. 1, 190–201. doi:\n10.1093/oxfordjournals.deafed.\na014294\nLyxell, B., and Rönnberg, J. (1987).\nGuessing and speechreading. Br. J.\nAudiol. 21, 13–20.\nLyxell, B., and Rönnberg, J. (1989).\nInformation-processing skills and\nspeechreading. Br. J. Audiol.\n23, 339–347. doi: 10.3109/\n03005368909076523\nLyxell, B., and Rönnberg, J. (1991).\nWord-discrimination and chrono-\nlogical age related to sentence-\nbased speechreading skill. Br. J.\nAudiol. 25, 3–10. doi: 10.3109/\n03005369109077858\nLyxell, B., and Rönnberg, J. (1992).\nThe relationship between ver-\nbal ability and sentence-based\nspeechreading. Scand. Audiol. 21,\n67–72. doi: 10.3109/010503992090\n45984\nLyxell, B., Rönnberg, J., Andersson,\nJ., and Linderoth, E. (1993).\nVibrotactile support: initial effects\non visual speech perception. Scand.\nAudiol. 22, 179–183. doi: 10.3109/\n01050399309047465\nLyxell, B., Rönnberg, J., and\nSamuelsson, S. (1994). Internal\nspeech functioning and speechread-\ning in deafened and normal hearing\nadults. Scand. Audiol. 23, 179–185.\ndoi: 10.3109/01050399409047505\nMajerus, S., Attout, L., D’Argembeau,\nA., Degueldre, C., Fias, W.,\nMaquet, P ., et al. (2012). Attention\nsupports verbal short-term mem-\nory via competition between\ndorsal and ventral attention\nnetworks. Cereb. Cortex 22,\n1086–1097.\nMarslen-Wilson, W. (1987). Functional\nparallelism in spoken word recog-\nnition. Cognition 25, 71–103. doi:\n10.1016/0010-027790005-9\nM a t t y s ,S .L . ,D a v i s ,M .H . ,a n d\nBradlow, A. R. (2012). Speech\nrecognition in adverse conditions:\nar e v i e w . Lang. Cogn. Process. 27,\n953–978. doi: 10.1080/01690965.\n2012.705006\nM c C l e l l a n d ,J .L . ,a n dE l m a n ,J .L .\n(1986). The TRACE model of\nspeech perception. Cogn. Psychol.\n18, 1–86. doi: 10.1016/0010-\n028590015-0\nMcKellin, W., Shahin, K., Jamieson, J.,\nHodgson, M., and Pichora-Fuller,\nM. K. (2007). Pragmatics of con-\nversation and communication in\nnoisy settings. J. Pragmatics 39,\n2159–2184.\nMcNab, F., Varrone, A., Farde, L.,\nJucaite, A., Bystritsky, P ., Forssberg,\nH., et al. (2009). Changes in corti-\ncal dopamine D1 receptor binding\nassociated with cognitive training.\nScience 323, 800–802. doi: 10.1126/\nscience.1166102\nMesgarani, N., and Chang, E. F. (2012).\nSelective cortical representation of\nattended speaker in multi-talker\nspeech perception. Nature 485,\n233–236. doi: 10.1038/nature11020\nMishra, S., Lunner, T., Stenfelt, S.,\nRönnberg, J., and Rudner, M.\n(2013). Visual information can\nhinder working memory processing\nof speech. J. Speech Lang. Hear. Res.\n56, 1–13. doi: 10.1044/1092-4388\n(2012/12-0033)\nMoradi, S., Lidestam, B., and\nRönnberg, J. (2013). Gated audiovi-\nsual speech identiﬁcation in silence\nversus noise: effects on time and\naccuracy. Front. Lang. Sci. 4:359.\ndoi: 10.3389/fpsyg.2013.00359\nNäätänen, R., and Escera, C. (2000).\nMismatch negativity: clinical\nand other applications. Audiol.\nNeurootol. 5, 105–110. doi: 10.1159/\n000013874\nNg, E. H. N., Rudner, M., Lunner, T.,\nPedersen, M. S., and Rönnberg, J.\n(2013a). Effects of noise and work-\ning memory capacity on memory\nprocessing of speech for hearing aid\nusers. Int. J. Audiol. 52, 433–441.\ndoi: 10.3109/14992027.2013.776181\nN g ,E .H .N . ,R u d n e r ,M . ,L u n n e r ,\nT., and Rönnberg, J. (2013b).\nRelationships between self- report\nand cognitive measures of hearing\naid outcome. Speech. Lang. Hear.\ndoi: 10.1179/2050572813Y.000000\n0013\nNilsson, L.-G., Bäckman, L., Erngrund,\nK., Nyberg, L., Adolfsson, R.,\nBucht, G., et al. (1997). The\nbetula prospective cohort study:\nmemory, health and aging. Aging\nNeuropsychol. Cogn .4, 1–32. doi:\n10.1080/13825589708256633\nN ö s t l ,A . ,M a r s h ,J .E . ,a n dS ö r q v i s t ,P .\n(2012). Expectations modulate the\nmagnitude of attentional capture\nby auditory events. PLoS ONE 7:\ne48569. doi: 10.1371/journal.pone.\n0048569\nObleser, J., and Kotz, S. A. (2011).\nMultiple brain signatures of inte-\ngration in the comprehension of\ndegraded speech. Neuroimage 55,\n713–723.\nObleser, J., Wöstmann, M., Hellbernd,\nN., Wilsch, A., and Maess, B.\n(2011). Adverse listening condi-\ntions and memory load drive a\ncommon alpha oscillatory network.\nJ. Neurosci. 32, 12376–12383. doi:\n10.1523/JNEUROSCI.4908-11.2012\nPeelle, J. E., and Davis, M. H. (2012).\nNeural oscillations carry speech\nrhythm through to comprehension.\nFront. Psychol. 3:320. doi: 10.3389/\nfpsyg.2012.00320\nPichora-Fuller, M. K. (1996).\n“Speechreading and working\nmemory,” in Speechreading By\nHumans and Machines: Models,\nSystems and Applications, eds D.\nStork and M. Hennecke (Berlin:\nSpringer-Verlag), 257–274.\nPichora-Fuller, M. K. (2003).\nProcessing speed: psychoacoustics,\nspeech perception, and comprehen-\nsion. Int. J. Audiol.42, S59–S67. doi:\n10.3109/14992020309074625\nPichora-Fuller, M. K. (2006).\nPerceptual effort and apparent\ncognitive decline: implications for\naudiologic rehabilitation. Semin.\nHear. 27, 284–293.\nPichora-Fuller, M. K. (2007). “Audition\nand cognition: what audiologists\nneed to know about listening,”\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 15\nRönnberg et al. ELU: theory, data, and clinical implications\nin Hearing Care for Adults ,e d s\nC. Palmer and R. Seewald (Stäfa:\nPhonak), 71–85.\nPichora-Fuller, M. K. (2013). “Auditory\nand cognitive processing in audi-\nologic rehabilitation,” in Adult\nAudiologic Rehabilitation: Advanced\nPractices, 2nd Edn., eds J. Spitzer\nand J. Montano (San Diego, CA:\nPlural Publishing), 519–536.\nPichora-Fuller, M. K., Johnson, C. E.,\nand Roodenburg, K. E. J. (1998).\nThe discrepancy between hearing\nimpairment and handicap in the\nelderly: balancing transaction\nand interaction in conversa-\ntion. J. Appl. Commun. Res. 26,\n99–119. doi: 10.1080/00909889\n809365494\nPichora-Fuller, M. K., Schneider, B.\nA., and Daneman, M. (1995). How\nyoung and old adults listen to and\nremember speech in noise. J. Acoust.\nSoc. Am.97, 593–608. doi: 10.1121/\n1.412282\nPichora-Fuller, M. K., and Singh, G.\n(2006). Effects of age on audi-\ntory and cognitive processing:\nImplications for hearing aid ﬁtting\nand audiological rehabilitation.\nTrends Amplif. 10, 29–59. doi:\n10.1177/108471380601000103\nPiquado, T., Benichov, J. I., Brownel,\nH., and Wingﬁeld, A. (2012). The\nhidden effect of hearing acuity on\nspeech recall, and compensatory\neffects of self-paced listening. Int. J.\nAudiol. 51, 576–583. doi: 10.3109/\n14992027.2012.684403\nPiquado, T., Isaacowitz, D., and\nWingﬁeld, A. (2010). Pupillometry\nas a measure of cognitive effort\nin younger and older adults.\nPsychophysiology 47, 560–569.\nPoeppel, D., Idsardi, W. J., and van\nWassenhove, V . (2008). Speech per-\nception at the interface of neurobi-\nology and linguistics. Philos. Trans.\nR. Soc. Lond. B Biol. Sci. 363,\n1071–1086.\nPoeppel, D., and Monahan, P . J. (2011).\nFeedforward and feedback in speech\nperception: revisiting analysis by\nsynthesis. Lang. Cogn. Process. 26,\n935–951. doi: 10.1080/01690965.\n2010.493301\nRodd, J. M., Berriman, R., Landau,\nM . ,L e e ,T . ,H o ,C . ,a n dD a v i s ,M .\nH. (2012). Learning new meanings\nfor old words: effects of seman-\ntic relatedness. Mem. Cogn. 40,\n1095–1108. doi: 10.3758/s13421-\n012-0209-0201\nRodd, J. M., Longe, O. A., Randall,\nB., and Tyler, L. K. (2010). The\nfunctional organisation of the\nfronto-temporal language system:\nevidence from syntactic and seman-\ntic ambiguity. Neuropsychologia\n48, 1324–1335. doi: 10.1016/j.\nneuropsychologia.2009.12.035\nR o g e r s ,C .S . ,J a c o b y ,L .L . ,a n d\nSommers, M. S. (2012). Frequent\nfalse hearing by older adults: the\nrole of age differences in metacogni-\ntion. Psychol. Aging 27, 33–45. doi:\n10.1037/a0026231\nRönnberg, J. (1990). Cognitive and\ncommunicative function: the\neffects of chronological age and\n“handicap age” . Eur. J. Cogn.\nPsychol. 2, 253–273. doi: 10.1080/\n09541449008406207\nRönnberg, J. (1993). Cognitive charac-\nteristics of skilled tactiling: the case\nof GS. Eur. J. Cogn. Psychol.5, 19–33.\ndoi: 10.1080/09541449308406512\nRönnberg, J. (1995). “Perceptual com-\npensation in the deaf and blind:\nmyth or reality,” inCompensating for\nPsychological Deﬁcits and Declines:\nManaging Losses and Promoting\ngains,e d sR .A .D i x o na n dL .\nBäckman (Mahwah, NJ: Lawrence\nErlbaum Associates), 251–274.\nRönnberg, J. (2003). Cognition in the\nhearing impaired and deaf as a\nbridge between signal and dialogue:\na framework and a model. Int. J.\nAudiol. 42, S68–S76. doi: 10.3109/\n14992020309074626\nRönnberg, J., Andersson, J., Andersson,\nU., Johansson, K., Lyxell, B.,\nSamuelsson, S. (1998a). Cognition\nas a bridge between signal and\ndialogue: communication in\nthe hearing impaired and deaf.\nScand. Audiol. 27(Suppl. 49),\n101–108.\nRönnberg, J., Andersson, U., Lyxell, B.,\nand Spens, K. (1998b). Vibrotactile\nspeechreading support: cogni-\ntive prerequisites for training.\nJ. Deaf Stud. Deaf Educ. 3,\n143–156.\nRönnberg, J., Andersson, J.,\nSamuelsson, S., Söderfeldt, B.,\nLyxell, B., and Risberg, J. (1999). A\nspeechreading expert: the case of\nMM. J. Speech Lang. Hear. Res.42,\n5–20.\nRönnberg, J., Arlinger, S., Lyxell, B.,\nand Kinnefors, C. (1989). Visual\nevoked potentials: Relation to\nadult speechreading and cognitive\nfunction. J. Speech Hear. Res. 32,\n725–735.\nRönnberg, J., Öhngren, G., and Nilsson,\nL.-G. (1982). Hearing deﬁciency,\nspeechreading and memory func-\ntions. Scand. Audiol. 11, 26l–268.\ndoi: 10.3109/01050398209087477\nRönnberg, J., Öhngren, G., and Nilsson,\nL.-G. (1983). Speechreading per-\nformance evaluated by means of\nTV and real-life presentation: a\ncomparison between a normally\nhearing, moderately impaired\nand profoundly hearing-impaired\ngroup. Scand. Audiol. 12, 71–77.\ndoi: 10.3109/01050398309076227\nRönnberg, J., Rudner, M., Foo, C.,\nand Lunner, T. (2008). Cognition\ncounts: a working memory system\nfor ease of language understand-\ning (ELU). Int. J. Audiol.47(Suppl.\n2), S99–S105. doi: 10.1080/14992\n020802301167\nRönnberg, J., Rudner, M., and Ingvar,\nM. (2004). Neural correlates of\nworking memory for sign language.\nCogn. Brain Res. 20, 165–182. doi:\n10.1016/j.cogbrainres.2004.03.002\nRönnberg, J., Rudner, M., and Lunner,\nT. (2011a). Cognitive hearing sci-\nence: the legacy of Stuart Gatehouse.\nTrends Amplif.15, 140–148.\nRönnberg, J., Danielsson, H., Rudner,\nM., Arlinger, S., Sternäng, O.,\nWahlin, A., et al. (2011b). Hearing\nloss is negatively related to episodic\nand semantic LTM but not to\nshort-term memory. J. Speech Lang.\nHear. Res.54, 705–726.\nRönnberg, J., Rudner, M., Lunner,\nT., Zekveld, A. A. (2010). When\ncognition kicks in: Working mem-\nory and speech understanding\nin noise. Noise Health 12, 49,\n263–269. doi: 10.4103/1463-\n1741.70505\nRudner, M., Andin, J., and Rönnberg,\nJ. (2009a). Working memory, deaf-\nness, and sign language. Scand. J.\nPsychol. 50, 495–505. doi: 10.1111/j.\n1467-9450.2009.00744.x\nRudner, M., Foo, C., Rönnberg, J., and\nLunner, T. (2009b). Cognition and\naided speech recognition in noise:\nspeciﬁc role for cognitive factors fol-\nlowing nine-week experience with\nadjusted compression settings in\nhearing aids. S c a n d .J .P s y c h o l .50,\n405–418. doi: 10.1111/j.1467-9450.\n2009.00745.x\nRudner, M., Davidsson, L., and\nRönnberg, J. (2010). Effects of\nage on the temporal organiza-\ntion of working memory in deaf\nsigners. Aging, Neuropsychol.\nCogn.17, 360–383. doi: 10.1080/\n13825580903311832\nRudner, M., Foo, C., Sundewall Thorén,\nE., Lunner, T., and Rönnberg, J.\n(2008). Phonological mismatch\nand explicit cognitive processing\nin a sample of 102 hearing aid\nusers. Int. J. Audiol. 47(Suppl. 2),\nS163–S170.\nRudner, M., Fransson, P ., Ingvar, M.,\nNyberg, L., and Rönnberg, J. (2007).\nNeural representation of binding\nlexical signs and words in the\nepisodic buffer of working memory.\nNeuropsychologia 45, 2258–2276.\ndoi: 10.1016/j.neuropsychologia.\n2007.02.017\nRudner, M., Hoi Ning, E., Ng\nRönnberg, N., Mishra, S.,\nRönnberg, J., Lunner, T., and\nStenfelt. S. (2011). Cognitive spare\ncapacity as a measure of listening\neffort. J. Hear. Sci.1, 47–49.\nRudner, M., Karlsson, T., Gunnarsson,\nJ., and Rönnberg, J. (2013). Levels of\nprocessing and language modality\nspeciﬁcity in working memory.\nNeuropsychologia 51, 656–666.\ndoi: 10.1016/j.neuropsychologia.\n2012.12.011\nRudner, M., Lunner, T., Behrens,\nT., Sundewall-Thorén, E., and\nRönnberg, J. (2012). Working\nmemory capacity may inﬂuence\nperceived effort during aided speech\nrecognition in noise.\nJ. Am. Acad.\nAudiol. 23, 577–589. doi: 10.3766/\njaaa.23.7.7\nRudner, M., and Rönnberg, J. (2008a).\nExplicit processing demands reveal\nlanguage modality speciﬁc organi-\nzation of working memory. J. Deaf\nStud. Deaf Educ. 13, 466–484. doi:\n10.1093/deafed/enn005\nRudner, M., and Rönnberg, J. (2008b).\nThe role of the episodic buffer in\nworking memory for language pro-\ncessing. Cogn. Process.9, 19–28. doi\n10.1007/s10339-007-0183-x\nSamuelsson, S., and Rönnberg, J.\n(1993). Implicit and explicit use of\nscripted constraints in lipreading.\nEur. J. Cogn. Psychol. 5, 201–233.\ndoi: 10.1080/09541449308520116\nSarampalis, A., Kalluri, S., Edwards,\nB., and Hafter, E. (2009). Objective\nmeasures of listening effort: effects\nof background noise and noise\nreduction. J. Speech, Lang. Hear. Res.\n52, 1230–1240 . doi: 10.1044/1092-\n4388(2009/08-0111)\nSchneider, B. A., Daneman, M., and\nPichora-Fuller, M. K. (2002) .\nListening in aging adults: from\ndiscourse comprehension to psy-\nchoacoustics. Can. J. Exp. Psychol.\n56, 139–152. doi: 10.1037/h0087392\nSchneider, B. A., Pichora-Fuller, M.\nK., and Daneman, M. (2010). “The\neffects of senescent changes in\naudition and cognition on spoken\nlanguage comprehension,” in The\nAging Auditory System: Perceptual\nCharacterization and Neural Bases\nof Presbycusis, eds R. D. Gordon-\nS a l a n t ,A .F r i s i n a ,A .P o p p e r ,a n dD .\nFay (Berlin: Springer Handbook of\nAuditory Research), 167–210.\nScott, S. K., and Johnsrude, I. S.\n(2003). The neuroanatomical and\nfunctional organization of speech\nperception. Trends Neurosci. 26,\n100–107. doi: 10.1016/S0166-\n223600037-1\nScott, S. K., Rosen, S., Beaman, C. P .,\nDavis, J. P ., and Wise, R. J. S. (2009).\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 16\nRönnberg et al. ELU: theory, data, and clinical implications\nThe neural processing of masked\nspeech: evidence for different mech-\nanisms in the left and right tempo-\nral lobes. J. Acoust. Soc. Am. 125,\n1737–1743. doi: 10.1121/1.3050255\nSignoret, C., Johnsrude, I. S., Classon,\nE., and Rudner, M. (2012). “Does\nsemantic context inﬂuence per-\nceptual clarity,” in Neurobiology\nof Language Conference (San\nSebastian), 63.\nSöderfeldt, B., Rönnberg, J., and\nRisberg, J. (1994). Regional cerebral\nblood ﬂow in sign-language users.\nBrain Lang.46, 59–68.\nSörqvist, P ., Ljungberg, J. K., and\nLjung, R. (2010). A sub-process\nview of working memory capac-\nity: evidence from effects of speech\non prose memory. Memory 18,\n310–326.\nSörqvist, P ., Stenfelt, S., and Rönnberg,\nJ. (2012a). Working memory capac-\nity and visual-verbal cognitive load\nmodulate auditory-sensory gating\nin the brainstem: toward a uniﬁed\nview of attention. J. Cogn. Neurosci.\n24, 11, 2147–2154.\nSörqvist, P ., Nöstl, A., and Halin,\nN. (2012b). Working memory\ncapacity modulates habituation\nrate: evidence from a cross-\nmodal auditory distraction\nparadigm. Psychon. Bull. Rev. 19,\n245–259.\nSörqvist, P ., and Rönnberg, J. (2012).\nEpisodic L TM of spoken discourse\nmasked by speech: what is the\nrole for working memory capac-\nity. J. Speech Lang. Hear. Res. 55,\n210–218.\nSperanza, F., Daneman, M., and\nSchneider, B. A. (2000). How aging\naffects the reading of words in noisy\nbackgrounds. Psychol. Aging 15,\n253–258. doi: 10.1037/0882-7974.\n15.2.253\nStenfelt, S., and Rönnberg, J. (2009).\nThe signal-cognition interface:\ninteractions between degraded\nauditory signals and cognitive\nprocesses. Scand. J. Psychol. 50,\n385–393. doi: 10.1111/j.1467-9450.\n2009.00748.x\nTsuchida, Y., Katayama, J., and\nMurohashi, H. (2012). Working\nmemory capacity affects the inter-\nference control of distractors at\nauditory gating. Neurosci. Lett. 516,\n62–66.\nTulving, E. (1983). Elements of Episodic\nMemory. Oxford: Oxford University\nPress.\nTulving, E., and Colotla, V . A. (1970).\nFree recall of trilingual lists. Cogn.\nPsychol. 1, 86–98. doi: 10.1016/\n0010-028590006-X\nT u n ,P .A . ,M c C o y ,S . ,a n dW i n g ﬁ e l d ,A .\n(2009). Aging, hearing acuity, and\nthe attentional costs of effortful lis-\ntening. Psychol. Aging24, 761–766.\nUnsworth, N., and Engle, R. W. (2007).\nOn the division of short-term and\nworking memory: an examination\nof simple and complex span and\ntheir relation to higher order abili-\nties. Psychol. Bull. 133, 1038–1066.\ndoi: 10.1037/0033-2909.133.\n6.1038\nVan Boxtel, M. P . J., van Beijsterveldt,\nC. E. M., Houx, P . J., Anteunis, L. J.\nC . ,M e t s e m a k e r s ,J .F .M . ,a n dJ o l l e s ,\nJ. (2000). Mild hearing impairment\ncan reduce verbal memory perfor-\nmance in a healthy adult popu-\nlation. J .C l i n .E x p .N e u r o p s y c h o l .\n22, 147–154. doi: 10.1076/1380-\n3395(200002)22:1;1-8;FT147\nVan der Meer, E., Beyer, R., Horn, J.,\nFoth, M., Bornemann, B., Ries, J.,\net al. (2010). Resource allocation\nand ﬂuid intelligence: Insights from\npupillometry. Psychophysiology 47,\n158–169. doi: 10.1111/j.1469-8986.\n2009.00884.x\nvan Wassenhove, V ., Grant, K.\nW., and Poeppel, D. (2007).\nTemporal window of integration in\nauditory-visual speech perception.\nNeuropsychologia 45, 598–607. doi:\n10.1016/j.neuropsychologia.2006.\n01.001\nWang, D. L., Kjems, U., Pedersen,\nM .S . ,B o l d t ,J .B . ,a n dL u n n e r ,\nT. (2009). Speech intelligibility\nin background noise with ideal\nbinary time-frequency masking .J .\nAcoust. Soc. Am 125, 2336–2347.\ndoi: 10.1121/1.3083233\nW i l d ,C .J . ,Y u s u f ,A . ,W i l s o n ,D .\nE . ,P e e l l e ,J .E . ,D a v i s ,M .H . ,\nand Johnsrude, I. S. (2012).\nEffortful listening: the process-\ning of degraded speech depends\ncritically on attention. J. Neurosci.\n32, 14010–14021. doi:10.1523/\nJNEUROSCI.1528-12.2012\nZekveld, A. A., Kramer, S. E., and\nFesten, J. M. (2010). Pupil response\nas an indication of effortful\nlistening: the inﬂuence of sen-\ntence intelligibility. Ear Hear. 31,\n480–490. doi: 10.1097/AUD.0b013\ne3181d4f251\nZekveld, A. A., Rudner, M., Johnsrude,\nI. S., Festen, J. M., Van Beek, J. H.\nM., and Rönnberg, J. (2011a). The\ninﬂuence of semantically related\nand unrelated text cues on the intel-\nligibility of sentences in noise. Ear\nHear. 32, e16–e25.\nZekveld, A. A., Kramer, S. E., and\nFesten, J. M. (2011b). Cognitive\nload during speech perception\nin noise: the Inﬂuence of age,\nhearing loss, and cognition on\nthe pupil response. Ear Hear. 32,\n498–510.\nZekveld, A. A., Rudner, M., Johnsrude,\nI. S., Dirk, J., Heslenfeld, D. J., and\nRönnberg, J. (2012). Behavioural\nand fMRI evidence that cognitive\nability modulates the effect of con-\ntext on speech intelligibility. Brain\nLang. 122, 103–113. doi: 10.1016/j.\nbandl.2012.05.006\nConﬂict of Interest Statement: The\nauthors declare that the research\nwas conducted in the absence of any\ncommercial or ﬁnancial relationships\nthat could be construed as a potential\nconﬂict of interest.\nReceived: 12 March 2013; accepted: 24\nJune 2013; published online: 13 July\n2013.\nCitation: Rönnberg J, Lunner T, Zekveld\nA, Sörqvist P , Danielsson H, Lyxell\nB, Dahlström Ö, Signoret C, Stenfelt\nS, Pichora-Fuller MK and Rudner\nM (2013) The Ease of Language\nUnderstanding (ELU) model: theoret-\nical, empirical, and clinical advances.\nFront. Syst. Neurosci.7:31. doi:10.3389/\nfnsys.2013.00031\nCopyright © 2013 Rönnberg, Lunner,\nZekveld, Sörqvist, Danielsson, Lyxell,\nDahlström, Signoret, Stenfelt, Pichora-\nFuller and Rudner. This is an open-\naccess article distributed under the terms\nof the Creative Commons Attribution\nLicense, which permits use, distribution\nand reproduction in other forums, pro-\nvided the original authors and source\nare credited and subject to any copy-\nright notices concerning any third-party\ngraphics etc.\nFrontiers in Systems Neuroscience www.frontiersin.org July 2013 | Volume 7 | Article 31 | 17",
  "topic": "Active listening",
  "concepts": [
    {
      "name": "Active listening",
      "score": 0.7183573246002197
    },
    {
      "name": "Conversation",
      "score": 0.6320666074752808
    },
    {
      "name": "Cognitive psychology",
      "score": 0.5965837240219116
    },
    {
      "name": "Working memory",
      "score": 0.55059415102005
    },
    {
      "name": "Semantic memory",
      "score": 0.5391566753387451
    },
    {
      "name": "Psychology",
      "score": 0.517834484577179
    },
    {
      "name": "Episodic memory",
      "score": 0.5082682967185974
    },
    {
      "name": "Perception",
      "score": 0.4849545955657959
    },
    {
      "name": "Meaning (existential)",
      "score": 0.48078054189682007
    },
    {
      "name": "Computer science",
      "score": 0.4517461955547333
    },
    {
      "name": "Cognition",
      "score": 0.24434912204742432
    },
    {
      "name": "Communication",
      "score": 0.1585574448108673
    },
    {
      "name": "Neuroscience",
      "score": 0.08360815048217773
    },
    {
      "name": "Psychotherapist",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I102134673",
      "name": "Linköping University",
      "country": "SE"
    },
    {
      "id": "https://openalex.org/I4210130492",
      "name": "Oticon Medical (Denmark)",
      "country": "DK"
    },
    {
      "id": "https://openalex.org/I4210124285",
      "name": "Amsterdam Public Health",
      "country": "NL"
    },
    {
      "id": "https://openalex.org/I4210141702",
      "name": "University of Gävle",
      "country": "SE"
    },
    {
      "id": "https://openalex.org/I2799838188",
      "name": "Toronto Rehabilitation Institute",
      "country": "CA"
    },
    {
      "id": "https://openalex.org/I1325899441",
      "name": "University Health Network",
      "country": "CA"
    },
    {
      "id": "https://openalex.org/I185261750",
      "name": "University of Toronto",
      "country": "CA"
    }
  ]
}