{
  "title": "Transforming Driver Education: A Comparative Analysis of LLM-Augmented Training and Conventional Instruction for Autonomous Vehicle Technologies",
  "url": "https://openalex.org/W4396905623",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3011859185",
      "name": "Mohsin Murtaza",
      "affiliations": [
        "RMIT University"
      ]
    },
    {
      "id": "https://openalex.org/A4224206502",
      "name": "Chi-Tsun Cheng",
      "affiliations": [
        "RMIT University"
      ]
    },
    {
      "id": "https://openalex.org/A2250195944",
      "name": "Mohammad Fard",
      "affiliations": [
        "RMIT University"
      ]
    },
    {
      "id": "https://openalex.org/A76571739",
      "name": "John Zeleznikow",
      "affiliations": [
        "La Trobe University"
      ]
    },
    {
      "id": "https://openalex.org/A3011859185",
      "name": "Mohsin Murtaza",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4224206502",
      "name": "Chi-Tsun Cheng",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2250195944",
      "name": "Mohammad Fard",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A76571739",
      "name": "John Zeleznikow",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4382656966",
    "https://openalex.org/W2766702721",
    "https://openalex.org/W2969211102",
    "https://openalex.org/W4324019775",
    "https://openalex.org/W4322492760",
    "https://openalex.org/W3012519286",
    "https://openalex.org/W2966983573",
    "https://openalex.org/W2037517962",
    "https://openalex.org/W4312381072",
    "https://openalex.org/W4313008974",
    "https://openalex.org/W4323338414",
    "https://openalex.org/W4360620450",
    "https://openalex.org/W2973161263",
    "https://openalex.org/W316935178",
    "https://openalex.org/W4362721098",
    "https://openalex.org/W2249595199",
    "https://openalex.org/W4316041216",
    "https://openalex.org/W4214741016",
    "https://openalex.org/W4383472720",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W4381331127",
    "https://openalex.org/W3090622150",
    "https://openalex.org/W2600731273",
    "https://openalex.org/W2068719503",
    "https://openalex.org/W3187613202",
    "https://openalex.org/W2504526017",
    "https://openalex.org/W4379537879",
    "https://openalex.org/W4366495212",
    "https://openalex.org/W4223971808",
    "https://openalex.org/W4387222209",
    "https://openalex.org/W4323979944",
    "https://openalex.org/W2747125209",
    "https://openalex.org/W4210846074",
    "https://openalex.org/W3167631805",
    "https://openalex.org/W2970329503",
    "https://openalex.org/W2100328157",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W2527693370",
    "https://openalex.org/W4366377796",
    "https://openalex.org/W3009335665",
    "https://openalex.org/W4381804284",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4321499901",
    "https://openalex.org/W2102970422",
    "https://openalex.org/W4367849331",
    "https://openalex.org/W4381327944",
    "https://openalex.org/W2999500542",
    "https://openalex.org/W4320186799",
    "https://openalex.org/W3206070692"
  ],
  "abstract": null,
  "full_text": "ARTICLE\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nhttps://doi.org/10.1007/s40593-024-00407-z\nAbstract\nAs modern vehicles continue to integrate increasingly sophisticated Advanced Driv-\ner Assistance Systems (ADAS) and Autonomous Vehicles (A V) functions, conven-\ntional user manuals may no longer be the most effective medium for conveying \nknowledge to drivers. This research analysed conventional, paper and video-based \ninstructional methods versus a Large Language Model (LLM)-based instructional \ntool to educate 86 participants about the operation of specific ADAS and A V func-\ntionalities. The study sampled participants aged between 20 and over 40, with driv -\ning experience ranging from one to over six years. The first group was educated \nusing the conventional methods. In contrast, the second group received instructions \nvia an LLM, i.e., users learn via ChatGPT interaction. Our goal was to assess the \nefficiency and effectiveness of these teaching methodologies based on the reaction \ntimes participants required to activate ADAS functions and the corresponding ac -\ncuracies. Our findings revealed that the group trained via ChatGPT demonstrated \nsignificantly improved learning outcomes compared to conventional training. This \nincluded shorter activation times, higher consistency, and higher accuracy across \nexamined functions. This study further proposed a framework to effectively use \nChatGPT for different training scenarios and education purposes, offering a valu -\nable resource for leveraging Artificial Intelligence (AI) in training users to handle \ncomplex systems. The framework empowers educators to tailor ChatGPT’s interac -\ntions, ensuring efficient, guided learning experiences for learners. For researchers, \nthis study lays the foundation for exploring the role of LLM-based instructional \ntools in a broader range of applications.\nKeywords Advanced driver assistance systems (ADAS) · Artificial intelligence \n(AI) · Autonomous vehicles (A V) · ChatGPT · Driver training · Large language \nmodel (LLM)\nAccepted: 14 April 2024 / Published online: 14 May 2024\n© The Author(s) 2024\nTransforming Driver Education: A Comparative Analysis of \nLLM-Augmented Training and Conventional Instruction for \nAutonomous Vehicle Technologies\nMohsin Murtaza1  · Chi-Tsun Cheng1  · Mohammad Fard1  · \nJohn Zeleznikow2\nExtended author information available on the last page of the article\n1 3\n\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nIntroduction\nThe rise and rapid proliferation of Advanced Driver Assistance Systems (ADAS) and \nAutonomous Vehicles (A V) constitute a significant transformation in the automotive \nindustry, possessing the potential to reshape transportation systems across the globe \ndrastically (Fagnant & Kockelman, 2015; Litman, 2017) and offer various benefits, \nnotably increased safety (Zahabi et al., 2020), enhanced mobility, and a substantial \nreduction in traffic congestion (Fagnant & Kockelman, 2015). Human factors con -\ntribute to more than 90% of accidents, according to Australia’s National Road Safety \nPartnership Program (NRSPP) (Murtaza et al., 2023). The technology-driven shifts \ntriggered by the advancements in ADAS, and A Vs can significantly mitigate human-\nrelated accidents, which remain one of the leading causes of road casualties world -\nwide. The capabilities of A Vs vary based on their level of automation, as categorised \nby the Society of Automotive Engineers (SAE), ranging from no driving automa -\ntion (level 0) to full automation (level 5) (SAE International, 2021). However, the \nintroduction of these sophisticated systems raises a fundamental question: How can \nhuman drivers be effectively trained to safely interact and cooperate with vehicles \nwith ADAS functions or A Vs (Murtaza et al., 2023)?\nThe seamless operation and utilisation of ADAS functions and A Vs largely depend \nupon drivers’ comprehensive understanding and ability to control these advanced \nsystems effectively, which could be obstructed by several barriers. These include the \nlack of standardisation across manufacturers (Murtaza et al., 2022a) and the lack of \nspecific training, practising platforms and opportunities (Murtaza et al., 2023). The \nurgency of addressing these concerns is highlighted by the growing consensus among \nthe research community about the critical role of appropriate training in availing the \nfull potential of A V technology (Zahabi et al., 2020; Zheng et al., 2023).\nThe automotive industry and academia have invested considerable resources into \ntraining to ensure trainees have the competencies to perform their tasks safely and \neffectively (Merriman et al., 2023). Existing training programs primarily focus on \nfostering confidence and imparting necessary skills in individuals, enabling them to \ninteract with advanced systems with high proficiency and safety (Merriman et al., \n2023a; Nandavar et al., 2023). The range of conventional training methods spans \nfrom paper-based, video-based instructions to demonstration-based and trial-and-\nerror techniques.\nThis variance in training methods is evident across sectors. For instance, mod -\nern current vehicle driver training in the automotive industry relies on user manu -\nals, demonstrations at dealerships, videos, information brochures, and trial and error \n(Boelhouwer et al., 2020; Greenwood et al., 2022; Murtaza et al., 2023; Nandavar \net al., 2023; Zahabi et al., 2020), while forklift driving and situational awareness \ncycling also employ video-based instruction (Lehtonen et al., 2017, 2021). In the \naviation industry, pilot training employs simulation-based and video-based methods \n(Nasir & Bargstädt, 2017; Ng, 2022; Salas et al., 1998), while the software devel -\nopment industry utilises both video and paper-based methods (Lloyd & Robertson, \n2012; Van der Meij & Van Der Meij, 2014). Similarly, video and paper-based training \nis used in the medical field to instruct medical procedures and train staff, including \nphysiotherapists (Buch et al., 2014; Ji & Butterworth, 2019). This diversity in training \n1 3\n737\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\napproaches across various industries underscores the importance of tailoring instruc-\ntional methods to specific sector requirements and learning objectives, emphasising \nthe evolving nature of educational techniques in response to technological advance -\nments and industry-specific needs.\nUnderstanding drivers’ interaction with ADAS functions and A Vs is grounded \nin mental models, which represent drivers’ knowledge and comprehension of these \nadvanced in-vehicle systems (Gaspar et al., 2020). These mental models can be \nshaped by different formal and/or informal training methods, such as trial-and-error, \nuser manuals (Lubkowski et al., 2021), dealership demonstrations (Nandavar et al., \n2023), and video-based training (Zahabi et al., 2020). An accurate mental model \nallows drivers to utilise ADAS effectively and safely, while an inaccurate model can \nlead to misuse, over-reliance, and potentially dangerous situations (Nandavar et al., \n2023). Hence, choosing effective training methods is crucial in developing accurate \nmental models, enhancing drivers’ understanding of ADAS functions, and ensuring \nsafer interaction with these systems (Murtaza et al., 2023).\nCurrently, there is a lack of a formal training platform specifically designed for \ndrivers of modern vehicles equipped with ADAS functions. According to (Kay, \n2023), the recent launch of ChatGPT has been a historic breakthrough for the appli -\ncation of Artificial Intelligence (AI) within the realm of education. Several studies \n(Abdelghani et al., 2023; Al Kahf et al., 2023; Aleven et al., 2023; Biswas, 2023; \nColabianchi et al., 2022; Du et al., 2023; Dwivedi et al., 2023; Fauzi et al., 2023; \nFirat, 2023; Nick, 2023; Sallam, 2023; Smutny & Schreiberova, 2020; Susnjak, 2023; \nYuan, 2023; Zhou et al., 2021) have evidenced the potential of Large Language Mod-\nels (LLMs), such as ChatGPT, in enhancing learning outcomes, learner motivation, \nengagement, customised support and output presentation, consistency and scalability \nin training across a wide range of industries including automotive, transportation, \naviation, maritime, medical, education, information system, and construction. How -\never, to our knowledge, no comprehensive study discusses how an LLM-augmented \napproach can be employed as an effective training tool for ADAS functions or A Vs.\nConsequently, this study seeks to investigate this unexplored area by offering a \nsystematic framework for using ChatGPT’s LLM as a training tool for drivers to \nuse ADAS functions and A Vs in the future. By leveraging our LLM-augmented \napproach’s cognitive and dialogic capabilities, we aim to enhance users’ understand-\ning of ADAS, thereby improving their interactions with these systems and ensur -\ning safer and more efficient driving experiences. The efficacy of the ChatGPT-based \ntraining approach was evaluated in an empirical study and compared with conven -\ntional training methods for operating ADAS functions. Participants’ performance, \nas measured by their accuracies and reaction times in interacting with ADAS func -\ntions, served as a primary metric for assessing the effectiveness of different training \nmethods. By investigating the cognitive underpinnings of learning and understanding \nADAS functions, this research attempts to reveal how different training methods can \ninfluence the formation of mental models, thereby impacting the utilisation of ADAS \nfunctions.\nIn this study, we utilised ChatGPT’s capabilities to develop an interactive train -\ning program for teaching drivers how to use ADAS functions and A V capabilities. \nChatGPT was asked to digest the contents of simulated ADAS and A V manuals and \n1 3\n738\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nconvey this information through a conversational, interactive medium that adapts to \nusers’ responses. The training content was developed by inputting manual descrip -\ntions into ChatGPT. This information was transformed into clear, conversational lan-\nguage suitable for learners even with little or no relevant technical backgrounds. \nBy doing so, ChatGPT provided personalised guidance, clarified user queries, and \nverified understanding through targeted follow-up questions. This methodology was \ndesigned to impart knowledge and engage users in a two-way dialogue, fostering a \ndeeper understanding of ADAS functionalities and enhancing the learning experi -\nence. To ensure the consistency and accuracy of the information provided, in the \nexperiment, ChatGPT was restricted to using only the data from the manuals, avoid-\ning any external knowledge sources. The technical implementation of this approach \nutilised the foundation of instructional design and the science of learning to enhance \nthe effectiveness of the ChatGPT-facilitated training.\nThe findings of this study hold implications for both the automotive industry and \neducators, suggesting practical strategies for ADAS training that can be incorporated \ninto driver education programs, dealership demonstrations, and user manuals. As the \nautomotive landscape shifts towards increased automation, it becomes imperative to \nre-evaluate our training methodologies. This study offers a novel perspective by inte-\ngrating LLMs into the training process, providing a promising avenue for enhancing \ndrivers’ comprehension of ADAS functions and ensuring safer road experiences in \nan era of automation.\nThe remainder of this paper is organised as follows: Sect. 2 presents the meth -\nodology, experimental setup, and driving environment. Section 3 describes the \nrecruitment process and the composition of the participants. In the same section, we \nalso discussed the framework for effectively using the ChatGPT prompt for train -\ning purposes. Section 4 compares the two different training methods, conventional \nvs. ChatGPT, by analysing their corresponding participants’ accuracy and response \ntimes when interacting with ADAS functions. Section 5 compares various training \nmethods and the significance of ChatGPT-based training and its applications in other \nindustries. Based on the findings and analyses, recommendations for stakeholders \nand concluding remarks are provided in Sect. 6.\nMethodology\nExperiment Setup\nThe experiment was conducted using a York driving simulator, interfaced with a Log-\nitech G27 racing wheel system comprising pedals and a shifter module. An array of \nADAS functions (detailed in Table 1) were assigned to specific buttons on the steer-\ning wheel and the shifter module to mimic an authentic driving environment.\nThe experimental methodology encompassed manoeuvres of an A V in a three-\ndimensional virtual setting. This vehicle was either autonomous or controlled by the \nparticipant, with ADAS functions in either an activated or deactivated state. The sim-\nulated A V was equipped with an automatic transmission feature, enabling the panel \non the shifter module to be dedicated entirely to the activation and deactivation of \n1 3\n739\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nADAS functions. Consequently, the shifter lever was disabled for the duration of the \nexperiment.\nTo enhance the ecological validity of the experiment, thorough attention to detail \nwas exerted in the design process to emulate a highly authentic and immersive driv -\ning experience. This setup is visually represented in Figs. 1 and 2. Figure 1 identifies \ncomponents “a” to “c” as the steering wheel, pedals, and driving seat, respectively. \nFigure 2 displays components “d” to “h”, signifying distinct aspects of the setup and \ntheir corresponding ADAS functions.\nIn Fig. 2, component “d” illustrates the location of the Lane Keeping Assist (LKA) \nbutton on the shifter module. Component “e” shows the positioning of the Autopilot-\nOn (AP-On) function on the steering wheel. The Adaptive Cruise Control (ACC) \nfunction, represented by component “f”, is positioned on the shifter module. Compo-\nnent “g” indicates the location of the Autopilot-Off (AP-Off) function on the steering \nwheel, and component “h” highlights the Collision Avoidance (CA) function, also \nlocated on the steering wheel. This exhaustive labelling and description provide a \ncomprehensive overview of the experimental setup, contributing to the experiment’s \nreproducibility.\nDriving Scenario and Environment\nThe driving simulator’s interface is shown in Fig. 4, where the red box stands for the \nfront of the vehicle, i.e., the bonnet. The dashboard, which includes a speedometer \nFig. 1 Experiment setup [a: \nsteering wheel, b: pedals, c: \ndriving seat]\n \n1 3\n740\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nand indicators for the ADAS functions, is displayed underneath that. These indicators \nlight up in green to show when the functions are ON, as illustrated in Fig. 4, indicat-\ning, for example, that the LKA function is active. The 3D simulated environment \nincorporates several key features that one can find on a real road, such as different \ntraffic densities, streetlights, road signs, pedestrians, speed zones, buildings, and veg-\netation. These features help participants better understand their environment within \nthe simulation (Kolekar et al., 2020).\nFig. 3 An overview of the simulated driving scenario [red and blue arrows indicate the low-speed and \nhigh-speed zones, respectively]\n \nFig. 2 ADAS functions’ loca-\ntions [d: LKA, e: AP-On, f: \nACC, g: AP-Off, h: CA]\n \n1 3\n741\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nFigure 3 shows a bird’s-eye view of the driving route, with a red circle showing \nwhere the vehicle starts. The route’s low-speed (50 km/h) and high-speed (100 km/h) \nzones are indicated with red and blue arrows, respectively. These zones mimic city \nand highway driving changes, providing participants with different driving expe -\nriences. During each test, participants were told to start from the low-speed zone, \ncross an intersection, enter the high-speed zone, cross the intersection again, and then \nreturn to the low-speed zone. Several triggers (T1 to T5) along the route start differ -\nent events as the vehicle passes, as shown in Fig. 3. Table 1 shows the instructions \nlinked to these triggers. When the vehicle passes a trigger, an audio instruction from \nTable 1 is played, asking the participant to act accordingly. Out of the five actions, \nonly the ACC requires two buttons to be pressed sequentially, and the others can be \nactivated with one button. In this work, we analyse data on the steering angle, the \nutilisation of acceleration and braking, the times when events were triggered, and \ndrivers’ response time to these events. We measured how accurately (as a percentage) \nparticipants used the correct ADAS functions and how long they took to respond (in \nseconds).\nTable 1 Instruction for each trigger\nTrigger no Instruction\nT1 Turn on the auto-pilot function\nT2 Turn off the auto-pilot function\nT3 Turn on the lane-keeping assist function\nT4 Turn on the collision avoidance function\nT5 Turn on the adaptive cruise control function\nFig. 4 A snapshot of the simulator interface [i: Rear mirror view, j: front of the simulated A V , k: Shows \nLKA function is ON, l: right side mirror, m: speedometer, n: left side mirror view, o: A V current \nparameters]\n \n1 3\n742\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nRecruitment of Participants\nThe sample comprised various ages and genders to maintain heterogeneity. The par-\nticipant recruitment was conducted via a hybrid approach, utilising both digital and \nconventional methods. In this study, we recruited a diverse sample of participants, \nincluding RMIT University students, staff, and members of the general public inter -\nested in A V research. To recruit participants, we leveraged the university’s online \nplatform, including webpages, emails, and online forms. This effort was comple -\nmented by paper-based advertisements, i.e., posters and leaflets, distributed through-\nout RMIT University’s Bundoora campus.\nData collection was extended over six months to ensure a sufficiently large and \nrepresentative dataset for subsequent analyses. Our final sample group consisted \nof 86 adult participants aged 20 to above 40 years old, as detailed in Table 2. All \nparticipants had driving experience ranging from novice (one to three years), inter -\nmediate (four to six years), to experienced (over six years), as outlined in Table 3. \nThis division of driving experience categorisation is consistent with established road \nsafety and insurance benchmarks for defining driver expertise (Commonwealth of \nMassachusetts, 2023; Robbins & Chapman, 2019). Additionally, participants were \ncategorised based on their frequency of ADAS function usage, and this information \nis presented in Table 4. In this study, we only collected the above information in \nranges instead of their absolute values due to privacy concerns, which were essential \nfor our ethics approval application. In the experiment, participants were divided into \nTable 2 Participants division w.r.t age group\nTraining type Number of \nparticipants\nAge group(20–\n30 years)\nAge \ngroup(30–40 \nyears)\nAge group\n(Above 40 \nyears)\nConventional learning group 46 20 14 12\nChatGPT-based learning group 40 18 12 10\nTable 3 Participants division w.r.t driving experience\nTraining type Number of \nparticipants\nDriving \nexperience\nNovice driver \n(1–3 years)\nDriving experience\nIntermediate driver \n(4–6 years)\nDriving experience\n(Experienced \ndriver (above 6 \nyears)\nConventional learning \ngroup\n46 14 13 19\nChatGPT-based learning \ngroup\n40 13 11 16\nTable 4 Participant’s division w.r.t ADAS functions frequency of use\nTraining type Number of \nparticipants\nNovice/Occa-\nsional user\nIntermittent \nuser\nReg-\nular \nuser\nConventional learning group 46 15 17 14\nChatGPT-based learning group 40 13 15 12\n1 3\n743\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\ntwo distinct learning groups. They were randomly allocated to each group to enhance \nthe validity of the comparison between training methods. Group 1, the conventional \nlearning group, consisted of 46 participants trained through video presentations and \nuser manuals. Group 2 comprised 40 participants who received training through a \nChatGPT-based learning platform. Both groups had an almost balanced gender dis -\ntribution, with the first group having 26 males and 20 females and the second group \ncomprising 23 males and 17 females. A prerequisite for all participants was to hold a \nvalid driving license.\nTo prevent potential bias, we carefully chose student participants from a wide \narray of academic disciplines, thereby ensuring a diverse representation of educa -\ntional backgrounds. Additionally, we extended invitations to the general public, \nattracting participants from various backgrounds and enhancing our dataset’s diver -\nsity. Before initiating the experiment, all participants were comprehensively briefed \nabout the study’s objectives and procedures. Informed consent was obtained from all \nparticipants, ensuring their voluntary and informed participation.\nGiven the categorical nature of our data, we conducted Pearson’s Chi-Square tests \nfor our analysis. This test is suitable for comparing frequencies across categorical \nvariables (Field, 2013). The Mann-Whitney U test was not considered appropriate \nbecause it is intended for continuous or ordinal data with individual scores, which \ndoes not match our dataset’s characteristics (Field, 2013; MacFarland et al., 2016).\nWe conducted statistical analyses to assess the comparability of participant char -\nacteristics between the two learning groups. The results of Pearson Chi-Square tests \nrevealed no statistically significant association between the training group type and \ngender (p = 0.927), age distribution (p = 0.989), driving experience levels (p = 0.979), \nand ADAS use frequency ( p = 0.998). All p-values were above the standard signif -\nicance threshold of p < 0.05. These findings indicate that the observed differences \nbetween the conventional learning group and the ChatGPT-based learning group \nwere not statistically significant, suggesting a balanced distribution of participants \nacross key demographic and experiential variables. This equivalence between \ngroups supports the validity of comparisons made in subsequent analyses of training \neffectiveness.\nThe experimental protocol was subjected to a thorough review process and was \napproved by the RMIT University Human Research Ethics Committee (Approval \nNumber: EC 25,022). This ensured adherence to the ethical standards and guidelines \nincumbent on academic research.\nParticipant’s Registration and Briefing Session\nUpon arrival at the experiment site, all participants were guided through a stan -\ndardised registration process. They were provided with a comprehensive explanation \nof the experiment’s setup, objectives, and potential implications. Each participant was \npresented with a “Participant Information and Consent Form,” which had received \nprior approval from the RMIT University Human Research Ethics Committee. After \ngoing through the details mentioned in the form, participants gave informed consent \nto participate in the study by signing the form.\n1 3\n744\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nSubsequently, all participants were introduced to the project through a concise \nvideo. This video aimed to set the context for the experiment rather than serving as \npart of the training process.\nGroup 1 Training: Conventional Method\nFollowing the introductory video, group 1 participants proceeded with their training \nsession. This session commenced with an informative video lasting approximately \nten minutes, which demonstrated the project’s objectives, hardware setup, virtual \ndriving environment, route, and, notably, three of the five ADAS functions.\nThe video’s decision to focus on only three ADAS functions was informed by the \nneed to simulate the experience of purchasing a new vehicle, where car dealers typi-\ncally showcase a limited number of key functions due to time constraints and legal \nlimitations (Murtaza et al., 2022b). Meticulous design underscored this methodology \nto ensure an accurate explanation of the experiment setup and a professional demon-\nstration of the ADAS functions. To maintain consistency across the study and ensure \nthat all participants receive the same level of information, video recordings were \nutilised as the medium for training and demonstration. This approach aligns with the \nfindings of (Ebnali et al., 2019; Zahabi et al., 2020), who suggest video-based train-\ning as one of the highly effective methods.\nAfter the video, participants were presented with a comprehensive user manual \nin printed form that was structured to emulate the look and feel of an actual vehicle \nowner’s manual while being tailored for the experimental setup. The length of this \nuser manual was around 1100 words. This manual consisted of three sections. The \nfirst section overviews the driving simulator’s interface, layout, and operations. The \nsecond section offered detailed descriptions of all five ADAS functions’ functionality \nand activation/deactivation processes, extending beyond the three discussed in the \nvideo. The final section outlined the boundaries and limitations of each ADAS func-\ntion. Participants were given 15 min to read and understand the manual, emphasis -\ning the remaining two ADAS functions not covered in the video. Time allocation to \nread the user manual is consistent with that mentioned in (Merriman, Revell et al., \n2023). The 15-minute time allocation for reading the manual was carefully chosen \nto maintain uniform experimental conditions across the conventional and ChatGPT \ngroups, accounting for consistency and logistical constraints within the study design. \nBy standardising the duration, we aimed to minimise variability in exposure to the \ninstructional material, thus providing a fair baseline for comparing training effec -\ntiveness across demographically diverse participants. This approach ensures that any \nobserved differences in the outcomes can be more confidently attributed to the train-\ning methods rather than differences in the time spent with the manual. According to \n(Brysbaert, 2019), a non-native English speaker reads an average of 139 words per \nminute; hence, our manual was designed to be comfortably read in around 8 min, \nproviding ample time for participants to review sections as needed, mainly the two \nADAS functions not covered in the instructional video. After training, all participants \nwere invited to drive the A V in a simulated environment.\n1 3\n745\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nGroup 2 Training: ChatGPT-Based Interactive User Manual\nGroup 2 participants underwent a distinctive training approach. Instead of the con -\nventional method, they were introduced to a ChatGPT-based interactive user manual, \nwith training conducted directly on a simulator screen. While the text content of \nthe user manual remained the same for both groups, the delivery method differed \nsignificantly. This innovative approach, utilising the ChatGPT-based manual, aimed \nto create a more engaging and efficient learning environment within a 15-minute \ntraining session.\nThe ChatGPT prompt has been specifically modified to instruct participants on \nusing numerous ADAS functions of the simulated A V , a process comprehensively \ndiscussed in Sect. 3.3.1. It is imperative to note that there is no imposed limit on the \nnumber or length of questions that participants can put forward to ChatGPT. This \nopen-ended approach is intended to provide users with a more expansive and flex -\nible learning environment. Participants are thus given the liberty to ask any number \nof questions, regardless of their complexity or scope, within 15 min. The rationale \nbehind this procedure is to ensure that participants have ample opportunity to explore \nand understand the A V’s operations deeply and comprehensively within a reasonable \ntime frame.\nAccording to (Dwivedi et al., 2023), it has been noted that instructions delivered \nvia ChatGPT can occasionally be vague or unrelated to the context if not properly \nstructured. This observation aligns with the findings of (Chandra et al., 2022), who \nasserted that poorly constructed queries or instructions may elicit incorrect or irrel -\nevant responses from the LLMs. Consequently, to ensure that ChatGPT provides \naccurate instructions tailored to a specific scenario, it becomes imperative to furnish \nthe system with ample context and detailed information.\nIn this study, we proposed a comprehensive set of guidelines to optimise com -\nmunication with ChatGPT. These guidelines describe the most effective strategies \nfor structuring queries and instructions to obtain the expected and most beneficial \nresponses from the LLM-augmented approach. By adhering to these guidelines, users \ncan maximise the potential of ChatGPT and facilitate more accurate and contextu -\nally relevant outputs, thereby enhancing the overall effectiveness of the interactive \ntraining sessions. It is important to highlight that participants were not required to \ncreate prompts to interact with ChatGPT. This aspect was managed by providing pre-\ndesigned prompts designed by the Author, as detailed in Sect. 3.3.1 of our manuscript.\nFramework for Preparing a ChatGPT Prompt for Training\nThe development and application of instructional content through ChatGPT requires \na detailed understanding of the context and background information relevant to \nthe training scenario. This paper introduces a comprehensive framework aimed at \noptimising the creation and delivery of ChatGPT prompts for a variety of training \ndomains. Although our primary focus is on ADAS and A V driver training, our frame-\nwork’s principles are broadly applicable, extending to diverse industries beyond A V \ntraining. The framework is structured around a set of guiding principles that enhance \n1 3\n746\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nthe instructional effectiveness of ChatGPT, ensuring that the content is both relevant \nand accessible to learners from different backgrounds.\nOur framework’s approach is designed with a dual focus, incorporating general \nLLM prompting principles, which apply universally across multiple contexts, and \napplication-specific (pedagogical) principles tailored to particular training scenarios \nsuch as those involving ADAS and A V . The general principles aim to guide the cre-\nation of effective, clear, focused, and contextually appropriate prompts. The applica-\ntion-specific principles enable the customisation of instructional content to meet the \nunique needs of learners. This dual approach ensures that ChatGPT delivers informa-\ntive, engaging, personalised, and directly relevant training to the specific learning \nobjectives.\nIn applying these principles to A V driver training, we equipped ChatGPT with \na detailed user manual for an A V , instructing it to use this information to conduct \nan interactive, conversation-based training session. This method focuses on per -\nsonalised learning experiences and ensures that instruction is based solely on the \nprovided materials, thereby avoiding external information that could lead to incon -\nsistencies or inaccuracies. The framework offers a versatile methodology for devel -\noping instructional content for ChatGPT by articulating a clear distinction between \ngeneral and application-specific principles. This approach facilitates the creation of \ntraining programs that are effective, engaging, and tailored to the diverse needs and \nbackgrounds of learners. To optimise the instructional effectiveness of ChatGPT in \ntraining scenarios, such as ADAS and A V driver training, we introduce a framework \ndistinguishing between general LLM prompting principles and application-specific \n(pedagogical) principles. This distinction clarifies the underlying rationale of each \nprinciple and its relevance to specific applications, including ADAS and A V training. \nTo study the practical application and effectiveness of our framework, we present a \ndetailed demonstration of its implementation in training drivers for A V . This illus -\ntrates the adaptability and precision of our guiding principles and also showcases \nthe tangible benefits of our approach. This practical demonstration serves as a robust \nproof of concept, reinforcing the applicability of our framework across various train-\ning domains and specifically highlighting its efficacy in preparing drivers for the \ncomplexities of navigating A V .\nGeneral LLM Prompting Principles\nThese foundational principles are applicable across a wide range of applications and \nare crucial for creating effective ChatGPT prompts:\ni. Goal and scene setting: Begin the conversation with ChatGPT by clearly defin-\ning the goals, approaches, and conditions. The rationale behind setting the scene \nand defining goals is to provide a clear context that guides the LLM to respond \nappropriately to the user’s needs within the specified scenario. When the LLM \nis aware of the scene, it can customise its language, tone, and content to match \nthe specific requirements of the task, ensuring that the training is relevant and \neffective. A well-defined prompt significantly reduces the likelihood of misun -\nderstandings, which are critical to avoid when the LLM is the primary source of \n1 3\n747\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\ninstruction. The design rational is consistent with (Chandra et al., 2022; Dwivedi \net al., 2023).\nBelow is a practical example that demonstrates how to apply our framework’s prin -\nciples, explicitly focusing on the initial goal and scene setting with ChatGPT.\nHello ChatGPT, in my next message, I will provide you with the contents of a \nuser manual for an autonomous vehicle (A V). This manual provides informa -\ntion on how to operate an A V in a simulated environment. Instead of asking the \nparticipants to read the manual by themselves, you will digest the contents and \nthen use an interactive, conversation-based approach to teach the participants \nhow to drive the A V and operate various ADAS functions [Approaches]\nYour goal is to ensure that participants feel confident and capable of using the \nADAS functions and operating the A V safely and efficiently after they have \nreceived this training from you [Goals]\nPlease ensure that the guide and instructions that you provide to the participants \nare solely based on the information provided within the given manual and do \nnot draw from general knowledge or external resources [Conditions]\nFollowing this, the contents of the user manual were pasted to ChatGPT via the \nprompt.\nIn this study, we provided ChatGPT with all the contents in the user manual, which \ninclude clear definitions of the operation procedures and limitations of each ADAS \nfunction. We instructed ChatGPT not to pull information from external resources \nto maintain clarity and consistency. This approach ensures all participants receive \nthe same level of detail about each function, avoiding the situation where ChatGPT \nmight generate false information, thus reducing potential confusion.\nii. Providing structured instruction to ChatGPT: Consistency is crucial in help-\ning ChatGPT understand and respond appropriately. This could apply to various \nscenarios, like instructing different operations in a factory or explaining other \nadministrative procedures in an office setting. Framing information consistently \ncan significantly improve the clarity of the response and facilitate the learning \nprocess. To ensure this, we have established a standard structure for present -\ning instructions to ChatGPT. For every ADAS function, we begin with its func -\ntion name, then provide a brief description, specify its physical location on the \nexperiment setup, verbally describe its symbol, and finally, with its activation \nand deactivation procedures. This consistent approach facilitates more effective \nprompt responses. Since our user manual has already been written in a systemic \nstructure, no special instructions are needed in our experiment.\niii. Reiterate objectives and conditions to ChatGPT regularly : It is vital to \nremind ChatGPT regularly each time a session is initiated or resumed to adhere \nstrictly to the instructions provided in the manual or training materials. It could \nbe critical because of the conversational memory and the maximum token limi -\ntations in LLM-based tools. This practice could make ChatGPT less likely to \ndivert or start utilising information from external or generic sources and thus \n1 3\n748\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nensure context retention and adherence to specified guidelines throughout the \ninteraction. Regular reinforcement of these guidelines helps maintain the focus \nand accuracy of the ChatGPT responses. Such reiteration can compensate for \nthe absence of a sustained conversational memory (Open, 2023) in AI systems \nsuch as ChatGPT, facilitating more accurate and contextually relevant responses. \nHowever, our study did not encounter this issue, as each participant received \ntraining through separate prompts. Furthermore, the user manual was concise \nand short (approximately 1100 words); therefore, we did not reach ChatGPT’s \nmaximum token capacity.\nTokenisation and chunking, specifically in the context of Open-AI’s GPT-3 and GPT-\n4, refers to breaking down the input and output into smaller pieces known as tokens. \nA token could be as small as one character or a word (for example, the letter ‘a’ could \nbe a token, and the word ‘apple’ could also be a token). When there’s a long dialogue \nwith many back-and-forth conversations, ChatGPT can hit its maximum token limit \n(e.g., GPT maximum is 4097 tokens) (Raf, 2023). When this limit is reached, some \nof the earlier parts of the conversation may be cut off, resulting in the model losing \nthe context or instructions provided at the beginning. To address this issue, important \ninstructions should be reiterated regularly to ensure the model continues following \nthem. This is especially crucial when the instructions involve adhering strictly to a \nparticular set of guidelines or utilising specific terms. For instance, in this study, they \nare the names and symbols of the ADAS functions.\nApplication-Specific (Pedagogical) Principles\niv. Personalised responses : Customise your instructions and questions to match \nyour task’s specific requirements and your audience’s characteristics. Person -\nalised responses ensure that the instruction is comprehensible to participants \nfrom diverse backgrounds, thereby enhancing their understanding and applica -\ntion of the information provided. For instance, considering our participants are \nfrom diverse backgrounds, we guided ChatGPT to keep its instructions simple \nand clear. This makes it easier for participants to understand and follow. How -\never, if the participating groups have relevant professional knowledge, using \nwell-known technical terminologies and jargon can ease understanding and make \nthe conversation more engaging. Highlighting or bolding key points may help \ndraw participants’ attention to crucial information. For example, in our experi -\nment, we instructed ChatGPT: “Your audience is the general public; please use \nsimple words and highlight keywords in your response to participants’ inquiries.”\nv. Proactive knowledge checking on learners: One can train ChatGPT to respond \nto a query with the corresponding answer plus a relevant follow-up question to \ncheck a learner’s understanding. Using follow-up questions is one of the best \nmethods to reinforce learning through retrieval practice (Agarwal & Bain, 2019). \nThis can be achieved by instructing ChatGPT to pose a follow-up question to the \nparticipant after its response. For instance, in this study, we instructed ChatGPT \nthat if a participant asks how to activate any ADAS function, it should display the \n1 3\n749\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nsteps and then ask a follow-up question. The following instruction was given to \nChatGPT: “After you respond to the participant’ s question, please ask a follow-\nup question similar to the one which is mentioned below”. “Do you understand \nhow to use this function, or would you like me to explain it to you again”?\nvi. Phrasing output format : One can instruct ChatGPT to present its responses \nin various formats, such as bullet points, paragraphs, or tables. Utilising bullet \npoints is particularly effective for presenting sequential instructions in a clear \nand easy-to-follow manner. For instance, in this study, we guided ChatGPT to \nrephrase its output by instructing it to; “ Please use bullet points to list the steps \nfor activating or deactivating any function”.\nAssessment of ChatGPT’s Response Accuracy and Sample Interactions\nIn our experimental setup, we designed a unique user manual, approximately 1,100 \nwords in length, detailing the location and function of each ADAS feature. Three \nfunctions were located on the steering wheel and two on the shifter module. This \nspecificity ensured that ChatGPT relied solely on the information provided, which \nhelped maintain the accuracy of its responses. Throughout the experiment, we did not \nobserve any false responses generated by ChatGPT.\nHowever, ChatGPT does have limitations, especially after pauses in interaction \nor when initiating a new session due to the sustained conversational memory issue \nin ChatGPT (Open, 2023), as well as when reaching the maximum token limit (Raf, \n2023), which may result in irrelevant or incorrect information. These limitations are \nfurther compounded when requesting real-time or very recent information (Du et al., \n2023). We did not observe any false or incorrect responses generated by ChatGPT \nduring our experiment, confirming its accuracy within our specific parameters. The \nstudy’s limitation lies in the brief nature of our user manual (which was around 1100 \nwords in length), which does not adequately represent the complexities of process -\ning larger documents. Such complexities could challenge ChatGPT’s token capacity, \npotentially increasing the risk of generating inaccurate or invented information.\nFurthermore, for more robust analysis, it would be ideal to implement systematic \nprocedures to identify false, biased, or incomplete information automatically. For \nfuture work, it is also important to investigate how LLMs manage more lengthy doc-\numents and whether this affects the tendency to invent information. Future research \nshould also be conducted to validate ChatGPT’s performance in terms of accuracy \nand reliability. This aspect has also been highlighted by (Thirunavukarasu et al., \n2023) as a key area for future research.\nParticipants learned about all the ADAS and A V functions available in the sim -\nulated A V through interactions with ChatGPT. To provide a comprehensive over -\nview of ChatGPT’s performance, we present five examples of questions asked by \nthe learners, distributed across three types of inquiries. These include two questions \nrelating to functions available in our A V simulator, two queries about non-existing \nfunctions, and one more complex, conditional inquiry illustrated through a specific \nscenario-based question. The rationale was to assess whether ChatGPT can provide \nvalid answers across various scenarios without inventing information. In all cases, \n1 3\n750\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nthe responses from ChatGPT were accurate, demonstrating the model’s capability to \nhandle direct inquiries (the functions available in simulated A V as shown in Figs. 5 \nand 6) and hypothetical scenarios (functions not available in A V as demonstrated in \nFigs. 7 and 8), and complex, conditional inquiries (as illustrated in the new Fig. 9) \neffectively.\nAdditionally, we observed that, on average, participants asked seven questions \nwhile interacting with ChatGPT. The responses from ChatGPT, averaging approxi -\nmately 124 words per question, were concise yet comprehensive, making it easier for \nFig. 7 Screenshot of a learner-1 \ninquiring about a non-existing \nfunction in the simulator\n \nFig. 6 Screenshot of a learner-2 \ninquiring about an existing \nfunction in the simulator\n \nFig. 5 Screenshot of a learner-1 \ninquiring about an existing \nfunction in the simulator\n \n1 3\n751\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nparticipants to understand and engage with the content. Furthermore, we analysed \nthe total length of participant’s communication with ChatGPT, including the pro -\nvided A V user manual, instructions and questions asked by the participants, which \namounted to approximately 2520 words. This quantitative analysis is instrumental in \nhighlighting the level of engagement, depth of user interactions and the efficacy of \nChatGPT’s responses.\nPreparing the Learners\nThe effectiveness of using ChatGPT as a teaching aid in education and training \ndepends on educators or trainers providing clear guidance to their learners on how \nto interact with and learn from the system. In this work, our training approach is \nbased on a well-structured preparation process, which was delivered through a short \nFig. 9 Screenshot of a learner \ninquiring about a complex, con-\nditional inquiry of an existing \nfunction in the simulator\n \nFig. 8 Screenshot of a learner-2 \ninquiring about a non-existing \nfunction in the simulator\n \n1 3\n752\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nintroduction video to ensure consistency in the instruction mode. The following steps \noutline our methodology for preparing the video:\nDefining Learning Objectives In the beginning section, we set clear learning goals, \nemphasising the participants’ comprehension of ADAS functions. This step provides \na clear target for the training and ensures learners know what they are expected to \nlearn.\nIntroducing ADAS Context and Vocabulary  The next section in the instructional \nvideo presents the experimental context and introduces key ADAS features within \na simulated A V environment to engage the participants. Simultaneously, it provides \nessential ADAS-related technical terms such as Autopilot, ACC, LKA, and CA, \nequipping learners with the language needed for accurate discussions with ChatGPT. \nThis ensures that the discussions are technically relevant.\nAn Interaction Kickstarting Example The final section of the video guides learners on \ninitiating interaction with ChatGPT. It suggests starting the conversation with spe -\ncific queries like, “I am a new user, please tell me what functions are available in the \nAV”? to ensure that learners engage in informed discussions about the functions and \ntheir operational processes.\nResults and Analysis\nIn our study, we aimed to investigate the significance and impact of different training \napproaches for end-users of ADAS and autonomous driving functionalities within \nan A V . Participants interacted with the A V system within a simulated environment, \nusing either an innovative training method facilitated by ChatGPT or a conventional \nmethod comprising video demonstrations and user manual instructions. A critical ele-\nment of ChatGPT-based training was developing a set of principles designed to opti-\nmise the effectiveness of ChatGPT in generating prompts and yielding better learning \noutcomes. Performance metrics included participants’ accuracies, represented by \nthe percentage of correct actions executed, and response latencies, calculated as the \ntime difference between when the audio instruction was issued and when the correct \nADAS function was activated or deactivated.\nAccuracy Analysis\nThe results of this study are derived from the comparative analysis of two groups: a \nconventional learning group of 46 participants and a ChatGPT group of 40 partici -\npants, a total of 86 participants. Participants were trained on five ADAS functions: \nAP-On, AP-Off, LKA, CA, and ACC, using their respective training methods.\nAccording to the data presented in Table 5, those trained with ChatGPT demon -\nstrated a comprehensive understanding of all five functions, achieving accuracies \nranging from 80 to 100%. It was observed that both ChatGPT and video-based learn-\n1 3\n753\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\ners reached 100% accuracy in identifying and using the AP-On and AP-Off functions, \nirrespective of training methods and their driving experience levels. The prominent \nplacement of these AP functions at the top of the steering wheel likely contributed to \nthe uniform high accuracy rates.\nThe physical placement of each ADAS function is also an important factor in \nunderstanding the study’s outcomes. LKA and ACC functions were situated on the \nshifter module, whereas the CA system’s control was accessible on the side of the \nsteering wheel. Compared to the AP-On and AP-Off functions at the top of the steer-\ning wheel, the less intuitive placement of the LKA, CA, and ACC functions likely \ncontributed to the varied accuracy rates across these functions. The ChatGPT group \noutperformed the video-based group for the LKA function by achieving a 92% accu-\nracy rate compared to the latter’s 71%. It is worth noting that the video-based group \ndid not have data for CA and ACC, mimicking a real-world scenario where not all \nADAS functions are demonstrated by the sales agent. The ChatGPT group demon -\nstrated a 95% accuracy rate for the CA function, compared to the 73% observed in \nthe user manual group. Likewise, ACC function accuracy was 80% for ChatGPT \nlearners, compared to 58% for those who used the user manual.\nTo thoroughly evaluate the effectiveness of the training methods, a statistical anal-\nysis was conducted using the Pearson Chi-square method. This analysis revealed \nsignificant differences in learning outcomes between the groups for several ADAS \nfunctions. Specifically, the p-values obtained are 0.014 for the LKA function, 0.008 \nfor the ACC function, and 0.034 for the CA function. Given that these p-values are \nbelow the threshold of 0.05, it can be concluded that the observed differences in \nlearning outcomes are statistically significant. This evidence supports the superior \neffectiveness of the ChatGPT-based training approach, particularly for ADAS func -\ntions where operational complexity and non-intuitive physical placement may hin -\nder learning. The slightly lower accuracy for the ACC function across both learning \nmethods could be due to its more complex operation, requiring sequential button \npresses to engage and set speed, emulating manufacturers’ real-time vehicle control \nsystems (Mercedes-Benz, 2021; Toyota Motor Corporation, 2022).\nAnalysis Based on the Driving Experience\nDriver experience is categorised as either a novice driver (one to three years), an \nintermediate driver (four to six years), or an experienced driver (over six years). This \nis consistent with (Commonwealth of Massachusetts, 2023; Robbins & Chapman, \n2019). Our study investigated the relationship between driving experience and the \nTable 5 Participants’ average accuracies after being trained using different methods\nGroup-division w.r.t train-\ning method\nNo. of par-\nticipants in \neach group\nAP-on \nresponse \naccuracy \nin %\nAP-off \nresponse \naccuracy \nin %\nLKA \nresponse \naccuracy \nin %\nCA \nresponse \naccuracy \nin %\nACC \nresponse \naccuracy \nin %\nChatGPT-based learning \nGroup\n40 100 100 92 95 80\nConventional learning \ngroup\n46 100 100 71 73 58\n1 3\n754\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nproficiency with which participants engaged with ADAS. This is outlined in Tables 6 \nand 7 for the conventional and ChatGPT learning groups, respectively. Our findings \nconcur with (Murtaza et al., 2023) that increased driving experience corresponds to \nimproved performance in activating ADAS functions.\nIt is clear from Table 6 that novice drivers in the conventional group had lower \naccuracy rates (57% for LKA and CA and 43% for ACC), reflecting a learning curve \nassociated with these functions. As experience increased, so did proficiency: interme-\ndiate drivers (four to six years) showed improved accuracy (70% for LKA and CA, \nand 54% for ACC), and experienced drivers (over six years) reached higher accuracy \nlevels (84% for LKA, 89% for CA, and 74% for ACC).\nFor the ChatGPT group (Table 7), novice drivers started with higher accuracy \nrates of 84% for LKA and CA and 77% for ACC. This trend of improvement was \nmore noticeable as drivers gained experience, with intermediate drivers reaching \n90% in LKA and 100% in CA and experienced drivers achieving a perfect 100% \naccuracy in both LKA and CA, with ACC at 88%. The ACC function showed slightly \nlower accuracy in both learning methods. This may be because it is more complex to \nuse, requiring sequential button presses to activate and set the speed, which mirrors \nthe vehicle control system of the actual vehicle (Mercedes-Benz, 2021; Toyota Motor \nCorporation, 2022).\nThe observed differences in performance between the conventional and ChatGPT \ngroups indicate that the method of instruction may influence how drivers learn and \napply ADAS and A V functions. The ChatGPT group’s results suggest that this edu-\ncational methodology may offer a more effective foundation for understanding these \ncomplex systems, particularly for novice drivers. These insights support the integra-\ntion of advanced instructional tools, such as ChatGPT, into driver training programs. \nThis integration aims to enhance the utilisation of ADAS and potentially improve \nroad safety for drivers at all experience levels.\nTable 6 Conventional group participant’s response accuracy w.r.t their driving experience\nDriving experience AP-on \nresponse \naccuracy in %\nAP-off \nresponse \naccuracy \nin %\nLKA \nresponse \naccuracy \nin %\nCA \nresponse \naccuracy \nin %\nACC \nresponse \naccuracy \nin %\nNovice driver (1–3 years) 100 100 57 57 43\nIntermediate driver (4–6 years) 100 100 70 70 54\nExperienced driver (above 6 \nyears)\n100 100 84 89 74\nTable 7 ChatGPT group participant’s response accuracy w.r.t their driving experience\nDriving experience AP-On \nresponse \naccuracy in %\nAP-Off \nresponse \naccuracy \nin %\nLKA \nresponse \naccuracy \nin %\nCA \nresponse \naccuracy \nin %\nACC \nresponse \naccuracy \nin %\nNovice driver (1–3 years) 100 100 84 84 77\nIntermediate driver (4–6 years) 100 100 90 100 82\nExperienced driver (above 6 \nyears)\n100 100 100 100 88\n1 3\n755\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nAnalysis Based on the Frequency of use of the ADAS Function\nIn a comprehensive analysis of driver engagement with ADAS functions, we observed \na consistent positive relationship between the real-life frequency of ADAS utilisation \nand the accuracy of participant responses. Analysing the conventional training group \nmore closely, individuals who had never/occasionally used ADAS functions (in their \nreal-life) demonstrated initial competencies at 53% for LKA, 60% for CA, and 46% \nfor ACC. Intermittent users of ADAS in their daily driving have experienced notice-\nable improvements. The accuracy rates for LKA and CA have increased to 76%, \nwhile the accuracy for ACC has risen to 58%. Regular ADAS users within this group \nimproved further, achieving 85% precision in LKA and CA and 71% in ACC, as \ndemonstrated in Table 8.\nParticipants in the ChatGPT educational group who never/occasionally used \nADAS functions demonstrated high accuracy rates, 76% for LKA, 84% for CA, and \n69% for ACC. The intermittent users showed swift learning, with perfect scores of \n100% for LKA and CA and an impressive 86% for ACC. Regular users in this group \nupheld these high precision levels, consistently scoring 100% for LKA and CA and \nimproving to 91% for ACC, as demonstrated in Table 9.\nOur findings concur with the research of (Murtaza et al., 2023), supporting the \nconcept that consistent real-world utilisation of ADAS is associated with enhanced \ndriver performance. The comparison between conventional training and the ChatGPT-\nbased approach highlights the potential influence of teaching methods on understand-\ning and implementing ADAS features. Participants who were trained using ChatGPT \ndemonstrated enhanced proficiency, suggesting that this method might provide ben -\nefits for learning complex automotive technologies. This is especially evident among \nnew and occasional users, where the ChatGPT group’s performance was relatively \nhigher than the conventional group, suggesting ChatGPT offers a potentially more \nintuitive learning experience. These results support the integration of educational \ntools like ChatGPT into driver training curriculums, with the potential to increase the \nTable 8 Conventional group participant’s response accuracy w.r.t their ADAS frequency of use\nGroups- division w.r.t ADAS \nfunction frequency of use\nAP-on \nresponse ac-\ncuracy in %\nAP-off \nresponse ac-\ncuracy in %\nLKA \nresponse ac-\ncuracy in %\nCA response \naccuracy \nin %\nACC \nresponse \naccuracy \nin %\nNever/Occasionally used 100 100 53 60 46\nIntermittent user 100 100 76 76 58\nRegular user 100 100 85 85 71\nTable 9 CHATGPT group participant’s response accuracy w.r.t their ADAS frequency of use\nGroups- division w.r.t ADAS \nfunction frequency of use\nAP-on \nresponse ac-\ncuracy in %\nAP-off \nresponse ac-\ncuracy in %\nLKA \nresponse ac-\ncuracy in %\nCA response \naccuracy \nin %\nACC \nresponse \naccuracy \nin %\nNever/Occasionally used 100 100 76 84 69\nIntermittent user 100 100 100 100 86\nRegular user 100 100 100 100 91\n1 3\n756\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\neffectiveness of ADAS usage and improve road safety for drivers of different experi-\nence levels.\nAnalysis Based on the Participants’ Familiarity with ChatGPT\nTable 10 demonstrates a positive correlation between the frequency of ChatGPT \nusage and the improvement in ADAS function response accuracy. Those who use \nChatGPT regularly achieved 100% accuracy in performing most functions, with a \n92% performance in ACC. This suggests that consistent interaction with LLM-based \ntools can enhance one’s ability to learn effectively.\nIntermittent engagement with ChatGPT demonstrated improved performance out-\ncomes. This is evidenced by a 100% accuracy rate in AP-On and AP-Off responses \nand a high degree of proficiency of 95% in LKA and CA functionalities. These find-\nings suggest that periodic interactions with LLM-based platforms can substantially \naugment learning processes.\nIndividuals with minimal or no previous interaction with ChatGPT showed com -\nparatively lower yet acceptable proficiency in activating ADAS functions. Spe -\ncifically, in LKA and ACC functionalities, they achieved 75% and 63% accuracy, \nrespectively, which, although satisfactory, are less than those observed in individuals \nwho engaged with ChatGPT intermittently or regularly, as demonstrated in Table 10. \nThese functions, located on the shifter module and not as intuitively accessible as \nthose on the steering wheel, presented a steeper learning curve for these users. The \nchallenge mentioned by participants, which we collected through feedback discussed \nin Sect. 5.3, reflects their initial struggles with navigating ChatGPT. They recom -\nmended incorporating visual aids in ChatGPT-focused training to help new users \neasily find and use ADAS functions. However, most participants reflected that Chat-\nGPT training is engaging, enjoyable, and interactive. They appreciated that ChatGPT \nsimplifies the information retrieval process, allowing users to concentrate more on \nlearning and understanding ADAS and A V functions. This observation resonates well \nwith (Dwivedi et al., 2023; Shoufan, 2023; Tlili et al., 2023). A noticeable correlation \nexists between regular ChatGPT usage and proficiency in handling ADAS and A V \nfunctions, emphasising the importance of integrating LLM-based tools in training for \ncomplex technological systems.\nTable 10 ChatGPT group participants’ response accuracy w.r.t their familiarity with ChatGPT\nGroups- division \nw.r.t their familiar-\nity with ChatGPT\nChatGPT learn-\ning group: No of \nparticipants in \nthe group\nAP-on \nresponse \naccuracy \nin %\nAP-off \nresponse \naccuracy \nin %\nLKA \nresponse \naccuracy \nin %\nCA \nresponse \naccuracy \nin %\nACC \nresponse \naccuracy \nin %\nNever/Occasionally \nused\n8 100 100 75 87 63\nIntermittent user 20 100 100 95 95 85\nRegular user 12 100 100 100 100 92\n1 3\n757\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nReaction Time Analysis\nData from the two groups, one trained with a conventional method and the other \nwith ChatGPT was initially subjected to a normality analysis using Shapiro-Wilk’s \nand Anderson-Darling’s test. This preliminary analysis was performed to guide our \ndecision in choosing the appropriate statistical test, parametric or non-parametric, \ndepending on the normality of the data.\nFor the group that underwent training via the conventional methods, covering all \nADAS functions (AP-On, AP-Off, LKA, CA, and ACC), it was verified through Sha-\npiro-Wilk’s and Anderson-Darling’s tests that the collected data did not conform to a \nnormal distribution. In contrast, data from participants trained through the ChatGPT \nsystem showed mixed results. The data adhered to a normal distribution for certain \nADAS functions, namely AP-On and AP-Off, as confirmed by Shapiro-Wilk’s and \nAnderson-Darling’s tests. However, the data did not follow the normal distribution \nfor the remaining functions, LKA, CA, and ACC. Consequently, conventional statis-\ntical measurements that assume normality, such as the analysis of variance (ANOV A) \ntest, did not apply to this dataset. Given these observations, we determined that non-\nparametric testing was the appropriate statistical method for our analysis. We utilised \nthe Mann-Whitney U test, a recommended non-parametric test for comparing two \nunrelated samples when the data are not normally distributed (Field, 2013). There-\nfore, the interpretation of our results was approached with due consideration of these \nanalytical choices and the inherent attributes of the collected data.\nThe key performance indicator examined in this section is the reaction time \nrequired by the participants to activate/deactivate ADAS functions correctly. This \nmetric was selected to evaluate and compare the efficacy of the two different instruc-\ntional methodologies in imparting the participants’ critical operational skills related \nto ADAS.\nAP-On and AP-Off Functions\nThe box plots in Figs. 10 and 11 demonstrate unique patterns between participants \ntrained using conventional methods and those trained using ChatGPT. It is clear from \nFig. 10 (AP-On) group 1 that participants trained with the conventional method had \na median response time recorded as 3.25 s. The span of response times for this group \nranged from 2.30 to 6.00 s. This relatively wide range suggests a dispersion in data \npoints, reflecting variability in the time taken by participants to press the correct but-\nton. The Standard Deviation (SD) for this group was calculated to be 0.92 s, underlin-\ning a higher variability in response times.\nConversely, participants in group 2, trained using ChatGPT, demonstrated a lower \nmedian response time of 2.51 s. Data from this group was more narrowly distributed, \nranging from 1.80 to 3.32 s, and there was a significantly lower SD of 0.44 s. This \ntight range reflects greater consistency among participants, suggesting that they were \nquicker and more uniform in selecting the correct button. Outliers for both groups are \nmarked with the “+” symbols on the plot.\nIn Fig. 11 (AP-Off condition), the median response time for the conventional \nmethod group increased slightly to 3.30 seconds, with responses scattered between \n1 3\n758\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\n2.31 and 6.20 seconds. The SD for this group was calculated as 0.93 seconds. In \ncontrast, the ChatGPT group in the AP-Off condition posted a median response time \nof 2.59 seconds. Their responses, ranging from 1.86 to 3.63 seconds and displaying \na notably lower SD of 0.46 seconds, exhibited a tighter data clustering, indicative of \nmore uniform performance among this cohort. Outliers for both groups are marked \nwith the “+” symbols on the plot.\nAs presented in Table 2, the average accuracy for both AP-On and AP-Off condi-\ntions was recorded at 100% for all participants, irrespective of the training methods. \nHowever, the lower deviation and shorter response times of the ChatGPT groups \nsuggest a better learning outcome of this approach.\nA statistical comparison between the groups, employing the Mann-Whitney U test, \nwas conducted for both AP-On and AP-Off conditions. The tests revealed statistically \nsignificant differences (p < 0.05) between the two groups in both situations. Partici -\npants trained via ChatGPT consistently selected the correct response more rapidly \nthan their conventionally trained counterparts. The highly significant p-value of less \nthan 0.0001 provides compelling evidence for rejecting the null hypothesis, thereby \nvalidating the observed training advantage of the ChatGPT method in both autopilot \nconditions.\nFig. 10 AP-On reaction time compari-\nson between Video vs. ChatGPT train-\ning methods. “+” shows the outliners\n \n1 3\n759\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nLKA Function\nThe box plots in Fig. 12 demonstrate response times (in activating the LKA function) \nbetween participants trained through conventional methods and those trained using \nChatGPT. It’s noteworthy that, unlike the AP-On and AP-Off functions, the LKA \nfunction is situated on the shifter module instead of the steering wheel, a factor that \nmay influence response times.\nIt can be observed from Fig. 12 that participants trained using conventional meth-\nods showed a median response time of 4.70 s. The response times for this group \nranged from 2.52 to 8.84 s, with an SD of 1.92 s, highlighting a broad distribution in \nthe time participants took to activate the correct function, indicating a wider variation \nin individual performance. In contrast, the group trained via ChatGPT had a lower \nmedian response time of 3.59 s. Their response times were tightly packed, ranging \nfrom 1.99 to 6.60 s, with a lower SD of 1.03 s. This data suggests a higher level of \nconsistency among the participants in this group, implying they were both quicker \nand steadier in selecting the correct command on the shifter module.\nStatistical comparisons between the two groups using the Mann-Whitney U test \nhighlighted a significant difference in the response times (p < 0.05). The test produced \na p-value of 0.0037, demonstrating strong evidence that the response times between \nthe two groups were not the same. This underscores the superior efficiency of the \nFig. 11 AP-Off reaction time \ncomparison between Video vs. \nChatGPT training methods. “+” \nshows the outliners\n \n1 3\n760\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nChatGPT training method, which showed significantly shorter response times than \nthe conventional training method, even when interacting with the ADAS function \nlocated on the shifter module, which generally can take longer to reach.\nCA Function\nThe box plots in Fig. 13 show the variability and central tendency of response times \nacross both groups in activating the CA function. The group trained using the user \nmanual recorded a median activation time of 4.40 s. In contrast, the ChatGPT-trained \ngroup demonstrated a faster median activation time of 3.18 s. This difference again \nsuggests a quicker response time for participants trained through the ChatGPT model.\nAnalysing the spread of data offers additional insights. The group trained with the \nuser manual showed a wide range of response times, extending from 2.02 to 8.54 s, \nwith an SD of 1.64. This signifies a substantial variation in individual performance \nwithin this group. Conversely, the group trained with ChatGPT showed a more con-\nsistent range of response times, stretching from 2.10 to 6.40 s, and a lower SD of \n0.98. This tighter spread suggests a greater consistency in performance among these \nparticipants.\nThe Mann-Whitney U test was used to ascertain the statistical significance of the \ndifferences observed. The resulting p-value was 0.0002, substantially below the com-\nmonly accepted significance level of 0.05. This indicates that the difference in median \nactivation times between the two groups is statistically significant. These findings \nFig. 12 LKA reaction time compari-\nson between Video vs. ChatGPT \ntraining methods. “+” shows the \noutliners\n \n1 3\n761\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nsuggest that ChatGPT-based interactive training could lead to faster activation of the \nCA function than instruction methods relying on conventional user manuals.\nACC Function\nThe study further investigates the effectiveness of two distinct training approaches \nin instructing participants to operate the ACC function. This operation is slightly \nmore complex, requiring the activation of two buttons: one to engage the ACC and a \nsecond to set the speed. This configuration was designed to emulate real-time vehicle \ncontrol systems in models like those outlined in the (Mercedes-Benz, 2021; Toyota \nMotor Corporation, 2022).\nThe group trained via the conventional user manual displayed a median activation \ntime of 6.95 s, with individual values ranging from 3.94 to 9.05 s. The SD for this \ngroup was 1.35, reflecting a substantial variation in individual performances. On the \nother hand, participants trained through the ChatGPT-based interactive user manual \nshowed a notably more efficient performance. The median activation time for this \ngroup was significantly reduced to 4.91 s. Furthermore, the range of response times \nin this group was narrower, spanning from 3.04 to 7.90 s, with a lower SD of 1.007. \nThis suggests a greater level of consistency in performance among the ChatGPT-\ntrained participants.\nFig. 13 CA reaction time com-\nparison between User Manual vs. \nChatGPT training methods. “+” \nshows the outliners\n \n1 3\n762\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nA Mann-Whitney U test was performed to statistically assess the observed differ-\nences in median activation times between the two groups. As displayed in Fig. 14, the \nresulting p-value was less than 0.0001, significantly lower than the standard thresh -\nold of 0.05, indicating a statistically significant difference. These findings suggest \nthat ChatGPT-based interactive user manual training is more effective in teaching \nparticipants to promptly activate the ACC function than the conventional user manual \napproach.\nDiscussion\nTraining Methods\nThis study aimed to determine whether the interactive and personalised instruction \noffered by ChatGPT could enhance learning efficiency and accuracy compared to \nconventional methods. Our key findings revealed that ChatGPT-based training led to \nfaster activation times, increased consistency, and high accuracy across all examined \nADAS functions.\nThe conventional learning process for ADAS functions is indeed diverse, involv -\ning demonstrations by sales agents at dealerships (Nandavar et al., 2023), video-\nFig. 14 ACC reaction time com-\nparison between User Manual vs. \nChatGPT training methods. “+” \nshows the outliners\n \n1 3\n763\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nbased instruction (Merriman, Revell et al., 2023; Zahabi et al., 2020), and self-study \nthrough the vehicle’s user manual (Boelhouwer et al., 2020; Greenwood et al., 2022). \nHowever, these methods have their limitations. For instance, due to time constraints \nand the complexity of ADAS features, dealership sales agents might not fully cover \nall available functionalities, leading to a knowledge gap (Murtaza et al., 2023). Fur-\nthermore, these agents may lack the necessary expertise to adequately explain the \noperation of ADAS (Abraham et al., 2017), further widening this informational gap. \nAdditionally, user manuals, although detailed, often require a high level of existing \nknowledge and considerable time to be effectively used (Oviedo-Trespalacios et al., \n2021). This is further compounded by the lack of interactive learning experience \n(Seel, 2011), which limits the effectiveness of these manuals.\nA potential explanation for the superior performance of the ChatGPT-based train-\ning could be attributed to the interactive, responsive, and engaging nature of chatbot-\nbased learning. Prior research (Dwivedi et al., 2023; Hirunyasiri et al., 2023) has \nsuggested that applying LLMs, such as ChatGPT, enhances the educational experi -\nence by providing personalised instructions and immediate feedback. This feature \npotentially creates a more engaging learning environment that could facilitate quicker \nmastery of tasks and improved consistency in task performance.\nThe observed improvements of participants in learning outcomes can be further \nexplained as follows: The interactive nature of chatbot learning infuses an element of \ngamification into the educational process. As (Wu & Yu, 2023) suggests, this aspect \nmakes learning more enjoyable, thereby increasing user engagement. The ‘game-\nlike’ interaction keeps the learners interested, providing a more dynamic, participa -\ntory, and effective learning experience. It is, therefore, reasonable to infer that the \nintroduction of chatbots like ChatGPT into the learning paradigm has the potential \nto enrich the learning experience and motivate learners by making the process more \nenjoyable and engaging.\nThe growing complexity of ADAS demands innovative approaches to user educa-\ntion. Our study’s findings suggest that AI-assisted tools like ChatGPT could poten -\ntially fill this gap, offering a more comprehensive and efficient learning experience \nthan conventional video-based training or user manuals. The ChatGPT training meth-\nodology in our study demonstrated a high degree of accuracy across all tested ADAS \nfunctions.\nThe results presented in Table 2 reflect the significant benefits of using ChatGPT \nfor learning ADAS functions. Notably, the ChatGPT group achieved an impressive \naccuracy range of 80–100% across all functions. Even when confronted with the \ncomplexities of ACC, the accuracy remained at a substantial 80%. In comparing \nthese two instructional methodologies, the ChatGPT-based training consistently led \nto shorter median activation times and tighter data dispersion, indicating that partici-\npants were quicker and more consistent in activating the desired functions. Further \nresearch should be conducted to investigate the optimum number of training sessions \nto achieve even higher accuracy and to shorten the reaction time further in activating \nthe ADAS or A V functions.\nThese results support the continued development and application of AI-based \ntraining methods like ChatGPT. However, further research is needed to corroborate \nthese findings and explore the potential of such training methods across a broader \n1 3\n764\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nspectrum of tasks and contexts. With technological advances and the increasing com-\nplexity of vehicle control systems, the need for effective and efficient training meth -\nods is evident. The findings of this study indicate that ChatGPT-based training could \nbe a promising approach in this respect.\nWhile promising, these findings should be interpreted cautiously, as other hidden \nfactors could have influenced the outcomes. Future research should strive to replicate \nthese findings across different settings and with larger participant samples to estab -\nlish the generalisability of these results. The potential for extending the application \nof such AI-based training to other vehicle systems or even beyond the automotive \nindustry is also worth investigating.\nThe Framework for Preparing a ChatGPT Prompt\nIn this work, we used a customised, ChatGPT-based interactive training platform \nto educate participants about the ADAS functions of a simulated A V . The principles \nwe followed in this context ensured an effective training program and illustrated the \nbroader potential of LLM across different industries.\nThe essence of effective training with ChatGPT lies in the level of specificity and \ncontext provided. We aimed to equip participants with comprehensive knowledge \nabout each ADAS function. For instance, we detailed the concept, purpose, location, \nsymbol, and procedure for activating/deactivating different functions. This meticu -\nlous approach eliminated any assumption of prior knowledge on the part of partici -\npants and reduced the possibility of confusion.\nEnsuring the consistency of instruction delivery is another fundamental aspect of \nour method. We established a standard format for presenting information on ADAS \nfunctions. Additionally, we incorporated a proactive knowledge check mechanism \ninto our training framework. This mechanism provides necessary information and \nasks a follow-up question to assess participant comprehension, thereby promoting \niterative learning.\nThe constraints of AI systems, such as the absence of sustained memory in Chat -\nGPT, necessitate regular reiteration of key instructions throughout user interactions \n(Open, 2023) and have been incorporated into the framework into some best prac -\ntices, which ensure more accurate and contextually relevant responses. Furthermore, \nsetting an output format personalised to each individual’s learning experience can \noptimise the training efficacy.\nPrompt engineers play a crucial role in enhancing user experiences with LLMs by \nguiding learners on how to effectively phrase and frame their questions or requests to \nutilise the LLM’s full potential. We found that treating interactions with ChatGPT as \ntwo-way conversations, providing long-form questions, or sharing contextual narra -\ntives resulted in more precise and relevant responses.\nOverall, our training method using a ChatGPT-based platform led to enhanced per-\nformance among participants compared to those trained using conventional methods. \nThis was validated by the accuracy in activating the ADAS functions and reaction \ntime in activating those functions. This suggests that the customised and interactive \napproach adopted for ChatGPT-based training was more effective in teaching partici-\n1 3\n765\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\npants about ADAS functions. Our study thus shows the immense potential of LLM-\naugmented approach training methods and their viability across various industries.\nSubjective Opinions of Participants\nThe objective outcomes presented in Sect. 4 indicated improved accuracy and reac -\ntion times when using ChatGPT for ADAS training. To complement these findings, \nwe collected the participants’ subjective views to understand their personal experi -\nences with the training process. These subjective experiences are crucial for interpret-\ning the objective results, offering insights into the specific features of the ChatGPT \ntraining, which participants found beneficial. By examining these perspectives, we \naim to uncover the factors contributing to their improved performance.\nAt the end of each participant’s training, we collected their subjective opinions \nabout the learning process with ChatGPT. Our study’s qualitative analysis suggests \nthat 90% of these opinions were positive. Participants highlighted ChatGPT as a \ndynamic and engaging environment ideal for learning ADAS functionalities. Nota -\nbly, the system’s interactivity and tailored approach were well-received, with learners \nappreciating the information’s concise and direct delivery. Well-structured responses \nwith highlighted keywords expedited the learning process and made it more enjoy -\nable, integrating elements of gamification and motivation into the educational experi-\nence. These observed benefits are consistent with the studies (Dwivedi et al., 2023; \nKasneci et al., 2023; Shoufan, 2023; Tlili et al., 2023). However, a minority of partic-\nipants, approximately 8%, reported initial difficulties in interaction and a preference \nfor additional visual aids to assist in the learning process. Despite these minor chal -\nlenges, introducing the LLM into the training process positively influenced learning \noutcomes. In future research, we aim to conduct quantitative analysis, such as the \nNASA TLX (Task Load Index), to substantiate further the correlation between par -\nticipant motivation, engagement, cognitive load, and learning efficiency. A key focus \ncould be on examining the cognitive load during the learning process, particularly \nhow AI-based learning compares to conventional methods in this aspect. A com -\nparative study could also explore whether adopting LLM-based training tools can \nresult in a reduced mental workload, thereby leading to improved performance and \nunderstanding of complex ADAS functionalities. Furthermore, conducting a study to \ndetermine if learning with LLM-augmented methodologies leads to quicker learning \nthan conventional methods would be a valuable extension of our research.\nSelected feedback from participants is as follows:\nPositive feedback:\n1. “Using ChatGPT has significantly enhanced my learning experience. It’s par -\nticularly helpful for quick, direct responses to specific queries. The instructions \ngiven by ChatGPT were easy for me to follow and to locate the buttons. I like \nthe output format in bullet points, and it allows me to step by step follow the \ninstructions”.\n2. “Interacting with ChatGPT is enjoyable and makes learning easier because you \ncan get direct answers to your questions. For example, when I asked about acti -\nvating the Autopilot feature in a car, ChatGPT promptly directed me to its button \n1 3\n766\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\non the steering wheel. This immediate assistance saves time and makes learning \nefficient, enjoyable, and fun. I like that you do not need to search for the relevant \ninformation, ChatGPT does it for you”.\nNegative feedback:\n1. “I found the learning process with ChatGPT a bit confusing since it didn’t pro -\nvide any visuals for the ADAS functions. I had to read the text and figure out \nthe location of the button. It would be easier if ChatGPT included images of the \nADAS functions”.\n2. “I had a bit of trouble learning with ChatGPT because it didn’t show me any \npictures of the ADAS buttons; I only got written explanations. In my opinion, \nimages can help to make learning easier. Overall, I like learning with ChatGPT \nas I do not need to read all the details. You ask ChatGPT it filters for you”.\nThe participants’ reflections on using ChatGPT for ADAS training reveal its potential \nto enhance the educational experience. Their positive feedback underscores Chat -\nGPT’s intuitive interface and engaging interaction, suggesting that the AI-facilitated \ntraining could lead to more effective learning outcomes by making the process \nengaging and interactive. Additionally, the feedback highlights ChatGPT’s role in \nstreamlining the learning process by efficiently offloading the information retrieval \ntask. ChatGPT enables participants to focus more on memorising and understanding \nthe placement and use of ADAS features, as illustrated by participants’ feedback for \ndirect, step-by-step instructions and immediate, relevant answers.\nHowever, the feedback also highlights areas for improvement, such as the need \nfor visual aids to complement textual explanations. Recognising this, future research \nshould consider the integration of multimedia into ChatGPT’s reply. This advance -\nment could potentially revolutionise the training experience by providing customised \nvisual prompts alongside textual explanations, thereby accommodating the diverse \naudience for learning.\nExtending LLM-Augmented Training to Other Industries\nThe previous sections demonstrated the framework’s effectiveness in preparing a \nChatGPT prompt to train drivers on ADAS and A V functions. Nonetheless, the pro-\nposed framework has broader applicability beyond the autonomous vehicle industry. \nFor instance, it can be used in the manufacturing sector to facilitate the assembly of \ncomplex machinery. Consider an ordinary assembly task involving a jet engine in an \naviation manufacturing setting. In this context, the proposed framework can effec -\ntively utilise a ChatGPT prompt for training technicians or engineers in assembling/\nmaintaining a jet engine.\nGoal and Scene Setting  Start the interaction with ChatGPT by outlining the goals, \nmethods, and conditions.\n1 3\n767\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nHello ChatGPT, in my next message, I will provide you with the contents of a \ndetailed operational manual for assembling a jet engine. This manual includes \ncomprehensive instructions on how to assemble the jet engine in a manufac -\nturing setting. Instead of having the technical staff read the manual, you will \ninterpret the contents and use an interactive, dialogue-based method to guide \nthem through the assembly process [Approaches].\nYour goal is to ensure that the technicians or engineers can navigate through the \ncomplex assembly process of the jet engine efficiently, confidently, and safely \nafter they have received this training. [Goals]\nEnsure that the guidance and instructions you provide to the technical staff are \nsolely based on the specifics within the given manual and do not draw from \ngeneric knowledge or external resources [Conditions]\nThen, the contents of the operational manual (in this case, the Jet engine assembly \nguideline) are provided to ChatGPT via the prompt. This approach assures that all \nparticipants receive consistent and accurate information about each task, avoiding \npotential confusion.\nPersonalise Responses The prompt engineer should customise the instructions and \nquestions to match the audience’s characteristics and task. In this scenario, where \nqualified engineers and technicians assemble a jet engine, it is important to instruct \nChatGPT to use technical language and terminologies specific to the industry. The \ninstructions should be detailed and precise, facilitating easy understanding and fol -\nlow-through for the employees involved in the assembly process.\nProviding Structured Instruction to ChatGPT Consistency is vital to helping ChatGPT \nto understand and respond correctly. It would be good to follow the standard process \nand procedure for each assembly step to tell ChatGPT about each part’s assembly \nguidelines. For example, start with each part/instrument name, provide a detailed \ndescription, specify its physical location on the jet engine, describe any symbols or \ntools related to it, and finally, explain its execution procedure.\nProactive Knowledge Checking on Learners  Train ChatGPT to answer a query with \nthe corresponding answer and a relevant follow-up question to check the understand-\ning of the engineers or technicians. For example, if a technician asks how to install a \nparticular part, ChatGPT should present the steps and then ask a follow-up question: \n“Do you know where the part is located and what tools you need to use, or would you \nlike me to explain in further detail?”\nReiterate Objectives and Conditions to ChatGPT Regularly  It’s crucial to remind \nChatGPT every few prompts to adhere strictly to the instructions in the manual. This \nmaintains the focus and accuracy of ChatGPT responses. Regular reinforcement of \nthese guidelines is important, especially when a new conversation with ChatGPT is \ninitiated or resumed after a pause.\n1 3\n768\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nPhrasing Output Format Guide ChatGPT in presenting its responses in various for -\nmats as needed. For instance, instruct ChatGPT to “ use detailed paragraphs for the \ndescription of each assembly step, use bullet points to list the steps for executing each \nstep, and if the engineer or technician specifically requests information in a table \nformat, provide it accordingly.”\nConclusion\nThe comparative study on the efficacy of conventional instructional and LLM-\naugmented methods for teaching ADAS functions has yielded insightful findings. \nWe found that using an LLM-based tool such as ChatGPT resulted in high accu -\nracy and efficiency, which could enhance user education in advanced vehicular \nsystems.\nThe implications of these findings are far-reaching, particularly for the automotive \nand transportation industry. ChatGPT could significantly bridge the knowledge gap \nconcerning ADAS functions, leading to a higher adoption rate. Moreover, this novel \ninstructional approach may reduce the number of incidents resulting from misuse or \nmisunderstanding of these complex systems and thus yield better road safety.\nFor educators, our findings underline the potential of LLM in transforming user \neducation, clearly indicating how this could shape future educational strategies. \nThe effectiveness of ChatGPT, as shown in our research, suggests that LLM-based \ninstructional tools could be included in considerations for future educational guide -\nlines or instructional strategies surrounding the training for ADAS or other complex \nvehicular systems. There is a lack of comprehensive regulation or standardised plat -\nform for ADAS function training. Thus, these findings could be influential in initiat-\ning dialogues to develop such a framework.\nAuthor Contributions Conceptualisation: Mohsin Murtaza, Chi-Tsun Cheng, Mohammad Fard, and John \nZeleznikow. Methodology: Mohsin Murtaza, Chi-Tsun Cheng, Mohammad Fard, and John Zeleznikow. \nSoftware: Mohsin Murtaza. Validation: Mohsin Murtaza, Chi-Tsun Cheng, Mohammad Fard, and John \nZeleznikow. Formal analysis: Mohsin Murtaza and Chi-Tsun Cheng. Resources: Chi-Tsun Cheng, \nMohammad Fard, and John Zeleznikow. Writing—original draft preparation: Mohsin Murtaza and Chi-\nTsun Cheng. Writing review and editing: Mohsin Murtaza, Chi-Tsun Cheng, Mohammad Fard, and John \nZeleznikow. Visualisation: Mohsin Murtaza. Project administration: Mohsin Murtaza, Chi-Tsun Cheng, \nMohammad Fard, and John Zeleznikow. All authors have read and agreed to the published version of the \nmanuscript.\nFunding Open Access funding enabled and organized by CAUL and its Member Institutions\nData Availability As part of RMIT University's human research ethical approval requirements and due to \nprivacy concerns, supporting data is not available.\nDeclarations\nCompeting Interests The authors declare no competing interests. The authors have no relevant financial \nor non-financial interests to disclose.\n1 3\n769\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nOpen Access  This article is licensed under a Creative Commons Attribution 4.0 International License, \nwhich permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, provide a link to the Creative \nCommons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your intended use \nis not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission \ndirectly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/\nlicenses/by/4.0/.\nReferences\nAbdelghani, R., Wang, Y . H., Yuan, X., Wang, T., Lucas, P., Sauzéon, H., & Oudeyer, P. Y . (2023). GPT-3-\nDriven Pedagogical agents to train children’s curious question-asking skills. International Journal of \nArtificial Intelligence in Education, 1–36. https://doi.org/10.1007/s40593-023-00340-7.\nAbraham, H., Reimer, B., & Mehler, B. (2017). Advanced driver assistance systems (ADAS): A consider-\nation of driver perceptions on training, usage & implementation. Proceedings of the Human Factors \nand Ergonomics Society Annual Meeting.\nAgarwal, P. K., & Bain, P. M. (2019). Powerful teaching: Unleash the science of learning. Wiley. https://\ndoi.org/10.1177/1045159519871920.\nAl Kahf, S., Roux, B., Clerc, S., Bassehila, M., Lecomte, A., Moncomble, E., Alabadan, E., de Montmolin, \nN., Jablon, E., & François, E. (2023). Chatbot-based serious games: A useful tool for training medical \nstudents? A randomised controlled trial. Plos One, 18(3), e0278673. https://doi.org/10.1371/journal.\npone.0278673.\nAleven, V ., Baraniuk, R., Brunskill, E., Crossley, S., Demszky, D., Fancsali, S., Gupta, S., Koedinger, K., \nPiech, C., & Ritter, S. (2023). Towards the Future of AI-Augmented Human Tutoring in Math Learn-\ning. [https://doi.org/10.1007/978-3-031-36336-8]. International Conference on Artificial Intelligence \nin Education, Tokyo, Japan.\nBiswas, S. (2023). Prospective role of Chat GPT in the military: According to ChatGPT. Qeios. https://doi.\norg/10.32388/8WYYOD.\nBoelhouwer, A., van den Beukel, A. P., van der V oort, M. C., Hottentot, C., de Wit, R. Q., & Martens, M. \nH. (2020). How are car buyers and car sellers currently informed about ADAS? An investigation \namong drivers and car sellers in the Netherlands. Transportation Research Interdisciplinary Perspec-\ntives, 4, 100103. https://doi.org/10.1016/j.trip.2020.100103.\nBrysbaert, M. (2019). How many words do we read per minute? A review and meta-analysis of reading \nrate. Journal of Memory and Language, 109, 104047. https://doi.org/10.1016/j.jml.2019.104047.\nBuch, S. V ., Treschow, F. P., Svendsen, J. B., & Worm, B. S. (2014). Video-or text-based e-learning when \nteaching clinical procedures? A randomised controlled trial. Advances in Medical Education and \nPractice, 257–262. https://doi.org/10.2147/AMEP.S62473.\nChandra, S., Shirish, A., & Srivastava, S. C. (2022). To be or not to be… human? Theorising the role of \nhuman-like competencies in conversational artificial intelligence agents. Journal of Management \nInformation Systems, 39(4), 969–1005. https://doi.org/10.1080/07421222.2022.2127441.\nColabianchi, S., Bernabei, M., & Costantino, F. (2022). Chatbot for training and assisting operators \nin inspecting containers in seaports. Transportation Research Procedia , 64, 6–13. https://doi.\norg/10.1016/j.trpro.2022.09.002.\nCommonwealth of Massachusetts (2023). Safe Driver Insurance Plan (SDIP) and your auto insurance \npolicy. Retrieved 25th Nov 2023 from https://www.mass.gov/topics/transportation.\nDu, H., Teng, S., Chen, H., Ma, J., Wang, X., Gou, C., Li, B., Ma, S., Miao, Q., & Na, X. (2023). Chat with \nChatGPT on intelligent vehicles: An IEEE tiv perspective. IEEE Transactions on Intelligent Vehicles. \nhttps://doi.org/10.1109/TIV .2023.3253281.\nDwivedi, Y . K., Kshetri, N., Hughes, L., Slade, E. L., Jeyaraj, A., Kar, A. K., Baabdullah, A. M., Koohang, \nA., Raghavan, V ., & Ahuja, M. (2023). So what if ChatGPT wrote it? Multidisciplinary perspectives \non opportunities, challenges and implications of generative conversational AI for research, practice \nand policy. International Journal of Information Management, 71, 102642. https://doi.org/10.1016/j.\nijinfomgt.2023.102642.\n1 3\n770\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nEbnali, M., Hulme, K., Ebnali-Heidari, A., & Mazloumi, A. (2019). How does training effect users’ atti -\ntudes and skills needed for highly automated driving? Transportation Research Part F: Traffic Psy-\nchology and Behaviour, 66, 184–195. https://doi.org/10.1016/j.trf.2019.09.001.\nFagnant, D. J., & Kockelman, K. (2015). Preparing a nation for autonomous vehicles: Opportunities, barri-\ners and policy recommendations. Transportation Research Part A: Policy and Practice, 77, 167–181. \nhttps://doi.org/10.1016/j.tra.2015.04.003.\nFauzi, F., Tuhuteru, L., Sampe, F., Ausat, A. M. A., & Hatta, H. R. (2023). Analysing the role of ChatGPT \nin improving student productivity in higher education. Journal on Education , 5(4), 14886–14891. \nhttps://doi.org/10.31004/joe.v5i4.2563.\nField, A. (2013). Discovering statistics using IBM SPSS statistics . Sage. https://uk.sagepub.com/en-gb/\neur/request-inspection-copies.\nFirat, M. (2023). How ChatGPT can transform autodidactic experiences and open education. Depart-\nment of Distance Education Open Education Faculty Anadolu Unive . https://doi.org/10.31219/osf.\nio/9ge8m.\nGaspar, J. G., Carney, C., Shull, E., & Horrey, W. J. (2020). The Impact of Driver’ s Mental Models of \nAdvanced Vehicle Technologies on Safety and Performance [supporting datasets]. A. F. f. T. Safety. \nhttps://rosap.ntl.bts.gov/view/dot/56626.\nGreenwood, P. M., Lenneman, J. K., & Baldwin, C. L. (2022). Advanced driver assistance systems \n(ADAS): Demographics, preferred sources of information, and accuracy of ADAS knowledge. \nTransportation Research Part F: Traffic Psychology and Behaviour , 86, 131–150. https://doi.\norg/10.1016/j.trf.2021.08.006.\nHirunyasiri, D., Thomas, D. R., Lin, J., Koedinger, K. R., & Aleven, V . (2023). Comparative Analysis of \nGPT-4 and Human Graders in Evaluating Praise Given to Students in Synthetic Dialogues. arXiv \npreprint arXiv:2307.02018. https://doi.org/10.48550/arXiv.2307.02018.\nJi, T. A., & Butterworth, S. (2019). Using Video and Paper–Based Educational Resources to Teach Com-\nmon Surgical Techniques to Pre–Clerkship Medical Students: Results from a Simulation–Based \nTraining Workshop. UBC Medical Jornal. https://doi.org/UBCMJ. 2019: 11.1.\nKasneci, E., Seßler, K., Küchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh, G., \nGünnemann, S., & Hüllermeier, E. (2023). ChatGPT for good? On opportunities and challenges of \nlarge language models for education. Learning and Individual Differences, 103, 102274. https://doi.\norg/10.1016/j.lindif.2023.102274.\nKay, J. (2023). Foundations for Human-AI teaming for self-regulated learning with explainable AI (XAI). \nComputers in Human Behavior, 107848. https://doi.org/10.1016/j.chb.2023.107848.\nKolekar, S., de Winter, J., & Abbink, D. (2020). Human-like driving behaviour emerges from a risk-based \ndriver model. Nature communications, 11(1), 4850. https://doi.org/10.1038/s41467-020-18353-4\nLehtonen, E., Airaksinen, J., Kanerva, K., Rissanen, A., Ränninranta, R., & Åberg, V . (2017). Game-based \nsituation awareness training for child and adult cyclists. Royal Society open Science , 4(3), 160823. \nhttps://doi.org/10.1098/rsos.160823.\nLehtonen, E., Perttula, P., Maasalo, I., Reuna, K., Kannisto, H., Puro, V ., & Hirvonen, M. (2021). Learning \ngame for improving forklift drivers’ safety awareness. Cognition Technology & work, 23, 743–753. \nhttps://doi.org/10.1007/s10111-020-00648.\nLitman, T. (2017). Autonomous vehicle implementation predictions . Victoria Transport Policy Institute \nVictoria, Canada. https://www.vtpi.org/avip.pdf.\nLloyd, S. A., & Robertson, C. L. (2012). Screencast tutorials enhance student learning of statistics. Teach-\ning of Psychology, 39(1), 67–71. https://doi.org/10.1177/0098628311430640.\nLubkowski, S. D., Lewis, B. A., Gawron, V . J., Gaydos, T. L., Campbell, K. C., Kirkpatrick, S. A., Reagan, \nI. J., & Cicchino, J. B. (2021). Driver trust in and training for advanced driver assistance systems in \nReal-World driving. Transportation Research Part F: Traffic Psychology and Behaviour, 81 , 540–\n556. https://doi.org/10.1016/j.trf.2021.07.003\nMacFarland, T. W., Yates, J. M., MacFarland, T. W., & Yates, J. M. (2016). Mann–Whitney U test. Intro-\nduction to nonparametric statistics for the biological sciences using R, 103–132.\nMercedes-Benz (2021). S-class operator’ s manual. https://www.mbusa.com/en/owners/manuals.\nMerriman, S. E., Revell, K. M., & Plant, K. L. (2023). Training for the safe activation of Automated \nvehicles matters: Revealing the benefits of online training to creating glaringly better mental models \nand behaviour. Applied Ergonomics, 112, 104057. https://doi.org/10.1016/j.apergo.2023.104057.\nMerriman, S. E., Plant, K. L., Revell, K. M., & Stanton, N. A. (2023a). A new approach for training needs \nanalysis: A case study using an automated vehicle. Applied Ergonomics, 111, 104014. https://doi.\norg/10.1016/j.apergo.2023.104014.\n1 3\n771\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nMurtaza, M., Cheng, C. T., Fard, M., & Zeleznikow, J. (2022a). The importance of transparency in naming \nconventions, designs, and operations of safety features: From modern ADAS to fully autonomous \ndriving functions. AI & Society, 1–11. https://doi.org/10.1007/s00146-022-01442-x.\nMurtaza, M., Cheng, C. T., Fard, M., & Zeleznikow, J. (2022b). Supporting Driver Training - from Vehi-\ncles with Advanced Driver Assistance Systems to Fully Autonomous Vehicles. Autonomous Vehicle \nTechnology conference-APAC21, Melbourne, Australia.\nMurtaza, M., Cheng, C. T., Fard, M., & Zeleznikow, J. (2023). Preparing drivers for the future: Evaluating \nthe effects of Training on drivers’ performance in an Autonomous Vehicle Landscape. Transporta-\ntion Research Part F: Traffic Psychology and Behaviour. https://doi.org/10.1016/j.trf.2023.09.013.\nNandavar, S., Kaye, S. A., Senserrick, T., & Oviedo-Trespalacios, O. (2023). Exploring the factors influ -\nencing acquisition and learning experiences of cars fitted with advanced driver assistance systems \n(ADAS). Transportation Research Part F: Traffic Psychology and Behaviour, 94, 341–352. https://\ndoi.org/10.1016/j.trf.2023.02.006.\nNasir, A. R., & Bargstädt, H. J. (2017). An approach to develop video tutorials for construction tasks. \nProcedia Engineering, 196, 1088–1097. https://doi.org/10.1016/j.proeng.2017.08.066.\nNg, D. T. K. (2022). Online lab design for aviation engineering students in higher education: A pilot study. \nInteractive Learning Environments, 1–18. https://doi.org/10.1080/10494820.2022.2034888.\nNick (2023). Your AI Flight Instructor. Part Time Pilot. Retrieved 8th June 2023 from https://parttimepilot.\ncom/ai-flight-instructor-chat/.\nOpen, A. I. (2023). The Challenges and Opportunities in Long-Term Memory for Lan -\nguage Models . Open AI. Retrieved 25th June from https://community.openai.com/t/\nthe-challenges-and-opportunities-in-long-term-memory-for-language-models/237178.\nOviedo-Trespalacios, O., Tichon, J., & Briant, O. (2021). Is a flick-through enough? A content analysis of \nAdvanced driver Assistance systems (ADAS) user manuals. Plos One, 16(6), e0252688. https://doi.\norg/10.1371/journal.pone.0252688.\nRaf (2023). What are tokens and how to count them? Open AI. Retrieved 15 June from https://help.openai.\ncom/en/articles/4936856-what-are-tokens-and-how-to-count-them#h_051eb08805.\nRobbins, C., & Chapman, P. (2019). How does drivers’ visual search change as a function of experience? \nA systematic review and meta-analysis. Accident Analysis & Prevention , 132, 105266. https://doi.\norg/10.1016/j.aap.2019.105266.\nSAE International. (2021). SAE levels of driving Automation™ Refined for Clarity and International Audi-\nence. SAE International. https://www.sae.org/blog/sae-j3016-update.\nSalas, E., Bowers, C. A., & Rhodenizer, L. (1998). It is not how much you have but how you use it: Toward \na rational use of simulation to support aviation training. The International Journal of Aviation Psy-\nchology, 8(3), 197–208. https://doi.org/10.1207/s15327108ijap0803_2.\nSallam, M. (2023). ChatGPT utility in healthcare education, research, and practice: Systematic review \non the promising perspectives and valid concerns. Healthcare, 11(6), 887. https://doi.org/10.3390/\nhealthcare11060887.\nSeel, N. M. (2011). Encyclopedia of the sciences of Learning. Springer Science & Business Media. https://\ndoi.org/10.1007/978-1-4419-1428-6.\nShoufan, A. (2023). Exploring students’ perceptions of CHATGPT: Thematic analysis and Fol -\nlow-Up survey. Ieee Access: Practical Innovations, Open Solutions . https://doi.org/10.1109/\nACCESS.2023.3268224.\nSmutny, P., & Schreiberova, P. (2020). Chatbots for learning: A review of educational chatbots for \nthe Facebook Messenger. Computers & Education , 151, 103862. https://doi.org/10.1016/j.\ncompedu.2020.103862.\nSusnjak, T. (2023). Beyond predictive learning analytics modelling and onto explainable Artificial Intel -\nligence with Prescriptive Analytics and ChatGPT. International Journal of Artificial Intelligence in \nEducation, 1–31. https://doi.org/10.1007/s40593-023-00336-3.\nThirunavukarasu, A. J., Ting, D. S. J., Elangovan, K., Gutierrez, L., Tan, T. F., & Ting, D. S. W. (2023). \nLarge language models in medicine. Nature Medicine, 29(8), 1930–1940. https://doi.org/10.1038/\ns41591-023-02448-8.\nTlili, A., Shehata, B., Adarkwah, M. A., Bozkurt, A., Hickey, D. T., Huang, R., & Agyemang, B. (2023). \nWhat if the devil is my guardian angel: ChatGPT as a case study of using chatbots in education. \nSmart Learning Environments, 10(1), 15. https://doi.org/10.1186/s40561-023-00237-x.\nKluger Hybrid Owner’ s Manual. Toyota Motor Corporation, & Corporation, T. M. (2022). https://toyota-\nmanuals.com.au/document/landing_page/kluger-hybrid-owners-manual-oct-22-current.\n1 3\n772\nInternational Journal of Artificial Intelligence in Education (2025) 35:736–773\nVan der Meij, H., & Van Der Meij, J. (2014). A comparison of paper-based and video tutorials for software \nlearning. Computers & Education, 78, 150–159. https://doi.org/10.1016/j.compedu.2014.06.003.\nWu, R., & Yu, Z. (2023). Do AI chatbots improve students learning outcomes? Evidence from a meta-\nanalysis. British Journal of Educational Technology. https://doi.org/10.1111/bjet.13334.\nYuan, L. (2023). Where does AI-driven education, in the Chinese context and Beyond, go next? International \nJournal of Artificial Intelligence in Education, 1–11. https://doi.org/10.1007/s40593-023-00341-6.\nZahabi, M., Razak, A. M. A., Shortz, A. E., Mehta, R. K., & Manser, M. (2020). Evaluating advanced \ndriver-assistance system trainings using driver performance, attention allocation, and neural effi -\nciency measures. Applied Ergonomics, 84, 103036. https://doi.org/10.1016/j.apergo.2019.103036.\nZheng, H., Mason, J. R., Classen, S., & Giang, W. C. (2023). Pilot study: Effect of roles and responsi -\nbility training on driver’s use of adaptive cruise control between younger and older adults. Trans-\nportation Research Part F: Traffic Psychology and Behaviour, 94, 53–66. https://doi.org/10.1016/j.\ntrf.2023.01.023.\nZhou, L., Xu, S., & Qiu, Z. (2021). Intervening Construction Workers’ Unsafe Behaviour with a Chatbot. \n[https://doi.org/10.1007/978-981-16-3587-8]. Proceedings of the 25th International Symposium on \nAdvancement of Construction Management and Real Estate, Online.\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps \nand institutional affiliations.\nAuthors and Affiliations\nMohsin Murtaza1  · Chi-Tsun Cheng1  · Mohammad Fard1  · \nJohn Zeleznikow2\n \r Mohsin Murtaza\nmohsin.murtaza@rmit.edu.au\nChi-Tsun Cheng\nben.cheng@rmit.edu.au\nMohammad Fard\nmohammad.fard@rmit.edu.au\nJohn Zeleznikow\nj.zeleznikow@latrobe.edu.au\n1 School of Engineering, STEM College, RMIT University, Melbourne, Australia\n2 Law and Technology Group, Law School, La Trobe University, Melbourne, Australia\n1 3\n773",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5987739562988281
    },
    {
      "name": "Educational technology",
      "score": 0.5424431562423706
    },
    {
      "name": "Augmented reality",
      "score": 0.45480626821517944
    },
    {
      "name": "Training (meteorology)",
      "score": 0.44008055329322815
    },
    {
      "name": "Multimedia",
      "score": 0.3853810131549835
    },
    {
      "name": "Human–computer interaction",
      "score": 0.35025036334991455
    },
    {
      "name": "Mathematics education",
      "score": 0.33526158332824707
    },
    {
      "name": "Psychology",
      "score": 0.20637467503547668
    },
    {
      "name": "Meteorology",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I82951845",
      "name": "RMIT University",
      "country": "AU"
    },
    {
      "id": "https://openalex.org/I196829312",
      "name": "La Trobe University",
      "country": "AU"
    }
  ]
}