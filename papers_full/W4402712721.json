{
  "title": "Prompting Large Language Models for Supporting the Differential Diagnosis of Anemia",
  "url": "https://openalex.org/W4402712721",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5107508043",
      "name": "Elisa Castagnari",
      "affiliations": [
        "Centre de Recherche des Cordeliers",
        "Inserm",
        "Sorbonne Université"
      ]
    },
    {
      "id": "https://openalex.org/A3048988255",
      "name": "Lillian Muyama",
      "affiliations": [
        "Sorbonne Université",
        "Inserm",
        "Centre de Recherche des Cordeliers"
      ]
    },
    {
      "id": "https://openalex.org/A2097734390",
      "name": "Adrien Coulet",
      "affiliations": [
        "Inserm",
        "Centre de Recherche des Cordeliers",
        "Sorbonne Université"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4200109803",
    "https://openalex.org/W4400098873",
    "https://openalex.org/W4403077524",
    "https://openalex.org/W2772892852",
    "https://openalex.org/W4352978402",
    "https://openalex.org/W3138366809",
    "https://openalex.org/W4317395168",
    "https://openalex.org/W2511274660",
    "https://openalex.org/W2618700632",
    "https://openalex.org/W2888597733",
    "https://openalex.org/W1942377719",
    "https://openalex.org/W1999526345",
    "https://openalex.org/W4367397235",
    "https://openalex.org/W3160143777",
    "https://openalex.org/W4309867298",
    "https://openalex.org/W3012850108",
    "https://openalex.org/W4206541992",
    "https://openalex.org/W2963401755",
    "https://openalex.org/W2963561234",
    "https://openalex.org/W4213357307",
    "https://openalex.org/W6850875801",
    "https://openalex.org/W4401024268",
    "https://openalex.org/W4393160078",
    "https://openalex.org/W4391170193",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W6850625674",
    "https://openalex.org/W4402407635",
    "https://openalex.org/W6600537923",
    "https://openalex.org/W6809646742",
    "https://openalex.org/W6777615688"
  ],
  "abstract": "In practice, clinicians achieve a diagnosis by following a sequence of steps, such as laboratory exams, observations, or imaging. The pathways to reach diagnosis decisions are documented by guidelines authored by expert organizations, which guide clinicians to reach a correct diagnosis through these sequences of steps. While these guidelines are beneficial for following medical reasoning and consolidating medical knowledge, they have some drawbacks. They often fail to address patients with uncommon conditions due to their focus on the majority population, and are slow and costly to update, making them unsuitable for rapidly emerging diseases or new practices. Inspired by clinical guidelines, our study aimed to develop pathways similar to those that can be obtained in clinical guidelines. We tested three Large Language Models (LLMs) -Generative Pretrained Transformer 4 (GPT-4), Large Language Model Meta AI (LLaMA), and Mistral -on a synthetic yet realistic dataset to differentially diagnose anemia and its subtypes. By using advanced prompting techniques to enhance the decision-making process, we generated diagnostic pathways using these models. Experimental results indicate that LLMs hold huge potential in clinical pathway discovery from patient data, with GPT-4 exhibiting the best performance in all conducted experiments.",
  "full_text": "Prompting Large Language Models for Supporting the\nDifferential Diagnosis of Anemia\nElisa Castagnari1,2, Lillian Muyama1,2, Adrien Coulet1,2,⋆\n1 Inria Paris, Paris, France\n2 Centre de Recherche des Cordeliers, Inserm, Universit´ e Paris Cit´ e, Sorbonne\nUniversit´ e, Paris, France\n⋆ corresponding author: adrien.coulet@inria.fr\nAbstract\nIn practice, clinicians achieve a diagnosis by following a sequence of\nsteps, such as laboratory exams, observations, or imaging. The pathways\nto reach diagnosis decisions are documented by guidelines authored by\nexpert organizations, which guide clinicians to reach a correct diagnosis\nthrough these sequences of steps. While these guidelines are beneficial for\nfollowing medical reasoning and consolidating medical knowledge, they\nhave some drawbacks. They often fail to address patients with uncommon\nconditions due to their focus on the majority population, and are slow and\ncostly to update, making them unsuitable for rapidly emerging diseases or\nnew practices. Inspired by clinical guidelines, our study aimed to develop\npathways similar to those that can be obtained in clinical guidelines. We\ntested three Large Language Models (LLMs) — Generative Pre-trained\nTransformer 4 (GPT-4), Large Language Model Meta AI (LLaMA), and\nMistral — on a synthetic yet realistic dataset to differentially diagnose\nanemia and its subtypes. By using advanced prompting techniques to\nenhance the decision-making process, we generated diagnostic pathways\nusing these models. Experimental results indicate that LLMs hold huge\npotential in clinical pathway discovery from patient data, with GPT-4\nexhibiting the best performance in all conducted experiments.\nKeywords: Large Language Models, Diagnosis, Decision support, Diagnostic\npathways, Anemia.\n1 Introduction\nFor complex diagnostic decisions, clinicians typically follow diagnostic guide-\nlines that outline the sequential steps necessary to reach a diagnosis. These\nguidelines, developed by panels of experts based on the best available evidence,\naim to standardize and streamline clinical decisions through recommended pro-\ncedures such as gathering information, making observations, and ordering lab-\noratory tests. However, the development of guidelines is both costly and time-\nconsuming, making it challenging to develop guidelines that comprehensively\n1\narXiv:2409.15377v1  [cs.CL]  20 Sep 2024\ncover the entire spectrum of diseases. Therefore, there is a pressing need for\nmore flexible and scalable methods to provide insights when clinical guidelines\nare incomplete or unavailable.\nWe believe that new techniques, trained on clinical data or embedding a large\namount of domain knowledge, can complement traditional diagnostic guidelines.\nOur goal is to develop methods that assist the decision-making process in a step-\nby-step manner, as it has been importantly outlined in previous research [1].\nFollowing such an approach has the potential to minimize unnecessary tests,\noptimize healthcare costs, and offer more personalized and accurate diagnoses,\nparticularly for patients with uncommon conditions.\nThe extensive data available in Electronic Health Records (EHRs), as well\nas the emergence of large language models (LLMs) offers significant opportu-\nnities to enhance clinical practice. EHRs contain structured, semi-structured,\nand unstructured data about patients’ health, including medications, labora-\ntory test orders and results, diagnoses, and demographic information. Previous\nstudies have leveraged EHRs to train machine learning (ML) methods to au-\ntomatically suggest diagnoses for patients [2]. However, these studies typically\nuse supervised ML methods to predict a single endpoint, represented as a class\nlabel. For data-driven approaches to be truly adopted in clinical practice, di-\nagnoses should not be limited to a single endpoint. Instead, they could be\nrepresented as a pathway that encompasses the steps of medical reasoning and\ndecision-making. This work builds upon a previous study that employed Deep\nReinforcement Learning (DRL) trained on EHRs to achieve this goal [3]. In this\npaper, we propose an approach that uses LLMs and explores different models,\nevaluate their performance on the basis of synthetic but realistic EHRs, and\ncompare them with the DRL approach.\nAnemia, defined as a lower-than-normal amount of healthy red blood cells,\nwas chosen as the clinical condition for this study for three reasons: its diagnosis\nis primarily based on a series of laboratory tests available in most EHRs; it is a\ncommon diagnosis, implying that the associated amount of data is sufficient to\ntrain ML models; and the differential diagnosis of anemia is frequently complex,\nmaking its guidance particularly useful.\nWe chose to use LLMs because, like the DRL approach, they can construct\nmodels that operate sequentially, passing through various steps, or following a\nhuman-readable chain of thought. We propose adapting prompts for LLMs to\nprogressively build individualized pathways of observations to make before sug-\ngesting a diagnostic decision. For instance, in the anemia use case, a pathway\nwould involve a sequence of laboratory test requests, with their results guiding\nthe decision to request additional tests or make a diagnosis. We believe that\nthese constructed pathways can complement clinical guidelines to aid practi-\ntioners in decision-making during the diagnosis process.\nOur main contributions are:\n1. Developing and Evaluating Prompts:We created various prompts\nthat communicate the diagnostic task to the LLM to generate diagnostic\npathways, and compared their performance.\n2\n2. Evaluating LLM Performance:We compared the performance of dif-\nferent LLMs in generating diagnostic pathways and diagnosing patients.\n3. Comparative Analysis:We compared the performance of LLM-generated\npathways with those generated by a concurrent DRL-based approach, to\nassess differences and improvements.\n2 Related Works\nThe discovery of clinical pathways from patient data has been extensively stud-\nied, with unsupervised learning methods such as clustering [4–7], topic model-\ning [8–10], and particularly process mining [11–13] being the most prevalent.\nOther works used supervised learning methods, such as decision trees [14, 15]\nand neural networks [16, 17], to learn patient pathways from EHRs. Mean-\nwhile, reinforcement learning has been actively applied in recent years to learn\ndynamic treatment regimens for patients [18–20]. The application of Deep Re-\ninforcement Learning for diagnosis pathways using EHRs represents another\ninnovative approach. Yu et al. [21] used DRL methods for cost-effective clini-\ncal tasks, including the prediction of Acute Kidney Injury. In [3], Muyama et\nal. used EHR data to train DRL models for clinical diagnosis pathway genera-\ntion, formulating the diagnosis process as a sequential decision-making problem\nwithin a Markov Decision Process (MDP) framework.\nMoreover, the recent emergence of LLMs has seen their application in a wide\nrange of tasks, including text generation, language translation, chatbot develop-\nment, among others. Their potential in clinical reasoning has gained significant\nattention, particularly for enhancing diagnostic accuracy and interpretability.\nVarious studies have explored different frameworks and methodologies to inte-\ngrate LLMs into clinical decision-making processes, aiming to address the unique\nchallenges of the medical domain. Traditionally, the assessment of LLMs has\nfocused on multiple-choice questions. However, recent studies have shifted to-\nwards free-response clinical questions, showing the promise of newer LLMs like\nGenerative Pre-trained Transformer 4 (GPT-4) in diagnosing complex clinical\ncases. In [22], Wu et al. developed a framework called In-Context Padding to\nguide LLMs’ reasoning with medical knowledge seeds. This method involved ex-\ntracting medical entities from clinical contexts, inferring relevant entities using\na knowledge graph, and padding these knowledge seeds into prompts to guide\nthe inference process of LLMs. Similarly, Kwon et al. [23] used the Reasoning-\nAware Diagnosis Framework, which leverages prompt-based learning to generate\ndiagnostic rationales. They formulated clinical reasoning as a Clinical Chain-\nof-Thought (CoT), allowing LLMs to provide insights into patient data and the\nreasoning paths toward diagnoses. Moreover, Savage et al. [24] developed di-\nagnostic reasoning prompts to evaluate the interpretability of LLMs, such as\nGPT-4, in medicine.\nIn addition to these specific frameworks, LLMs like the Pathways Language\nModel (PaLM) and its instruction-tuned variant, Flan-PaLM, have shown state-\n3\nof-the-art performance on various medical question datasets [25]. These models\nleverage a combination of prompting strategies and instruction prompt tuning\nto enhance comprehension, knowledge recall, and reasoning.\nIf these related works highlight the potential of LLMs in clinical reasoning\nand decision-making, the study presented in the paper aims to evaluate the\neffectiveness of various prompting techniques and incorporate domain knowledge\nto improve the performance and explainability of LLMs for diagnosing anemia,\nspecifically using Electronic Health Records. It explores how different prompting\nstrategies, including examples, domain knowledge rules, and Chain-of-Thought\nreasoning, impact the performance of different LLMs for this task. Also, it\nprovides a comparative error analysis between LLMS and a DRL approach used\nin a previous study.\n3 Methods\n3.1 The Models\nWe explored the programmatic use of three different LLMs, based on the Trans-\nformer architecture described in [26] to generate anemia diagnosis pathways. All\nthree LLMs have been pre-trained on a large corpus of texts. The LLMs we used\nare:\n3.1.1 Generative Pre-trained Transformer\nDeveloped by OpenAI [27], GPT [28] is an LLM that can be applied to various\ngenerative tasks. In this work, we used the fourth iteration in the GPT series,\nnamed GPT-4. A previous iteration (GPT-3.5) was initially considered but\nultimately discarded because it consistently had a worse performance than GPT-\n4 on our preliminary tasks. This study uses GPT-4 Turbo.\n3.1.2 Large Language Model Meta AI (LLaMA)\nLLaMA [29] is a family of LLMs, developed by Meta AI [30]. This study uses\nLLaMA-3.\n3.1.3 Mistral\nMistral is an LLM created by Mistral AI [31]. This study uses Mistral7B v0.3.\nThese models were applied to clinical reasoning tasks and adapted to the\nspecific case of finding the optimal sequence of actions needed to achieve an\naccurate anemia diagnosis. We note that while Mistral and LLaMA are open-\nsource, GPT is not.\n4\n3.2 Prompting\nTo achieve our objective, we tested the LLMs with various prompt engineer-\ning approaches to enhance the decision-making process and evaluate it over a\nsynthetic, but realistic dataset. The considered prompting approaches were:\n• Providing a closed list of answers: The model is prompted with the\nspecification of the set of possible answers it could answer.\n• Setting a “Persona” [32]: Setting a personality or character within\nthe prompting, so that the LLM reasons and answers as if it was that\npersonality.\n• Providing examples: Providing the LLM with one to n problem-\nsolution or input-output examples so it has a better understanding of the\ndesired output.\n• Sequential prompting: Instead of providing a single question and re-\nceiving a single answer, the model is prompted in a sequential manner,\nwhere at each step, it asks one question and gains new information about\nthe patient, which in turn feeds the next step of the process.\n• Providing sets of rules: Feeding the LLM with rules from existing\nclinical diagnosis guidelines, to guide its responses.\n• Chain-of-thought [33]: The model is prompted to generate a step-by-\nstep (chain) reasoning to explain its response, which breaks down the task\ninto smaller reasoning steps.\nOur various prompting experiments fall in two major categories: the Plain\nprompt, where we provide the LLM with all the patient’s features ( e.g. lab test\nresults) at once and the LLM responds once with a diagnosis; and theSequential\nprompt, where the LLM requests for patient features one-by-one, and values are\nprovided by our program to the LLM until a diagnosis is reached.\n3.2.1 Plain Prompt\nFollowing prompting good practices and preliminary testing, the very first prompt\nwe tested included the set of possible diagnoses, i.e., the set of possible answers.\nTo improve our results, we experimented with changing the persona of the mod-\nels. We tested three persona settings: no persona, an AI Assistant specialized in\nanemia, and a clinician, expert in anemia. Based on preliminary and unreported\nempirical results, we employed the “clinician” persona in all our reported ex-\nperiments. Similarly, we explored in preliminary phases the impact of providing\nthe LLM with examples, referred to as “shots”, with three configurations: 0-\nshot, 1-shot, and few-shot (i.e., 3 examples). Based on the unreported empirical\nfindings, we chose the 1-shot approach for the rest of our experiments.\n5\nTo assess the impact of incorporating additional domain knowledge into the\nprompt, we used a decision tree made from clinical diagnosis guidelines [3] and\nshown in Figure 1. We used it to provide LLMs with rules usually used for the\ndifferential diagnosis of anemia. We propose a pattern structure for translating\npieces of the decision tree in natural language, as illustrated by the following\nprompt.\nYou are a clinician who is skilled in assessing whether a patient has anemia\nor not, and what type of anemia they have. You make the diagnosis based on\ntheir gender and laboratory test results. In your clinician role, you will give me\nthe name of every lab test you took into consideration to determine the final\ndiagnosis and the final diagnosis at the end.\nUsually, you make a diagnosis based on the following rules:\n1) Look for the ## value first.\n2) If the ## value is ** than ++, the diagnosis is @. If the ## value is **\nthan ++ but ** than ++, look for the ## of the patient.\n[If there are more than 2 cases:]\n3) Otherwise, look for the ##. Here you can distinguish the following cases\n(named a, b,...,n):\na) If the ## results are unavailable, the diagnosis is **.\nb) If the ## is ** than ++, look for the ## value. If the ## results\nare unavailable, the diagnosis is **. If the ## value is ** than ++,\nthe diagnosis is @.\nc) ...\nd) [do step b]\nFor example, if you have that ##: **, ##: **, ##: **, the diagnosis will be @.\nwhere:\n• ## is a laboratory test or the gender;\n• ** is an operator (e.g., <, ≤, >, ≥, =);\n• ++ is a numerical value;\n• @ is a diagnosis type.\nPlease note that ##, **, ++ and @ are local variables and for this reason they\ncan take various values within a single prompt.\nLastly, we evaluate the effectiveness of incorporating the chain-of-thought\nprompting strategy by asking the LLM to explain the steps leading to its re-\nsponse.\n6\nFigure 1: Anemia Decision Tree\n3.2.2 Sequential Prompt\nThe plain prompt provides all the patient’s information at once, effectively\ntreating the diagnosis task as the prediction of a single endpoint without gener-\nating a pathway to reach that diagnosis. Conversely, we consider a “sequential”\nprompt, where the LLM is instructed to request one patient feature at a time in\neach turn of the dialogue. The LLM receives results for each requested feature\nuntil it reaches a diagnosis. In this mode, at any given time, the LLM only has\naccess to the information it has already specifically requested.\nWe restricted the models to inquire only about the features present in the\ndecision tree and also specified the set of possible anemia diagnoses from which\nthe model would select the final diagnosis. Similar to the experiments with\nthe plain prompt, we propose to evaluate the impact of providing of examples,\nincorporating rules from the decision tree, and the use of the chain-of-thought\nstrategy.\n3.3 Dataset\nThe experiments were conducted using the synthetic anemia dataset described\nin [3], which was constructed based on the decision tree shown in Figure 1. This\ndataset includes 17 features— hemoglobin, gender, mean corpuscular volume\n(MCV), ferritin, reticulocyte count, segmented neutrophils, Total Iron Binding\nCapacity (TIBC), hematocrit, transferrin saturation (TSAT), red blood cells\n(RBC), serum iron, folate, creatinine, cholesterol, copper, ethanol, and glu-\ncose—and 8 classes: No anemia, Vitamin B12/Folate deficiency anemia, Un-\nspecified anemia, Anemia of chronic disease (ACD), Iron deficiency anemia\n(IDA), Hemolytic anemia, Aplastic anemia, and Inconclusive diagnosis.\nFor each diagnostic class, feature values were generated using a uniform prob-\nability distribution, with minimum and maximum values determined through a\n7\nmanual review of medical literature and thresholds from the decision tree. The\ndataset encompasses 70,000 patients. A more detailed description of the dataset\nsynthesis can be found in [3]. For our experiments, we used 1,000 patients from\nit for both LLaMA and Mistral, whose class distribution is shown in Fig. 2.\nWe only used 250 patients for GPT-4 due to resource constraints. We used the\nfirst 1,000 and 250 patients from the dataset for LLaMA/Mistral and GPT-4,\nrespectively.\nFigure 2: Distribution of patients across anemia classes.\n3.4 Evaluation Approach and Implementation\nThe performance was evaluated using the following metrics:\n1. Accuracy: The proportion of patients that were correctly diagnosed.\n8\n2. Mean Pathway Length:The average number of actions in the diagnos-\ntic pathways generated by the model.\n3. F1 Score: The harmonic mean of the precision and recall scores. We\nreport one-vs-rest and macro-averaging F1 scores.\n4. ROC-AUC (Receiver Operating Characteristic - Area Under\nCurve) Score:This measures the model’s ability to distinguish between\ndifferent classes. We report one-vs-rest and macro-averaging ROC-AUC\nscores.\n5. Time: The time for the LLMs to infer the results.\nAs mentioned, we conducted experiments on 1,000 patients, except for GPT-\n4, where we used 250 patients due to resource constraints. Due to inconclusive\nresults with the seed parameter, our reported results are based on a single\nexperiment run corresponding to the state of our machine at the time of exper-\nimentation.\nThe LLaMA and Mistral experiments were implemented using the Langchain\nPython library, and the GPT-4 experiments were conducted via the OpenAI\nAPI. The source code of these experiments is available at: https://anonymous.\n4open.science/r/anemia_diag_with_llm-1C1A/. The reference for all the prompts\nused is in: https://anonymous.4open.science/r/anemia_diag_with_llm-1C1A/\nprompts.txt\n4 Results\n4.1 Plain Prompts\nThe baseline experiment involved a plain prompt specifying the set of anemia\nclasses. The results of this experiment are shown in Table 1. All the models\nexhibited poor performance, with Mistral performing the worst and GPT-4 the\nbest.\nTable 1: Plain prompt with specified anemia classes.\nLLM Accuracy F1-Score ROC-AUC Time\nLLaMA 29.59 15.98 59.07 10m 2.4s\nMistral 11.3 6.51 49.97 8m 34.1s\nGPT-4 40.0 29.40 67.74 4m 11.8s\nNext, we enhanced the baseline prompt with a single example of a diagnosis,\nsuch as: For example, you have that hemoglobin: 10g/dL, mean corpuscular\nvolume: 83fL, reticulocyte count: 1.6%. The diagnosis will be Aplastic anemia.\nResults in Table 2 show that incorporating an example slightly improved the\nperformance of all the models.\n9\nTable 2: Plain prompt with specified anemia classes and 1-shot.\nLLM Accuracy F1-Score ROC-AUC Time\nLLaMA 30.03 16.35 59.33 10m 9.0s\nMistral 15.7 12.93 51.96 8m 59.25s\nGPT-4 44.0 32.65 66.35 4m 16.6s\nTo experiment with the addition of domain knowledge to the LLMs’ decision-\nmaking process, we manually converted the decision tree in Figure 1 into natural\nlanguage rules and added these rules to the prompt. Various templates for these\nrules were tested and the most suitable one was retained. The results in Table 3\nshow that there was a significant improvement for GPT-4, with both GPT-4 and\nMistral doubling their scores. LLaMA also improved, though to a lesser extent.\nDespite the use of rules, there were still numerous misdiagnoses, particularly\nwith LLaMA and Mistral, whereas the decision tree alone would perform a\nperfect classification.\nTable 3: Plain prompt with specified anemia classes, 1-shot, and decision tree\nrules.\nLLM Accuracy F1-Score ROC-AUC Time\nLLaMA 36.1 28.07 62.89 10m 36.4s\nMistral 30.7 26.32 59.44 18m 56.0s\nGPT-4 82.0 74.91 87.49 4m 14.6s\nFinally, we added the Chain-of-Thought to the plain prompt. The results,\ndisplayed in Table 4, revealed a massive improvement for LLaMA and a reason-\nable improvement for GPT-4. Mistral’s performance did not show any signifi-\ncant change. Also, this approach made the models’ decisions more explainable,\nallowing us to identify the causes of misdiagnoses and misunderstandings of the\nmodels. This enabled us to better understand the model’s errors and areas of\nconfusion.\nTable 4: Plain prompt with specified anemia classes, 1-shot, decision tree rules\n, and Chain-of-Thought\nLLM Accuracy F1-Score ROC-AUC Time\nLLaMA 72.5 72.56 84.29 65m 47.6s\nMistral 29.29 26.27 59.96 406m 47.0s\nGPT-4 92.8 91.41 94.90 17m 14.8s\n4.2 Sequential Prompts\nWe reproduced the same evaluation schema for the sequential prompts, but for\nsimplicity, we only report the results of the two best-performing variants of these\n10\nprompts. The first, whose results are shown in Table 5, involved a sequential\nprompt with specified anemia classes, 1-shot, and rules.\nTable 5: Sequential prompt with specified anemia classes, 1-shot, and decision\ntree rules LLMAccuracyF1-ScoreROC-AUCAvg. LengthTimeLLaMA49.1 43.19 70.63 3.35 22m 1sMistral27.7 22.89 58.89 3.63 23m 3.1sGPT-474.0 69.56 85.60 4.16 17m 3.9s\nThe second prompt is similar, but included the CoT. Its results, presented\nin Table 6, show that adding CoT improved performance for both GPT-4 and\nLLaMA, while Mistral did not show similar gains. GPT-4 in this scenario\nachieved the best results of all our experiments. Here, for comparison, we also\ndisplay results from the Deep Q-Network (DQN) approach used in [3] to gener-\nate anemia diagnosis pathways.\nTable 6: Sequential prompt with specified anemia classes, 1-shot, decision tree\nrules, and Chain-of-ThoughtLLMAccuracyF1-ScoreROC-AUCAvg. LengthTimeLLaMA61.4 62.98 78.62 6.10 262m 1.0sMistral24.9 20.88 56.89 3.13 106m 9.7sGPT-498.4 98.21 99.09 4.08 23m 49.0sDQN 97.5 97.50 98.60 4.82 1.6s\n5 Discussion\n5.1 LLM Performance\nIn all our experiments, GPT-4 consistently had the best performance, followed\nby LLaMA, with Mistral performing the worst in all scenarios. As for the\nprompting, adding an example to the prompt improved results across all the\nmodels. However, the performance of all models was notably poor before the\nintroduction of rules from diagnosis guidelines into the prompts. Therefore,\nwhile these models have been pre-trained on vast amounts of texts, including\nmedical texts, for specific use cases, it may be beneficial to fine-tune the models\nusing task-specific datasets if the goal is to learn only from new patient data\nwithout considering existing guidelines. Similarly, using Retrieval Augmented\nGeneration (RAG) [34], could enable the identification and consideration of\nnarrative clinical guidelines to fine-tune the embeddings, potentially leading\nto improved results. Additionally, incorporating the CoT strategy further im-\nproved the results for GPT-4 and LLaMA. This is because breaking down the\ntask into smaller reasoning steps has been shown to enhance the reasoning abil-\nities of LLMs. However, this was not the case with Mistral. Upon analyzing its\nresponses, we found that Mistral did not consistently apply the CoT for some\npatients, even if prompted. Overall, LLMs present a valuable opportunity. By\nincluding domain knowledge in the form of rules expressed in natural langage to\ntheir input, they can generate diagnostic decision pathways in a conversational\n11\ncontext and assist in comparing existing guidelines to newly suggested clinical\npathways.\n5.2 Error Analysis\nWe conducted a detailed error analysis for the results of both plain and sequen-\ntial prompts with CoT. For the plain prompt, the majority of the misdiagnoses\nacross all models were due to “comparison errors”, where the LLMs were in-\ncorrect in determining whether a value was greater than, less than, or equal to\nanother value. For GPT-4, the remaining misdiagnoses were only attributed to\nthe model not following the provided decision tree rules. For Mistral, a signifi-\ncant portion of the misdiagnoses (23.40%) may have been caused by the model\nnot applying the CoT, even though it was explicitly mentioned in the prompt.\nThis explains why Mistral was the only model with a worse performance when\nCoT was prompted. Other misdiagnoses were due to diverse factors, such as\nnot adhering to the decision tree rules, the model continuing the chat after a\ndiagnosis was found (despite the conversation being supposed to terminate),\nand not accepting the provided value for a feature, among other issues.\nIn the sequential prompt, again, the majority of misdiagnoses were due to\ncomparison errors, particularly for GPT-4, where these accounted for 100% of\nthe misdiagnoses. Specifically, for LLaMA, several hemolytic anemia patients\nwere diagnosed with aplastic anemia , and vice versa. This is not surprising\nas both anemia types are found on the same branch of the decision tree as\nshown in Figure 1, with the value of a single feature (reticulocyte count) making\nthe difference. Other errors were due to not following the decision tree rules\nprovided, with Mistral requesting values for features that were not included in\nthe dataset, despite the fact that the list of features to be selected was explicitly\nstated in the prompt.\n5.3 Generated Pathways\nFig. 3 illustrates the pathways generated by GPT-4 using the sequential prompt\nand CoT. In this Sankey diagram, the orange nodes represent the lab test results\nrequested by the model in their order from left to right, while the dark green\nnodes represent the final diagnoses. The pink pathways correspond to patients\ndiagnosed with ACD, and the blue pathways correspond to patients diagnosed\nwith Aplastic anemia.\nFigs. 4, 5, and 6 display the most common diagnostic pathways for each\nanemia class, as produced by GPT-4, LLaMA, and Mistral, respectively. Each\nclass is represented by a different color,e.g. pink for ACD, green for No anemia,\nand blue for Vitamin B12/Folate deficiency anemia . As shown in Fig. 3 and\n4, the pathways generated by GPT-4 align closely with the decision tree used\nto label the dataset, whose rules were provided to the LLMs. For LLaMA, as\nillustrated in Fig. 5, although its most common pathways generally adhere to\nthe decision tree rules, there were instances where it repeatedly requested the\nferritin value before terminating with an inconclusive diagnosis. Additionally,\n12\nFigure 3: Pathways to Anemia of Chronic Disease (ACD) and Aplastic anemia,\nin pink and blue respectively, as generated by GPT-4.\nunlike GPT-4, gender is a significant feature in almost all its most common\npathways for each anemia class. In contrast, Fig. 6 shows that Mistral frequently\nmade anemia diagnoses based solely on hemoglobin level. While hemoglobin is\nsufficient to confirm the presence of anemia, it is inadequate for identifying the\nspecific type of anemia. This further explains Mistral’s poor performance.\nTo further investigate the similarities between the pathways generated by\neach model, we calculated the Levenshtein distance between the most common\npathways for each anemia type produced by the LLMs. For comparison, we also\ngenerated pathways based on the decision tree depicted in Fig. 1. We encoded\nthe pathways into strings, where each feature in the pathway was represented by\na single character, and these characters were concatenated to form a string rep-\nresenting the entire pathway. We compared the most common pathway for each\nanemia type across models and calculated the average Levenshtein distances.\nThe results revealed that GPT-4’s most common pathways perfectly matched\nthose of the decision tree, suggesting that GPT-4 is the most effective model\nfor rule-based diagnostic techniques. Among the LLMs, GPT-4 and LLaMA\nexhibited the greatest similarity, with an average Levenshtein distance of 1.75,\nwhile GPT-4 and Mistral followed with an average distance of 1.88. Conversely,\nthe pathways generated by Mistral and LLaMA had the greatest divergence,\nwith a mean Levenshtein distance of 2.63.\n5.4 Comparison with DRL approach\nIn a previous study by Muyama et al. [3], they used a DRL approach to learn\nclinical diagnostic pathways from EHR data. Specifically, they employed various\nextensions of a Deep Q-Network to achieve this goal. We decided to compare our\n13\nFigure 4: The commonest pathway to each anemia class for GPT-4.\nFigure 5: The commonest pathway to each anemia class for LLaMA.\n14\nFigure 6: The commonest pathway to each anemia class for Mistral.\nsequential prompt-based results to theirs, as both approaches involve sequential\ndecision-making and share the same objective. It is important to note that the\nDQN models were trained and tested exclusively on EHR data, allowing them\nto learn diagnostic pathways solely from the data, without prior knowledge. In\ncontrast, the LLMs used in our study, in addition to their pre-training on texts,\nwere also provided with domain knowledge in the form of rules to follow in order\nto make a diagnosis.\nMoreover, the DQN-based study used a broader set of features, some of\nwhich were unrelated to anemia diagnosis. In our LLM-based approach, the\nfeatures to be queried are explicitly mentioned in the prompt and incorporated\ninto the decision tree rules. Despite these differences, among the three LLMs\nevaluated, only GPT-4 outperformed the DRL approach. When comparing the\ndiagnostic pathways generated by both methods, we found that the pathways\nfrom the DQN were, on average, longer than those generated by GPT-4. This\nis likely due to GPT-4 being constrained by the decision tree rules, which limit\nthe number of features considered.\nAdditionally, certain features, such as RBC, were prominent in the DQN-\ngenerated pathways, but absent in the LLM-generated pathways, as they are\nnot included in the decision tree. To further assess pathway similarity, we mea-\nsured the Levenshtein distance between the most common pathways for each\nanemia class generated by each approach. We found that the pathways gen-\nerated by GPT-4 had the highest similarity to those produced by the DQN,\nwith an average Levenshtein distance of 2. In comparison, the average Lev-\nenshtein distances between the DQN-generated pathways and those generated\nby LLaMA and Mistral were 2.25 and 2.36, respectively. This indicates that\nthe LLM-generated pathways were more similar to each other than to those\ngenerated by the DQN, with the exception of those generated by Mistral and\n15\nLLaMA, which exhibited the lowest similarity between them.\nIn terms of time (thus energy) efficiency, the trained DQN model quickly\ngenerates the diagnostic pathway by following its learned optimal policy, tak-\ning significantly less time than the LLMs, which must process the prompt’s\ninformation at each step.\n5.5 Limitations\nWhile our study demonstrates the potential of LLMs for clinical decision-making,\nparticularly in the diagnostic process, it has several limitations, primarily the\nuse of synthetic data. Given these preliminary results, our current effort is to\nevaluate our methods on real-world data.\nAnother limitation is the size of the dataset. Although we believe that\nthe dataset used is a good indicator of the models’ performance given that\nno additional model training is involved, we restricted the expense of funding\nresources by limiting the dataset size for GPT-4 to only a quarter of what\nwas used for LLaMA and Mistral. While this provides a useful performance\nindication in terms of patient pathways and diagmoses, it should be considered\na limitation and should be adjusted accordingly, especially for time comparisons.\nA critical issue encountered is the variability in results due to the man-\nagement of seeds for variable initialisation. Our findings from using LLaMA\nwith the LangChain library indicate inconsistent seed behavior, particularly in\nsequential communication sessions with chains of messages. This inconsistency\nmanifests as different results with the same seed and across different seeds. Con-\nversely, in non-sequential scenarios, results were more consistent with the same\nseed and similar results with different seeds. Nevertheless, seed management\nwithin the system can lead to alterations in execution times and disparate out-\ncomes. Consequently, the seed’s unreliability drived us to exclude it from our\nconsiderations, emphasizing that results are ultimately contingent on system\ndynamics.\nAnother limitation observed is with the Sequential prompt and CoT, which\nis associated with a higher length of inference, associated with a high complexity\nand length of the prompt itself. Longer and more complex prompts hinder the\nLLM’s ability to precisely follow instructions, leading to inconsistent results.\nEach of our runs with the CoT introduced variations, as the model navigates\nthrough different scenarios and attempts to cover all possible cases. We observed\nthat this complexity made it challenging for the model to consistently adhere\nto the decision tree rules.\nAdditionally, while some deviations from the decision tree’s prescribed rules\nwere noted, these deviations may not necessarily indicate errors. They could\npotentially represent valid alternative diagnostic pathways. To validate these\nalternative solutions, a crucial next step is to involve a physician who can assess\nwhether these deviations are indeed correct and whether the LLMs are capable\nof identifying more efficient or accurate diagnostic pathways.\nFinally, in our comparison with the DRL approach, we acknowledge that\nmultiple runs were conducted, resulting in various models, some of which demon-\n16\nstrated better performance than the one used in our study. This particular DQN\nmodel was selected because it had accuracy closest to the mean of the models\nevaluated in that study.\n6 Conclusions and Future Work\nIn this study, we used three LLMs, i.e. GPT-4, LLaMA, and Mistral to gener-\nate diagnostic pathways for anemia. We employed various prompting techniques\nand assessed their impact on the models’ performance. Additionally, we com-\npared these LLMs both to each other and to a DRL approach used in a previous\nstudy with a similar objective. Our findings indicate that, in certain scenarios,\nin particular when domain knowledge is provided in the form of decision rules\nto the LLMs, they can enhance the decision-making process.\nFor future work, we plan to apply our approach to real-world data and ex-\npand the decision tree to include a wider range of anemia types. This expansion\nwill not only provide a more comprehensive evaluation of the LLMs’ diagnostic\ncapabilities but also address a broader spectrum of clinical scenarios. Addi-\ntionally, we intend to explore the applicability of this approach to other clinical\nconditions beyond anemia. Furthermore, we aim to improve the LLMs’ perfor-\nmance by exploring techniques such as LLM fine-tuning, prompt tuning, and\nRAG.\n7 Acknowledgement\nThis works is supported by the Agence Nationale de la Recherche under the\nFrance 2030 program, reference ANR-22-PESN-0007 ShareFAIR, and ANR-22-\nPESN-0008 NEUROVASC.\nReferences\n[1] Julia Adler-Milstein, Jonathan H. Chen, and Gurpreet Dhaliwal. Next-\nGeneration Artificial Intelligence for Diagnosis: From Predicting Diagnostic\nLabels to “Wayfinding”. JAMA, 326(24):2467–2468, 12 2021.\n[2] Lin Lawrence Guo, Jason Fries, Ethan Steinberg, Scott Lanyon Fleming,\nKeith Morse, Catherine Aftandilian, Jose Posada, Nigam Shah, and Lillian\nSung. A multi-center study on the adaptability of a shared foundation\nmodel for electronic health records. NPJ Digital Medicine , 7(1):171, 2024.\n[3] Lillian Muyama, Antoine Neuraz, and Adrien Coulet. Deep reinforce-\nment learning for personalized diagnostic decision pathways using electronic\nhealth records: A comparative study on anemia and systemic lupus ery-\nthematosus. arXiv preprint arXiv:2404.05913 , 2024.\n17\n[4] Anastasia A Funkner, Aleksey N Yakovlev, and Sergey V Kovalchuk. Data-\ndriven modeling of clinical pathways using electronic health records. Pro-\ncedia Comput. Sci., 121:835–842, 2017.\n[5] Verena Hokino Yamaguti, Alberto Freitas, Anderson Chidi Apunike, Rui\nPedro Charters Lopes Rijo, Domingos Alves, and Antonio Ruffino Netto.\nClinical pathways and hierarchical clustering for tuberculosis treatment\noutcome prediction. Procedia Comput. Sci., 219:1373–1379, 2023.\n[6] Shusaku Tsumoto, Tomohiro Kimura, and Shoji Hirano. Automated dual\nclustering for clinical pathway mining. In 2020 IEEE International Con-\nference on Big Data (Big Data) , pages 5387–5396. IEEE, 2020.\n[7] Rom´ eo Baulain, J´ er´ emy Jov´ e, Dunia Sakr, Marine Gross-Goupil, Magali\nRouyer, Marius Puel, Patrick Blin, C´ ecile Droz-Perroteau, R´ egis Lassalle,\nand Nicolas H Thurin. Clustering of prostate cancer healthcare pathways in\nthe french national healthcare database. Cancer Innov., 2(1):52–64, 2023.\n[8] Xiao Xu, Tao Jin, Zhijie Wei, Cheng Lv, and Jianmin Wang. TCPM: topic-\nbased clinical pathway mining. In 2016 IEEE first international conference\non connected health: Applications, systems and engineering technologies\n(CHASE), pages 292–301. IEEE, 2016.\n[9] Xiao Xu, Tao Jin, Zhijie Wei, Jianmin Wang, et al. Incorporating topic\nassignment constraint and topic correlation limitation into clinical goal\ndiscovering for clinical pathway mining. J. Healthc. Eng. , 2017, 2017.\n[10] Zhengxing Huang, Zhenxiao Ge, Wei Dong, Kunlun He, and Huilong Duan.\nProbabilistic modeling personalized treatment pathways using electronic\nhealth records. J. Biomed. Inform. , 86:33–48, 2018.\n[11] Jochen De Weerdt, Filip Caron, Jan Vanthienen, and Bart Baesens. Getting\na grasp on clinical pathway data: an approach based on process mining. In\nEmerging Trends in Knowledge Discovery and Data Mining: PAKDD 2012\nInternational Workshops: DMHM, GeoDoc, 3Clust, and DSDM, Kuala\nLumpur, Malaysia, May 29–June 1, 2012, Revised Selected Papers 16 ,\npages 22–35. Springer, 2013.\n[12] Xiaojin Zhang and Songlin Chen. Pathway identification via process mining\nfor patients with multiple conditions. In 2012 IEEE international confer-\nence on industrial engineering and engineering management , pages 1754–\n1758. IEEE, 2012.\n[13] Alireza Bakhshi, Erfan Hassannayebi, and Amir Hossein Sadeghi. Optimiz-\ning sepsis care through heuristics methods in process mining: A trajectory\nanalysis. Healthc. Anal., 3:100187, 2023.\n[14] Nicole M Zimmerman, David Ray, Nicole Princic, Meghan Moynihan, Cal-\nlisia Clarke, and Alexandria Phan. Exploration of machine learning tech-\nniques to examine the journey to neuroendocrine tumor diagnosis with\nreal-world data. Future Oncol., 17(24):3217–3230, 2021.\n18\n[15] Diti Machnes-Maayan, Soad Haj Yahia, Shirly Frizinsky, Ramit Maoz-\nSegal, Irena Offengenden, Ron S Kenett, Mona I Kidon, and Nancy Agmon-\nLevin. A clinical pathway for the diagnosis of sesame allergy in children.\nWorld Allergy Organ. J. , 15(11):100713, 2022.\n[16] Xiangyang Ye, Qing T Zeng, Julio C Facelli, Diana I Brixner, Mike Conway,\nand Bruce E Bray. Predicting optimal hypertension treatment pathways\nusing recurrent neural networks. Int. J. Med. Inform. , 139:104122, 2020.\n[17] Xijie Lin, Yuan Li, Yonghui Xu, Wei Guo, Wei He, Honglu Zhang, Lizhen\nCui, and Chunyan Miao. Personalized clinical pathway recommendation\nvia attention based pre-training. In 2021 IEEE International Conference\non Bioinformatics and Biomedicine (BIBM) , pages 980–987. IEEE, 2021.\n[18] Ying Liu, Brent Logan, Ning Liu, Zhiyuan Xu, Jian Tang, and Yangzhi\nWang. Deep reinforcement learning for dynamic treatment regimes on\nmedical registry data. In 2017 IEEE international conference on healthcare\ninformatics (ICHI), pages 380–385. IEEE, 2017.\n[19] Lu Wang, Wei Zhang, Xiaofeng He, and Hongyuan Zha. Supervised rein-\nforcement learning with recurrent neural network for dynamic treatment\nrecommendation. In Proceedings of the 24th ACM SIGKDD international\nconference on knowledge discovery & data mining , pages 2447–2456, 2018.\n[20] Haihong Guo, Jiao Li, Hongyan Liu, and Jun He. Learning dynamic treat-\nment strategies for coronary heart diseases by artificial intelligence: real-\nworld data-driven study.BMC Med. Inform. Decis. Mak., 22(1):1–16, 2022.\n[21] Zheng Yu, Yikuan Li, Joseph Kim, Kaixuan Huang, Yuan Luo, and Mengdi\nWang. Deep reinforcement learning for cost-effective medical diagnosis.\narXiv preprint arXiv:2302.10261 , 2023.\n[22] Jiageng Wu, Xian Wu, and Jie Yang. Guiding clinical reasoning with large\nlanguage models via knowledge seeds. arXiv preprint arXiv:2403.06609 ,\n2024.\n[23] Taeyoon Kwon, Kai Tzu-iunn Ong, Dongjin Kang, Seungjun Moon,\nJeong Ryong Lee, Dosik Hwang, Beomseok Sohn, Yongsik Sim, Dongha\nLee, and Jinyoung Yeo. Large language models are clinical reasoners:\nReasoning-aware diagnosis framework with prompt-generated rationales. In\nProceedings of the AAAI Conference on Artificial Intelligence , volume 38,\npages 18417–18425, 2024.\n[24] Thomas Savage, Ashwin Nayak, Robert Gallo, Ekanath Rangan, and\nJonathan H Chen. Diagnostic reasoning prompts reveal the potential for\nlarge language model interpretability in medicine. NPJ Digital Medicine ,\n7(1):20, 2024.\n19\n[25] Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei,\nHyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis,\nStephen Pfohl, et al. Large language models encode clinical knowledge.\nNature, 620(7972):172–180, 2023.\n[26] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N Gomez,  Lukasz Kaiser, and Illia Polosukhin. Attention is all you\nneed. Advances in neural information processing systems , 30, 2017.\n[27] OpenAI. https://openai.com/. Accessed: 2024-08-06.\n[28] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Ka-\nplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,\nAmanda Askell, et al. Language models are few-shot learners. Advances in\nneural information processing systems, 33:1877–1901, 2020.\n[29] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-\nAnne Lachaux, Timoth´ ee Lacroix, Baptiste Rozi` ere, Naman Goyal, Eric\nHambro, Faisal Azhar, et al. Llama: Open and efficient foundation lan-\nguage models. arXiv preprint arXiv:2302.13971 , 2023.\n[30] Meta AI. https://www.meta.ai/. Accessed: 2024-08-06.\n[31] Mistral AI. https://www.mistral.ai/. Accessed: 2024-08-06.\n[32] Jamil Zaghir, Marco Naguib, Mina Bjelogrlic, Aur´ elie N´ ev´ eol, Xavier Tan-\nnier, and Christian Lovis. Prompt engineering paradigms for medical ap-\nplications: scoping review and recommendations for better practices. arXiv\npreprint arXiv:2405.01249, 2024.\n[33] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia,\nEd Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elic-\nits reasoning in large language models. Advances in neural information\nprocessing systems, 35:24824–24837, 2022.\n[34] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir\nKarpukhin, Naman Goyal, Heinrich K¨ uttler, Mike Lewis, Wen-tau Yih,\nTim Rockt¨ aschel, et al. Retrieval-augmented generation for knowledge-\nintensive nlp tasks. Advances in Neural Information Processing Systems ,\n33:9459–9474, 2020.\n20",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6114726066589355
    },
    {
      "name": "Process (computing)",
      "score": 0.43121880292892456
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3798298239707947
    },
    {
      "name": "Medicine",
      "score": 0.369931697845459
    },
    {
      "name": "Machine learning",
      "score": 0.3629244565963745
    },
    {
      "name": "Data science",
      "score": 0.32219165563583374
    },
    {
      "name": "Natural language processing",
      "score": 0.3219727873802185
    },
    {
      "name": "Programming language",
      "score": 0.08895429968833923
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1326498283",
      "name": "Institut national de recherche en sciences et technologies du numérique",
      "country": "FR"
    }
  ],
  "cited_by": 1
}