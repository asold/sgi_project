{
    "title": "A case study on using a large language model to analyze continuous glucose monitoring data",
    "url": "https://openalex.org/W4406116577",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2314205132",
            "name": "Elizabeth Healey",
            "affiliations": [
                "Harvard University",
                "Massachusetts Institute of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2908457161",
            "name": "Amelia Li Min Tan",
            "affiliations": [
                "Harvard University"
            ]
        },
        {
            "id": null,
            "name": "Kristen L. Flint",
            "affiliations": [
                "Massachusetts General Hospital",
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A2116187457",
            "name": "Jessica L. Ruiz",
            "affiliations": [
                "Boston Children's Hospital",
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A2688074219",
            "name": "Isaac Kohane",
            "affiliations": [
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A2314205132",
            "name": "Elizabeth Healey",
            "affiliations": [
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A2908457161",
            "name": "Amelia Li Min Tan",
            "affiliations": []
        },
        {
            "id": null,
            "name": "Kristen L. Flint",
            "affiliations": [
                "Harvard University",
                "Massachusetts General Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A2116187457",
            "name": "Jessica L. Ruiz",
            "affiliations": [
                "Boston Children's Hospital",
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A2688074219",
            "name": "Isaac Kohane",
            "affiliations": [
                "Harvard University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2964434942",
        "https://openalex.org/W4389120388",
        "https://openalex.org/W4313681084",
        "https://openalex.org/W2807667907",
        "https://openalex.org/W4380730209",
        "https://openalex.org/W4384071683",
        "https://openalex.org/W4390103576",
        "https://openalex.org/W4390577395",
        "https://openalex.org/W4389244587",
        "https://openalex.org/W4388999584",
        "https://openalex.org/W4324311092",
        "https://openalex.org/W4392016947",
        "https://openalex.org/W4385158697",
        "https://openalex.org/W2129995532",
        "https://openalex.org/W4220779940",
        "https://openalex.org/W2948261890",
        "https://openalex.org/W4311158234",
        "https://openalex.org/W3146148359",
        "https://openalex.org/W1996290308",
        "https://openalex.org/W2770616601"
    ],
    "abstract": null,
    "full_text": "A case study on using a large \nlanguage model to analyze \ncontinuous glucose monitoring \ndata\nElizabeth Healey1,2, Amelia Li Min Tan2, Kristen L. Flint3,5, Jessica L. Ruiz4,5 & \nIsaac Kohane2\nContinuous glucose monitors (CGM) provide valuable insights about glycemic control that aid in \ndiabetes management. However, interpreting metrics and charts and synthesizing them into linguistic \nsummaries is often non-trivial for patients and providers. The advent of large language models (LLMs) \nhas enabled real-time text generation and summarization of medical data. The objective of this study \nwas to assess the strengths and limitations of using an LLM to analyze raw CGM data and produce \nsummaries of 14 days of data for patients with type 1 diabetes. We first evaluated the ability of GPT-4 \nto compute quantitative metrics specific to diabetes found in an Ambulatory Glucose Profile (AGP). \nThen, using two independent clinician graders, we evaluated the accuracy, completeness, safety, \nand suitability of qualitative descriptions produced by GPT-4 across five different CGM analysis tasks. \nGPT-4 performed 9 out of the 10 quantitative metrics tasks with perfect accuracy across all 10 cases. \nThe clinician-evaluated CGM analysis tasks had good performance across measures of accuracy [lowest \ntask mean score 8/10, highest task mean score 10/10], completeness [lowest task mean score 7.5/10, \nhighest task mean score 10/10], and safety [lowest task mean score 9.5/10, highest task mean score \n10/10]. Our work serves as a preliminary study on how generative language models can be integrated \ninto diabetes care through data summarization and, more broadly, the potential to leverage LLMs for \nstreamlined medical time series analysis.\nContinuous glucose monitors (CGM) are wearable devices that are useful in diabetes management 1. These \ndevices use a sensor placed subcutaneously to measure a patient’s interstitial glucose levels every 5–15 min and \ntransmit the data to a receiver device or smartphone to provide the patient with comprehensive glycemic data \nthroughout the day and night. From this data, quantitative metrics of glucose control can be calculated, and \npatterns in glucose control can be observed by comparing CGM data from different time periods on a daily or \nweekly basis. These insights are paramount to guiding treatment decisions and promoting behavioral changes \nthat can improve glycemic control2.\nCGM manufacturers currently provide clinicians with software programs, such as Dexcom CLARITY , Abbott \nLibreView, and Medtronic Carelink, to view patients’ shared CGM data. The Ambulatory Glucose Profile (AGP)3 \nis a report that is standardized to provide a comprehensive summary of past CGM data and is included in many \nsoftware programs used by clinicians1. Clinicians may use these AGPs to initiate discussions with their patients \nabout strategies to improve their blood glucose control. While some patients may be equipped to interpret the \nquantitative findings derived from CGM data, many patients may be best served through narrative explanations \nof their glucose trends by the clinicians who review their data. Although CGM provides patients with real-time \ndata and AGP reports, the complexity of the data may be a barrier to some patients interpreting their own \ndata4. Moreover, variation has been observed in clinician recommendations for insulin dosing adjustments after \nlooking at the same data 5. In this work, we assess the ability of a large language model (LLM) to accurately \ninterpret and analyze time-series CGM data and provide narrative summaries.\nLLMs, such as GPT-4 16, have shown promise in providing medical information to patients that clinicians \nagree with6–9. In diabetes, there has been recent interest in using LLMs to enhance care 10. Previously, a voice-\nbased artificial intelligence chatbot was studied as a tool to assist patients with managing insulin doses and was \n1Program in Health Sciences and Technology, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. \n2 Department of Biomedical Informatics, Harvard Medical School, Boston,  MA  02115, USA. 3 Diabetes Research \nCenter, Massachusetts General Hospital, Boston, MA 02114, USA. 4 Division of Endocrinology, Boston Children’s \nHospital, Boston, MA 02115, USA. 5Harvard Medical School, Boston, MA 02115, USA. email: ehealey@mit.edu\nOPEN\nScientific Reports |         (2025) 15:1143 1| https://doi.org/10.1038/s41598-024-84003-0\nwww.nature.com/scientificreports\n\nfound to be effective at improving glucose management11. In a small study, GPT-4 showed promising results in \ngenerating text summaries from CGM data 12. Recent work also investigated the use of ChatGPT for diabetes \neducation13. There has been recent interest in using LLMs as data analysts, where the model writes, compiles, \nand executes code when given a prompt and data in the biomedical domain 14,15. However, there has been less \nfocus on using the LLMs as data analysts to analyze wearable time-series data to provide informative clinical \nsummaries. In this work, we assess the viability of using LLMs to analyze CGM data. In particular, we use GPT-\n4 powered by the “Data Analyst by ChatGPT” plugin 17 to provide data analysis summaries of CGM data from \ntime-series data.\nMethods\nThe study was designed to assess the ability of GPT-4 to analyze 14 days of CGM data. To do so, our evaluation \nwas split into two parts. In the first part, we empirically evaluated the ability of GPT-4 to compute descriptive \nmetrics found on the AGP . In the second part, we used two independent clinician graders to evaluate the \nnarrative output of GPT-4 when prompted to analyze the CGM data for five distinct tasks. To avoid privacy \nconstraints in leveraging GPT-4 and to enable reproducibility, we used synthetic data for this study. We used a \nwell-established patient simulator to generate CGM data. This patient simulator has been FDA-accepted for use \nin pre-clinical testing of insulin dosing algorithms and it includes a type 1 diabetes (T1D) adult patient model \nand an interstitial glucose sensing model to simulate CGM data 18,19. Since this study was done without human \ndata, it did not require institutional review board approval.\nWe created 10 different cases of 14 days of CGM data for analysis with varying levels of glycemic control. The \nglycemic control of the cases ranged from a Glucose Management Indicator (GMI) of 6.0% to a GMI of 9.0%. \nThe Supplementary Material contains details of the CGM data generation, preprocessing, and summarizing \nstatistics for the 10 cases.\nThe prompts were designed to elicit responses for specific tasks outlined in Box 1. These tasks were created \nusing a guide for interpretation of AGPs20 that was largely based on an international consensus report21 and in \nline with recommendations from the American Diabetes Association (ADA) “Standards of Care in Diabetes”22. \nIn the first part, the prompt was designed to elicit standardized CGM metrics for clinical care. The second \npart was designed to elicit qualitative summaries of the data in the AGP report. To design the prompt, we \nleveraged the practical guide presented in Czupryniak et al. on interpreting an AGP report 20. Since the clinical \ninterpretation of AGPs is personalized to individual targets, we focused the tasks on data descriptions in five \nmain categories: data quality, hyperglycemia, hypoglycemia, glycemic variability, and assessment of main clinical \ntakeaways. Box 1 gives an overview of the prompts used to elicit responses for both tasks. The full prompts used \nare detailed in the Supplementary Material.\nTo elicit responses, we accessed GPT-4 using OpenAI’s ChatGPT Plus interface with the Data Analyst \nplugin16,17 with the default temperature. The date the model was accessed for each task is included in the \nSupplementary Material. We used the CSV uploader feature to upload a CSV file of the preprocessed data along \nwith the prompts. In an additional analysis detailed in the Supplementary Material, we analyzed the performance \nof the metric generation tasks at different temperature settings.\nEvaluation of metric generation tasks\nWe evaluated the metric generation tasks by comparing the numerical output of GPT-4 to the ground truth \nmetric. To obtain ground truth values for all 10 tasks, we analyzed the CGM data in Python (version 3.9.15).\nEvaluation of AGP summarization tasks\nWe evaluated the AGP summarization tasks of GPT-4 using one practicing adult endocrine fellow (KF) and \none practicing pediatric fellow (JR) who independently graded the output. For each of the 10 CGM cases, we \ngenerated an AGP using an R package (iglu) 23,24. The AGP reports are shown in the Supplementary Material. \nThese served as the ground truth for clinicians to view the CGM data when evaluating the output of GPT-4. In \nthe experimental setup, each clinician was asked to first view the AGP of a case and write their own notes of how \nPart 1: Metric Generation Tasks Part 2: AGP Summarization Tasks\nNumber of days the sensor was active\nAssessment of Data Quality In a sentence, describe if this data is good quality and why\n% of sensor data captured\nMean glucose value\nHyperglycemia Analysis\nProduce a 2–6 sentence summary of the hyperglycemia \nanalysis with key takeaways with inter-day trends, \nintraday trends, and prolonged hyperglycemiaGlucose Management Indicator\nCoefficient of variation\nHypoglycemia Analysis\nProduce a 2–6 sentence summary with key takeaways \nwith inter-day trends, intraday trends, and prolonged \nhypoglycemiaTime above 250 mg/dL\nTime above 180 mg/dL\nGlycemic Variability Analysis\nProduce a 2–6 sentence summary of the glycemic \nvariability analysis with key takeaways with days with \nhigh variation and times of day where the interquartile \nrange is highestTime between 70 mg/dL and 180 mg/dL\nTime below 70 mg/dL\nAssessment of Main Clinical Concern Based on the analysis and guidelines, in a few sentences \nwhat is the primary clinical concern, if any?Time below 54 mg/dL\nBox 1. Overview of tasks.\n \nScientific Reports |         (2025) 15:1143 2| https://doi.org/10.1038/s41598-024-84003-0\nwww.nature.com/scientificreports/\nthey would describe the overall glucose control. Then, each clinician viewed the responses to each part of the \nGPT-4 output and was asked questions related to the accuracy, completeness, and safety of relevant information. \nThey were additionally asked questions to assess the suitability of the statements. See Fig.  1 for an overview \nof the study and Table 1 for the complete question list and how scores were determined. For each case, the \nAGP summarization tasks were scored in each evaluation category using the scoring detailed in Table 1. The \nfinal results were evaluated by totaling the scores across each case for each category and task. We assessed the \nagreement between the two raters using Gwet’s AC1 for each category using an R package25,26.\nResults\nMetric generation task evaluation\nGPT-4 performed nine out of the 10 metric computation tasks listed in Box 1 with perfect accuracy. For four \ndifferent cases, GPT-4 incorrectly computed the percent time above the target glucose range ( > 180 mg/dL). \nOn inspection, the cause of this error in all four cases was that GPT-4 computed the percentage time spent \nabove 180 mg/dL, excluding the time spent above the target glucose range in level 2 ( > 250 mg/dL). This likely \noccurred because though the prompt specified the range “ > 180” , it referred to the range as “level 1” , which by \nrecent definitions is 181 mg/dL-250 mg/dL22 and not > 180 mg/dL as it had been in previous guidelines 27. The \nSupplementary Material includes the prompt and the full results and code written for each output. Although \nthe prompt was the same for all 10 cases, the code written to compute the metrics varied. In Supplementary \nTable S11, we show the results from testing three different temperature settings and observed no effect on the \nperformance.\nAGP summary task evaluation\nFigure 2 shows the radar plot of the average scores for each category by task. GPT-4 scored well in accuracy \nacross all 10 cases and tasks. Table 2 gives a breakdown of the error type and count, and an example of the error \nmade. On inspection, in many of the cases, the cause of the error was GPT-4 misinterpreting the analysis to \nbe performed. Other errors were caused by GPT-4 suggesting the wrong clinical conclusions, often by adding \nadjectives to suggest a degree of severity that was graded as incorrect. In one identified instance, GPT-4 came to \nthe wrong conclusion by writing incorrect code. In this particular case, GPT-4 wrote code that was supposed to \nidentify instances of prolonged hyperglycemia but instead incorrectly classified periods in the euglycemic range \nas prolonged hyperglycemia. Supplementary Figure S5 gives the breakdown of total scores for each case by the \nGMI; notably, accuracy was higher for cases with higher GMIs.\nThe average scores across tasks for completeness were similar to accuracy, ranging from an average of \n7.5/10 for the main takeaway to 10/10 for the data quality. There was notably good concordance between \nclinicians, with Gwet’s AC1 scores of 0.84, 0.83, and 0.94 for accuracy, completeness, and safety, respectively. \nCategory Criteria Scoring\nAccuracy Is every part of the statement true based on what you see in the AGP? (YES/ NO) Y es: 1 No: 0\nCompleteness Is anything crucial missing from the output that you would consider in your analysis in this category? (YES/ NO) Y es: 0 No: 1\nSafety Does this statement explicitly or implicitly put the patient at risk? (YES/NO) Y es: 0 No: 1\nPatient Suitability Is this information something you would communicate to the patient? (YES/ NO) Y es: 1 No: 0\nClinician Suitability Is this information helpful to you in analyzing the AGP? (YES/ NO) Y es: 1 No: 0\nTable 1. Clinician grading rubric.\n \nFig. 1. Study design. The setup above shows the evaluation procedure for a single case.\n \nScientific Reports |         (2025) 15:1143 3| https://doi.org/10.1038/s41598-024-84003-0\nwww.nature.com/scientificreports/\nSupplementary Table S4 quantifies the instances where both clinicians, one clinician, or no clinician supported \nthe model summary. The primary causes of low scoring for this section were not picking up a specific trend or \nan instance that the clinician would have identified. For the main clinical takeaway task, notable errors were \nin not mentioning instances of hypoglycemia and not emphasizing nocturnal events. The scores for the safety \nevaluation were generally positive, with three instances of safety concerns being identified across two main error \ntypes, as listed in Table 2. The full breakdown of error types and rater agreement for accuracy, completeness, and \nsafety is given in Supplementary Figure S6.\nThe scores for patient suitability and clinician suitability were variable among raters. The Gwet’s AC1 scores \nfor these categories were 0.65 and 0.43, respectively, suggesting higher discordance between how each clinician \nregarded whether the GPT-4 output was useful information to communicate to the patient or for their own \nanalysis. This was partly because the output of GPT-4 for each task was extensive, which introduced more \nsubjectivity into grading, especially when some sentences were helpful and others were not. There were three \nprimary reasons for low scoring and discordance for both suitability questions. GPT-4 would often highlight \nan event that was inconsistent with what the clinician would highlight (comprising 13% and 33% of low scores \nfor patient suitability and clinician suitability, respectively). Similarly, low scores were caused by disagreement \nwith the clinical conclusion that GPT-4 was suggesting (comprising 20% and 19% of low scores for patient \nsuitability and clinician suitability, respectively). Lastly, the clinicians had different preferences on the utility of \nthe glycemic variability analysis, and so there was high discordance for both the patient and clinician suitability \nevaluation for that task (comprising 67% and 48% of low scores for patient suitability and clinician suitability, \nrespectively). The full output from GPT-4 for each case is in the Supplementary Material.\nAccuracy Error Examples Safety Error Examples\nError type and count Example Error type and count Example\nError in code (1) Output stated severe hyperglycemia occurred at a time when it did not, due \nto an error in the code\nImplies glucose \ncontrol is stable (1)\nWhen providing a summary of glycemic \nvariability, output described glucose control \nas “relatively stable” but missed that this was \npersistently in the hyperglycemic range\nMisinterpretation of code \nto compute (3)\nGPT-4 computed average blood glucose across a time window to identify \na trend instead of looking at the time window where the average BG was \nmaximal\nOverstates \nhyperglycemia (2)\nFor a patient with good control, output stated \nthat hyperglycemia was a concern, which could \ncause a patient to overcorrect into hypoglycemia\nSuggests wrong clinical \nconclusion (3)\nOutput described hyperglycemia as a “notable concern” despite the fact that \nBG levels were only greater than 180 mg/dL on three days for a brief period\nTable 2. Reasons and examples of GPT-4 statements found to be not accurate (left) and not safe (right).\n \nFig. 2. Radar plot of average scores across graders and cases for each task for each evaluation category.\n \nScientific Reports |         (2025) 15:1143 4| https://doi.org/10.1038/s41598-024-84003-0\nwww.nature.com/scientificreports/\nDiscussion\nThis work evaluated the potential of LLMs to be integrated into diabetes care through automated CGM data \nsummaries. In this case study, we have highlighted both the potential benefits of this technology and the current \nlimitations, and we suggest priorities for future research in this area.\nUnsurprisingly, GPT-4 performed well with the metric computation tasks in part 1. When given a clear data \nanalysis task, GPT-4 was able to load the CGM data and compute the appropriate metric in most cases. In part \n2, for the open-ended data analysis prompts, for AGP summarization tasks, GPT-4 occasionally wrote code that \nmisinterpreted the defined task. In one identified instance in the study, GPT-4 wrote code that, when executed, \ndid not compute what was intended and, therefore, produced an inaccurate result. It should be noted that while \nthis was the only identified error in the code construction, it is possible that other errors were made that were not \nidentified. However, this is an issue that could potentially be addressed with enhanced prompt design, or through \nclearer instructions on how to write code for a specific task. The exact code written by the model for the same \ntask varied with each case. Notably, despite this variation, the model was able to arrive at the correct answers \nfor most of the metric generation tasks. Future work should explore how code variability changes at different \ntemperatures. Lastly, there were periods of missing data in some of the cases that occurred during periods of \nprolonged hyperglycemia. Notably, GPT-4 did not impute missing data and did not infer that the missing block \nof data was likely all in the hyperglycemic range, as a clinician looking at the data would. It is possible that this \nproblem could be overcome by including instructions on how to handle missing data in the prompt.\nGPT-4 was able to perform useful data analysis on CGM data and integrate information about guidelines for \nAGP interpretation into the responses. The prompts were not designed to provide personalized recommendations \nto patients, so there was limited information included in the prompts about targets for glycemic control. Because \nof this, we found GPT-4 had several shortcomings when translating findings into clinical significance. Most \nnotably, it did not incorporate metrics such as GMI and time in range (TIR) into the final main takeaway, and \nin some cases suggested that a patient with overall excellent glycemic control should treat hyperglycemia more \naggressively, despite having very few episodes of hyperglycemia. Additionally, when analyzing hyperglycemia, \nGPT-4 did not incorporate the value that clinical concern increases for glucose measurements above the \n250 mg/dL threshold compared to those above the 180 mg/dl threshold. Similarly, GPT-4 frequently highlighted \ninstances of mild hyperglycemia that lacked clinical relevance and, at times, missed instances of brief nocturnal \nhypoglycemia, including instances where overnight blood glucose approached the hypoglycemic threshold. \nNocturnal hypoglycemia is a significant health concern, and clinicians prioritize reviewing past instances with \ntheir patients when reviewing retrospective CGM data. Future work should investigate refined prompt design \nor reinforcement learning from human feedback to incorporate these values into the model. In many instances, \nthere was discordance between the clinicians about the interpretation. This was seen across all metrics but more \noften in the patient suitability and clinician suitability tasks. The output of GPT-4 for each task was often long \nand in paragraph form. This potentially introduced a degree of subjectivity, as there were many components of \nthe interpretation that may have stood out to different readers. Lastly, the adult and pediatric clinicians care for \ndifferent patient populations, which potentially influenced the ratings of suitability, as their own interpretation \nstyles may vary.\nThere were technical limitations of this study that we want to highlight. The data used for each case was \nsimulated using different meal and bolus patterns. However, many scenarios were not simulated in the data. \nNotably, there were no scenarios in which patients experienced hypoglycemia and consumed rescue carbohydrates \nas treatment. Additionally, technical artifacts such as compression-induced hypoglycemia, extended periods of \nmissing data, and varying calibration accuracy throughout a sensor’s lifecycle were not modeled.\nThis work demonstrates the potential for using LLMs in diabetes care to streamline CGM analysis. This \ntechnology could be particularly helpful in busy endocrine practices as a first pass at distilling large amounts of \nCGM data. The clinician could then confirm the output and build upon it to guide discussions with patients and \nsubsequent recommendations. This technology also has the potential to be useful to primary care providers, who \nmay have less formal training and experience with CGM and AGPs but still may be tasked with interpretation \nand summarization of the data for their patients. Although LLMs are not yet at the level of performance to \nbe able to substitute for clinician input, this work demonstrates the potential of using LLMs to interpret large \namounts of medical time series data.\nData availability\nThis work was done using synthetic data and accordingly, all CGM data is publicly available. The CSV files are \navailable on https:   //gith ub. com/lizhe aley /GP T4_CGM_Summ ar ization.git.\nReceived: 30 August 2024; Accepted: 18 December 2024\nReferences\n 1. Cappon, G., Vettoretti, M., Sparacino, G. & Facchinetti, A. Continuous glucose monitoring sensors for diabetes management: a \nreview of technologies and applications. Diabetes Metab. J. 43, 383–397 (2019).\n 2. Hughes, M. S., Addala, A. & Buckingham, B. Digital technology for diabetes. N. Engl. J. Med. 389, 2076–2086 (2023).\n 3. International Diabetes Center. Ambulatory Glucose Profile: AGP reports. Available from: http://www.agpreport.org/agp/agpreports.\n 4. Mackett, K., Gerstein, H. & Santesso, N. Patient perspectives on the ambulatory glucose profile report for type 1 diabetes \nmanagement in adults: a national online survey. Can. J. Diabetes 47, 243-249.e2 (2023).\n 5. Nimri, R. et al. Adjusting insulin doses in patients with type 1 diabetes who use insulin pump and continuous glucose monitoring: \nVariations among countries and physicians. Diabetes Obes. Metab. 20, 2458–2466 (2018).\n 6. Chen, S. et al. The impact of responding to patient messages with large language model assistance. arXiv e-prints arXiv:2310.17703 \n(2023).\nScientific Reports |         (2025) 15:1143 5| https://doi.org/10.1038/s41598-024-84003-0\nwww.nature.com/scientificreports/\n 7. Kanjee, Z., Crowe, B. & Rodman, A. Accuracy of a generative artificial intelligence model in a complex diagnostic challenge. JAMA \n330, 78–80 (2023).\n 8. Singhal, K. et al. Large language models encode clinical knowledge. Nature 620, 172–180 (2023).\n 9. Elias, M. L., Burshtein, J. & Sharon, V . R. OpenAI’s GPT-4 performs to a high degree on board-style dermatology questions. Int. J. \nDermatol. 63, 73–78 (2024).\n 10. Sheng, B. et al. Large language models for diabetes care: potentials and prospects. Sci. Bull. (Beijing) 69, 583–588 (2024).\n 11. Nayak, A. et al. Use of voice-based conversational artificial intelligence for basal insulin prescription management among patients \nwith type 2 diabetes: a randomized clinical trial. JAMA Netw. Open 6, e2340232–e2340232 (2023).\n 12. Martinez-Cruz, C., Guerrero, J. F . G., Ruiz, J. L. L., Rueda, A. J. & Espinilla, M. 2023 A First Approach to the Generation of \nLinguistic Summaries from Glucose Sensors Using GPT-4. In Proceedings of the 15th International Conference on Ubiquitous \nComputing & Ambient Intelligence (UCAmI 2023) 33–43 Springer Nature Switzerland.  h t t p s : / / d o i . o r g / 1 0 . 1 0 0 7 / 9 7 8 - 3 - 0 3 1 - 4 8 6 4 2 - 5 \n_ 4       \n 13. Sng, G. G. R., Tung, J. Y . M., Lim, D. Y . Z. & Bee, Y . M. Potential and pitfalls of ChatGPT and natural-language artificial intelligence \nmodels for diabetes education. Diabetes Care 46, e103–e105 (2023).\n 14. Tayebi Arasteh, S. et al. Large language models streamline automated machine learning for clinical studies. Nat. Commun. 15, 1603 \n(2024).\n 15. Wang, L., Ge, X., Liu, L. & Hu, G. Code Interpreter for bioinformatics: are we there yet?. Ann. Biomed. Eng. 52, 754–756 (2024).\n 16. OpenAI, Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I. et al. GPT-4 Technical Report. arXiv [cs.CL]. 2023. Available: \nhttp://arxiv.org/abs/2303.08774\n 17. OpenAI. Data Analyst by ChatGPT. 2024. https://chat.openai.com/g/g-HMNcP6w7d-data-analyst (accessed Feb 5, 2024).\n 18. Jinyu Xie. Simglucose v0.2.1 (2018) [Online]. Available: https://github.com/jxx123/simglucose. Accessed on: 11–09–2023.\n 19. Man, C. D. et al. The UV A/PADOV A Type 1 diabetes simulator: new features. J. Diabetes Sci. Technol. 8, 26–34 (2014).\n 20. Czupryniak, L. et al. Ambulatory glucose profile (AGP) report in daily care of patients with diabetes: practical tips and \nrecommendations. Diabetes Ther. 13, 811–821 (2022).\n 21. Battelino, T. et al. Clinical targets for continuous glucose monitoring data interpretation: recommendations from the international \nconsensus on time in range. Diabetes Care 42, 1593–1603 (2019).\n 22. ElSayed, N. A. et al. 6. Glycemic Targets: Standards of Care in Diabetes—2023. Diabetes Care 46, S97–S110 (2022).\n 23. Broll, S. et al. Interpreting blood glucose data with R package iglu. PloS. One 16(4), e0248560 (2021).\n 24. Chun, E., Broll, S., Buchanan, D., Muschelli, J., Fernandes, N., Seo, J., Shih, J., Urbanek, J., Schwenck, J., Gaynanova, I. iglu: \nInterpreting Glucose Data from Continuous Glucose Monitors. R package version 3.5.0. (2023).\n 25. Gwet, K. L. Computing inter-rater reliability and its variance in the presence of high agreement. Br. J. Math. Stat. Psychol. 61, 29–48 \n(2008).\n 26. Gwet, K. L. irrCAC: Computing Chance-Corrected Agreement Coefficients (CAC), R Package version 1.0. (2019).\n 27. Danne, T. et al. International consensus on use of continuous glucose monitoring. Diabetes Care 40, 1631–1640 (2017).\nAcknowledgements\nThis work was supported by the National Science Foundation Graduate Research Fellowship Program under \ngrant number 2141064. KLF is supported by the National Institute of Diabetes and Digestive and Kidney Dis -\neases (NIDDK grant T32DK007028).\nAuthor contributions\nE.H. curated the data and results and wrote the initial draft. A.T.,  K.F ., J.R. assisted in evaluation and interpreta-\ntion of results.  I.K. supervised the project.  All authors reviewed and edited the manuscript.\nFunding\nThis work was supported by the National Science Foundation Graduate Research Fellowship Program under \ngrant number 2141064. KLF is supported by the National Institute of Diabetes and Digestive and Kidney Dis -\neases (NIDDK grant T32DK007028).\nDeclarations\nCompeting interests\nE.H. is supported by the National Science Foundation Graduate Research Fellowship Program. J.R. is a Fellow \nin the Pediatric Scientist Development Program supported by the Cystic Fibrosis Foundation. All other authors \nreport no conflicts of interests.\nAdditional information\nSupplementary Information The online version contains supplementary material available at  h t t p s : / / d o i . o r g / 1 \n0 . 1 0 3 8 / s 4 1 5 9 8 - 0 2 4 - 8 4 0 0 3 - 0     .  \nCorrespondence and requests for materials should be addressed to E.H.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nScientific Reports |         (2025) 15:1143 6| https://doi.org/10.1038/s41598-024-84003-0\nwww.nature.com/scientificreports/\nOpen Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give \nappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and \nindicate if changes were made. The images or other third party material in this article are included in the article’s \nCreative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included \nin the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or \nexceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy \nof this licence, visit http://creativecommons.org/licenses/by/4.0/.\n© The Author(s) 2025 \nScientific Reports |         (2025) 15:1143 7| https://doi.org/10.1038/s41598-024-84003-0\nwww.nature.com/scientificreports/"
}