{
  "title": "COVID-19 Tweets Analysis through Transformer Language Models",
  "url": "https://openalex.org/W3134146412",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5018911648",
      "name": "Abdul Hameed Azeemi",
      "affiliations": [
        "Information Technology University"
      ]
    },
    {
      "id": "https://openalex.org/A5050341915",
      "name": "Adeel Waheed",
      "affiliations": [
        "Information Technology University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3022261834",
    "https://openalex.org/W3013571468",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2147194983",
    "https://openalex.org/W2049271634",
    "https://openalex.org/W854920577",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3025477721"
  ],
  "abstract": "Understanding the public sentiment and perception in a healthcare crisis is essential for developing appropriate crisis management techniques. While some studies have used Twitter data for predictive modelling during COVID-19, fine-grained sentiment analysis of the opinion of people on social media during this pandemic has not yet been done. In this study, we perform an in-depth, fine-grained sentiment analysis of tweets in COVID-19. For this purpose, we perform supervised training of four transformer language models on the downstream task of multi-label classification of tweets into seven tone classes: [confident, anger, fear, joy, sadness, analytical, tentative]. We achieve a LRAP (Label Ranking Average Precision) score of 0.9267 through RoBERTa. This trained transformer model is able to correctly predict, with high accuracy, the tone of a tweet. We then leverage this model for predicting tones for 200,000 tweets on COVID-19. We then perform a country-wise analysis of the tone of tweets, and extract useful indicators of the psychological condition about the people in this pandemic.",
  "full_text": "COVID-19 Tweets Analysis through Transformer Language Models\nAbdul Hameed Azeemi\nInformation Technology University\nmsds19003@itu.edu.pk\nAdeel Waheed\nInformation Technology University\nmsds19030@itu.edu.pk\n1. Abstract\nUnderstanding the public sentiment and perception in\na healthcare crisis is essential for developing appropriate\ncrisis management techniques. While some studies have\nused Twitter data for predictive modelling during COVID-\n19, ﬁne-grained sentiment analysis of the opinion of peo-\nple on social media during this pandemic has not yet been\ndone. In this study, we perform an in-depth, ﬁne-grained\nsentiment analysis of tweets in COVID-19. For this pur-\npose, we perform supervised training of four transformer\nlanguage models on the downstream task of multi-label\nclassiﬁcation of tweets into seven tone classes: [conﬁ-\ndent, anger, fear, joy, sadness, analytical, tentative]. We\nachieve a LRAP (Label Ranking Average Precision) score\nof 0.9267 through RoBERTa. This trained transformer\nmodel is able to correctly predict, with high accuracy, the\ntone of a tweet. We then leverage this model for predicting\ntones for 200,000 tweets on COVID-19. We then perform\na country-wise analysis of the tone of tweets, and extract\nuseful indicators of the psychological condition about the\npeople in this pandemic.\n2. Introduction\nCOVID-19 has affected more than 11 million people\nall around the world as of 28 May 2020. The overall\npublic sentiment on Twitter during this global pandemic\nhas largely echoed the real world events and the situa-\ntion prevailing in that region. During COVID-19, people\nhave extensively used social media platforms, particularly\nTwitter, for conveying medical information, conveying the\nstats, expressing emotions and alerting other people of the\nimpending danger.\nIn the past, global health events have shown that so-\ncial media surveillance systems can be successfully uti-\nlized to extract the public sentiment and perception instan-\ntaneously [6, 5, 9]. In this scenario, the biggest advantage\nof a social media platform such as Twitter is its global, in-\nstantaneous coverage, which makes it highly suitable for\nuse in real-time, adaptive alert systems.\nDespite the emergence of a number of works on the\nsocial media analysis of COVID-19 tweets, ﬁne-grained\nsentiment analysis still remains an unexplored area in this\nregard. Particularly, there is a need of a system that can re-\nliably extract tone of the ever-growing number of COVID-\n19 tweets, and then use it to make reliable judgements\nabout the public sentiment.\nIn this project, we tackle the problem of multi-label\nclassiﬁcation of tweets into multiple tone classes (angry,\nsad, analytical etc.). We train a transformer based lan-\nguage model on this task (RoBERTa) and use it for pre-\ndicting the tone of a large number of tweets.\nGithub: https://github.com/ahazeemi/\nMSDS19003_Project_DLSpring2020\n3. Related Work\nA wealth of recent studies have utilized the tweets dur-\ning this pandemic for extracting useful information and\npresenting insights into the public health. Particularly,\nsentiment analysis has been utilized in the analysis of\nlockdown life [10], topic modelling has been used for\nthe analysis of the response of politicians [8] and situa-\ntion forecasting has been leveraged for surfacing the tech-\nniques of crisis management [4] during COVID-19.\nA recent, useful study uses causal inference approach\nthrough bayesian networks to discover and quantify causal\nrelationships between pandemic characteristics (e.g. num-\nber of infections and deaths) and Twitter activity as well\nas public sentiment [3]. The authors use DistilBERT for\nsentiment analysis of the tweets. The model labels each\ntweet with a sentiment of POSTIVE or NEGATIVE. This\nsentiment is then related to the country-wide statistics for\n12 countries: Italy, Spain, Germany, France, Switzer-\nland, United Kingdom, Netherlands, Norway, Austria,\nBelgium, Sweden, and Denmark.\nThis work is closely related to our study as it uses a\ntransformer-based model (BERT) for analyzing COVID-\n19 tweets and then relating it to the country-wide statis-\ntics. However, the type of sentiment analysis in this pa-\nper produces a boolean output i.e. POSITIVE or NEGA-\nTIVE. On the other hand, our study relates to labelling of\nCOVID-19 tweets with some of the seven tone classes:\n[conﬁdent, anger, fear, joy, sadness, analytical, tenta-\ntive] through transformer based language models. Hence,\nour problem is essentially multi-label tweet classiﬁcation\nthrough transformer language models.\nSince we will be using transformer-based language\nmodels, we have selected four popular transformer LM\nmodels: BERT, RoBERTa, XLNet and ELECTRA which\nachieve high accuracy on natural language understanding\ntasks.\nBERT [2]: BERT is based on transformer architecture. It\nis designed to pre-train bidirectional representations from\nunlabeled text by jointly conditioning on both left and\nright context. As a result, the pre-trained BERT model can\nbe ﬁne-tuned with just one additional output layer to cre-\nate state-of-the-art models for a wide range of NLP tasks.\n1\narXiv:2103.00199v1  [cs.CL]  27 Feb 2021\nBERT is pre-trained on two NLP tasks. 1. Masked Lan-\nguage Models 2. Next Sentence Prediction\nELECTRA [1]: ELECTRA (Efﬁciently Learning an En-\ncoder that Classiﬁes Token Replacements Accurately) is\na new pre-training approach which aims to match or ex-\nceed the downstream performance of an MLM (Masked\nLanguage Model) pre-trained model while using signiﬁ-\ncantly less compute resources for the pre-training stage.\nThe pre-training task in ELECTRA is based on detecting\nreplaced tokens in the input sequence. This setup requires\ntwo Transformer models, a generator and a discriminator.\nROBERTA [7]: RoBERTa is an optimized BERT Pre-\ntraining Approach. RoBERTa performs better than BERT\nby applying the following adjustments:\n1. RoBERTa uses BookCorpus (16G), CC-NEWS\n(76G), OpenWebText (38G) and Stories (31G) data\nwhile BERT only uses BookCorpus as training data\nonly.\n2. BERT masks training data once for MLM objective\nwhile RoBERTa duplicates training data 10 times and\nmasks this data differently.\nXLNet [11]: XLNET is a generalized autoregressive\n(AR) model where next token is dependent on all previ-\nous tokens. XLNET is generalized because it captures\nbi-directional context by means of a mechanism called\npermutation language modeling. AR language model is\na kind of model that using the context word to predict the\nnext word. But here the context word is constrained to\ntwo directions, either forward or backward. BERT out-\nperforms previous LMs but XLNET outperforms BERT. It\nuses the [MASK] in the pretraining but this kind of sym-\nbols are absent from real data at ﬁne-tuning time result-\ning in a pretrain-ﬁnetune discrepancy. XLNET proposes\na new a way to avoid the disadvantages brought by the\n[MASK] method in BERT. In pre-train phase, XLNET\nproposed a new objective called Permutation Language\nModeling. This objective learns contextual text represen-\ntation using permutation of input.\n4. Dataset\nThe dataset consists of 658,967 COVID-19 tweets of\nseven days (from 25-03-2020 to 31-03-2020). The tweets\nin the dataset were extracted using these hashtags: [”iso-\nlation”, ”social distance”, ”socialdistancing”, ”socialdis-\ntancing”, ”conﬁned”, ”stayathome”, ”covid”, ”stayath-\nome”, ”sath”, ”corona”, ”covid-19”, ”quarantine”, ”iso-\nlation”, ”untiltomorow”, ”homeofﬁce”]. This dataset con-\ntains the following columns: user-id, tweet, tweet-id, fol-\nlowers, location. The data cleanup and tone extraction\nmethodology is as under:\n1. Only the tweets with retweet count > 1 were kept.\nThis removes most of the bot-generated tweets and\nresults in a high-quality dataset. The count of the\nresulting tweets is 20,200.\n2. The tweets were grouped by the date they were\nposted, and randomly 2000 tweets were extracted\nfrom each day. The resulting tweets were 12,461 in\nnumber.\nTone Number of Tweets\nAnger 268\nAnalytical 4364\nTentative 3136\nConﬁdent 2373\nSadness 1405\nFear 287\nJoy 4274\nTable 1. Number of tweets belonging to each tone. The total\nnumber of tweets is 12,461\n3. The tone for each of these tweets was extracted using\nthe IBM Watson Tone Analyzer API. The API tags a\npiece of text with one of these seven tone classes:\n[conﬁdent, anger, fear, joy, sadness, analytical, tenta-\ntive]. A tone is only assigned to a text if it has been\npredicted with high probability (>0.5).\nFigure 1. The number of tweets of each tone per day\n5. Methodology\nWe leverage transfer learning for training a model that\ncan accurately predict the tone of any given text. There are\ntwo steps in the application of transfer learning in NLP:\n1. Unsupervised training on large amounts of text (e.g.\nwikipedia, books etc.) The output of this step is a\ntrained model (e.g. BERT) which has captured the\npatterns of a language like english.\n2. Supervised ﬁnetuning on a downstream task with a\nlabelled dataset e.g. text classiﬁcation, sentiment\nanalysis etc.\nIn our case, we selected four transformer based models\nthat had already been trained through step 1: RoBERTa,\nElectra, XLNet, BERT. We then performed supervised\nﬁnetuning of these transformer models on the downstream\ntask of tone classiﬁcation into seven classes. This part es-\nsentially adapts the transformer parameters to the super-\nvised target task.\nThe whole pipeline is as under:\n1. We collect 600,000 COVID-19 tweets which contain\nthe following information: user-id, tweet, tweet-id,\nfollowers, location.\n2. We preprocess this dataset to retain high-quality\ntweets.\n3. We label the tone 12,000 tweets using IBM watson\ntone analyzer API.\n4. We perform supervised ﬁne-tuning of multiple trans-\nformer language models on this dataset (RoBERTA,\nBERT, XLnet, Electra).\n2\n5. We predict the tone of 200,000 COVID19 tweets us-\ning this trained model.\n6. Lastly, we extract useful insights about the psycho-\nlogical condition of people throughout the timeline\nof COVID-19 pandemic.\nFigure 2. Methodology\n6. Experimental Setup\nWe perform supervised ﬁne-tuning of RoBERTA,\nBERT-base, XLnet and Electra. Since supervised ﬁne-\ntuning may take a large footprint on GPU memory, we\nleverage FP16 computation to reduce the size of the\nmodel. We set the learning to 0.00003. The maximum\nlength of sequence is set to 250. The number of subbatch\nis set to 2. We use Adam optimizer and set the learning\nrate to be 3e-5. We train 3 epochs and set the gradient\naccumulation steps to 16.\nTotal tweets were 12,459. Train test split was 80-20.\nFor training the models, we use the SimpleTransform-\ners library built on top of PyTorch. Tesla P4 GPU was\nused for training (on GoogleColab).\n7. Results\nWe report the Label Ranking Average Precision\n(LRAP) for each of the four models.\nGiven a binary indicator matrix of ground-truth labels:\ny∈{0,1}nsamples∗nlabels\nThe score associated with each label is denoted by ˆf\nwhere\nˆfϵ{R}nsamples∗nlabels\nThen LRAP is calculated as:\nLRAP(y, ˆf) = 1\nnsamples\n∗\nnsamples−1∑\ni=0\n1\n∥yi∥0\n∑\nj:yij=1\n|Lij|\nrankij\nRoBERTa achieves the highest LRAP of 0.9267 on the\ntest set (Table. 2 ). It took 41m 8s to train, which is a\nreasonable training time on this dataset. The fastest trans-\nformer model was Electra which took only 16m for su-\npervised ﬁne-tuning, although this came at the cost of a\nreduced ﬁnal LRAP of 0.8553.\nFigure 3. LRAP per step.\nFigure 4. Loss on the evaluation set per iteration.\nMethod Running Time LRAP Eval Loss\nRoBERTa 41m 8s 0.9267 0.2254\nBERT 40m 22s 0.9207 0.2285\nXLNet 1h 8m 40s 0.9099 0.2428\nElectra Small 16m 30s 0.8553 0.3142\nTable 2. Comparison of ﬁne-tuning four transformer language\nmodels on the task of multi-label tweet classiﬁcation into seven\ntone classes. RoBERTa achieves the highest Label Ranking Av-\nerage Precision (LRAP) score of 0.9267. Electra Small was the\nfastest to train(16m30s) whereas XLNet took the longest time to\ntrain (1h 8m)\n8. Extracting Tone and Location\nWe label the tones of 658,967 tweets using the trained\nRoBERTa model. The output of the model is a vector\nof probabilities for each of the seven tone classes. For\neach tweet, this vector is thresholded at 0.5, i.e. a tweet\nis classiﬁed as belonging to a certain tone only if that\ntone has been predicted with a probability greater than\n0.5. This retains tones that have been predicted with high\nconﬁdence.\nNext, we extract the location of users by geoparsing\nthe location text in their proﬁles. We drop the tweets\nauthored by users who have no location information. The\nresulting location tagged tweets are 233,762 in number.\nDivision of these tweets amongst the seven tones is given\nin Table. 3.\n9. Tweets Analysis\nWe perform analysis on the resulting dataset containing\ntones and location corresponding to each tweet.\nWe deﬁne two simple mood indicators for the people of a\nparticular country: Happiness Indicator (HI) and Sadness\nIndicator (SI):\n3\nTone Number of Tweets\nAnger 2997\nAnalytical 58717\nTentative 59850\nConﬁdent 34293\nSadness 23050\nFear 1163\nJoy 58632\nTable 3. Number of tweets belonging to each tone in the ﬁnal\nlabelled dataset of 233,762 tweets.\nHI = NumberofTweetswithJoyTone\nTotalNumberofTweets\nSI = NumberofTweetswithSadTone\nTotalNumberofTweets\nThese two indicators essentially describe the ratio of\nthe sad or joyful tweets in a particular country.\nHappiest Countries We utilize HI to rank countries\nin the order of how joyful the tweets were in that country\nbetween the time-period of 25th-31st March. The results\nare shown in table 4.\nSaddest Countries We utilize SI to rank countries\nin the order of how sad the tweets were in that country\nbetween the time-period 25th-31st March. The results are\nshown in table 5.\nWe hypothesize from these results that the psycholog-\nical condition of the people within a particular country\nin the early phases of COVID19 outbreak (25th to 31st\nMarch) seems to be greatly inﬂuenced by the perceived\nlevel of healthcare facilities or the ability of that country\nto cope with such a pandemic. The countries included\nin table 5 (sad sentiment) can be mostly characterized as\nhaving lesser perceived ability to deal with a healthcare\ncrises (Botswana, Namibia, Canada, Zimbabwe, Tonga).\nA study of tweets on a larger time period (e.g. Jan to July)\nwill be be better able to conﬁrm this hypothesis.\nTemporal Analysis of Tweets We visualize the\ncountry-wise tone of tweets on a temporal chart (Figure\n4.) We can see the varied sentiment of people in each of\nthe six different countries. The most popular tones are:\n[Analytical, Tentative, Joy].\n10. Conclusion\nIn this project, we trained a transformer based language\nmodel, RoBERTa, on the task of multilabel tone classiﬁ-\ncation in tweets. After achieving a LRAP score of 0.92,\nwe used the trained transformer model for predicting the\ntone of a large number of tweets. The resulting tweets\nwere used for performing a country-wise analysis. We hy-\npothesized from these results that the psychological con-\ndition of the people within a particular country in the early\nphases of COVID19 outbreak (25th to 31st March) seems\nNo. Country Joy Sadness HI\n1 Spain 417 90 4.63\n2 Germany 1158 261 4.43\n3 France 595 153 3.88\n4 Cayman Islands 356 94 3.78\n5 Ghana 737 205 3.59\n6 Ireland 1996 577 3.45\n7 Holy See 713 210 3.39\n8 New Caledonia 1005 298 3.37\n9 Mongolia 443 132 3.35\n10 Macao 351 105 3.34\nTable 4. Countries ranked according to the happiness indicator\nof tweets\nNo. Country Sadness Joy SI\n1 Botswana 48 52 0.92\n2 Namibia 53 72 0.73\n3 Kenya 619 894 0.69\n4 Zambia 47 68 0.69\n5 Iceland 82 124 0.66\n6 Japan 75 115 0.65\n7 Zimbabwe 76 131 0.58\n8 Nepal 48 86 0.55\n9 Tonga 168 304 0.55\n10 Norway 88 162 0.54\nTable 5. Countries ranked according to the sadness indicator of\ntweets\nto be greatly inﬂuenced by the perceived level of health-\ncare facilities or the ability of that country to cope with\nsuch a pandemic. The countries ranking higher in sad sen-\ntiment can be mostly characterized as having lesser per-\nceived ability to deal with a healthcare crises (Botswana,\nNamibia, Canada, Zimbabwe, Tonga). A study of tweets\non a larger time period (e.g. Jan to July) will be be better\nable to conﬁrm this hypothesis.\nReferences\n[1] K. Clark, M.-T. Luong, Q. V . Le, and C. D. Manning. Elec-\ntra: Pre-training text encoders as discriminators rather than\ngenerators. arXiv preprint arXiv:2003.10555, 2020.\n[2] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert:\nPre-training of deep bidirectional transformers for lan-\nguage understanding. arXiv preprint arXiv:1810.04805,\n2018.\n[3] O. Gencoglu and M. Gruber. Causal modeling of twitter\nactivity during covid-19.arXiv preprint arXiv:2005.07952,\n2020.\n[4] E. Gharavi, N. Nazemi, and F. Dadgostari. Early out-\nbreak detection for proactive crisis management using twit-\nter data: Covid-19 a case study in the us. arXiv preprint\narXiv:2005.00475, 2020.\n[5] X. Ji, S. A. Chun, and J. Geller. Monitoring public health\nconcerns using twitter sentiment classiﬁcations. In 2013\nIEEE International Conference on Healthcare Informatics,\npages 335–344. IEEE, 2013.\n[6] X. Ji, S. A. Chun, Z. Wei, and J. Geller. Twitter sentiment\nclassiﬁcation for measuring public health concerns. Social\nNetwork Analysis and Mining, 5(1):13, 2015.\n4\nFigure 5. Temporal analysis of the tone of tweets in each of 6\ncountries\n[7] Y . Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen,\nO. Levy, M. Lewis, L. Zettlemoyer, and V . Stoyanov.\nRoberta: A robustly optimized bert pretraining approach.\narXiv preprint arXiv:1907.11692, 2019.\n[8] H. Sha, M. A. Hasan, G. Mohler, and P. J. Brantingham.\nDynamic topic modeling of the covid-19 twitter narrative\namong us governors and cabinet executives.arXiv preprint\narXiv:2004.11692, 2020.\n[9] A. Signorini, A. M. Segre, and P. M. Polgreen. The use of\ntwitter to track levels of disease activity and public concern\nin the us during the inﬂuenza a h1n1 pandemic. PloS one,\n6(5):e19467, 2011.\n[10] M. Thelwall and S. Thelwall. Retweeting for covid-\n19: Consensus building, information sharing, dissent, and\nlockdown life. arXiv preprint arXiv:2004.02793, 2020.\n[11] Z. Yang, Z. Dai, Y . Yang, J. Carbonell, R. R. Salakhutdi-\nnov, and Q. V . Le. Xlnet: Generalized autoregressive pre-\ntraining for language understanding. In Advances in neural\ninformation processing systems, pages 5753–5763, 2019.\n5",
  "topic": "Sentiment analysis",
  "concepts": [
    {
      "name": "Sentiment analysis",
      "score": 0.8322296142578125
    },
    {
      "name": "Transformer",
      "score": 0.6330879926681519
    },
    {
      "name": "Disgust",
      "score": 0.617481529712677
    },
    {
      "name": "Anger",
      "score": 0.6067396402359009
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.6056922078132629
    },
    {
      "name": "Sadness",
      "score": 0.5793504118919373
    },
    {
      "name": "Computer science",
      "score": 0.5567947626113892
    },
    {
      "name": "Social media",
      "score": 0.5181192755699158
    },
    {
      "name": "Coronavirus disease 2019 (COVID-19)",
      "score": 0.5108632445335388
    },
    {
      "name": "Credibility",
      "score": 0.45386385917663574
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4360882043838501
    },
    {
      "name": "Natural language processing",
      "score": 0.41398561000823975
    },
    {
      "name": "Machine learning",
      "score": 0.36730819940567017
    },
    {
      "name": "Psychology",
      "score": 0.34808942675590515
    },
    {
      "name": "Social psychology",
      "score": 0.15012234449386597
    },
    {
      "name": "World Wide Web",
      "score": 0.13964515924453735
    },
    {
      "name": "Engineering",
      "score": 0.12308099865913391
    },
    {
      "name": "Political science",
      "score": 0.11309641599655151
    },
    {
      "name": "Disease",
      "score": 0.0
    },
    {
      "name": "Medicine",
      "score": 0.0
    },
    {
      "name": "Pathology",
      "score": 0.0
    },
    {
      "name": "Infectious disease (medical specialty)",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1323252656",
      "name": "Information Technology University",
      "country": "PK"
    }
  ],
  "cited_by": 1
}