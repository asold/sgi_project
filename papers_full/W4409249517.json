{
  "title": "Prompting large language models to extract chemical‒disease relation precisely and comprehensively at the document level: an evaluation study",
  "url": "https://openalex.org/W4409249517",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2085608437",
      "name": "Mei Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1996870650",
      "name": "Tingting Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2100654968",
      "name": "Shibin Wang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4392748392",
    "https://openalex.org/W4399361544",
    "https://openalex.org/W4385665820",
    "https://openalex.org/W4282984139",
    "https://openalex.org/W4392384979",
    "https://openalex.org/W4392002118",
    "https://openalex.org/W4391836235",
    "https://openalex.org/W2346452181",
    "https://openalex.org/W4308760226",
    "https://openalex.org/W4303648559",
    "https://openalex.org/W4399807068",
    "https://openalex.org/W4391971084",
    "https://openalex.org/W4311642023"
  ],
  "abstract": "Given the scarcity of annotated data, current deep learning methods face challenges in the field of document-level chemical-disease relation extraction, making it difficult to achieve precise relation extraction capable of identifying relation types and comprehensive extraction tasks that identify relation-related factors. This study tests the abilities of three large language models (LLMs), GPT3.5, GPT4.0, and Claude-opus, to perform precise and comprehensive extraction in document-level chemical-disease relation extraction on a self-constructed dataset. Firstly, based on the task characteristics, this study designs six workflows for precise extraction and five workflows for comprehensive extraction using prompting engineering strategies. The characteristics of the extraction process are analyzed through the performance differences under different workflows. Secondly, this study analyzes the content bias in LLMs extraction by examining the extraction effectiveness of different workflows on different types of content. Finally, this study analyzes the error characteristics of extracting incorrect examples by the LLMs. The experimental results show that: (1) The LLMs demonstrate good extraction capabilities, achieving the highest F1 scores of 87% and 73% respectively in the tasks of precise extraction and comprehensive extraction; (2) In the extraction process, the LLMs exhibit a certain degree of stubbornness, with limited effectiveness of prompting engineering strategies; (3) In terms of extraction content, the LLMs show a content bias, with stronger abilities to identify positive relations such as induction and acceleration; (4) The essence of extraction errors lies in the LLMs’ misunderstanding of the implicit meanings in biomedical texts. This study provides practical workflows for precise and comprehensive extraction of document-level chemical-disease relations and also indicates that optimizing training data is the key to building more efficient and accurate extraction methods in the future.",
  "full_text": null,
  "topic": "Relationship extraction",
  "concepts": [
    {
      "name": "Relationship extraction",
      "score": 0.7496211528778076
    },
    {
      "name": "Workflow",
      "score": 0.725310742855072
    },
    {
      "name": "Computer science",
      "score": 0.6171472072601318
    },
    {
      "name": "Relation (database)",
      "score": 0.5248020887374878
    },
    {
      "name": "Process (computing)",
      "score": 0.5216448903083801
    },
    {
      "name": "Extraction (chemistry)",
      "score": 0.4500853419303894
    },
    {
      "name": "Natural language processing",
      "score": 0.4088178277015686
    },
    {
      "name": "Artificial intelligence",
      "score": 0.38993895053863525
    },
    {
      "name": "Information extraction",
      "score": 0.335676372051239
    },
    {
      "name": "Data mining",
      "score": 0.20595014095306396
    },
    {
      "name": "Chemistry",
      "score": 0.09757637977600098
    },
    {
      "name": "Database",
      "score": 0.0
    },
    {
      "name": "Chromatography",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ]
}