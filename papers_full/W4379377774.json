{
  "title": "Comparing neural language models for medical concept representation and patient trajectory prediction",
  "url": "https://openalex.org/W4379377774",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2753436674",
      "name": "Alban Bornet",
      "affiliations": [
        "University of Geneva"
      ]
    },
    {
      "id": "https://openalex.org/A2775153052",
      "name": "Dimitrios Proios",
      "affiliations": [
        "University of Geneva",
        "HES-SO University of Applied Sciences and Arts Western Switzerland"
      ]
    },
    {
      "id": "https://openalex.org/A4314030486",
      "name": "Anthony Yazdani",
      "affiliations": [
        "HES-SO University of Applied Sciences and Arts Western Switzerland",
        "University of Geneva"
      ]
    },
    {
      "id": "https://openalex.org/A2725953826",
      "name": "Fernando Jaume-Santero",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1986054831",
      "name": "Guy Haller",
      "affiliations": [
        "University Hospital of Geneva",
        "Monash University"
      ]
    },
    {
      "id": "https://openalex.org/A2183278384",
      "name": "Edward Choi",
      "affiliations": [
        "Korea Advanced Institute of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2234087575",
      "name": "Douglas Teodoro",
      "affiliations": [
        "University of Geneva"
      ]
    },
    {
      "id": "https://openalex.org/A2753436674",
      "name": "Alban Bornet",
      "affiliations": [
        "University of Geneva"
      ]
    },
    {
      "id": "https://openalex.org/A2775153052",
      "name": "Dimitrios Proios",
      "affiliations": [
        "HES-SO University of Applied Sciences and Arts Western Switzerland",
        "University of Geneva"
      ]
    },
    {
      "id": "https://openalex.org/A4314030486",
      "name": "Anthony Yazdani",
      "affiliations": [
        "University of Geneva",
        "HES-SO University of Applied Sciences and Arts Western Switzerland"
      ]
    },
    {
      "id": "https://openalex.org/A1986054831",
      "name": "Guy Haller",
      "affiliations": [
        "Monash Health",
        "University Hospital of Geneva",
        "Monash University"
      ]
    },
    {
      "id": "https://openalex.org/A2183278384",
      "name": "Edward Choi",
      "affiliations": [
        "Korea Advanced Institute of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2234087575",
      "name": "Douglas Teodoro",
      "affiliations": [
        "University of Geneva"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2612374874",
    "https://openalex.org/W1997057722",
    "https://openalex.org/W2004910511",
    "https://openalex.org/W2257962105",
    "https://openalex.org/W2551716331",
    "https://openalex.org/W2166213950",
    "https://openalex.org/W2580767461",
    "https://openalex.org/W2152845372",
    "https://openalex.org/W980140715",
    "https://openalex.org/W2059531989",
    "https://openalex.org/W1441192051",
    "https://openalex.org/W2151068025",
    "https://openalex.org/W1974660612",
    "https://openalex.org/W1808652302",
    "https://openalex.org/W2179498003",
    "https://openalex.org/W2060947741",
    "https://openalex.org/W1441560749",
    "https://openalex.org/W2606513243",
    "https://openalex.org/W236448318",
    "https://openalex.org/W2168057267",
    "https://openalex.org/W2057443209",
    "https://openalex.org/W2128124510",
    "https://openalex.org/W2103742358",
    "https://openalex.org/W2607113351",
    "https://openalex.org/W2204794060",
    "https://openalex.org/W2120751691",
    "https://openalex.org/W2594685110",
    "https://openalex.org/W3163217846",
    "https://openalex.org/W1568685344",
    "https://openalex.org/W1971676632",
    "https://openalex.org/W2591382767",
    "https://openalex.org/W2982149480",
    "https://openalex.org/W2525984666",
    "https://openalex.org/W4224277562",
    "https://openalex.org/W3092301826",
    "https://openalex.org/W2557074642",
    "https://openalex.org/W2997494090",
    "https://openalex.org/W2610332124",
    "https://openalex.org/W2625625371",
    "https://openalex.org/W2805089815",
    "https://openalex.org/W3095676345",
    "https://openalex.org/W2963532813",
    "https://openalex.org/W1981276685",
    "https://openalex.org/W2481271618",
    "https://openalex.org/W2511950764",
    "https://openalex.org/W3088911909",
    "https://openalex.org/W2556399337",
    "https://openalex.org/W2768114048",
    "https://openalex.org/W3190901875",
    "https://openalex.org/W2789244308",
    "https://openalex.org/W2947903144",
    "https://openalex.org/W1902526473",
    "https://openalex.org/W3136253378",
    "https://openalex.org/W4294052933",
    "https://openalex.org/W3196995059",
    "https://openalex.org/W6632983741",
    "https://openalex.org/W3152019416",
    "https://openalex.org/W3113725046",
    "https://openalex.org/W3087156149",
    "https://openalex.org/W4293812381",
    "https://openalex.org/W3026804883",
    "https://openalex.org/W3211037369",
    "https://openalex.org/W3082810340",
    "https://openalex.org/W2903877319",
    "https://openalex.org/W2584780866",
    "https://openalex.org/W2367952659",
    "https://openalex.org/W4312590844",
    "https://openalex.org/W3112116031",
    "https://openalex.org/W2964233659",
    "https://openalex.org/W3160137267",
    "https://openalex.org/W2963626623",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2997522493",
    "https://openalex.org/W2560219888",
    "https://openalex.org/W2963923670",
    "https://openalex.org/W2936126040",
    "https://openalex.org/W4327813569",
    "https://openalex.org/W1934602670",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W2527672088",
    "https://openalex.org/W3014988774",
    "https://openalex.org/W4286242951",
    "https://openalex.org/W3165462110",
    "https://openalex.org/W2601243251",
    "https://openalex.org/W4244777963",
    "https://openalex.org/W2146774335",
    "https://openalex.org/W2160654481",
    "https://openalex.org/W4213013997",
    "https://openalex.org/W4309208605",
    "https://openalex.org/W1495323148",
    "https://openalex.org/W3129993689"
  ],
  "abstract": "Abstract Effective representation of medical concepts is crucial for secondary analyses of electronic health records. Neural language models have shown promise in automatically deriving medical concept representations from clinical data. However, the comparative performance of different language models for creating these empirical representations, and the extent to which they encode medical semantics, has not been extensively studied. This study aims to address this gap by evaluating the effectiveness of three popular language models – word2vec, fastText, and GloVe – in creating medical concept embeddings that capture their semantic meaning. By using a large dataset of digital health records, we created patient trajectories and used them to train the language models. We then assessed the ability of the learned embeddings to encode semantics through an explicit comparison with biomedical terminologies, and implicitly by predicting patient outcomes and trajectories with different levels of available information. Our qualitative analysis shows that empirical clusters of embeddings learned by fastText exhibit the highest similarity with theoretical clustering patterns obtained from biomedical terminologies, with a similarity score between empirical and theoretical clusters of 0.88, 0.80, and 0.92 for diagnosis, procedure, and medication codes, respectively. Conversely, for outcome prediction, word2vec and GloVe tend to outperform fastText, with the former achieving AUROC as high as 0.78, 0.62, and 0.85 for length-of-stay, readmission, and mortality prediction, respectively. In predicting medical codes in patient trajectories, GloVe achieves the highest performance for diagnosis and medication codes (AUPRC of 0.45 and of 0.81, respectively) at the highest level of the semantic hierarchy, while fastText outperforms the other models for procedure codes (AUPRC of 0.66). Our study demonstrates that subword information is crucial for learning medical concept representations, but global embedding vectors are better suited for more high-level downstream tasks, such as trajectory prediction. Thus, these models can be harnessed to learn representations that convey clinical meaning, and our insights highlight the potential of using machine learning techniques to semantically encode medical data.",
  "full_text": " \n \nComparing neural language models for medical concept \nrepresentation and patient trajectory prediction \nAlban Bornet1,*, Dimitrios Proios 1,2, Anthony Yazdani 1,2, Fernando Jaume-Santero 1, Guy Haller 3,4, Edward Choi 5, \nDouglas Teodoro1,* \n1 Department of Radiology and Medical Informatics, University of Geneva, Geneva, Switzerland \n2 Geneva School of Business Administration, HES-SO University of Applied Sciences and Arts of Western \nSwitzerland, Geneva, Switzerland \n3 Department of Acute Care Medicine, Division of Anaesthesiology, Geneva University Hospitals, Switzerland. \n4 Department of Epidemiology and Preventive Medicine, Health Services Management and Research Unit, \nMonash University, Melbourne Victoria, Australia. \n5 KAIST, Republic of Korea \n* Corresponding authors - {alban.bornet,douglas.teodoro}@unige.ch \nAbstract \nEffective representation of medical concepts is crucial for secondary analyses of electronic health \nrecords. Neural language models have shown promise in automatically deriving medical concept \nrepresentations from clinical data. However, the comparative performance of different language \nmodels for creating these empirical representations, and the extent to which they encode medical \nsemantics, has not been extensively studied. This study aims to address this gap by evaluating the \neffectiveness of three popular language models - word2vec, fastText, and GloVe - in creating medical \nconcept embeddings. By using a large dataset of digital health records, we created patient trajectories \nand used them to train the language models. We then assessed the ability of the learned embeddings \nto encode semantics through an explicit comparison with biomedical terminologies, and implicitly by \npredicting patient outcomes and trajectories with different degrees of information. Our qualitative \nanalysis shows that empirical clusters of embeddings learned by fastText exhibit the highest similarity \nwith theoretical clustering patterns obtained from biomedical terminologies, with a similarity score \nbetween empirical and theoretical clusters of 0.88, 0.80, and 0.92 for diagnosis, procedures, and \nmedication codes, respectively. Conversely, for outcome prediction, word2vec and GloVe tend to \noutperform fastText, with the former achieving AUROC as high as 0.80, 0.63, and 0.88 for length-of-\nstay, readmission, and mortality prediction, respectively. In predicting the next steps in patient \ntrajectories, GloVe achieves the highest performance for diagnostic and medication codes (AUPRC of \n0.46 and of 0.82, respectively) at the highest level of the semantic hierarchy, while fastText outperforms \nthe other models for procedure codes (AUPRC of 0.67). Our study demonstrates that subword \ninformation is crucial for learning medical concept representations, but global embedding vectors are \nbetter suited for downstream tasks, such as trajectory prediction. Thus, these models can be harnessed \nto learn representations that convey clinical meaning, and our insights highlight the potential of using \nmachine learning techniques to semantically encode medical data. \nKeywords: neural language models, medical concept embeddings, electronic health records, patient \ntrajectory prediction, clinical outcome prediction, biomedical terminologies, hierarchical clustering \n  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n \n \n1. Introduction \nWith the widespread adoption of electronic health record (EHR) systems in healthcare institutions, \nlarge-scale analysis of digitalized patient data for secondary usage offers great opportunities to improve \nclinical research and healthcare management [1–5]. It enables for example to identify patterns and \ntrends that can be used to estimate quality of care and clinical outcomes, such as the likelihood of \nadverse events [6–9] or poor outcomes [10–13]. This data can also be leveraged to automatically \ncharacterize specific phenotypes, such as disease subtypes [14–17] or treatment response profiles [18, \n19], and perform patient trajectory prediction [20–22], e.g., for clinical decision support [23–25] or real-\ntime mortality prediction [26–28]. However, healthcare data is complex, heterogeneous, and significant \nhuman curation and modeling are often required to represent clinical entities and capture intricate \nrelationships between them [29–31]. \nClassic approaches to abstract patient data and create homogeneous representations for secondary \nanalyses are based on data mappings [32–35], in which raw data are encoded using concepts from \nbiomedical knowledge organization systems [36], such as the International Classification of Diseases \n(ICD) [37] and the Anatomical Therapeutic Chemical (ATC) [38] classification systems, and the \nSystematized Nomenclature in Medicine – Clinical Terms (SNOMED-CT) ontology [39]. Despite the \nbenefits of these approaches for representing knowledge in EHRs and the facilitated semantic \ninteroperability, there are limitations and challenges that need to be considered. First, large human \nefforts are required to curate and annotate data, a resource that is often not at one’s disposal in \nhospitals [40–42]. Additionally, as data and information evolve, the lack of readily available and up-to-\ndate formal representations might hinder their application to the full extent of EHR data [43]. Lastly, \nthe resulting representations of medical concepts are highly dimensional, leading to sparse and \ncomputationally inefficient data structures (e.g., SNOMED-CT alone has more than 300’000 concepts). \nIn recent years, as a complementary alternative to fully semantic encoding, data-driven methods for \nEHR concept representation based on deep learning were proposed [44–47]. In contrast to knowledge-\nbased approaches, deep learning algorithms learn representations of patients and clinical concepts \nautomatically and directly from the data, with minimal pre-processing. The learnt representations are \ndense, low-dimensional vectors that can be used in many downstream tasks. This approach, known as \nmedical concept embedding, has already achieved promising results (for reviews: [48–51]). For \nexample, convolutional, long short-term memory, as well as attention-based neural networks were \ntrained with patient data to perform various patient trajectory prediction tasks [52–55]. Moreover, \nsimilar neural network architectures were used for automated phenotyping, by building \nrepresentations of structured [56–58], unstructured [59–62] EHR data, or both [63–65]. As a recent \nuse-case scenario, deep learning methods were applied to COVID-19-related EHR data for \nepidemiological prediction [66], automatic diagnosis [67], drug repurposing [68–71], or mortality risk \nassessment [72–74]. \nA key aspect of developing accurate patient and medical concept embeddings lies in abstracting and \nmodeling the relevant data features. In that respect, neural language models can process EHRs, not \nonly for clinical notes, but also by considering events in the patient trajectory as tokens, and entire \ntrajectories as a sequence of tokens, similar to word sentences [75–80]. Medical concepts relate to \neach other, either with causal relationships, e.g., diagnosis and medication, or through similar \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \nmeanings, e.g., related, or synonymous diagnoses or compounds with similar effects or indications. \nAnalogous to text, syntactic and semantic relationships among EHR concepts can thus be learned by \nneural language models: leveraging this inherent data structure was shown to improve representations \nof medical concepts and patients [47, 81]. For example, attention-based language models were trained \nwith sequences of clinical events and produced representations which improved performance for \ndisease prediction [53] as well as for length-of-stay, readmission, and mortality prediction [82, 83]. \nSeveral studies compared the advantages and shortcomings of popular neural language models, such \nas word2vec [84], fastText [85, 86] and Global Vectors for Word Representation (GloVe) [87], to create \nword embeddings when applied to clinical notes [88–91]. Still, no study has yet performed such a \ncomparison for medical concept code representations. In this work, we aim to assess the performance \nof neural language models to generate embeddings from patients’ stays at the hospital expressed as \nsequences of healthcare related event codes. In previous work, using the Medical Information Mart for \nIntensive Care (MIMIC) IV dataset [92], we showed that embeddings produced by word2vec provide \nuseful representations of medical concept codes [79]. In this work, we extend this study by comparing \nthe quality of embeddings produced by word2vec, fastText and GloVe. To do so, we create patient \ntrajectories as sequences of administrative, demographic, and clinical events using the MIMIC-IV \ndataset. Then, the different neural language models are trained to learn medical concept \nrepresentations from these trajectories. Finally, we qualitatively evaluate the extracted representations \nusing a clustering task (intrinsic evaluation) and quantitatively using binary and categorical trajectory \nprediction tasks (extrinsic evaluation). The code that we used to build patient trajectories, train the \nmodels, and evaluate them, is available on our repository1. \nThe contribution of this work can be summarized as follows: \n1. We compare popular neural language model architectures - word2vec, fastText and GloVe - \ntrained on patient trajectories created from sequences of medical codes and show that these \nlanguage models can produce data-driven embeddings that capture the semantic meaning of \nmedical concepts, as defined by biomedical terminologies. \n2. We evaluate the alignment between medical concept embeddings and biomedical \nterminologies and, using a clustering algorithm, we show that fastText naturally presents the \nhighest similarity to the different hierarchical levels of the terminologies, with a cluster \nsimilarity distance between 0.80 and 0.92 for diagnosis, procedure, and medication codes. \n3. We assess patient outcome prediction at different information levels and show that after 10% \nof the trajectory, the extracted embeddings can estimate mortality risks with performance \nabove 0.80 AUROC. On the other hand, using the full trajectory (i.e., 100% of patient tokens), \nwe can estimate readmission with performance of only around 0.60 AUROC. \n4. Lastly, we evaluate how much intrinsic information the learned embeddings encode to infer \nthe next events in the patient trajectory, i.e., diagnoses, procedures, and medication. We \ndemonstrate that while high-level information can be encoded by the embeddings, with \nperformance varying from 0.46 AUPRC for diagnosis codes to 0.82 AUPRC for medication codes, \nprediction performance decay exponentially with the increase of semantic granularity.\n \n \n1 https://github.com/ds4dh/medical_concept_representation \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \n2. Methodology \n2.1 MIMIC-IV dataset and pre-processing steps \nWe extracted 431,231 hospital stays from the 299,712 patients present in the MIMIC-IV database [92]. \nMIMIC-IV is a large, openly available dataset of de-identified EHRs from patients admitted to intensive \ncare units (ICUs) or to the emergency department at Beth Israel Deaconess Medical Center in Boston \nbetween 2008 and 2019. The dataset contains comprehensive clinical data, including vital signs, \nlaboratory results, medications, procedures, and diagnoses, as well as demographic information such \nas age, gender, and race. All entries in MIMIC-IV are associated with a patient and an admission \nidentifier, and most of them are (directly or indirectly) labeled with a timestamp. This allowed us to \nassemble sequences of events occurring during patients’ hospital stays. Each patient may be admitted \nseveral times at the hospital, and for each sequence of events happening between admission and \ndischarge time, we computed one sequence of events, which will be referred to as “patient trajectory” \nfrom now on. Each event was extracted from MIMIC-IV tables as a token which could encode a label \nassociated with the patient demographic, administrative information, or a medical event  (Figure 1). \nWe provide a detailed description of each token category in the supplementary information (Appendix \nA1). \n \nFigure 1. Patient trajectory sequence generation. Medical data was extracted from the MIMIC-IV database. Patient and \nadmission ids were used to parse the data and obtain one sequence per patient trajectory. Outcome labels and \ndemographic tokens were built using patient and admission data. Token sequences were built from the MIMIC tables, \nusing mappings from MIMIC or custom mappings. Tokens for location, procedures, abnormal lab events and medication \nprescriptions were sorted by datetime. Outcomes, demographic information, and ICD10-CM codes were prepended to \nthe sequence, because they do not have any associated datetime. ICD10-CM codes were sorted by priority. \nAs shown in Figure 1, patient trajectories were built by concatenating the tokens from the outcome \n(LBL), demographic (DEM), diagnosis (DIA), administrative (LOC), procedures (PROC), laboratory (LAB) \nand medication (MED) categories. The outcome and demographic tokens started each sequence, and \ndiagnosis codes came second, as a reason for intensive care hospitalization. The remaining tokens were \nappended to the sequence, after being sorted altogether by their associated datetimes (Figure 1). The \ndifferent token categories extracted from the MIMIC database are summarized in Table 1. \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \nCategory Content Encoding Token instances (#) Tokens per sequence (# ) \nLBL Labels for binary classification Custom  6 3.00 ± 0.00 \nDEM Gender, age, race Custom 37 3.28 ± 0.45 \nDIA Diagnoses and reason for visits ICD10-CM 9774 11.01 ± 7.29 \nLOC Care unit locations Custom 28 5.22 ± 2.99 \nPRO Procedures ICD10-PCS 4243 1.53 ± 2.40 \nLAB Lab results outside normal range Ids 398 49.39 ± 127.99 \nMED Medication prescriptions ATC 1122 31.57 ± 41.34 \nTable 1. Summary of the tokens used to build patient trajectory sequences. The number of tokens per sequence \nindicates the mean and the standard deviation, which were computed from the training dataset. Note that, in MIMIC-\nIV, all medications are stored as Generic Sequence Number (GSN) or National Drug Code (NDC) entries. We mapped \nthese entries to their Anatomical Therapeutic Chemical (ATC) code equivalents, by using the work of Kury et al. [93], \nwhich queries the online RxNorm API [94] automatically. ATC codes are hierarchically arranged following the target \nanatomical system of medications, as well as their therapeutic, pharmacological, and chemical effects. Appendix A1 \ndescribes in detail how we built the mapping, which we make available in our repository2. \nOnce all sequences were constructed, the dataset was split into training, validation and testing subsets, \ncontaining 345.3k, 43.5k, and 42.4k patient trajectory sequences, respectively. The splitting was based \non patient ids (80% for training, 10% for validation, 10% for testing) and not admission ids, which \nexplains the different number of samples for the validation and testing sets. This means that for any \npatient, all patient trajectories were included in the same data subset. This avoided patient information \nleaking from the training data to the validation and testing data. \n2.2 Training language models \nWe trained three language models - word2vec [84], fastText [85, 86], and GloVe [87] - to compute \nmedical concept embeddings for any token appearing in the patient trajectory sequences. Patient \ntrajectory sequences were encoded by a vocabulary that assigned an integer id to any token appearing \nat least 5 times in the training data and a special id for the remaining “unknown” tokens. Each model \nmapped these ids to fixed-size float vectors, i.e., embeddings, initialized with a random floating point \nlook-up table. We used an embedding dimensionality of 512 for all models. These embeddings were \ntrained by optimizing the different model’s objectives, in order to provide useful representations of \nmedical concepts (Figure 2, top). \n \n2 https://github.com/ds4dh/medical_concept_representation/tree/main/data/datasets/mimic-iv-2.2/maps \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \n \nFigure 2. Training and evaluation of language models. Language models (word2vec, fastText or GloVe) were trained, \nbased on their respective objectives (see sections 2.2.1 to 2.2.3 for details), using patient trajectories from the training \ndataset. After training, embeddings of patient trajectories or single medical concepts were queried using the hidden \nweights of the models. To generate a single embedding vector for a patient trajectory, token embeddings were \naveraged, weighting each token by the inverse of its frequency in the training dataset. \nWe trained all models until convergence - 100’000 training steps for word2vec and fastText, and \n300’000 for GloVe - with a batch size of 4096 tokens. After training, any medical concept could be given \nas input to the language model to obtain a vector representation (Figure 2, bottom). To embed any \npatient trajectory, we computed a weighted average of the embeddings of its tokens (Figure 2, bottom-\nright). The weights were defined as the inverse token frequencies in the training dataset. The neural \nlanguage models used in our experiments are described in sections 2.2.1 to 2.2.3.  \n2.2.1 Word2vec \nWord2vec [84] is a 2-layer neural network whose goal is to represent tokens by the context in which \nthey appear. We used the skip-gram architecture of word2vec, which receives single tokens as input \nand embeds them to predict nearby target tokens. The reason is that skip-gram works better with small \ndatasets and has better representations of rare tokens [95]. Training samples were built from patient \ntrajectory sequences by collecting all tokens that appear in a fixed-size context window and assigning \nthem to the token in the center of the window. For our case, the context window extended over 5 \ntokens on both sides. During training, the model updates its parameters by maximizing the likelihood \nof predicting the context tokens given the corresponding input tokens. This is achieved by applying the \nsoftmax function to the dot product of the input token embedding and all possible token embeddings, \nwhich produces a probability distribution of the target context token over the vocabulary. After training, \ntokens that appear in similar contexts are expected to be close to each other in the embedding space, \nenabling word2vec to capture meaningful relationships between medical concepts. \n2.2.2 FastText \nFastText [85, 86] is a neural network that extends the word2vec model by representing words as bags \nof character n-grams, capturing subword information. FastText can represent unseen words based on \ntheir subword units. The architecture and training schedule of fastText is similar to word2vec. The main \ndifference is that, before being processed further, a token embedding is computed as the sum of the \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \nembeddings of its n-grams. The motivation to use fastText in our case is that codes from biomedical \nterminologies tend to be structured in a hierarchical manner (e.g., ICD10-CM, ICD-PCS, ATC). Subword \ninformation may hence automatically include this hierarchy in the token representations. To add \nsubword information to the medical concept tokens, we used n-grams for 2 ≤ n ≤ 5. \n2.2.3 GloVe \nGloVe [87] is a count-based algorithm that captures global word co-occurrence statistics. It constructs \na co-occurrence matrix by counting how frequently words co-occur in the sequences of the dataset and \nthen factorizes the matrix to obtain word embeddings. Unlike word2vec and fastText, GloVe considers \nthe entire co-occurrence matrix during training, rather than focusing on local context windows around \neach word. In principle, this allows GloVe to capture more complex semantic and syntactic relationships \nbetween words that may be separated by several words or even sentences. In our experiments, to \ncreate the co-occurrence matrix we counted, for each pair of tokens, how many times they appeared \nin a common patient trajectory sequence of the training dataset. Empirically, this approach led to better \nperformance than using a fixed-size context window to compute co-occurrences. During training, the \nmodel embedded token pairs to predict their co-occurrence score. \n2.2.4 Creating training sequences \nFor fastText and word2vec, we followed the procedure of reference [79] to create the training \nsequences. The procedure shuffled the content of patient trajectory sequences when building center-\ncontext token pairs, which resulted in better predictive performance. The reason was that tokens \nprepended to the sequence, e.g., demographics, were otherwise almost never part of other tokens’ \ncontext windows. In the current work, to preserve local relationships among tokens in the learned \nrepresentations, we shuffled each sequence only with 50% probability. We also ran an alternative \ntraining schedule, where no shuffling was applied, but all context windows artificially included the \noutcome tokens, demographic information, as well as the 3 most important diagnosis codes, in addition \nto the normal context tokens. However, this alternative training procedure produced very small and \ninconsistent improvements. For GloVe, as the co-occurrence matrix is created using the whole \ntrajectory (i.e., window size equals to the trajectory length), we used the original trajectory sequence. \n2.3 Visualization of medical concept embeddings \nWe visualized the embeddings of different medical concepts present in the MIMIC-IV dataset, as \ncomputed by the different language models described in section 2.2. More specifically, using the t-SNE \nalgorithm [96], we generated a 2-dimensional representation of the embeddings of all ICD10-CM \n(diagnoses and reason for visits), ICD10-PCS (procedures) and ATC (medication) codes appearing in the \nmodel’s vocabulary. We used the python package scikit-learn [97] to implement the t-SNE algorithm, \nwith the following hyper-parameters: perplexity = 30.0, learning_rate = auto, metric = cosine, init = pca, \nn_iter: 10000, and n_iter_without_progress = 1000. \nTo evaluate the capacity of each model’s embeddings to capture the semantic meaning of medical \nconcepts, we labeled the codes with the main terminological subcategories to which they belong. Our \nexpectations were that trained embedding would form clusters of medical concepts that correspond to \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \nthese subcategories. For ICD10-CM codes, we used the ICD10 chapter indices 3, which mainly \ncorrespond to the first letter of the code, and encode the general type of injury or disease, e.g., G \n(nervous), I (circulatory), or J (respiratory). For ATC codes we used the first letter as well, which indicates \nthe main anatomical group that the medication is intended to act upon, e.g., C (cardiovascular system), \nand D ( dermatologicals). For ICD10-PCS codes, although the first character indicates the general \ncategory of the procedure, e.g., 7 (osteopathic) or B (imaging), most entries start with the character 0 \n(medical and surgical procedures ). For this reason, in addition to first-letter subcategories, we split \nsubcategory 0 using the second character, which stands for the body system or general anatomical \nregion involved in the procedure, e.g., 0D (medical and surgical procedures, gastrointestinal system) or \n0T (medical and surgical procedures, urinary system). Note that we only kept subcategories that, on the \none hand, held at least 1% of the codes in the terminology and, on the other hand, represented at least \n1% of the tokens of the training dataset. More details about all subcategories are available in Table S3, \n(Suppl. Inf.). \n2.4 Prediction tasks \nWe extrinsically evaluated the quality of embeddings produced by the trained models (see section 2.2) \nwith two types of patient trajectory prediction tasks (Figure 3, left): binary and multi-label. For the \nbinary task, the aim was to predict the outcome of a stay, namely length-of-stay (normal or extended), \nreadmission, and mortality. For the multi-label task, the aim was to predict the next clinical events in \nthe patient trajectory, namely diagnoses or reason for visits (ICD10-CM), procedures (ICD10-PCS), and \nmedications (ATC). Importantly, no model supervision was involved, i.e., predictions were solely based \non the cosine-similarity between embeddings of patient trajectories and potential target token (Figure \n3, right). More specifically, for each task, we assigned a score to any code belonging to the relevant \ncategory, i.e., the outcome labels for the binary prediction task, and all codes of the specific category \n(ICD10-CM, ICD10-PCS, ATC) for the multi-label prediction task. The score was defined as 1.0 minus the \ncosine-similarity, which we used to compute the receiver operating characteristic and the precision-\nrecall curves for any combination of task and model. To feature a realistic prediction scenario, model \ninputs included only a fraction of the medical concept tokens of each patient trajectory sequence. \nStarting from demographics tokens, we gradually increased the proportion of medical tokens given to \nthe model (i.e., P = 0.0, 0.1, 0.3, 0.6, 1.0). We give more details about each prediction task in sections \n2.4.1 and 2.4.2. \n \nFigure 3. Prediction tasks performed by the models. Left. Patient trajectory sequences from the testing dataset were \nembedded by the trained language models. Task-specific target tokens were removed from the input sequences embedded \nby the models. Label tokens (used for the binary prediction tasks) were also removed for any prediction task. Right. For each \n \n3 https://icd.who.int/browse10/2010/en \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \npredicted category, patient trajectory embeddings were compared to embeddings of any code belonging to that category \n(ICD10-CM codes in the figure example). Model predictions were computed as the set of medical concept tokens that are \nwithin a threshold level of dissimilarity from the patient trajectory embedding (note that, for illustration purpose, the figure \ndepicts a threshold Euclidean distance, but we actually used 1.0 minus cosine-similarity). Predicted target tokens within \nthreshold level correspond to true positives and predicted non-target tokens to false positives. Target tokens outside threshold \nlevel correspond to false negatives. Based on these numbers, precision-recall and ROC curves were computed using different \nthresholds. \n2.4.1 Length-of-stay, readmission, and mortality prediction \nIn these tasks, single label tokens for length-of-stay, readmission, and mortality were predicted by the \nmodel, based on patient trajectory embeddings. Each label token had two possible statuses: normal \nand extended for length-of-stay; no-readmission and readmitted for readmission; alive and dead for \nmortality. During training, these tokens were added at the beginning of the patient trajectory \nsequences and, hence, models learned to represent these tokens in relation to other medical concepts. \nDuring evaluation, these tokens were removed from the trajectory sequence (Figure 3, left). The \nprediction of the model was then simply computed as the outcome token whose embedding is closer \nto the patient trajectory embedding in terms of cosine-similarity (Figure 3, right). For each task, we \nevaluated model prediction performance with the areas under the receiver operating characteristic \n(AUROC) and the precision-recall (AUPRC) curves. \n2.4.2 Prediction of diagnoses and reasons for visits, procedures, and medications \nIn these tasks, diagnosis, and reason for visit (ICD10-CM), procedure (ICD10-PCS) and medication (ATC) \ncodes were predicted by the model based on patient trajectory embeddings. For each task, the tokens \nbelonging to the category of tokens being predicted were removed from the input sentence and set as \ntarget tokens (see Figure 3, left). Outcome tokens, i.e., length-of-stay, readmission, and mortality, were \nalso removed from the input. Cosine-similarity was then computed between the embedding of the \ninput sequence and any potential target token. These tasks are particularly challenging. For example, \nwhen predicting ICD10-CM codes, the model must correctly guess, on average, 11 tokens, any of which \ncomes from a set of 10k possible values. We evaluated model prediction performance for different \nlevels of lenience. First, we considered a model prediction as a hit by requiring an exact match between \npredicted and target tokens. Then, we only asked for a lenient match, i.e., having N letters in common \nwith at least one of the target tokens, for N = 1, 2, 3, and 4. Finally, precision, recall, and AUPRC were \ncomputed for each level of lenience.  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \n3. Results \n3.1 Qualitative visualization of medical concept embeddings \n3.1.1 Comparison to ICD10-CM, ICD10-PCS, ATC terminologies \nFigure 5 shows the output of the t-SNE algorithm using embeddings obtained by the word2vec, fastText, \nand GloVe models for the ICD10-CM, ICD10-PCS, and ATC codes. Note that for ICD10-CM codes we did \nnot visualize the subcategory R, since it stands for “symptoms, signs and abnormal clinical and \nlaboratory findings, not elsewhere classified”, which we deemed too heterogeneous to have any chance \nto form a cluster. Moreover, we separated the subcategory “injury, poisoning and certain other \nconsequences of external causes” into two, i.e., S and T (instead of keeping them together). \n \nFigure 4. Medical concept embeddings obtained after training the language models.  We used the t-SNE algorithm to \nreduce the dimensionality of embeddings (d = 2). Colors represent the main subcategories of ICD10-CM, ICD10-PCS, \nand ATC codes (for details, see section 2.3 and Table S3, Suppl. Inf.). \nAmongst all models, fastText provides embeddings whose t-SNE visualization forms the most separate \nclusters. Moreover, embedding clusters are visually aligned with the subcategories that are defined in \nsection 2.1, denoted by the different colors in Figure 4. Since the t-SNE algorithm preserves local \ndistance relationships between data samples, this suggests that semantic relationships between \nmedical codes are part of the low-level structure of fastText embeddings. For ICD10-CM codes, the \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \nsubcategories whose fastText embeddings are the most spread out and undefined are G ( diseases of \nthe nervous system), L (diseases of the skin and subcutaneous tissue ), and H6-H9 ( diseases of the ear \nand mastoid process ). Some codes have a substructure within subcategories, e.g., N ( diseases of the \ngenitourinary system ) which presents two subclusters that, upon further inspection, separate \nconditions related to male and female genital organs. Other subcategories are mixed but are still part \nof well-defined clusters. For example, ICD10-CM tokens of subcategories S and T (injury, poisoning and \ncertain other consequences of external causes ) are separated into one cluster made only of T-tokens, \nand another one that mixes S and T tokens. Upon closer examination, the cluster composed of both \nsubcategories corresponds to injuries made to an external body part (i.e., fractures, burnings, \nfrostbites, etc., included in ICD10-CM codes that start with S00 to T34 and T66 to T88), while the other \ncluster corresponds to internal causes of harm (toxic substance effects, poisoning, etc., included in \nICD10-CM codes that start with T36 to T65). This suggests that, even though subword information (in \nthis case, the first letter of ICD10-CM codes) acts as prior knowledge during training in the case of \nfastText, data-driven statistics are smoothly integrated into the medical embedding representation of \nthe trained model. In general, fastText embeddings of all subcategories tend to have an inner \nsubstructure. To compare these substructures to the second hierarchical level of terminologies, we also \nperformed a clustering analysis of fastText embeddings, focusing on a specific set of subcategories (see \nsection 3.1.2). Word2vec produces embeddings that are significantly more mixed between \nsubcategories, especially for ICD10-CM codes. For example, subcategory T, which forms well defined \nclusters with fastText, spreads across the entire representation space. For ICD10-PCS codes, \nembeddings are more aligned with subcategories, but not as much as using fastText. For example, \nsubcategories 0H, 0J, 0Q, 0S (standing for medical and surgical procedures performed on the skin, \nsubcutaneous tissues, bones, and joints, respectively), are found to be mixed with each other, whereas \nthey form distinct clusters with fastText. Another example is the subcategory 0W (Medical and Surgical \nBody Systems - Anatomical Regions, General ), for which tokens are completely shattered when \nprovided by word2vec, which is not the case for fastText. Finally, GloVe embeddings are the ones that \nare the most mixed between subcategories after t-SNE reduction. \nTo quantify the quality of the embeddings learned by the models, we computed rate reduction [98, 99] \nfor any combination of model representation and medical concept category. Rate reduction is the \ndifference between the rate distortion of the whole dataset and the mean rate distortion of each class \nconsidered separately (e.g., all ICD10-CM codes as represented by fastText vs. all subcategories of \nICD10-CM codes). Rate distortion quantifies the number of bits needed to encode any representation. \nA reduction in rate distortion indicates that the learned representation effectively distinguishes \nbetween different classes, as the amount of information required to represent the data is reduced \nwhen the class structure is considered as a prior. Table 2 shows rate reduction for any combination of \nmodel and category using the full dimensionality of the embeddings or the output of the t-SNE \nalgorithm (i.e., a 2-dimensional representation). \n word2vec fastText GloVe \nRaw \nembeddings \n(d = 512) \nICD10-CM 410 531 403 \nICD10-PCS 1387 1245 1463 \nATC 1804 1504 1833 \n \nReduced \nembeddings \nICD10-CM 0.38 0.72 0.11 \nICD10-PCS 0.47 1.20 0.09 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \n(t-SNE, d = 2) ATC 0.21 0.30 0.07 \nTable 2. Rate reduction of medical concept representations. Higher values mean better representations (note that rate \nreduction cannot be compared across dimensionalities). When using reduced embeddings (dim = 2), fastText obtains \nhigher rate reductions. This reflects its better alignment with the first level of biomedical terminologies. However, when \nusing raw model embeddings, GloVe tends to obtain larger rate reduction. \nWhen considering embeddings after dimensionality reduction, fastText obtains the largest rate \nreduction score for all categories (Table 2, d = 2), which reflects the better alignments of reduced \nfastText embeddings with the hierarchy of biomedical terminologies (Figure 4). For unreduced \nembeddings, while fastText achieves the largest rate reduction score for ICD10-CM codes, GloVe shows \nthe largest scores for ICD10-PCS and ATC codes (Table 2, d = 512). This suggests that, if semantic \ninformation of medical concepts is accurately represented in the embedding space of GloVe, they are \npart of a more global and high-dimensional structure. This may have an impact on the quality of \nembeddings for prediction tasks (see section 3.2). \n3.1.2 Hierarchical analysis \nWe assessed the ability of all models to uncover the hierarchical relationships among ICD10-CM, ICD10-\nPCS, and ATC codes. Specifically, we evaluated whether models’ embeddings could be used to \nrediscover the second hierarchical level of medical terminologies. We focused on ICD10-CM codes \nbeginning with C0 to D4, ICD10-PCS codes beginning with B0 to BY, and ATC codes beginning with L01 \nto L04. We generated empirical clusters from the reduced (2-dimensional) embedding vectors of these \ncodes and compared them to theoretical clusters based on the second hierarchical level of the \nterminologies, namely the second character of ICD10-CM and ICD10-PCS codes, and the third character \nof ATC codes. We used the hdbscan algorithm [100] to compute the empirical clusters, either using raw \nembeddings or embeddings after t-SNE dimensionality reduction. Note that we used the number of \ntheoretical clusters as prior knowledge when determining the clusters (i.e., we set a flat lambda value \ncutoff in the hdbscan cluster tree to obtain the same number of clusters as in the medical terminology). \nWe measured the quality of the clusters generated by each model (Table 3). \n Raw embeddings (d = 512)  Reduced embeddings (t-SNE, d = 2) \nword2vec fastText GloVe word2vec fastText GloVe \n ICD10-CM codes \nHomogeneity 0.032 0.432 0.026  0.429 0.880 0.202 \nCompleteness 0.157 0.602 0.124 0.475 0.880 0.305 \nV-measure 0.053 0.503 0.044  0.451 0.880 0.243 \n ICD10-PCS codes \nHomogeneity 0.173 0.170 NC  0.707 0.773 0.281 \nCompleteness 0.495 0.387 NC 0.750 0.825 0.416 \nV-measure 0.256 0.236 NC  0.728 0.799 0.336 \n ATC codes \nHomogeneity NC 0.524 0.022  0.288 0.961 0.169 \nCompleteness NC 0.408 0.027 0.206 0.873 0.158 \nV-measure NC 0.459 0.024  0.240 0.915 0.163 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \nTable 3. Evaluation of empirical clusters as determined by model embeddings.  We quantified the homogeneity of \nempirical clusters and their match with theoretical clusters (completeness). V-measure is computed as the harmonic \nmean between homogeneity and completeness. NC: the clustering algorithm could not identify any cluster. \nReduced fastText embeddings consistently outperform other combinations when used to rediscover \nthe second level of the hierarchy of biomedical terminologies. For this reason, we visualized theoretical \nclusters, as well as empirical clusters generated with this combination of model and dimensionality \n(Figure 5). \n \nFigure 5. Clusterization of a selected subset of medical concepts using fastText  embeddings after dimensionality \nreduction (t-SNE, d = 2). Top. Theoretical clusters. Samples are positioned following reduced embeddings. Colors are \nderived from the second hierarchical level of ICD10-CM, ICD10-PCS, and ATC codes. Center. Empirical clusters. Colors \nare assigned using the hdbscan clustering algorithm, and then aligned with the top row by maximizing the number of \nsample matches between theoretical and empirical clusters. Samples labeled with a black color were not assigned to \nany cluster (i.e., labeled as noise). Bottom. The empirical cluster trees were also generated with hdbscan. We cut the \ntree after the number of theoretical clusters was reached (i.e., 15 for ICD10-CM, 8 for ICD10-PCS and 4 for ATC codes). \nWe added color patches that correspond to the empirical cluster in the center row. \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \nThe empirical clusters derived from fastText embeddings are generally well-aligned with the theoretical \nclusters. Still, empirical data proposes alternative ways of defining the terminology of medical codes by \nidentifying new clusters. For example, procedure codes at the bottom-right of the diagram (Figure 5, \ncenter column, top vs. center row) form a well-defined group although the medical concepts belonging \nto that cluster come mainly from two different ICD10-PCS subgroups, namely BW (anatomical regions) \nand BR ( axial skeleton, except skull and facial bones ). Moreover, some singular medical concepts are \nmoved to different clusters by empirical data. For example, for ATC codes, L02AE02 ( leuprorelin) that \nbelongs to the orange theoretical cluster (L02: endocrine therapy) is moved towards the blue empirical \ncluster (L01: antineoplastic agents) by empirical data, which is also a valid categorization of leuprorelin, \ni.e., an antineoplastic agent (Figure 5, top-right). \nAlso note that, for ICD10-CM codes, the way we defined theoretical groups (i.e., relying on the second \ncode letter) includes inaccuracies. For example, the group Malignant neoplasms of ill-defined, other \nsecondary and unspecified sites consists of ICD10-CM codes that start with C76 to C80, which include \nsamples coming from both theoretical clusters C7 (gray) and C8 (orange). Empirical clusters correctly \nidentified this issue (Figure 5, top-left, group of orange codes around the gray cluster), even though \nsubword information should bias C80 tokens to be closer to other tokens starting with C8. Another \nexample for ICD10-CM codes are the groups malignant neoplasms of breast (codes that start with C50) \nand malignant neoplasms of female genital organs  (code that start with C51 to C58). Empirical \nembeddings correctly identified these two groups (Figure 5, center row, right column, mauve and \nsalmon clusters on the right of the plot), even though they belong to the same theoretical cluster C5. \n3.2 Prediction tasks \nWe computed the precision and recall of word2vec, fastText and GloVe based on the medical concepts \nthat were close to each patient trajectory embedding. Note that model predictions are computed in a \ncompletely unsupervised way and are only used to compare the quality of the embeddings provided by \nthe different models. \n3.2.1 Length-of-stay, readmission, and mortality prediction \nFigure 6 shows AUROC and AUPRC obtained with the embeddings of all models, when predicting \noutcomes from patient trajectories. Note that AUPRC is a better measure for prediction problems with \nunbalanced classes, which is the case here. Also note that P is the fraction of the tokens of each patient \ntrajectory sequence given to the model as an input for prediction, increasing from P = 0.0 \n(demographics tokens only) to P = 1.0 (full trajectory). First, increasing the fraction of tokens given as \ninput to the models always improves their prediction performance, for any model. However, fastText \nseems to benefit slightly less from more information about patient trajectories, as its performance \npeaks to lower values than what is obtained with word2vec and GloVe, even though they all start from \nsimilar baseline performances at P = 0.0. \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \n \nFigure 6. AUROC and AUPRC obtained with word2vec, fastText and GloVe for outcome prediction tasks. P stands for the \ndifferent proportions of the patient stay tokens given as input to the models (see section 2.4). The random performance \nfor AUPRC corresponds to the number of positive samples over the total number of samples. \n3.2.2 Comparison of patient outcome embeddings \nIn Figure 7, we visualize patient trajectory embeddings for the different outcomes - length-of-stay, \nreadmission, and mortality - to assess whether high-level outcome information is present in the local \nstructure of embeddings. The patient trajectories were taken from the testing dataset and their \nembeddings were generated by removing the outcome label from the trajectory and averaging the \nremaining concept embeddings. The 2-dimensional representations were then obtained by applying \nthe t-SNE algorithm for word2vec, fastText, and GloVe embeddings. To improve visualization, we used \nthe same number of patient trajectories for each outcome, which were randomly sampled from the \ntest set. The limiting factor was the smallest number of patients for any outcome in the testing dataset, \nwhich was 1800 (patients that passed away). Results show that patients with antagonistic outcomes, \ne.g., dead and alive patients, populate similar regions of the embedding space. This suggests that \ninformation relevant to predict outcomes might have been entangled during the dimensionality \nreduction, or during the averaging (from several clinical concepts to a single representation of the \ntrajectory). Moreover, the distance between antagonistic outcome tokens themselves (Figure 7, large \ncircles) seem to be very close to each other in some cases. For example, GloVe embeddings for any \noutcome token are almost at the same location in the embedding space. \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \n \nFigure 7.  Visualization of patient trajectory embeddings for all combinations of different outcomes (length-of-stay, \nreadmission, mortality) and models (word2vec, fastText, GloVe), after t-SNE dimensionality reduction.  We also added \nthe reduced embedding of outcome tokens (large circles). Dimensionality reduction was performed using the \nembeddings of all patient trajectories from the testing dataset, extended with the embeddings of all outcome tokens. \nThen, for each outcome label, 1800 trajectories were randomly sampled for visualization. \n3.2.3 Diagnosis, procedure, and medication code prediction \nFigure 8 shows the AUPRC obtained with the models when predicting all medical codes of a category \ngiven the patient trajectory embeddings (AUROC values are shown in Figure S1, Suppl. Inf.). First, \nword2vec has, in most cases, a lower score than fastText. It is stronger only for edge cases where \nperformance is very low already. Second, GloVe obtains the best mean results amongst models. It is \nbetter than fastText for ICD10-CM codes prediction and obtains better performance for ICD10-PCS and \nATC codes prediction when the task is more challenging (i.e., for less lenient matches). It should be \nnoted that sometimes, the best performance is reached when only the demographic tokens are used \nto compute patient trajectory embeddings (i.e., P = 0.0; e.g., GloVe, 1 letter match, ICD10-CM or ATC \ncodes prediction). This means that adding more tokens to the sentence worsens the alignment between \npatient trajectory embeddings and associated target code embeddings. \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \n \nFigure 8. AUPRC obtained with word2vec, fastText and GloVe  for medical concept prediction tasks. L stands for the \nlenient letter match. For example, 1L means that precision and recall were computed on the basis of the first letter of \nthe codes only. EM means that an exact match was required between a model prediction and a target code. P stands \nfor the different proportions of the patient trajectories given as input to the models (see section 2.4). The random \nperformance corresponds to the number of positive samples over the total number of samples. \nWe also performed medical code prediction in different settings. For ICD10-CM codes, patient \ntrajectory embeddings were used to predict only the most important diagnosis code (see Figure 1, p1), \ngiven the full patient trajectory from which all outcome and diagnosis tokens were removed. For ICD10-\nPCS and ATC codes, we used the embeddings of a patient’s trajectory, including events only up to a \ncertain point in time, to predict the next occurring procedure or medication token. Figure 9 shows \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \nAUPRC for these prediction tasks (AUROC values are shown in Figure S2, Suppl. Inf.). As we can notice, \nthese tasks are very challenging for the three models assessed. The results differentiate from a random \nprediction only for the first and second code letters, while exact matching prediction is equivalent to a \nrandom prediction. We assume that this low performance is due to the lack of temporality information \nencoded by the embeddings, that is, they tend to learn hierarchical relationships among medical \nconcepts but ignore their sequential relationship, which is trajectory dependent.  \n \nFigure 9. AUPRC obtained with word2vec, fastText and GloVe for alternative prediction tasks.  We used model \nembeddings to predict the most important ICD10-CM code of the patient trajectory, as well as the next ICD10-PCS and \nATC code, given the medical events that happened so far.  L stands for the lenient letter match. For example, 1L means \nthat precision and recall were computed on the basis of the first letter of the codes only. EM means that an exact match \nwas required between a model prediction and a target code.  \n  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \n4. Discussion \nIn this study, we compared the ability of different language models, word2vec, fastText, and GloVe, to \nrepresent medical concepts by expressing patient trajectories as sequences of medical codes. We \nshowed that language models can learn data-driven embeddings that retrieve the semantic meaning \nof medical concepts, as provided by biomedical terminologies. Using an unsupervised approach, we \nalso compared the respective capabilities and limitations of different language models for patient \ntrajectory prediction. \nTo evaluate the semantic content of embeddings as produced by the different language models, we \ncompared their alignment with existing medical concept terminologies. Using rate reduction as a \nquantitative measurement, we showed that, in terms of low-level representation, fastText is the model \nwhose embeddings are best aligned with the hierarchy of existing medical concept terminologies \n(Figure 4 and Table 2). Note that, in the case of fastText, subword information includes the hierarchical \nstructure of medical terminologies. Indeed, some subwords of ICD10 and ATC codes correspond to their \ntop-level categories. For instance, the subwords of the ICD10-CM code T3302XA ( superficial frostbite \nof nose, initial encounter ) include T33 ( superficial frostbite) and T3302 ( superficial frostbite of nose ). \nHowever, most subword tokens are irrelevant, such as 02XA or 330 in the aforementioned example. \nMoreover, the hierarchy of medical terminologies does not strictly follow subword information. For \nexample, medical concepts describing physical injuries consist of ICD10-CM codes that start with S00 \nto T34, and from T66 to T88, skipping codes that go from T35 to T65. Still, fastText embeddings are able \nto update prior subword knowledge and uncover the complex hierarchy of medical terminologies \n(Figure 4 and 5). This suggests that fastText is an efficient way of combining prior knowledge (included \nin subword information, which reflects existing terminologies) with data-driven representations (which \ndepend on the history of patients at the ICUs). \nWe extrinsically evaluated the quality of the medical concept embeddings via outcome and trajectory \nprediction tasks using an unsupervised method. First, we performed a multi-label prediction task in \nwhich tokens belonging to one category (ICD10-CM, ICD10-PCS, or ATC codes) were detached from \npatient trajectories and used as target tokens. Patient trajectories were embedded using the language \nmodels (Figure 2) and compared to the embeddings of the target tokens using their cosine-similarity \n(Figure 3). In terms of multi-label prediction, GloVe tends to outperform fastText and word2vec, \nalthough not consistently and by a small margin (Figure 8, 9, S1 and S2, Suppl. Inf.). We suggest the \nreason for GloVe superiority for medical concept prediction tasks is that it considers long-range \nrelationships, as it has no context window, and instead computes co-occurrences on whole sequences. \nThis provides a more global scope to GloVe embeddings, which may be beneficial for high-level tasks \nsuch as medical concept prediction. It should be noted that this is also reflected in the rate reduction \nof raw embeddings (i.e., d = 512), for which GloVe obtains the largest values overall (Table 2, top). This \nmeans that, even though GloVe embeddings appear to have a low semantic agreement with medical \nterminologies after dimensionality reduction, they agree more than other models in the full-\ndimensional space. The t-SNE algorithm maps high-dimensional vectors to a low-dimensional space \nwhile preserving the local structure of the data but is not guaranteed to preserve the global structure \nof the representation. Hence, the visualization in Figure 4 only highlights the semantics of the low-level \nstructure of embeddings. This suggests that, if semantic information of medical concepts is accurately \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \nrepresented in the embedding space of GloVe, they are part of a more global and high-dimensional \nstructure. \nWe also carried out a binary prediction task in which patient trajectory embeddings were compared to \nthe embeddings of binary outcome tokens (length-of-stay, readmission, mortality) that were \nprepended to each patient trajectory during training. As for the multi-label prediction tasks, we used \nan unsupervised method to generate predictions, which were computed as the outcome tokens that \nwere more similar to the patient trajectory embeddings. First and foremost, achieved performance \nlevels for any model are considerably low, with most AUPRC measurements rarely exceeding a value of \n0.4. This was to expect given the simplicity of our unsupervised prediction method, as compared to the \ntarget outcomes which inherently depend both on global trajectory patterns and on nuanced \ninteractions between medical concepts. Moreover, pooling all tokens together when building patient \ntrajectory embeddings is likely suboptimal for capturing the rich, dynamic information contained in \npatient trajectories. A supervised method would probably be more suited to perform outcome \npredictions. This is reflected in Figure 7, where we visualized patient trajectory embeddings for different \noutcomes. These should ideally span contrasting regions of the embedding space, but actually present \na large degree of overlap (at least in the reduced embeddings space). Besides, outcome tokens \nthemselves tend to be very similar to each other, which might be a byproduct of prepending them to \neach patient trajectory during training, since they always appear in similar contexts. \nNevertheless, the binary outcome prediction task was used as a comparative evaluation method of \nmodel embeddings and their potential for more complex and high-level tasks. From our analysis, we \nfound that word2vec and GloVe have similar performance levels, while they both consistently \noutperform fastText (Figure 6). We suggest that the cause of this discrepancy lies in fastText's intrinsic \nmodeling of the hierarchical structure of medical terminologies. While this feature benefits fastText in \nthe semantic alignment of its embeddings with existing medical terminologies, it seems to hinder the \nmodel in more high-level tasks, such as clinical outcome prediction. This task requires a broad and \nflexible representation of medical concepts and may be disrupted by fastText's stricter adherence to \nthe hierarchy of biomedical terminologies. This underlines the importance of understanding the specific \nstrengths and weaknesses of each model in relation to the nature of the task at hand. \nThis study has several limitations. First, we focused only on methods that produce static embeddings. \nHowever, more modern language models, such as those based on attention, provide contextualized \nembeddings, which usually improve performance in downstream tasks [101, 102]. In this case, instead \nof having a unique representation, clinical concepts have many according to the context in which they \nappear. Contextualized representation would thus require a different clustering and concept mapping \nmethodology and should be a subject of further study. Second, for all prediction tasks that we used to \nevaluate model embeddings, no supervision was involved. While supervised learning tends to improve \nupon unsupervised methods, our goal here was to compare the quality of the extracted embeddings \nrather than devise an optimal trajectory prediction method. In that sense, we argue that the \nunsupervised methodology provides a less biased comparison, as it is independent of the learning \nmodel. A supervised methodology based on the proposed embedding strategy could also be a topic for \nfurther research and would benefit from the results presented in the current study. Third, due to the \nlack of explicitly time-stamped information for diagnosis codes, i.e., clinical evaluation time instead of \nbilling time, we used the diagnosis priority to order these codes in the patient trajectory. As patients \ntend to have a recoverable condition before ICU admission, these codes were inserted early during the \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \noriginal patient trajectory sequence generation. However, this may not necessarily always reflect the \nactual trajectory, as new diagnosis codes can be assigned to a patient during the ICU stay [103]. Finally, \nthere may exist 1-to-1 relationships between medical concepts, e.g., an antiretroviral therapy might be \nspecific to HIV/AIDS patients. Hence, for the ICD10-CM, ICD10-PCS and ATC code prediction tasks, there \nmight be some leakage from input to target tokens. Nevertheless, given the limited performance of the \npredictions, we assume that this effect is negligible, especially due to the n:m relation between the \ndimensions. \n  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \n5. Conclusion \nWe assessed the capabilities of different language models (word2vec, fastText, and GloVe), each \ncoming with their own set of hypotheses, in expressing patient trajectories as sequences of medical \ncodes. We found that these models can indeed learn data-driven embeddings that capture the \nsemantic meaning of medical concepts. However, the effectiveness of these models varies based on \nthe task at hand. While fastText aligns well with existing medical terminologies thanks to subword \ninformation, GloVe is more useful for medical concept prediction tasks thanks to its ability to consider \nlong-range relationships and global co-occurrences in text. These results offer important insights for \nsupervised medical concepts and clinical outcomes prediction methods and open up several exciting \navenues for future exploration. One promising research avenue is refining strategies for encoding \nsubword information for representing medical concepts. For instance, tokenization that aligns with \nICD10 and ATC hierarchies, instead of relying on basic n-grams, could enhance the accuracy and depth \nof the embeddings by providing crucial prior knowledge. Besides, it would reduce vocabulary sizes, thus \noptimizing model performance and efficiency. In conclusion, our study confirms the potential of \nlanguage models in healthcare data analysis, particularly in understanding patient trajectories in \nintensive care. \n  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \nFunding statement \nThis work was funded by the Innosuisse - Schweizerische Agentur für Innovationsförderung - project \nno.: 55441.1 IP ICT. \n  \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \nReferences \n1.  Meystre SM, Lovis C, Bürkle T, Tognola G, Budrionis A, Lehmann CU (2017) Clinical data reuse or secondary use: \ncurrent status and potential future progress. Yearbook of medical informatics 26:38–52 \n2.  O’malley KJ, Cook KF, Price MD, Wildes KR, Hurdle JF, Ashton CM (2005) Measuring diagnoses: ICD code \naccuracy. Health services research 40:1620–1639 \n3.  McGinnis JM, Stuckhardt L, Saunders R, Smith M (2013) Best care at lower cost: the path to continuously \nlearning health care in America. \n4.  Project HC and U (2016) Clinical classifications software (CCS) for ICD-9-CM. \n5.  Jensen PB, Jensen LJ, Brunak S (2012) Mining electronic health records: towards better research applications \nand clinical care. Nature Reviews Genetics 13:395–405 \n6.  Furukawa MF, Eldridge N, Wang Y, Metersky M (2020) Electronic health record adoption and rates of in-\nhospital adverse events. Journal of patient safety 16:137–142 \n7.  Melton GB, Hripcsak G (2005) Automated detection of adverse events using natural language processing of \ndischarge summaries. Journal of the American Medical Informatics Association 12:448–457 \n8.  Bean DM, Wu H, Iqbal E, Dzahini O, Ibrahim ZM, Broadbent M, Stewart R, Dobson RJ (2017) Knowledge graph \nprediction of unknown adverse drug reactions and validation in electronic health records. Scientific reports \n7:1–11 \n9.  Bruland P, McGilchrist M, Zapletal E, Acosta D, Proeve J, Askin S, Ganslandt T, Doods J, Dugas M (2016) \nCommon data elements for secondary use of electronic health record data for clinical trial execution and \nserious adverse event reporting. BMC medical research methodology 16:1–10 \n10.  Edwards ST, Neri PM, Volk LA, Schiff GD, Bates DW (2014) Association of note quality and quality of care: a \ncross-sectional study. BMJ quality & safety 23:406–413 \n11.  Bell SK, Folcarelli PH, Anselmo MK, Crotty BH, Flier LA, Walker J (2015) Connecting patients and clinicians: the \nanticipated effects of open notes on patient safety and quality of care. Joint Commission Journal on Quality and \nPatient Safety 41:378–384 \n12.  Kutney-Lee A, Kelly D (2011) The effect of hospital electronic health record adoption on nurse-assessed quality \nof care and patient safety. The Journal of nursing administration 41:466 \n13.  Spiranovic C, Matthews A, Scanlan J, Kirkby KC (2016) Increasing knowledge of mental illness through \nsecondary research of electronic health records: opportunities and challenges. Advances in Mental Health \n14:14–25 \n14.  Pathak J, Kho AN, Denny JC (2013) Electronic health records-driven phenotyping: challenges, recent advances, \nand perspectives. Journal of the American Medical Informatics Association 20:e206–e211 \n15.  Shivade C, Raghavan P, Fosler-Lussier E, Embi PJ, Elhadad N, Johnson SB, Lai AM (2014) A review of approaches \nto identifying patient phenotype cohorts using electronic health records. Journal of the American Medical \nInformatics Association 21:221–230 \n16.  Oellrich A, Collier N, Groza T, Rebholz-Schuhmann D, Shah N, Bodenreider O, Boland MR, Georgiev I, Liu H, \nLivingston K (2016) The digital revolution in phenotyping. Briefings in bioinformatics 17:819–830 \n17.  Austin PC, Tu JV, Ho JE, Levy D, Lee DS (2013) Using methods from the data-mining and machine-learning \nliterature for disease classification and prediction: a case study examining classification of heart failure \nsubtypes. Journal of clinical epidemiology 66:398–407 \n18.  Wei W-Q, Denny JC (2015) Extracting research-quality phenotypes from electronic health records to support \nprecision medicine. Genome medicine 7:1–14 \n19.  Ananthakrishnan AN, Cagan A, Cai T, Gainer VS, Shaw SY, Savova G, Churchill S, Karlson EW, Murphy SN, Liao KP \n(2016) Identification of nonresponse to treatment using narrative data in an electronic health record \ninflammatory bowel disease cohort. Inflammatory bowel diseases 22:151–158 \n20.  Ebadollahi S, Sun J, Gotz D, Hu J, Sow D, Neti C (2010) Predicting patient’s trajectory of physiological data using \ntemporal trends in similar patients: a system for near-term prognostics. In: AMIA annual symposium \nproceedings. American Medical Informatics Association, p 192 \n21.  Pinaire J, Azé J, Bringay S, Landais P (2017) Patient healthcare trajectory. An essential monitoring tool: a \nsystematic review. Health information science and systems 5:1–18 \n22.  Pham T, Tran T, Phung D, Venkatesh S (2017) Predicting healthcare trajectories from medical records: A deep \nlearning approach. Journal of biomedical informatics 69:218–229 \n23.  Romano MJ, Stafford RS (2011) Electronic health records and clinical decision support systems: impact on \nnational ambulatory care quality. Archives of internal medicine 171:897–903 \n24.  Zhao D, Weng C (2011) Combining PubMed knowledge and EHR data to develop a weighted bayesian network \nfor pancreatic cancer prediction. Journal of biomedical informatics 44:859–868 \n25.  Kuperman GJ, Bobb A, Payne TH, Avery AJ, Gandhi TK, Burns G, Classen DC, Bates DW (2007) Medication-\nrelated clinical decision support in computerized provider order entry systems: a review. Journal of the \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \nAmerican Medical Informatics Association 14:29–40 \n26.  Cai X, Perez-Concha O, Coiera E, Martin-Sanchez F, Day R, Roffe D, Gallego B (2016) Real-time prediction of \nmortality, readmission, and length of stay using electronic health record data. Journal of the American Medical \nInformatics Association 23:553–561 \n27.  Tabak YP, Sun X, Nunez CM, Johannes RS (2014) Using electronic health record data to develop inpatient \nmortality predictive model: Acute Laboratory Risk of Mortality Score (ALaRMS). Journal of the American \nMedical Informatics Association 21:455–463 \n28.  Lee J, Maslove DM, Dubin JA (2015) Personalized mortality prediction driven by electronic medical data and a \npatient similarity metric. PloS one 10:e0127428 \n29.  Raghupathi W, Raghupathi V (2014) Big data analytics in healthcare: promise and potential. Health information \nscience and systems 2:1–10 \n30.  Yadav P, Steinbach M, Kumar V, Simon G (2018) Mining electronic health records (EHRs) A survey. ACM \nComputing Surveys (CSUR) 50:1–40 \n31.  Critical Data MIT (2016) Secondary analysis of electronic health records. Springer Nature \n32.  Gaudet-Blavignac C, Raisaro JL, Touré V, Österle S, Crameri K, Lovis C (2021) A national, semantic-driven, three-\npillar strategy to enable health data secondary usage interoperability for research within the swiss personalized \nhealth network: Methodological study. JMIR Medical Informatics 9:e27591 \n33.  Teodoro D, Choquet R, Schober D, Mels G, Pasche E, Ruch P, Lovis C (2011) Interoperability driven integration \nof biomedical data sources. Studies in health technology and informatics 169:185–9 \n34.  Cunningham JA, Van Speybroeck M, Kalra D, Verbeeck R (2016) Nine principles of semantic harmonization. In: \nAMIA Annual Symposium Proceedings. American Medical Informatics Association, p 451 \n35.  Goble C, Stevens R (2008) State of the nation in data integration for bioinformatics. Journal of biomedical \ninformatics 41:687–693 \n36.  Hodge GM (2000) Systems of knowledge organization for digital libraries: beyond traditional authority files. \nDigital Library Federation \n37.  Organization WH (2004) International Statistical Classification of Diseases and related health problems: \nAlphabetical index. World Health Organization \n38.  WHOCC - ATC/DDD Index. https: //www.who.int/tools/atc-ddd-toolkit/atc-classification. Accessed 26 Mar 2023 \n39.  SNOMED CT. https://www.nlm.nih.gov/healthit/snomedct/index.html. Accessed 26 Mar 2023 \n40.  Lee CH, Yoon H-J (2017) Medical big data: promise and challenges. Kidney research and clinical practice 36:3 \n41.  Adnan K, Akbar R, Khor SW, Ali ABA (2020) Role and challenges of unstructured big data in healthcare. Data \nManagement, Analytics and Innovation: Proceedings of ICDMAI 2019, Volume 1 301–323 \n42.  Obermeyer Z, Emanuel EJ (2016) Predicting the future—big data, machine learning, and clinical medicine. The \nNew England journal of medicine 375:1216 \n43.  Pfaff ER, Madlock-Brown C, Baratta JM, Bhatia A, Davis H, Girvin A, Hill E, Kelly E, Kostka K, Loomba J (2023) \nCoding long COVID: characterizing a new disease through an ICD-10 lens. BMC medicine 21:1–13 \n44.  Si Y, Du J, Li Z, Jiang X, Miller T, Wang F, Zheng WJ, Roberts K (2021) Deep representation learning of patient \ndata from Electronic Health Records (EHR): A systematic review. Journal of Biomedical Informatics 115:103671 \n45.  Choi E, Bahadori MT, Schuetz A, Stewart WF, Sun J (2016) Doctor ai: Predicting clinical events via recurrent \nneural networks. In: Machine learning for healthcare conference. PMLR, pp 301–318 \n46.  Choi E, Bahadori MT, Song L, Stewart WF, Sun J (2017) GRAM: graph-based attention model for healthcare \nrepresentation learning. In: Proceedings of the 23rd ACM SIGKDD international conference on knowledge \ndiscovery and data mining. pp 787–795 \n47.  Choi E, Xu Z, Li Y, Dusenberry M, Flores G, Xue E, Dai A (2020) Learning the graphical structure of electronic \nhealth records with graph convolutional transformer. In: Proceedings of the AAAI conference on artificial \nintelligence. pp 606–613 \n48.  Miotto R, Wang F, Wang S, Jiang X, Dudley JT (2018) Deep learning for healthcare: review, opportunities and \nchallenges. Briefings in bioinformatics 19:1236–1246 \n49.  Shickel B, Tighe PJ, Bihorac A, Rashidi P (2017) Deep EHR: a survey of recent advances in deep learning \ntechniques for electronic health record (EHR) analysis. IEEE journal of biomedical and health informatics \n22:1589–1604 \n50.  Xiao C, Choi E, Sun J (2018) Opportunities and challenges in developing deep learning models using electronic \nhealth records data: a systematic review. Journal of the American Medical Informatics Association 25:1419–\n1428 \n51.  Egger J, Gsaxner C, Pepe A, Pomykala KL, Jonske F, Kurz M, Li J, Kleesiek J (2022) Medical deep learning–a \nsystematic meta-review. Computer methods and programs in biomedicine 106874 \n52.  Lipton ZC, Kale DC, Elkan C, Wetzel R (2015) Learning to diagnose with LSTM recurrent neural networks. arXiv \npreprint arXiv:1511.03677 \n53.  Song H, Rajan D, Thiagarajan J, Spanias A (2018) Attend and diagnose: Clinical time series analysis using \nattention models. Proceedings of the AAAI conference on artificial intelligence 32: \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \n54.  Choi E, Bahadori MT, Sun J, Kulas J, Schuetz A, Stewart W (2016) Retain: An interpretable predictive model for \nhealthcare using reverse time attention mechanism. Advances in neural information processing systems 29: \n55.  Nguyen P, Tran T, Wickramasinghe N, Venkatesh S (2016) $\\mathtt {Deepr} $: a convolutional net for medical \nrecords. IEEE journal of biomedical and health informatics 21:22–30 \n56.  Cheng Y, Wang F, Zhang P, Hu J (2016) Risk prediction with electronic health records: A deep learning approach. \nIn: Proceedings of the 2016 SIAM international conference on data mining. SIAM, pp 432–440 \n57.  Nori VS, Hane CA, Sun Y, Crown WH, Bleicher PA (2020) Deep neural network models for identifying incident \ndementia using claims and EHR datasets. Plos one 15:e0236400 \n58.  Gunasekar S, Ho JC, Ghosh J, Kreml S, Kho AN, Denny JC, Malin BA, Sun J (2016) Phenotyping using Structured \nCollective Matrix Factorization of Multi--source EHR Data. arXiv preprint arXiv:1609.04466 \n59.  Ni Y, Bachtel A, Nause K, Beal S (2021) Automated detection of substance use information from electronic \nhealth records for a pediatric population. Journal of the American Medical Informatics Association 28:2116–\n2127 \n60.  Eisman AS, Shah NR, Eickhoff C, Zerveas G, Chen ES, Wu W-C, Sarkar IN (2020) Extracting angina symptoms \nfrom clinical notes using pre-trained transformer architectures. In: AMIA Annual Symposium Proceedings. \nAmerican Medical Informatics Association, p 412 \n61.  Gehrmann S, Dernoncourt F, Li Y, Carlson ET, Wu JT, Welt J, Foote Jr J, Moseley ET, Grant DW, Tyler PD (2018) \nComparing deep learning and concept extraction based methods for patient phenotyping from clinical \nnarratives. PloS one 13:e0192360 \n62.  Wei Q, Ji Z, Li Z, Du J, Wang J, Xu J, Xiang Y, Tiryaki F, Wu S, Zhang Y (2020) A study of deep learning approaches \nfor medication and adverse drug event extraction from clinical text. Journal of the American Medical \nInformatics Association 27:13–21 \n63.  Pivovarov R, Perotte AJ, Grave E, Angiolillo J, Wiggins CH, Elhadad N (2015) Learning probabilistic phenotypes \nfrom heterogeneous EHR data. Journal of biomedical informatics 58:156–165 \n64.  Ferté T, Cossin S, Schaeverbeke T, Barnetche T, Jouhet V, Hejblum BP (2021) Automatic phenotyping of \nelectronical health record: PheVis algorithm. Journal of Biomedical Informatics 117:103746 \n65.  Ahuja Y, Zou Y, Verma A, Buckeridge D, Li Y (2022) MixEHR-Guided: A guided multi-modal topic modeling \napproach for large-scale automatic phenotyping using the electronic health record. Journal of biomedical \ninformatics 134:104190 \n66.  Kapoor A, Ben X, Liu L, Perozzi B, Barnes M, Blais M, O’Banion S (2020) Examining covid-19 forecasting using \nspatio-temporal graph neural networks. arXiv preprint arXiv:2007.03113 \n67.  Lybarger K, Ostendorf M, Thompson M, Yetisgen M (2021) Extracting COVID-19 diagnoses and symptoms from \nclinical text: A new annotated corpus and neural event extraction framework. Journal of Biomedical Informatics \n117:103761 \n68.  Delijewski M, Haneczok J (2021) AI drug discovery screening for COVID-19 reveals zafirlukast as a repurposing \ncandidate. Medicine in Drug Discovery 9:100077 \n69.  Zhou Y, Wang F, Tang J, Nussinov R, Cheng F (2020) Artificial intelligence in COVID-19 drug repurposing. The \nLancet Digital Health 2:e667–e676 \n70.  Muñoz AA, Carro EU, Santamaría LP, Carrasco BO, Ruiz EM, Gallardo YP, Rodriguez-Gonzalez A (2022) \nREDIRECTION: Generating drug repurposing hypotheses using link prediction with DISNET data. In: 2022 IEEE \n35th International Symposium on Computer-Based Medical Systems (CBMS). IEEE, pp 7–12 \n71.  Santamaría LP, Uzquiano MD, Carro EU, Ortiz-Roldán N, Gallardo YP, Rodríguez-González A (2021) Integrating \nheterogeneous data to facilitate COVID-19 drug repurposing. Drug Discovery Today \n72.  Obeid JS, Davis M, Turner M, Meystre SM, Heider PM, O’Bryan EC, Lenert LA (2020) An artificial intelligence \napproach to COVID-19 infection risk assessment in virtual visits: A case report. Journal of the American Medical \nInformatics Association 27:1321–1325 \n73.  Wanyan T, Honarvar H, Jaladanki SK, Zang C, Naik N, Somani S, De Freitas JK, Paranjpe I, Vaid A, Zhang J (2021) \nContrastive learning improves critical event prediction in COVID-19 patients. Patterns 2:100389 \n74.  Schwab P, Mehrjou A, Parbhoo S, Celi LA, Hetzel J, Hofer M, Schölkopf B, Bauer S (2021) Real-time prediction of \nCOVID-19 related mortality using electronic health records. Nature communications 12:1058 \n75.  Bai T, Chanda AK, Egleston BL, Vucetic S (2018) EHR phenotyping via jointly embedding medical concepts and \nwords into a unified vector space. BMC medical informatics and decision making 18:15–25 \n76.  Zhu Z, Yin C, Qian B, Cheng Y, Wei J, Wang F (2016) Measuring patient similarities via a deep architecture with \nmedical concept embedding. In: 2016 IEEE 16th International Conference on Data Mining (ICDM). IEEE, pp 749–\n758 \n77.  Amunategui M, Markwell T, Rozenfeld Y (2015) Prediction using note text: Synthetic feature creation with \nword2vec. arXiv preprint arXiv:1503.05123 \n78.  Turner CA, Jacobs AD, Marques CK, Oates JC, Kamen DL, Anderson PE, Obeid JS (2017) Word2Vec inversion and \ntraditional text classifiers for phenotyping lupus. BMC medical informatics and decision making 17:1–11 \n79.  Jaume-Santero F, Zhang B, Proios D, Yazdani A, Gouareb R, Bjelogrlic M, Teodoro D (2022) Cluster Analysis of \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint \n \n \nLow-Dimensional Medical Concept Representations from Electronic Health Records. In: Health Information \nScience: 11th International Conference, HIS 2022, Virtual Event, October 28–30, 2022, Proceedings. Springer, \npp 313–324 \n80.  Steinberg E, Jung K, Fries JA, Corbin CK, Pfohl SR, Shah NH (2021) Language models are an effective \nrepresentation learning technique for electronic health record data. Journal of biomedical informatics \n113:103637 \n81.  Choi E, Xiao C, Stewart W, Sun J (2018) Mime: Multilevel medical embedding of electronic health records for \npredictive healthcare. Advances in neural information processing systems 31: \n82.  Li Y, Rao S, Solares JRA, Hassaine A, Ramakrishnan R, Canoy D, Zhu Y, Rahimi K, Salimi-Khorshidi G (2020) \nBEHRT: transformer for electronic health records. Scientific reports 10:1–12 \n83.  Rasmy L, Xiang Y, Xie Z, Tao C, Zhi D (2021) Med-BERT: pretrained contextualized embeddings on large-scale \nstructured electronic health records for disease prediction. NPJ digital medicine 4:86 \n84.  Mikolov T, Chen K, Corrado G, Dean J (2013) Efficient estimation of word representations in vector space. arXiv \npreprint arXiv:1301.3781 \n85.  Joulin A, Grave E, Bojanowski P, Mikolov T (2016) Bag of tricks for efficient text classification. arXiv preprint \narXiv:1607.01759 \n86.  Bojanowski P, Grave E, Joulin A, Mikolov T (2017) Enriching word vectors with subword information. \nTransactions of the association for computational linguistics 5:135–146 \n87.  Pennington J, Socher R, Manning CD (2014) Glove: Global vectors for word representation. In: Proceedings of \nthe 2014 conference on empirical methods in natural language processing (EMNLP). pp 1532–1543 \n88.  Beam AL, Kompa B, Schmaltz A, Fried I, Weber G, Palmer N, Shi X, Cai T, Kohane IS (2019) Clinical concept \nembeddings learned from massive sources of multimodal medical data. In: Pacific Symposium on Biocomputing \n2020. World Scientific, pp 295–306 \n89.  Huang J, Xu K, Vydiswaran VV (2016) Analyzing multiple medical corpora using word embedding. In: 2016 IEEE \nInternational Conference on Healthcare Informatics (ICHI). IEEE, pp 527–533 \n90.  Wang Y, Liu S, Afzal N, Rastegar-Mojarad M, Wang L, Shen F, Kingsbury P, Liu H (2018) A comparison of word \nembeddings for the biomedical natural language processing. Journal of biomedical informatics 87:12–20 \n91.  Dynomant E, Lelong R, Dahamna B, Massonnaud C, Kerdelhué G, Grosjean J, Canu S, Darmoni SJ (2019) Word \nembedding for the French natural language in health care: comparative study. JMIR medical informatics \n7:e12310 \n92.  Johnson AE, Bulgarelli L, Shen L, Gayles A, Shammout A, Horng S, Pollard TJ, Moody B, Gow B, Lehman LH \n(2023) MIMIC-IV, a freely accessible electronic health record dataset. Scientific data 10:1 \n93.  Kury FS, Bodenreider O (2017) Mapping US FDA National Drug Codes to Anatomical-Therapeutic-Chemical \nClasses using RxNorm. AMIA \n94.  Nelson SJ, Zeng K, Kilbourne J, Powell T, Moore R (2011) Normalized names for clinical drugs: RxNorm at 6 \nyears. Journal of the American Medical Informatics Association 18:441–448 \n95.  Mikolov T, Sutskever I, Chen K, Corrado GS, Dean J (2013) Distributed representations of words and phrases \nand their compositionality. Advances in neural information processing systems 26: \n96.  Van der Maaten L, Hinton G (2008) Visualizing data using t-SNE. Journal of machine learning research 9: \n97.  Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, Blondel M, Prettenhofer P, Weiss R, \nDubourg V (2011) Scikit-learn: Machine learning in Python. the Journal of machine Learning research 12:2825–\n2830 \n98.  Ma Y, Tsao D, Shum H-Y (2022) On the principles of parsimony and self-consistency for the emergence of \nintelligence. Frontiers of Information Technology & Electronic Engineering 23:1298–1323 \n99.  Chan KHR, Yu Y, You C, Qi H, Wright J, Ma Y (2022) ReduNet: A white-box deep network from the principle of \nmaximizing rate reduction. The Journal of Machine Learning Research 23:4907–5009 \n100.  McInnes L, Healy J, Astels S (2017) hdbscan: Hierarchical density based clustering. J Open Source Softw 2:205 \n101.  Hur K, Lee J, Oh J, Price W, Kim Y, Choi E (2022) Unifying Heterogeneous Electronic Health Records Systems via \nText-Based Code Embedding. In: Conference on Health, Inference, and Learning. PMLR, pp 183–203 \n102.  Hur K, Oh J, Kim J, Kim J, Lee MJ, Cho E, Moon S-E, Kim Y-H, Choi E (2022) UniHPF: Universal Healthcare \nPredictive Framework with Zero Domain Knowledge. arXiv preprint arXiv:2211.08082 \n103.  Smith G, Nielsen M (1999) Criteria for admission. Bmj 318:1544–1547 \n \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 5, 2023. ; https://doi.org/10.1101/2023.06.01.23290824doi: medRxiv preprint ",
  "topic": "Word2vec",
  "concepts": [
    {
      "name": "Word2vec",
      "score": 0.8717334270477295
    },
    {
      "name": "Computer science",
      "score": 0.6907100677490234
    },
    {
      "name": "Semantics (computer science)",
      "score": 0.603098452091217
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5791784524917603
    },
    {
      "name": "Natural language processing",
      "score": 0.576113760471344
    },
    {
      "name": "Similarity (geometry)",
      "score": 0.5435978174209595
    },
    {
      "name": "ENCODE",
      "score": 0.5410017967224121
    },
    {
      "name": "Representation (politics)",
      "score": 0.49632078409194946
    },
    {
      "name": "Distributional semantics",
      "score": 0.4806303381919861
    },
    {
      "name": "Language model",
      "score": 0.46424731612205505
    },
    {
      "name": "Unified Medical Language System",
      "score": 0.44602125883102417
    },
    {
      "name": "Machine learning",
      "score": 0.38619521260261536
    },
    {
      "name": "Semantic similarity",
      "score": 0.28590553998947144
    },
    {
      "name": "Embedding",
      "score": 0.11745560169219971
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Image (mathematics)",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I114457229",
      "name": "University of Geneva",
      "country": "CH"
    },
    {
      "id": "https://openalex.org/I173439891",
      "name": "HES-SO University of Applied Sciences and Arts Western Switzerland",
      "country": "CH"
    },
    {
      "id": "https://openalex.org/I56590836",
      "name": "Monash University",
      "country": "AU"
    },
    {
      "id": "https://openalex.org/I4210106256",
      "name": "University Hospital of Geneva",
      "country": "CH"
    },
    {
      "id": "https://openalex.org/I157485424",
      "name": "Korea Advanced Institute of Science and Technology",
      "country": "KR"
    }
  ]
}