{
  "title": "A Future of Smarter Digital Health Empowered by Generative Pretrained Transformer",
  "url": "https://openalex.org/W4386228009",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5085827512",
      "name": "Hongyu Miao",
      "affiliations": [
        "Florida State University"
      ]
    },
    {
      "id": "https://openalex.org/A5101561593",
      "name": "Chengdong Li",
      "affiliations": [
        "Florida State University"
      ]
    },
    {
      "id": "https://openalex.org/A5100651242",
      "name": "Jing Wang",
      "affiliations": [
        "Florida State University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4381550225",
    "https://openalex.org/W1605743674",
    "https://openalex.org/W2405966729",
    "https://openalex.org/W4251337230",
    "https://openalex.org/W2789608004",
    "https://openalex.org/W2917052233",
    "https://openalex.org/W2946661638",
    "https://openalex.org/W4224866902",
    "https://openalex.org/W2771435422",
    "https://openalex.org/W2102560179",
    "https://openalex.org/W3086667591",
    "https://openalex.org/W3087532900",
    "https://openalex.org/W3012501605",
    "https://openalex.org/W4321606510",
    "https://openalex.org/W4318591734",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W4293192484",
    "https://openalex.org/W4377138257",
    "https://openalex.org/W4309623083",
    "https://openalex.org/W4320920036",
    "https://openalex.org/W4322208207",
    "https://openalex.org/W4319341091",
    "https://openalex.org/W3086590218",
    "https://openalex.org/W4386045865",
    "https://openalex.org/W4381480701"
  ],
  "abstract": "Generative pretrained transformer (GPT) tools have been thriving, as ignited by the remarkable success of OpenAI’s recent chatbot product. GPT technology offers countless opportunities to significantly improve or renovate current health care research and practice paradigms, especially digital health interventions and digital health–enabled clinical care, and a future of smarter digital health can thus be expected. In particular, GPT technology can be incorporated through various digital health platforms in homes and hospitals embedded with numerous sensors, wearables, and remote monitoring devices. In this viewpoint paper, we highlight recent research progress that depicts the future picture of a smarter digital health ecosystem through GPT-facilitated centralized communications, automated analytics, personalized health care, and instant decision-making.",
  "full_text": "Viewpoint\nA Future of Smarter Digital Health Empowered by Generative\nPretrained Transformer\nHongyu Miao, PhD; Chengdong Li, PhD; Jing Wang, PhD\nCollege of Nursing, Florida State University, Tallahassee, FL, United States\nCorresponding Author:\nJing Wang, PhD\nCollege of Nursing\nFlorida State University\n98 Varsity Way\nTallahassee, FL, 32306\nUnited States\nPhone: 1 8506443299\nEmail: JingWang@nursing.fsu.edu\nAbstract\nGenerative pretrained transformer (GPT) tools have been thriving, as ignited by the remarkable success of OpenAI’s recent\nchatbot product. GPT technology offers countless opportunities to significantly improve or renovate current health care research\nand practice paradigms, especially digital health interventions and digital health–enabled clinical care, and a future of smarter\ndigital health can thus be expected. In particular, GPT technology can be incorporated through various digital health platforms\nin homes and hospitals embedded with numerous sensors, wearables, and remote monitoring devices. In this viewpoint paper,\nwe highlight recent research progress that depicts the future picture of a smarter digital health ecosystem through GPT-facilitated\ncentralized communications, automated analytics, personalized health care, and instant decision-making.\n(J Med Internet Res 2023;25:e49963) doi: 10.2196/49963\nKEYWORDS\ngenerative pretrained model; artificial intelligence; digital health; generative pretrained transformer; ChatGPT; precision medicine;\nAI; privacy; ethics\nIntroduction\nAs a very successful commercial product in the market, the big\nstory of ChatGPT started with an adventure of a group of Google\nresearchers in 2017 [1], who introduced the transformer structure\nbased on an attention mechanism for a specific natural language\nprocessing (NLP) task—neural machine translation. OpenAI\nbuilt ChatGPT upon this technology, and it is one of the fastest\ngrowing consumer applications [2]. The magic here is\nquantitative change leading to qualitative change: ChatGPT has\nsignificantly more model parameters than the original attention\nmodel. More specifically, Generative Pretrained\nTransformer–3.5 (GPT-3.5) [3] launched in November 2022\nhas 175 billion parameters and GPT-4.0 [4] released in March\n2023 has 1 trillion parameters. For this reason, ChatGPT and\nits competitors including Google Bard and Facebook LLaMA\nare called large language models (LLMs). However, training\nLLMs is expensive, and the estimated cost falls between US $2\nmillion and US $12 million nowadays [5]. OpenAI thus adopts\na traditional business model for its groundbreaking product to\n“share” such costs primarily via monthly user subscription. In\nMarch 2023, ChatGPT alone reached 1.16 billion registered\nusers [6]. Note that many users are attracted to LLMs because\nof the great potential of GPT tools in improving and renovating\nhealth care research and practice [7], including the current\ntransformation happening in digitizing health care [8].\nDigital health is a blooming field in which digital technology,\nmedicine, behavior, health care, and community living are\nintegrated for health improvement of both the population and\nindividuals [9-15]. In particular, the development and\ndeployment of innovative hardware and software (eg, wearable\nand implantable sensors and mobile apps) and communication\ntechnologies (eg, real-time augmented reality and streaming\ndata platforms) lay the foundation of modern digital health.\nWithin the past decade, numerous novel concepts and ideas in\ndigital health have been generated to renovate our health care\nsystems, triumphing over a variety of challenges in improving\ntreatment efficacy, reshaping health care delivery, personalizing\nmedical and behavioral intervention, etc. One representative\nexample of digital medicine is deep brain stimulation for, for\nexample, drug-resistant epilepsy [16], where medications are\nJ Med Internet Res 2023 | vol. 25 | e49963 | p. 1https://www.jmir.org/2023/1/e49963\n(page number not for citation purposes)\nMiao et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nnot in the traditional form of chemical compounds but\nimplantable chips with computational intelligence for seizure\nonset detection and disruption. We are also witnessing the\nthriving of numerous mobile medical and health apps [17] for,\nfor example, emergency medicine, chronic condition\nmanagement, behavioral medicine, and mental health, all of\nwhich heavily rely on existing or novel communication\ntechnologies such as Bluetooth, 5G, Wi-Fi, and privacy\nprotection instruments. The built-in complexity of digital health\ntools and their significantly large number of data elements\ngenerated through such tools naturally call for the customization\nand application of artificial intelligence (AI)–based devices and\nalgorithms [18-20]. Therefore, it is not an exaggeration to say\nthat we live in an era of intelligent digital health. Given the\nremarkable success of GPT in many fields, including but not\nlimited to protein design [21], drug discovery [22], intelligent\ntransportation [23], and health care research and practice [24],\nintelligent digital health is expected to become even smarter if\nappropriately integrated with LLMs such as ChatGPT.\nIn this viewpoint paper, we discuss how GPT tools could lead\nto smarter digital health, and we briefly describe certain areas\nof caution related to the use of GPT and similar AI tools in\ndigital health education, research, and practice.\nSimplification and Streamlining of\nCommunication to Reduce Clinician\nBurden\nIn digital health research and practice, communication has never\nbeen as simple as in-person conversations between patients and\nclinicians. Frequent communications among various hardware,\nsoftware, backend cloud or streaming data platforms, engineers,\ndata scientists, patients, and health care providers are the\ncommon scene for digital health applications. For instance,\nstreaming time-series data are constantly measured by a variety\nof mobile sensors (eg, accelerometers, gyroscopes,\nthermometers, and photoplethysmography), and such data might\nbe preprocessed and transferred in real time via secured\nBluetooth, Wi-Fi, or 5G to centralized data cloud for storage,\nmanagement, analysis, and mining by engineers, data scientists,\nor automated algorithms. The summarized results (eg, diagnostic\nor prognostic) may then be sent to health care providers for\ninterpretation and decision-making, which are eventually\nconveyed to patients via, for example, mobile apps. The\ninteresting thing is that despite the central roles of mobile\nsensors in such communication cycles, users currently do not\nhave the option to directly “talk” to such sensors. It is not\ndifficult to imagine how significantly the aforementioned\ncommunication cycle can be simplified if wearable or mobile\nsensors can passively or actively vocalize the health status (eg,\nsymptoms, anomalies, and behavioral changes) they detect, and\neven give instant suggestions or make decisions such as\nemergent calls directly for the users. Technically, achieving this\ngoal requires a better integrated electronic system, a higher\nmarginal computing power, and a GPT-powered brain. If one\nmay question the feasibility of such smarter sensor-based\ncommunication in digital health by pointing out that speakers\nand microphones are too bulky to fit in small chips, one must\nconsider that Massachusetts Institute of Technology researchers\nhave recently developed a paper-thin loudspeaker that is\npotentially wearable [25]. Note that many other industries are\nsharing the same vision; for instance, Amazon is loading\nChatGPT into its Alexa devices and Boston Dynamics is\nenabling their robots to speak after the integration with\nChatGPT. Finally, as a selected example, a recent study\nconducted by Tafferner et al [26] presented interesting attempts\ntoward the integration of ChatGPT with temperature, light,\nmotion, humidity, gas, water, or smoke sensors in the smart\nhome setting, and ChatGPT was found to be able to even\nfacilitate the design of such smart home systems and thus reduce\nthe workload of not only health care professionals but also\nsystem engineers.\nDevelopment of Personalized or Precise\nDigital Health Interventions\nIt is not surprising that nowadays people are asking ChatGPT\nvarious medical and health care questions, including available\ntherapies for specific diseases or options for symptom\nmanagement. As a commercial product made available to the\npublic, ChatGPT is expected to give similar answers to the same\nquestion even if asked by different people. However, a natural\nquestion to ask is whether LLMs can learn individual user\npreferences like many other AI tools do, such that ChatGPT\ncan adapt to a specific user’s trajectory (eg, inquiry history,\ncontent of interest, satisfaction with answers, and type and\nfrequency of purposeful use) and thus may provide customized\ncontents in a personalized tone. This is a question of significant\ninterest to both users and researchers. A very recent article by\nthe Brain Team of Google Research [27] just tackled this exact\nquestion by evaluating the effectiveness of an LLM-based\nrecommendation system, and their results suggested the\nfeasibility and potential of such concepts. An alternative solution\nis to create a personal version of ChatGPT (also known as\nprivate and individualized AI), the training and operation of\nwhich should be afforded through a PC rather than\nhigh-performance computing clusters. There are multiple\nongoing efforts in both directions, and the good news is that\ntools such as MiniGPT-4 have been made available to the public\nand they are intended for individual use. Personalized ChatGPT\ncould substantially renovate the ecosphere of digital health.\nLike oncology treatment, many one-size-fits-all digital health\ntherapies or interventions have been proven less effective or\nfutile in terms of minimizing harms and maximizing benefits\nto an individual. There is a need for precision oncology\ntreatment in a similar way for precision digital health therapies\nor interventions. Using nonpharmacological neuromodulation\n(eg, transcranial magnetic or electrical stimulation) as an\nexample, it remains unclear to researchers what factors or\nmechanisms dictate whether and how an individual will\npositively respond to open-loop neuromodulation. This is an\nimportant question as the percentage of nonresponders found\nin previous digital health studies could be 20% or higher.\nPersonalized ChatGPT is expected to help our researchers to\nbetter understand individual-level behavioral patterns, stress\nlevels, vital sign trajectories, dietary habits, health care needs,\nand even instant treatment responses. We also expect a gradual\nJ Med Internet Res 2023 | vol. 25 | e49963 | p. 2https://www.jmir.org/2023/1/e49963\n(page number not for citation purposes)\nMiao et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nshift of classical clinical trial design paradigms toward an\nAI-assisted N-of-1 trial design in digital health. Toward such\ngoals, the recent work of Singhal et al [7] should be noted as a\nrepresentative example since they introduced an expert-level\nmedical question–answering platform based on LLM, which\ncan be tailored to specific health care domains and eventually\nbe personalized as an individual’s health care assistant after\nappropriate data feeding and parameter tuning.\nImprove Analytics to Enable Easier\nInterpretation and Better Clinical\nDecision-Making\nNLP research and its applications have a long history that can\nbe traced back to Turing’s thinking machine and the\nHodgkin-Huxley model in the 1950s. However, analytic power\nhad never been the focus of NLP methodology development\nbefore ChatGPT was launched. It turned out to be a big surprise\nto many users that ChatGPT, as an NLP product, can carry out\ncomputer coding and data analytics even better than many entry-\nto moderate-level professionals. While it is well known that\nmore than 145 million dialogues extracted from various sources\n(eg, Twitter, Reddit, and Wikipedia) have been used to train\nChatGPT, people may wonder what, in addition to the power\nof big data, suddenly grants LLMs analytical skills. We\nhypothesize that such observation should be attributed to the\npower of language itself. Specifically, language data are\ndifferent from many other data types in the sense that instead\nof cold numbers, language data contain rich amounts of human\nthinking, logic, knowledge, behavioral patterns, etc. Anyway,\nlanguage data are a type of so-called sequence data. Since LLMs\nare capable of processing and understanding language data well,\nwe speculate the possibility of using LLMs for other types of\nsequence data such as multivariate time series. In the digital\nhealth field, a big volume of various sequence data, including\nbut not limited to vital sign signals, electronic health or medical\nrecords, image streams, clinical genetic or metabolic profiles,\nand ambient sensor signals, are being generated every day from,\nfor example, hospitals, clinics, outpatient organizations,\ncommunities, and individuals worldwide. Such big and complex\nsequence data present serious challenges to the analytic\ncapabilities of many existing algorithms and tools. LLMs such\nas ChatGPT could be an alternative framework to better address\ndigital health data analytical problems. For recent progress along\nthis line of ideas, BERT-log [28] and AnomalyBERT [29] for\nanomaly detection in sequence data can be noted. Also, it should\nbe noted that OpenAI recently used GPT-4 to explain every\nneuron in GPT-2, which suggests a different but promising\ndirection of using ChatGPT’s analytic power for deep learning\ninterpretation. Further examples of ChatGPT’s applications in\nhealth care analytics and decision-making include the work of\nHirosawa et al [30] for differential diagnosis list generation and\nthat of Rao et al [31,32] for clinical decision-making support\nincluding cancer screening.\nPrivacy and Ethical Issues of Trustworthy\nGPT Tools for Digital Health\nWith the right training data and right model structure, ChatGPT\nis now able to speak like a human; however, it has not evolved\nsufficiently to think like a human, which is a double-edged\nsword for humanity. Even at the current stage of its maturity,\nnumerous concerns regarding privacy, ethics, job security,\neducation policies, etc, have been raised regarding the use of\nChatGPT in various scenarios. In digital health, the story is the\nsame. The most common way of using ChatGPT is to input\nquestions or upload digital documents (or both). It is possible\nthat such information is intercepted by malicious third parties,\ncausing serious privacy concerns especially when protected\nhealth information is involved. Currently, it is unclear to the\npublic how OpenAI will detect and protect such sensitive\ninformation. Another common concern for digital health\nprofessional communities is the possibility of a scientist either\nwriting or reviewing manuscripts or grant applications using\nChatGPT. Given the many years of training and experience of\na qualified scientist, using ChatGPT to carry out such work\nlooks “reckless” and “not scientific” to many of our peers. The\nother side of the story is that researchers constantly get\nassistance from various colleagues, mentors, training courses,\nand scientific writing specialists. Therefore, using ChatGPT as\nan assistant tool may resemble the aforementioned kind of help\nand may thus be acceptable. However, the real situation is\ntrickier than that. One must consider the possibility of a scientist\nasking ChatGPT certain questions about a manuscript’s central\nidea that is new to the professional community or about the\nnovel specific aims of a grant proposal, or generating fake\ninformation or data (or both). When someone feeds such\nquestions or information into ChatGPT, they become a part of\nits knowledge base; this will make confidential or misleading\ninformation available to the whole system and to general users.\nThe development of safeguards that can protect privacy and\navoid ethical concerns when using GPT tools should be on our\ndigital health scientific communities’ agenda. Technically,\nmachine “unlearning” [33] might be one of the potential\nsolutions for GPT tools to “forget” certain information and thus\nprotect privacy and reduce ethical concerns.\nDespite major debates regarding the use of GPT tools for\neducation, research, and practice purposes, here we have\npresented a perspective and pioneering examples in the digital\nhealth field where GPT tools have the potential to enhance and\nempower a smarter future of digital health or more intelligent\nways to optimize digital health applications in reducing clinician\nburden, simplifying communications and workflow in health\ncare, and personalizing digital health interventions for precision\ntreatment responses. In short, considering various risks and\nconcerns of using GPT in digital health, we would like to call\non all GPT developers, digital health researchers, health care\npractitioners, and policy makers to coevolve smarter digital\nhealth technologies while developing privacy and ethical rules\nand policies embedding humanity principles in this\ntransformative GPT era in health and health care.\nJ Med Internet Res 2023 | vol. 25 | e49963 | p. 3https://www.jmir.org/2023/1/e49963\n(page number not for citation purposes)\nMiao et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nAcknowledgments\nHM’s work is partially supported by a National Science Foundation grant (#2133106). JW’s and HM’s work is supported in part\nby the National Institutes of Health’s National Center for Advancing Translational Sciences (award UL1TR001427).\nConflicts of Interest\nNone declared.\nReferences\n1. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, et al. Attention is all you need. 2017 Presented at:\n31st Conference on Neural Information Processing Systems (NIPS2017); December 4-9, 2017; Long Beach, CA\n2. Gordon C. ChatGPT is the fastest growing app in the history of web applications. Forbes. 2023 Feb 02. URL: https://www.\nforbes.com/sites/cindygordon/2023/02/02/chatgpt-is-the-fastest-growing-ap-in-the-history-of-web-applications/\n?sh=5e5e6f6b678c [accessed 2023-03-27]\n3. OpenAI. URL: https://openai.com/blog/gpt-3-edit-insert [accessed 2023-09-18]\n4. OpenAI. GPT-4 Technical Report. arXiv. Preprint posted online March 15, 2023. [FREE Full text]\n5. Li C. OpenAI's GPT-3 language model: a technical overview. Lambda. 2020. URL: https://lambdalabs.com/blog/\ndemystifying-gpt-3 [accessed 2023-09-18]\n6. Dhapte A. ChatGPT turns out to be most liked AI tools by the users in 2023. Market Research Future. 2023. URL: https:/\n/tinyurl.com/7udhf5a8 [accessed 2023-09-18]\n7. Singhal K, Tu T, Gottweis J, Sayres R, Wulczyn E, Hou L, et al. Towards expert-level medical question answering with\nlarge language models. arXiv. Preprint posted online May 16, 2023. [FREE Full text]\n8. Temsah M, Aljamaan F, Malki KH, Alhasan K, Altamimi I, Aljarbou R, et al. ChatGPT and the future of digital health: a\nstudy on healthcare workers' perceptions and expectations. Healthcare (Basel) 2023 Jun 21;11(13):A [FREE Full text] [doi:\n10.3390/healthcare11131812] [Medline: 37444647]\n9. Elenko E, Underwood L, Zohar D. Defining digital medicine. Nat Biotechnol 2015 May 12;33(5):456-461 [doi:\n10.1038/nbt.3222] [Medline: 25965750]\n10. Shinbane JS, Saxon LA. Digital monitoring and care: virtual medicine. Trends Cardiovasc Med 2016 Nov;26(8):722-730\n[doi: 10.1016/j.tcm.2016.05.007] [Medline: 27373351]\n11. Lupton D. Digital Health: Critical and Cross-Disciplinary Perspectives. Oxfordshire: Routledge; 2017.\n12. Vayena E, Haeusermann T, Adjekum A, Blasimme A. Digital health: meeting the ethical and policy challenges. Swiss Med\nWkly 2018 Jan 16;148:w14571 [doi: 10.4414/smw.2018.14571]\n13. Chen CE, Harrington RA, Desai SA, Mahaffey KW, Turakhia MP. Characteristics of digital health studies registered in\nClinicalTrials.gov. JAMA Intern Med 2019 Jun 01;179(6):838-840 [FREE Full text] [doi: 10.1001/jamainternmed.2018.7235]\n[Medline: 30801617]\n14. Mathews SC, McShea MJ, Hanley CL, Ravitz A, Labrique AB, Cohen AB. Digital health: a path to validation. NPJ Digit\nMed 2019 May 13;2(1):38 [FREE Full text] [doi: 10.1038/s41746-019-0111-3] [Medline: 31304384]\n15. Hrynyschyn R, Prediger C, Stock C, Helmer SM. Evaluation methods applied to digital health interventions: what is being\nused beyond randomised controlled trials?-A scoping review. Int J Environ Res Public Health 2022 Apr 25;19(9):5221\n[FREE Full text] [doi: 10.3390/ijerph19095221] [Medline: 35564616]\n16. Li MCH, Cook MJ. Deep brain stimulation for drug-resistant epilepsy. Epilepsia 2018 Feb 07;59(2):273-290 [doi:\n10.1111/epi.13964] [Medline: 29218702]\n17. Boulos MNK, Brewer AC, Karimkhani C, Buller DB, Dellavalle RP. Mobile medical and health apps: state of the art,\nconcerns, regulatory control and certification. Online J Public Health Inform 2014 Feb 05;5(3):229 [FREE Full text] [doi:\n10.5210/ojphi.v5i3.4814] [Medline: 24683442]\n18. Benjamens S, Dhunnoo P, Meskó B. The state of artificial intelligence-based FDA-approved medical devices and algorithms:\nan online database. NPJ Digit Med 2020 Sep 11;3:118 [doi: 10.1038/s41746-020-00324-0]\n19. Ho A. Are we ready for artificial intelligence health monitoring in elder care? BMC Geriatr 2020 Sep 21;20(1):358 [FREE\nFull text] [doi: 10.1186/s12877-020-01764-9] [Medline: 32957946]\n20. Rieke N, Hancox J, Li W, Milletarì F, Roth HR, Albarqouni S, et al. The future of digital health with federated learning.\nNPJ Digit Med 2020 Sep 14;3(1):119 [FREE Full text] [doi: 10.1038/s41746-020-00323-1] [Medline: 33015372]\n21. Eisenstein M. AI-enhanced protein design makes proteins that have never existed. Nat Biotechnol 2023 Mar 23;41(3):303-305\n[FREE Full text] [doi: 10.1038/s41587-023-01705-y] [Medline: 36823357]\n22. Sharma G, Thakur A. ChatGPT in Drug Discovery. Comput Theor Chem 2023 [doi: 10.26434/chemrxiv-2023-qgs3k]\n23. Zheng O, Abdel-Aty M, Wang D, Wang Z, Ding S. ChatGPT is on the horizon: could a large language model be suitable\nfor intelligent traffic safety research and applications? arXiv. Preprint posted online March 6, 2023. [FREE Full text]\n24. Sallam M. ChatGPT utility in healthcare education, research, and practice: systematic review on the promising perspectives\nand valid concerns. Healthcare (Basel) 2023 Mar 19;11(6):887 [FREE Full text] [doi: 10.3390/healthcare11060887]\n[Medline: 36981544]\nJ Med Internet Res 2023 | vol. 25 | e49963 | p. 4https://www.jmir.org/2023/1/e49963\n(page number not for citation purposes)\nMiao et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\n25. Han J, Lang JH, Bulovic V. An ultrathin flexible loudspeaker based on a piezoelectric microdome array. IEEE Trans Ind\nElectron 2023 Jan;70(1):985-994 [doi: 10.1109/tie.2022.3150082]\n26. Tafferner Z, Balázs I, Krammer O, Géczy A. Can ChatGPT help in electronics research and development? A case study\nwith applied sensors. Sensors (Basel) 2023 May 18;23(10):4879 [FREE Full text] [doi: 10.3390/s23104879] [Medline:\n37430793]\n27. Kang W, Ni J, Mehta N, Sathiamoorthy M, Hong L, Chi E, et al. Do LLMs understand user preferences? Evaluating LLMs\non user rating prediction. arXiv. Preprint posted online May 10, 2023. [FREE Full text]\n28. Chen S, Liao H. BERT-Log: anomaly detection for system logs based on pre-trained language model. Appl Artif Intell\n2022 Nov 17;36(1) [doi: 10.1080/08839514.2022.2145642]\n29. Jeong Y, Yang E, Ryu JH, Park I, Kang M. AnomalyBERT: Self-Supervised Transformer for Time Series Anomaly\nDetection using Data Degradation Scheme. arXiv. Preprint posted online May 8, 2023. [FREE Full text]\n30. Hirosawa T, Harada Y, Yokose M, Sakamoto T, Kawamura R, Shimizu T. Diagnostic accuracy of differential-diagnosis\nlists generated by Generative Pretrained Transformer 3 chatbot for clinical vignettes with common chief complaints: a pilot\nstudy. Int J Environ Res Public Health 2023 Feb 15;20(4):3378 [FREE Full text] [doi: 10.3390/ijerph20043378] [Medline:\n36834073]\n31. Rao A, Pang M, Kim J, Kamineni M, Lie W, Prasad AK, et al. Assessing the Utility of ChatGPT Throughout the Entire\nClinical Workflow. medRxiv. Preprint posted online February 26, 2023. [FREE Full text] [doi: 10.1101/2023.02.21.23285886]\n[Medline: 36865204]\n32. Rao A, Kim J, Kamineni M, Pang M, Lie W, Succi MD. Evaluating ChatGPT as an adjunct for radiologic decision-making.\nmedRxiv. Preprint posted online February 7, 2023. [FREE Full text] [doi: 10.1101/2023.02.02.23285399] [Medline:\n36798292]\n33. Bourtoule L, Chandrasekaran V, Choquette-Choo CA, Jia H, Travers A, Zhang B, et al. Machine unlearning. 2021 Presented\nat: 2021 IEEE Symposium on Security and Privacy (SP); May 24-27, 2021; San Francisco, CA\nAbbreviations\nAI: artificial intelligence\nGPT: Generative Pretrained Transformer\nLLM: large language model\nNLP: natural language processing\nEdited by G Eysenbach, T Leung; submitted 14.06.23; peer-reviewed by E Sezgin, H Tanaka, M Chatzimina; comments to author\n07.07.23; revised version received 30.07.23; accepted 28.08.23; published 26.09.23\nPlease cite as:\nMiao H, Li C, Wang J\nA Future of Smarter Digital Health Empowered by Generative Pretrained Transformer\nJ Med Internet Res 2023;25:e49963\nURL: https://www.jmir.org/2023/1/e49963\ndoi: 10.2196/49963\nPMID:\n©Hongyu Miao, Chengdong Li, Jing Wang. Originally published in the Journal of Medical Internet Research (https://www.jmir.org),\n26.09.2023. This is an open-access article distributed under the terms of the Creative Commons Attribution License\n(https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium,\nprovided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic\ninformation, a link to the original publication on https://www.jmir.org/, as well as this copyright and license information must\nbe included.\nJ Med Internet Res 2023 | vol. 25 | e49963 | p. 5https://www.jmir.org/2023/1/e49963\n(page number not for citation purposes)\nMiao et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX",
  "topic": "Digital health",
  "concepts": [
    {
      "name": "Digital health",
      "score": 0.6273068785667419
    },
    {
      "name": "Health care",
      "score": 0.5603221654891968
    },
    {
      "name": "Wearable computer",
      "score": 0.5380266904830933
    },
    {
      "name": "mHealth",
      "score": 0.5072738528251648
    },
    {
      "name": "Computer science",
      "score": 0.48122453689575195
    },
    {
      "name": "eHealth",
      "score": 0.4756429195404053
    },
    {
      "name": "Chatbot",
      "score": 0.4713919758796692
    },
    {
      "name": "Wearable technology",
      "score": 0.4418315291404724
    },
    {
      "name": "Telemedicine",
      "score": 0.4380026161670685
    },
    {
      "name": "Analytics",
      "score": 0.4182566702365875
    },
    {
      "name": "Data science",
      "score": 0.4072553515434265
    },
    {
      "name": "Internet privacy",
      "score": 0.370654433965683
    },
    {
      "name": "Psychological intervention",
      "score": 0.30708035826683044
    },
    {
      "name": "Medicine",
      "score": 0.22716262936592102
    },
    {
      "name": "World Wide Web",
      "score": 0.2160860300064087
    },
    {
      "name": "Embedded system",
      "score": 0.12411168217658997
    },
    {
      "name": "Nursing",
      "score": 0.10782349109649658
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Economic growth",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I103163165",
      "name": "Florida State University",
      "country": "US"
    }
  ]
}