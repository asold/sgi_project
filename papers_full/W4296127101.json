{
    "title": "Hyper-ES2T: Efficient Spatial–Spectral Transformer for the classification of hyperspectral remote sensing images",
    "url": "https://openalex.org/W4296127101",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2142863397",
            "name": "Wenxuan Wang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2117398542",
            "name": "Leiming Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2115153549",
            "name": "Tianxiang Zhang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2200686634",
            "name": "Jiachen Shen",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2096763361",
            "name": "Jing Wang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2119045575",
            "name": "Jiangyun Li",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2500751094",
        "https://openalex.org/W2029316659",
        "https://openalex.org/W3127042927",
        "https://openalex.org/W2782517596",
        "https://openalex.org/W2907100627",
        "https://openalex.org/W2022470997",
        "https://openalex.org/W6683834652",
        "https://openalex.org/W2101711129",
        "https://openalex.org/W2609880332",
        "https://openalex.org/W2950266692",
        "https://openalex.org/W3128776197",
        "https://openalex.org/W6750315611",
        "https://openalex.org/W2194775991",
        "https://openalex.org/W2971432438",
        "https://openalex.org/W3047443805",
        "https://openalex.org/W6797691975",
        "https://openalex.org/W1521436688",
        "https://openalex.org/W2067532478",
        "https://openalex.org/W1964541653",
        "https://openalex.org/W2548791488",
        "https://openalex.org/W2257669061",
        "https://openalex.org/W3107591966",
        "https://openalex.org/W2345128667",
        "https://openalex.org/W6642159730",
        "https://openalex.org/W2611655888",
        "https://openalex.org/W6799693006",
        "https://openalex.org/W2136251662",
        "https://openalex.org/W4240485910",
        "https://openalex.org/W4200507278",
        "https://openalex.org/W6766978945",
        "https://openalex.org/W3114720220",
        "https://openalex.org/W2004990382",
        "https://openalex.org/W6840034992",
        "https://openalex.org/W4312743284",
        "https://openalex.org/W2131864940",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W2757242159",
        "https://openalex.org/W6729546649",
        "https://openalex.org/W2765739551",
        "https://openalex.org/W6839944659",
        "https://openalex.org/W2811355488",
        "https://openalex.org/W2764276316",
        "https://openalex.org/W2133564696",
        "https://openalex.org/W4297795522",
        "https://openalex.org/W4285258250",
        "https://openalex.org/W1686810756",
        "https://openalex.org/W3094502228",
        "https://openalex.org/W3191251640",
        "https://openalex.org/W3103695279",
        "https://openalex.org/W4295312788",
        "https://openalex.org/W2598545494",
        "https://openalex.org/W3214821343",
        "https://openalex.org/W4285262969"
    ],
    "abstract": "In recent years, convolutional neural networks have continuously dominated the downstream tasks on hyperspectral remote sensing images with its strong local feature extraction capability. However, convolution operations cannot effectively capture the long-range dependencies and repeatedly stacking convolutional layers to pursue a hierarchical structure can only make this problem alleviated but not completely solved. Meantime, the appearance of Transformer happens to cope with this problem and provides an opportunity to capture long-distance dependencies between tokens. Although Transformer has been introduced into HSI classification field recently, most of these related works only focus on exploiting a single kind of spatial or spectral information and neglect to explore the optimal fusion method for these two different-level features. Therefore, to fully exploit the abundant spatial information and spectral correlations in HSIs in a highly effective and efficient way, we present the initial attempt to explore the Transformer architecture in a dual-branch manner and propose a novel bilateral classification network named Hyper-ES2T. Besides, the Aggregated Feature Enhancement Module is proposed for effective feature aggregation and further spatial–spectral feature enhancement. Furthermore, to tackle the problem of high computational costs brought by vanilla self-attention block in Transformer, we design the Efficient Multi-Head Self-Attention block, pursuing the trade-off between model accuracy and efficiency. The proposed Hyper-ES2T reaches new state-of-the-art performance and outperforms previous methods by a significant margin on four benchmark datasets for HSI classification, which demonstrates the powerful generalization ability and superior feature representation capability of our Hyper-ES2T. It can be anticipated that this work provides a novel insight to design network architecture based on Transformer with superior performance and great model efficiency, which may inspire more following research in this direction of HSI processing field. The source codes will be available at https://github.com/Wenxuan-1119/Hyper-ES2T.",
    "full_text": null
}