{
  "title": "WangLab at MEDIQA-Chat 2023: Clinical Note Generation from Doctor-Patient Conversations using Large Language Models",
  "url": "https://openalex.org/W4385571397",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2144896225",
      "name": "John Giorgi",
      "affiliations": [
        "University of Toronto",
        null,
        "Vector Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2549472424",
      "name": "Augustin Toma",
      "affiliations": [
        "Health Net",
        "Vector Institute",
        "University of Toronto",
        "University Health Network"
      ]
    },
    {
      "id": "https://openalex.org/A2650344702",
      "name": "Ronald Xie",
      "affiliations": [
        "University Health Network",
        "Vector Institute",
        "University of Toronto",
        "Health Net",
        null
      ]
    },
    {
      "id": "https://openalex.org/A5087894642",
      "name": "Sondra Chen",
      "affiliations": [
        "University of Toronto",
        "Sunnybrook Health Science Centre",
        "Health Sciences Centre"
      ]
    },
    {
      "id": "https://openalex.org/A2142375099",
      "name": "Kevin An",
      "affiliations": [
        "University of Toronto"
      ]
    },
    {
      "id": "https://openalex.org/A2636204715",
      "name": "Grace Zheng",
      "affiliations": [
        "Sunnybrook Health Science Centre",
        "Health Sciences Centre",
        "University of Toronto"
      ]
    },
    {
      "id": "https://openalex.org/A290155247",
      "name": "Bo Wang",
      "affiliations": [
        "Health Net",
        "Vector Institute",
        "University Health Network",
        "University of Toronto"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2152304691",
    "https://openalex.org/W3024110527",
    "https://openalex.org/W4205646617",
    "https://openalex.org/W4285274604",
    "https://openalex.org/W4385570594",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W2963926728",
    "https://openalex.org/W3045635560",
    "https://openalex.org/W4297841431",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W2806237610",
    "https://openalex.org/W4285242550",
    "https://openalex.org/W3169068430",
    "https://openalex.org/W3098562101",
    "https://openalex.org/W2908510526",
    "https://openalex.org/W3015468748",
    "https://openalex.org/W2754518417",
    "https://openalex.org/W22309152",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W3177464472",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W4287887173",
    "https://openalex.org/W1828163288",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W4224223051",
    "https://openalex.org/W4385573908",
    "https://openalex.org/W3035252911",
    "https://openalex.org/W4386566731"
  ],
  "abstract": "This paper describes our submission to the MEDIQA-Chat 2023 shared task for automatic clinical note generation from doctor-patient conversations. We report results for two approaches: the first fine-tunes a pre-trained language model (PLM) on the shared task data, and the second uses few-shot in-context learning (ICL) with a large language model (LLM). Both achieve high performance as measured by automatic metrics (e.g. ROUGE, BERTScore) and ranked second and first, respectively, of all submissions to the shared task. Expert human scrutiny indicates that notes generated via the ICL-based approach with GPT-4 are preferred about as often as human-written notes, making it a promising path toward automated note generation from doctor-patient conversations.",
  "full_text": "Proceedings of the 5th Clinical Natural Language Processing Workshop, pages 323–334\nJuly 14, 2023 ©2023 Association for Computational Linguistics\nWangLab at MEDIQA-Chat 2023: Clinical Note Generation from\nDoctor-Patient Conversations using Large Language Models\nJohn Giorgi1,2,3∗ Augustin Toma1,3,4∗ Ronald Xie1,2,3,4∗\nSondra S. Chen1,5 Kevin R. An1,6 Grace X. Zheng1,5 Bo Wang1,3,4∗\n1University of Toronto 2Terrence Donnelly Centre for Cellular and Biomolecular Research\n3Vector Institute for AI 4University Health Network 5Sunnybrook Health Sciences Centre\n6Department of Cardiac Surgery, University of Toronto\n{john.giorgi, augustin.toma, ronald.xie, bowang.wang}@mail.utoronto.ca\nAbstract\nThis paper describes our submission to the\nMEDIQA-Chat 2023 shared task for automatic\nclinical note generation from doctor-patient\nconversations. We report results for two ap-\nproaches: the first fine-tunes a pre-trained lan-\nguage model (PLM) on the shared task data,\nand the second uses few-shot in-context learn-\ning (ICL) with a large language model (LLM).\nBoth achieve high performance as measured by\nautomatic metrics (e.g. ROUGE, BERTScore)\nand ranked second and first, respectively, of all\nsubmissions to the shared task. Expert human\nscrutiny indicates that notes generated via the\nICL-based approach with GPT-4 are preferred\nabout as often as human-written notes, mak-\ning it a promising path toward automated note\ngeneration from doctor-patient conversations.1\n1 Introduction\nThe growing burden of clinical documentation has\nemerged as a critical issue in healthcare, increas-\ning job dissatisfaction and burnout rates among\nclinicians and negatively impacting patient experi-\nences (Friedberg et al., 2013; Babbott et al., 2014;\nArndt et al., 2017). On the other hand, timely and\naccurate documentation of patient encounters is\ncritical for safe, effective care and communication\nbetween specialists. Therefore, interest in assisting\nclinicians by automatically generating consultation\nnotes is mounting (Finley et al., 2018; Enarvi et al.,\n2020; Molenaar et al., 2020; Knoll et al., 2022).\nTo further encourage research on automatic clin-\nical note generation from doctor-patient conversa-\ntions, the MEDIQA-Chat Dialogue2Note shared\ntask was proposed (Ben Abacha et al., 2023). Here,\nwe describe our submission to subtask B: the gener-\nation of full clinical notes from doctor-patient dia-\nlogues. We explored two approaches; the first fine-\ntunes a pre-trained language model (PLM, §3.1),\n∗Core contributors. See author contributions\n1https://github.com/bowang-lab/\nMEDIQA-Chat-2023\nLED\n(1) Fine-tune on shared task data\nLED \n(fine-tuned)\nInstructor\nTrain set\n(2) Generate notes given unseen dialogues\n(A) Fine-tuning a PLM\n(B) Few-shot ICL with LLMs\n(1) Rank train examples based on similarity to test dialogue\nTrain set\n(2) Use top-k notes as in-context examples\nTest dialogue Generated note\nTest dialogue\n Generated note\nNatural language \ninstructions\nTop-k train notes\nTest dialogue\nFigure 1: (A) Fine-tuning a pre-trained language model\n(PLM), Longformer-Encoder-Decoder (LED, Beltagy\net al. 2020). (B) In-context learning (ICL) with large lan-\nguage models (LLMs). We rank train examples based\non their similarity to the test dialogue using Instructor\n(Su et al., 2022a). Notes of the top- kmost similar ex-\namples are then used as in-context examples to form a\nprompt alongside natural language instructions and fed\nto GPT-4 (OpenAI, 2023) to generate the clinical note.\nwhile the second uses few-shot in-context learn-\ning (ICL, §3.2). Both achieve high performance\nas measured by automatic natural language gen-\neration metrics (§4) and ranked second and first,\nrespectively, of all submissions to the shared task.\nIn a human evaluation with three expert physicians,\nnotes generated via the ICL-based approach with\nGPT-4 were preferred about as often as human-\nwritten notes (§4.3).\n2 Shared Task and Dataset\nMEDIQA-Chat 2023 proposed two shared tasks:\n1. Dialogue2Note Summarization : Given a\nconversation between a doctor and patient, the\ntask is to produce a clinical note summarizing\nthe conversation with one or more note sec-\n323\n Example Doctor-Patient Conversation\n[doctor]   hi, ms. thompson. i'm dr. moore. how are you?\n[patient]  hi, dr. moore.\n[doctor]   hi.\n[patient]  i'm doing okay except for my knee.\n[doctor]   all right, hey, dragon, ms. thompson is a 43 year old \nfemale here for right knee pain. so tell me what happened \nwith your knee?\n[patient]  well, i was, um, trying to change a light bulb, and i \nwas up on a ladder and i kinda had a little bit of a stumble \nand kinda twisted my knee as i was trying to catch my fall.\n[doctor]   okay. and did you injure yourself any place else?\n[patient]  no, no. it just seems to be the knee.\n[doctor]   all right. and when did this happen?\n[patient]  it was yesterday.\n[doctor]   all right. and, uh, where does it hurt mostly?\n[patient]  it hurts like in, in, in the inside of my knee.\n[doctor]   okay.\n[patient]  right here.\n[doctor]   all right. and anything make it better or worse?\n[patient]  i have been putting ice on it, uh, and i've been \ntaking ibuprofen, but it doesn't seem to help much.\n[doctor]   okay. so it sounds like you fell a couple days ago, \nand you've hurt something inside of your right knee.\n[patient]  mm-hmm.\n[doctor]   and you've been taking a little bit of ice, uh, putting \nsome ice on it, and hasn't really helped and some ibuprofen. is \nthat right?\n--------- TRUNCATED ---------\n[doctor]   so in summary after my exam, uh, looking at your \nknee, uh, on the x-ray and your exam, you have some \ntenderness over the medial meniscus, so i think you have \nprobably an acute medial meniscus sprain right now or strain. \nuh, at this point, my recommendation would be to put you in a \nknee brace, uh, and we'll go ahead and have you use some \ncrutches temporarily for the next couple days. we'll have you \ncome back in about a week and see how you're doing, and if \nit's not better, we'll get an mri at that time.\n[patient]  okay.\n[doctor]   i'm going to recommend we give you some motrin, \n800 milligrams. uh, you can take it about every six hours, uh, \nwith food. uh, and we'll give you about a two week supply.\n[patient]  okay.\n[doctor]   okay. uh, do you have any questions?\n[patient]  no, i think i'm good.\n[doctor]   all right. hey, dragon, order the medications and \nprocedures discussed, and finalize the report. okay, come with \nme and we'll get you checked out.\n Example Clinical Note\nObjective Results\nRESULTS\nX-rays of the right knee show no obvious signs of acute \nfracture or dislocation. Mild effusion is noted.\nSubjective\nCHIEF COMPLAINT\nRight knee pain.\nHISTORY OF PRESENT ILLNESS\nMs. Thompson is a 43-year-old female who presents \ntoday for an evaluation of right knee pain. She states \nshe was trying to change a lightbulb on a ladder [...]\nCURRENT MEDICATIONS\nIbuprofen, digoxin.\nPAST MEDICAL HISTORY\nAtrial fibrillation.\nPAST SURGICAL HISTORY\nRhinoplasty.\nAssessment and Plan\nIMPRESSION\nRight knee acute medial meniscus sprain.\nPLAN\nAt this point, I discussed the diagnosis and treatment \noptions with the patient. I have recommended a knee \nbrace. She will take Motrin 800 mg, every 6 hours with \nfood, for two weeks. She will use crutches for the next \ncouple of days. She will follow up with me in 1 week [...]\nObjective Exam\nEXAM\nExamination of the right knee shows pain with flexion. \nTenderness over the medial joint line. No pain in the calf. \nPain with valgus stress. Sensation is intact.\nFigure 2: Example of a paired doctor-patient conversation and clinical note from the subtask B validation set.\nDialogue has been lightly cleaned for legibility (e.g. remove trailing white space). Parts of the dialogue and note\nhave been truncated. During evaluation, sections are grouped under one of four categories: “Subjective”, “Objective\nExam”, “Objective Results”, and “Assessment and Plan” (see §2.1 for details).\ntions (e.g. Assessment, Past Medical History).\n2. Note2Dialogue Generation: Given a clinical\nnote, the task is to generate a synthetic doctor-\npatient conversation related to the information\ndescribed in the note.\nWe focused on Dialogue2Note, which is divided\ninto two subtasks. In subtask ‘A’ (Ben Abacha et al.,\n2023), the goal is to generate specific sections of a\nnote given partial doctor-patient dialogues. In sub-\ntask ‘B’ (Yim et al., 2023), the goal isfull note gen-\neration from complete dialogues. The remainder\nof the paper focuses on subtask B; see Appendix A\nfor our approach to subtask A, which also ranks\nfirst of all submissions to the shared task.\n2.1 Task definition\nEach of the kexamples consist of a doctor-patient\ndialogue, D = d1,...,d k and a corresponding\nclinical note, N = n1,...,n k. The aim is to au-\ntomatically generate a note ni given a dialogue di.\nEach note comprises one or more sections, such as\n“Chief Complaint”, and “Family history”. During\nevaluation, sections are grouped under one of four\ncategories: “Subjective”, “Objective Exam”, “Ob-\njective Results”, and “Assessment and Plan”.2 See\nFigure 2 for an example doctor-patient conversa-\ntion and clinical note pair.\n2See here for the mapping\n324\nFigure 3: Histogram of token lengths for subtask B train\nand validation sets. Dialogues and notes were tokenized\nwith tiktoken using the “gpt-4” encoding.\n2.2 Dataset\nThe dataset comprises 67 train and 20 valida-\ntion examples, featuring transcribed dialogues\nfrom doctor-patient encounters and the resulting\nclinician-written notes. Each example is labelled\nwith the ‘dataset source’, indicating the dialogue\ntranscription system used to produce the note.\n3 Approach\nWe take two high-performant approaches to the\nshared task. In the first, we fine-tune a pre-trained\nlanguage model (PLM) on the provided training set\n(§3.1). In the second, we use in-context learning\n(ICL) with a large language model (LLM, §3.2).\n3.1 Fine-tuning pre-trained language models\nAs a first approach, we fine-tune a PLM on the\ntraining set following a canonical, sequence-to-\nsequence training process (Figure 1 A; see Ap-\npendix C for details). Given the length of input\ndialogues (Figure 3), we elected to use Longformer-\nEncoder-Decoder (LED, Beltagy et al. 2020),\nwhich has a maximum input size of 16,384 tokens.\nWe begin fine-tuning from a LEDLARGE checkpoint\ntuned on the PubMed summarization dataset (Co-\nhan et al., 2018), which performed best in prelimi-\nnary experiments.3 The model was fine-tuned using\nHuggingFace Transformers (Wolf et al., 2020) on\na single NVIDIA A100-40GB GPU. Hyperparame-\nters were lightly tuned on the validation set.4\n3https://huggingface.co/patrickvonplaten/\nled-large-16384-pubmed\n4See Appendix B.1 for details\n Prompt Template\nIn-context examples (up to 3)\nEXAMPLE NOTE: HISTORY OF PRESENT ILLNESS\\nMr. Fisher is \na 59-year-old male who presents for routine follow up of \nhis chronic problems. [...]\nNatural language instructions\nWrite a clinical note reflecting this doctor-patient \ndialogue. Use the example notes below to decide the \nstructure of the clinical note. Do not make up information.\nTest input\nDIALOGUE: [doctor] hi , martha . how are you ?\\n[patient] \ni'm doing okay . how are you ? [...] [doctor] martha is a \n50-year-old female with a past medical history \nsignificant for congestive heart failure [...]\nCLINICAL NOTE:\nFigure 4: Prompt template for our in-context learning\n(ICL) based approach. Each prompt includes natural\nlanguage instructions, up to 3 in-context examples, and\nan unseen doctor-patient dialogue as input.\n3.2 In-context learning with LLMs\nAs a second approach, we attempt subtask B with\nICL. We chose GPT-4 (OpenAI, 2023)5 as the LLM\nand designed a simple prompt, which included nat-\nural language instructions and in-context examples\n(Figure 4). We limited the prompt size to 6192\ntokens — allowing for 2000 output tokens, as the\nmodel’s maximum token size is 8,192 — and used\nas many in-context examples as would fit within\nthis token limit, up to a maximum of 3. We set the\ntemperature parameter to 0.2 and left all other hy-\nperparmeters of the OpenAI API at their defaults.\nNatural language instructions During prelim-\ninary experiments, we found that GPT-4 was not\noverly sensitive to the exact phrasing of the natural\nlanguage instructions in the prompt. We, therefore,\nelected to use short, simple instructions (Figure 4).\nIn-context example selection Each in-context\nexample is a note from the train set. To select the\nnotes, we first embed the dialogues of each training\nexample and the input dialogue. Train dialogues\nare then ranked based on cosine similarity to the\ninput dialogue; notes of the resulting top-ktraining\nexamples are selected as the in-context examples\n(see Figure 1, B). Dialogues were embedded using\nInstructor (Su et al., 2022a), a text encoder that\n5Specifically, the 03/14/2023 snapshot, “gpt-4-0314”\n325\nsupports natural language instructions.6 Lastly, we\nrestricted in-context examples to be of the same\n‘dataset source’ (see §2.2) as the input dialogue,\nhypothesizing that this may improve performance.7\n3.3 Evaluation\nModels are evaluated with the official evaluation\nscript8 on the validation set (as test notes are not\nprovided). Generated notes are evaluated against\nthe provided ground truth notes with ROUGE\n(Lin, 2004), BERTScore (Zhang et al., 2020) and\nBLEURT (Sellam et al., 2020). We report perfor-\nmance as the arithmetic mean of ROUGE-1 F1,\nBERTScore F1 and BLEURT-20 (Pu et al., 2021).\n4 Results\n4.1 Fine-tuning pre-trained language models\nWe present the results of fine-tuning LED in Ta-\nble 1. Due to the non-determinism of the LED im-\nplementation,9 we report the mean results of three\ntraining runs. Unsurprisingly, we find that scaling\nthe model size from LEDBASE (12 layers, ∼162M\nparameters) to LEDLARGE (24 layers, ∼460M pa-\nrameters) leads to sizable gains in performance.\nPerformance further improves by initializing the\nmodel with a checkpoint fine-tuned on the PubMed\nsummarization dataset (LEDLARGE-PubMed). This is\nlikely because (1) Dialouge2Note resembles a sum-\nmarization task, and (2) text from PubMed is more\nsimilar to clinical text than is the general domain\ntext used to pre-train LED. 10 Our submission to\nthe shared task using this approach ranked second\noverall, outperforming the next-best submission by\n2.7 average score; a difference comparable to the\nimprovement in performance we see by doubling\nmodel size (see LEDBASE vs. LEDLARGE, Table 1).\n4.2 In-context learning with LLMs\nWe present the results of ICL with GPT-4 in Ta-\nble 2. We note several interesting trends in order\nof magnitude of impact. First, selecting in-context\n6We used the following instructions: “Represent the\nMedicine dialogue for clustering: {dialogue}”\n7Manual review revealed that dataset source was predictive\nof note structure & style; likely because it indicates which\nclinician or electronic health record system produced the note\n8https://github.com/abachaa/MEDIQA-Chat-2023/\nblob/main/scripts/evaluate_summarization.py\n9https://github.com/huggingface/transformers/\nissues/12482\n10LED is initialized from BART (Lewis et al., 2020), which\nwas pre-trained on a combination of text from Wikipedia and\nBooksCorpus (Zhu et al., 2015)\nTable 1: Fine-tuning LED. Mean and standard deviation\n(SD) of three training runs is shown. Scaling model size\nand pre-training on a related task improve performance.\nBold: best scores.\nModel ROUGE-1 F1 BERTScore F1 BLEURT Avg.\nLEDBASE 57.00.4 67.30.1 36.90.0 53.8\nLEDLARGE 59.80.2 70.00.6 41.10.8 57.0\nLEDLARGE-PubMed 61.70.4 70.70.2 41.50.6 57.9\nexamples based on the similarity of dialogues has a\nstrong positive impact, typically improving average\nscore by 4 or more. Using only notes as in-context\nexamples, as opposed to dialogue-note pairs, also\nhas a positive impact, typically improving average\nscore by ∼1. Surprisingly, increasing the number\nof in-context examples had a marginal effect on per-\nformance. Together these results suggest that the\nin-context examples’ primary benefit is providing\nguidance with regard to the expected note structure,\nstyle and length. Finally, filtering in-context exam-\nples to be of the same ‘dataset source’ as the input\ndialogue has a negligible impact on performance.\nThe best strategy out-performs LED by almost 3\naverage score (60.8 vs. 57.9, see Table 1 & Table 2)\nand achieves first place of all submissions to the\nshared task, out-performing the runner up by >9\naverage score. We conclude that (1) few-shot ICL\nwith GPT-4, using as little as one example, is a per-\nformant approach for note generation from doctor-\npatient conversations, and (2) using the notes of\nsemantically similar dialogue-note pairs is a strong\nstrategy for selecting the in-context examples.\n4.3 Human evaluation\nAutomatic evaluation metrics like ROUGE,\nBERTScore and BLEURT are imperfect and may\nnot correlate with aspects of human judgment. 11\nTherefore, we conducted an expert human eval-\nuation to validate our results. To make annota-\ntion feasible, we conducted it on the validation set\n(20 examples) using the best performing fine-tuned\nmodel: LEDLARGE-PubMed (Table 1), and best per-\nforming ICL-based approach: 3-shot, similar, note-\nonly examples filtered by dataset type (Table 2).\nThree senior resident physicians12 were shown\na ground truth note, a note generated by the\nfine-tuned model, and a note generated by the\nICL-based approach for each example (presented\nin random order as clinical note ‘A’, ‘B’ and ‘C’)\n11See §6 for an extended discussion\n12The three annotators are a subset of the authors who did\nnot interact with the model or model outputs before annotation\n326\nTable 2: ICL with GPT-4. Mean of ROUGE-1 F1, BERTScore F1 and BLEURT for three runs is shown. Selecting\nin-context examples based on similarity to input dialogue improves performance. Dialogue-note pairs as in-context\nexamples (omitting 3-shot results due to token length limits) underperforms notes only. Filtering in-context examples\nto be of the same ‘dataset source’ as the input dialogue has little effect. Bold: best scores. SD < 0.1 in all cases.\nUnfiltered Filtered by dataset source\nExample selection strategy 0-shot 1-shot 2-shot 3-shot 0-shot 1-shot 2-shot 3-shot\nDialogue-note pairs as in-context examples\nrandom 52.2 54.5 53.9 – – 54.8 54.5 –\nsimilar dialogues – 59.4 59.4 – – 60.1 60.3 –\nNotes only as in-context examples\nrandom – 56.3 56.7 56.7 – 56.3 56.5 56.7\nsimilar dialogues – 60.7 60.6 60.4 – 60.8 60.4 60.8\nTable 3: Human evaluation. Three physicians selected\ntheir preference from human written ground-truth notes\n(GT), notes produced by the fine-tuned model (FT) and\nnotes produced by in-context learning (ICL). Win rate\nis % of cases where note was preferred, excluding ties.\nPreferred Ties Win rate (%)\nPhysician GT FT ICL FT/ICL All GT FT ICL\n1 9 1 4 2 4 64 7 29\n2 5 0 14 0 1 26 0 74\n3 9 0 6 0 5 60 0 40\nTotal 23 1 24 2 10 48 2 50\nand asked to select which note(s) they preferred,\ngiven a dialogue and some simple instructions:\nInstructions: Please asses the clinical notes A ,\nB and C relative to the provided doctor-patient\ndialogue. For each set of notes, you should se-\nlect which note you prefer (‘A’, ‘B’, or ‘C’). If you\nhave approximately equal preference for two notes,\nselect (‘A/B’, ‘B/C’, or ‘C/A’). If you have no pref-\nerence, select ‘A/B/C’. A ‘good’ note should con-\ntain all critical, most non-critical and very little\nirrelevant information mentioned in a dialogue:\n• Critical: Items medico-legally required to\ndocument the diagnosis and treatment deci-\nsions whose absence or incorrectness may\nlead to wrong diagnosis and treatment later\non, e.g. the symptom \"cough\" in a suspected\nchest infection consultation. This is the key\ninformation a note needs to capture correctly\nin order to not mislead clinicians.\n• Non-critical: Items that should be docu-\nmented in a complete note but whose absence\nwill not affect future treatment or diagnosis,\ne.g. \"who the patient lives with\" in a consulta-\ntion about chest infection.\n• Irrelevant: Medically irrelevant information\ncovered in the consultation, e.g. the pet of a\npatient with a suspected chest infection just\ndied.\nThe definitions of critical, non-critical and irrel-\nevant information are taken from previous work\non human evaluation of generated clinical notes\n(Moramarco et al., 2022; Savkov et al., 2022).\nIn short, notes generated by ICL are strongly\npreferred over notes generated by the fine-tuned\nmodel and, on average, slightly preferred over the\nhuman-written notes (Table 3), validating the high\nperformance reported by the automatic metrics. We\nnote, however, that inter-annotator agreement is\nlow and speculate why this might be in §6.\n5 Related Work\nAutomated note generation from doctor-patient\nconversations has received increasing attention in\nrecent years (Finley et al., 2018; Enarvi et al., 2020;\nMolenaar et al., 2020; Knoll et al., 2022). Different\nmethods have been proposed, such as extractive-\nabstractive approaches (Joshi et al., 2020; Krishna\net al., 2021; Su et al., 2022b) and fine-tuning PLMs\n(Zhang et al. 2021, similar to our approach in §3.1).\nOthers have focused on curating data for training\nand benchmarking (Papadopoulos Korfiatis et al.,\n2022), including the use of LLMs to produce syn-\nthetic data (Chintagunta et al., 2021). Lastly, there\nhave been efforts to improve the evaluation of gen-\nerated clinical notes, both with automatic metrics\n(Moramarco et al., 2022) and human evaluation\n(Savkov et al., 2022). While recent literature has\ncommented on the potential of ICL for note gener-\nation (Lee et al., 2023), our work is among the first\nto evaluate this approach rigorously.\n327\n6 Conclusion\nWe present our submission to the MEDIQA-Chat\nshared task for clinical note generation from doctor-\npatient dialogues. We evaluated a fine-tuning-based\napproach with LED and an ICL-based approach\nwith GPT-4, ranking second and first, respectively,\namong all submissions. Human evaluation with\nthree physicians revealed that notes produced by\nGPT-4 via ICL were strongly preferred over notes\nproduced by LED and, on average, slightly pre-\nferred over human-written notes. We conclude that\nICL is a promising path toward clinical note gener-\nation from doctor-patient conversations.\nLimitations\nEvaluation of generated text is difficult Evalu-\nating automatically generated text, including clin-\nical notes, is generally hard due to the inherently\nsubjective nature of many aspects of output quality.\nAutomatic evaluation metrics such as ROUGE and\nBERTScore are imperfect (Deutsch et al., 2022)\nand may not correlate with aspects of expert judg-\nment. However, they are frequently used to evalu-\nate model-generated clinical notes and do correlate\nwith certain aspects of quality (Moramarco et al.,\n2022). To further validate our findings, we also\nconducted a human evaluation with three expert\nphysicians (§4.3). As noted previously (Savkov\net al., 2022), even human evaluation of clinical\nnotes is far from perfect; inter-annotator agreement\nis generally low, likely because physicians have\ndiffering opinions on the importance of each pa-\ntient statement and whether it should be included\nin a consultation note. We also found low inter-\nannotator agreement in our human evaluation and\nspeculate this is partially due to differences in spe-\ncialties among the physicians. Physicians 1 and\n3, both from family medicine, had high agreement\nwith each other but low agreement with physician 2\n(cardiac surgery, see Table 3). Investigating better\nautomatic metrics and best practices for evaluating\nclinical notes (and generated text more broadly) is\nan active field of research. We hope to integrate\nnovel and performant metrics in future work.\nData privacy While our GPT-4 based solution\nachieves the best performance, it is not compliant\nwith data protection regulations such as HIPAA;\nalthough Azure does advertise a HIPAA-compliant\noption.13 From a privacy perspective, locally de-\nploying a model such as LED may be preferred;\nhowever, our results suggest that more work is\nneeded for this approach to reach acceptable per-\nformance (see Table 3). In either case, when im-\nplementing automated clinical note-generation sys-\ntems, healthcare providers and developers should\nensure that the whole system — including text-to-\nspeech, data transmission & storage, and model\ninference — adheres to privacy and security re-\nquirements to maintain trust and prevent privacy\nviolations in the clinical setting.\nEthics Statement\nDeveloping an automated system for clinical note\ngeneration from doctor-patient conversations raises\nseveral ethical considerations. First, informed con-\nsent is crucial: patients must be made aware of their\nrecording, and data ownership must be prioritized.\nEquitable access is also important; the system must\nbe usable for patients from diverse backgrounds,\nincluding those with disabilities, limited technical\nliteracy, or language barriers. Addressing issues\nof data bias and fairness are necessary to avoid un-\nfair treatment or misdiagnosis for certain patient\ngroups. The system must implement robust secu-\nrity measures to protect patient data from unautho-\nrized access or breaches. Establishing clear lines\nof accountability for errors or harms arising from\nusing an automated system for note generation is\nparamount. Disclosure of known limitations or po-\ntential risks associated with using the system is\nessential to maintain trust in the patient-physician\nrelationship. Finally, ongoing evaluations are nec-\nessary to ensure that system performance does not\ndegrade and negatively impact the quality of care.\nAcknowledgements\nThis research was enabled in part by support\nprovided by the Digital Research Alliance of\nCanada (alliancecan.ca) and Compute Ontario\n(www.computeontario.ca). We thank all inter-\nnal and external reviewers for their thoughtful\nfeedback, which improved earlier drafts of this\nmanuscript.\nAuthor Contributions\nJohn Giorgi (JG), Augustin Toma (AT) and Ronald\nXie (RX) led the project in general, including\n13https://azure.microsoft.com/en-us/products/\ncognitive-services/openai-service#security\n328\ndata cleaning and processing, model implemen-\ntation, and running experiments. JG wrote the\ninitial manuscript and designed the human eval-\nuation with feedback from AT and RX. AT and\nRX recruited Sondra S. Chen, Kevin R. An and\nGrace X. Zheng, who served as expert physicians\nin the human evaluation. Bo Wang provided high-\nlevel feedback and advice.\nReferences\nBrian G. Arndt, John W. Beasley, M. Watkinson,\nJonathan L Temte, Wen-Jan Tuan, Christine A. Sin-\nsky, and Valerie J. Gilchrist. 2017. Tethered to the\nehr: Primary care physician workload assessment us-\ning ehr event log data and time-motion observations.\nThe Annals of Family Medicine, 15:419–426.\nStewart F. Babbott, Linda Baier Manwell, Roger L.\nBrown, Enid N. H. Montague, Eric S. Williams,\nMark D. Schwartz, Erik P. Hess, and Mark Linzer.\n2014. Electronic medical records and physician\nstress in primary care: results from the memo study.\nJournal of the American Medical Informatics Associ-\nation : JAMIA, 21 e1:e100–6.\nIz Beltagy, Matthew E. Peters, and Arman Cohan. 2020.\nLongformer: The long-document transformer. ArXiv,\nabs/2004.05150.\nAsma Ben Abacha, Wen wai Yim, Griffin Adams, Neal\nSnider, and Meliha Yetisgen. 2023. Overview of the\nmediqa-chat 2023 shared tasks on the summarization\nand generation of doctor-patient conversations. In\nACL-ClinicalNLP 2023.\nAsma Ben Abacha, Wen-wai Yim, Yadan Fan, and\nThomas Lin. 2023. An empirical study of clinical\nnote generation from doctor-patient encounters. In\nProceedings of the 17th Conference of the European\nChapter of the Association for Computational Lin-\nguistics, pages 2283–2294, Dubrovnik, Croatia. As-\nsociation for Computational Linguistics.\nBharath Chintagunta, Namit Katariya, Xavier Amatri-\nain, and Anitha Kannan. 2021. Medically aware\nGPT-3 as a data generator for medical dialogue sum-\nmarization. In Proceedings of the Second Workshop\non Natural Language Processing for Medical Conver-\nsations, pages 66–76, Online. Association for Com-\nputational Linguistics.\nHyung Won Chung, Le Hou, S. Longpre, Barret Zoph,\nYi Tay, William Fedus, Eric Li, Xuezhi Wang,\nMostafa Dehghani, Siddhartha Brahma, Albert Web-\nson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suz-\ngun, Xinyun Chen, Aakanksha Chowdhery, Dasha\nValter, Sharan Narang, Gaurav Mishra, Adams Wei\nYu, Vincent Zhao, Yanping Huang, Andrew M.\nDai, Hongkun Yu, Slav Petrov, Ed Huai hsin Chi,\nJeff Dean, Jacob Devlin, Adam Roberts, Denny\nZhou, Quoc V . Le, and Jason Wei. 2022. Scal-\ning instruction-finetuned language models. ArXiv,\nabs/2210.11416.\nArman Cohan, Franck Dernoncourt, Doo Soon Kim,\nTrung Bui, Seokhwan Kim, Walter Chang, and Nazli\nGoharian. 2018. A discourse-aware attention model\nfor abstractive summarization of long documents. In\nProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 2 (Short Papers), pages 615–621, New Or-\nleans, Louisiana. Association for Computational Lin-\nguistics.\nDaniel Deutsch, Rotem Dror, and Dan Roth. 2022. Re-\nexamining system-level correlations of automatic\nsummarization evaluation metrics. In Proceedings of\nthe 2022 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 6038–6052,\nSeattle, United States. Association for Computational\nLinguistics.\nSeppo Enarvi, Marilisa Amoia, Miguel Del-Agua Teba,\nBrian Delaney, Frank Diehl, Stefan Hahn, Kristina\nHarris, Liam McGrath, Yue Pan, Joel Pinto, Luca Ru-\nbini, Miguel Ruiz, Gagandeep Singh, Fabian Stem-\nmer, Weiyi Sun, Paul V ozila, Thomas Lin, and Ran-\njani Ramamurthy. 2020. Generating medical reports\nfrom patient-doctor conversations using sequence-to-\nsequence models. In Proceedings of the First Work-\nshop on Natural Language Processing for Medical\nConversations, pages 22–30, Online. Association for\nComputational Linguistics.\nGregory Finley, Erik Edwards, Amanda Robinson,\nMichael Brenndoerfer, Najmeh Sadoughi, James\nFone, Nico Axtmann, Mark Miller, and David\nSuendermann-Oeft. 2018. An automated medical\nscribe for documenting clinical encounters. In Pro-\nceedings of the 2018 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Demonstrations, pages 11–15, New Or-\nleans, Louisiana. Association for Computational Lin-\nguistics.\nMark W. Friedberg, Peggy G. Chen, Kristin R Van\nBusum, Frances Aunon, Chau Pham, John P. Caloy-\neras, Soeren Mattke, Emma Pitchforth, Denise D.\nQuigley, Robert Henry Brook, Francis J. Crosson,\nand Michael A. Tutty. 2013. Factors affecting physi-\ncian professional satisfaction and their implications\nfor patient care, health systems, and health policy.\nRand health quarterly, 3 4:1.\nAlex Graves. 2012. Sequence transduction with recur-\nrent neural networks. ArXiv preprint, abs/1211.3711.\nAnirudh Joshi, Namit Katariya, Xavier Amatriain, and\nAnitha Kannan. 2020. Dr. summarize: Global sum-\nmarization of medical dialogue by exploiting local\nstructures. In Findings of the Association for Com-\nputational Linguistics: EMNLP 2020 , pages 3755–\n3763, Online. Association for Computational Lin-\nguistics.\n329\nTom Knoll, Francesco Moramarco, Alex Papadopou-\nlos Korfiatis, Rachel Young, Claudia Ruffini, Mark\nPerera, Christian Perstl, Ehud Reiter, Anya Belz, and\nAleksandar Savkov. 2022. User-driven research of\nmedical note generation software. In Proceedings of\nthe 2022 Conference of the North American Chapter\nof the Association for Computational Linguistics: Hu-\nman Language Technologies, pages 385–394, Seattle,\nUnited States. Association for Computational Lin-\nguistics.\nKundan Krishna, Sopan Khosla, Jeffrey Bigham, and\nZachary C. Lipton. 2021. Generating SOAP notes\nfrom doctor-patient conversations using modular\nsummarization techniques. In Proceedings of the\n59th Annual Meeting of the Association for Compu-\ntational Linguistics and the 11th International Joint\nConference on Natural Language Processing (Vol-\nume 1: Long Papers), pages 4958–4972, Online. As-\nsociation for Computational Linguistics.\nPeter Lee, Sébastien Bubeck, and Joseph Petro. 2023.\nBenefits, limits, and risks of gpt-4 as an ai chatbot\nfor medicine. The New England journal of medicine,\n388 13:1233–1239.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020.\nBART: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and com-\nprehension. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 7871–7880, Online. Association for Computa-\ntional Linguistics.\nChin-Yew Lin. 2004. ROUGE: A package for auto-\nmatic evaluation of summaries. In Text Summariza-\ntion Branches Out, pages 74–81, Barcelona, Spain.\nAssociation for Computational Linguistics.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization. In 7th International\nConference on Learning Representations, ICLR 2019,\nNew Orleans, LA, USA, May 6-9, 2019 . OpenRe-\nview.net.\nSabine Molenaar, Lientje Maas, Verónica Burriel, Fabi-\nano Dalpiaz, and Sjaak Brinkkemper. 2020. Medical\ndialogue summarization for automated reporting in\nhealthcare. Advanced Information Systems Engineer-\ning Workshops, 382:76–88.\nFrancesco Moramarco, Alex Papadopoulos Korfiatis,\nMark Perera, Damir Juric, Jack Flann, Ehud Reiter,\nAnya Belz, and Aleksandar Savkov. 2022. Human\nevaluation and correlation with automatic metrics in\nconsultation note generation. In Proceedings of the\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n5739–5754, Dublin, Ireland. Association for Compu-\ntational Linguistics.\nOpenAI. 2023. Gpt-4 technical report. ArXiv,\nabs/2303.08774.\nAlex Papadopoulos Korfiatis, Francesco Moramarco,\nRadmila Sarac, and Aleksandar Savkov. 2022. Pri-\nMock57: A dataset of primary care mock consul-\ntations. In Proceedings of the 60th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 2: Short Papers), pages 588–598, Dublin,\nIreland. Association for Computational Linguistics.\nAmy Pu, Hyung Won Chung, Ankur Parikh, Sebastian\nGehrmann, and Thibault Sellam. 2021. Learning\ncompact metrics for MT. In Proceedings of the 2021\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 751–762, Online and Punta\nCana, Dominican Republic. Association for Compu-\ntational Linguistics.\nAleksandar Savkov, Francesco Moramarco, Alex Pa-\npadopoulos Korfiatis, Mark Perera, Anya Belz, and\nEhud Reiter. 2022. Consultation checklists: Stan-\ndardising the human evaluation of medical note gen-\neration. In Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Processing:\nIndustry Track, pages 111–120, Abu Dhabi, UAE.\nAssociation for Computational Linguistics.\nThibault Sellam, Dipanjan Das, and Ankur Parikh. 2020.\nBLEURT: Learning robust metrics for text genera-\ntion. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pages\n7881–7892, Online. Association for Computational\nLinguistics.\nHongjin Su, Weijia Shi, Jungo Kasai, Yizhong Wang,\nYushi Hu, Mari Ostendorf, Wen tau Yih, Noah A.\nSmith, Luke Zettlemoyer, and Tao Yu. 2022a. One\nembedder, any task: Instruction-finetuned text em-\nbeddings. ArXiv, abs/2212.09741.\nJing Su, Longxiang Zhang, Hamidreza Hassanzadeh,\nand Thomas Schaaf. 2022b. Extract and abstract\nwith bart for clinical notes from doctor-patient con-\nversations. In Interspeech.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems 30: Annual Conference on Neural\nInformation Processing Systems 2017, December 4-9,\n2017, Long Beach, CA, USA, pages 5998–6008.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38–45, Online. Association\nfor Computational Linguistics.\nWen-wai Yim, Yujuan Fu, Asma Ben Abacha, Neal\nSnider, Thomas Lin, and Meliha Yetisgen. 2023. The\n330\naci demo corpus: An open dataset for benchmark-\ning the state-of-the-art for automatic note generation\nfrom doctor-patient conversations. Submitted to Na-\nture Scientific Data.\nLongxiang Zhang, Renato Negrinho, Arindam Ghosh,\nVasudevan Jagannathan, Hamid Reza Hassanzadeh,\nThomas Schaaf, and Matthew R. Gormley. 2021.\nLeveraging pretrained models for automatic summa-\nrization of doctor-patient conversations. In Find-\nings of the Association for Computational Linguis-\ntics: EMNLP 2021, pages 3693–3712, Punta Cana,\nDominican Republic. Association for Computational\nLinguistics.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020. Bertscore: Evalu-\nating text generation with BERT. In8th International\nConference on Learning Representations, ICLR 2020,\nAddis Ababa, Ethiopia, April 26-30, 2020. OpenRe-\nview.net.\nYukun Zhu, Ryan Kiros, Richard S. Zemel, Ruslan\nSalakhutdinov, Raquel Urtasun, Antonio Torralba,\nand Sanja Fidler. 2015. Aligning books and movies:\nTowards story-like visual explanations by watching\nmovies and reading books. In 2015 IEEE Interna-\ntional Conference on Computer Vision, ICCV 2015,\nSantiago, Chile, December 7-13, 2015, pages 19–27.\nIEEE Computer Society.\n331\nFLAN-T5\n(2) Fine-tune on shared task data\nFLAN-T5\n(fine-tuned)\nTrain set\nTest dialogue\n(1) Preprocess targets\n(3) Parse section headers and text from model generations\nTarget\n\"Section header: {section_header} Section text: {section_text}\"\nOutput\nSection header: GENHX\nSection text: The patient is a 26 YO female, \nreferred to Physical Therapy for low back pain [...]\nFigure 5: Fine-tuning FLAN-T5 (Chung et al., 2022)\nfor subtask A. Before training, targets are preprocessed\nas “Section header: {section_header} Section text:\n{section_text}”. After decoding, the section header\nand text are parsed using regular expressions.\nA Subtask A\nIn subtask A of the Dialogue2Note Summarization\nshared task, given a partial doctor-patient dialogue,\nthe goals are to: (1) predict the appropriate section\nheader, e.g. “PASTMEDICALHX” and (2) gener-\nate that specific section of a note. We approached\nthis task by fine-tuning a PLM on the provided\ntraining set, following a canonical, sequence-to-\nsequence training process (see Appendix C for\ndetails). In preliminary experiments, we found\nthat the instruction-tuned FLAN-T5 (Chung et al.,\n2022) performed particularly well at this task.\nWe hypothesized that jointly learning to predict\nthe section header and generate the section text\nwould improve overall performance. To do this, we\npreprocessed the training set so the targets were\nof the form: “Section header: {section_header}\nSection text: {section_text}”. After decoding,\nthe section header and text were parsed using reg-\nular expressions and evaluated separately (Fig-\nure 5). Section header prediction was evaluated\nas the fraction of predicted headers that match the\nground truth (accuracy), and section text was eval-\nuated similarly to subtask B (see §3.3). In cases\nwhere the model output an invalid section header,14\nwe replaced it with “GENHX” (general history),\nwhich tends to summarize the contents of the other\nsections. The model was fine-tuned on a single\nNVIDIA A100-40GB GPU. Hyperparameters were\nlightly tuned on the validation set (Table 4).\nWe present the results of our approach on the\n14In practice, we found that the fine-tuned model rarely, if\never, generates invalid section headers\nFigure 6: Histogram of token lengths for subtask\nA train and validation sets. Dialogues and notes\nwere tokenized with HuggingFace Tokenizers using\n“google/flan-t5-large”. Lengths greater than the\n99th-percentile are omitted to make the plot legible.\nvalidation set in Table 5. Similar to subtask B (see\n§4.1), we find, perhaps unsurprisingly, that scal-\ning the model size from FLAN-T5BASE (24 layers,\n∼250M parameters) to FLAN-T5LARGE (48 layers,\n∼780M parameters) leads to large improvements in\nperformance. Performance is further improved by\njointly learning to predict section headers and gen-\nerate note sections. Our submission to the shared\ntask based on this approach tied for first on section\nheader prediction (78% accuracy), and ranked first\nfor note section generation (average ROUGE-1,\nBERTScore and BLEURT F1-score of 57.9).\nB Subtask B\nB.1 Hyperparameter tuning of LED\nWe lightly tuned the hyperparameters of\nLEDLARGE-PubMed on the subtask B validation set\nagainst the average ROUGE-1 F1, BERTScore F1\nand BLEURT-20 scores. The best hyperparameters\nobtained are given in Table 6. We used the same\nhyperparameters when fine-tuning LEDBASE and\nLEDLARGE in §4.1.\nB.2 Post processing LEDs outputs\nIn practice, we found that the fine-tuned LED\nmodel sometimes produces invalid section head-\ners; notably, this problem did not occur with the\nICL-based approach using GPT-4. Therefore, we\nlightly post-processed LEDs outputs using a simple\nscript that identifies section headers produced by\nthe model not in the ground truth set and uses fuzzy\n332\nTable 4: Hyperparameters used with FLAN-T5 on the Dialogue2Note subtask A\nHyperparameter Value Comment\nmax_source_length 1024 truncate input sequences to this max length\nmax_target_length 512 truncate output sequences to this max length\nsource_prefix “Summarize the following patient-\ndoctor dialogue. Include all medi-\ncally relevant information, including\nfamily history, diagnosis, past medical\n(and surgical) history, immunizations,\nlab results and known allergies. You\nshould first predict the most relevant\nclinical note section header and then\nsummarize the dialogue. Dialogue:”\ninstruction text prepended to all inputs\ntrain_batch_size 8 batch size during training\neval_batch_size 12 batch size during inference\nlearning_rate 1e-4 learning rate during training\noptimizer AdamW (Loshchilov and Hutter,\n2019)\noptimizer used during training\nnum_train_epochs 20 total number of training epochs\nwarmup_ratio 0.1 proportion of training steps to linearly increase\nthe learning rate to learning_rate\nlr_scheduler linear with warmup learning rate linearly increased during first\nwarmup_ratio fraction of train steps and linearly\ndecreased to 0 afterwords\nweight_decay 0.01 not applied to bias & LayerNorm weights\nlabel_smoothing 0.1 label smoothing factor used during training\nbf16 true whether to use BF16 during training\nnum_beams 2 beam size used during beam search decoding\nTable 5: Fine-tuning FLAN-T5. Accuracy of predicted section headers and score of generated note sections is\nshown. Jointly learning to predict section headers and generate notes improve performance. Bold: best scores.\nNote generation\nModel Header prediction (%) ROUGE-1 F1 BERTScore F1 BLEURT Avg.\nRandom header 8.0 – – – –\nMajority header 22.0 – – – –\nFLAN-T5BASE 71.0 40.1 70.5 52.7 54.5\nFLAN-T5LARGE 79.0 49.8 74.5 58.0 60.8\n↪→w/o header prediction – 48.0 74.3 57.6 59.9\nstring matching15 to replace them with the closest\nvalid header. For example, in one run, this process\nconverted the (incorrect) predicted section header\n“HISTORY OF PRESENT” to the nearest valid\nheader “HISTORY OF PRESENT ILLNESS”.\nC Fine-tuning Seq2Seq Models\nWhen training the sequence-to-sequence (seq2seq)\nmodels for both subtask A (Appendix A) and\nB (§3.1), we followed a canonical supervised\nfine-tuning (SFT) process. We start with a pre-\ntrained, encoder-decoder transformer-based lan-\nguage model (Vaswani et al., 2017). First, the en-\ncoder maps each token in the input to a contextual\nembedding. Then, the autoregressive decoder gen-\nerates an output, token-by-token, attending to the\n15We used https://github.com/seatgeek/thefuzz\noutputs of the encoder at each timestep. Decoding\nproceeds until a special “end-of-sequence” token\n(e.g. </s>) is generated, or a maximum number of\ntokens have been generated. Formally, X is the in-\nput sequence, which in our case is a doctor-patient\ndialogue, and Y is the corresponding output se-\nquence of length T, in our case a clinical note. We\nmodel the conditional probability:\np(Y|X) =\nT∏\nt=1\np(yt|X,y<t) (1)\nDuring training, we optimize over the model pa-\nrameters θthe sequence cross-entropy loss:\nℓ(θ) =−\nT∑\nt=1\nlog p(yt|X,y<t; θ) (2)\n333\nTable 6: Hyperparameters used with Longformer-Encoder-Decoder (LED) on the Dialogue2Note subtask B\nHyperparameter Value Comment\nmax_source_length 4096 truncate input sequences to this max length\nmax_target_length 1024 truncate output sequences to this max length\nsource_prefix “Summarize the following patient-\ndoctor dialogue. Include all medi-\ncally relevant information, including\nfamily history, diagnosis, past medical\n(and surgical) history, immunizations,\nlab results and known allergies. Dia-\nlogue:”\ninstruction text prepended to all inputs\ntrain_batch_size 8 batch size during training\neval_batch_size 6 batch size during inference\nlearning_rate 3e-5 learning rate during training\noptimizer AdamW (Loshchilov and Hutter,\n2019)\noptimizer used during training\nnum_train_epochs 50 total number of training epochs\nwarmup_ratio 0.1 proportion of training steps to linearly increase\nthe learning rate to learning_rate\nlr_scheduler linear with warmup learning rate linearly increased during first\nwarmup_ratio fraction of train steps and linearly\ndecreased to 0 afterwords\nweight_decay 0.01 not applied to bias & LayerNorm weights\nlabel_smoothing 0.1 label smoothing factor used during training\nfp16 true whether to use FP16 during training\nnum_beams 4 beam size used during beam search decoding\nmin_length 100 min length of generated sequences\nmax_length 1024 max length of generated sequences\nlength_penalty 2.0 values > 0 promote longer output sequences\nno_repeat_ngram 3 ngrams of this size can only occur once\nmaximizing the log-likelihood of the training data.\nAs is common, we use teacher forcing during train-\ning, feeding previous ground truth inputs to the\ndecoder when predicting the next token in the se-\nquence. During inference, we generate the out-\nput using beam search (Graves, 2012). Beams are\nranked by mean token log probability after apply-\ning a length penalty. Models are fine-tuned using\nthe HuggingFace Transformers library.16\n16https://github.com/huggingface/transformers/\nblob/main/examples/pytorch/summarization/run_\nsummarization.py\n334",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7542251348495483
    },
    {
      "name": "Task (project management)",
      "score": 0.7154655456542969
    },
    {
      "name": "Scrutiny",
      "score": 0.6497023105621338
    },
    {
      "name": "Context (archaeology)",
      "score": 0.6037463545799255
    },
    {
      "name": "Language model",
      "score": 0.5496304631233215
    },
    {
      "name": "Natural language processing",
      "score": 0.48111099004745483
    },
    {
      "name": "Path (computing)",
      "score": 0.4399879574775696
    },
    {
      "name": "Artificial intelligence",
      "score": 0.41340500116348267
    },
    {
      "name": "Human–computer interaction",
      "score": 0.3966098427772522
    },
    {
      "name": "Multimedia",
      "score": 0.3885439336299896
    },
    {
      "name": "World Wide Web",
      "score": 0.3667740225791931
    },
    {
      "name": "Programming language",
      "score": 0.2071266770362854
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    }
  ]
}