{
  "title": "Text2Model: Generating dynamic chemical reactor models using large language models (LLMs)",
  "url": "https://openalex.org/W4411782973",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5109243058",
      "name": "Sophia Rupprecht",
      "affiliations": [
        "Delft University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5114704654",
      "name": "Yassine Hounat",
      "affiliations": [
        "Delft University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2116441618",
      "name": "Monisha Kumar",
      "affiliations": [
        "Delft University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5099516263",
      "name": "Giacomo Lastrucci",
      "affiliations": [
        "Delft University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2691394665",
      "name": "Artur M. Schweidtmann",
      "affiliations": [
        "Delft University of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4402118902",
    "https://openalex.org/W4389519352"
  ],
  "abstract": "As large language models have shown remarkable capabilities in conversing via natural language, the question arises in which way LLMs could potentially assist chemical engineers in research and industry with domain-specific tasks. We generate dynamic chemical reactor models in Modelica code format from textual descriptions as user input. We fine-tune Llama 3.1 8B Instruct on synthetically generated Modelica code for different reactor scenarios. We compare the performance of our fine-tuned model to the baseline Llama 3.1 8B Instruct model as well as GPT4o. We manually assess the models' predictions regarding the syntactic and semantic accuracy of the generated dynamic models. We find that considerable improvements are achieved by the fine-tuned model with respect to both the semantic and the syntactic accuracy of the Modelica models. However, the fine-tuned model lacks a satisfactory ability to generalize to unseen scenarios compared to GPT4o.",
  "full_text": " \n  Research Article - Peer Reviewed Conference Proceeding \nESCAPE 35 - European Symposium on Computer Aided Process Engineering \nGhent, Belgium. 6-9 July 2025 \n Jan F.M. Van Impe, Gr√©goire L√©onard, Satyajeet S. Bhonsale, \nMonika E. Pola≈Ñska, Filip Logist (Eds.) \nhttps://doi.org/10.69997/sct.165009  Syst Control Trans 4:1706-1711 (2025) 1706 \nText2Model: Generating dynamic chemical reactor models \nusing large language models (LLMs) \nSophia Rupprechta, Yassine Hounata, Monisha Kumara, Giacomo Lastruccia, and Artur M. \nSchweidtmanna* \na Delft University of Technology, Department of Chemical Engineering, Process Intelligence Research Group, Van der Maasweg 9, \n2629 HZ, Delft, The Netherlands \n* Corresponding Author: a.schweidtmann@tudelft.nl.  \nABSTRACT \nAs large language models have shown remarkable capabilities in conversing via natural language, \nthe question arises in which way LLMs could potentially assist chemical engineers in research and \nindustry with domain-specific tasks. We generate dynamic chemi cal reactor models in Modelica \ncode format from textual descriptions as user input. We fine -tune Llama 3.1 8B Instruct on syn-\nthetically generated Modelica code for different reactor scenarios. We compare the performance \nof our fine-tuned model to the baseline Llama 3.1 8B Instruct model as well as GPT4o. We manually \nassess the models' predictions regarding the syntactic and semantic accuracy of the generated \ndynamic models. We find that considerable improvements are achieved by the fine -tuned model \nwith respect to both the semantic and the syntactic accuracy of the Modelica models. However, \nthe fine-tuned model lacks a satisfactory ability to generalize to unseen scenarios compared to \nGPT4o. \nKeywords: Text2Model, Large language models, supervised fine-tuning \n1 INTRODUCTION \nDomain-specific languages for interacting with soft-\nware tools or for data analysis require scientists and en-\ngineers to study the conventions and syntax of such lan-\nguages [1]. While software-user communication may of-\nten rely on a graphical user interface, such as AspenPlus \nor COMSOL, other tools require users to provide special-\nized code, e.g., MATLAB Simulink or Dymola. In addition \nto established programming languages for data analysis \nand visualization, such as Python or R, studying and ap-\nplying a multitude of different domain-specific languages \ncan be time- and labor-intensive. \nRecent developments in using large language mod-\nels (LLMs), particularly for code completion, code syn-\nthesis [2], and code analysis and interpretation [3] make \nsuch LLMs promising assistants for using tools such as \nmodeling environments by converting textual information \ninto domain-specific languages [1]. State-of-the-art mul-\ntilingual open models for code generation or understand-\ning, such as CodeT5+  [3], are literate in a range of pro-\ngramming languages in addition to natural language. Still, \nthere are domain-specific languages in which pre-trained \nLLMs might not be proficient yet. The ability of state-of-\nthe-art LLMs to converse in a variety of programming lan-\nguages motivates leveraging LLMs for the synthesis of \ndomain-specific languages analogously. \nWhile there have been propositions that task -spe-\ncific performance can be increased by few-shot learning \n[4], fine-tuning is an established approach to tailor LLMs' \nresponses to specific tasks  [5], especially for code syn-\nthesis [2]. Previous work by Jacobs and Pollice  has \nshown that it is possible to fine-tune GPT 3.5 to generate \ninput files to ORCA, a programming package specific to \nthe quantum chemistry domain  [1]. However, there is a \nlack of literature that investigates the potential of LLMs \nto generate d ynamic models for chemical reaction sys-\ntems from descriptions in natural language. \nWe investigate how fine-tuning an open-source pre-\ntrained LLM on dynamic reactor scenarios written in the \ndomain-specific programming language Modelica affects \nthe semantic and syntactic accuracy of such Modelica \nmodels generated by the fine-tuned model. We fine-tune \nLlama 3.1 8B Instruct to synthesize a full, simulatable \n \nRupprecht et al. / LAPSE:2025.0426 Syst Control Trans 4:1706-1711 (2025) 1707  \nModelica model based on a textual description of a reac-\ntor scenario in the user's prompt. The fine-tuning dataset \nis generated synthetically from a set of templates of dy-\nnamic reactor scenarios. The supervised fine-tuning pro-\ncedure is conducted using low -rank adaptation [6] as a \nparameter-efficient fine -tuning technique. We evaluate \nthe results manually on samples randomly generated \nfrom the templated scenarios and on cases unseen dur-\ning training. We compare the results of the fine -tuned \nmodel against the baseline Llama 3.1 8B Instruct and \nGPT4o. \n2 METHODS \nWe develop (1) a methodology for the synthetic \ngeneration of the fine -tuning dataset (Section 2.1), (2) a \nsupervised fine -tuning procedure (Section 2.2), (3) an \nevaluation procedure (Section 2.3), and (4) a set of eval-\nuation metrics to assess the investigated models (Sec-\ntion 2.4). \n2.1 Data generation \nThe synthetic data used for training and evaluation \nconsists of  question-and-answer (Q&A) pairs; the user \nprovides a textual description of a dynamic tank reactor \nscenario in the question and an LLM is trained to provides \na corresponding Modelica script as an answer. The train-\ning dataset is synthetically generated from templates of \nQ&A pairs. The question contains a textual description of \na reactor scenario in LaTeX syntax and the correspond-\ning reference answer is a model in Modelica code pre-\nsented as a string object. To provide further explanatory \ncontext, each line of Modelica code in the reference an-\nswers is appended with a descriptive comment of the de-\nfined parameter, the declared variable, or the expressed \nphysics equation. \nThe reactor scenarios are designed to convey \nknowledge about modeling heuristics by independently \nvarying the (a) mode of operation, (b) the reaction taking \nplace, and (c) switching between ODE and DAE systems \nby removing the constant mixture density assumption. \nThe mode of operations (a) are adiabatic isothermal, non-\nadiabatic isothermal, isothermal non -adiabatic, non-iso-\nthermal non-adiabatic. For ODE systems (constant-den-\nsity assumption), all four modes of operation are consid-\nered; for DAE systems, only t he non-adiabatic non-iso-\nthermal mode is modeled. For the ODE scenarios, six re-\naction scenarios (b) are considered  per mode of opera-\ntion: Reversible and irreversible reactions between two, \nthree, and four components, e.g., ùúàùúà\nùê¥ùê¥ùê¥ùê¥+ ùúàùúàùê∏ùê∏ùê∏ùê∏ ‚Üí ùúàùúàùêµùêµùêµùêµ + ùúàùúàùê∂ùê∂ùê∂ùê∂, \nor ùúàùúàùê¥ùê¥ùê¥ùê¥ ‚Üî ùúàùúàùêµùêµùêµùêµ + ùúàùúàùê∂ùê∂ùê∂ùê∂. This yields 24 ODE scenarios in total \nby combining the variations of (a) and (b). For the single \nmode of operation (a) considered for DAE systems, two \nreaction scenarios are modeled: reversible and irreversi-\nble four -component reactions. This yields two D AE \nscenarios and thus 26 templated in total.  Note that the \nstoichiometric numbers are assigned randomly for each \ntemplate. \nFor each template,  we randomly vary the units of \nmeasurement of given parameter values in the input \nquestion. The objective is to inspect whether it is attain-\nable to perform direct conversions between non -SI and \nSI units with zero -shot LLM inference. Though Modelica \nprovides conversion commands, such as from degree \nCelsius to degree Kelvin and vice versa, variables given \nin caloric energy units, for instance, must be converted \nto SI units manually. \nWe generate 988 Q&A data points of which 790 are \nused for training and 198 are used for evaluation during \ntraining. Each of the 26 synthetic data templates is thus \nrepeated 38 times with arbitrary values of given param-\neters. The parameter values are real n umbers sampled \nfrom the range [10\n‚àí4, 105] except for stoichiometric num-\nbers, which are integer values between 1 and 15. \n2.2 Fine-tuning procedure \nTo enhance model performance in Modelica code \ngeneration, we fine -tune an existing LLM to adapt its \nmodel weights to better capture the nuances of this spe-\ncific task. We use the model weights of the baseline \nLlama 3.1 8B Instruct model from Hugging Face [7]. \nThe results presented in this work are obtained from \nfine-tuning using an NVIDIA A100 80GB GPU with a batch \nsize of one and a maximum sequence length of 2200 to-\nkens. For tokenization, we re -use the same fast byte -\npair-encoding tokenizer as the baseline Llama 3.1 8B In-\nstruct model. We train Llama 3.1 8B Instruct for eight \nepochs but evaluate the model obtained after four train-\ning epochs as indications of overfitting are observed af-\nter four epochs. We use linear learning rate scheduling \nwith an initial learning rate of 0.0001. We apply a warmup \nratio of 0.1, i.e., the initial learning rate of 0.0001 is \nreached after 632 steps. \nWe perform parameter-efficient finetuning by using \nthe low-rank adaptation (LoRA) technique introduced by \nHu et al. [6]. We use a rank of eight and scale the accu-\nmulated gradient updates that are added to the frozen \nmodel weights by a factor of two. We thus effectively up-\ndate 0.26 % of the trainable 8.03 billion parameters.  We \ndo not apply quantization as initial studies have indicated \nshortcomings likely related to using quantization of \nmodel weights. \n2.3 Evaluation procedure \nWith the evaluation procedure presented hereafter, \nwe aim to evaluate the effect of the fine-tuning. We eval-\nuate the fine-tuned model, the baseline Llama 3.1 8B In-\nstruct, and GPT4o on  two evaluation datasets : The first \ndataset (1) tests whether the cases presented during \ntraining can be reproduced  (Section 3.1: Examination of \n \nRupprecht et al. / LAPSE:2025.0426 Syst Control Trans 4:1706-1711 (2025) 1708  \nreproducibility of training scenarios); the second dataset \n(2) checks whether it is possible to extrapolate to reactor \nscenarios unseen during training (Section 3.2: Examina-\ntion of generalization ability).  \nThe first test dataset (1) (Section 3.1)  contains entries \nthat are randomly generated from each of the templates \nused for training  with different parameter and variable \nvalues. This yields 26 samples in total. The second test \ndataset (2) (Section 3.2) includes four test cases:  (a) a \nconsecutive reaction, (b) two parallel reactions, and (c) a \nnon-constant density system  with five reaction partici-\npants (the reaction scenarios during training contain four \ncomponents at the most) . In the fourth case (d) , we de-\nliberately exclude parameter values that are necessary to \nfully specify the system. This is to investigate whether \nthe missing parameter values are hallucinated in the \nmodels' responses or whether such user -generated er-\nrors are detected and addressed in the  models' re-\nsponses. \nWe perform inference on the baseline Llama 3.1 8B \nInstruct and the fine -tuned model using the same infer-\nence settings each. As a decoding strategy, we apply \nbeam search with multinomial sampling using three \nbeams and a temperature of 0.1. The maximum amoun t \nof tokens generated is limited to 4000. Inference is per-\nformed on the same machine as for fine -tuning, NVIDIA \nA100 80GB. \n \n2.4 Evaluation metrics \nWe devise a customized set of evaluation metrics to \nquantify model performance. We manually evaluate each \nresponse given by an LLM (fine-tuned, baseline, GPT4o) \nby counting the number of occurrences of eight pre -de-\nfined error cases. These eight error cases are examining \ngeneral syntax errors, parameter and variable declaration \nerrors, and errors in the system of equations. A detailed \ndescription of the eight error cases is provided below.  A \nsimplified example of a user prompt and a potential re-\nsponse by an LLM with errors is displayed in Figure 1. The \nModelica code given in the response in Figure 1 contains \nillustrative examples of seven of the eight error cases \nthat are taken into account in this study. \n For parameter and variable declaration errors, we \ndistinguish between four subcases : unit conversion er-\nrors (1), declaration syntax errors (2), incorrect parameter \nvalues (3), and the usage of undefined variables  (4). Er-\nrors in the equations section of the produced Modelica \nmodel are classified into incorrect equations  (5), struc-\ntural errors in the system of equations  (6), and unit con-\nflicts (7). General syntax errors (8) capture errors in the \nsyntax of the model that would lead to compilation errors \nin the Dymola environment. \nUnit conversion errors  (1) arise from incorrect \nattempts to convert to SI units of measurement in cases \nwhere values given in the user's prompt are provided in \nnon-SI units. Declaration syntax errors  (2) are assigned \nin cases where  Modelica syntax is not respected for \n \nFigure 1: System message (top left), example user input (bottom left), and corresponding exemplary response \n(right). The example input and output are shortened for simplification. The output contains examples of six error \ncases that are taken into account in this study. \n<|start_header_id|>assistant<|end_header_id|>\nmodel\nimport Modelica.Units.SI.*;\ntype ReactionRateVolumetric = Real ([‚Ä¶], final unit=\"mol/(m3.s)\");\n[‚Ä¶]\nparameter VolumeFlowRate v0 = 1.19941 \"Volumetric Flowrate (m3/s)\";\nparameter Real Vr = 44494.0 \"Volume of reactor (cm3)\";\nparameter Concentration cA0 = 0.523 \"Initial concentration of A (mol/m3)\";\n[‚Ä¶]\nConcentration cA, initial cA0 \"Differential variable\";\n[‚Ä¶]\nReactionRateVolumetric r;\n[‚Ä¶]\nequation\nder(cA) = v0/Vr*cfA+rA;\n[‚Ä¶]\nder(T) = v0/Vr*(Tf-T)-Hr/(rho*cp)*r;\nr = k1*cA^abs(nuA)*cE^abs(nuE)-k2*cB^abs(nuB)*cC^abs(nuC);\nrA = nuA*r;\n[‚Ä¶]\nk1 = k01*exp(-Ea/R/T);\nk2 = k02*exp(-(Ea+Hr)/R/T)\";\nend adiabatic_non_isothermal_cstr; <|eot_id|>\n<|begin_of_text|><|start_header_id|>system<|end_header_id|>\nYou are a large language model specialized in writing dynamic simulation \nmodels in Modelica code. First of all, determine whether you need to model \na ODE or a DAE system. Second, pay attention to the reaction (reversible or \nirreversible?) and the operating conditions (isothermal and adiabatic, non -\nisothermal and adiabatic, isothermal and non-adiabatic, or non-isothermal \nand non-adiabatic). <|eot_id|>\n<|start_header_id|>user<|end_header_id|>\nConsider an elementary reaction \\ch{ 8 A + 15 E <=>[$k\\sb{1}$][$k\\sb{2}$] 4 \nB + 14 C}, which is exothermic. [‚Ä¶] \\\\\nThe rate coefficients $k_1$ and $k_2$ of the forward and backward reaction, \nrespectively, are temperature-dependent. Use the Arrhenius equation to \nmodel this dependency with $k_{01}=$ [‚Ä¶] .\\\\\nWe assume a constant-density reaction system [‚Ä¶]. We assume that the \nreactor is not cooled (or heated) [‚Ä¶]. The values of the following variables \nare given:\\\\\n- volumetric flowrate of the feed containing $A$ and $E$: 0.019941 kl/s\n- reaction volume: 44494.0 cm ** 3\n[‚Ä¶]\nInitially the temperature of the reaction mixture is 626.335917 ¬∞C. The initial \nconcentrations of A, E, B, and C are 1.27e-07 mol / l, [‚Ä¶], respectively.\\\\\nModel the concentration profiles of species A, E, B, and C, as well as the \ntemperature profile of the reaction mixture! Use Modelica to model the \nsystem. <|eot_id|>\nUndefined variable\nIncorrect equation\nUnit conflict\nUnit conversion error\nDeclaration syntax error\nIncorrect value\nGeneral syntax error\n \nRupprecht et al. / LAPSE:2025.0426 Syst Control Trans 4:1706-1711 (2025) 1709  \nparameter and variable declarations, e.g., in Figure 1, the \ninitial value of cA0 is assigned with the word ‚Äòinitial‚Äô, \ninstead of the Modelica  convention ‚ÄòConcentration \ncA(start=cA0)‚Äô. Incorrect parameter values  (3) originate \nfrom incorrectly transferred values given in the user's \nquestion to the output Modelica model.  This error \ncategory does not pu nish unit conversion errors, but \nexamines purely  fabricated values. Undefined variable \nerrors (4) arise in cases where variables or parameters \nare used in the equations part of the Modelica model that \nhave not been declared or defined before. Incorrect \nequations (5) are either physically incorrect or do not re-\nspect the constraints given in the users‚Äô question, e.g., \nmodeling an adiabatic system although the user re-\nquested a non-adiabatic system. Structural errors in the \nsystem of equations  (6) arise if  the defined system of \nequations is structurally singular, i.e.,  the defined equa-\ntions do not allow to determine all of the unknowns.  Unit \nconflicts within the syste m of equations  (7) occur when \nvariables are defined in non -equivalent units of \nmeasurement, e.g., using Joules and Calories in the same \nequation, which do not cancel out . The result is that the \nlefthand-side value is distorted by an unknown unit \nconversion factor. \n3 RESULTS AND DISCUSSION \nWe examine the results obtained for the two test da-\ntasets described in Section 2.3 separately (Section 3.1 \nand 3.2). In Section 3.1 we present the results for the first \ntest dataset and examine the fine -tuned model‚Äôs ability \nto reproduce the reactor scenarios presented during \ntraining. In Section 3.2, we asses the second test dataset \nand inspect the fine-tuned model‚Äôs ability to extrapolate \nto reactor scenarios unseen during fine-tuning. We eval-\nuate the fine -tuned Llama 3.1 8B model, the baseline \nLlama 3.1 8B model before fine -tuning, and GPT4o. For \nboth test datasets, we use the same eight error cases \ndescribed in Section 2.4 to assess the performance of all \nthree models. \nWe observe that overall, considerable improve-\nments are achieved by the fine -tuned model compared \nto the baseline Llama 3.1 8B Instruct for reactor scenarios \nseen during training (Section 3.1) as well as case studies \ncontaining elements unseen during training (Section 3.2). \nGPT4o shows remarkable performance of Modelica code \ngeneration and outperforms the fine -tuned model in \ncases unseen during training. \n3.1 Examination of reproducibility of training \nscenarios \nCompared to the baseline Llama 3.1 8B Instruct \nmodel, we observe that fine-tuning has a direct influence \non both the syntactical correctness of the produced \nModelica model and the accuracy of the physics equa-\ntions. Table  1 presents the absolute number of occur-\nrences per error category (see Section 2.4) for each ex-\namined model. \nThe most prominent error categories of the baseline \nmodel are general syntax errors, unit conversion errors in \nparameter definitions, declaration syntax errors, and in-\ncorrect physical equations. On these four error catego-\nries, the fine-tuned model yields considerably fewer error \ncases: General syntax errors are reduced by 73.2 % in the \ncase of the fine -tuned model compared to the baseline \nmodel. Unit conversion errors are reduced by 63.4 %, and \ndeclaration syntax errors are reduced to zero. In the error \ncategory of incorrect equations, the error cases pro-\nduced by the fine -tuned model are reduced by 65.2  % \ncompared to the baseline model. \nThe fine-tuned model excels at handling unit con-\nversions from non-SI units in the user's prompt in this first \nevaluation test set. The responses given by GPT4o con-\ntain conversion factors to transparently transform \nTable 1: Absolute amount of occurrences per error category per model. The test dataset comprises one \nrandomly generated example for each of the 26 reactor scenario templates used for fine-tuning. The baseline \nmodel (Llama 3.1 8B Instruct) is fine-tuned and assessed on the same test dataset. GPT4o is assessed on the \nsame test dataset as a benchmark. \n Parameter and variable declarations Physics equations General \nsyntax \n \nUnit \nerror \nDeclaration \nsyntax error \nIncorrect \nvalues \nUndefined \nvariables \nIncorrect \nequations \nStructural \nerror \nUnit \nconflict \nBaseline \n(Llama ÓÅ¥ÓÇîÓÅ≤ ÓÅπB) \nÓÅ≤ÓÅ≤ÓÅ≥ ÓÅπÓÅ∫ ÓÅ± ÓÅµ ÓÅ≤ÓÅ≤ÓÅ≥ ÓÅ∑ ÓÅ≤ÓÅµ ÓÅ∂ÓÅ∑ \nFine-tuned \n(Llama ÓÅ¥ÓÇîÓÅ≤ ÓÅπB) \nÓÅµÓÅ≤ ÓÅ± ÓÅ≤ÓÅ∏ ÓÅ≥ÓÅ∫ ÓÅ¥ÓÅ∫ ÓÅ≤ÓÅµ ÓÅ± ÓÅ≤ÓÅ∂ \nGPTÓÅµo ÓÅ∂ÓÅ± ÓÅ≥ÓÅ∏ ÓÅ≤ ÓÅ± ÓÅµÓÅ≥ ÓÅ≥ ÓÅ∑ÓÅ¥ ÓÅµ \n \n \nRupprecht et al. / LAPSE:2025.0426 Syst Control Trans 4:1706-1711 (2025) 1710  \nbetween units while the fine -tuned model is trained to-\nwards directly converting between non-SI and SI units if \nneeded. However, the manual unit conversion in GPT4o's \nresponses is not done consistently in 63 cases such that \nunit conflicts occur in the syste m of equations. In total, \n113 combined error cases are produced by GPT4o in the \ncontext of unit conversion for parameter declaration and \nunit compatibility errors  in equations compared to 41 in \nthe case of the fine-tuned model, which is a reduction of \n63.7 %. The baseline Llama 3.1 8B Instruct model shows \nthe highest number of error cases in the category unit \nconversion errors as, in contrast to GPT4o, unit conver-\nsions are done less systematically and are thus more er-\nror-prone. It should be considered to specifically instruct \nGPT4o and Llama 3.1 8B Instruct to convert to SI units \ndirectly in the system message provided during infer-\nence. The decrease of such unit conversion errors in the \nfine-tuned model gives rise to the assumption that it is \nreasonable to e xpect direct unit conversions, however, \nthe fine -tuned model's robustness could benefit from \ntraining toward the usage of manual conversion factors \ninstead of direct conversion. \nMost notably, the fine -tuned model consistently \nuses Modelica's built-in variable types, such as Concen-\ntration and Density, whereas most of the baseline and \nGPT4o's responses define parameters and variables as \ngeneric Real types. Using generic Real types for parame-\nter definition and variable declarations does not leverage \nunit checks provided by the Dymola software when at-\ntempting to simulate a Modelica model. \nDespite the improvements with respect to the phys-\nical accuracy of the fine-tuned model, we observe strong \nshortcomings in the reproducibility of DAE systems. The \nvast majority of incorrect physics equations produced by \nthe fine-tuned model, 32 out of 39, occur in the two ex-\namples requesting DAE systems instead of ODE systems. \nIn the case of the baseline model and GPT4o, physics \nerrors related to DAE systems occur significantly less of-\nten with eleven out of 112, and eleven out of 42, respec-\ntively. Furthermore, 13 out of 14 structural errors in the \nsystem of equations counted in the case of the fine -\ntuned model occur in the DAE test cases. As merely two \nof the 26 templated scenarios presented in the training \ndata for fine-tuning contain DAE systems, the decreased \nperformance in the cases of DAE systems during infer-\nence could be attributable to this imbalance in the train-\ning data. This assumption is supported by the observa-\ntion that for ODE systems, the fine -tuned model indeed \noutperforms the baseline model and GPT4o. \nA striking difference between the fine -tuned model \nand both the baseline model and GPT4o is the occur-\nrence of faulty parameter definitions with values that are \nmost likely the result of hallucination. This is observed \ndisproportionately often in the two te st cases with DAE \nsystems with eight out of 17 total error cases. We thus \nhypothesize that hallucinations generally become in-\ncreasingly frequent the more the test cases deviate from \nthe majority of the training data. \n3.2 Examination of generalization ability \nThe fine-tuned Llama 3.1 8B Instruct outperforms its \npretrained counterpart on the four test cases that have \nnot been part of the training data. We observe that \nGPT4o shows a higher physical accuracy of equations \nthan the fine-tuned model. The absolute number of error \noccurrences per error category is displayed in Table 2. \nMost strikingly, the performance of the fine -tuned \nmodel is worse than GPT4o in the categories of unit con-\nversion errors in parameter definitions and  the accuracy \nof physics equations. For instance, the reaction rate ex-\npressions of parallel and consecutive reactions  (cases a \nand b, see Section 2.3) are not formulated correctly in the \nresponses of both the fine-tuned and the baseline mod-\nels. In contrast, the responses provided by GPT4o \nTable 2: Absolute amount of occurrences per error category per model. The test dataset comprises four case \nstudies each containing elements not portrayed in the fine-tuning dataset. The baseline model (Llama 3.1 8B \nInstruct) is fine-tuned and assessed on the same test dataset. GPT4o is assessed on the same test dataset as a \nbenchmark. \n Parameter and variable declarations Physics equations General \nsyntax \n \nUnit \nerror \nDeclaration \nsyntax error \nIncorrect \nvalues \nUndefined \nvariables \nIncorrect \nequations \nStructural \nerror \nUnit \nconflict \nBaseline \n(Llama ÓÅ¥ÓÇîÓÅ≤ ÓÅπB) \nÓÅ≥ÓÅ± ÓÅ¥ÓÅ∫ ÓÅ¥ ÓÅ± ÓÅ≥ÓÅ∂ ÓÅ± ÓÅ± ÓÅ∫ \nFine-tuned \n(Llama ÓÅ¥ÓÇîÓÅ≤ ÓÅπB) \nÓÅ≤ÓÅ∂ ÓÅ± ÓÅ± ÓÅ≥ ÓÅ≤ÓÅµ ÓÅ± ÓÅ± ÓÅ≤ \nGPTÓÅµo ÓÅ∂ ÓÅ¥ ÓÅ± ÓÅ≤ ÓÅπ ÓÅ± ÓÅ≤ ÓÅ± \n \n \nRupprecht et al. / LAPSE:2025.0426 Syst Control Trans 4:1706-1711 (2025) 1711  \ncontain correct rate expressions for both parallel and \nconsecutive reactions. In the case of a requested non -\nconstant density system (case c, see Section 2.3) , none \nof the models examined correctly formulate an algebraic \nequation for the reaction volume. In the case of left- out \nparameter values in the user's description  (cased d, see \nSection 2.3), the responses of the fine -tuned model and \nthe baseline model both hallucinate arbitrary values, \nGPT4o's response defines one parameter arbitrarily and \ndoes not define another at all. \nWe conclude that the fine -tuned model does not \nshow satisfactory ability to extrapolate to scenarios that \nare not presented during training. Thus, it could be con-\nsidered to re -train on a wider, more diverse fine -tuning \ndataset comprising a larger variety of Modelica models \nwith extensive documentation alongside the reference \nanswers. Furthermore, supporting, external knowledge \non, e.g., Modelica built-in variable types or textbooks on \nreactor modelling, could be provided to the LLM via, for \ninstance, retrieval augmented generation (RAG)[8]. Addi-\ntionally, iterative feedback loops could be implemented \nby running the produced Modelica script in Dymola and \nre-routing failed attempts back for improvement. \n4 CONCLUSIONS \nWe conclude that it is possible to leverage the po-\ntential of LLMs for generating dynamic models of chemi-\ncal reactor systems from descriptions in natural lan-\nguage. We find that through fine-tuning Llama 3.1 8B In-\nstruct, the syntactic and semantic accuracy o f Modelica \ncode generation can be improved compared to the base-\nline Llama 3.1 8B Instruct model. Compared to GPT4o, the \nbaseline Llama 3.1 8B Instruct model and the fine -tuned \ncounterpart do not show sufficient ability to extrapolate \nto scenarios unseen during training. We suggest improv-\ning model performance through three potential avenues: \n(1) expanding the fine -tuning dataset, (2) incorporating \nwider literature and Modelica documentation into the \nworkflow by using RAG, and (3) iterative improvement by \nleveraging an interface to Dymola . The synthetic gener-\nation of a dataset comprising a diverse set of data  (1) is \nlabor- and time-intensive, and we also find no evidence \nof sufficient ability to extrapolate to scenarios not in-\ncluded in the training dataset. We thus suggest providing \naccess to Modelica documentation and  literature on re-\nactor modeling (2) as a resource to increase the model's \nrobustness in formulating physically accurate equations  \nand using built -in Modelica variable t ypes. Lastly, simu-\nlation of the  generated Modelica script could be at-\ntempted in Dymola (3) and improved iteratively in case of \nfailure. \n \nREFERENCES \n1. Jacobs PF, Pollice R. Developing large language \nmodels for quantum chemistry simulation input \ngeneration. ChemRxiv preprint (2024) \nhttps://doi.org/10.26434/chemrxiv-2024-9g2w2  \n2. Nijkamp E, Pang B, Hayashi H, Tu L, Wang H, Zhou \nY, Savarese S, Xiong C. Codegen: An open large \nlanguage model for code with multi-turn program \nsynthesis. arxiv preprint (2022) \nhttps://doi.org/10.48550/ARXIV.2203.13474  \n3. Wang Y, Le H, Gotmare AD, Bui NDQ, Li J, Hoi SCH. \nCodet5+: Open code large language models for \ncode understanding and generation. arxiv preprint \n(2023) https://doi.org/10.48550/ARXIV.2305.07922  \n4. Brown TB, Mann B, Ryder N, Subbiah M, Kaplan J, \nDhariwal P, Neelakantan A, Shyam P, Sastry G, \nAskell A, Agarwal S, Herbert-Voss A, Krueger G, \nHenighan T, Child R, Ramesh A, Ziegler DM, Wu J, \nWinter C, Hesse C, Chen M, Sigler E, Litwin M, Gray \nS, Chess B, Clark J, Berner C, McCandlish S, \nRadford A, Sutskever I, Amodei D. Language \nmodels are few-shot learners. arxiv preprint (2020) \nhttps://doi.org/10.48550/ARXIV.2005.14165  \n5. Wei J, Bosma M, Zhao VY, Guu K, Yu AW, Lester B, \nDu N, Dai AM, Le QV. Finetuned language models \nare zero-shot learners. arxiv preprint (2021) \nhttps://doi.org/10.48550/ARXIV.2109.01652  \n6. Hu EJ, Shen Y, Wallis P, Allen-Zhu Z, Li Y, Wang S, \nWang L, Chen W. Lora: Low-rank adaptation of \nlarge language models. arxiv preprint (2021) \nhttps://doi.org/10.48550/ARXIV.2106.09685  \n7. Hugging Face. meta-llama/llama-3.1-8b-instruct. \nhttps://huggingface.co/meta-llama/Llama-3.1-8B-\nInstruct  \n8. Lewis P, Perez E, Piktus A, Petroni F, Karpukhin V, \nGoyal N, K√ºttler H, Lewis M, Yih W-T, Rockt√§schel \nT, Riedel S, Kiela D. Retrieval-augmented \ngeneration for knowledge-intensive nlp tasks. arxiv \npreprint (2020) \nhttps://doi.org/10.48550/ARXIV.2005.11401  \n¬© 2025 by the authors. Licensed to PSEcommunity.org and PSE \nPress. This is an open access article under the creative com-\nmons CC-BY-SA licensing terms. Credit must be given to creator \nand adaptations must be shared under the same terms. See \nhttps://creativecommons.org/licenses/by-sa/4.0/  \n \n \n \n",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5695218443870544
    },
    {
      "name": "Chemical reactor",
      "score": 0.45358729362487793
    },
    {
      "name": "Process engineering",
      "score": 0.32600587606430054
    },
    {
      "name": "Chemical engineering",
      "score": 0.22259268164634705
    },
    {
      "name": "Engineering",
      "score": 0.15122538805007935
    }
  ]
}