{
    "title": "Utilizing Large Language Models for Enhanced Clinical Trial Matching: A Study on Automation in Patient Screening",
    "url": "https://openalex.org/W4394768876",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5050965260",
            "name": "Jacob Beattie",
            "affiliations": [
                "Southwestern Medical Center",
                "Southwestern Medical Center",
                "The University of Texas Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2978597149",
            "name": "Sarah Neufeld",
            "affiliations": [
                "Southwestern Medical Center",
                "Southwestern Medical Center",
                "The University of Texas Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2234892317",
            "name": "Daniel Yang",
            "affiliations": [
                "The University of Texas Southwestern Medical Center",
                "Southwestern Medical Center",
                "Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2800765973",
            "name": "Christian Chukwuma",
            "affiliations": [
                "Southwestern Medical Center",
                "The University of Texas Southwestern Medical Center",
                "Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A3047928349",
            "name": "Ahmed Gul",
            "affiliations": [
                "The University of Texas Southwestern Medical Center",
                "Southwestern Medical Center",
                "Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2367095951",
            "name": "Neil Desai",
            "affiliations": [
                "Southwestern Medical Center",
                "The University of Texas Southwestern Medical Center",
                "Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A3206076192",
            "name": "Steve Jiang",
            "affiliations": [
                "The University of Texas Southwestern Medical Center",
                "Southwestern Medical Center",
                "Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2972776848",
            "name": "Michael Dohopolski",
            "affiliations": [
                "Southwestern Medical Center",
                "The University of Texas Southwestern Medical Center",
                "Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A5050965260",
            "name": "Jacob Beattie",
            "affiliations": [
                "Southwestern Medical Center",
                "Southwestern Medical Center",
                "The University of Texas Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2978597149",
            "name": "Sarah Neufeld",
            "affiliations": [
                "The University of Texas Southwestern Medical Center",
                "Southwestern Medical Center",
                "Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2234892317",
            "name": "Daniel Yang",
            "affiliations": [
                "Southwestern Medical Center",
                "Southwestern Medical Center",
                "The University of Texas Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2800765973",
            "name": "Christian Chukwuma",
            "affiliations": [
                "Southwestern Medical Center",
                "Southwestern Medical Center",
                "The University of Texas Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A3047928349",
            "name": "Ahmed Gul",
            "affiliations": [
                "Southwestern Medical Center",
                "The University of Texas Southwestern Medical Center",
                "Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2367095951",
            "name": "Neil Desai",
            "affiliations": [
                "Southwestern Medical Center",
                "Southwestern Medical Center",
                "The University of Texas Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A3206076192",
            "name": "Steve Jiang",
            "affiliations": [
                "Southwestern Medical Center",
                "The University of Texas Southwestern Medical Center",
                "Southwestern Medical Center"
            ]
        },
        {
            "id": "https://openalex.org/A2972776848",
            "name": "Michael Dohopolski",
            "affiliations": [
                "Southwestern Medical Center",
                "The University of Texas Southwestern Medical Center",
                "Southwestern Medical Center"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2896442240",
        "https://openalex.org/W2990730188",
        "https://openalex.org/W4387744040",
        "https://openalex.org/W3022063204",
        "https://openalex.org/W4281557260",
        "https://openalex.org/W2116972869",
        "https://openalex.org/W2972984751",
        "https://openalex.org/W2142862978",
        "https://openalex.org/W2007419664",
        "https://openalex.org/W2975249097",
        "https://openalex.org/W2951591277",
        "https://openalex.org/W4367626167",
        "https://openalex.org/W4221161695",
        "https://openalex.org/W4321524373"
    ],
    "abstract": "Abstract Background Clinical trial matching, essential for advancing medical research, involves detailed screening of potential participants to ensure alignment with specific trial requirements. Research staff face challenges due to the high volume of eligible patients and the complexity of varying eligibility criteria. The traditional manual process, both time-consuming and error-prone, often leads to missed opportunities. Utilizing Artificial Intelligence (AI) and Natural Language Processing (NLP) can significantly enhance the accuracy and efficiency of this process through automated patient screening against established criteria. Methods Utilizing data from the National NLP Clinical Challenges (n2c2) 2018 Challenge, we utilized 202 longitudinal patient records. These records were annotated by medical professionals and evaluated against 13 selection criteria encompassing various health assessments. Our approach involved embedding medical documents into a vector database to determine relevant document sections, then using a large language model (GPT-3.5 Turbo and GPT-4 OpenAI API) in tandem with structured and chain-of-thought prompting techniques for systematic document assessment against the criteria. Misclassified criteria were also examined to identify classification challenges. Results This study achieved an accuracy of 0.81, sensitivity of 0.80, specificity of 0.82, and a micro F1 score of 0.79 using GPT-3.5 Turbo, and an accuracy of 0.87, sensitivity of 0.85, specificity of 0.89, and micro F1 score of 0.86 using GPT-4 Turbo. Notably, some criteria in the ground truth appeared mislabeled, an issue we couldn’t explore further due to insufficient label generation guidelines on the website. Conclusion Our findings underscore the significant potential of AI and NLP technologies, including large language models, in the clinical trial matching process. The study demonstrated strong capabilities in identifying eligible patients and minimizing false inclusions. Such automated systems promise to greatly alleviate the workload of research staff and improve clinical trial enrollment, thus accelerating the process and enhancing the overall feasibility of clinical research.",
    "full_text": "Utilizing Large Language Models for Enhanced Clinical Trial\nMatching: A Study on Automation in Patient Screening\nJacob Beattie, B.Sc.1, 2, Sarah Neufeld, MBA 1, Daniel Yang, M.D.1, 2, Christian\nChukwuma, B.Sc.1, Ahmed Gul, B.Sc. 1, Neil Desai, M.D. 1, Steve Jiang, Ph.D.1, 2, and\nMichael Dohopolski, M.D.1, 2\n1Department of Radiation Oncology, UT Southwestern Medical Center, Dallas, TX,\nUSA\n2Medical Artificial Intelligence and Automation Lab, UT Southwestern Medical\nCenter, Dallas, TX, USA\nApril 10, 2024\nAbstract\nBackground: Clinical trial matching, essential for advancing medical research, involves de-\ntailed screening of potential participants to ensure alignment with specific trial requirements.\nResearch staff face challenges due to the high volume of eligible patients and the complexity of\nvarying eligibility criteria. The traditional manual process, both time-consuming and error-prone,\noften leads to missed opportunities. Utilizing Artificial Intelligence (AI) and Natural Language\nProcessing (NLP) can significantly enhance the accuracy and efficiency of this process through\nautomated patient screening against established criteria.\nMethods: Utilizing data from the National NLP Clinical Challenges (n2c2) 2018 Challenge,\nwe utilized 202 longitudinal patient records. These records were annotated by medical professionals\nand evaluated against 13 selection criteria encompassing various health assessments. Our approach\ninvolved embedding medical documents into a vector database to determine relevant document\nsections, then using a large language model (GPT-3.5 Turbo and GPT-4 OpenAI API) in tandem\nwith structured and chain-of-thought prompting techniques for systematic document assessment\nagainst the criteria. Misclassified criteria were also examined to identify classification challenges.\nResults: This study achieved an accuracy of 0.81, sensitivity of 0.80, specificity of 0.82,\nand a micro F1 score of 0.79 using GPT-3.5 Turbo, and an accuracy of 0.87, sensitivity of 0.85,\nspecificity of 0.89, and micro F1 score of 0.86 using GPT-4 Turbo. Notably, some criteria in the\nground truth appeared mislabeled, an issue we couldn’t explore further due to insufficient label\ngeneration guidelines on the website.\nConclusion: Our findings underscore the significant potential of AI and NLP technologies,\nincluding large language models, in the clinical trial matching process. The study demonstrated\nstrong capabilities in identifying eligible patients and minimizing false inclusions. Such automated\nsystems promise to greatly alleviate the workload of research staff and improve clinical trial en-\nrollment, thus accelerating the process and enhancing the overall feasibility of clinical research.\n1\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n1 Introduction\nClinical trials are essential for advancing medical knowledge and introducing new treatment paradigms.\nHowever, many eligible patients miss out on participating in these trials due to a lack of discussion\nwith their treatment teams, a problem rooted in challenges, such as resource scarcity for patient\nscreening [1, 5]. Screening is often manual and inefficient, consuming up to 45 minutes per patient and\ncontributing to a 3-9 hour process for a single enrollment [12]. Physicians, nurses, and research staff\nhighlight time constraints and inadequate support as key obstacles [4, 6]. This situation contributes\nto low enrollment rates, leading to the premature closure of studies and limiting the scope of their\nfindings [13]. The advent of automated patient screening technologies offers a promising solution by\nfacilitating the identification of potential participants and alleviating the workload on research teams,\naiming to enhance patient recruitment efficiency and trial outcomes.\nEfforts to automate participant selection have shown promise. Applications that perform automatic\nmatching based on genetic biomarkers have seen relative success, and this workflow was able to perform\nin real-time with improved accuracy [3]. Natural language processing (NLP) has also been used to\nanalyze unstructured data sources like clinical notes. In combination with additional structured data,\nresults from 2015 showed that these techniques could significantly reduce the patient-trial matching\nworkload [8]. However, these approaches have substantial limitations. Methods relying on information\nextraction techniques fail to interpret semantic relations correctly [8], and several of these older, existing\nmethods that process free text still require manual preprocessing from domain experts [3]. These\nbarriers may prevent a large-scale implementation across a hospital system as they fail to work across\nall types of criteria or do not fully address clinical research staff shortages.\nIn recent advancements, NLP techniques and large language models (LLMs) have significantly\nevolved, showing great potential in transforming clinical trial eligibility screening. The screening\nprocess, inherently reliant on interpreting extensive unstructured text, finds a promising solution in\nNLP and LLMs due to their advanced reasoning and semantic understanding capabilities [19]. Despite\ntheir promise, the comprehensive application and in-depth evaluation of LLMs, including GPT-3.5\nTurbo [10], GPT-4 [11], and Llama2 [15], for clinical trial patient screening have been sparse [21].\nOur research aims to bridge this gap by employing state-of-the-art LLMs to directly analyze un-\nstructured clinical data, thereby accurately determining patient eligibility for clinical trials. Through\nthis endeavor, we aspire to significantly enhance the efficiency and accuracy of identifying eligible trial\nparticipants.\n2 Methods\n2.1 Data\nWe utilized the Harvard University National NLP Clinical Challenges (n2c2) 2018 cohort selection\nchallenge dataset. This dataset comprises 288 longitudinal patient records and information regarding\n13 selection criteria. These criteria include drug abuse, alcohol abuse, English proficiency, decision-\nmaking capacity, history of intra-abdominal surgery, major diabetes-related complications, advanced\ncardiovascular disease, dietary supplement intake in the past two months (excluding Vitamin D),\ndiagnosis of ketoacidosis in the past year, aspirin use for myocardial infarction prevention, HbA1C\nvalues outside the 6.5%-9.5% range, abnormal creatinine levels, and myocardial infarction occurrence\nwithin the past six months. Each patient record was annotated by two medical experts, with any\ndiscrepancies resolved through adjudication by a researcher in consultation with a physician. [14].\nOf the 288 patient records in the n2c2 2018 challenge dataset, 202 were made publicly available for\ntraining. We utilized 20 patient records for prompt engineering, while the 182 remaining records were\nreserved for testing.\n2.2 Indexing and Document Transformation\nTo analyze patient records against specific criteria, we employed GPT-3.5 Turbo and GPT-4, mindful\nof their context length limits of 16,385 and 32,768 tokens, respectively. This limitation necessitated\nthe careful selection of the most pertinent segments from a patient’s Electronic Health Record (EHR),\nas the full EHR could not be directly processed.\n2\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \nFigure 1: Data indexing process.\n Figure 2: Eligibility screening process for a single\npatient on a single criterion.\nInitially, we transformed the patient EHR documents into a format suitable for querying. Us-\ning LlamaIndex, documents were indexed by first partitioning each into 1024-token sections with a\n10% overlap to ensure contextual continuity—a process known as chunking. These chunks were then\nembedded into a vector database using OpenAI’s ada-002 embedding model, creating vector represen-\ntations for similarity search and retrieval. The embedded chunks and their original text were stored\nas key-value pairs in a database, facilitating the identification of the top- k chunks most semantically\nsimilar to a given query’s embedding.\n2.3 Retrieval-Augmented Generation (RAG) with LlamaIndex\nLlamaIndex enhanced GPT-3.5 Turbo and GPT-4’s accuracy by providing targeted context (EHR text\nchunks) through Retrieval-Augmented Generation (RAG). We created a retrieval system that selects\nthe top-k relevant text passages for a given query. For each criterion, we set k = 5 and used the LLM\nprompt as the document retrieval search query. This process yielded the five most relevant chunks of\nthe patient’s EHR.\n2.4 Criteria Eligibility Analysis\nThe relevant EHR portions obtained were appended to the prompt, and GPT-3.5 Turbo was then\napplied to predict the criteria eligibility status. After processing all five relevant chunks, the final\nresponse was saved for analysis. This iterative process of retrieving context and applying the LLM\nto the prompt/context combination was repeated for each criterion for each patient, culminating in a\ncomprehensive automated eligibility screening depicted in Figures 1 and 2.\n2.5 Prompt Engineering\nIn our approach, we leveraged the principles of zero-shot learning with GPT-3.5 Turbo and GPT-4,\napplying a dynamic prompting strategy to evaluate patient eligibility for clinical trials from the n2c2\ndataset[20, 7]. This strategy utilized a general template, customized with criterion-specific expert guid-\nance and relevant excerpts from patient records to generate tailored prompts for each case (Figure 3).\nThis method combines the zero-shot learning capability of making classifications without direct prior\nexamples of the task with the adaptability of customized prompts, ensuring accuracy and relevance in\na clinical context.\nThe prompt engineering process began with two foundational templates outlining the structure of\nthe inquiry to the LLM: one focused on producing a structured JSON output, and the other focused\non producing chain-of-thought (CoT) reasoning. This template was enriched with expert-generated\ntips to add in targeted patient data retrieval, creating a unique prompt for each eligibility criterion.\n3\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \nRole: Clinical Trial Patient Screener\nTasks: Manually review the medical documents (delimited following ) below to determine if the\nspecified criteria (delimited by ***) for a clinical trial are met. Review the helpful tips keywords/phrases\n(delimited by ###) for help identifying the pertinent data, which may aid in assessing if the criteria\nare met. Additionally, identify which information in the medical documents was used to determine if the\ncriteria were met. Alternatively, if criteria were not met, specify why and add uncertain areas. It is not a\ncomprehensive guide, so you must still use your best judgment. Follow the format instructions (delimited\nby ===) for reporting your findings. Again, only use the information delimited following\n.\nCriteria: ***ASP-FOR-MI Use of aspirin to prevent myocardial infarction***\nHelpful tips: ###Strategies:\n1. Examine the medication list for aspirin; if asa or aspirin is mentioned, it is likely for MI prevention.\nTherefore, the criteria is met.\nKeywords/Phrases: Aspirin therapy, Low-dose aspirin, aspirin 81, asa 81, Baby aspirin, aspirin 325,\nAspirin regimen, ASA (Acetylsalicylic Acid), Coated aspirin###\nreporting format: ===...===\nDocuments:\n...\nFigure 3: Example prompt for producing JSON output using manually created expert guidance\nTo fully automate the screening process, we also created a set of LLM-generated prompts to provide\nguidance; we used GPT-4 to create criteria descriptions and instructions. These LLM-generated tips\nconsist of vocabulary commonly associated with the criteria being met or not met, emulating rule-\nbased approaches used by the winning team of the original n2c2 challenge [9]. Full prompts for both\nJSON and CoT output, as well as examples of manual and LLM-created expert tips, can be found in\nAppendix A.\nThrough iterative testing with a subset of 20 patients, we identified and addressed discrepancies\nbetween the LLM’s outputs and the ground truth, refining the manually-created expert guidance and\nprompt templates. This iterative cycle of customization and evaluation continued until we achieved\nsignificant accuracy and micro F1 improvements, defined as 0.85, as this was the competitive per-\nformance in the n2c2 competition. The two prompting structures were applied to the n2c2 dataset,\nand their performance was compared. These optimized prompts, embodying the refined integration of\nexpert guidance and patient-specific information, were subsequently applied across the entire dataset.\nThis approach not only harnessed the power of zero-shot learning for efficient patient screening but also\nenhanced it through tailored prompts, striking a balance between the flexibility of zero-shot learning\nand the precision needed for clinical applicability.\n2.6 Analyses\nWe assessed our model’s performance using accuracy, recall, precision, specificity, and micro F1 metrics\nacross all criteria and patients. Individual criteria were analyzed to highlight specific classification\nchallenges. Our results were benchmarked against the leading teams from the 2018 n2c2 competition\nto evaluate our standing.\nIn understanding our model’s limitations, we analyzed misclassifications (false negatives and false\npositives) by reviewing the LLM’s generated rationales and cross-referencing them with patient charts.\nThis process aimed to identify common error patterns and underlying reasons for inaccuracies, inform-\ning future model improvements.\n4\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \n3 Results\nIn our testing encompassing 2366 criteria from 182 patient EHRs from the n2c2 dataset using GPT-\n3.5 Turbo, we achieved an overall accuracy of 0.81, sensitivity of 0.80, specificity of 0.82, and micro\nF1 of 0.79. For GPT-3.5 Turbo, the best-performing approach utilized structured JSON output and\nmanually created expert guidance. Additionally, we tested our approach on a smaller subset of data\n(40 patients) due to cost limitations, using GPT-4. Here, we observed an accuracy of 0.87, sensitivity\nof 0.85, specificity of 0.89, and micro F1 score of 0.86. Here, the best-performing approach again\nutilized structured JSON output and manually created expert guidance. This model’s performance\nacross each criterion is listed in table3. Our approach processes a single patient for all included criteria\nin 1-5 minutes. Variability was due to GPT3.5 and 4 resource allocations during experimentation.\nPrompting Format Accuracy Sensitivity Specificity Precision Micro F1\nStructured output + manual expert guidance 0.8081 0.7988 0.8154 0.7721 0.7852\nStructured output + LLM-generated expert guidance 0.6593 0.6006 0.7054 0.6148 0.6076\nCoT output + manual expert guidance 0.7747 0.6064 0.9066 0.8355 0.7027\nCoT output + LLM-generated expert guidance 0.6416 0.3367 0.8802 0.6876 0.4522\nTable 1: GPT-3.5 Turbo results when applied to test data (182 patients)\nPrompting Format Accuracy Sensitivity Specificity Precision Micro F1\nStructured output + manual expert guidance 0.8692 0.8449 0.8909 0.8734 0.8589\nStructured output + LLM-generated expert guidance 0.7712 0.6490 0.8800 0.8281 0.7277\nCoT output + manual expert guidance 0.8558 0.8694 0.8436 0.8320 0.8503\nCoT output + LLM-generated expert guidance 0.8519 0.8571 0.8473 0.8333 0.8451\nTable 2: GPT-4 results when applied to a subset of test data (40 patients)\n3.1 Failure Analysis\nWe performed a thorough failure analysis of the best-performing approach, GPT-4, with structured\nJSON output and manually created expert guidance. The analysis pinpointed four criteria—\nDIETSUPP-2MOS, ADVANCED-CAD, and MI-6MOS —with significantly low accuracy rates, with\nMI-6MOS exhibiting the poorest performance at an accuracy of only 0.65. For MI-6MOS, this sub-\noptimal performance primarily resulted from the LLM’s improper reasoning about dates, leading to\nseveral false positives where the LLM recognized myocardial infractions outside of the past six months.\nThe same improper temporal reasoning led to poor performance in DIETSUPP-2MOS, where the LLM\ncategorized patients as meeting the criteria based on dietary supplements they had taken at one point\nbut not within the past two months. For ADVANCED-CAD, the issue was much more nuanced; the\nLLM correctly identified certain relevant information as per the guidance provided, but the patient\ndid not completely fit all the criteria.\nAmong all criteria, we observed two prominent types of failures. First, several false negatives were\nattributed to insufficient document retrieval, where the LLM did not correctly classify a patient as\nmeeting a criterion because no relevant context was provided. Finally, when using GPT-3.5 Turbo, we\nobserved cases of hallucination, with the LLM citing evidence that was either not present or found in\nthe prompt rather than the patient documents. Such hallucinations were observed at a far lower rate\nin results using GPT-4. For detailed instances of each type of error, see Appendix A.\n5\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \nCriteria Accuracy Sensitivity Specificity Precision Micro F1\nDRUG-ABUSE 0.98 0.75 1 1 0.86\nALCOHOL-ABUSE 0.98 1 0.97 0.67 0.80\nENGLISH 1 1 1 1 1\nMAKES-DECISIONS 0.93 0.92 1 1 0.96\nABDOMINAL 0.88 0.71 1 1 0.96\nMAJOR-DIABETES 0.83 0.86 0.78 0.83 0.84\nADVANCED-CAD 0.78 1 0 0.78 0.87\nDIETSUPP-2MOS 0.70 0.47 0.90 0.82 0.60\nKETO-1YR 1 0 1 0 0\nASP-FOR-MI 0.88 0.86 1 1 0.93\nHBA1C 0.88 0.58 1 1 0.74\nCREATININE 0.85 0.71 0.96 0.92 0.80\nMI-6MOS 0.65 0.83 0.62 0.28 0.42\nOverall 0.87 0.84 0.89 0.87 0.86\nTable 3: GPT-4 results when utilizing structured JSON output and manually-created expert guidance.\n4 Discussion\nIn this study, we have shown that OpenAI’s GPT-3.5 Turbo and GPT-4 offer remarkable zero-shot\ncapabilities for clinical trial eligibility screening, achieving an accuracy of 0.81 and 0.87, respectively,\nboth using the structured output and manually-created expert guidance. Our methodology stands\nout for its user-friendly approach and efficiency, significantly enhancing both aspects compared to\ntraditional screening methods [3, 8]. This improvement is marked by an innovative blend of information\nretrieval and prompting techniques, allowing clinical research staff to utilize natural language for\nscreening criteria fully. This method not only simplifies the screening process, which is predominantly\nmanual in many clinical settings [4], but also drastically reduces the time required for screening from\nhours to less than a minute per patient, offering a substantial efficiency gain.\nIn the 2018 n2c2 challenge, the Medical University of Graz achieved top results with a micro F1\nscore of 0.91 [14], using a rule-based system reliant on regular expressions and textual markers [9].\nThe University of Michigan utilized pattern-based, knowledge-intensive methods to achieve a micro\nF1 score as high as 0.91 [16], placing second in the original 2018 challenge [14]. However, these\nmethods require significant manual effort, with manual annotation and analysis of 202 patient records\nenabling such high performance. Furthermore, these approaches necessitate complex technical tools for\nanalyzing natural language, posing a barrier to clinical use. These requirements dramatically limit the\naccessibility and adaptability of this approach. In contrast, our GPT-3.5 Turbo and GPT-4 approaches\noffer a more user-friendly and flexible solution capable of interpreting patient data in any supported\nlanguage without extensive setup or maintenance. Utilizing 10% of available patient records, little\nto no manual analysis, and little to no technical knowledge from end-users, we achieved competitive\nresults. This adaptability significantly broadens the approach’s application and eases the workload for\nclinical research teams, highlighting the LLMs’ potential to make clinical trial screening more efficient\nand inclusive.\nOur study marks a significant advancement in applying LLMs, particularly GPT-3.5 Turbo and\nGPT-4, directly facilitating automatic eligibility screening for clinical trials. This approach represents\na departure from existing methods, which either rely on rule-based systems with inherent limitations in\nflexibility and user-friendliness or necessitate manual preprocessing and struggle to interpret complex\nsemantic relationships in clinical data [3, 8]. Unlike previous efforts that utilized LLMs to generate\n6\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \nsupplemental descriptions for NLP-based models [21], our method leverages LLMs’ advanced seman-\ntic analysis capabilities to process unstructured clinical notes directly. This eliminates the need for\nmanual rule definition, preprocessing steps, and additional model training, significantly reducing the\noperational burden on clinical research staff.\nBy employing LLMs as the primary engine for screening, we introduce a solution that is more\nefficient, adaptable, scalable across different clinical contexts. GPT-3.5 Turbo and GPT-4’s ability\nto autonomously identify and interpret pertinent information from raw clinical notes streamlines the\nscreening workflow, ensuring contextually aware evaluations without the extensive technical expertise\nrequired by traditional methods. This innovation underscores the practical benefits of LLMs in clinical\ntrial screenings, enhancing the process’s efficiency and accuracy while offering a scalable and user-\nfriendly tool for clinical research teams.\nOur approach, while advancing the use of LLMs in clinical trial eligibility screening, has several\nlimitations, including variability in performance across different criteria, particularly with those that\nare time-sensitive or necessitate multiple requirements to be met. Additionally, the propensity of LLMs\nto generate incorrect evidence, known as hallucinations, poses a challenge to achieving consistent and\nreliable results. These issues highlight the need for further refinement to enhance trust and applicability\nin clinical settings. To address these challenges, we propose several avenues for improvement. Enhanced\nprompt engineering techniques, including the adoption of few-shot prompting, offer promising paths\nto bolster LLM performance directly [17, 2, 19]. Furthermore, leveraging these prompt engineering\ntechniques when creating LLM-generated expert guidance could potentially increase the screening\nprocess’s accuracy. Experimenting with sampling answers from the LLM to ensure decision certainty\nand expanding our method’s testing across diverse clinical datasets will also be critical in identifying\nand mitigating weaknesses [18]. Finally, recent developments provide a potential path for customizing\nprompts on a per-criteria basis automatically, further increasing performance and ease-of-use [22]. As\nwe refine our approach, our goal remains to balance accuracy with usability, providing clinical research\nteams with powerful, easy-to-implement tools to revolutionize patient screening processes.\n5 Conclusions\nIn our study, we leveraged the advanced capabilities of GPT-3.5 Turbo and GPT-4, combined with doc-\nument retrieval technologies, to innovate patient eligibility screening for clinical trials. This approach,\nutilizing dynamically generated prompts based on expert guidance and raw clinical data, significantly\nminimizes manual intervention while offering extensive adaptability across medical disciplines. With\nits promise for scalability and ease of implementation, our method opens new avenues for enhancing\nthe efficiency and effectiveness of clinical trial screenings.\n7\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \nReferences\n[1] Anderson, A., Borfitz, D., and Getz, K. Global public attitudes about clinical research\nand patient experiences with clinical trials. JAMA Network Open 1, 6 (2018), e182969.\n[2] Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Nee-\nlakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A.,\nKrueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Win-\nter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J.,\nBerner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. Language\nmodels are few-shot learners. In Proceedings of the 34th International Conference on Neural\nInformation Processing Systems(Red Hook, NY, USA, 2020), NIPS’20, Curran Associates Inc.\n[3] Chen, J. W., Kunder, C. A., Bui, N., Zehnder, J. L., Costa, H. A., and Stehr, H.\nIncreasing clinical trial accrual via automated matching of biomarker criteria. In Biocomputing\n2020 (2019), WORLD SCIENTIFIC, pp. 31–42.\n[4] Durden, K., Hurley, P., Butler, D. L., Farner, A., Shriver, S. P., and Fleury,\nM. E. Provider motivations and barriers to cancer clinical trial screening, referral, and operations:\nFindings from a survey. Cancer 130, 1 (2023), 68–76.\n[5] for Information, C., and on Clinical Research, S. General perceptions. Tech. rep.,\nCenter for Information and Study on Clinical Research Participation, 2021.\n[6] Knelson, L. P., Cukras, A. R., Savoie, J., Agarwal, A., Guo, H., Hu, J., Fell, G.,\nLederman, R., Hughes, M. E., Winer, E. P., Lin, N. U., and Tolaney, S. M. Barriers\nto clinical trial accrual: Perspectives of community-based providers. Clinical Breast Cancer 20, 5\n(2020), 395–401.e3.\n[7] Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. Large language models are\nzero-shot reasoners. In Advances in Neural Information Processing Systems(2022), S. Koyejo,\nS. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, Eds., vol. 35, Curran Associates, Inc.,\npp. 22199–22213.\n[8] Ni, Y., Wright, J., Perentesis, J., Lingren, T., Deleger, L., Kaiser, M., Kohane,\nI., and Solti, I. Increasing the efficiency of trial-patient matching: automated clinical trial\neligibility pre-screening for pediatric oncology patients. BMC Medical Informatics and Decision\nMaking 15, 1 (2015), 28.\n[9] Oleynik, M., Kugic, A., Kas ´aˇc, Z., and Kreuzthaler, M. Evaluating shallow and deep\nlearning strategies for the 2018 n2c2 shared task on clinical text classification. Journal of the\nAmerican Medical Informatics Association 26, 11 (2019), 1247–1254.\n[10] OpenAI. Introducing ChatGPT. Tech. rep., OpenAI, 2022.\n[11] OpenAI. GPT-4 technical report. Tech. rep., OpenAI, 2023. Publisher: arXiv Version Number:\n4.\n[12] Penberthy, L. T., Dahman, B. A., Petkov, V. I., and DeShazo, J. P. Effort required in\neligibility screening for clinical trials. Journal of Oncology Practice 8, 6 (2012), 365–370.\n[13] Stensland, K. D., McBride, R. B., Latif, A., Wisnivesky, J., Hendricks, R., Roper,\nN., Boffetta, P., Hall, S. J., Oh, W. K., and Galsky, M. D. Adult cancer clinical trials\nthat fail to complete: An epidemic? JNCI: Journal of the National Cancer Institute 106, 9 (2014).\n[14] Stubbs, A., Filannino, M., Soysal, E., Henry, S., and Uzuner, ¨O. Cohort selection\nfor clinical trials: n2c2 2018 shared task track 1. Journal of the American Medical Informatics\nAssociation 26, 11 (2019), 1163–1171.\n8\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \n[15] Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bash-\nlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer,\nC. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., Fuller,\nB., Gao, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini, S., Hou, R., Inan,\nH., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I., Korenev, A., Koura, P. S.,\nLachaux, M.-A., Lavril, T., Lee, J., Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mi-\nhaylov, T., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta,\nR., Saladi, K., Schelten, A., Silva, R., Smith, E. M., Subramanian, R., Tan, X. E.,\nTang, B., Taylor, R., Williams, A., Kuan, J. X., Xu, P., Yan, Z., Zarov, I., Zhang,\nY., Fan, A., Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S., and\nScialom, T. Llama 2: Open foundation and fine-tuned chat models. arXiv (2023). Publisher:\narXiv Version Number: 2.\n[16] Vydiswaran, V. G. V., Strayhorn, A., Zhao, X., Robinson, P., Agarwal, M., Bagazin-\nski, E., Essiet, M., Iott, B. E., Joo, H., Ko, P., Lee, D., Lu, J. X., Liu, J., Murali, A.,\nSasagawa, K., Wang, T., and Yuan, N. Hybrid bag of approaches to characterize selection\ncriteria for cohort identification. Journal of the American Medical Informatics Association 26, 11\n(2019), 1172–1180.\n[17] Wang, J., Shi, E., Yu, S., Wu, Z., Ma, C., Dai, H., Yang, Q., Kang, Y., Wu, J., Hu,\nH., Yue, C., Zhang, H., Liu, Y., Li, X., Ge, B., Zhu, D., Yuan, Y., Shen, D., Liu, T.,\nand Zhang, S. Prompt engineering for healthcare: Methodologies and applications, 2023.\n[18] Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., and\nZhou, D. Self-consistency improves chain of thought reasoning in language models.\n[19] Wei, J., Wang, X., Schuurmans, D., Bosma, M., ichter, b., Xia, F., Chi, E., Le,\nQ. V., and Zhou, D. Chain-of-thought prompting elicits reasoning in large language models. In\nAdvances in Neural Information Processing Systems(2022), S. Koyejo, S. Mohamed, A. Agarwal,\nD. Belgrave, K. Cho, and A. Oh, Eds., vol. 35, Curran Associates, Inc., pp. 24824–24837.\n[20] Wei, X., Cui, X., Cheng, N., Wang, X., Zhang, X., Huang, S., Xie, P., Xu, J., Chen,\nY., Zhang, M., Jiang, Y., and Han, W. Zero-shot information extraction via chatting with\nchatgpt, 2023.\n[21] Yuan, J., Tang, R., Jiang, X., and Hu, X. Large language models for healthcare data\naugmentation: An example on patient-trial matching. arXiv (2023). Publisher: arXiv Version\nNumber: 2.\n[22] Zhou, P., Pujara, J., Ren, X., Chen, X., Cheng, H.-T., Le, Q. V., Chi, E. H., Zhou,\nD., Mishra, S., and Zheng, H. S. Self-discover: Large language models self-compose reasoning\nstructures. arXiv (2024). Publisher: arXiv Version Number: 1.\n9\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \nA Prompting\nA.1 Structured Output\nTo induce a structured output, we use Pydantic, a data validation library for Python. This allows us to\ngenerate a set of formatting instructions automatically. This guides the LLM to produce its output as a\nJSON object, allowing for easy parsing. As the criteria description, the description and name provided\nin the original n2c2 challenge were used without modification. The full prompt structure can be seen\nin Figure 4. The output will be provided as a JSON object with keys ”criteria\nname”, ”support”,\nand ”criteria”, representing the criteria label, cited evidence, and met/not met status respectively.\nRole : Clinical Trial Patient Screener\nTasks : Manually review the medical documents ( delimited following ___ ) below to\ndetermine if the specified criteria ( delimited by ***) for a clinical trial are met\n. Review the helpful tips ( delimited by ###) for identifying the pertinent data\nthat may help aid screening . It is not a comprehensive guide , so you will still\nneed to use your best judgment ; the keywords and phrases can also help . Follow the\nformat instructions ( delimited by ===) for reporting your findings .\nCriteria : ***...***\nHelpful tips : ###...###\nReporting format : === The output should be formatted as a JSON instance that conforms\nto the JSON schema below .\nAs an example , for the schema {\" properties \": {\" foo \": {\" title \": \" Foo \", \" description \": \"\na list of strings \", \" type \": \" array \", \" items \": {\" type \": \" string \"}}} , \" required \": [\"\nfoo \"]} the object {\" foo \": [\" bar \", \" baz \"]} is a well - formatted instance of the\nschema . The object {\" properties \": {\" foo \": [\" bar \", \" baz \"]}} is not well - formatted .\nHere is the output schema :\n‘‘‘\n{\" properties \": {\" criteria_name \": {\" description \": \" Name of criteria \", \" title \": \"\nCriteria Name \", \" type \": \" string \"} , \" support \": {\" description \": \" include the\ninformation that supports if criteria is met or not ,\" , \" title \": \" Support \", \" type \":\n\" string \"} , \" criteria \": {\" description \": \" Evaluating if an individual criterion is\nmet after reviewing the medical document . Output should be True or False \", \" title \":\n\" Criteria \", \" type \": \" string \"}} , \" required \": [\" criteria_name \", \" support \", \" criteria\n\"]}\n‘‘‘ ===\nDocuments :\n___\n...\nFigure 4: Example prompt for producing structured JSON output\nA.2 Chain-of-thought (CoT) Output\nDue to the potential accuracy benefits of inducing CoT reasoning from a LLM, we use a prompt\nstructure that utilizes CoT reasoning. The LLM is prompted to decide, think step-by-step, and\nprovide its thought process. Then, the LLM is asked to use this reasoning to categorize a criterion as\n”met” or ”not met.” In this prompt structure, the n2c2 criteria titles are not included, only the criteria\ndescription. The full, prompt structure for ASP-FOR-MI can be seen in Figure 5. The output is not\nstructured naturally but is saved into a JSON object with the same format as the structured prompt\nresults for easy analysis.\n10\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \nRole : Clinical Trial Patient Screener\nYou are a clinical trial eligibility screener . You have expert medical knowledge and\ncan make definitive judgments on whether criteria are met or not . Specifically , you\nwill be screening for the following criterion :\nCriteria : ***...***\nYou will be given a set of documents from a patient ’s health record . Manually review\nthe medical documents to determine if the above criterion is met or not met . Follow\nthis process when screening for the above criteria :\n1. Extract evidence from the medical record to determine if the criterion is met . Use\nthe tips below :\n---...---\n2. Think step -by - step . Identify which information in the medical documents was used to\ndetermine if the criterion is met . Alternatively , if the criterion was not met ,\nspecify why and list uncertain areas . Quote sections of the medical record that\nsupport your decision . Assume that the patient is average and able - bodied unless\nstated otherwise . Consider all documents at once , and should any single document\nshow a criterion that is met , then the criterion is met for the patient . Make a\ndefinitive choice , and state clearly if the criterion is met or not .\nTake a deep breath and analyze the documents below :\n___\n...\nFigure 5: Example prompt for producing CoT reasoning\nA.3 Manual Expert Guidance\nThrough fine-tuning over 20 patient records, we created a set of expert tips to assist the LLM in\nthe screening process. These tips are inserted directly into the prompt, guiding how to go about the\nscreening process and relevant keywords and phrases. The full, manually created tips for all criteria\nare listed below.\nDRUG - ABUSE :\nStrategies :\n1. Review the social , past medical , and family sections for illicit drug use .\n2. Look for rehab , detox , or addiction - related interventions .\n3. Check for addiction management meds or multiple controlled substance prescriptions .\n4. Scan for overdoses , withdrawal symptoms , or drug - linked incidents .\n5. Review drug screenings or relevant toxicology results .\n6. Check for counseling on drug use risks or medication misuse .\nKeywords / Phrases :\nOpioids : Heroin , Fentanyl , Oxycodone .\nStimulants : Cocaine , Methamphetamine .\nDepressants : Benzodiazepines (e.g., Xanax ), Barbiturates .\nHallucinogens : LSD , PCP .\nCannabinoids : Marijuana , THC .\nClub Drugs : MDMA , GHB .\nOthers : Inhalants , Steroids , Prescription med abuse .\nALCOHOL - ABUSE :\nStrategies :\nFemale : No more than 1 drink in a single day and no more than 7 drinks per week . Male :\nNo more than 2 drinks in a single day and no more than 14 drinks per week\n1. Review clinical notes for mentions of alcohol intake frequency , quantity , or\npatterns .\n2. Check for records of discussions , interventions , or counseling sessions\nspecifically addressing alcohol consumption .\n11\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \n3. Look for physical signs often associated with excessive alcohol use , such as facial\nflushing , broken blood vessels on the face , or palmar erythema .\n4. Monitor liver function tests , GGT levels , and any imaging results revealing liver\nchanges or damage .\nKeywords / Phrases :\nDrinking Patterns : Social drinking , Heavy drinking , Daily drinking , Morning drinking .\nLiver Issues : Fatty liver , Alcoholic liver disease , Ascites , Jaundice .\nIntervention : AA ( Alcoholics Anonymous ), Counseling , Alcohol cessation .\nComplications : Withdrawal symptoms , Delirium tremens , Gastritis , Esophageal varices .\nBehavioral Indicators : Blackouts , Alcohol - related accidents , DUIs .\nENGLISH :\nStrategies :\n1. Check if translation was needed during visits .\n2. If not specified , assume English - speaking . ie default answer is True .\nKeywords / Phrases :\nEnglish proficiency , non - English speaking , Interpreter used , Fluent in English , ESL .\nMAKES - DECISIONS :\nStrategies :\n1. If a child , assume cant make their own decisions\n2. Review notes on cognitive function and decision - making capacity , if they have\nlimited cognitive funtion or capacity then likely cant make decisions .\n3. If medical decision - making is not specified , assume the patient makes their own\ndecisions . ie default answer is True .\nKeywords / Phrases :\nChild , Guardian , Legal guardian , Power of attorney .\nABDOMINAL :\nStrategies :\n1. If any of the following surgeries are mentioned in Keywords / Phrases , then the\ncriterion is met .\n2. If no surgeries are mentioned , then the criterion is not met . ie answer is False .\n3. If minor surgery like cardiac catheterization or stent placement is mentioned , then\nthe criteria are not met . ie answer is False .\n4. Surgeries in the chest , neck , head , eyes , legs , or arms are not considered\nabdominal surgeries . ie answer is False .\n5. bypass grafts , angioplasty , and stent placement are not considered abdominal\nsurgeries . ie answer is False .\nKeywords / Phrases :\nLaparotomy , Bowel resection , Colectomy , Enterectomy , Abdominal surgery , Hernia repair ,\nCholecystectomy ( gallbladder removal ), Appendectomy ( appendix removal ),\nGastrectomy ( stomach removal ), Splenectomy ( spleen removal ), Pancreatectomy (\npancreas surgery ), Cystectomy ( bladder removal ), Nephrectomy ( kidney removal ),\nLysis of adhesions , bowel obstruction , ileus .\nMAJOR - DIABETES\nStrategies :\nFirst , the patient must have a history of diabetes , then review for any of the\nfollowing complications .\n1. Review for any signs of foot complications often seen in diabetes , like ulcers ,\nneuropathy , amputation , or poor circulation . If the patient has diabetes and foot\ncomplications , then the criterion is met .\n2. Review for signs of retinopathy , optic neuropathy , macular edema , or other vision\nissues related to diabetes . If the patient has diabetes and vision issues , then the\ncriterion is met . Cataracts alone do not meet the criterion\n3. Review for signs of kidney damage or nephropathy , like chronic kidney disease ,\nelevated Creatinine , and dialysis . If the patient has diabetes and related kidney\ndisease , then the criterion is met .\n4. Diabetic skin conditions , including diabetic dermopathy , necrobiosis , lipoidica ,\ndiabeticorum , and ulcers . If the patient has diabetes and similar diabetes - related\n12\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \nskin issues , then the criterion is met .\nKeywords / Phrases :\nDiabetic foot ulcer , Retinal damage , Neuropathy , optic neuropathy , Nephropathy ,\nDiabetic kidney disease , Peripheral artery disease , Diabetic macular edema ,\nPeripheral neuropathy , Autonomic neuropathy , skin ulcer , chronic kidney disease ,\nCKD , sacral ulcer , decubitus ulcer , foot ulcer , toe ulcer .\nADVANCED - CAD\nStrategies :\nThe patient does not need to match all but just one of the following criteria . Also ,\nnote that this is not a comprehensive strategy , so it is to use the best judgment .\n1. Review these for a history of CAD , angina , or other heart - related issues . If\nmentioned , then the criterion is met .\n2. Scan for multiple CAD - related medications . Two or more key medications for CAD ,\nsuch as beta - blockers , calcium channel blockers , or antiplatelet agents ( like\nPlavix , but excluding aspirin ). If mentioned , then the criteria are met .\n3. Examine results from tests like angiograms , echocardiograms , cardiac\ncatheterization , and stress tests for signs of ischemia or damaged heart tissue . If\nmentioned , then the criteria are met .\n4. Look out for any stent / placements . If mentioned , then the criterion is met\nKeywords / Phrases :\nMyocardial infarction , Stable / unstable angina , Ischemic heart disease , Coronary artery\nstents , CAD , congestive heart failure , CHF , Coronary artery bypass graft ( CABG ),\nAngioplasty , Nitroglycerin , Beta - blockers , Calcium channel blockers , Plavix , Chest\ndiscomfort , Echocardiogram findings , cardiac catheterization .\nDrugs that could be mentioned include Aspirin , Clopidogrel ( Plavix ), Ticagrelor (\nBrilinta ), Prasugrel ( Effient ), Warfarin ( Coumadin ), Rivaroxaban ( Xarelto ),\nApixaban ( Eliquis ), Metoprolol ( Lopressor , Toprol XL), Atenolol ( Tenormin ),\nBisoprolol ( Zebeta ), Carvedilol ( Coreg ), Amlodipine ( Norvasc ), Diltiazem ( Cardizem ,\nTiazac ), Verapamil ( Calan , Verelan ), Nifedipine ( Adalat CC , Procardia ),\nNitroglycerin ( Nitrostat , Nitro - Dur ), Isosorbide dinitrate ( Isordil ), Isosorbide\nmononitrate , Atorvastatin ( Lipitor ), Simvastatin ( Zocor ), Rosuvastatin ( Crestor ),\nPravastatin ( Pravachol ), Lisinopril ( Zestril , Prinivil ), Enalapril ( Vasotec ),\nRamipril ( Altace ), Losartan ( Cozaar ), Valsartan ( Diovan ), Spironolactone ( Aldactone\n), Eplerenone ( Inspra ), Ranolazine ( Ranexa ), Digoxin ( Lanoxin ), and Ivabradine (\nCorlanor ).\nDIETSUPP -2 MOS\nStrategies :\n1. Review the medical documents for items listed that match the keywords / phrases below\n. If so , the criteria is met .\n2. Consider extracting all the medications , then do a step -by - step comparison to the\nkeywords / phrases below . If any match , then the criterion is met .\nKeywords / Phrases : Not a comprehensive list , so can use your judgment but the list\nincludes -\nDietary supplement , Herbal supplement , Multivitamins , Over -the - counter , OTC , Minerals ,\ncalcium , vit e, vit a, vitamin e, vitamin a, Amino acids , Probiotics , Fish oil ,\nOmega -3 , Herbal tea , Natural remedy , Supplement brand names (e.g., Centrum , Nature ’\ns Bounty ). Coenzyme Q10 , Turmeric / Curcumin , Glucosamine , Chondroitin , Biotin ,\nMelatonin , Zinc , Magnesium , Green tea extract , Echinacea , Ginkgo biloba , St. John ’s\nwort , Ginseng , Flaxseed oil , Whey protein , Collagen , Fiber supplements , Lysine ,\nand brand names such as NOW Foods , Garden of Life , and Solgar in your list of\nsupplements . Ashwagandha , Saw Palmetto , Milk Thistle , Elderberry , Cranberry , Lutein\n, Selenium , Iron , Folate , B- complex vitamins , L- theanine , Creatine , Resveratrol ,\nMoringa , Maca root , Valerian root , Rhodiola , SAM -e, BCAAs ( Branched - Chain Amino\nAcids ), Calcium , L- carnitine , green tea , ginger , Chromium , Iodine , Potassium ,\nSpirulina , Bee pollen , Propolis , and brand names such as Pure Encapsulations ,\nJarrow Formulas , and Bluebonnet Nutrition .\nKETO -1 YR\nStrategies :\n13\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \n1. Look for any visits related to diabetic crises , with a particular focus on episodes\ncharacterized by severe hyperglycemia or the presence of ketones .\n2. Examine the clinical presentation , such as dehydration or altered consciousness ,\nwhich might indicate ketoacidosis .\n3. Look for any mentions of insulin non - compliance or instances where insulin might\nhave been omitted intentionally or unintentionally .\nKeywords / Phrases :\nKetoacidosis , Diabetic ketoacidosis ( DKA ), Hyperglycemic crisis , Blood ketones ,\nMetabolic acidosis , Blood gas analysis , Ketonuria , kussmaul respiration , insulin\nnon compliance\nASP -FOR -MI\nStrategies :\n1. Examine the medical documents for mention of aspirin , If asa or aspirin is\nmentioned it is likely it is for MI prevention . Therefore , the criterion is met .\n2. Unless aspirin is mentioned under \" allergies ,\" then criterion is not met\nKeywords / Phrases : Aspirin , Low - dose aspirin , aspirin 81 , asa 81 , Baby aspirin , aspirin\n325 , Aspirin regimen , ASA ( Acetylsalicylic Acid ), Coated aspirin\nHBA1C\nStrategies :\nReview Chemistry / Laboratory data for all HbA1c levels .\n1. if HbA1c is mentioned , check if a value is given . If not , assume it is not between\n6.5 and 9.5. The default answer is False .\nOtherwise\n2. Extract the numerical value after the word \" HbA1c \" or \" A1c \" and compare it to the\nnormal range . If the value is between 6.5 and 9.5 , the criterion is met .\n3. If multiple values are given , use the largest value . If no value is given , assume\nit is not between 6.5 and 9.5. The default answer is False .\n4. Sample Example : \" HbA1c 7.2%\" or \" A1c 8.5%\" would meet the criterion . But \" HbA1c\n5.8%\" or \" A1c 10.1%\" would not .\nKeywords / Phrases : Hemoglobin A1c , HbA1c test results , A1c , A1c percentage , Hemoglobin\nA1c level\nCREATININE\nStrategies :\nA normal result is 0.7 to 1.3 mg/dL (61.9 to 114.9 µmol /L) for men and 0.6 to 1.1 mg/dL\n(53 to 97.2 µmol /L) for women .\nReview all the medical records for mention of creatinine /Cr or other keywords .\n1. Extract all numerical values after the word \" creatinine \" or \"Cr\" and compare them\nto the normal range . If any value is higher than the upper limit of normal (1.3 for\nmen and 1.1 for women ), the criterion is met .\n2. If provided with a range , then take the largest value of that range and analyze it.\nFor example , Cr 1.6 -2.0 would be elevated because 2.0 is abnormal\n3. If multiple values are given , use the largest value .\n4. If no value is given , assume it is not above the upper limit of normal . ie answer\nis False .\nKeywords / Phrases : Serum creatinine , Cr , Chemistry , Lab , Creatinine blood test ,\nLABORATORY DATA\nMI -6 MOS\nStrategies :\nNeeds to be a relatively recent MI\n1. Look for reported symptoms of chest pain , shortness of breath , or other signs of a\nheart attack . However , symptoms alone are not enough to meet the criteria . They\nwill need to have evidence of elevated cardiac biomarkers or ECG changes .\n14\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \n2. If troponin levels are mentioned , check if they are elevated . If so , the criterion\nis met .\n3. Look for recent ECG changes , such as ST - segment elevation or T- wave inversion . If\npatient had symptoms of a heart attack and ECG changes , the criteria is met .\n4. See if procedures like cardiac catheterization or angioplasty were performed or\nplanned . If so , the criterion is met .\n5. If STEMI , NSTEMI , or myocardial infarction are mentioned , the criterion is met .\nKeywords / Phrases : STEMI , NSTEMI , Myocardial infarction , Recent heart attack , Troponin\nelevation , Cardiac enzymes , Post -MI changes , Coronary syndrome , Elevated troponin\nlevels , ECG changes , Acute coronary event , stent , cardiac cath .\nA.4 LLM-Generated Expert Guidance\nTo fully automate the eligibility screening process, we used LLMs abilities to generate expert guidance\nwithout manual intervention. The LLM is provided with the criteria description and tasked with\ngenerating vocabulary, keywords, and phrases associated with the criteria being met or not met. This\nis done to assist with reasoning and the document retrieval process. The full list of LLM-generated\nexpert tips can be found below.\nDRUG - ABUSE :\nAssociated with meeting the criterion of evidence of drug abuse , current or past , you\nmight encounter terms such as substance abuse , addiction , positive drug screen ,\ntoxicology report , withdrawal symptoms , tolerance , dependency , rehabilitation ,\nrelapse , narcotics , stimulants , depressants , hallucinogens , drug - seeking behavior ,\noverdose , and history of substance use disorder .\nFor not meeting the criterion , terms could include a negative drug screen , sobriety ,\nabstinence , clean toxicology report , recovery , non -user , and no history of\nsubstance abuse .’ ’req ’: ’ Evidence of Drug abuse , current or past\nALCOHOL - ABUSE :\nAssociated with meeting the criterion of current alcohol use over weekly recommended\nlimits might include terms such as \" heavy drinking ,\" \" excessive alcohol consumption\n,\" \" binge drinking ,\" \" alcohol abuse ,\" \" high alcohol intake ,\" \" above recommended\nlimits ,\" \" chronic alcohol use ,\" \" frequent intoxication ,\" \" alcohol dependence ,\" and\n\" positive alcohol screening test .\"\nConversely , terms indicating the criterion is not met could include \" moderate drinking\n,\" \" within recommended limits ,\" \"low - risk alcohol use ,\" \" abstinence ,\" \" sober ,\" \"\ninfrequent drinking ,\" \" negative alcohol screening test ,\" \" responsible drinking ,\"\nand \" alcohol consumption within guidelines .\nENGLISH :\nAssociated with the criterion being met : fluent , proficient , English - speaking ,\nbilingual , native speaker , conversational level , language proficiency ,\nunderstanding English , communicating in English , and English literacy .\nAssociated with criterion not being met : non - English speaking , limited English ,\nlanguage barrier , requires interpreter , non - fluent , poor comprehension , language\ndifficulty , non - native speaker , ESL ( English as a Second Language ), inadequate\nEnglish skills .\nMAKES - DECISIONS :\nAssociated with the criterion being met : competent , autonomous , decision - making\ncapacity , informed consent , self - determined , cognitive ability , understanding ,\nvoluntary , legal age , emancipated minor , mental capacity , lucid , coherent ,\nunimpaired judgment .\nAssociated with the criterion not being met : incapacitated , cognitive impairment ,\ndementia , Alzheimer ’s, minor , underaged , legally incompetent , guardian , power of\nattorney , conservatorship , delirium , psychiatric illness , impaired consciousness ,\ncoerced , undue influence .\nABDOMINAL :\nAssociated words for meeting the criterion of a history of intra - abdominal surgery ,\nsmall or large intestine resection , or small bowel obstruction might include\nappendectomy , colectomy , gastrectomy , hysterectomy , laparotomy , cholecystectomy ,\nbowel resection , anastomosis , adhesiolysis , ileostomy , colostomy , diverticulectomy ,\nand enterectomy . Words indicating complications or related conditions could be\nadhesions , hernia repair , or postoperative ileus .\n15\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \nWords indicating the criterion is unmet might include no prior surgery , intact bowel ,\nno history of obstructions , non - surgical management , and uncomplicated abdominal\nhistory . Terms like laparoscopy or endoscopy might appear in both contexts but\nwould need clarification , as they could refer to diagnostic procedures without any\nresection or obstruction .\nMAJOR - DIABETES :\nAssociated with meeting the criterion of having a history of diabetes and major\ndiabetes - related complications , words might include hyperglycemia , insulin , type 1\ndiabetes , type 2 diabetes , HbA1c , diabetic neuropathy , retinopathy , diabetic foot\nulcer , nephropathy , cardiovascular disease , stroke , myocardial infarction ,\nperipheral artery disease , and end - stage renal disease .\nWords indicating the criterion is unmet could include normoglycemia , non - diabetic , no\nhistory of hyperglycemia , absence of retinopathy , healthy renal function , no\nneuropathy , intact peripheral circulation , and no cardiovascular complications .\nThese terms suggest the individual does not have diabetes or has not developed\nsignificant complications associated with the condition .\nADVANCED - CAD :\nAssociated with meeting the criterion of advanced cardiovascular disease : myocardial\ninfarction , congestive heart failure , angina pectoris , coronary artery disease ,\ncardiomyopathy , arrhythmia , peripheral arterial disease , stroke , transient ischemic\nattack , atherosclerosis , heart valve disease , aneurysm , ischemic heart disease ,\nleft ventricular dysfunction , stent , bypass surgery , angioplasty , electrocardiogram\nabnormalities , echocardiogram abnormalities , heart failure , elevated troponin ,\nelevated BNP (B- type natriuretic peptide ), abnormal stress test , pacemaker ,\nimplantable cardioverter - defibrillator ( ICD ), severe hypertension , advanced\natheroma .\nAssociated with not meeting the criterion of advanced cardiovascular disease : normal\nblood pressure , normal cholesterol levels , normal EKG /ECG , normal echocardiogram ,\nno history of cardiac events , no interventions ( stents , bypass ), no symptoms ( chest\npain , dyspnea ), normal stress test , healthy lifestyle , absence of cardiac\nmedications , no peripheral vascular symptoms , no carotid bruits , normal cardiac\nbiomarkers .\nDIETSUPP -2 MOS :\nAssociated with meeting the criterion : supplementation , vitamins , minerals , herbal ,\nnutrients , omega -3 , probiotics , amino acids , antioxidants , enzymes , fiber\nsupplements , protein powders , dietary intake , nutritional support , health regimen ,\ndaily intake , nutritional products , nutraceuticals , ingest , consumption , dietary\nhabits .\nAssociated with not meeting the criterion : no supplements , diet -only , food sources ,\nnatural intake , unaided nutrition , no additional nutrients , exclusive diet reliance\n, whole foods , supplement -free , no pills , no capsules , no powders , no artificial\nnutrients , no fortified products .\nKETO -1 YR:\nAssociated with the criterion being met : ketoacidosis , diagnosis , DKA , diabetic\nketoacidosis , hyperglycemia , ketones , acidosis , hospitalization , medical records ,\nlab results , blood tests , urine tests , pH imbalance , bicarbonate levels , anion gap ,\ninsulin deficiency , diabetes , emergency treatment , metabolic acidosis , high blood\nsugar , endocrinologist , medical history , past 12 months .\nNot associated with the criterion being met : no history , no episodes , stable blood\nglucose , normal ketone levels , euglycemia , balanced pH , absence of symptoms , no\nhospital admissions for DKA , controlled diabetes , effective insulin therapy ,\nregular monitoring , no acid - base disturbances , no diabetic complications , no acute\ndiabetes events , good glycemic control , no metabolic acidosis , within normal range\nlab values .\nASP -FOR -MI:\nAssociated with meeting the criterion of using aspirin / ASA to prevent myocardial\ninfarction (MI) might include prophylaxis , cardiovascular risk , anticoagulant\ntherapy , antiplatelet therapy , secondary prevention , primary prevention , low - dose\naspirin , coronary artery disease ( CAD ), atherosclerosis , stroke prevention , and\nischemic heart disease .\nWords indicating the criterion is not met could include aspirin allergy ,\ncontraindications , bleeding disorders , hemorrhagic stroke , peptic ulcer disease ,\nanticoagulant use , drug interactions , non - compliance , and alternative therapies .\nHBA1C :\n16\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \nFor the criterion of an HbA1c value between 6.5% and 9.5% , associated words when the\ncriterion is met might include \" eligible ,\" \" controlled diabetes ,\" \" within range ,\" \"\nmoderate hyperglycemia ,\" \" acceptable ,\" \" enrollment criteria satisfied ,\" and \"\nqualified .\" Conversely , words associated with the criterion not being met could\ninclude \" ineligible ,\" \" exclusion ,\" \" below threshold ,\" \"non - diabetic ,\" \" above\nthreshold ,\" \" poorly controlled diabetes ,\" \" severe hyperglycemia ,\" \" disqualified ,\"\nand \" out of range .\" These terms reflect whether a potential participant ’s HbA1c\nlevels fall within the specified range for inclusion in the clinical trial .\nCREATININE :\nAssociated with elevated serum creatinine or serum creatinine levels above the upper\nlimit of normal : renal impairment , kidney dysfunction , nephrotoxicity , renal\ninsufficiency , chronic kidney disease ( CKD ), acute kidney injury ( AKI ),\nglomerulonephritis , reduced glomerular filtration rate ( GFR ), proteinuria ,\nhematuria , azotemia , uremia , nephropathy , hypertension , diabetes mellitus ,\ndehydration , rhabdomyolysis , muscle mass increase , dietary intake ( high meat\nconsumption ), certain medications (e.g., ACE inhibitors , NSAIDs , aminoglycosides ),\nand supplements (e.g., creatine ).\nWords associated with serum creatinine levels within or below the normal range : normal\nrenal function , healthy kidneys , adequate glomerular filtration , absence of renal\ndisease , stable kidney condition , normal hydration status , normal muscle mass , and\nbalanced diet .\nMI -6 MOS :\nAssociated with meeting the criterion of a recent myocardial infarction (MI) or\ncurrent MI: chest pain , angina , ECG changes , elevated troponins , ST elevation , Q\nwaves , coronary angiography , revascularization , stent placement , coronary artery\nbypass grafting ( CABG ), thrombolysis , aspirin , beta - blockers , ACE inhibitors ,\nshortness of breath , cardiac enzymes , heart attack , percutaneous coronary\nintervention ( PCI ), left ventricular dysfunction , echocardiogram abnormalities .\nAssociated with not meeting the criterion : stable angina , normal ECG , normal troponin\nlevels , no ST changes , no Q waves , no recent coronary intervention , no recent\nrevascularization , no symptoms of heart failure , normal cardiac function , no recent\nchest pain , clear echocardiogram , absence of cardiac biomarkers , no history of MI\nin the past six months .\n17\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \nB Common Failures\nAmong the results produced by our approach, we observe that incorrect results often fall into one of a\nhandful of categories. With this, the frequency of each type of failure varies based on the criteria type.\nSpecifically, we observe failures due to incorrect logic, uncertainty, or insufficient document retrieval.\nB.1 Incorrect Temporal Reasoning\nWhen screening for date-sensitive criteria, we observed several failures in temporal reasoning. These\nfailures often occurred when evidence was correctly retrieved and identified by the LLM, but a date\nwas not correctly associated with it or reasoned about. For example, when screening a patient for\nMI-6MOS, the LLM often produces results as shown in Figure 6. False negatives due to errors in\ntemporal reasoning were also observed but were much rarer.\nThe patient had a myocardial infarction in the past six months, as indicated\nby the history of NSTEMI in March, 2136, and subsequent cardiac catheterization\nrevealing in-stent stenosis in LCx stent, which was addressed with bare metal\nstent placement.\nFigure 6: LLM response with incorrect temporal reasoning.\nB.2 Incorrect Logic\nIn some cases, the LLM correctly identifies evidence but makes an incorrect conclusion based on said\nevidence. These cases seem most common when screening complex criteria with multiple requirements,\nsuch as ADVANCED-CAD or MAJOR-DIABETES. These errors seem to be due to the LLM failing\nto understand the criteria requirements fully. In the case of ADVANCED-CAD, false positives are\ncommon due to the LLM identifying evidence that meets some criteria requirements but not a sufficient\namount. An example of this type of error is shown in Figure 7, where the LLM classifies a patient as\nmeeting ADVANCED-CAD, but the ground truth rules that the patient does not meet the criteria.\nThe patient has a history of CAD (Coronary Artery Disease) as mentioned in\nthe PMH (Past Medical History). Additionally, the patient is on multiple\nCAD-related medications, including Atenolol and Simvastatin, which are\nbeta-blockers and statins, respectively, used in the management of CAD.\nFigure 7: LLM response with incorrect logic.\nB.3 Insufficient Retrieval\nFailures across all criteria can be attributed to insufficient document retrieval or information extraction\nfrom the LLM. This type of failure is commonly associated with false negatives, as the LLM is not\nprovided with relevant context from the patient record. In most instances of this failure, reasoning\nsuch as ”No evidence found in the EHR” is listed. This may cause generally lower sensitivity than\nspecificity values across all models.\nB.4 Hallucinations\nIn our testing, we found that hallucinations of evidence comprised a sizable number of misclassifications\nwhen using GPT-3.5 Turbo and a much smaller number of misclassifications when using GPT-4. The\nLLM often cited evidence from the prompt or expert guidance, even when this information is not found\nin the patient documents. For example, several patients with varying HbA1c values were incorrectly\n18\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint \nclassified as meeting the HBA1C criterion. The LLM often cited ”HbA1c 7.2%” as evidence in these\ncases, reflecting a portion of the manually-created expert guidance.\n19\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 12, 2024. ; https://doi.org/10.1101/2024.04.10.24305571doi: medRxiv preprint "
}