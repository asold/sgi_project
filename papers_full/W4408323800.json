{
  "title": "Performance Evaluation and Application Potential of Small Large Language Models in Complex Sentiment Analysis Tasks",
  "url": "https://openalex.org/W4408323800",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2145590441",
      "name": "Yunchu Yang",
      "affiliations": [
        "Macao Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2234461638",
      "name": "Jiaxuan Li",
      "affiliations": [
        "Macao Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2735461339",
      "name": "Jielong Guo",
      "affiliations": [
        "Macao Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A4298508334",
      "name": "Patrick Cheong-Iao Pang",
      "affiliations": [
        "Macao Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2110527939",
      "name": "Yapeng Wang",
      "affiliations": [
        "Macao Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2055575727",
      "name": "Xu Yang",
      "affiliations": [
        "Macao Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2973710654",
      "name": "Sio-Kei Im",
      "affiliations": [
        "Macao Polytechnic University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2910164082",
    "https://openalex.org/W3196324893",
    "https://openalex.org/W3020349211",
    "https://openalex.org/W3016235703",
    "https://openalex.org/W3090347447",
    "https://openalex.org/W4386973901",
    "https://openalex.org/W3139172628",
    "https://openalex.org/W4312924043",
    "https://openalex.org/W4306743104",
    "https://openalex.org/W4386989263",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4362558246",
    "https://openalex.org/W4385611483",
    "https://openalex.org/W4401042286",
    "https://openalex.org/W6855218505",
    "https://openalex.org/W4386691702",
    "https://openalex.org/W4379259169",
    "https://openalex.org/W4388777264",
    "https://openalex.org/W4406195132",
    "https://openalex.org/W4404592166",
    "https://openalex.org/W4392669753",
    "https://openalex.org/W4407139145",
    "https://openalex.org/W4396597709",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W4399394027",
    "https://openalex.org/W3172642864",
    "https://openalex.org/W2804228850",
    "https://openalex.org/W4386998832",
    "https://openalex.org/W4392506286",
    "https://openalex.org/W6860985507",
    "https://openalex.org/W6858100026",
    "https://openalex.org/W4281763794",
    "https://openalex.org/W6809646742"
  ],
  "abstract": "Sentiment analysis using Large Language Models (LLMs) has gained significant attention in recent research due to its outstanding performance and ability to understand complex texts. However, popular LLMs, such as ChatGPT, are typically closed-source and come with substantial API costs, posing challenges for resource-limited scenarios and raising concerns about privacy. To address this, our study evaluates the feasibility of using small LLMs (sLLMs) as alternatives to GPT for aspect-based sentiment analysis in Chinese healthcare reviews. We compared several Chinese sLLMs of varying sizes with GPT-3.5, using GPT-4o&#x2019;s results as the benchmark, and assessed their classification accuracy by computing F1 scores for each individual aspect as well as an overall F1 score. Additionally, we examined sLLMs&#x2019; instruction-following capabilities, VRAM requirements, generation times, and the impact of temperature settings on the performance of top-performing sLLMs. The results demonstrate that several sLLMs can effectively follow instructions and even surpass GPT-3.5 in accuracy. For instance, InternLM2.5 achieved an F1 score of 0.85 with zero-shot prompting, while the smaller Qwen2.5-3B model performed well despite its minimal size. Prompt strategies significantly influenced smaller and older models like Qwen2.5-1.5B and ChatGLM3.5 but had limited impact on newer models. Temperature settings showed minimal effect, while older models generated responses faster, and newer models offered higher accuracy. This study underscores the potential of sLLMs as resource-efficient, privacy-preserving alternatives to closed-source LLMs in specialized domains. Our work demonstrates versatility, with potential applications across domains such as finance and education, and tasks like sentiment analysis, credit risk assessment, and learning behavior analysis, offering valuable insights for real-world use cases.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8104565143585205
    },
    {
      "name": "Sentiment analysis",
      "score": 0.6067721843719482
    },
    {
      "name": "Natural language processing",
      "score": 0.5132033824920654
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4205382466316223
    }
  ]
}