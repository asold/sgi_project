{
    "title": "GATransformer: A Graph Attention Network-Based Transformer Model to Generate Explainable Attentions for Brain Tumor Detection",
    "url": "https://openalex.org/W4407223927",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2568581170",
            "name": "Sara Tehsin",
            "affiliations": [
                "Kaunas University of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A3040304364",
            "name": "Inzamam  Mashood Nasir",
            "affiliations": [
                "Kaunas University of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A4207370342",
            "name": "Robertas Damaševičius",
            "affiliations": [
                "Kaunas University of Technology"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4311442013",
        "https://openalex.org/W4311767714",
        "https://openalex.org/W4281887347",
        "https://openalex.org/W4306146238",
        "https://openalex.org/W4289229573",
        "https://openalex.org/W6838436261",
        "https://openalex.org/W4283330963",
        "https://openalex.org/W4229458598",
        "https://openalex.org/W4377970488",
        "https://openalex.org/W4308333450",
        "https://openalex.org/W4384937010",
        "https://openalex.org/W4402499135",
        "https://openalex.org/W4292289324",
        "https://openalex.org/W4378714324",
        "https://openalex.org/W4380989166",
        "https://openalex.org/W4323530522",
        "https://openalex.org/W4365135358",
        "https://openalex.org/W4303628775",
        "https://openalex.org/W4283080861",
        "https://openalex.org/W4312100216",
        "https://openalex.org/W4405673968",
        "https://openalex.org/W4381435789",
        "https://openalex.org/W4401888784",
        "https://openalex.org/W4403068662",
        "https://openalex.org/W6964665992",
        "https://openalex.org/W2148143831",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W2183341477",
        "https://openalex.org/W2963446712",
        "https://openalex.org/W2946948417",
        "https://openalex.org/W2963163009",
        "https://openalex.org/W2194775991",
        "https://openalex.org/W4384938272",
        "https://openalex.org/W4282937861",
        "https://openalex.org/W4280550823"
    ],
    "abstract": "Brain tumors profoundly affect human health owing to their intricacy and the difficulties associated with early identification and treatment. Precise diagnosis is essential for effective intervention; nevertheless, the resemblance among tumor forms often complicates the identification of brain tumor types, particularly in the early stages. The latest deep learning systems offer very high classification accuracy but lack explainability to help patients understand the prediction process. GATransformer, a graph attention network (GAT)-based Transformer, uses the attention mechanism, GAT, and Transformer to identify and preserve key neural network channels. The channel attention module extracts deeper properties from weight-channel connections to improve model representation. Integrating these elements results in a reduction in model size and enhancement in computing efficiency, while preserving adequate model performance. The proposed model is assessed using two publicly accessible datasets, FigShare and Kaggle, and is cross-validated using the BraTS2019 and BraTS2020 datasets, demonstrating high accuracy and explainability. Notably, GATransformer generates interpretable attention maps, visually highlighting tumor regions to aid clinical understanding in medical imaging.",
    "full_text": null
}