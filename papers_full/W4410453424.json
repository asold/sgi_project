{
  "title": "A review of LLMs and their applications in the architecture, engineering and construction industry",
  "url": "https://openalex.org/W4410453424",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5084256276",
      "name": "Dimitrios Kampelopoulos",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5053980856",
      "name": "Athina Tsanousa",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5065313479",
      "name": "Stefanos Vrochidis",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5084122016",
      "name": "Ioannis Kompatsiaris",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3203241482",
    "https://openalex.org/W2980412932",
    "https://openalex.org/W4378464975",
    "https://openalex.org/W4389157038",
    "https://openalex.org/W3201021139",
    "https://openalex.org/W3093515092",
    "https://openalex.org/W4377121468",
    "https://openalex.org/W4388184452",
    "https://openalex.org/W4283392904",
    "https://openalex.org/W4382400718",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W4396685186",
    "https://openalex.org/W3195577433",
    "https://openalex.org/W4226082499",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4399031574",
    "https://openalex.org/W3177813494",
    "https://openalex.org/W4400209938",
    "https://openalex.org/W2103278824",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4321392130",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W4391555522",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4213425661",
    "https://openalex.org/W4401306886",
    "https://openalex.org/W2162531320",
    "https://openalex.org/W2950637580",
    "https://openalex.org/W3082558305",
    "https://openalex.org/W4287391717",
    "https://openalex.org/W2050269490",
    "https://openalex.org/W4389984066",
    "https://openalex.org/W4390880765",
    "https://openalex.org/W4396892628",
    "https://openalex.org/W4389326242",
    "https://openalex.org/W4378510404",
    "https://openalex.org/W4393928899",
    "https://openalex.org/W4285132330",
    "https://openalex.org/W4281390335",
    "https://openalex.org/W3033187248",
    "https://openalex.org/W2964303773",
    "https://openalex.org/W4292358656",
    "https://openalex.org/W3168867926",
    "https://openalex.org/W4399424728",
    "https://openalex.org/W4382322410",
    "https://openalex.org/W4394779177",
    "https://openalex.org/W4387561528",
    "https://openalex.org/W4390723197",
    "https://openalex.org/W4396986140",
    "https://openalex.org/W4387074810",
    "https://openalex.org/W4384920109",
    "https://openalex.org/W2105934661",
    "https://openalex.org/W6600511658",
    "https://openalex.org/W4296512863",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W3040573126",
    "https://openalex.org/W4287208373",
    "https://openalex.org/W4288088047",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W3119438769",
    "https://openalex.org/W2996936831",
    "https://openalex.org/W4391421504",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3107826490",
    "https://openalex.org/W4280638966",
    "https://openalex.org/W4378188762",
    "https://openalex.org/W4387356327",
    "https://openalex.org/W3194860946",
    "https://openalex.org/W3156470785",
    "https://openalex.org/W4393236964",
    "https://openalex.org/W4406072453",
    "https://openalex.org/W2969536608",
    "https://openalex.org/W4391069894",
    "https://openalex.org/W4391766565",
    "https://openalex.org/W4284886889",
    "https://openalex.org/W4384389802",
    "https://openalex.org/W2901026139",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4393399294",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4283704460",
    "https://openalex.org/W4378498597",
    "https://openalex.org/W4224903276",
    "https://openalex.org/W4399778962",
    "https://openalex.org/W2796105695",
    "https://openalex.org/W3192208786",
    "https://openalex.org/W4399507014",
    "https://openalex.org/W4360847209",
    "https://openalex.org/W4400146581",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4391855109",
    "https://openalex.org/W4388154082",
    "https://openalex.org/W4386185625",
    "https://openalex.org/W4389618734",
    "https://openalex.org/W4313457971",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W3027176846",
    "https://openalex.org/W4308760226",
    "https://openalex.org/W3093666741",
    "https://openalex.org/W4293718192",
    "https://openalex.org/W4353112996",
    "https://openalex.org/W4313197536",
    "https://openalex.org/W4377009978",
    "https://openalex.org/W4391614156",
    "https://openalex.org/W4283761305",
    "https://openalex.org/W4391901199",
    "https://openalex.org/W4379919478",
    "https://openalex.org/W2891059300",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4288245699",
    "https://openalex.org/W4366990278",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4378505261",
    "https://openalex.org/W3198599617",
    "https://openalex.org/W4286987939",
    "https://openalex.org/W1975633953",
    "https://openalex.org/W2966798122",
    "https://openalex.org/W4320559489",
    "https://openalex.org/W3093517588",
    "https://openalex.org/W4393213649",
    "https://openalex.org/W4402862959",
    "https://openalex.org/W4366835671",
    "https://openalex.org/W3093500471",
    "https://openalex.org/W3215371923",
    "https://openalex.org/W4287704453",
    "https://openalex.org/W4396794417",
    "https://openalex.org/W2979476646",
    "https://openalex.org/W4402525770",
    "https://openalex.org/W4386276891",
    "https://openalex.org/W4391765649",
    "https://openalex.org/W2023184793",
    "https://openalex.org/W4310743188",
    "https://openalex.org/W4311642023"
  ],
  "abstract": "Abstract During the past decade, there has been rapid emergence, continuous development and advancements in the field of Artificial Intelligence (AI), and a broad adaptation ofLarge Language Models (LLMs) in a wide variety of application domains transforming and streamlining industry practices. However, the construction industry has yet to fully incorporate these technologies, delaying their wide-scale adaptation. Only a limited number of recent studies have explored the opportunities, capabilities and potential of current LLM implementations in the broad domain of Architecture Engineering and Construction (AEC) industry, leaving a significant gap in this field of research. This study aims to address this gap and provide an extensive review of already established state-of-the-art applications and use case scenarios of LLMs in the AEC industry. Apart from that, by exploring the key contributions and limitations of these applications, and by considering relative reviews on this subject, it was possible to categorize them, to extract the emerging challenges and future directions of the field and propose actionable recommendations for industry stakeholders. This study also includes an introduction to important concepts and recent advancements of LLM technologies, focusing on transformer-based architectures and providing an extensive list of LLM families.",
  "full_text": "Accepted: 17 April 2025 / Published online: 16 May 2025\n© The Author(s) 2025\n \r Dimitrios Kampelopoulos\ndkampelo@iti.gr\n \r Athina Tsanousa\natsan@iti.gr\n \r Stefanos Vrochidis\nstefanos@iti.gr\n \r Ioannis Kompatsiaris\nikom@iti.gr\n1 Information Technology Institute, Centre for Research and Technology Hellas - CERTH, \n60361, 6th km Charilaou-Thermi Rd, 57001 Thessaloniki, Greece\nA review of LLMs and their applications in the architecture, \nengineering and construction industry\nDimitrios Kampelopoulos1  · Athina Tsanousa1  · Stefanos Vrochidis1  · \nIoannis Kompatsiaris1\nArtificial Intelligence Review (2025) 58:250\nhttps://doi.org/10.1007/s10462-025-11241-7\nAbstract\nDuring the past decade, there has been rapid emergence, continuous development and \nadvancements in the field of Artificial Intelligence (AI), and a broad adaptation ofLarge \nLanguage Models (LLMs) in a wide variety of application domains transforming and \nstreamlining industry practices. However, the construction industry has yet to fully incor -\nporate these technologies, delaying their wide-scale adaptation. Only a limited number \nof recent studies have explored the opportunities, capabilities and potential of current \nLLM implementations in the broad domain of Architecture Engineering and Construc -\ntion (AEC) industry, leaving a significant gap in this field of research. This study aims to \naddress this gap and provide an extensive review of already established state-of-the-art \napplications and use case scenarios of LLMs in the AEC industry. Apart from that, by \nexploring the key contributions and limitations of these applications, and by considering \nrelative reviews on this subject, it was possible to categorize them, to extract the emerging \nchallenges and future directions of the field and propose actionable recommendations for \nindustry stakeholders. This study also includes an introduction to important concepts and \nrecent advancements of LLM technologies, focusing on transformer-based architectures \nand providing an extensive list of LLM families.\nKeywords Literature review · Large language models · Transformer-based architecture · \nAEC industry · Use cases · Challenges · Future directions\n1 3\nD. Kampelopoulos et al.\n1 Introduction\nThe AEC industry plays a significant role in the global economy, with the construction \nindustry alone contributing to approximately 13% of the global GDP (Ribeirinho et al. \n2020). This broad domain contains multiple sub-fields, including architecture, civil and \nelectrical engineering, residential, commercial and industrial building construction, opera -\ntion, maintenance, demolition, lifecycle management and more. However, the industry is \ncharacterized by a productivity growth rate of only 1% per year compared to 2.8% for \nthe global economy and 3.6% for the manufacturing domain (Barbosa et al. 2017), with \nresearchers highlighting delays and a general stagnation in the development and diffusion of \ntechnical innovation in construction for the past decades (Gambatese and Hallowell 2011).\nΤhe recent years, researchers have employed Artificial Intelligence (AI) methodologies \non different aspects of the industry for tasks requiring human intelligence, reasoning, per -\nception and decision-making. AI systems are utilized to process and analyze large datasets, \nwith multiple AI sub-fields being employed like machine-learning (ML), Deep Learning \n(DL), Computer Vision (CV), Natural Language Processing (NLP), Conversational Arti -\nficial Intelligence (CAI), robotics, automated planning, scheduling and optimization tech -\nniques leveraging AI (Abioye et al. 2021). More specifically, AI and its subdomains are \nsuccessfully employed in a variety of industry related tasks, including cost prediction (Wil-\nliams and Gong 2014; Baduge et al. 2022), safety management (Poh et al. 2018; Liu et al. \n2022), schedule optimization (Zhang et al. 2019; Hatami et al. 2022), progress monitor -\ning (Zhu and Brilakis 2010), quality control (Andenæs et al. 2020), supply chain manage-\nment (Pournader et al. 2021), logistics management (Fang and Ng 2019), risk management \n(Sanni-Anibire et al. 2020; Afzal et al. 2019), dispute resolution (Chou and Lin 2012), waste \nmanagement (Lu et al. 2021; Yu et al. 2020), sustainability assessment (Kar et al. 2022), \nvisualization (Seo et al. 2020; Tan 2018), energy efficiency and occupant comfort (Mehm -\nood et al. 2019; Fathi et al. 2020) as well as in Building Information Modeling (BIM) (Zabin \net al. 2021; Bassir et al. 2023).\nLarge language models (LLMs) are a subdomain of the broad field of AI that presents \nsignificant differences from traditional AI approaches, like ML, DL, rule-based and deci -\nsion-making systems. Unlike standard ML models, LLMs are based on the transformer \narchitecture, utilizing innovative approaches like the self-attention mechanism and posi -\ntional encoding to process text input in natural language and extract complex connections \nand dependencies between words based on how closely they are located within the text. To \nachieve that, they are pre-trained on large datasets consisting of research databases, online \ncontent, code repositories and more. Unlike other AI technologies targeting specific tasks \nlike image recognition, classification, regression, etc., their multi-disciplinary training on \nmassive amounts of text data allows them to generate human-like responses and perform \ngeneral-purpose tasks with little to no prior training examples. Apart from that, compared \nto earlier models for language processing requiring extensive manual tuning, LLMs employ \ntransfer learning. They are pre-trained on the massive datasets and can then be fine-tuned \non domain-specific datasets, with the ability to adapt based on human input. This combina-\ntion of large-scale training, advanced text processing, general-purpose effectiveness with \nminimal to no additional training and parallel processing capabilities offers an adaptable and \nscalable solution for a wide range of potential applications on multiple domains.\n1 3\n250 Page 2 of 46\nA review of LLMs and their applications in the architecture, engineering…\nLLMs sparked significant interest in the research community during the past few years, \nwith many contributions exploring the capabilities, the challenges and future directions of \nthis technology. With new models, architectures, techniques emerging at a growing pace, it \nis crucial to systematically document the advances in this domain. Some recent contributions \ninclude Raaian et al. (2024) who provided an overview of transformer-based LLMs—exam-\nining their history, architecture, and performance across various domains—and Naveed et \nal. (2023) who focused on technical aspects, performance differences, and fine-tuning strat-\negies across multiple LLM families. In a similar manner, Minaee et al. ( 2024) compared \nLLM families based on operational metrics and evaluation benchmarks while Bengesi et al. \n(2024) offered a broader review of generative AI beyond text generation, including model \narchitectures such as Generative Adversarial Networks (GANs), Autoencoders, and Diffu -\nsion models for image, audio and video generation.\n1.1 Literature review\nIn the construction domain, there is a limited amount of literature reviews conducted on the \nutilization of GAI technologies. One key contribution is (Ding et al. 2022) who presented \na comprehensive review of early NLP applications in the construction industry, covering a \ndiverse range of NLP applications, with 91 research articles from 2000 to 2020. They were \nable to highlight tasks that can be efficiently automated within the fields of document man-\nagement, safety monitoring, risk management, compliance checking, while also emphasiz -\ning the datasets adopted by each study. Their results indicated the problem of data isolation \nduring that time and raised the need for data-sharing across the construction sector. This \nstudy, while comprehensive and thorough, is restricted to studies up until 2020, not account-\ning for the recent growth in the field and the major improvements in capabilities of recent \nLLM models. Another contribution comes from Rane ( 2023), who demonstrated the role \nof generative AI, particularly ChatGPT, in transforming the construction industry in three \nmajor aspects: Industry 4.0, Industry 5.0, and Society 5.0. They provide opportunities, chal-\nlenges and potential tasks that can be automated with LLMs while also providing a semantic \nanalysis on the subject. However, their work is focused solely on ChatGPT and presents \nlimited case studies that are already established while focusing on suggesting opportunities \nfor LLMs in construction.\nRecent reviews on the field of GAI in construction include major contributions like Taiwo \net al. ( 2024) who conducted a review of potential GAI applications in the construction \nindustry, presenting the current architectures, models being currently developed for pro -\ncessing and generating text, images and video. They suggest potential applications through \nall phases of construction and also provide a case study for processing contract documents \nrelated to the construction of a three-story facility. While their work is comprehensive and \na significant contribution to the field, they present only six already established applications \nof LLMs in construction, not addressing the recent adoption of this technology. Another key \nreview comes from Ghimire et al. ( 2024) who explored GAI in construction focusing on \nthe adoption of text-based models. They present a description of the common and state-of-\nthe-art architectures and techniques employed for GAI, and explore potential applications \nand tasks throughout the lifecycle of a building. In a similar manner, their contribution is \nthorough, presenting opportunities and potential applications in the field for future develop-\nment, including a limited number of already established applications (ten).\n1 3\nPage 3 of 46 250\nD. Kampelopoulos et al.\nSaka et al. ( 2023a) did a holistic review of GPT models in the construction industry, \nfocusing on opportunities and limitations in all stages of construction. They present current \napplications leveraging models from the ChatGPT family, however only a limited num -\nber of them. Another contribution comes from Preuss et al. ( 2024) who focused on life-\ncycle assessment (LCA) of buildings and the opportunities, technical challenges and risks \nof using LLMs in that domain. They address all phases of construction however they only \naddress the LCA component of each phase. Additionally, Zhang et al. ( 2024) focused on \nthe domain of Building Energy Modeling (BEM) and explored the potential of LLMs in \nthis particular field. They propose a list of potential LLM applications and tasks that can be \nautomated, to improve efficiency and accessibility of BEM tools. Their work is supported \nby three use cases where LLMs were able to generate or modify input objects for simula -\ntions, visualize data and extract knowledge. However, it is limited to use cases targeting a \nspecific subdomain of construction.\nThe field of LLMs is growing at a fast pace, with new models, architectures, and tech -\nniques being developed and new capabilities and milestones being achieved on a monthly \nbasis. While researchers have highlighted the opportunities, the role and challenges of GAI \nand, specifically LLMs, in the AEC industry extensively, there is still a limited number of \nwell-established case studies and applications being documented. This can be attributed to \nthe relatively recent development and growth of LLMs leaving not much time for research-\ners to fully adopt them in all fields, but also on the fact that the construction industry is \ncharacterized by slow adaptation to new technologies (Dubois and Gadde 2002) (Table 1).\nAdditionally, the research on this particular field is limited with some key contributions, \nlike Saka et al. ( 2023a) covering all building management phases but being limited to a \nsmall number of use cases utilizing only ChatGPT models, Preuss et al. (2024) focusing spe-\ncifically on the LCA domain, Ding et al. (2022) being restricted to studies up until 2020 and \nZhang et al. (2024) emphasizing on automating BEM-related tasks. Table I summarizes the \nkey contributions and limitations of these review studies. The key limitation that becomes \napparent is the small number of already established applications, which is true for all of the \nabove reviews. As a result, while the opportunities, potential applications and challenges \nare well-established, there is a research gap in already established LLM applications and \ncase studies for automating and streamlining tasks on all phases of construction. This study \nfocuses on addressing that gap and achieving the following main objectives:\n ● Providing an introduction to non-experts to the recent advancements, important con -\ncepts of LLM technologies and popular LLM families, focusing on transformer-based \narchitectures.\n ● Explore the latest applications of LLMs in the AEC industry and provide an increased \nnumber (compared to similar studies) of already established case studies while address-\ning their key contributions and limitations.\n ● Explore the multi-aspect challenges, limitations and future directions of the field.\n ● Extract actionable insights and recommendations for industry stakeholders.\n1 3\n250 Page 4 of 46\nA review of LLMs and their applications in the architecture, engineering…\nTable 1 Summary of the key contributions and limitations of similar studies\nReferences Contributions Limitations\nDing et al. (2022) Large number of NLP applications in construction.\nAddressing all phases of construction.\nLimited to pre-2021 studies not utilizing \nLLMs.\nRane (2023) Potential applications, opportunities and challenges.\nSemantic analysis.\nFocuses solely on ChatGPT.\nLack of use cases.\nTaiwo et al. (2024) Addresses text, video, image generation and processing capabilities.\nDeep architecture analysis.\nLimited to only six LLM applications.\nGhimire et al. (2024) Potential text-based applications of GAI in construction.\nAddresses all phases of construction.\nFocus on future opportunities and potential \napplications.\nLimited number of case studies.\nSaka et al. (2023a) Opportunities and potential of GPT models. Addresses all phases of construction. Restricted to ChatGPT models.\nLimited number of case studies.\nPreuss et al. (2024) Extensive list of potential LLM applications for automating LCA processes.\nAddresses LCA aspect in all phases.\nFocused specifically on the subdomain of LCA.\nLimited number of case studies.\nZhang et al. (2024) Potential LLM applications in BEM.\nDeveloped use cases of LLMs for simulation input generation, visualization, and error \nanalysis.\nFocused only on the subdomain of BEM.\nLimited number of case studies.\n1 3\nPage 5 of 46 250\nD. Kampelopoulos et al.\n2 Methodology\nThe research approach that was followed to provide an extensive list of use cases, capture \nthe recent innovations, challenges and extract up-to-date insights and recommendations, \ninvolved the identification, the screening and the eligibility assessment of literature, utiliz -\ning the Scopus and Web of Science (WoS) databases. The overall methodology is summa -\nrized in the flowchart of Fig. 1, which also includes the resulting number of studies after \neach elimination step to reach the final set of studies that were considered for this review.\nFor the initial identification, a strategy involving search queries with two main collec -\ntions of keywords was employed, one that includes a broad range of LLM-related terms \nand domains and, one encompassing the AEC industry (Table 2). Each collection includes \nmultiple terms that are combined using the OR operator and the resulting search query is \nformed by combining those two collections with the AND operator. The exact keywords that \nwere used are presented in Table 2. Note that some LLM-related terms (e.g. AI, Machine \nLearning, Deep Learning, Self-supervised Learning, etc.) had to be omitted due to their \nbroad range of applications and technologies they are related to. In the same manner, it was \nnecessary to avoid keywords like construction, automation, architecture, etc. since they sig-\nnificantly increased the scope of the search beyond the target domain. This initial collection \nresulted in a total of 927 studies from the Scopus and 437 from the WoS databases.\nThe search was, then, limited to research articles and conference proceeding papers that \nwere written in English and published from 2021 to 2024. The main reason behind select -\ning such a narrow timeframe of only three years was the fact that large general-purpose \nNLP models for text-generation exhibiting a certain degree of reasoning were made public \nand gained popularity after 2021. From that year onwards, more and more companies and \nresearch institutes emerged in this field which led to the development of more models with \nincreased capabilities. As a result, the rapid growth and broad-domain adaptation of LLMs \nbecame apparent after 2021, as exhibited in the documents by year analysis from the Scopus \nsearch results (Fig. 2). Apart from that, given that this review is targeting state-of-the-art use \ncases and applications, this limited year selection is in alignment with this study’s goal. This \nfiltering step resulted in a total of 510 studies in the Scopus and 266 in the WoS databases. \nAfter merging both databases to eliminate duplicate documents, the identification process \nresulted in a total of 776 documents.\nThe following step is the screening process which involves manually inspecting each \nentry’s title and abstract to determine its relevance to this review’s topic. From the title \nscreening, a total of 494 documents were eliminated and from the abstract screening a total \n113 documents. The result of this screening process was a set of 95 documents that include \nonly entries related to the AEC industry that employ LLMs at one or more stages of their \napproach. The final step involves iterating through each entry and assessing the full text \nto determine their eligibility. On this step, only studies presenting use case scenarios and \napplications were selected, resulting in a total of 28 studies showcasing applications of \nLLMs in the AEC industry. Any relevant review articles from the final eligibility assessment \nwere also considered to establish the current challenges, limitations and future directions, \nto extract actionable recommendations for stakeholders and for the categorization of the \nresulting set of use cases.\n1 3\n250 Page 6 of 46\nA review of LLMs and their applications in the architecture, engineering…\n3 Large language models: an overview\n3.1 General information\nAt this point, it is important to address some of the key concepts along with major recent \ncontributions that have a significant impact on the performance, the operation, the capabili-\nties and the limitations of LLMs. These various aspects of LLMs are some of the key areas \nof innovation in the field that elevated them, led to their success and will be a topic of dis -\ncussion throughout this study.\nThere are three fundamental components behind LLMs’ operation that were key for their \nNLP and text generation capabilities: Tokenization, Positional Encoding and the Attention \nmechanism. Tokenization involves dividing an input text into tokens which are smaller units \nof text (words/sub-words/characters). Positional Encoding (PE) involves assigning a unique \nposition identifier for every token in a sequence, in an attempt to capture positional rela -\ntionships within tokens. This technique allows the model to differentiate between words \nbased on their position in a sentence, an important factor for translation, text generation \nFig. 1 Methodology flowchart for the identification and elimination steps resulting in the final list of case \nstudies for review\n \n1 3\nPage 7 of 46 250\nD. Kampelopoulos et al.\nand reasoning tasks. Currently there are various PE methods, including Absolute Positional \nEmbeddings (APE) used in GPT-3 (Brown et al. 2020), Relative bias used in T5 (Raffel \net al. 2019), Rotary used in PALM (Chowdhery et al. 2022) and LLaMA (Touvron et al. \n2023a) and ALiBi used in BLOOM (Scao et al. 2022). The choice behind the PE signifi -\ncantly impacts on the context length of a model, which is the maximum number of tokens it \ncan effectively handle during inference. PE is crucial for most transformer-based architec -\ntures, but certain decoder-only models can perform better even without PE (Tsai et al. 2019).\nFig. 2 Number of documents per year resulting from the search query on the Scopus database\n \nLLM-related keywords AEC-related keywords\n“Large Language Model*” OR \n“LLM*” OR “Generative AI” OR \n“Generative Artificial Intelligence” \nOR “AI-generated text” OR \n“Text-to-text Generation” OR “AI-\ngenerated content” OR “Prompt En-\ngineering” OR “Conversational AI” \nOR “Natural Language Processing” \nOR “NLP” OR “ChatGPT*” OR \n“GPT” OR “Llama*” OR “Trans-\nformer Model*” OR “Foundation \nModel*” OR “Pre-trained Language \nModel*” OR “Self-Supervised \nLearning” OR “Few-shot Learning” \nOR “Zero-shot Learning”\n“Construction Industry” OR \n“Construction site*” OR \n“Construction manage*” OR \n“Construction Project*” OR \n“Building Industry” OR “Civil \nEngineering” OR “AEC \nIndustry” OR “Infrastruc-\nture Project*” OR “Built \nEnvironment*” OR “Smart \nConstruction” OR “Construc-\ntion Technology” OR “Digital \nConstruction” OR “Built \nEnvironment Technology” OR \n“Infrastructure Engineering” \nOR “Structural Engineering” \nOR “Urban Development” OR \n“Building Information Model-\ning” OR “BIM” OR “AEC \nTechnology” OR “Construc-\ntion Safety” OR “Building En-\nergy Modeling” OR “BEM”\nTable 2 Keywords used for the \nsearch query on the selected \ndatabases\n \n1 3\n250 Page 8 of 46\nA review of LLMs and their applications in the architecture, engineering…\nAttention is one of the key mechanisms behind the NLP capabilities in LLMs. The \nattention mechanism involves calculations between positionally encoded tokens to assign \nweights and eventually extract the most important part of the input data. Attention mecha -\nnism is an ongoing field of research with contributions like Lin et al. ( 2020) who proposed \nself-attentive sentence embedding, Zaheer et al. ( 2020) who combined attention patterns \n(global, local, random) to handle longer sequences of longer sequences, and Yeom and An \n(2024) who introduced query-only attention.\nPre-training and post-training are key aspects of the development and optimization of \nLLMs. Pre-training is performed during the initial stage of a model’s development during \nwhich it is trained on massive datasets with unsupervised learning techniques and learns \nthe language structure and patterns. The process involves token and word prediction based \non context and plays a significant role in providing the model with broad general knowl -\nedge, fact and grammar understanding. This process is computationally expensive with \npre-training requiring weeks or months depending on model and dataset size. Post-training \nis the stage where the pre-trained model is fine-tuned on specialized domain-specific data -\nsets to adjust them on specific tasks, applications and user requirements. This process is \none of many tuning techniques utilized in LLMs and is performed in a supervised manner \nenabling the model to be more specialized in the desired domain while maintaining its gen-\neral knowledge.\nThere are a variety of methods developed by LLM developers for tuning models in order \nto make them more adaptable to specific tasks and improve their performance. Tuning is \napplied either during the pre-training or the post-training phase of models, with some meth-\nods (like task-specific tuning) introducing an additional intermediate phase. Some broadly \nutilized tuning methods include: Instruction-tuning, a post-training technique that involves \ntraining LLMs to follow human instructions by exposing it to specific prompts that provide \ntask-specific guidance (Wei et al. 2021), Fine-tuning, a post-training process that involves \nusing a smaller and more focused dataset targeting a specific domain or task (Howard and \nRuder 2018), and Prompt-tuning, a post-training method that focuses on providing opti -\nmized and specifically structured prompts to make the model produce more accurate outputs \nwithout altering its parameter values (Lester et al. 2021). Reinforcement Learning from \nHuman Feedback (RLHF) is also a post-training method that involves rewarding or penal -\nizing desirable or unwanted outputs respectively by employing human input on the model’s \nresponses (Christiano et al. 2017). Domain-adaptive tuning is a pre-training approach that \ninvolves using large-scale datasets of a specific domain to create models with broad knowl-\nedge on that specific domain (Ngiam et al. 2018; Xie et al. 2019).\nTask-specific tuning (or task-adaptive pre-training) is a technique applied between the \npre-training and post-training phases. The model is, first, pre-trained on general datas -\nets normally but then is exposed to a specific type of tasks (like summarization, question \nanswering, translation, etc.). Prefix-tuning is a post-training technique that introduces a set \nof learnable parameters to the input sequence and by only adjusting them and not the whole \nset of parameters, the model can become task-specific, in a way that is computationally \nefficient (Li and Liang 2021). Similar approaches include: Adapter tuning, a post-training \nmethod that involves introducing trainable layers into the model adjusting only this layers \ninstead of the whole parameter set (Houlsby et al. 2019), Low-Rank Adaptation (LoRA), \na post-training tuning approach that involves decomposing weight matrices into smaller, \nlower dimension ones, requiring again the adjustment of a small number of parameters \n1 3\nPage 9 of 46 250\nD. Kampelopoulos et al.\nfor tuning (Hu et al. 2021), and Retrieval-Augmented Generation (RAG), a post-training \napproach that involves requesting additional data related to the input from specified data -\nbases during inference (Lewis et al. 2020; Arora et al. 2023; Borgeaud et al. 2021). The \nmodel retrieves the most relevant documents to the input and generates an output based on \nthese documents and the initial prompt. Gao et al. (2023) conducted a systematic review of \nthe state-of-the-art RAG methods within the context of LLMs, identifying and analyzing in \ndetail the technical processes behind retrieval, generation and augmentation.\nZero-shot and few-shot learning are concepts that play a crucial role in the performance \nand applicability of LLMs. Zero-shot refers to the ability of a model to perform tasks that \nit was not trained on specifically during pre- and post-training. It is a metric of a model’s \ngeneral knowledge and is a key feature when there is unavailability of data, or the model \nis targeting a broad range of tasks. Few-shot learning refers to the ability of the model \nto perform a task that has received minimal training on. The few-shot capabilities of a \nmodel are a metric of its adaptability to diverse tasks and is a significant feature that allows \nthe model to leverage from the large-scale pre-training without the need of extensive task-\nspecific retraining. Recent research has highlighted innovative approaches like Test-Time \nTraining (TTT) enabling models to temporarily adapt their parameters during inference (by \ngenerating a training dataset from the input) achieving high accuracy on extremely low-data \nscenarios.\nLLM agents are autonomous systems leveraging LLMs to perform complex tasks, \nwith the ability to interact with external environments, make decisions and take actions \nwith no human supervision. Apart from natural language understanding, text generation \nand reasoning capabilities, agents can be linked with external components like APIs and \ndatabases. Their ability to interact, communicate, receive information from and to their \nenvironment, take actions in real-time along with their multi-step reasoning renders them \nversatile across a wide range of applications. LLM agents demonstrated promising per -\nformance on a variety of tasks, including code generation (Shinn et al. 2023), autopilot \nsystems (Jin et al. 2023), complex tasks in gaming environment (Wang et al. 2023) and \nmore. Systems utilizing multiple agents or multi-agent systems is a recent development \nwith researchers exploring and developing frameworks for multi-agent collaborations \n(Liu et al. 2023b; Talebirad and Nadiri 2023), demonstrating advanced problem-solving \nskills, autonomy and versatility.\n3.2 Transformer-based LLM architectures\nThe basic architecture that LLMs are based on is the Transformer model, introduced by \nVaswani et al. (2017). This architecture was designed primarily for parallel computing, opti-\nmizing parallel processing on Graphical Processing Units (GPUs). The key innovation of \nthis model lies within its attention mechanism which allows it to capture long-term depen -\ndencies in context with significantly better performance against recurrent and convolutional \nmechanisms. The high-level architecture of the transformer is illustrated in Fig. 3, with \nthe original design consisting of an encoder and a decoder with six identical layers. The \nencoder layers include a sublayer of multi-head self-attention mechanism and a sublayer of \na position-wise fully connected feed-forward network. The decoder has one extra sublayer \nin each of its layers that performs multi-head attention mechanism on the encoder’s output. \n1 3\n250 Page 10 of 46\nA review of LLMs and their applications in the architecture, engineering…\nThe model also incorporates tokenization and positional encoding to integrate information \nabout the position of tokens in the text sequence.\nLLMs are implemented based on four transformer-based architectures, Encoder-only, \nDecoder-only, Encoder-Decoder and Mixture of Experts (MoE), with each of them featur -\ning unique capabilities and specializing in either interpretation or generation tasks. The \nEncoder-only LLMs are designed basically for deep input text understanding tasks, such \nas classification, named entity recognition, and sentiment analysis. They use bidirectional \nself-attention mechanism, meaning that it can capture context from both preceding and fol-\nlowing tokens, allowing processing of the whole input sequence at once.\nThis architectural framework is particularly good for tasks requiring text comprehen -\nsion plays, because it allows the model to better understand the interrelations among \ntokens. Perhaps the most famous encoder-only LLM is Bidirectional BERT (Devlin et \nal. 2018) which adopted an approach where some tokens are masked and hidden, and the \nFig. 3 The original transformer architecture, courtesy of Vaswani et al. (2017)\n \n1 3\nPage 11 of 46 250\nD. Kampelopoulos et al.\nmodel is trained to predict these masked tokens based on other contextual information \nthat is shown.\nDecoder-only LLMs are best suited for applications involving text generation, such as \ndialogue systems, content creation, and machine translation. These models apply unidirec -\ntional self-attention where each token in the sequence looks only at previous tokens, making \nthese models suitable for autoregressive tasks where text is generated one token at a time. \nContrary to encoder-based models that simply focus on the comprehension of the input, \ndecoder-only models are used for the prediction of the next token within a sequence based \non the context obtained from earlier tokens. One of the most broadly known LLM families \nusing this architecture is the Generative Pre-trained Transformers (GPT), namely GPT-2, \nGPT-3, and GPT-4, introduced by OpenAI (Radford et al. 2018, 2019; Brown et al. 2020). \nThese models have shown exceptional performance in text generation-related tasks, and \nsignificant few-shot learning capabilities.\nEncoder-Decoder is a model architecture that is commonly employed for tasks requiring \nthe comprehension and production of sequences, including machine translation, text sum -\nmarization, question answering, text-to-speech and image captioning. In such a paradigm, \nthe encoder transforms the entire input sequence into a latent representation of itself, better \ncapturing the semantic meaning of it and the interrelation between tokens. Examples of \nsuch tasks are translation of a sentence from one language to another, dialogue systems \n(chatbots), text-based code generation, Named Entity Recognition (NER), data-to-text gen-\neration, etc. Notable examples of LLMs using this architecture include: the T5-Text to Text \nTransfer Transformer (Raffel et al. 2019) and the Bidirectional Auto-Regressive Transform-\ners (BART) (Lewis et al. 2019).\nThe MoE architecture is specifically aiming at improving the scalability of LLMs while \nfocusing on efficiency during computation. Only a subset of the parameters, also known as \n“experts,” are activated for a given input. In other words, The model is divided into subsets \nof parameters, called experts, that require only a small number of them being spawned \nfor any given input. The basic concept is that different experts specialize in different tasks \nor data types and a gating network dynamically selects which experts to activate given a \nparticular input (Shazeer et al. 2017). Thus, only a small fraction of resources is allocated \nwhen the specified task requires it. Notable contributions on this architecture are the Switch \nTransformer (Fedus et al. 2021) and GShard (Lepikhin et al. 2020).\nAnother promising architecture that is related to transformers is the State Space Models \n(SSM), a configuration that can be interpreted as a combination of RNNs and CNNs that \ndrew inspiration from classical state space models (Kalman 1960). Gu and Dao ( 2023) \nproposed an architecture designed based on SSMs, called Structured SSM or Mamba, that \ninvolves letting the SSM parameters be functions of the input and based on the current token \nit allows the model to selectively propagate or forget information along the sequence length. \nTheir architecture was able to achieve faster inference than transformers, linear scaling \nin sequence length without involving the attention mechanism. However, it was tested on \nrelatively low parameter models (up to 3B) but was able to match the results of transformer \nmodels of twice its size.\n1 3\n250 Page 12 of 46\nA review of LLMs and their applications in the architecture, engineering…\n3.3 Current LLM families\nThere are multiple groups of models, also known as LLM families, with each company \ndeveloping their signature family consisting of a series of models, each with variable \ncharacteristics. Some of these models are general-purpose, while others are task or \ndomain specific. They feature multiple parameter sizes, with some of them targeting effi -\nciency, others targeting safety and alignment of the generated content, others focusing on \naccuracy and high scores in evaluation datasets. As a result, there is an increasing number \nof available new models and families, with some of them featuring hundreds of variants \nthat are updated on a frequent basis. Thus, it is becoming impossible to keep up with the \nstate-of-the-art and include all these models in single comprehensive study. For that mat -\nter, this study is limited to only a few LLM families, selecting some of the most broadly \nutilized and wide-spread models of the industry, to showcase the capabilities, the restric -\ntions and the evolution of these families. Table 3 presents an overview of the selected \nLLM families, along with the developer company, release year, architecture, parameter \nsize, and task descriptions.\nOne of the most widely recognized families of LLMs is the GPT Family, developed by \nOpenAI utilizing a decoder-only architecture. Models of this family use an autoregressive \nframework that relies on masked self-attention mechanisms for the prediction of the next \ntoken in a sequence. Due to their architecture, these models are particularly effective for \napplications like text generation, conversational interfaces, content creation, translation, and \nsummarization, among others. There are multiple variations in the GPT family including \nthe GPT-1, GPT-2, GPT-3, GPT-4 and GPT-5 (under development at the time of writing) as \nwell as sub-versions of each GPT series. Their parameter size has increased dramatically \nbetween the different series ranging from 117M in GPT-2, to 175B in GPT-2 and GPT-3. \nGPT-4 is a MoE model with a parameter size of 1.7T. Based on these series there are task-\nspecific variants such as the GPT-4 Vision, which is able to receive input and generate both \ntext and images, the InstructGPT which is fine-tuned for instruction-based tasks and Codex, \nspecializing in code generation.\nAnother widely acknowledged family of LLMs is the LlaMA Family, developed by Meta \nAI. Like the GPT, it also adopted a decoder-only architecture but with a focus on optimiz -\ning efficiency. For that matter, it is a much smaller and highly performant model compared \nto GPT. There are multiple iterations of the LlaMA model with LlaMA-1, LlaMA-2 and \nLlaMA-3 being released with parameter sizes ranging from 7B to 70B. The LLaMA-3.1 is \nat the time of writing the latest model release featuring 405B parameters. There are other \ntask-specific variants of this family like Alpaca, a fine-tuned variant of LLaMA but more \nbiased towards instruction-following tasks, Vicuna, optimized for conversational agents and \nCode LLaMA designed explicitly for code generation.\nThe Mistral family, developed by Mistral AI, is also based on a decoder-only architec -\nture, designed to optimize the alignment efficiency and the employment of instructions with \ntools. These models are mainly used in instruction-following, research tasks, and tool usage. \nMistral 7B is the main model fine-tuned for instruction-following tasks, while Mistral 7B \nInstruct is fine-tuned for better tool usage and function calls. Mixtral 8 × 22B is a MoE \nmodel with 141B total parameters, of which only 39B are activated on any given task, due \nto its optimization for maximum performance relative to cost.\n1 3\nPage 13 of 46 250\nD. Kampelopoulos et al.\nThe Claude Family, developed by Anthropic, is a decoder-only architecture focusing on \nsafety and alignment of the model’s outputs intended for commercial use. It is suitable for \ntasks like long document processing, reasoning tasks, and also as conversational agents. \nThere are multiple series of this family’s models, namely Claude 1, 2, and 3, achieving \nimprovements with respect to context window sizes and reasoning capabilities with each \niteration, with Claude 3 supporting up to 200,000 tokens. There are also sub-variant models \nlike Claude Opus, Claude Haiku, and Claude Sonnet, each featuring different performance \nand targeting different consumers.\nThe PaLM family, developed by Google AI, is based on a decoder-only architecture and \nis particularly designed for tasks like natural language understanding, text generation, rea -\nsoning and multi-lingual translation. There are two series of this family’s models, PaLM-1 \nand PaLM-2, The main variants of this family are the PaLM-8B, the PaLM-62B and the \nPaLM-540B, named after their number of parameters. These variants were optimized over \na wide range of NLP tasks, while there are other task-specific variants like FLAN-PaLM \nwhich is fine-tuned using instruction data to meet zero-shot and few-shot performances of \nvarious tasks and Med-PaLM which is a specialized version for healthcare and medical \npurposes. The BERT Family, developed by Google, is based on an encoder-only architec -\nture designed to get a bidirectional contextual understanding of various text comprehension \ntasks. These models are suitable for tasks involving text classification, named entity recog-\nnition, sentiment analysis, and question answering. RoBERTa is its variant with improved \ntraining methods and large-sized training datasets. ALBERT is a light version featuring a \nsmaller model size without sacrificing performance. DistilBERT is a small and efficient \nversion of BERT, particularly specialized for speed, while DeBERTa utilizes disentangled \nattention mechanisms and a relative position bias to enhance its results.\nThe T5 family, developed by Google AI, is based on the encoder-decoder architecture. \nThat type of architecture makes the models very efficient for tasks such as text generation, \nsummarization, machine translation, and question answering, among others. Some variants \nof the family are the T5-Base, the T5-Large, the T5-3B, and the T5-11B, featuring a param-\neter size ranging from 220M to 11B, each reflecting added complexity. mT5 is the multilin-\ngual version of T5, FLAN-T5 is a version that is fine-tuned on instructional data for better \ngeneralization across tasks and T5-X is a variant developed to efficiently scale T5 models.\nThe BART family, originally proposed by Lewis et al. ( 2019), is based on the encoder-\ndecoder architecture and operates as a denoising autoencoder that is designed for tasks \nrequiring understanding and generation of text. These models are suitable for a very broad \nrange of applications such as summarization, machine translation, text generation, and ques-\ntion answering. Some variants of this family include the BART-Base implemented with \n6 encoder layers and 6 decoder layers and a total of 140M parameters, the large version, \nBART-Large, with 12 encoder and 12 decoder layers and a total of 406M parameters, and \nthe m-Bart, a multilingual variant that is optimized for translation and summarization tasks. \nThe BART-CNN is a version fine-tuned on summarization datasets and BART-Tiny is a \nvariant smaller in size focusing on low-resource applications.\nThe Falcon LLM family, developed by the Technology Innovation Institute (TII) in the \nUAE, is based on a decoder-only architecture and focuses on NLP tasks including text \ngeneration and reasoning in multiple languages. There are several iterations of the Falcon \nmodel series like the Falcon-7B, Falcon-40B and Falcon-180B, named after the number of \ntheir parameters. Later versions of this family include the Falcon-2 11B offering Vision-to-\n1 3\n250 Page 14 of 46\nA review of LLMs and their applications in the architecture, engineering…\nLLM model LLM \nfamily\nDeveloper Architecture Year Number\nof\nparameters\nTask\nDescription\nReferences\nGPT-1 GPT OpenAI Decoder-only 2018 125M Unsupervised language \nmodeling\nRadford et al. \n(2018)\nGPT-2 GPT OpenAI Decoder-only 2019 1.5B Unsupervised multitask \nlearning and text generation\nRadford et al. \n(2019)\nGPT-3 GPT OpenAI Decoder-only 2020 175B Few-shot, zero-shot and \nmultitask NLP\nBrown et al. \n(2020)\nInstructGPT GPT OpenAI Decoder-only 2022 – Instruction-tuned Ouyang et al. \n(2022)\nCodex GPT OpenAI Decoder-only 2021 12B Code generation Chen et al. \n(2021)\nGPT-4,\nGPT-4 Vision\nGPT OpenAI MoE 2023 1.8T Multimodal tasks,\nText and image processing\nOpenAI (2023a, \nb)\nLlaMA-1,\nLlaMA-2\nLlaMA Meta AI Decoder-only 2023 65B, 70B Efficient general-purpose \nNLP, Improved NLP perfor-\nmance and scalability\nTouvron et al. \n(2023a,\nb)\nLlaMA-3, 3.1 LlaMA Meta AI Decoder-only 2024 8B/70B, 8B/70B/405B Latest version with larger \ncontext window, multilingual \nsupport and task versatility\nDubey et al. \n(2024)\nAlpaca LlaMA Stanford Decoder-only 2023 – Lightweight instruction-tuned Taori et al. \n(2023),\nVicuna LlaMA LMSYS Decoder-only 2023 13B Instruction-tuned conversa-\ntional tasks\nChiang et al. \n(2023)\nCode LlaMA LlaMA Meta AI Decoder-only 2023 7B/34B Code Generation Rozière et al. \n(2023)\nMistral 7B, Mistral 7B Instruct Mistral Mistral AI Decoder-only 2023 7B Efficient NLP, Instruction \ntuning\nJiang et al. \n(2023)\nMixtral 8×7B Mistral Mistral AI Sparse MoE 2023 141B (39B active) Multitask MoE model Jiang et al. \n(2024a)\nMixtral 8×22B Mistral Mistral AI Sparse MoE 2024 176B Large-scale MoE model (Mistral 2024a)\nTable 3 Overview of model variants of broadly acknowledged LLM families, their release year, architecture, parameter size and task description\n1 3\nPage 15 of 46 250\nD. Kampelopoulos et al.\nLLM model LLM \nfamily\nDeveloper Architecture Year Number\nof\nparameters\nTask\nDescription\nReferences\nMathstral 7B Mistral Mistral AI Sparse MoE 2024 7B Advanced multi-step reason-\ning specializing in STEM \nsubjects\n(Mistral 2024b)\nCodestral,\nCodestral Mamba\nMistral Mistral AI Sparse MoE, Mamba 2024 22B, 7B Code generation and \nreasoning,\n(Mistral 2024c),\n(Mistral 2024d)\nClaude 1, 2, 3 Claude Anthropic Decoder-only 2024 – Safe and aligned NLP (Anthropic 2024)\nClaude Opus, Claude Haiku, Claude \nSonnet\nClaude Anthropic Decoder-only 2024 – NLP aiming for safety,\nSmall-scale variant,\nAligned NLP for efficiency\n–\nPaLM-1 (8B/62B/540B) PaLM Google AI Decoder-only 2022 8B/62B/540B General-purpose NLP Chowdhery et al. \n(2022)\nPaLM-2 (8B/62B/540B) PaLM Google AI Decoder-only 2023 8B/62B/540B Multimodal, multilingual \ntasks\nAnil et al. (2023)\nFLAN-PaLM PaLM Google AI Decoder-only 2022 540B Instruction-tuned Liu et al. (2020)\nMed-PaLM, Med-PaLM 2 PaLM Google AI Decoder-only 2022, \n2023\n– Instruction-tuned in medical \ndomain\nSinghal et al. \n(2022, 2023)\nBERT-Tiny/Mini/Small/Medium/\nBase/ Large\nBERT Google Encoder-only 2018 4M/11M/29M/41M/110M/\n340M\nText classification, NLP Devlin et al. \n(2018)\nRoBERTa,\nALBERT,\nDistilBERT\nBERT Google Encoder-only 2019 355M, 235M, 66M Text classification,\nLanguage reasoning,\nText classification\nLiu et al. (2019),\nLan et al. (2019), \nand Sanh et al. \n(2019)\nDeBERTa BERT Google Encoder-only 2020 1.5B General-purpose NLP He et al. (2020)\nT5-Small/Base/Large/3B/11B T5 Google AI Encoder-Decoder 2019 60M/223M/770M/3B/11B Text-to-text transfer tasks Raffel et al. \n(2019)\nmT5 T5 Google AI Encoder-Decoder 2020 300M Multilingual text-to-text \ntransfer tasks\nXue et al. (2020)\nFLAN-T5-Small/Base/Large/xl/xxl T5 Google AI Encoder-Decoder 2022 – Instruction-tuned version Chung et al. \n(2022)\nTable 3 (continued)\n \n1 3\n250 Page 16 of 46\nA review of LLMs and their applications in the architecture, engineering…\nLLM model LLM \nfamily\nDeveloper Architecture Year Number\nof\nparameters\nTask\nDescription\nReferences\nBART-Base/Large BART Meta AI Encoder-Decoder 2019 140M/406M General-purpose NLP Lewis et al. \n(2019)\nm-BART,\nBART-CNN\nBART Meta AI Encoder-Decoder 2020 680M, 406M Multilingual tasks,\nText summarization and \ncomprehension tasks\nLiu et al. (2020)\nFalcon-7B/40B/180B Falcon TII UAE Decoder-only 2023 7B/40B/180B General-purpose NLP tasks Almazrouei et al. \n(2023)\nFalcon-2 11B Falcon TII UAE Decoder-only 2024 11B Image-to-text and general \nNLP tasks\nMalartic et al. \n(2024)\nTable 3 (continued)\n \n1 3\nPage 17 of 46 250\nD. Kampelopoulos et al.\nLanguage capabilities and Falcon Mamba 7B introducing the selective SSM architecture \nwhich is expected to release in 2025.\n4 Applications/case studies of LLMs in the AEC domain\nThe adoption of LLMs in the AEC industry presents opportunities across different proj -\nect phases, with multiple applications targeting automation, risk management, and decision \nsupport. In the pre-design phase, LLMs can streamline feasibility analysis, generate project \nbriefing documents, and assist in conceptual design selection through rapid data retrieval \nand generative modeling (Ghimire et al. 2024) . During the design phase, they perform code \ncompliance verification, cost estimation, energy efficiency modeling, and automated design \ngeneration (Saka et al. 2023a, b). Mid-construction, LLMs can perform tasks like real-time \nsafety monitoring, predictive risk assessment, schedule optimization, resource allocation, \nand automated reporting, ensuring smoother execution and proactive issue resolution . Post-\nconstruction, for operation and maintenance, LLMs can perform tasks like predictive main-\ntenance, digital twin integration, and automated regulatory compliance. In the demolition \nphase, LLMs can assist in deconstruction planning, sustainable material reuse, and waste \nclassification. Additionally, LLMs can offer value-added services that span across all phases \nand facilitate real-time decision support, dispute resolution as well as provide AI-powered \ntraining by enhancing worker education, assist in safety briefings and on-site troubleshoot -\ning through intuitive chat interfaces and automated content generation.\nGiven the wide range of potential tasks that LLMs can accomplish along with the mul -\ntiple options of LLM families available, there are multiple use case scenarios and applica -\ntions of LLMs being employed in the AEC industry. The implementations described in this \nsection are categorized based on their associated task, into the following categories:\n ● Training, education and literature analysis.\n ● Planning and scheduling tasks.\n ● Safety analysis and hazard recognition.\n ● Document generation and compliance check.\n ● Specialized virtual assistant and question answering systems.\n ● Code and data generation, interpretation and visualization.\n ● BIM and BEM functionalities.\nSome of the studies under review can be associated with multiple task categories or show -\ncase multiple case scenarios, each associated with different tasks. A key example is the BIM \nand BEM functionalities category, which includes studies that utilize LLMs for a variety of \ntasks like data interpretation, code generation, compliance check, planning and more but for \nthis study’s needs it was decided to combine these works into a single inclusive category. \nFigure 4 presents the reviewed use cases, assigning them to the above task categories.\n4.1 Training, education and literature analysis\nThis category includes all case studies that involve the use of LLMs for training and educa-\ntional purposes. It involves studies focusing on enhancing users’ training and understand -\n1 3\n250 Page 18 of 46\nA review of LLMs and their applications in the architecture, engineering…\ning of complex topics, specialized subjects and documentation either as a virtual assistant, \neither to provide feedback, real-time support and evaluate essays, or to perform literature \nanalysis of a large number of studies.\nUddin et al. ( 2023) conducted a study involving construction students to determine if \nChatGPT can assist them in identifying construction hazards. The experimental procedure \ninvolved a pre-intervention where students were called to identify potential hazards on case \nimages taken from construction sites. The students were then introduced to ChatGPT and its \nhazard recognition capabilities and re-reviewed the case images. The results demonstrated \nan over 25% increase in the detected hazards when students utilized ChatGPT. However, \nalmost 40% of hazards still remained undetected, especially those requiring construction-\nspecific knowledge due to the model’s general-purpose nature, emphasizing the need for \ndomain-specific training and raising reliability concerns. Apart from that, there are concerns \nabout the prompt sensitivity where the performance of the model was impacted from the \nprompts’ wording leading to inconsistent safety recommendations, and ethical and liability \nconcerns since there is lack of accountability in the case of an accident following the AI-\ngenerated instructions.\nCastro et al. ( 2024) targeted the challenge of writing technical reports in the field of \nurban construction and explored the capabilities of GPT-4 in providing feedback in a timely \nand scalable manner on student’s technical reports. Their experiment involves assigning \nprojects to a group of students that were evaluated in terms of sustainability by human \nevaluators and by GPT-4. The results indicate that GPT-4 is able to identify relevant sustain-\nability criteria for each student project but tended to prioritize the quantity of sustainability \nmeasures over the quality and depth of explanations. Another key observation was that \nGPT-4 encountered issues with the format, exhibiting difficulties in reports with multiple \nFig. 4 Representation of the reviewed use cases categorized based on task\n \n1 3\nPage 19 of 46 250\nD. Kampelopoulos et al.\nfigures and tables. Other limitations of the proposed work are associated with the domain-\nspecific knowledge of the model which exhibited gaps in construction-specific terminology \nand standards, the integration of such technology in educational practices, and the computa-\ntional demands required for real-time review of multiple students. Also, ethical concerns are \nraised for potential overreliance on AI, limiting independent skill development.\nMeng et al. ( 2024) focused on the domain of Demand-Size Management (DSM) and \nutilized LLMs to perform extensive bibliometric analysis in the field. They created a \nDSM literature corpus compiling and standardizing datasets from Scopus and OpenAlex. \nTheir key contribution is their methodology for semantic analysis by employing LLMs, \nfirst, to create embeddings (vector representations) of each paper, and then to cluster \nembeddings that are semantically similar, identifying and labeling the main topic words \nfrom the paper. They categorized these papers based on these clusters into a hierarchical \nstructure that they visualized by applying dimensionality reduction techniques. The result \nis a comprehensive bibliometric and citation network analysis, with their proposed frame -\nwork being scalable, reproducible and applicable in other scientific fields for literature \nanalysis and trend mapping. However, there are limitations regarding the computational \ndemands and cost of the advanced LLM tools they utilized, significantly impacting their \nability to execute the method at scale, as well as challenges regarding the integration of \ndata from different databases. The authors also highlighted reliability concerns due to the \nlack of robust validation mechanisms for LLM-driven semantic analysis, requiring human \noversight and validation.\n4.2 Planning and scheduling tasks\nThis category includes all studies utilizing LLMs for their planning and scheduling capabili-\nties. These models have the ability to dissect complex tasks into more manageable subtasks, \na process that can streamline and find useability in a wide variety of construction-related \napplications.\nOne of the first attempts at exploring the use of LLMs in construction management is the \nwork of Amer et al. (2021) that employed an earlier version (GPT-2) of a transformer-based \nmodel to automate the alignment between long-term master schedules with short-term look-\nahead plans. The study demonstrated the potential of LLMs in construction scheduling and \nmanagement processes, however they highlighted reliability concerns due to the limited \nprecision of the models, the sensitivity to prompt variations in phrasing, and the requirement \nfor human oversight and validation. Computational demand is another constraint, with the \nmodels requiring significant processing time especially when scaling to large schedules, \nlimiting their practical deployment. Other concerns are raised in terms of generalizability, \nsince their approach relied heavily on data from specific projects that might result in lower \naccuracy on projects with significantly varying conditions.\nPrieto et al. (2023) also evaluated the GPT-3.5 model’s capabilities in construction sched-\nuling attempting to generate resource-loaded schedules from inputs in natural language. The \ncase study involved a simple construction task (building of a wall) with ChatGPT gen -\nerating task sequences that were coherent and logical. Key limitations exhibited include \nomitting important steps, proposing tasks that were not needed, and missing details of the \nprocess like the curing time needed for materials, indicating lack of construction-specific \nknowledge and raising concerns regarding reliability and accuracy, especially in complex \n1 3\n250 Page 20 of 46\nA review of LLMs and their applications in the architecture, engineering…\nreal-world scheduling tasks. Prompt sensitivity is another limitation, along with ethical con-\ncerns regarding overreliance on AI-generated schedules.\nYou et al. ( 2023) integrated ChatGPT’s planning capabilities into robotic systems to \nautomate construction assembly, with the model used for optimizing sequence planning \nand for adapting to dynamic environments. They explored two use cases including material \nstacking and pipeline installation with the model being able to generate the sequence of \nactions from natural language prompts. The model could efficiently handle complex tasks, \nadapt to real-time changes, such as dealing with obstacles. Main limitations of this study \ninclude its dependence on pre-defined dictionaries for object detection and action map -\nping, indicating lack of specialized knowledge in construction and struggling to extract task \ndependencies in scenarios it was not trained on. Prompt sensitivity is another limiting factor \nalong with integration issues when attempting to incorporate their framework with existing \nrobotic and BIM workflows.\nXie et al. (2023) focused on evaluating LLMs, particularly GPT-3.5 variants, in translat-\ning instructions in natural language text into planning goals in Planning Domain Definition \nLanguage (PDDL). Their study is supported by experiments in two domains: Blocksworld \na planning problem involving stacked blocks with spatial relations, and ALFRED, a house-\nhold environment where LLMs translate simple tasks into PDDL. As indicated by the \nresults, LLMs demonstrated better performance in translating goals than planning tasks, and \nthey were able to provide additional insight on missing details from underspecified goals \nbased on general logic and common sense. Key limitations were the lack of domain-specific \nreasoning, the difficulties dealing with tasks requiring numerical, physical, spatial and hier-\narchical reasoning between objects and the inconsistency of results with minimal prompt \nvariations. Apart from that, the authors highlighted the need for human oversight and valida-\ntion and emphasized integration challenges due to format differences, semantic compatibil-\nity and complexity of structured planning language compared to natural language.\nA similar approach was followed by Guan et al. ( 2023) who developed a framework \nutilizing LLMs to generate symbolic world models in PDDL from action descriptions in \nnatural language. They utilize LLMs in various steps of the process including during the \ninitial generation of the PDDL models, during an error checking step where LLMs are used \nto modify PDDL models based on feedback from sources, like PDDL model tools or human \nexperts, and for generation of the final plans based on the extracted error-free PDDL models. \nTheir framework was tested in three scenarios: a household robot, Tyreworld and Logistics, \nand exhibited better performance with fewer errors than GPT-3.5 but with limited spatial \nreasoning capabilities. A key limitation drives from the fact that it requires initial human \ninput to construct accurate world models and begin the process as well as on multiple steps \nof the approach limiting the automation capabilities and creating feedback bottlenecks lim-\niting its efficiency. Also, the lack of construction-specific knowledge of the models often \nresulted in inaccuracies or incomplete domain specifications. Other limitations include the \ncomputational overhead required that can limit its scalability and real-time applicability in \nmore complex environments as well as integration challenges to ensure compatibility and \nsemantic consistency between instructions in natural language and PDDL models.\n1 3\nPage 21 of 46 250\nD. Kampelopoulos et al.\n4.3 Safety analysis and hazard recognition\nThis category involves studies that focus on extracting useful information from reports \nand relative documentation for the purpose of performing hazard recognition, risk assess -\nment and safety analysis. This task category can be really helpful especially in the con -\nstruction industry, for early identification of hazards, for proposing safety guidelines and \npractices where necessary and to mitigate and prevent risks.\nSmetana et al. (2024) explored the potential of LLMs for hazard recognition and safety \nanalysis in the domain of highway construction. The proposed approach involves the use of \nNLP and ML techniques such as text-embedding, clustering algorithms, and dimensional -\nity reduction to analyze the OSHA Severe Injury Reports (SIR) database in an attempt to \ncluster, summarize and identify causes and patterns across the dataset. The results exhibited \nhigh precision and recall in identifying key causes of accidents and allowed for the extrac -\ntion of insights beyond the capabilities of traditional statistical methods. A key limitation \naddressed by the authors is the need for domain-specific tuning to address knowledge gaps \nin construction safety and accurately identify and consider site-specific details. Even with \nfine-tuning, human oversight is still crucial since there are still concerns regarding the accu-\nracy and reliability of the responses, which in safety-critical applications it can also raise \nethical and liability concerns.\nHassan et al. ( 2022) utilized an LLM model (BERT) to parse through construction \ninjury reports and identify risks and hazards. They followed a sentence-pair classification \napproach for fine-tuning the model where each narrative is paired with a question descrip -\ntion and the model associates the narrative’s content to the relevant label based on the ques-\ntion. They utilized the Occupational Safety and Health Administration (OSHA) dataset with \n5845 injury cases, each including the narrative’s descriptions, the worker’s activity, the type \nof incident and the severity of the injury. The fine-tuned model was compared with other \ntext classification models exhibiting higher F1-scores. Additionally, they propose a model-\nagnostic interpretability technique utilizing Local Interpretable Model-agnostic Explana -\ntions (LIME) to pinpoint specific key words in the narrative and correlate them to potential \nhazards, like the term “scaffold” with its frequent appearance in fall-related narratives is \nmarked as a potential hazard. The authors identified the data quality as an important limita-\ntion since inconsistent annotations or ambiguous reports of incidents present in the OSHA \ndataset can undermine performance. Another limitation is identified in terms of generaliza-\ntion with the model struggling to handle incident reports from other sources or in varying \nstyles. Also, despite their interpretability approach utilizing LIME, the full reasoning behind \nthe model’s classifications and predictions and generally the explainability of BERT models \nis a topic of ongoing research.\nMoon et al. (2022) also presented a method utilizing BERT for identifying and classify-\ning risk-related clauses from construction specifications. First, they identified seven key \nrisks related to payment, time, safety and more, and trained a separate binary BERT classi-\nfier for each risk. Each model was fine-tuned on the clause dataset of the associated risk and \nthe resulting models’ performance was compared with two baseline models (SVM, DNN \nwith two hidden layers) exhibiting significantly higher F1-scores. Key limitations include \nthe small dataset size (including 2807 clauses from 56 documents) as well as data quality \nand bias issues causing inconsistent results due to ambiguous human annotations of risk \ncategories (like clauses related to multiple categories, or undefined category boundaries). \n1 3\n250 Page 22 of 46\nA review of LLMs and their applications in the architecture, engineering…\nAnother limiting factor is the computational requirements of locally deploying models like \nBERT raising concerns about resource consumption and energy efficiency that could poten-\ntially limit widespread adoption in resource constrained environments.\n4.4 Document generation and compliance check\nThis category includes studies that involve the generation of high-quality documents or pro-\ncessing of complex documents to perform compliance checks with regulatory requirements \nand practices. This is an important capability of LLMs considering the extensive documen-\ntation associated with even the simplest construction projects as well the increasing number \nof rules and guidelines.\nPu et al. ( 2024) proposed a framework for generating construction reports using LLMs \nfrom images captured by unmanned vehicles. Their approach involves making a 3D model \nfrom images taken from multiple angles, and then fine-tuning a pre-trained GPT-4 model \nwith a paired dataset of images and their associated reports. The proposed system was \nable to generate detailed inspection reports from images, with the reports being evaluated \nin terms of data accuracy, depth of analysis, clarity, objectivity and bias by independent \nreview teams. The authors highlight the need for fine-tuning on construction-specific data to \naccurately interpret complex scenarios. Also, the use and deployment of sophisticated mul-\ntimodal LLMs along with robot technology for data collection results in significant compu-\ntational and resource requirements that may be a barrier for organizations lacking technical \ninfrastructure. Additionally, the authors highlighted potential limitations in terms of real-\ntime responsiveness due to latency and computational constraints of the robot systems and \nthe LLM, that can negatively impact the adaptability to dynamic scenarios. Other limita -\ntions include integration and interoperability issues between multimodal sensor inputs that \ncan potentially affect data consistency and report accuracy, as well as the need for human \nverification and validation of the generated reports.\nChen et al. ( 2024) proposed a compliance checking framework that integrates LLMs, \nDL and ontology knowledge models. Their proposed approach involves an initial pre-pro -\ncessing step where TextCNN, LSTM and BERT models are utilized for text-classification, \nclassifying the text into single-layer, double-layer and triple-layer based on the number of \nconditions described. The classified text is fed into the LLM (GPT-4) to extract important \ndetails including object properties, dimensions and conditions. They followed a few-shot \nlearning approach where the LLM is trained on a small dataset with few examples for each \nlabel category. This information is aligned with the ontology model that provides a domain-\nspecific structured representation of building knowledge and is being compared using \nSPARQL queries against compliance rules. The proposed framework was validated in a \ncase study involving a nine-story residential building demonstrating its ability to streamline \ncompliance checking and reduce manual effort. However, the method relies heavily on the \nquality of the ontology and BIM data, with missing or incomplete data significantly reducing \ncompliance checking accuracy. Another key limitation is the computational complexity and \nresource demands associated with integrating deep learning, ontology and LLM systems, \nwhich also raises concerns about the responsiveness of the overall system and its ability to \nperform compliance checking in real time. Apart from that, the lack of construction-specific \nknowledge of LLMs on technical and regulatory aspects is also a limiting factor raising the \n1 3\nPage 23 of 46 250\nD. Kampelopoulos et al.\nneed for fine-tuning, as well as limitations and challenges regarding interoperability and \nseamless integration between BIM, ontology and LLM systems.\n4.5 Specialized virtual assistant and question answering systems\nThis category involves use cases that utilize LLMs as virtual assistants with specialized \nknowledge on a specific domain that can operate as question answering systems. This can be \nparticularly important for the construction industry for supporting users and operators with-\nout the need for extensive technical knowledge and expertise and can provide assistance in \na wide variety of construction-related tasks.\nLu et al. ( 2024) investigated twelve LLMs on their ability to pass the ASHRAE CHD \nexam, a standardized examination in the field of HV AC system design and operation. This \nexamination focuses on evaluating the knowledge capabilities (recall, analysis and applica-\ntion) of HV AC designers on four scenarios including system design, design calculation, \nprocedural and coordination). The models exhibited promising results outscoring half of \nthe human examinees, with GPT-4 managing to consistently pass the exam, indicating \nthe effectiveness of LLMs in that domain. However, the authors highlighted the need for \ndomain-specific training to address gaps in technical knowledge regarding HV AC systems \nand reported significant limitations on the reasoning capabilities of the model and errors \nwhen handling numerical data and equations.\nZhong and Goodfellow (2024) realized the need for a domain-specific LLM on the field \nof Construction Management Systems (CMS) and produced a CMS domain corpus with aca-\ndemic papers that they employed to fine-tune pre-trained BERT and RoBERTa models. The \ndomain-specific tuned models outperformed the ones trained on general corpora on the tasks \nof Named Entity Recognition (NER) and text classification. Another key contribution of this \nstudy is the impact analysis of various steps during the model training process including dif-\nferent pre-training techniques, hyperparameters, LLM choice, and data-cleansing methodol-\nogies. Throughout their study they highlighted key limitations regarding the limited volume \nof construction-specific datasets which also resulted in semantic gaps between words that \nhave different meanings in the context of construction. The authors also emphasized the sig-\nnificant computational demands and recourse requirements for deploying LLMs locally and \ntraining them on domain-specific datasets. Additionally, they address generalization limita-\ntions beyond the training data, multilingual limitations due to the exclusive use of English \ndatasets, as well as risks of data overlap between public databases used during pre-training \nand domain-specific datasets used for fine-tuning.\n4.6 Code and data generation, interpretation and visualization\nThis category includes studies that utilize LLMs for automating tasks via generation of code \nand data or for the interpretation and visualization of data time-series. This can involve \nLLMs for generating simulation data, or frameworks for the development of automation \nroutines by non-expert users which can be highly effective in the construction industry.\nYang et al. (2024) proposed an LLM-based approach for simulating human behavior in \nlarge-space environments to generate data that were used to train RL algorithms to balance \nenergy consumption and occupant comfort. They utilize LLMs to simulate a mall environ -\nment and multiple autonomous LLM-powered agents, each representing a population group \n1 3\n250 Page 24 of 46\nA review of LLMs and their applications in the architecture, engineering…\nwith unique characteristics like mobility patterns and thermal preferences, to simulate their \narrival time and distribution within the mall. With that data they trained RL algorithms to \ncontrol the HV AC systems in the mall, in centralized and distributed control scenarios, \noptimizing and balancing between occupant comfort and energy savings. Their approach \nindicated superior performance compared to similar simulation techniques, like set point \ncontrol policies, and highlighted the potential of LLMs in generating human-related data \n(mobility patterns, thermal preferences) which are challenging to acquire or simulate. The \nauthors highlight limitations in the accuracy of simulated human behavior, often failing \nto consider complex interactions or capture occupant preferences accurately. Prompt sen -\nsitivity is another issue affecting the performance of their approach reducing consistency \nbetween simulations. Other limiting factors were the computational complexity reducing \nthe responsiveness of the system, along with privacy, ethical and social risks associated with \nhuman behavior simulation.\nGiudici et al. (2024) proposed an LLM-based home automation agent framework, named \nGreenIFTTT, that interacts with users to suggest energy consumption reduction and cost \noptimization routines. The framework also allows users to easily create and control home \nautomation routines without prior programming knowledge or configuration tool experi -\nence. Their approach involves an LLM-based chat-bot that provides suggestions, real-time \nfeedback from connected sensors and optimization tips for energy consumption, all inte -\ngrated in a user-friendly interface. Based on user input, the LLM can generate a JSON \nresponse which the backend parses, implements the routine and provides feedback to the \nuser. Their framework was evaluated in terms of user experience, interaction satisfaction \nand sustainable behaviors in an exploratory study involving 13 participants demonstrating \nthe potential of LLMs in the home-automation domain. Key limitations of this study include \nthe small sample of participants and the fact that the suggestions are based on simulated \ndata and preferences that may not be accurate in real-world scenarios. Real-time respon -\nsiveness is another limitation with authors reporting latency issues that can compromise \nperformance especially when requiring fast decisions based on real-time data. Sensitivity to \nprompt variations is also a significant limitation, especially in this study that minor prompt \nvariations might lead to completely different automation routines. Also, running code gen -\nerated from the LLM to create automations raises significant security and safety concerns. \nLast but not least, while the objective of the case study is to promote sustainability and \nenergy efficiency, the computational and power requirements of deploying and training an \nLLM can significantly increase energy consumption and may offset the benefits of the sug-\ngested sustainable practices.\nHu et al. (2024) proposed a methodology for data restoration of user power profiles uti -\nlizing LLMs in an attempt to minimize the data requirements for energy load profile analy-\nsis. Their approach involves two stages of fine-tuning. The former involves acquiring the \ndata of multiple users with similar profiles and converting them into words that are fed into \nthe LLM. The second stage of fine-tuning is performed by using the data from the target user \nto refine the model’s performance specifically for that particular user. Through elaborate \nprompt engineering, the LLMs can generate accurate data restorations, achieving compara-\nble performance to similar state-of-the-art models. Their study demonstrates the impact that \nLLMs can have on cost-effectiveness and time efficiency compared to training models for \ndata restoration from scratch. However, while the LLM was able to restore data, capturing \ncomplex temporal dependencies between load profile data is still a challenging task, with \n1 3\nPage 25 of 46 250\nD. Kampelopoulos et al.\nLLMs generally struggling to process numerical data accurately. Also, prompt engineering \nis an important aspect of the proposed approach with minor prompt variations significantly \naffecting data restoration tasks. The generalizability of the approach is also limited since it \nrequires further fine-tuning to handle different types of load profiles or power systems. Apart \nfrom that, while their approach does not require pre-training the models from scratch, there \nare still significant computational requirements for their tuning approach.\nOuyang and Srivastava ( 2024) employed LLMs for data interpretation of raw environ -\nmental sensor signals for occupancy tracking. Their approach involves an initial layer of \nmultiple small-scale LLMs that are fed the raw data traces directly from each sensor and a \nhigh-level reasoning LLM layer processing the results of the previous layer and generating \nactionable insights. They also present two strategies for handling long-term sensor traces, \nincluding summarization before reasoning and selective inclusion of historical traces. The \nproposed framework, named LLMSense, achieved over 80% on the task of occupancy \ntracking from environmental sensors as well as the task of dementia diagnosis with behav -\nior traces. The key limitations of this work include the inability of the model to handle long \nsequences of historical data due to the LLM’s input token restrictions, requiring alternatives \nlike summarization or selective inclusion, as well as the sensitivity to prompt variations, \nthat both heavily impact the system’s accuracy and reliability. Also, while exhibiting high \naccuracy, their approach still exhibited occasional inaccuracies raising additional reliabil -\nity concerns. Additionally, while successfully addressing two completely different tasks, \nthe generalizability of this study is not guaranteed without substantial adaptation or addi -\ntional fine-tuning. Lastly, another limiting factor is the computational and infrastructure \nrequirements along with the complexity of deploying multiple LLM systems in edge-cloud \nscenarios.\n4.7 BIM and BEM functionalities\nThis category involves a wide variety of tasks that are closely related to simulation software \nfor building or energy modeling of infrastructure. It includes tasks from all the previous \ncategories by incorporating them into parts of the simulation and design processes of this \nsoftware, including the extraction of BIM objects from documentation, compliance checks, \ngeneration of IDF files, configuration of human behavior and preferences for simulating \noccupant behavior and more. Given the growing adaptation of BIM and BEM frameworks \nin the construction industry and the incorporation of digital twin systems, LLMs can offer \nmultiple opportunities for streamlining, automating and enhancing these tasks.\nJang et al. (2024) developed a framework utilizing LLMs to generate detailed architec -\ntural designs of exterior walls by processing text input in natural language and integrating \nthem into the BIM models. Their approach involves three main modules, an interface mod-\nule that allows users to input design tasks in natural language, a task execution module that \nprocesses these inputs and generates design details and a design implementation module \nthat integrates the design details into the BIM environment. The proposed framework was \nevaluated on its ability to generate exterior wall details given specific requirements, like \nstructural materials, insulation methods and minimum thickness as well as its ability to \nproduce wall details that meet thermal performance standards. While exhibiting relatively \nhigh accuracy (83%), the model exhibited occasional inaccuracies in complex structures \nand components like the interior insulation details. The proposed approach is also highly \n1 3\n250 Page 26 of 46\nA review of LLMs and their applications in the architecture, engineering…\nsensitive to prompt variations leading to inconsistencies in architectural detailing outcomes \nand requiring elaborate prompt design. The authors highlighted the model’s lack of domain-\nspecific knowledge regarding construction methods and architectural practices. Another \nlimitation was its lack of generalizability to handle other essential components other than \nexterior wall detailing. Also, there are significant computational requirements for integrat -\ning the proposed system in the design workflows and achieving real-time responsiveness is \na challenging task.\nHan et al. (2024) proposed a framework that incorporates LLMs for BIM-based Design \nfor Manufacture and Assembly (DfMA), aiming to establish a methodology to optimize the \ndesign and construction of free-form prefabricated buildings. Their approach involves a \ncomprehensive BIM workflow guided by LLMs to streamline the design and manufacturing \nprocess. It utilizes Integrated Project Delivery (IPD) principles in its methodology to ensure \nefficient project execution, it employs algorithms to generate information for Engineer-to-\nOrder (ETO) components and automatically create manufacturing and assembly plans and, \nalso, it integrates knowledge from subcontractors and stakeholders to ensure the feasibility \nof production and assembly of components. Their methodology was evaluated on a case \nstudy involving a building and the creation of more than 50 customized ETO components \nas well as a total of 692 conversation scenarios to test the LLM’s effectiveness in real-world \nevents, such as designer requests, assembly challenges and manufacturing adjustments. A \nkey limitation of the study is the computational and resource requirements that involve \nsubstantial initial costs for acquisition of BIM software, for personnel training and for hard-\nware infrastructure. Apart from the initial investment, there are additional costs required \nfor maintenance, for updates and for technical support for the software and the hardware. \nThe authors also identified significant data privacy and security issues, raising the need of \nrobust measures to prevent unauthorized access, data breachers and loss of sensitive project \ninformation. Also, the method was validated on a single design project, limiting its general-\nizability and scalability to diverse projects.\nJiang et al. ( 2024b) proposed a platform utilizing LLMs to automate the BEM process \nby converting text descriptions of a building in natural language into EnergyPlus models. \nThe LLM, Flan-T5, is able to generate Input Data Files (IDFs) based on text description \nof a building’s geometry, occupancy rates and internal loads. The LLM uses these files to \nsimulate energy consumption and indoor conditions. The model was fine-tuned on a data -\nset with pairs of building descriptions and IDFs that were created using a Latin hypercube \ndesign simulation to cover multiple parameter combinations (geometries, window-to-wall \nratios, internal loads). The EnergyPlus API is then used with the IDFs to calculate energy \nconsumption and other performance metrics. Their platform was able to consistently gen -\nerate valid models and was further evaluated by modified prompts with variations (differ -\nent tones, additional words, misspellings) and maintained its accuracy. A key limitation is \nthat the proposed system is targeting simple rectangular building geometries limiting its \ngeneralizability to more complex scenarios. The authors also highlighted the significant \ncomputational requirements for deploying and fine-tuning the model. Also, while resistant \nto minor prompt variations, the performance of the model still depends on the clarity and \nquality of the prompts.\nZhang et al. ( 2024) in addition to their literature review on the incorporation of LLMs \nin the energy modeling domain, they present three related use case scenarios, revealing the \npotential of LLMs in automating and optimizing BEM tasks. The first scenario involves \n1 3\nPage 27 of 46 250\nD. Kampelopoulos et al.\ngenerating input objects for EnergyPlus simulations through simple prompt-engineering \nand modifying existing IDF files by employing a multi-agent LLM approach with a central \nLLM agent breaking down the task into subtasks and distributing them among multiple \ntask-specific LLM agents. Their approach enabled fast and accurate input generation and \nfile modification for the EnergyPlus simulations with minimal user expertise required. The \nsecond scenario involved the use of LLMs for visualizing the simulation’s output. With this \napproach they were able to produce energy consumption and weather plots that are modifi-\nable via prompts. The third scenario involves a retrieval-augmented approach to extract \naccurate and detailed answers from a specific BEM documentation database for training \nand educational purposes. Key limitations of this work include the self-consistency issue \nwhere different responses are provided for the same query, the prompt sensitivity requiring \nadvanced prompt engineering to obtain consistent and accurate results, the short context \nwindow length compared to the large volume of text inputs required in BEM, and the com-\nputational requirements for the deployment, the inference and the fine-tuning.\nZhang and Chen (2024) proposed an approach utilizing LLMs to enhance the interpret -\nability and transparency of Machine Learning Control (MLC) algorithms in HV AC systems. \nThis case study involves an EnergyPlus simulation of a virtual building with an ML-based \nModel Predictive Control (MPC) system to control the HV AC units. The score functions \nand constraints are fed through prompts into the LLM, so that it has knowledge over the \npredictive algorithm’s settings and goals. Additionally, the SHAP values of the predictive \nmodels (predicting temperature, thermal comfort, weather, energy consumption) are also \nfed into the LLM. Combining these input components, the LLM is able to provide a cohe -\nsive narrative and reasoning behind the control decisions and generate a comprehensive \ntext-graph document. The study provides detailed information about the prompt templates \nthat they used along with example responses from the framework to user prompts. Key limi-\ntations include the computational complexity and cost introduced by the LLMs, and the lim-\nited semantic accuracy of the model due to its lack of construction-specific knowledge that \nled to inaccuracies and limited reasoning in cases requiring advanced technical knowledge. \nThe reliability of the method and output consistency is also affected by the model’s sensitiv-\nity to prompt variations. Also, integrating LLMs into the existing workflow faced practical \nchallenges with latency, interoperability and complexity issues when handling dynamic and \nreal-time data.\nJang and Lee ( 2023) integrated LLMs, specifically GPT models, into several stages of \nthe BIM process in an attempt to streamline and reduce the technical knowledge required for \ncomplex architectural design tasks. Their approach involves first translating data from BIM \nelements (walls, rooms) into an XML format that is fed to the pre-trained language models \n(GPT). The models process the structured representation of the BIM data and based on user \ninput containing design instructions, like adding insulation to the exterior walls, it modifies \nthe object’s attributes (material, position, geometry) or suggest new objects when necessary. \nAfter the interaction with the user is finished, the modified XML description is translated \nback into the BIM format, which can be visualized with traditional BIM tools. The study is \nsupported by a case study where the LLMs were tasked with refining the wall details of a \ncomplex BIM structure and could successfully apply modifications based on architectural \ncontext (e.g. appropriate finishing on wet rooms). The GPT models in addition to traditional \nmetrics (accuracy, precision, recall, f1-score) were evaluated in terms of consistency based \non the Multi-rater Cohen’s Kappa metric with GPT-4 exhibiting the best performance. The \n1 3\n250 Page 28 of 46\nA review of LLMs and their applications in the architecture, engineering…\nauthors reported that slight prompt modifications could significantly impact the generated \ndesigns and highlighted the lack of knowledge regarding architectural concepts and con -\nstruction requirements. Also, the feasibility of the approach in practical workflows is also \nlimited by the computational requirements for real-time interaction between BIM systems \nand GPT models.\nZheng and Fischer (2023) developed a virtual assistant framework for BIM incorporating \nLLMs (GPT) to search and extract information providing responses with relevant 3D rep -\nresentations. Their approach involves a model processing the user’s BIM-related question \nin natural language. The model is pre-tuned with prompts in such a way that it can extract \nthe intent, keywords and the context of the user input. After processing it and extracting \nthe relevant information, the model responds with a specific SQL-query to the BIM data -\nbase selecting or filtering the necessary data. The extracted BIM data are then processed, \nand the model responds based on the user’s requirements with the appropriate information \nand visualization of the relevant objects in the BIM. Their framework was tested in a case \nstudy involving real-world BIM datasets and was evaluated in terms of accuracy, precision \nand user satisfaction. Their approach relies heavily on precisely engineered prompts, with \nminor variations resulting in substantial differences in the retrieved information. Also, the \nmethod’s generalizability is limited since it required initial data pre-processing and structur-\ning steps that involved BIM dictionaries. Apart from that, the implementation of the system \ndemanded substantial computational resources and cloud infrastructure. The authors also \nraised concerns regarding the security and data privacy risks associated with cloud-based \nBIM implementations and LLMs handling SQL-queries.\nPłoszaj-Mazurek and Ryńska (2024), developed a life cycle assessment tool combining \nAI, ML, LLMs and BIM technologies in order to make informed decisions during the design \nprocess and ultimately reduce the carbon footprint of buildings. Their approach involves \ntraining a CNN to perform carbon footprint estimates with a dataset generated using a para-\nmetric model simulating multiple design scenarios and parameters. They also developed a \nweb-based tool allowing users to input details of building components, leveraging Chat -\nGPT to provide optimization suggestions based on the user input. Finally, they developed a \nweb-based application that estimates the carbon footprint and provides optimization sugges-\ntions requiring IFC models, and material combinations for building components as input. \nA key limitation of this study is the reduced accuracy of early-stage predictions of carbon \nfootprint due to the simplified building parameters that were used. Also, the performance \ndepends heavily on the quality, the format and consistency of the input data. The lack of \nconstruction-specific knowledge and reasoning can lead to incorrect material recommenda-\ntions, raising reliability concerns as well as the need for fine-tuning. There are also concerns \nregarding the generalizability and broad adoption of the approach since it required manual \nand time-consuming input procedures. Another key limitation is related to the computa -\ntional and hardware requirements, with increased cost for training and maintaining the ML \nmodels, acquiring the BIM software and deploying the LLM.\n1 3\nPage 29 of 46 250\nD. Kampelopoulos et al.\n5 Challenges and future directions\nWhile the LLMs systems with their utilities and breakthroughs are already being adopted \nin several industry fields including and not limited to medicine, biology, education, media \nand entertainment, there are still challenges in the utilization of LLMs in general as well as \nchallenges specific to the construction industry that impact the performance of LLMs, their \nreliability and the potential adaptation of this technology in the future. Overcoming these \nlimitations and developing methods and technical solutions that address them is a topic of \ncontinuous research.\n5.1 General LLM challenges and future directions\nThere is a wide variety of challenges associated with the utilization of LLMs in general, \nincluding their computational and resource demands, technical limitations, concerns about \ntheir development, maintenance and usability, interdisciplinary and integration challenges, \nas well as ethical, privacy and security concerns. A more thorough analysis of the challenges \nand current approaches, solutions and directions for future research on LLMs was con -\nducted by Kaddour et al. ( 2023). The focus of this section is to present the most prevalent \nand impactful of these challenges and highlight the domains that current research is focused \non. Figure 5a and b present an overview of these challenges along with future directions \ntowards addressing them.\n5.1.1 Computational and resource demands\nThe development and utilization of LLMs face significant challenges related to the required \ncomputational infrastructure, energy efficiency, scalability, economic and research inequali-\nties that ultimately limit their availability and constrain technological innovation in the field. \nThe energy consumption and the hardware requirements are substantial and simply train -\ning a single advanced LLM can be equivalent to the carbon footprint of multiple vehicles \nthroughout their lifetime (Patterson et al. 2022). Additionally, improving these models’ \nperformance requires further scaling up, which in turn demands advanced hardware with \nhigh capabilities, like GPU clusters and specialized processing systems. Further scaling, \nalso, requires exponentially more computational resources with performance improving at \na gradually decreasing rate when dataset and model size remain fixed (Kaplan et al. 2020), \nwith Sorscher et al. (2022) highlighting that for a reduction of 2% in error, orders of magni-\ntude more energy consumption is required, proving diminishing returns in model accuracy. \nAs a result, a significant technological divide emerges where only well-funded institutions \ncan have access to this technology and advance LLM research, creating economic and \nresearch inequalities, specifically for researchers from developing countries (Bommasani \net al. 2021).\nTo address these challenges, developers should focus on more energy efficient and sus -\ntainable model architectures, develop and advance quantization approaches and model \ncompression strategies, as well as hardware acceleration techniques with more efficient \nhardware. These approaches aim to reduce computational requirements while maintaining \nperformance. There is also a recent trend in LLM families to also produce light-weight ver-\nsions of their models demonstrating greater performance in specific benchmarks than their \n1 3\n250 Page 30 of 46\nA review of LLMs and their applications in the architecture, engineering…\nlarge variants, highlighting the need for smaller and more efficient models. To overcome \nthese economic, environmental and research barriers the focus should prioritize and gravi -\ntate towards sustainability and democratization of these models parallel to performance \nimprovement.\n5.1.2 Technical limitations\nAside from computational and resource requirements, LLMs face limitations regarding their \ntechnical characteristics that substantially reduce their effectiveness. A key issue is prompt \nsensitivity or brittleness, where minor variations in the prompt syntax, often unintuitive to \nhumans, can produce significantly different outputs (Lu et al. 2022; Webson and Pavlick \n2022) reducing the reliability and reproducibility of LLMs. The reason behind this behav -\nior is still an unsolved research topic, with many prompt-engineering techniques, while \nbeing able to successfully steer the model’s output in the desired manner, they are rather \nempirical, leaving practitioners with no systematic approach for creating effective prompts. \nAdditionally, a key issue of LLMs is their inability to maintain contextual coherence and \nmanage long-term dependencies over extended inputs, often attributed as limited context \nFig. 5 Overview of the challenge categories, specific limitations and future directions associated with the \ngeneral use of LLMs (a) and (b)\n \n1 3\nPage 31 of 46 250\nD. Kampelopoulos et al.\nlength. This is a limitation originating from the architecture of the models, however Li et \nal. ( 2023), while evaluating several LLMs in long context scenarios, they demonstrated \nthat being architecturally able to handle large context lengths does not always guarantee \nhigh performance in these situations. Tokenization introduces additional limitations, like \ndifferent languages requiring more tokens to convey the same information (Petrov et al. \n2023; Ahia et al. 2023), or tokenizers and models trained on different data can lead to glitch \ntokens (Rumbelow and Mwatkins 2024). Tokenizer-reliance is associated with computa -\ntional overheads, fixed vocabulary size, low human interpretability, information loss and \nlanguage dependence.\nAnother key technical challenge is domain adaptation, with general-purpose LLMs \nrequiring post-training and fine-tuning to task-specific or domain-specific datasets to be \neffective in specialized tasks. Current fine-tuning techniques require storing and loading an \nindividual copy of the model and as a result they demand more data storage and memory \nallocation (Houlsby et al. 2019). Apart from that, even after fine-tuning the models still pro-\nduce inconsistent results in low-data scenarios if no elaborate data-selection approach is fol-\nlowed, highlighting the need for more adaptive learning model structures (Lin et al. 2024). \nLast but not least, another key technical limitation is dynamic and real-time responsiveness, \nwhich can be quite complex to achieve advanced and large-scale models and require a bal -\nance between model depth, accuracy and latency.\nFigure 5 (continued)\n \n1 3\n250 Page 32 of 46\nA review of LLMs and their applications in the architecture, engineering…\n5.1.3 Data and bias issues\nAnother category of challenges originates from the quality of the datasets used during \npre-training. These datasets inherently contain historical inequities that are embedded in \nlanguage and can be hard to mitigate effectively leading eventually these inequities to be \nreflected upon the outputs. As a result, the outputs may contain social and cultural preju -\ndices making the model behavior biased and less neutral (Bender et al. 2021). Addition-\nally, LLMs can generate hallucinations, which are incorrect responses but articulated in a \nplausible way that can mislead users. This issue can be significantly preventive from using \nLLMs in domains requiring high accuracy and confidence in the generated responses like in \nmedicine and science. This in turn brings forth the lack of generalizability between multiple \ndomains of these models, since they are trained on general-purpose datasets and not on \nhigh-quality domain-specific ones.\n5.1.4 Interdisciplinary and integration challenges\nAnother factor that limits the utilization of LLMs in more fields is the need for integra -\ntion of multiple modalities in certain applications, to overcome the limitations of text and \nprovide additional contextual adaptability. Expanding the abilities of LLMs to process \nother modalities than text, like images, video and voice requires even more advanced \narchitectures and complex models, however, there is a recent shift with latest versions \nof LLMs (like GPT-4, Claude 3.5) allowing interpretation and generation of context in \nall these formats. Although correlating information effectively and accurately between \nmodalities while maintaining context is in question (Wang et al. 2024). Also, integrating \nLLMs into professional workflows is challenging and requires adaptation to existing stan -\ndards, protocols and processes of each domain. Interdisciplinary collaboration between \ndiverse fields, like computer science, psychology, ethics, regulations and domain-specific \nexpertise is critical to ensure seamless integration of LLMs into existing workflows with -\nout disrupting these ecosystems.\n5.1.5 Development, maintenance, and usability\nAnother challenging factor is the sustainability, maintenance and usability of LLMs over \nextended periods of time. The models need to be updated to current events and technologi-\ncal advances, raising the need for continuous training and maintenance. Catastrophic for -\ngetting is also a barrier in keeping the models up to date, where often training to new data \noverwrites the old knowledge leading to knowledge temporality and reducing long-term \nadaptability of the models. Additionally, explainability and interpretability of these models \nis a key concern, as they operate as “black boxes”, with their actual operation and reason -\ning behind their generated outputs being unknown. Transparent and explainable reasoning \nis essential in critical fields like healthcare and law. Apart from that, the rapid surge of \nLLM technology has left regulatory frameworks lagging, with existing policies being inad-\nequate to regulate and manage LLM's adaptation effectively and responsibly. The need for \nan adaptive legal approach and updated regulatory guidelines rises, as well as the need for \ncollaboration between technologists and policymakers in this direction. One more concern \nregarding the usability and deployment of LLMs in practice is the skill gap in the workforce \n1 3\nPage 33 of 46 250\nD. Kampelopoulos et al.\nregarding these technologies. Training workers not only for the technical but also for the \nethical dimensions of AI is essential to address this concern.\n5.1.6 Ethical, privacy, and security concerns\nUtilization of LLMs raises significant concerns in regard to ethics, privacy, security and \naccountability. Ethical concerns are linked to biases embedded into the training data of \nthese models, which can promote social inequities and discrimination in their outputs. It is \nessential to develop frameworks focusing on transparency and accountability to identify and \nmitigate these issues, incorporating multi-disciplinary expertise. Developers should empha-\nsize on explainability of these “black box” models to provide additional insight behind \ntheir decision—making to allow human oversight and intervention when necessary. Privacy \nand data protection are also major concerns as LLMs become more complex and larger in \nsize, especially if the models are trained on private data and are publicly available (Plant \net al. 2022). LLMs tend to memorize phrases from their training datasets, which can be \nexploited by adversaries to extract sensitive data, posing a significant threat to data privacy \nand security. Researchers have identified such exploits, like backdoor attacks, jailbreaking, \ndata poisoning, prompt injections that can jeopardize the security of LLMs (Das et al. 2024).\n5.2 Construction-specific LLM challenges and future directions\nWhile researchers are actively trying to overcome the limitations of LLMs that were men -\ntioned in the previous subsection, there are also considerable challenges, inherent to the \nutilization of LLMs in construction, that can further delay or even prevent their broad adap-\ntation. Figure 6 summarizes these challenges along with future directions towards address-\ning them.\n5.2.1 Technological and operational challenges\nOne key category of challenges of employing LLMs in the construction industry are tech -\nnological and operational limitations, primarily linked to computational and infrastructure \ncosts, model stability and maintenance as well as data interoperability. First, training and \noperating LLMs require massive and expensive computational infrastructure running for \nextended periods of time to develop capable and accurate models. Adding to that, another \nlimitation is the energy required to run LLMs and the associated web-serving infrastructure \n(Liu et al. 2023a). Even utilizing already trained models from their associated web frame -\nworks and APIs is linked to significant costs for web access, with most LLM companies \noffering costly services based on token usage and introducing usage limits to their custom -\ners. All these additional cost overheads may be a prohibiting factor for smaller construction \ncompanies with limited financial resources (Saka et al. 2023b). Researchers should focus \non developing cost-effective optimization techniques to reduce computational resources, \npower consumption and data needs of these models in order to overcome these barriers and \nallow for a broader adaptation of LLMs in construction.\nThe continuous operation, optimal performance, stability and maintainability of LLMs \nare also key concerns, since these models require constant updates to new information, \nevolving user requirements, standards and data patterns. Over time these models’ perfor -\n1 3\n250 Page 34 of 46\nA review of LLMs and their applications in the architecture, engineering…\nmance drifts and deteriorates, impacting the accuracy, reliability and relevance of the gener-\nated content (Zong and Krishnamachari 2022). Maintaining and upkeeping the performance \nof these models over prolonged periods requires continuous training and updated datasets.\nIn order to overcome and mitigate this category of challenges industry stakeholders are \nadvised to make the following actions:\n ● Optimize computational efficiency: Focus on smaller and modular LLMs, consider \nquantization techniques to reduce the hardware and resource requirements and leverage \ncloud resources, efficient scheduling, and energy efficient hardware.\n ● Ensure model reliability and maintainability: Establish workflows that incorporate hu -\nman oversight and continuously update the model with updated data through fine-tuning \nFig. 6 Overview of the challenge categories, specific limitations and future directions associated with the \nuse of LLMs specifically for the AEC industry\n \n1 3\nPage 35 of 46 250\nD. Kampelopoulos et al.\nand prompt tuning to ensure long-term accuracy and maintainability.\n ● Structured prompting: Make sure to provide thorough prompts, with explicit instruc -\ntions to ensure alignment to the task and prevent unwanted responses.\n5.2.2 Domain-specific knowledge and data limitations\nAnother key challenge category of LLMs that hinders the broader adoption of LLMs in con-\nstruction is the lack of domain-specific knowledge and data limitations. LLMs are trained on \nlarge datasets that are general-purpose with limited domain-specific knowledge, resulting in \nbiased outputs. This is a significant limitation for the construction industry which requires \nunderstanding of complex and advanced principles, terminology, practices and regulations. \nThese requirements often need to be adapted from time to time and for different regions. \nFor that matter, the need arises for large-curated construction-specific datasets that will \nincorporate physical situational awareness, spatial reasoning and safety standards with tech-\nnical engineering expertise on mechanical, structural, plumbing and project management \nprinciples.\nAdditionally, interoperability is another important consideration, especially in the \ndomain of construction where most of the processes require specialized software like CAD, \nBIM, BEM and management systems. Achieving seamless data exchange, integration and \nprocessing between different input formats and files while maintaining data integrity and \nsemantic consistency across different platforms and LLMs is key for a broader adoption in \nthe construction industry. Future development should emphasize creating standardized data \nexchange practices, integration protocols and models that can handle input from multiple \nmodalities to address these concerns. Specifically, industry stakeholders are advised of the \nfollowing actions:\n ● Develop construction-specific datasets: Build high quality datasets that incorporate \nextensive project documentation, safety records, compliance and regulatory stand -\nards.\n ● Domain-specific fine-tuning: Explore public databases that are targeting a specific do -\nmain and fine-tune the models on these specialized data to ensure semantic accuracy and \nlimit contextual constrains inherent in general-purpose models.\n ● Interoperability and data exchange: Consider investing in middleware solutions that can \nconnect LLMs with other construction software (BIM, CAD, BEM) through APIs, and \nutilize standardized data formats to ensure seamless integration.\n5.2.3 Accuracy, reliability, and compliance\nAnother significant category of challenges is linked to the accuracy and reliability of LLMs \nas well as the compatibility with construction regulatory guidelines. Hallucinations are \noften generated by these models, which in the domain of construction can have catastrophic \nconsequences that apart from project delays or cost overruns can even endanger lives and \nproperties. Apart from that, construction projects must comply with safety regulations and \nstandards that may vary for different jurisdictions, which is a significant limitation due to \nthe general-purpose nature of current LLMs. While this is a challenge also concerning the \n1 3\n250 Page 36 of 46\nA review of LLMs and their applications in the architecture, engineering…\nmaintainability and sustainability of these models, it can significantly impact their accuracy \nand reliability.\nTo address these concerns, it is important to develop robust output verification and qual-\nity assurance frameworks, incorporating human oversight, to enable technical accuracy and \nregulatory alignment. Also, developers should focus on enhancing the transparency and \nexplainability of these models to provide accountability and to effectively identify and miti-\ngate these limitations. More specifically, the following recommendations are suggested for \nindustry stakeholders:\n ● Develop verification pipelines: Consider implementing AI-assisted tools to verify the \nLLM generated content against construction databases, code repositories and regula -\ntions.\n ● Ensure human-AI collaboration: Integrate human verification in multiple steps of the \nprocess especially when dealing with safety-critical applications.\n ● Enhance model explainability and transparency: Require LLMs to provide references, \ndetailed explanations for their generated responses and decisions. Consider utilizing \nLLM variants that have Chain of Thought capabilities.\n5.2.4 Ethical and social challenges\nFinally, the integration of LLMs in the construction industry is associated with major ethical \nand social challenges related to data privacy, intellectual property rights, level of trust as \nwell as societal, cultural and labor concerns. Protection of proprietary information is key in \nan area where one can inadvertently expose sensitive information about projects, including \ntrade secrets and competitive information, through the outputs of the models. Researchers \nhave underscored the risks of managing proprietary data and sensitive information within \nLLM systems, showing concerns regarding confidentiality and data security. Another major \nbarrier is trust, which is essential in safety-critical applications. Skepticism towards AI-gen-\nerated recommendations on technical decisions and safety protocols is a barrier to broader \nLLM adoption. Liability frameworks regarding AI-supported decision-making are impor -\ntant to ensure the legal accountability of construction projects.\nLLM deployment is further complicated by cultural and regional considerations. The \nconstruction industry has considerable regional diversity in terms of building techniques, \nregulatory frameworks, and professional practices, so the LLM should be able to adjust \nitself to these differences. Most existing AI solutions lack this cultural and contextual aware-\nness, which is quite fundamental to align with local construction standards and practices in \norder to ensure effective deployment in different regions. Moreover, the integration of LLMs \npresents issues regarding job displacement and raises labor concerns. LLMs are capable of \nautomating a wide variety of cognitive tasks rendering a significant fraction of the work -\nforce unutilized. However, they will also create new roles and job opportunities that will \nrequire additional training and development of the workforce. Addressing these workforce \nimplications will require careful planning to ensure the technological advancements do not \nleave workers behind but rather provide fair career opportunities. Industry stakeholders are \nadvised to apply the following recommendations:\n ● Implement data privacy and IP safeguards: Consider encrypting confidential informa -\n1 3\nPage 37 of 46 250\nD. Kampelopoulos et al.\ntion, enforcing strict access controls and anonymizing data during training.\n ● Adapt solutions to local cultures and regulations: Consider fine-tuning models to re -\ngion-specific data that contain local construction terminology, standards and regulatory \nrequirements.\n ● Invest in workforce training and job augmentation: Develop programs to train the work-\nforce on current AI technologies, promote AI literacy and ensure human-AI collabora -\ntion in industry practices. Utilize LLMs to streamline repetitive and time-consuming \ntasks while employing humans for high-value services, creative design, strategic plan -\nning and problem-solving.\n ● Leverage AI to augment jobs, not replace them.\n6 Conclusion\nSumming up, this work initially provides an overview and a discussion of key aspects of \ntraining, tuning, and operation of LLMs along with architecture configurations and some of \nthe broadly acknowledged and widely adopted LLM practices. Additionally, it focuses on \nthe AEC domain and provides a detailed review of recently developed use cases and appli-\ncations leveraging LLMs for a diverse range of tasks, ranging across all the construction \nphases from educational support to question answering machines, document generation, \nadvanced BIM and BEM functionalities and more. The final part of this work is focused on \na discussion involving some of the main challenges and limitations associated with both the \ngeneral use of LLMs and their utilization specifically for the AEC domain.\nThis work is an attempt to document, categorize and present state-of-the-art use cases of \nLLMs in the construction industry as well as the inherent barriers that researchers are cur -\nrently facing along with future directions of this field. The focus was given on extracting \nactionable recommendations for stakeholders based on the current literature and the specific \nlimitations that emerged from the reviewed use cases. However, this work is focused on \ntransformer-based architectures that mainly target text-generation tasks, not diving deeper \ninto audio, image and video generating models. Also, since the focus is on the AEC domain, \nthe analysis of state-of-the-art implementations, techniques and current aspects of LLMs is \nnot extensive and limited to basic concepts and trends that are mentioned throughout the \npaper.\nSome of the key findings from analyzing the case studies of LLMs in the AEC industry \ninvolved accuracy issues due to limited domain-specific knowledge, data interoperability \nissues, high computational costs, concerns regarding regulatory compliance, safety, and eth-\nics. To address these challenges, industry stakeholders should consider the main following \nrecommendations:\n ● Select appropriate LLM variations according to the task at hand and consider models \nwith a lower number of parameters or optimized architectures before selecting a larger \none.\n ● Utilize pre-trained models and employ fine-tuning techniques on domain-specific data-\nsets to improve accuracy, contextual understanding and ensure alignment to the task of \ninterest.\n ● Integrate LLMs with BIM and other digital tools for construction with standardized \n1 3\n250 Page 38 of 46\nA review of LLMs and their applications in the architecture, engineering…\nAPIs, common data formats to ensure seamless integration and reduce interoperability \nissues.\n ● Focus on computational efficiency and minimization of resources by utilizing quantiza-\ntion techniques, cloud-based solutions.\n ● Implement validation frameworks and routines that incorporate human oversight at \nmultiple steps of the process. Perform compliance checks, structured prompt-tuning to \nensure safe and accurate responses.\nAuthor contributions D.K was the main author responsible for the composition of the original manuscript, \nthe study conceptualization, as well as the selection, study and analysis of the relevant literature. A.T con -\ntributed to the writing, editing and reviewing of the manuscript, the conceptualization of the study and the \nsupervision of the process. S.V . and I.K. contributed to the reviewing of the manuscripts and supervised the \nwhole process.\nFunding Open access funding provided by HEAL-Link Greece.\nThis work was funded by the DATAWiSE, European project, under the framework program Horizon Europe \n[number 101147855].\nData availability No datasets were generated or analysed during the current study.\nDeclarations\nConflict of interest The authors declare no competing interests.\nOpen Access  This article is licensed under a Creative Commons Attribution 4.0 International License, \nwhich permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as \nyou give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons \nlicence, and indicate if changes were made. The images or other third party material in this article are \nincluded in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. \nIf material is not included in the article’s Creative Commons licence and your intended use is not permitted \nby statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the \ncopyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\nReferences\nAbioye SO, Oyedele LO, Akanbi L, Ajayi A, Delgado JMD, Bilal M, Akinade OO, Ahmed A (2021) Artificial \nintelligence in the construction industry: a review of present status, opportunities and future challenges. \nJ Build Eng 44:103299. https://doi.org/10.1016/j.jobe.2021.103299\nAfzal F, Yunfei S, Nazir M, Bhatti SM (2019) A review of artificial intelligence based risk assessment meth-\nods for capturing complexity-risk interdependencies. Int J Manag Projects Bus 14(2):300–328.  h t t p s : / / \nd o i . o r g / 1 0 . 1 1 0 8 / i j m p b - 0 2 - 2 0 1 9 - 0 0 4 7       \nAhia O, Kumar S, Gonen H, Kasai J, Mortensen DR, Smith NA, Tsvetkov Y (2023) Do all languages cost the \nsame? Tokenization in the era of commercial language models. Cornell University. Preprint at  h t t p s : / / d \no i . o r g / 1 0 . 4 8 5 5 0 / a r x i v . 2 3 0 5 . 1 3 7 0 7       \nAlmazrouei E, Alobeidli H, Alshamsi A, Cappelli A, Cojocaru R, Hesslow D, Launay J, Malartic Q, Maz -\nzotta D, Noune B, Pannier B, Penedo G (2023) The Falcon series of open Language models. Cornell \nUniversity. Preprint at https://doi.org/10.48550/arxiv.2311.16867\nAmer F, Jung Y , Golparvar-Fard M (2021) Transformer machine learning language model for auto-alignment \nof long-term and short-term plans in construction. Autom Constr 132:103929.  h t t p s : / / d o i . o r g / 1 0 . 1 0 1 6 / \nj . a u t c o n . 2 0 2 1 . 1 0 3 9 2 9       \nAndenæs E, Engebø A, Time B, Lohne J, Torp O, Kvande T (2020) Perspectives on quality risk in the build-\ning process of blue-green roofs in Norway. Buildings 10(10):189.  h t t p s : / / d o i . o r g / 1 0 . 3 3 9 0 / b u i l d i n g s 1 0 \n1 0 0 1 8 9       \n1 3\nPage 39 of 46 250\nD. Kampelopoulos et al.\nAnil R, Dai AM, Firat O et al (2023) PALM 2 Technical Report. Cornell University. Preprint at  h t t p s : / / d o i . o \nr g / 1 0 . 4 8 5 5 0 / a r x i v . 2 3 0 5 . 1 0 4 0 3       \nAnthropic (2024) Introducing the next generation of Claude.  h t t p s :  / / w w w  . a n t h r  o p i c  . c o m /  n e w s /  c l a u d e  - 3 - f  a \nm i l y\nArora D, Kini A, Chowdhury SR, Natarajan N, Sinha G, Sharma A (2023) GAR-meets-RAG paradigm for \nzero-shot information retrieval. Cornell University. Preprint at  h t t p s : / / d o i . o r g / 1 0 . 4 8 5 5 0 / a r x i v . 2 3 1 0 . 2 0 \n1 5 8       \nBaduge SK, Thilakarathna S, Perera JS, Arashpour M, Sharafi P, Teodosio B, Shringi A, Mendis P (2022) \nArtificial intelligence and smart vision for building and construction 4.0: machine and deep learning \nmethods and applications. Autom Constr 141:104440. https://doi.org/10.1016/j.autcon.2022.104440\nBarbosa F, Woetzel J, Mischke J (2017) Reinventing construction: a route of higher productivity. McKinsey \nGlobal Institute, New York\nBassir D, Lodge H, Chang H, Majak J, Chen G (2023) Application of artificial intelligence and machine \nlearning for BIM: review. Int J Simul Multi Design Optim 14:5. https://doi.org/10.1051/smdo/2023005\nBender EM, Gebru T, McMillan-Major A, Shmitchell S (2021) On the dangers of stochastic parro0ts. In: \nProceedings of the 2021 ACM conference on fairness, accountability, and transparency, pp 610–623. \nhttps://doi.org/10.1145/3442188.3445922\nBengesi S, El-Sayed H, Sarker MK, Houkpati Y , Irungu J, Oladunni T (2024) Advancements in generative \nAI: a comprehensive review of GANs, GPT, autoencoders, diffusion model, and transformers. IEEE \nAccess 12:69812–69837. https://doi.org/10.1109/access.2024.3397775\nBommasani R, Hudson DA, Adeli E et al (2021) On the opportunities and risks of foundation models. Cornell \nUniversity. Preprint at https://doi.org/10.48550/arxiv.2108.07258\nBorgeaud S, Mensch A, Hoffmann J, Cai T, Rutherford E, Millican K, Van Den Driessche G, Lespiau J-B, \nDamoc B, Clark A, De Las Casas D, Guy A, Menick J, Ring R, Hennigan T, Huang S, Maggiore L, \nJones C, Cassirer A, Brock A, Paganini M, Irving G, Vinyals O, Osindero S, Simonyan K, Rae JW, \nElsen E, Sifre L (2021) Improving language models by retrieving from trillions of tokens. Cornell Uni-\nversity. Preprint at https://doi.org/10.48550/arxiv.2112.04426\nBrown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P, Neelakantan A, Shyam P, Sastry G, Askell \nA, Agarwal S, Herbert-V oss A, Krueger G, Henighan T, Child R, Ramesh A, Ziegler DM, Wu J, Winter \nC, Hesse C, Chen M, Sigler E, Litwin M, Gray S, Chess B, Clark J, Berner C, McCandlish S, Radford \nA, Sutskever I, Amodei D (2020) Language Models are Few-Shot Learners. Cornell University. Preprint \nat https://doi.org/10.48550/arxiv.2005.14165\nCastro LMC, Castelblanco G, Antonenko PD (2024) LLM-based system for technical writing real-time review \nin urban construction and technology. EPiC Ser Built Environ 5:130–120. https://doi.org/10.29007/d9j3\nChen M, Tworek J, Jun H et al (2021) Evaluating large language models trained on code. Cornell University. \nPreprint at https://doi.org/10.48550/arxiv.2107.03374\nChen N, Lin X, Jiang H, An Y (2024) Automated Building information modeling compliance check through \na large Language model combined with deep learning and ontology. Buildings 14(7):1983.  h t t p s : / / d o i . \no r g / 1 0 . 3 3 9 0 / b u i l d i n g s 1 4 0 7 1 9 8 3       \nChiang WL, Li Z, Lin Z, Sheng Y , Wu Z, Zhang H, Zheng L, Zhuang S, Zhuang Y , Gonzalez JE, Stoica \nI, Xing EP (2023) Vicuna: an Open-Source chatbot impressing GPT-4 with 90%* ChatGPT quality. \nhttps://lmsys.org/blog/2023-03-30-vicuna/\nChou J-S, Lin C (2012) Predicting disputes in public-private partnership projects: classification and ensemble \nmodels. J Comput Civil Eng 27(1):51–60.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  6 1 / ( a s c e ) c p . 1 9 4 3 - 5 4 8 7 . 0 0 0 0 1 9 7\nChowdhery A, Narang S, Devlin J et al (2022) PaLM: scaling Language modeling with pathways. Cornell \nUniversity. Preprint athttps://doi.org/10.48550/arxiv.2204.02311\nChristiano P, Leike J, Brown TB, Martic M, Legg S, Amodei D (2017) Deep reinforcement learning from \nhuman preferences. Cornell University. Preprint at https://doi.org/10.48550/arxiv.1706.03741\nChung HW, Hou L, Longpre S, Zoph B, Tay Y , Fedus W, Li E, Wang X, Dehghani M, Brahma S, Webson \nA, Gu SS, Dai Z, Suzgun M, Chen X, Chowdhery A, Narang S, Mishra G, Yu A, Zhao V , Huang Y , \nDai A, Yu H, Petrov S, Chi EH, Dean J, Devlin J, Roberts A, Zhou D, Le QV , Wei J (2022) Scal -\ning Instruction-Finetuned Language Models. Cornell University. Preprint at https://doi.org/10.48550/\narxiv.2210.11416\nDas BC, Amini MH, Wu Y (2024) Security and privacy Challenges of large language Models: a survey. \nCornell University. Preprint at https://doi.org/10.48550/arxiv.2402.00888\nDevlin J, Chang M-W, Lee K, Toutanova K (2018) BERT: pre-training of deep bidirectional transformers \nfor language understanding. Cornell University. Preprint at https://doi.org/10.48550/arxiv.1810.04805\nDing Y , Ma J, Luo X (2022) Applications of natural Language processing in construction. Autom Constr \n136:104169. https://doi.org/10.1016/j.autcon.2022.104169\nDubey A, Jauhri A, Pandey A et al (2024) The Llama 3 Herd of models. Cornell University. Preprint at  h t t p s \n: / / d o i . o r g / 1 0 . 4 8 5 5 0 / a r x i v . 2 4 0 7 . 2 1 7 8 3       \n1 3\n250 Page 40 of 46\nA review of LLMs and their applications in the architecture, engineering…\nDubois A, Gadde L-E (2002) The construction industry as a loosely coupled system: implica -\ntions for productivity and innovation. Constr Manage Econ 20(7):621–631. https://doi.\norg/10.1080/01446190210163543\nFang Y , Ng ST (2019) Genetic algorithm for determining the construction logistics of precast components. \nEng Constr Architect Manage 26(10):2289–2306. https://doi.org/10.1108/ecam-09-2018-0386\nFathi S, Srinivasan R, Fenner A, Fathi S (2020) Machine learning applications in urban building energy \nperformance forecasting: a systematic review. Renew Sustain Energy Rev 133:110287.  h t t p s : / / d o i . o r g / \n1 0 . 1 0 1 6 / j . r s e r . 2 0 2 0 . 1 1 0 2 8 7       \nFedus W, Zoph B, Shazeer N (2021) Switch transformers: scaling to trillion parameter models with simple \nand efficient sparsity. Cornell University. Preprint at https://doi.org/10.48550/arxiv.2101.03961\nGambatese JA, Hallowell M (2011) Factors that influence the development and diffusion of technical innova-\ntions in the construction industry. Constr Manage Econ 29(5):507–517.  h t t p s : / / d o i . o r g / 1 0 . 1 0 8 0 / 0 1 4 4 6 \n1 9 3 . 2 0 1 1 . 5 7 0 3 5 5       \nGao Y , Xiong Y , Gao X, Jia K, Pan J, Bi Y , Dai Y , Sun J, Wang H (2023) Retrieval-augmented generation \nfor large language models: a survey. Cornell University. Preprint at  h t t p s : / / d o i . o r g / 1 0 . 4 8 5 5 0 / a r x i v . 2 3 1 \n2 . 1 0 9 9 7       \nGhimire P, Kim K, Acharya M (2024) Opportunities and challenges of generative AI in construction industry: \nfocusing on adoption of text-based models. Buildings 14(1):220.  h t t p s : / / d o i . o r g / 1 0 . 3 3 9 0 / b u i l d i n g s 1 4 0 \n1 0 2 2 0       \nGiudici M, Padalino L, Paolino G, Paratici I, Pascu AI, Garzotto F (2024) Designing home automation rou -\ntines using an LLM-based chatbot. Designs 8(3):43. https://doi.org/10.3390/designs8030043\nGu A, Dao T (2023) Mamba: linear-time sequence modeling with selective state spaces. Cornell University. \nPreprint at https://doi.org/10.48550/arxiv.2312.00752\nGuan L, Valmeekam K, Sreedharan S, Kambhampati S (2023) Leveraging pre-trained large Language mod-\nels to construct and utilize world models for model-based task planning. Cornell University. Preprint at \nhttps://doi.org/10.48550/arxiv.2305.14909\nHan D, Zhao W, Yin H, Qu M, Zhu J, Ma F, Ying Y , Pan A (2024) Large Language models driven BIM-based \nDfMA method for free-form prefabricated buildings: framework and a usefulness case study. J Asian \nArchit Build Eng.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  8 0 / 1 3  4 6 7 5 8  1 . 2 0 2 4  . 2 3 2  9 3 5 1\nHassan HA, Marengo E, Nutt W (2022) A BERT-based model for question answering on construction inci -\ndent reports. In: Natural language processing and information systems, 27th international conference \non applications of natural language to information systems, NLDB 2022. Lecture notes in computer \nscience. Springer, pp 215–223\nHatami M, Franz B, Paneru S, Flood I (2022) Using deep learning artificial intelligence to improve foresight \nmethod in the optimization of planning and scheduling of construction processes. Comput Civil Eng. \nhttps://doi.org/10.1061/9780784483893.143\nHe P, Liu X, Gao J, Chen W (2020) DeBERTa: decoding-enhanced BERT with disentangled attention. Cor-\nnell University. Preprint at https://doi.org/10.48550/arxiv.2006.03654\nHoulsby N, Giurgiu A, Jastrzebski S, Morrone B, De Laroussilhe Q, Gesmundo A, Attariyan M, Gelly S \n(2019) Parameter-efficient transfer learning for NLP. Cornell University. Preprint at  h t t p s : / / d o i . o r g / 1 0 . \n4 8 5 5 0 / a r x i v . 1 9 0 2 . 0 0 7 5 1       \nHoward J, Ruder S (2018) Universal language model fine-tuning for text classification. Cornell University. \nPreprint at https://doi.org/10.48550/arxiv.1801.06146\nHu EJ, Shen Y , Wallis P, Allen-Zhu Z, Li Y , Wang S, Chen W (2021) LORA: low-rank adaptation of large \nLanguage models. Cornell University. Preprint at https://doi.org/10.48550/arxiv.2106.09685\nHu Y , Kim H, Ye K, Lu N (2024) Applying fine-tuned LLMs for reducing data needs in load profile analysis. \nCornell University. Preprint at https://doi.org/10.48550/arxiv.2406.02479\nJang S, Lee G (2023) Interactive design by integrating a large pre-trained language model and building infor-\nmation modeling. Cornell University. Preprint at https://doi.org/10.48550/arxiv.2306.14165\nJang S, Lee G, Oh J, Lee J, Koo B (2024) Automated detailing of exterior walls using NADIA: natural-\nlanguage-based architectural detailing through interaction with AI. Adv Eng Inform 61:102532.  h t t p s : / \n/ d o i . o r g / 1 0 . 1 0 1 6 / j . a e i . 2 0 2 4 . 1 0 2 5 3 2       \nJiang AQ, Sablayrolles A, Mensch A, Bamford C, Chaplot DS, De Las Casas D, Bressand F, Lengyel \nG, Lample G, Saulnier L, Lavaud LR, Lachaux M-A, Stock P, Scao TL, Lavril T, Wang T, Lac -\nroix T, Sayed WE (2023) Mistral 7B. Cornell University. Preprint at https://doi.org/10.48550/\narxiv.2310.06825\nJiang AQ, Sablayrolles A, Roux A, Mensch A, Savary B, Bamford C, Chaplot DS, De Las Casas D, Hanna \nEB, Bressand F, Lengyel G, Bour G, Lample G, Lavaud LR, Saulnier L, Lachaux M-A, Stock P, Sub -\nramanian S, Yang S, Antoniak S, Scao TL, Gervet T, Lavril T, Wang T, Lacroix T, Sayed WE (2024a) \nMixtral of experts. Cornell University. Preprint at https://doi.org/10.48550/arxiv.2401.04088\n1 3\nPage 41 of 46 250\nD. Kampelopoulos et al.\nJiang G, Ma Z, Zhang L, Chen J (2024b) EPlus-LLM: a large language model-based computing platform \nfor automated Building energy modeling. Appl Energy 367:123431.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  1 6 / j .  a p e n e  r g \ny . 2 0  2 4 . 1  2 3 4 3 1\nJin Y , Shen X, Peng H, Liu X, Qin J, Li J, Xie J, Gao P, Zhou G, Gong J (2023) SurrealDriver: designing \ngenerative driver agent simulation framework in urban contexts based on large language model. Cornell \nUniversity. Preprint at https://doi.org/10.48550/arxiv.2309.13193\nKaddour J, Harris J, Mozes M, Bradley H, Raileanu R, McHardy R (2023) Challenges and applications of \nlarge language models. Cornell University. Preprint at https://doi.org/10.48550/arxiv.2307.10169\nKalman RE (1960) A new approach to linear filtering and prediction problems. J Basic Eng 82(1):35–45. \nhttps://doi.org/10.1115/1.3662552\nKaplan J, McCandlish S, Henighan T, Brown TB, Chess B, Child R, Gray S, Radford A, Wu J, Amodei \nD (2020) Scaling laws for neural language models. arXiv Preprint. https://arxiv.org/abs/2001.08361\nKar AK, Choudhary SK, Singh VK (2022) How can artificial intelligence impact sustainability: a systematic \nliterature review. J Clean Prod 376:134120.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  1 6 / j .  j c l e p  r o . 2 0 2  2 . 1 3  4 1 2 0\nLan Z, Chen M, Goodman S, Gimpel K, Sharma P, Soricut R (2019) ALBERT: A lite BERT for self-super-\nvised learning of Language representations. Cornell University. Preprint at  h t t p s : / / d o i . o r g / 1 0 . 4 8 5 5 0 / a r \nx i v . 1 9 0 9 . 1 1 9 4 2       \nLepikhin D, Lee H, Xu Y , Chen D, Firat O, Huang Y , Krikun M, Shazeer N, Chen Z (2020) GShard: scal-\ning giant models with conditional computation and automatic sharding. Cornell University. Preprint at \nhttps://doi.org/10.48550/arxiv.2006.16668\nLester B, Al-Rfou R, Constant N (2021) The power of scale for parameter-efficient prompt tuning. Cornell \nUniversity. Preprint at https://doi.org/10.48550/arxiv.2104.08691\nLewis M, Liu Y , Goyal N, Ghazvininejad M, Mohamed A, Levy O, Stoyanov V , Zettlemoyer L (2019) BART: \nDenoising sequence-to-sequence pre-training for natural language generation, translation, and compre-\nhension. Cornell University. Preprint at https://doi.org/10.48550/arxiv.1910.13461\nLewis P, Perez E, Piktus A, Petroni F, Karpukhin V , Goyal N, Küttler H, Lewis M, Yih W-T, Rocktäschel T, \nRiedel S, Kiela D (2020) Retrieval-Augmented Generation for Knowledge-Intensive NLP tasks. Cor -\nnell University. Preprint at https://doi.org/10.48550/arxiv.2005.11401\nLi XL, Liang P (2021) Prefix-tuning: optimizing continuous prompts for generation. Cornell University. \nPreprint at https://doi.org/10.48550/arxiv.2101.00190\nLi D, Shao R, Xie A, Sheng Y , Zheng L, Gonzalez JE, Stoica I, Ma X, Zhang H (2023) How long can Open-\nSource LLMs truly promise on context length? https://lmsys.org/blog/2023-06-29-longchat/\nLin Z, Li M, Zheng Z, Cheng Y , Yuan C (2020) Self-attention ConVLSTM for spatiotemporal prediction. In: \nProceedings of the AAAI conference on artificial intelligence, vol 34(07), pp 11531–11538.  h t t p s : / / d o i \n. o r g / 1 0 . 1 6 0 9 / a a a i . v 3 4 i 0 7 . 6 8 1 9       \nLin X, Wang W, Li Y , Yang S, Feng F, Wei Y , Chua T-S (2024) Data-efficient fine-tuning for LLM-based \nrecommendation. Cornell University. Preprint at https://doi.org/10.48550/arxiv.2401.17197\nLiu Y , Ott M, Goyal N, Du J, Joshi M, Chen D, Levy O, Lewis M, Zettlemoyer L, Stoyanov V (2019) \nROBERTA: a robustly optimized BERT pretraining approach. Cornell University. Preprint at  h t t p s : / / d o \ni . o r g / 1 0 . 4 8 5 5 0 / a r x i v . 1 9 0 7 . 1 1 6 9 2       \nLiu Y , Gu J, Goyal N, Li X, Edunov S, Ghazvininejad M, Lewis M, Zettlemoyer L (2020) Multilingual \ndenoising pre-training for neural machine translation. Cornell University. Preprint at  h t t p s : / / d o i . o r g / 1 0 \n. 4 8 5 5 0 / a r x i v . 2 0 0 1 . 0 8 2 1 0       \nLiu J, Luo H, Liu H (2022) Deep learning-based data analytics for safety in construction. Autom Constr \n140:104302. https://doi.org/10.1016/j.autcon.2022.104302\nLiu Y , Yang Z, Yu Z, Liu Z, Liu D, Lin H, Li M, Ma S, Avdeev M, Shi S (2023a) Generative artificial intelli-\ngence and its applications in materials science: current situation and future perspectives. J Materiomics \n9(4):798–816. https://doi.org/10.1016/j.jmat.2023.05.001\nLiu Z, Zhang Y , Li P, Liu Y , Yang D (2023b) Dynamic LLM-Agent network: an LLM-agent collaboration \nframework with agent team optimization. arXiv Preprint. Cornell University  h t t p s : / / d o i . o r g / 1 0 . 4 8 5 5 0 / \na r x i v . 2 3 1 0 . 0 2 1 7 0       \nLu W, Lou J, Webster C, Xue F, Bao Z, Chi B (2021) Estimating construction waste generation in the greater \nBay area, China using machine learning. Waste Manag 134:78–88.  h t t p s : / / d o i . o r g / 1 0 . 1 0 1 6 / j . w a s m a n . \n2 0 2 1 . 0 8 . 0 1 2       \nLu Y , Bartolo M, Moore A, Riedel S, Stenetorp P (2022) Fantastically ordered prompts and where to find \nthem: overcoming few-shot prompt order sensitivity. In: Proceedings of the 60th annual meeting of the \nAssociation for Computational Linguistics (volume 1: long papers).  h t t p s :  / / d o i  . o r g / 1  0 . 1 8  6 5 3 / v  1 / 2 0 2  2 \n. a c l -  l o n g  . 5 5 6\nLu J, Tian X, Zhang C, Zhao Y , Zhang J, Zhang W, Feng C, He J, Wang J, He F (2024) Evaluation of large \nlanguage models (LLMs) on the mastery of knowledge and skills in the heating, ventilation and air con-\nditioning (HV AC) industry. Energy Built Environ. https://doi.org/10.1016/j.enbenv.2024.03.010\n1 3\n250 Page 42 of 46\nA review of LLMs and their applications in the architecture, engineering…\nMalartic Q, Chowdhury NR, Cojocaru R, Farooq M, Campesan G, Djilali YAD, Narayan S, Singh A, \nVelikanov M, Boussaha BEA, Al-Yafeai M, Alobeidli H, Qadi LA, Seddik MEA, Fedyanin K, Alami \nR, Hacid H (2024) Falcon2-11B Technical Report. Cornell University. Preprint at  h t t p s : / / d o i . o r g / 1 0 . 4 8 \n5 5 0 / a r x i v . 2 4 0 7 . 1 4 8 8 5       \nMehmood MU, Chun D, Zeeshan N, Han H, Jeon G, Chen K (2019) A review of the applications of artificial \nintelligence and big data to buildings for energy-efficiency and a comfortable indoor living environ -\nment. Energy Build 202:109383.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  1 6 / j .  e n b u i  l d . 2 0 1  9 . 1 0  9 3 8 3\nMeng F, Lu Z, Li X, Han W, Peng J, Liu X, Niu Z (2024) Demand-side energy management reimagined: a \ncomprehensive literature analysis leveraging large language models. Energy 291:130303.  h t t p s : / / d o i . o r \ng / 1 0 . 1 0 1 6 / j . e n e r g y . 2 0 2 4 . 1 3 0 3 0 3       \nMinaee S, Mikolov T, Nikzad N, Chenaghlu M, Socher R, Amatriain X, Gao J (2024) Large language mod-\nels: a survey. Cornell University. Preprint at https://doi.org/10.48550/arxiv.2402.06196\nMistral AI (2024a) Cheaper, better, faster, stronger. In: Mistral AI| Frontier AI in your hands.  h t t p s : / / m i s t r a l \n. a i / n e w s / m i x t r a l - 8 x 2 2 b /       \nMistral AI (2024b) MathΣtral. In: Mistral AI| Frontier AI in your Hands. https://mistral.ai/news/mathstral/\nMistral AI (2024c) Codestral Mamba. In: Mistral AI| Frontier AI in Your Hands.  h t t p s : / / m i s t r a l . a i / n e w s / c o d \ne s t r a l - m a m b a /       \nMistral AI (2024d) Codestral: Hello, World! In: Mistral AI| Frontier AI in your hands.  h t t p s : / / m i s t r a l . a i / n e w \ns / c o d e s t r a l /       \nMoon S, Chi S, Im S-B (2022) Automated detection of contractual risk clauses from construction specifica -\ntions using bidirectional encoder representations from transformers (BERT). Autom Constr 142:104465. \nhttps://doi.org/10.1016/j.autcon.2022.104465\nNaveed H, Khan AU, Qiu S, Saqib M, Anwar S, Usman M, Barnes N, Mian A (2023) A comprehensive \noverview of large Language models. Cornell University. Preprint at  h t t p s : / / d o i . o r g / 1 0 . 4 8 5 5 0 / a r x i v . 2 3 \n0 7 . 0 6 4 3 5       \nNgiam J, Peng D, Vasudevan V , Kornblith S, Le QV , Pang R (2018) Domain adaptive transfer learning with \nspecialist models. Cornell University. Preprint at https://doi.org/10.48550/arxiv.1811.07056\nOpenAI (2023a) GPT-4 Technical Report. Cornell University. Preprint at  h t t p s : / / d o i . o r g / 1 0 . 4 8 5 5 0 / a r x i v . 2 3 \n0 3 . 0 8 7 7 4       \nOpenAI (2023b) GPT-4V(ision) system card. OpenAI, San Francisco.  h t t p s : / / o p e n a i . c o m / i n d e x / g p t - 4 v - s y s \nt e m - c a r d /       \nOuyang X, Srivastava M (2024) LLMSENSE: Harnessing LLMS for high-level reasoning over spatiotempo-\nral sensor traces. Cornell University. Preprint at https://doi.org/10.48550/arxiv.2403.19857\nOuyang L, Wu J, Jiang X, Almeida D, Wainwright CL, Mishkin P, Zhang C, Agarwal S, Slama K, Ray A, \nSchulman J, Hilton J, Kelton F, Miller L, Simens M, Askell A, Welinder P, Christiano P, Leike J, Lowe \nR (2022) Training Language models to follow instructions with human feedback. Cornell University. \nPreprint at https://doi.org/10.48550/arxiv.2203.02155\nPatterson D, Gonzalez J, Holzle U, Le Q, Liang C, Munguia L-M, Rothchild D, So DR, Texier M, Dean J \n(2022) The carbon footprint of machine learning training will plateau, then shrink. Computer 55(7):18–\n28. https://doi.org/10.1109/mc.2022.3148714\nPetrov A, Emanuele LM, Torr PHS, Bibi A (2023) Language model tokenizers introduce unfairness between \nlanguages. Cornell University. Preprint at https://doi.org/10.48550/arxiv.2305.15425\nPlant R, Giuffrida V , Gkatzia D (2022) You are what you write: preserving privacy in the era of large Lan-\nguage models. Cornell University. Preprint at https://doi.org/10.48550/arxiv.2204.09391\nPłoszaj-Mazurek M, Ryńska E (2024) Artificial intelligence and digital tools for assisting low-carbon archi-\ntectural design: merging the use of machine learning, large language models, and building information \nmodeling for life cycle assessment tool development. Energies 17(12):2997.  h t t p s : / / d o i . o r g / 1 0 . 3 3 9 0 / e \nn 1 7 1 2 2 9 9 7       \nPoh CQX, Ubeynarayana CU, Goh YM (2018) Safety leading indicators for construction sites: a machine \nlearning approach. Autom Constr 93:375–386. https://doi.org/10.1016/j.autcon.2018.03.022\nPournader M, Ghaderi H, Hassanzadegan A, Fahimnia B (2021) Artificial intelligence applications in supply \nchain management. Int J Prod Econ 241:108250. https://doi.org/10.1016/j.ijpe.2021.108250\nPreuss N, Alshehri AS, You F (2024) Large language models for life cycle assessments: opportunities, chal-\nlenges, and risks. J Clean Prod 466:142824.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  1 6 / j .  j c l e p  r o . 2 0 2  4 . 1 4  2 8 2 4\nPrieto SA, Mengiste ET, De Soto BG (2023) Investigating the use of ChatGPT for the scheduling of construc-\ntion projects. Buildings 13(4):857. https://doi.org/10.3390/buildings13040857\nPu H, Yang X, Li J, Guo R (2024) AutoRepo: a general framework for multimodal LLM-based automated \nconstruction reporting. Expert Syst Appl 255:124601. https://doi.org/10.1016/j.eswa.2024.124601\nRadford A, Narasimhan K, Salimans T, Sutskever I (2018) Improving language understanding by generative \npre-training. OpenAI, San Francisco.  h t t p s :  / / c d n  . o p e n a  i . c o  m / r e s  e a r c h  - c o v e r  s / l a  n g u a g  e - u n s  u p e r v i  s e d /  l a \nn g u  a g e _ u  n d e r s t  a n d i  n g _ p a p e r . p d f. Accessed 8 Jan 2025\n1 3\nPage 43 of 46 250\nD. Kampelopoulos et al.\nRadford A, Wu J, Child R, Luan D, Amodei D, Sutskever I (2019) Language models are unsupervised multi-\ntask learners.  h t t p s :  / / a p i  . s e m a n  t i c s  c h o l a  r . o r g  / C o r p u  s I D :  1 6 0 0 2 5 5 3 3\nRaffel C, Shazeer N, Roberts A, Lee K, Narang S, Matena M, Zhou Y , Li W, Liu PJ (2019) Exploring the \nlimits of transfer learning with a unified text-to-text transformer. Cornell University. Preprint at  h t t p s : / / \nd o i . o r g / 1 0 . 4 8 5 5 0 / a r x i v . 1 9 1 0 . 1 0 6 8 3       \nRaiaan MAK, Mukta MSH, Fatema K, Fahad NM, Sakib S, Mim MMJ, Ahmad J, Ali ME, Azam S (2024) A \nreview on large language models: architectures, applications, taxonomies, open issues and challenges. \nIEEE Access 12:26839–26874. https://doi.org/10.1109/access.2024.3365742\nRane N (2023) ChatGPT and similar generative artificial intelligence (AI) for building and construction \nindustry: contribution, opportunities and challenges of large language models for Industry 4.0, Industry \n5.0, and Society 5.0. SSRN Electron J. https://doi.org/10.2139/ssrn.4603221\nRibeirinho M, Mischke J, Strube J, Sjödin E, Blanco J, Palter R, Biörck J, Rockhill D, Andersson T (2020) \nThe next normal in construction: how disruption is reshaping the world’s largest ecosystem. McKinsey \n& Company, New York\nRozière B, Gehring J, Gloeckle F, Sootla S, Gat I, Tan XE, Adi Y , Liu J, Remez T, Rapin J, Kozhevnikov A, \nEvtimov I, Bitton J, Bhatt M, Ferrer CC, Grattafiori A, Xiong W, Défossez A, Copet J, Azhar F, Touvron \nH, Martin L, Usunier N, Scialom T, Synnaeve G (2023) Code Llama: open foundation models for code. \nCornell University. Preprint at https://doi.org/10.48550/arxiv.2308.12950\nRumbelow J, Mwatkins (2023) SolidGoldMagikarp (plus, prompt generation).  h t t p s :  / / w w w  . l e s s w  r o n g  . c o m /  \np o s t s  / a P e J E  8 b S o  6 r A F o  L q g / s  o l i d g o  l d m a  g i k a r  p - p l u  s - p r o m  p t - g  e n e r a t i o n\nSaka A, Taiwo R, Saka N, Salami BA, Ajayi S, Akande K, Kazemi H (2023a) GPT models in construction \nindustry: opportunities, limitations, and a use case validation. Dev Built Environ 17:100300.  h t t p s : / / d o \ni . o r g / 1 0 . 1 0 1 6 / j . d i b e . 2 0 2 3 . 1 0 0 3 0 0       \nSaka AB, Oyedele LO, Akanbi LA, Ganiyu SA, Chan DWM, Bello SA (2023b) Conversational artificial \nintelligence in the AEC industry: A review of present status, challenges and opportunities. Adv Eng \nInform 55:101869. https://doi.org/10.1016/j.aei.2022.101869\nSanh V , Debut L, Chaumond J, Wolf T (2019) DistilBERT, a distilled version of BERT: smaller, faster, \ncheaper and lighter. Cornell University. Preprint at https://doi.org/10.48550/arxiv.1910.01108\nSanni-Anibire MO, Zin RM, Olatunji SO (2020) Machine learning model for delay risk assessment in tall \nbuilding projects. Int J Constr Manage 22(11):2134–2143.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  8 0 / 1 5  6 2 3 5 9  9 . 2 0 2 0  . 1 7 \n6  8 3 2 6\nScao TL, Fan A, Akiki C et al (2022) BLOOM: a 176B-parameter open-access multilingual language model. \nCornell University. Preprint at https://doi.org/10.48550/arxiv.2211.05100\nSeo J, Park H, Choo S (2020) Inference of drawing elements and space usage on architectural drawings using \nsemantic segmentation. Appl Sci 10(20):7347. https://doi.org/10.3390/app10207347\nShazeer N, Mirhoseini A, Maziarz K, Davis A, Le Q, Hinton G, Dean J (2017) Outrageously large neural \nnetworks: the sparsely-gated mixture-of-experts layer. Cornell University. Preprint at  h t t p s : / / d o i . o r g / 1 \n0 . 4 8 5 5 0 / a r x i v . 1 7 0 1 . 0 6 5 3 8       \nShinn N, Labash B, Gopinath A (2023) Reflexion: language agents with verbal reinforcement learning. Cor-\nnell University. Preprint at https://doi.org/10.48550/arxiv.2303.11366\nSinghal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, Scales N, Tanwani A, Cole-Lewis H, Pfohl S, \nPayne P, Seneviratne M, Gamble P, Kelly C, Scharli N, Chowdhery A, Mansfield P, Arcas BAY , Webster \nD, Corrado GS, Matias Y , Chou K, Gottweis J, Tomasev N, Liu Y , Rajkomar A, Barral J, Semturs C, \nKarthikesalingam A, Natarajan V (2022) Large Language models encode clinical knowledge. Cornell \nUniversity. Preprint at https://doi.org/10.48550/arxiv.2212.13138\nSinghal K, Tu T, Gottweis J, Sayres R, Wulczyn E, Hou L, Clark K, Pfohl S, Cole-Lewis H, Neal D, Schaeker-\nmann M, Wang A, Amin M, Lachgar S, Mansfield P, Prakash S, Green B, Dominowska E, Arcas BAY , \nTomasev N, Liu Y , Wong R, Semturs C, Mahdavi SS, Barral J, Webster D, Corrado GS, Matias Y , Azizi \nS, Karthikesalingam A, Natarajan V (2023) Towards expert-level medical question answering with large \nlanguage models. Cornell University. Preprint at https://doi.org/10.48550/arxiv.2305.09617\nSmetana M, De Salles LS, Sukharev I, Khazanovich L (2024) Highway construction safety analysis using \nlarge language models. Appl Sci 14(4):1352. https://doi.org/10.3390/app14041352\nSorscher B, Geirhos R, Shekhar S, Ganguli S, Morcos AS (2022) Beyond neural scaling laws: beat -\ning power law scaling via data pruning. Cornell University. Preprint at https://doi.org/10.48550/\narxiv.2206.14486\nTaiwo R, Bello IT, Abdulai SF, Yussif A-M, Salami BA, Saka A, Zayed T (2024) Generative AI in the con-\nstruction industry: a state-of-the-art analysis. Cornell University. Preprint at  h t t p s : / / d o i . o r g / 1 0 . 4 8 5 5 0 / \na r x i v . 2 4 0 2 . 0 9 9 3 9       \nTalebirad Y , Nadiri A (2023) Multi-agent collaboration: harnessing the power of intelligent LLM agents. \nCornell University. Preprint at https://doi.org/10.48550/arxiv.2306.03314\n1 3\n250 Page 44 of 46\nA review of LLMs and their applications in the architecture, engineering…\nTan K (2018) The framework of combining artificial intelligence and construction 3D printing in civil engi-\nneering. MATEC Web Conf 206:01008.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  5 1 / m a  t e c c o  n f / 2 0 1  8 2 0 6  0 1 0 0 8\nTaori R, Gulrajani I, Zhang T, Dubois Y , Li X, Guestrin C, Liang P, Hashimoto TB (2023) Alpaca: a strong, \nreplicable Instruction-following model. In: Stanford CRFM.  h t t p s :  / / c r f  m . s t a n  f o r d  . e d u /  2 0 2 3 /  0 3 / 1 3 /  a l p \na  c a . h t m l\nTouvron H, Lavril T, Izacard G, Martinet X, Lachaux M-A, Lacroix T, Rozière B, Goyal N, Hambro E, Azhar \nF, Rodriguez A, Joulin A, Grave E, Lample G (2023a) LLAMA: open and efficient foundation language \nmodels. Cornell University. Preprint at https://doi.org/10.48550/arxiv.2302.13971\nTouvron H, Martin L, Stone K et al (2023b) Llama 2: open foundation and fine-tuned chat models. Cornell \nUniversity. Preprint at https://doi.org/10.48550/arxiv.2307.09288\nTsai Y-HH, Bai S, Yamada M, Morency L-P, Salakhutdinov R (2019) Transformer dissection: a unified under-\nstanding of transformer’s attention via the lens of kernel. Cornell University. Preprint at  h t t p s : / / d o i . o r g \n/ 1 0 . 4 8 5 5 0 / a r x i v . 1 9 0 8 . 1 1 7 7 5       \nUddin SMJ, Albert A, Ovid A, Alsharef A (2023) Leveraging CHATGPT to aid construction hazard recogni-\ntion and support safety education and training. Sustainability 15(9):7121.  h t t p s : / / d o i . o r g / 1 0 . 3 3 9 0 / s u 1 5 \n0 9 7 1 2 1       \nVaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I (2017) Attention \nis all you need. Cornell University. Preprint at https://doi.org/10.48550/arxiv.1706.03762\nWang G, Xie Y , Jiang Y , Mandlekar A, Xiao C, Zhu Y , Fan L, Anandkumar A (2023) V oyager: an open-ended \nembodied agent with large language models. Cornell University. Preprint at  h t t p s : / / d o i . o r g / 1 0 . 4 8 5 5 0 / a \nr x i v . 2 3 0 5 . 1 6 2 9 1       \nWang J, Jiang H, Liu Y , Ma C, Zhang X, Pan Y , Liu M, Gu P, Xia S, Li W, Zhang Y , Wu Z, Liu Z, Zhong T, \nGe B, Zhang T, Qiang N, Hu X, Jiang X, Zhang X, Zhang W, Shen D, Liu T, Zhang S (2024) A com -\nprehensive review of multimodal large language models: performance and challenges across different \ntasks. Cornell University. Preprint at https://arxiv.org/abs/2408.01319\nWebson A, Pavlick E (2022) Do Prompt-Based models really understand the meaning of their prompts? In: \nProceedings of the 2022 conference of the North American Chapter of the Association for Computa -\ntional Linguistics: human language technologies.  h t t p s :  / / d o i  . o r g / 1  0 . 1 8  6 5 3 / v  1 / 2 0 2  2 . n a a c  l - m a  i n . 1 6 7\nWei J, Bosma M, Zhao VY , Guu K, Yu AW, Lester B, Du N, Dai AM, Le QV (2021) Finetuned lan -\nguage models are zero-shot learners. Cornell University. Preprint at https://doi.org/10.48550/\narxiv.2109.01652\nWilliams TP, Gong J (2014) Predicting construction cost overruns using text mining, numerical data and \nensemble classifiers. Autom Constr 43:23–29. https://doi.org/10.1016/j.autcon.2014.02.014\nXie R, Yu F, Wang J, Wang Y , Zhang L (2019) Multi-level domain adaptive learning for cross-domain detec-\ntion. Cornell University. Preprint at https://doi.org/10.48550/arxiv.1907.11484\nXie Y , Yu C, Zhu T, Bai J, Gong Z, Soh H (2023) Translating natural language to planning goals with large-\nlanguage models. Cornell University. Preprint at https://doi.org/10.48550/arxiv.2302.05128\nXue L, Constant N, Roberts A, Kale M, Al-Rfou R, Siddhant A, Barua A, Raffel C (2020) mT5: a massively \nmultilingual pre-trained text-to-text transformer. Cornell University. Preprint at  h t t p s : / / d o i . o r g / 1 0 . 4 8 5 \n5 0 / a r x i v . 2 0 1 0 . 1 1 9 3 4       \nYang H, Siew M, Joe-Wong C (2024) An LLM-based digital twin for optimizing human-in-the loop systems. \nCornell University. Preprint at https://doi.org/10.48550/arxiv.2403.16809\nYeom H-G, An K-M (2024) A simplified query-only attention for encoder-based transformer models. Appl \nSci 14(19):8646. https://doi.org/10.3390/app14198646\nYou H, Ye Y , Zhou T, Zhu Q, Du J (2023) Robot-enabled construction assembly with automated sequence \nplanning based on ChatGPT: RoboGPT. arXiv Preprint. Cornell University  h t t p s : / / d o i . o r g / 1 0 . 4 8 5 5 0 / a \nr x i v . 2 3 0 4 . 1 1 0 1 8       \nYu KH, Zhang Y , Li D, Montenegro-Marin CE, Kumar PM (2020) Environmental planning based on reduce, \nreuse, recycle and recover using artificial intelligence. Environ Impact Assess Rev 86:106492.  h t t p s : / / d \no i . o r g / 1 0 . 1 0 1 6 / j . e i a r . 2 0 2 0 . 1 0 6 4 9 2       \nZabin A, González V A, Zou Y , Amor R (2021) Applications of machine learning to BIM: a systematic litera-\nture review. Adv Eng Inform 51:101474. https://doi.org/10.1016/j.aei.2021.101474\nZaheer M, Guruganesh G, Dubey A, Ainslie J, Alberti C, Ontanon S, Pham P, Ravula A, Wang Q, Yang L, \nAhmed A (2020) Big Bird: transformers for longer sequences. Cornell University. Preprint at  h t t p s : / / d o \ni . o r g / 1 0 . 4 8 5 5 0 / a r x i v . 2 0 0 7 . 1 4 0 6 2       \nZhang L, Chen Z (2024) Large Language model-based interpretable machine learning control in Building \nenergy systems. Energy Build 313:114278.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  1 6 / j .  e n b u i  l d . 2 0 2  4 . 1 1  4 2 7 8\nZhang C, Kuppannagari SR, Kannan R, Prasanna VK (2019) Building HV AC scheduling using reinforce-\nment learning via neural network based model approximation. In: Proceedings of the 6th ACM inter -\nnational conference on systems for energy-efficient buildings, cities, and transportation (BuildSys ’19). \nhttps://doi.org/10.1145/3360322.3360861\n1 3\nPage 45 of 46 250\nD. Kampelopoulos et al.\nZhang L, Chen Z, Ford V (2024) Advancing building energy modeling with large language models: explora-\ntion and case studies. Energy Build 323:114788.  h t t p s :   /  / d o  i . o r  g /  1 0 .  1 0  1  6  / j . e n b  u  i l d .   2 0 2  4 . 1 1 4 7 8 8\nZheng J, Fischer M (2023) Dynamic prompt-based virtual assistant framework for BIM information search. \nAutom Constr 155:105067. https://doi.org/10.1016/j.autcon.2023.105067\nZhong Y , Goodfellow SD (2024) Domain-specific language models pre-trained on construction management \nsystems corpora. Autom Constr 160:105316. https://doi.org/10.1016/j.autcon.2024.105316\nZhu Z, Brilakis I (2010) Parameter optimization for automated concrete detection in image data. Autom \nConstr 19(7):944–953. https://doi.org/10.1016/j.autcon.2010.06.008\nZong M, Krishnamachari B (2022) A survey on GPT-3. Cornell University. Preprint at  h t t p s : / / d o i . o r g / 1 0 . 4 8 \n5 5 0 / a r x i v . 2 2 1 2 . 0 0 8 5 7       \nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\n1 3\n250 Page 46 of 46",
  "topic": "Architecture",
  "concepts": [
    {
      "name": "Architecture",
      "score": 0.6570653915405273
    },
    {
      "name": "Computer science",
      "score": 0.5765843391418457
    },
    {
      "name": "Construction engineering",
      "score": 0.3765676021575928
    },
    {
      "name": "Manufacturing engineering",
      "score": 0.33955511450767517
    },
    {
      "name": "Engineering management",
      "score": 0.3368690013885498
    },
    {
      "name": "Engineering",
      "score": 0.18646380305290222
    },
    {
      "name": "History",
      "score": 0.06630635261535645
    },
    {
      "name": "Archaeology",
      "score": 0.0
    }
  ]
}