{
  "title": "Human interpretable structure-property relationships in chemistry using explainable machine learning and large language models",
  "url": "https://openalex.org/W4406362282",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A3041959245",
      "name": "Geemi P. Wellawatte",
      "affiliations": [
        "École Polytechnique Fédérale de Lausanne"
      ]
    },
    {
      "id": "https://openalex.org/A2769065378",
      "name": "Philippe Schwaller",
      "affiliations": [
        "École Polytechnique Fédérale de Lausanne"
      ]
    },
    {
      "id": "https://openalex.org/A3041959245",
      "name": "Geemi P. Wellawatte",
      "affiliations": [
        "École Polytechnique Fédérale de Lausanne"
      ]
    },
    {
      "id": "https://openalex.org/A2769065378",
      "name": "Philippe Schwaller",
      "affiliations": [
        "École Polytechnique Fédérale de Lausanne"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2318794083",
    "https://openalex.org/W2069808050",
    "https://openalex.org/W2047880108",
    "https://openalex.org/W4313880353",
    "https://openalex.org/W3091146869",
    "https://openalex.org/W2213443318",
    "https://openalex.org/W2898397916",
    "https://openalex.org/W3040660552",
    "https://openalex.org/W2971894235",
    "https://openalex.org/W2753962198",
    "https://openalex.org/W3153418506",
    "https://openalex.org/W2117825133",
    "https://openalex.org/W3189831819",
    "https://openalex.org/W3129084747",
    "https://openalex.org/W3186757172",
    "https://openalex.org/W2910705748",
    "https://openalex.org/W4313650676",
    "https://openalex.org/W4360992523",
    "https://openalex.org/W2963095307",
    "https://openalex.org/W4307212054",
    "https://openalex.org/W2963660754",
    "https://openalex.org/W2916327454",
    "https://openalex.org/W2909392392",
    "https://openalex.org/W4225876201",
    "https://openalex.org/W4377096651",
    "https://openalex.org/W4385027818",
    "https://openalex.org/W4386638789",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4389991792",
    "https://openalex.org/W4391561379",
    "https://openalex.org/W4386269388",
    "https://openalex.org/W4394782456",
    "https://openalex.org/W4320005767",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4396723768",
    "https://openalex.org/W4310846703",
    "https://openalex.org/W2295598076",
    "https://openalex.org/W6675354045",
    "https://openalex.org/W6801744293",
    "https://openalex.org/W2282821441",
    "https://openalex.org/W2973049920",
    "https://openalex.org/W3096930897",
    "https://openalex.org/W4300961340",
    "https://openalex.org/W4389984066",
    "https://openalex.org/W4380995299",
    "https://openalex.org/W4394780593",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W2903086336",
    "https://openalex.org/W2942998504",
    "https://openalex.org/W2325265950",
    "https://openalex.org/W2213037131",
    "https://openalex.org/W2004550299",
    "https://openalex.org/W2910111753",
    "https://openalex.org/W2082179062",
    "https://openalex.org/W2069537362",
    "https://openalex.org/W3200571383",
    "https://openalex.org/W2983028326",
    "https://openalex.org/W4308516360",
    "https://openalex.org/W3000303921",
    "https://openalex.org/W2084879615",
    "https://openalex.org/W2276859037",
    "https://openalex.org/W2200017991",
    "https://openalex.org/W1502481667",
    "https://openalex.org/W2888978359",
    "https://openalex.org/W2062758529",
    "https://openalex.org/W2966797369",
    "https://openalex.org/W2766764421",
    "https://openalex.org/W1999197232",
    "https://openalex.org/W2914605496",
    "https://openalex.org/W2095189332",
    "https://openalex.org/W2027800468",
    "https://openalex.org/W2048044102",
    "https://openalex.org/W4393200050",
    "https://openalex.org/W4401306886",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4206956621",
    "https://openalex.org/W4205411722"
  ],
  "abstract": "Abstract Explainable Artificial Intelligence (XAI) is an emerging field in AI that aims to address the opaque nature of machine learning models. Furthermore, it has been shown that XAI can be used to extract input-output relationships, making them a useful tool in chemistry to understand structure-property relationships. However, one of the main limitations of XAI methods is that they are developed for technically oriented users. We propose the XpertAI framework that integrates XAI methods with large language models (LLMs) accessing scientific literature to generate accessible natural language explanations of raw chemical data automatically. We conducted 5 case studies to evaluate the performance of XpertAI. Our results show that XpertAI combines the strengths of LLMs and XAI tools in generating specific, scientific, and interpretable explanations.",
  "full_text": "communicationschemistry Article\nhttps://doi.org/10.1038/s42004-024-01393-y\nHuman interpretable structure-property\nrelationships in chemistry using\nexplainable machine learning and large\nlanguage models\nCheck for updates\nGeemi P. Wellawatte 1 & Philippe Schwaller 1,2\nExplainable Artiﬁcial Intelligence (XAI) is an emergingﬁeld in AI that aims to address the opaque nature\nof machine learning models. Furthermore, it has been shown that XAI can be used to extract input-\noutput relationships, making them a useful tool in chemistry to understand structure-property\nrelationships. However, one of the main limitations of XAI methods is that they are developed for\ntechnically oriented users. We propose the XpertAI framework that integrates XAI methods with large\nlanguage models (LLMs) accessing scientiﬁc literature to generate accessible natural language\nexplanations of raw chemical data automatically. We conducted 5 case studies to evaluate the\nperformance of XpertAI. Our results show that XpertAI combines the strengths of LLMs and XAI tools in\ngenerating speciﬁc, scientiﬁc, and interpretable explanations.\nUnderstanding structure–property relationships has been a long-standing\nchallenge in chemistry1–3 Seybold et al.2 highlight a fundamental concept in\nchemistry: the“properties and behaviors ofmolecules follow from their\nstructures”. Therefore, elucidating these r elationships facilitates the\nmanipulation of molecules to achievedesired properties. Machine learning\n(ML) is a routinely used tool to complement human expertize, which\nsolves complex tasks in chemistry by modeling structure –property\nrelationships4–8. While ML has been proven to be successful in solving such\nt a s k si nc h e m i s t r y9–15, experimental chemists often harbor skepticism\ntoward predictions generated by such models, primarily due to the inherent\nopacity of these models. In essence, these ML models usually do not provide\na rationale as to why a certain prediction was made. EXplainable Artiﬁcial\nIntelligence (XAI) is a new branch of AI that is rapidly growing and aims to\nexplain the opacity nature of ML models. Therefore, developing XAI tools\nfor chemistry is critical for increasing trust in ML models and expanding the\npossibilities of experimentaland computational chemistry.\nJustiﬁcations, explanations, and interpretability are three terms asso-\nciated with XAI\n16–18.W h i l eaj u s t iﬁcation simply provides evidence for a\nprediction19, an explanation describes the rationale for the prediction20.\nHowever, the true potency of XAI lies in its interpretability, which concerns\nthe extent to which a human can comprehend the provided explanation\n16.I n\nar e c e n ts u r v e y ,C a m b r i ae ta l .21 emphasized that there is a pressing need to\nreﬁne the presentation of explanations. This means that although XAI\naddresses the opacity of ML models, they are not user-friendly for non-\ndomain experts or non-technical users. Therefore, there is growing interest\nin incorporating natural language (NL) with XAI to produce more acces-\nsible explanations\n21,22. Furthermore, it’s worth noting that existing XAI\nmethods often lack theﬂexibility to address speciﬁcu s e rq u e r i e s— can\nusually answer only one speciﬁc question, impeding their adaptability23–26.\nTo meet this demand for creating intelligent, adaptable, and user-friendly\nXAI tools for chemistry, we introduce a Python package named“XpertAI”.\nOur tool combines XAI methods with large language models (LLMs) to\nextract structure–property relationships from raw data.\nLLMs are generative models which can predict an output sequence\ng i v e na ni n p u ts e q u e n c e .L L M sc a nb em a d ei n t op o w e r f u la g e n t st h a tq u e r y\ndatabases, scrape and summarize literature, interpret, and generate text in\nNL\n27. Currently, there has been a surge in LLM-based research in chemistry\nand related sciences. For example, Zhiling et al.28 showed that ChatGPT\ncould be used to accelerate text-mining and to predict metal–organic fra-\nmework (MOF) synthesis using prompt engineering. Kan et al.29 showed\nthat GPT-430 language model can be used in parameter selection of polymer\ninformatics. Furthermore, the authors highlight the importance of LLMs in\nresearch domains plagued with data scarcity. Boiko et al.\n31 introduced\nCoscientist, an AI system based on natural language, to design, plan, and\nexecute chemical experiments. However ,L L M si ni s o l a t i o nc a nb el i m i t e di n\naddressing domain-speciﬁcp r o b l e m sw i t h i nt h eﬁeld of chemistry. To\n1Laboratory of Artiﬁcial Chemical Intelligence, Institute of Chemical Sciences and Engineering, Ecole Polytechnique Fédérale de Lausanne (EPFL),\nLausanne, Switzerland.2National Centre of Competence in Research (NCCR) Catalysis, Ecole Polytechnique Fédérale de Lausanne (EPFL),\nLausanne, Switzerland. e-mail: geemi.wellawatte@epﬂ.ch; philippe.schwaller@epﬂ.ch\nCommunications Chemistry|            (2025) 8:11 1\n1234567890():,;\n1234567890():,;\ncircumvent such challenges at the intersection of chemistry and LLMs,\nJablonka et al.32 demonstrated thatﬁnetuning LLMs could provide a solu-\ntion to this. Relatedly, DARWIN33 is a series ofﬁnetuned open-source LLMs\ntailored for natural sciences. PMC-LLaMA34,G a l a c t i c a35,a n dM e d - P a L M36\na r eaf e wm o r ee x a m p l e so fﬁnetuned LLMs for scientiﬁc research. Fol-\nlowing a different approach, Bran et al.37 showed LLMs can be enhanced to\ntackle tasks such as organic synthesis,drug discovery, and materials design\nby integrating external tools rather thanﬁnetuning.\nMotivation\nPreviously, it has been suggested that“black-box modelingﬁrst, followed by\nXAI” as a means to establish structure–property relationships without\ncompromising accuracy or interpretability18. In this work, we present\nXpertAI, a framework that aims to establish connections between black-box\nmodels, XAI tools, and literature through LLMs to uncover relationships\nbetween molecular features and target properties. In a previous study,\nSeshadri et al.\n38 showed that LLMs combined with XAI can generate human-\ninterpretable explanations. Unlikeour approach, this work used LLMs only\nto summarize theﬁndings from the XAI analysis in natural language.\nHowever, we show that LLMs combined with XAI tools and literature\nevidence, play a powerful role in generating both interpretable and scien-\ntiﬁcally accurate explanations. This work demonstrates that combining XAI\nwith LLMs can be effectively used for hypothesis generation, marking a\npioneering effort in this direction.\nA ss h o w ni nF i g .1, given a raw dataset, XpertAI employs XAI methods\nto identify crucial structural features that are correlated with the target\nproperty. Next, it draws on scientiﬁc evidence from literature to articulate\nstructure–property connections based on these features. One key advantage\nof XpertAI is its ability to deliver precise natural language explanations\n(NLEs) tailored to speciﬁc datasets, as opposed to providing generalized\nexplanations drawn from the broader literature. As illustrated in Fig.2\nXpertAI combines the strengths of XAI and LLMs in terms of speciﬁcity (to\ngiven data), interpretability, accessibility, and scientiﬁcn a t u r eo ft h e\nexplanations. In other words, XAI only directs the users to a trained model’s\nrationale and does not provide scienti ﬁc reasoning, although the\nexplanations may be interpretable. We show that LLMs can be used to\naddress this limitation, thereby mimicking the practices that a scientist\nwill follow to establish a hypothesis given raw data. To the best of our\nknowledge, currently, there is no such tool in chemistry that extracts NL\nstructure–property relationships from user-given raw data. Furthermore,\nour application is generalizable to any domain that requires extracting\ninput–output relationships as NLEs.\nMethods\nWe begin the workﬂow by training an ML model using the initial raw data.\nThis model serves as a surrogate for mapping input to output. The initial\ndata frame includes feature molecular structures and target labels for\ntraining. Note that these features must be human-interpretable (e.g.,\nmolecular descriptors/properties, and MACCS keys). However, XpertAI\nwill also improve feature readability by default. Currently, we employ\ngradient-boosting decision trees withthe XGBoost framework, utilizing the\nScikit-learn API for regression and classiﬁcation tasks\n39,40. We selected\nXGBoost as our default surrogate model because it has been shown to\noutperform many general neural network architectures regardless of its\nsimplicity41. Additionally, this choice is motivated by training and inference\nefﬁciency, comparably higher interpretability, and ease of integration with\nXAI methods. Once the model is trained, users can select from SHAP42,\nLIME43, or both to estimate the“most impactful”features correlated with the\nmolecular properties.\nSHAP and LIME are possibly the most commonly used XAI methods\nto generate local explanations. Theyhave been used in previous studies to\ni n t e r p r e tr e l e v a n tf e a t u r e st h a tc o n t r i b u t em o s tt o w a r d st h et a r g e tp r o p e r t i e s\nin chemistry and adjacent domains\n38,44–46 In this study, we compute the\nmean SHAP values andZ-scores for LIME explanations to extract globally\nimpactful features rather than generating local explanations. For the LIME\nanalysis, we only use a sample of the initial dataset due to time and resource\nconstraints. The default sample size is either 500 or the entire dataset if its\nlength is less than 500. After identifying impactful features, we draw\nknowledge from the literature to elucidate physicochemical relationships\nbetween these features and the target property.\nFig. 1 | Overview of XpertAI.This tool combines XAI with LLMs to uncover human-interpretable structure–property relationships from raw data.\nhttps://doi.org/10.1038/s42004-024-01393-y Article\nCommunications Chemistry|            (2025) 8:11 2\nAs seen in the overview of our proposed workﬂow (Fig.1) LLMs are\nused to unite the backend modules ge nerating human-interpretable\nexplanations. More technically, XpertAI makes use of the retrieval aug-\nmented generation (RAG)\n47 approach to reliably generate scientiﬁce x p l a -\nnations using evidence gathered from the literature. LLMs’ inherent\nknowledge can be limiting in knowledge-intensive, data-sparseﬁelds such as\nchemistry and materials science48. Therefore, LLMs are prone to generate\nmisinformation and hallucinate answe r si ns u c hc a s e s .T h eR A Ga p p r o a c h\nis commonly used to avoid such limitations in LLMs as it augments the\nLLM’s internal knowledge with external data sources\n49. It fundamentally\nconsists of a retriever and a generator (the LLM). Usually, given a query,\nrelevant chunks of text are retrieved based on a distance metric. We leverage\non LangChain python package ( https://github.com/langchain-ai/\nlangchain) Chroma vector database ( https://github.com/chroma-core/\nchroma) (the retriever) and, OpenAI’sG P T - 4 o\n30 language model (the\ngenerator) in this workﬂow. This GPT-4o version (gpt-4o-2024-08-06 at the\ntime of publication) was trained on data up to October 2023 (https://\nplatform.openai.com/docs/models/gpt-4o). Users have the ﬂexibility to\nprovide a literature dataset or scrapearxiv.orgto gather relevant literature\ninformation. The latter is enabled via the arXiv python API.\nWe used a similar approach as the“StuffDocumentsChain” in Lang-\nChain to reﬁne the explanations. First, we select the most related literature\nexcerpts using maximal marginal relevance search (MMR). Then, the text\nexcerpts are“stuffed” to a specialized prompt to generate theﬁnal expla-\nnation. We utilize the chain-of-thought prompting approach\n50 where a\nseries of intermediate steps and examples are provided in the prompt to\nimprove the output’s interpretability. Prompts are given in Appendix B.\nXpertAI also generates and adds citations in theﬁnal NLEs to improve the\naccountability of the explanations.We would like to highlight that, in\naddition to the NLEs, XpertAI also provides the surrogate model’se v a l u a -\ntion plot (error plot) and XAI analysis plots for the users. To streamline this\ncomplete workﬂo w ,w eh a v ed e p l o y e daS t r e a m l i tA p p(https://xpert-ai.\nstreamlit.app/) that can be used with an OpenAI API key. More technically\noriented users can implement XpertAI locally using our GitHub repository:\nhttps://github.com/geemi725/XpertAI.\nResults\nWe used the XpertAI tool to suggest structure–property relationships for\nﬁve case studies in chemistry: (1) the presence of open metal sites in\nmetal–organic frameworks (classiﬁcation), (2) pore-limiting diameter in\nmetal–organic frameworks (regression),(3) toxicity of small molecules\n(classiﬁcation), (4) solubility of small molecules (regression), and (5) upper\nﬂammability limit of organic molecules (regression). Please note that we\nused the SHAP method as the chosen XAI method and its default\nhyperparameters to generate NLEs in the following case studies. We chose\nthe SHAP method due to its consistencyin generating global explanations in\ncomparison to LIME. Complete NLEs and SHAP plots for each case study\nfrom XpertAI are provided in Appendices A and E in SI respectively. A set of\npublished articles was uploaded for each case study to draw scientiﬁce v i -\ndence. These articles were manually curated based on relevance, number of\ncitations, and the impact factor of the published journal. However, the\nrelevance of the article to the task at hand was prioritized over other criteria.\nWe only included peer-reviewed articles in this step to ensure scientiﬁc\naccountability. An additional technical beneﬁti st h el o w e rr e c a l lw i t h i nt h e\nRAG framework. The references to the articles used in this work can be\nfound in the XpertAI GitHub repository. Please note that XpertAI provides\nthe option to automatically scrape articles fromarxiv.org in place or in\naddition to uploading user-preferred literature.\nCase studies 1 and 2: structure– property relationships in\nmetal– organic frameworks (MOFs)\nMOFs, a hybrid class of materials in chemistry, consist of metal nodes\nconnected by organic linkers51. Their porous nature lends them versatile\nproperties such as gas separation and storage52–54, catalysis55,56,a n dd r u g\ndelivery57,58. Understanding MOF structure–property relationships is cru-\ncial for optimizing their design in speciﬁc applications. Open metal sites,\ncharacterized by coordinative unsaturation,ﬁnd valuable use in catalysis51.\nAdditionally, the pore-limiting diameter is a key feature for screening them\nin selective gas capture applications\n59. However, the precise relationship\nbetween MOF atomic structure and openm e t a ls i t e so rp o r e - l i m i t i n gd i a -\nmeter remains incompletely understood.\nIn case study 1, we sampled 4000 MOFs from the CoRE MOF 2019\ndatabase60 that contained labels for the presence of open metal sites and\npore-limiting diameter. After input validation and the featurization step, we\nended up with 3734 structures. These crystal structures obtained as CIFﬁles\nwere then featured using the CrystalFeatures tool\n61. Generated features are\ninterpretable descriptors encompassing atomic and crystal characteristics,\ngeometry features, and one-shot ab initio descriptors. Next, we uploaded the\nfeatured inputs and (binary) target labels as a CSV data frame along with a\npre-selected literature dataset containing 41 publications to our XpertAI\nStreamlit App. The list of publications can be found in our GitHub repo-\nsitory. The generated NLE from XpertAI explains how (a) metals fraction,\n(b) density of solid, and (c) average cationic radius correlate with the pre-\nsence of open metal sites. The XpertAI explanation aligns with theﬁndings\nof Hall et al.\n51, where the authors identify metal identity and oxidation state,\ndefect density, and site proximity as impactful structural components. Note\nthat we omitted this review paper\n51 in the literature dataset uploaded to\nXpertAI to avoid data leakage.\nFig. 2 | Attributes of XpertAI explanations.XpertAI explanations against baseline methods (XAI, LLMs, and LLMs+ Literature) across four key attributes: interpretability,\ntargeted explanations, incorporation of literature evidence, and accessibility to non-technical users.\nhttps://doi.org/10.1038/s42004-024-01393-y Article\nCommunications Chemistry|            (2025) 8:11 3\nFollowing a similar approach in case study 2, we used the same MOF\ndataset but with pore-limiting diameters as the label. Unlike case study 1,\nthis is a regression-type problem. Weuploaded a literature dataset with 24\njournal articles to support XpertAI explanations. The pore size characterized\nby the pore-limiting diameter is animportant property in MOFs that can\ncontrol charge transfer and direct air capture\n62. According to XpertAI, key\nfactors inﬂuencing the pore-limiting diameter include volume per atom,\nsymmetry function G, and unoccupied energy levels at the conduction band.\nFor instance, XpertAI hypothesizes that“Symmetry Function G1 may\nimpact the pore-limiting diameter by inﬂuencing the spatial arrangement of\natoms, potentially affecting the uniformity and size of the pores”.I tc o n -\ntinues to state that“an explicit relationship between Symmetry Function G1\nand the pore-limiting diameter wasnot found in the given documents.\nHowever, the documents discuss the geometric properties of MOFs, which\nare inherently related to symmetry\n63”. This highlights XpertAI’s capability to\nproduce insightful and plausible explanations while maintaining scientiﬁc\nrigor, avoiding speculative conclusions when supporting evidence is absent.\nWe prompted XpertAI to go beyond merely identifying the most relevant\nmolecular features associated with the target property. It also hypothesizes\npotential structure–property relationships and offers scientiﬁc reasoning,\ndrawing on insights from the provided literature, emulating the approach a\nhuman scientist would take. For a comprehensive textual explanation,\nplease refer to the Supporting Information (Appendix A).\nCase study 3: small molecule toxicity\nToxicity prediction of small molecules is a benchmark task in chemistry,\nparticularly in drug discovery64,65. Despite the extensive research in this area,\na precise understanding of the relationship between molecular structure and\ntoxicity remains elusive. In this case study, we sampled and validated 1478\nmolecules from the Tox21 database\n64 where binary labels indicate toxicity (a\nclassiﬁcation task). Then we featurized the input molecules in SMILES\nformat using MACCS descriptors65 implemented in the RDKit package66.\nThese descriptors are human-interpretable binary features containing 167\nyes/no questions regarding molecular structure. Additionally, we used 45\nmanually curated journal articles to gather scientiﬁce v i d e n c ef o rt h eX A I\nobservations. XpertAI identiﬁes the presence of a heteroatom bonded to\nthree oxygen atoms, tertiary amine and carbon-oxygen single bond to be\nassociated with the toxicity of molecules. The generated XpertAI explana-\ntion summarizes:“The analysis of features identiﬁe db yX A Ii nr e l a t i o nt o\nthe toxicity of small molecules reveals several key insights. The presence of a\nheteroatom bonded to three oxygen atoms, such as in phosphate groups, is\nassociated with increased chemical reactivity due to the electronegative\nnature of oxygen atoms, potentially inﬂuencing toxicity. Tertiary amines,\nknown for their nucleophilic properties, may interact with electrophilic sites\nin biological systems, contributing to toxicity. Additionally, carbon-oxygen\nsingle bonds, prevalent in functional groups like alcohols and ethers, can\naffect the solubility and reactivity ofmolecules, thereby impacting their\ntoxicity. These features highlight the complex interplay between chemical\nstructure and biological activity, underscoring the importance of under-\nstanding molecular interactions in toxicity predictions.” We note that the\nXpertAI explanation aligns with theﬁndings in work by Meanwell\n67 and\nLimban et al.68 which state that aromatic amines and nitro groups are\nassociated with increasing molecular toxicity. These references were not\nincluded in the literature dataset uploaded to XpertAI. The complete\nXpertAI NLE can be found in SI (Appendix A). While XpertAI suggests that\nthese features can alter toxicity as they affect the reactivity of the molecules\nand their ability to form reactive species, it’s important to note that toxicity is\na complex property that is likely inﬂuenced by a combination of many\nfeatures.\nCase study 4: small molecule solubility\nAqueous solubility of small molecules isa critical property in drug discovery\nas solubility determines the interaction of the drug in a biological\nenvironment\n69. To explain the relationship between the molecular structure\nand its solubility, we used a sample dataset with 9982 molecules from the\nAqSolDB\n70 dataset for training. Once again, we used MACCS descriptors to\nconvert the molecules into a binary vector.\nWe uploaded a literature dataset with 27 related publications.\nReferences to these can be found in our GitHub repository. XpertAI\nexplains the structure–solubility relationship as follows.“The features\nidentiﬁed by the XAI analysis, such as the presence of an atom at an\naromatic/non-aromatic boundary, two heteroatoms bonded to each other,\nand an atom with three heteroatom neighbors, all show strong negative\ncorrelations with solubility. These features likely inﬂuence solubility by\naffecting molecular planarity, symmetry, electronic distribution, and\nhydrogen bonding potential. The presence of aromatic boundaries and\nheteroatom interactions can maintain molecular structures that are less\nfavorable for solubility, as supported by the SHAP analysis and literature\non molecular modi ﬁcations for solubility enhancement (XpertAI,\n2024)”\n71,72.F i g u r e3 is an additional expert from the XpertAI explanation\nwith its native formatting. Complete explanations can be found in SI\n(Appendix A). This further demonstrates XpertAI’s accessibility as a tool\nthat generates credible, natural language explanations of molecular\nstructure–property relationships. To the best of our knowledge, XpertAI is\ncurrently the only tool that combines explainable AI (XAI) with large\nlanguage models (LLMs) to interpret such relationships.\nFig. 3 | An excerpt from the XpertAI exaplnation.\nThis illustrates how XpertAI combines features\nidentiﬁed through XAI analysis, scientiﬁc evidence,\nand hypotheses to provide interpretable and tar-\ngeted insights into molecular behavior.\nhttps://doi.org/10.1038/s42004-024-01393-y Article\nCommunications Chemistry|            (2025) 8:11 4\nCase study 5: compoundﬂammability\nThe upper ﬂammability limit (UFL) of an organic compound is an\nimportant characteristic that determines the hazardous nature of the\ncompound73. This is an interesting topic of study in both experimental and\ncomputational studies74–77. We used the UFL dataset used by Yuan et al.73,\nwhich was extracted from reference Crowl and Louvar78.T h i sd a t a s e to n l y\ncontained 79 organic compounds.W eu s e dt h es a m eq u a n t u ma n dn o n -\nquantum molecular descriptor set used in ref.73 to feature the molecules.\nAfter uploading the initial dataset and15 curated publications, we obtained\nthe following explanation.“The features identiﬁed by the XAI analysis,\nincluding the structural information content index (neighborhood sym-\nmetry of zero-order), information content index (neighborhood symmetry\nof order), and dipole moment, all play signiﬁcant roles in determining the\nupper ﬂammability limit (UFL) of organic molecules. The Structural\nInformation Content Index (neighborhood symmetry of zero-order) and its\ngeneralized form, information content index (neighborhood symmetry of\norder), quantify molecular symmetry, which inﬂuences molecular stability\nand reactivity. These factors can be crucial in determining how easily a\nmolecule can ignite and sustain combustion. The dipole moment, although\nnot explicitly discussed in the provided documents, could affect molecular\ninteractions and stability, thereby inﬂuencing ﬂammability. These features\ncollectively provide a comprehensive understanding of the molecular\ncharacteristics that impact the UFL of organic compounds.”\nThis case study is intentionally used as a negative example. We\ndeliberately selected a smaller datasetwith limited supporting literature,\nanticipating that the surrogate model would not be fully trained and may\npotentially produce spurious relationships. Furthermore, cross-referencing\nrevealed that the provided literature did not explicitly identify any corre-\nlations between the features examined and the upperﬂammability limit\n(UFL). As provided in SI Appendix A, XpertAI provides a complete, textual\nexplanation extracted from raw data. However, this may not correctly reﬂect\nthe underlying molecular structure–property relationship.\nEvaluations\nFirstly, to evaluate the explanations for the listed case studies, we compared\nthree different explanations from: (1) XpertAI, (2) ChatGPT (GPT-4o), and\n(3) Graphical plots from the XAI analysis. The aim was to evaluate if\nXpertAI can leverage the advantages of both XAI and LLMs, rather than\nusing one alone. We askedﬁve expert chemists (graduate students in\nchemistry) to score 15 explanations in total (5 tasks × 3 explanations). The\nexperts were given a scorecard (given in SI’s Appendix D) to evaluate each\nanswer based on accuracy, interpretability, accessibility, usefulness in\nresearch, and speciﬁcity to given data. Each category was given an arbitrarily\nselected maximum score of 6 for evaluation purposes. Values per answer are\ngiven next to answers in Appendix D.\nAs seen in Fig.4, on average, evaluators scored XpertAI NLEs highly\nunder each category. In all 5 tasks, experts identiﬁed that ChatGPT\nexplanations are not tailored to the given dataset. Contrastively, evalua-\ntors agreed that while XAI results (SHAP plots in this case) are speciﬁct o\ngiven data, these lack accessibility and interpretability. Often, XAI plots\nwere labeled as not useful for further research. On the other hand, it can\nbe inferred from Fig.4 that XpertAI explanations were preferred in terms\nof interpretability, reliability, and speciﬁcity. As summarized in Fig.2, the\nevaluations conclude that XpertAI effectively combines the advantages of\nboth ChatGPT and XAI to provide a complete explanation. The expert\nscores further validate the accomplishment of our goal to extract acces-\nsible and interpretable structure–property relationships in chemistry\nfrom raw data. Based on expert scores for individual studies, we noted\nthat for case studies 1–4 XpertAI’s explanations always scored better or as\nequally as ChatGPT, in terms of interpretability, accessibility, and use-\nfulness. As expected, for our negative case study, experts scored XpertAI\nlower than ChatGPT in all categories except for speciﬁcity. We point out\nthat, this is possibly due to inadequate training of the surrogate model\nused in the XAI study. We highlight that XpertAI’s success is dependent\nupon both the XAI method and LLM’s capabilities. A surrogate model\nthat can capture the“True” relationship as closely as possible can accu-\nrately identify the most impactful molecular features, LLM’s performance\ndetermines the interpretability and credibility of the generated explana-\ntions. Additionally, it should be emphasized that the quality of the gen-\nerated explanations is also dependent on the quality of the literature\ndataset provided. In all 5 case studies, we used manually curated, peer-\nreviewed journal articles only. These were selected based on the number\nof citations, relevance, and the impact factor of the journal. Note that a\nsystematic selection of literature articles balances the precision and recall\nFig. 4 | Human expert consensus for all case studies and the mean scores.Five\nhuman experts (graduate students in chemistry) were asked to evaluate explanations\nfrom XpertAI, ChatGPT, and SHAP plots for each case study based on accuracy,\ninterpretability, accessibility, usefulness in research, and speciﬁcity to given data.\nEach category was given a maximum score of 6.\nhttps://doi.org/10.1038/s42004-024-01393-y Article\nCommunications Chemistry|            (2025) 8:11 5\nof the generated references. The lists of references used can be found in\nour GitHub repository.\nAdditionally, we observe that XpertAI scored comparatively less in case\nstudy 3. We argue this is because human experts excel at validating broad\nscientiﬁc understanding and not knowledge speciﬁct oag i v e nd a t a s e t .\nHowever, XpertAI’s explanations are speciﬁc to relationships established\nfrom provided datasets, which may be different from familiar concepts in\nchemistry. While ChatGPT can generate broad explanations that can\nresemble general chemical understanding, these explanations are vulnerable\nto hallucinations and misinformation. The advantage of XpertAI is that it\novercomes these vulnerabilities by using the RAG approach.\nWe further evaluated the precision of the generated hypotheses by\nXpertAI and compared with GPT-4o explanations. For each task and each\nfeature that is identiﬁed in the XpertAI explanation, we extracted each\nproposed hypothesis and labeled the correlation of the feature with the\nproperty under study (OMS, PLD etc.) aspositive, negative,o r\nunclear. An example of an unclear correlation is“Metal ions with\nfavorable redox properties might be more likely to form stable open metal\nsites.” We used the following formula to compute the precision.\nprecision ¼\n1\nNfeatures × Nruns\nXNfeatures\ni\n∣ð1Þ × ni;positive þð /C0 1Þ × ni;negative\nþð0Þ × ni;unclear∣\nð1Þ\nHere, Nfeatures is the total number of unique features listed in the\nexplanations, andNruns = 5. assigned arbitrary weights of+1, −1, and 0 to\ncalculate precision ∈ 0, 1. These weights allow us to assess whether the\ngenerated explanations align or diverge at the feature level. The results\ns h o w ni nF i g .5 reﬂect this analysis. XpertAI either outperforms or is\ncomparable to the baseline at the feature level, except for case study 5, our\nnegative example. In instances where XpertAI scores were lower, the\nmajority of per-feature correlations were classiﬁed asunclear,r eﬂecting\nthe absence of explicit correlations in the literature. This suggests that\nXpertAI avoids generating speculative or unfounded conclusions. Con-\nversely, while the GPT-4o baseline model demonstrated more consistency\nin its claims across theﬁve runs, there is no assurance that these claims or\ncorrelations are free from hallucinations.\nNext, to assess the overall content of XpertAI and ChatGPT explana-\ntions, we asked Claude AI assistant (https://claude.ai/)b yA n t h r o p i chttps://\nwww.anthropic.com/to compare the two explanations based on relevance,\naccuracy, and interpretability. Thecomplete responses from Claude are\ngiven in SI (Appendix C). Based on the responses, Claude rates the expla-\nnations from XpertAI higher than ChatGPT’s for all case studies except for\ncase study 5. We summarize the evaluations by Claude for ranking Xper-\ntAI’s explanations higher. Note that we anonymized the two explanations\nduring the scoring; Explanation A is by XpertAI, and Explanation B\nis by ChatGPT. Each evaluation was run independently to avoid model\nbiases.\n Explanation A directly discusses the speciﬁc features identiﬁed by the\nXAI analysis and provides concrete examples of how changing those\nfeatures affects the target property, indicating high relevance for\nresearch. Explanation B provides a more general background on how\nmolecular structure inﬂuences the target properties. While still rele-\nvant, it does not directly address the speciﬁc features called out in the\nXAI analysis.\n By extensively referencing multiple recent studies on the topic,\nExplanation A establishes accuracyin its explanations. The research\nevidence lends credibility and precision to the statements made.\nExplanation B does not provide any citations, making its accuracy\nmore uncertain.\n Explanation A is more narrowly tailored to the speciﬁcq u e s t i o no fh o w\nthe features identiﬁed in the XAI analysis impact target properties. It\nprovides mechanistic interpretations, examples, and literature refer-\nences. This level of relevance, interpretability, and accuracy makes\nExplanation A better suited for guiding further research compared to\nthe more general background provided in Explanation B.\nHowever, for case study 5, Claude ranked the ChatGPT explanation\nhigher. This is similar to the observations from expert evaluations.\nAccording to Claude, Explanation B provides a more thorough and\nrelevant discussion of how molecular structure impacts the upper\nﬂammability limit. It covers key structural factors and gives useful insight\ninto the research question. However, Explanation A while relevant, lacks\nthe comprehensive coverage of Explanation B. We hypothesize this is due\nto the underperformance of the trained XGBoost model, as evidenced by\na higher root-mean-square error (RMSE) during testing, which results in\nXpertAI’s lower-rated explanation. This possibly stems from the limited\nsize of the training dataset (only 63 data points for training). As a result,\nthe XAI analysis reveals the model could have learned non-causal\nFig. 5 | Mean precision of hypotheses generated\n(↑). XpertAI-generated hypotheses are compared\nwith baseline GPT-4o. Equation (1) was used to\ncompute the precision∈ {0, 1}. Error bars represent\nthe standard deviation.\nhttps://doi.org/10.1038/s42004-024-01393-y Article\nCommunications Chemistry|            (2025) 8:11 6\ncorrelations within the dataset. Therefore, the essential features may not\nbe faithfully represented, thereby leading XpertAI to generate aﬂawed\nexplanation.\nNext, we validated the accuracy of the citations. Based on the results\ngiven in Table1 we see that XpertAI’s citations are accurate and relevant.\nAlthough XpertAI incorrectly cites ref.60 in case study 2:PLD, the text\nmentions the acronymPLD. However, in cases where XpertAI does not\nﬁnd explicit relationships in the text, it highlights this and avoids false\ncitations.\nBased on our analyses, we conclude that XpertAI’s overall cross-\nreferencing performance is satisfactory. However, we observed that one\nof the main causes of failure stems from the absence of feature labels in the\nscientiﬁc text. For example, in case studies 2 and 4, XpertAI attempts to\ncross-reference feature label such as“symmetry function G1”, “unoccu-\npied energy levels at conduction band minimum”, and“presence of an\natom with three heteroatom neighbors” in the provided literature corpus.\nWe therefore underscore the importance of carefully selecting feature\ndescriptions. Although XpertAI can search for synonymous descriptors\nwhen the exact label is unavailable, this process can result in deviations\nfrom the original XAIﬁndings. We note signiﬁcant room for improve-\nment within the XpertAI framework by increasing the number of pro-\nvided literature articles, although this would lead to increased recall.\nAdditionally, providing XpertAI access to automated literature scraping\ntools can signiﬁcantly enhance its capacity for scientiﬁc explanation. This\nexpanded toolkit allows the agent to perform more comprehensive\nanalyses, utilize specialized resources, and deliver more accurate and\nnuanced interpretations of complex scienti ﬁc concepts. There are\nnumerous leading works investigating this speciﬁc problem, which are\nbeyond the scope of this study.\nOpen-XpertAI: exploring open-source LLMs\nIn the previous sections, we demonstrated that XAI combined with GPT-4o\ngarners signiﬁcant advantages in explaining structure–property relation-\nships in molecules. However, a notable limitation of this approach lies in the\nproprietary nature of GPT-4o, necessitating a paid license for its utilization.\nConversely, there exists a substantial array of open-source LLMs that have\ndemonstrated remarkable prowess in text generation. In addition to the\nﬁnancial beneﬁts, open-source LLMs also provide transparency,ﬂexibility,\nand the beneﬁt of community contributions. Nonetheless, it is important to\nacknowledge that despite these advantages, the overall performance of these\nmodels still trails behind that of GPT-4o. In a related study, Bai et al.\n79\nevaluated the applications of open-source LLMs in MOF research.\nTo investigate the feasibility of integrating open-source LLMs into\nXpertAI, we conducted a brief study. We assessed the performance of 4\nopen-source LLMs that have demonstrated comparable capabilities to GPT-\n4, focusing on the accuracy of their generated explanations. The selected\nLLMs were: Llama3.1:8b\n80, Llama2:7b81, Mixtral:8 × 7b-instruct-v0.1-\nq5_082, Starling-lm:7b-alpha83 and Phi:2.7b84. These open-source LLMs\nwere conﬁgured and executed locally utilizing Ollama, a streamlined AI tool\ndesigned for the local deployment of open-source LLMs. For all LLMs\nexcept Mixtral:8 × 7b-instruct, Q4_0 quantization level was used. While we\nutilized a selection of open-source LLMs available at the time of research, we\nacknowledge that more advanced models may be available at the time of\npublication, and future studies could beneﬁt from these enhanced versions.\nDetailed performance metrics of each LLM against benchmark datasets can\nbe found in the respective references.\nThis study aims to assess the abilityof open-source LLMs to accurately\ngenerate explanations within an RAG system like XpertAI as an alternative\nto proprietary LLMs. We generated explanations from these LLMs using\nthe same molecular features and literature data employed in previous case\nstudies. Then a human evaluator was asked to assess the accuracy of\nthe generated explanations for all 5 case studies. The evaluator assigned a\nscore of 1 for accurate explanations and 0 for inaccurate ones. The scores for\nreferences were averaged by the number of references in each explanation\nbefore totaling. Please see Table2 for the summarized results. We generated\n5 explanations per case study and computed RougeL scores to gauge the\nvariation among explanations. The average RougeL scores over the 5 case\nstudies are given in Table2. Although the RougeL score can be used as a\nmeasure of variability in the content, this is not an indication of the accuracy\nof the explanations. Please see SI (Appendix F) for RougeL scores for\nindividual case studies. In our analysis, we noted that some LLMs have\nhigher RougeL scores than XpertAI explanations. However, XpertAI\nTable 1 | Quantitative analysis of citation accuracy in XpertAI\nexplanations\nCase study Citation accuracy Comments\nOMS 2/3 Ref. 60 was neither correct nor relevant.\nPLD 1/2 Ref. 60 mentions PLD, but the citation was\nincorrect.\nTOX 1/1 No issues with citations.\nSOL 2/2 No issues with citations.\nUFL 2/2 No issues with citations.\nTable 2 | Evaluation of open-source LLM-generated explanations in XpertAI\nLLM Num. parameters\nand (Ollama\nquant. level)\nAccurately describes\neach feature and how it\nis related to the target\nAccurately describes\nhow the target can be\naltered w.r.t. each\nfeature\nLists and explains\nadditional\nfeatures\nAccuracy of\ngenerated\nreferences\nAverage\nRougeL\nscore ± SD\nLlama3.1\n80 8B 4 4 5 1.8 0.6 ± 0.02\n(Q4_0)\nLlama281 7B 0 1 2 0.3 0.52 ± 0.05\n(Q4_0)\nmixtral:8 × 7b-\ninstruct-v0.1\n82\n8 × 7B 4 5 5 1.25 0.49 ± 0.04\n(Q5_0)\nPhi-284 7B 1 0 3 0 0.38 ± 0.06\n(Q4_0)\nStarling-LM:7b-\nalpha\n83\n7B 5 2 4 1.6 0.46 ± 0.02\n(Q4_0)\nXpertAI (GPT-4o)30 N/A 5 5 5 0.82 0.46 ± 0.05\nThe total scores of all 5 tasks are given here. Highest score= 5. GPT-4o is the default in XpertAI. B stands for Billion innum.parameters column.\nhttps://doi.org/10.1038/s42004-024-01393-y Article\nCommunications Chemistry|            (2025) 8:11 7\noutperformed all open-source modelsacross the listed metrics in Table2.\nFrom the results, we observe that mixtral (8 × 7b-instruct-v0.1-q5_0),\nLlama3.1:8b, and starling (7b) models demonstrate performance compar-\nable to GPT-4. Speciﬁcally, the latter’s small size makes it an attractive\noption to be implemented in RAG pipelines. However, it’s worth noting that\nnone of the open-source models excelled in generating references accurately.\nFrequently, these models provided incorrect references or failed to generate\nreferences altogether. Additionally, we observed substantial improvements\nin the explanations provided by Llama3.1:8b\n80 compared to those of\nLlama281. Notably, Llama3.1:8b indicates when citations are hypothetical by\nstating“generated citations are hypothetical”if the references are inaccurate.\nThis feature signiﬁcantly reduces the likelihood of misinformation\nappearing in the explanations generated by Llama3.1:8b. Based on these\nobservations, we conclude that we can be optimistic about using open-\nsource LLMs in place of proprietary models. Note that these open-source\nexplanations can further be improved with other techniques, such as\nprompt engineering and/orﬁnetuning. We did not investigate this aspect as\nit is beyond the scope of our study.\nConclusion and outlook\nX A Ii sb e c o m i n gi n c r e a s i n g l yi m p o r t a n ti nM Lw o r kﬂows due to develop-\nmental, scientiﬁc, and regulatory needs. In this context, we addressed a key\nchallenge in applying XAI to chemistry— the lack of interpretability and\nscientiﬁc grounding of explanations generated by XAI tools. Generally, XAI\ntools are developed with technical experts in mind, thereby reducing usability.\nWe proposed“XpertAI”, a framework leveraging XAI and LLMs to generate\nintelligent natural languageexplanations of structure–property relationships\nfrom raw chemistry data. In other words, XpertAI can be perceived as an LLM\nagent for hypotheses generation thatconsists of two main components: (1)\nXAI methods and (2) a RAG model. XpertAI produces readily interpretable\nand speciﬁc explanations while uncovering structure–property relationships.\nWe showed integrating XAI and LLMs is more powerful than using either\nalone. Furthermore, we demonstratedthat this combination can accurately\nexplain input–output relationships, not just model predictions.\nWe would like to highlight that XpertAI’s performance is limited by (a)\nthe surrogate model’s ﬁt, (b) feature descriptions, and (c) the RAG model’s\nperformance (literature retrieval and augmented text generation). Firstly, if\nthe surrogate model has acquired spuriousdata relationships, it will inevitably\nyield an inaccurate explanation. In the current version of XpertAI, hyper-\nparameters are hardcoded to enhance non-expert usability. In our upcoming\nwork, we plan to integrate automated hyperparameter optimization. Addi-\ntionally, we aim to incorporate other ML models and enable user-provided\nmodels, giving moreﬂexibility. However, if a user intends to implement an\nexisting model, they can do so easily using the GitHub codebase.\nOn the other hand, the quality of the explanations is governed by the\ndescriptions of the feature labels and the RAG model’sp e r f o r m a n c e .F o r\ninstance, if the features are not found in the literature, the precision of the\ngenerated explanations will be low. However, XpertAI is prompted to output\n“a ne x p l i c i tr e l a t i o n s h i pw a sn o tf o u n di nt h eg i v e nd o c u m e n t s” if it fails to\nﬁnd literature evidence. It is important to note that feature selection sig-\nniﬁcantly impacts theﬁt of the surrogate model. Therefore, careful selection\nof input features is crucial within the XpertAI framework. Enhancing the\nperformance and efﬁciency of the RAG model is an ongoing topic of inves-\ntigation that is beyond the scope of our work. However, we anticipate that\nimprovements in existing tools and methodologies will enhance XpertAI’s\noverall performance. For example, better-performing retrievers and LLMs\nwill undoubtedly improve XpertAI’s capabilities. The current version of\nXpertAI serves as a proof of concept that XAI integrated with LLMs can be a\nproxy for hypothesis generation in Chemistry. XpertAI mimicks the work-\nﬂow a scientist would follow to arrive at a hypothesis— following an obser-\nvation, a hypothesis is generated andsupported with literature evidence.\nGiven the growth of tools and methodologies based on LLMs, we aim that\nXpertAI can become a powerful hypothesis-generating agent in the future.\nAs we showed previously, open-source LLMs exhibit encouraging signs\nto be used in place of proprietary GPT models in RAG models. Therefore,\nour future work will incorporate streamlining the use of open-source LLMs\ninto XpertAI as an alternative to GPT-4 dependencies. This will further\nincrease XpertAI’s accessibility to generate accurate explanations.\nDespite current limitations, XpertAI demonstrates potential as an\ninterpretable approach that combines XAI and LLMS for uncovering novel\nstructure–property relationships and generating scientiﬁc insights in\nchemistry. By leveraging AI’s strengths in explanation and language,\nXpertAI accelerates scientiﬁc progress through chemical knowledge\nextraction and hypothesis generation.This exciting advancement elucidates\nmeaningful chemical structure–property relationships, thereby propelling\ndiscovery.\nCode availability\nCode to XpertAI can be found athttps://github.com/geemi725/XpertAIand\nthe XpertAI App can be found athttps://xpert-ai.streamlit.app/.\nData availability\nRelevant data can be found athttps://github.com/geemi725/XpertAI.\nReceived: 20 July 2024; Accepted: 11 December 2024;\nReferences\n1. Wiener, H. Structural determination of parafﬁn boiling points.J. Am.\nChem. Soc.69,1 7–20 (1947).\n2. Seybold, P. G., May, M. & Bagal, U. A. Molecular structure: property\nrelationships. J. Chem. Educ.64, 575 (1987).\n3. Mihali ć, Z. & Trinajstić, N. A graph-theoretical approach to structure-\nproperty relationships.J. Chem. Educ.69, 701 (1992).\n4. Ren, F. et al. Alphafold accelerates artiﬁcial intelligence powered drug\ndiscovery: efﬁcient discovery of a novel cdk20 small molecule\ninhibitor. Chem. Sci.14, 1443–1452 (2023).\n5. Kim, J.-Y. et al. Visual interpretation of [18 f]ﬂorbetaben pet supported\nby deep learning–based estimation of amyloid burden.Eur. J. Nucl.\nMed. Mol. Imaging48, 1116–1123 (2021).\n6. Gawehn, E., Hiss, J. A. & Schneider, G. Deep learning in drug\ndiscovery. Mol. Inform.35,3 –14 (2016).\n7. Lysenko, A., Sharma, A., Boroevich, K. A. & Tsunoda, T. An integrative\nmachine learning approach for prediction of toxicity-related drug\nsafety. Life Sci. Alliance1, 6 (2018).\n8. Jaiswal, A., Gianchandani, N., Singh, D., Kumar, V. & Kaur, M.\nClassiﬁcation of the covid-19 infected patients using densenet201\nbased deep transfer learning.J. Biomol. Struct. Dyn.39, 5682–5689\n(2021).\n9. Deringer, V. L., Caro, M. A. & Csányi, G. Machine learning interatomic\npotentials as emerging tools for materials science.Adv. Mater.31,\n1902765 (2019).\n10. Faber, F. A. et al. Prediction errors of molecular machine learning\nmodels lower than hybrid dft error.J. Chem. Theory Comput.13,\n5255–5264 (2017).\n11. Gupta, R. et al. Artiﬁcial intelligence to deep learning: machine intelligence\napproach for drug discovery.Mol. Divers.25, 1315–1360 (2021).\n12. Duch, W., Swaminathan, K. & Meller, J. Artiﬁcial intelligence\napproaches for rational drug design and discovery.Curr. Pharm. Des.\n13, 1497–\n1508 (2007).\n13. Dara, S. et al. Machine learning in drug discovery: a review.Artif. Intell.\nRev. 55, 1947–1999 (2022).\n14. Gormley, A. J. & Webb, M. A. Machine learning in combinatorial\npolymer chemistry.Nat. Rev. Mater.6, 642–644 (2021).\n15. Gomes, C. P., Fink, D., Van Dover, R. B. & Gregoire, J. M.\nComputational sustainability meets materials science.Nat. Rev.\nMater. 6, 645–647 (2021).\n16. Murdoch, W. J., Singh, C., Kumbier, K., Abbasi-Asl, R. & Yu, B.\nDeﬁnitions, methods, and applications in interpretable machine\nlearning. Proc. Natl Acad. Sci. USA116, 22071–22080 (2019).\nhttps://doi.org/10.1038/s42004-024-01393-y Article\nCommunications Chemistry|            (2025) 8:11 8\n17. Schwalbe, G. & Finzel, B. A comprehensive taxonomy for explainable\nartiﬁcial intelligence: a systematic survey of surveys on methods and\nconcepts. Data Min. Knowl. Discov.38, 3043–3101 (2024).\n18. Wellawatte, G. P., Gandhi, H. A., Seshadri, A. & White, A. D. A\nperspective on explanations of molecular prediction models.J. Chem.\nTheory Comput.19, 2149–2160 (2023).\n19. Miller, T. Explanation in artiﬁcial intelligence: insights from the social\nsciences. Artif. Intell.267,1 –38 (2019).\n20. Biran, O. & Cotton, C. Explanation and justiﬁcation in machine\nlearning: a survey. InIJCAI-17 Workshop on Explainable AI (XAI), vol.\n8, 8–13 (2017).\n21. Cambria, E., Malandri, L., Mercorio, F., Mezzanzanica, M. & Nobani, N.\nA survey on xai and natural language explanations.Inf. Process.\nManag. 60, 103111 (2023).\n22. Mariotti, E., Alonso, J. M. & Gatt, A. Towards harnessing natural\nlanguage generation to explain black-box models. In2nd Workshop\non Interactive Natural Language Technology for Explainable Artiﬁcial\nIntelligence,2 2–27 (2020).\n23. Kanehira, A. & Harada, T. Learning to explain with complemental\nexamples. InProceedings of the IEEE/CVF Conference on Computer\nVision and Pattern Recognition, 8603–8611 (2019).\n24. Sheridan, R. P. Interpretation of QSAR models by coloring atoms\naccording to changes in predicted activity: how robust is it?J. Chem.\nInf. Model.59, 1324–1337 (2019).\n25. Russell, C. Efﬁcient search for diverse coherent explanations. In\nProceedings of the Conference on Fairness, Accountability, and\nTransparency,2 0–28 (2019).\n26. Wellawatte, G. P., Seshadri, A. & White, A. D. Model agnostic\ngeneration of counterfactual explanations for molecules.Chem. Sci.\n13, 3697–3705 (2022).\n27. White, A. D. The future of chemistry is language.Nat. Rev. Chem.7,\n457–458 (2023).\n28. Zheng, Z., Zhang, O., Borgs, C., Chayes, J. T. & Yaghi, O. M. Chatgpt\nchemistry assistant for text mining and the prediction of mof\nsynthesis. J. Am. Chem. Soc.145, 18048–18062 (2023).\n29. Hatakeyama-Sato, K., Watanabe, S., Yamane, N., Igarashi, Y. &\nOyaizu, K. Using gpt-4 in parameter selection of polymer informatics:\nimproving predictive accuracy amidst data scarcity and‘ugly\nduckling’dilemma. Digit. Discov.2, 1548–1557 (2023).\n30. OpenAI. Gpt-4 Technical Report. Preprint atarXiv https://doi.org/10.\n48550/arXiv.2303.08774 (2023).\n31. Boiko, D. A., MacKnight, R., Kline, B. & Gomes, G. Autonomous\nchemical research with large language models.Nature 624, 570–578\n(2023).\n32. Jablonka, K. M., Schwaller, P., Ortega-Guerrero, A. & Smit, B.\nLeveraging large language models for predictive chemistry.Nat.\nMach. Intell.6, 161–169 (2024).\n33. Xie, T. et al. Darwin series: domain speciﬁc large language models for\nnatural science. Preprint atarXiv https://doi.org/10.48550/arXiv.2308.\n13565 (2023).\n34. Wu, C., Zhang, X., Zhang, Y., Wang, Y. & Xie, W. Pmc-llama: further\nﬁnetuning llama on medical papers.J. Am. Med. Inf. Assoc.31,\n1833–1843 (2024).\n35. Taylor, R. et al. Galactica: a large language model for science. Preprint\nat arXiv https://doi.org/10.48550/arXiv.2211.09085 (2022).\n36. Singhal, K. et al. Large language models encode clinical knowledge.\nNature 620, 172–180 (2023).\n37. Bran, A. M., Cox, S., Schilter, O., Baldassari, C., White, A. D. &\nSchwaller, P. Augmenting large-language models with chemistry\ntools. Nat. Mach. Intell.6, 525–535 (2024).\n38. Seshadri, A., Gandhi, H. A., Wellawatte, G. P. & White, A. D. Why does\nthat molecule smell?ChemRxiv (2022).\n39. Chen, T. & Guestrin, C. XGBoost: A scalable tree boosting system. In\nProceedings of the 22nd ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining, KDD’16, 785–794. https://\ndoi.org/10.1145/2939672.2939785(ACM, New York, NY, USA, 2016).\n40. Pedregosa, F. et al. Scikit-learn: machine learning in Python.J. Mach.\nLearn. Res.12, 2825–2830 (2011).\n41. Borisov, V. et al. Deep neural networks and tabular data: a survey.\nIEEE Trans. Neural Netw. Learn. Syst.(2022).\n42. Lundberg, S. M. & Lee, S.-I. A uniﬁed approach to interpreting model\npredictions. In (ed Guyon, I.)Advances in Neural Information\nProcessing Systems, vol. 30 (Curran Associates, Inc., 2017).https://\nproceedings.neurips.cc/paper_ﬁles/paper/2017/ﬁ\nle/\n8a20a8621978632d76c43dfd28b67767-Paper.pdf.\n43. Ribeiro, M. T., Singh, S. & Guestrin, C.“Why should I trust you?”:\nExplaining the predictions of any classiﬁer. InProceedings of the 22nd\nACM SIGKDD International Conference on Knowledge Discovery and\nData Mining, KDD’16, 1135-1144 (Association for Computing\nMachinery, New York, NY, USA, 2016).https://doi.org/10.1145/\n2939672.2939778.\n44. Rodríguez-Pérez, R. & Bajorath, J. Interpretation of compound activity\npredictions from complex machine learning models using local\napproximations and Shapley values.J. Med. Chem.63, 8761–8777\n(2020).\n45. Alsuradi, H., Park, W. & Eid, M. Explainable classiﬁcation of EEG data\nfor an active touch task using Shapley values. InInternational\nConference on Human-Computer Interaction, 406–416 (Springer,\n2020).\n46. Gandhi, H. A. & White, A. D. Explaining Molecular Properties with\nNatural LanguageChemRxiv (2022).\n47. Gao, Y. et al. Retrieval-augmented generation for large language\nmodels: a survey. Preprint atarXiv https://doi.org/10.48550/arXiv.\n2312.10997 (2023).\n48. Xu, W., Agrawal, S., Briakou, E., Martindale, M. J. & Carpuat, M.\nUnderstanding and detecting hallucinations in neural machine\ntranslation via model introspection.Trans. Assoc. Comput. Linguist.\n11, 546–564 (2023).\n49. Sawarkar, K., Mangal, A. & Solanki, S. R. Blended rag: improving rag\n(retriever-augmented generation) accuracy with semantic search and\nhybrid query-based retrievers. Preprint atarXiv https://doi.org/10.\n48550/arXiv.2404.07220 (2024).\n50. Wei, J. et al. Chain-of-thought prompting elicits reasoning in large\nlanguage models.Adv. Neural Inf. Process. Syst.35, 24824–24837\n(2022).\n51. Hall, J. N. & Bollini, P. Structure, characterization, and catalytic\nproperties of open-metal sites in metal organic frameworks.React.\nChem. Eng.4, 207–222 (2019).\n52. Ding, M., Flaig, R. W., Jiang, H.-L. & Yaghi, O. M. Carbon capture and\nconversion using metal-organic frameworks and mof-based\nmaterials. Chem. Soc. Rev.48, 2783–2828 (2019).\n53. Schoedel, A., Ji, Z. & Yaghi, O. M. The role of metal–organic\nframeworks in a carbon-neutral energy cycle.Nat. Energy1,1 –13\n(2016).\n54. Wang, S. & Wang, X. Imidazolium ionic liquids, imidazolylidene\nheterocyclic carbenes, and zeolitic imidazolate frameworks for co2\ncapture and photochemical reduction.Angew. Chem. Int. Ed.55,\n2308–\n2320 (2016).\n55. Lee, J. et al. Metal–organic framework materials as catalysts.Chem.\nSoc. Rev.38, 1450–1459 (2009).\n56. Yang, D. & Gates, B. C. Catalysis by metal organic frameworks:\nperspective and suggestions for future research.ACS Catal.9,\n1779–1798 (2019).\n57. Horcajada, P. et al. Flexible porous metal-organic frameworks\nfor a controlled drug delivery.J. Am. Chem. Soc.130, 6774–6780\n(2008).\n58. Horcajada, P. et al. Metal–organic frameworks in biomedicine.Chem.\nRev. 112, 1232–1268 (2012).\nhttps://doi.org/10.1038/s42004-024-01393-y Article\nCommunications Chemistry|            (2025) 8:11 9\n59. Hung, T.-H., Lyu, Q., Lin, L.-C. & Kang, D.-Y. Transport-relevant pore\nlimiting diameter for molecular separations in metal–organic\nframework membranes.J. Phys. Chem. C125, 20416–20425 (2021).\n60. Chung, Y. G. et al. Advances, updates, and analytics for the\ncomputation-ready, experimental metal–organic framework\ndatabase: core mof 2019.J. Chem. Eng. Data64, 5985–5998 (2019).\n61. Taw ﬁk, S. A. & Russo, S. P. Naturally-meaningful and efﬁcient\ndescriptors: machine learning of material properties based on robust\none-shot ab initio descriptors.J. Cheminform.14,1 –11 (2022).\n62. Cai, M., Loague, Q. & Morris, A. J. Design rules for efﬁcient charge\ntransfer in metal–organic frameworkﬁlms: the pore size effect.J.\nPhys. Chem. Lett.11, 702–709 (2020).\n63. Haldoupis, E., Nair, S. & Sholl, D. S. Efﬁcient calculation of diffusion\nlimitations in metal organic framework materials: a tool for identifying\nmaterials for kinetic separations.J. Am. Chem. Soc.132, 7528–7539\n(2010).\n64. Huang, R. et al. Tox21challenge to build predictive models of nuclear\nreceptor and stress response pathways as mediated by exposure to\nenvironmental chemicals and drugs.Front. Environ. Sci.3, 85 (2016).\n65. Durant, J. L., Leland, B. A., Henry, D. R. & Nourse, J. G. Reoptimization\nof mdl keys for use in drug discovery.J. Chem. Inf. Comput. Sci.42,\n1273–1280 (2002).\n66. Landrum, G. Rdkit: open-source cheminformaticshttp://www.rdkit.\norg. Google Scholar There is no corresponding record for this\nreference 3 (2016).\n67. Meanwell, N. A. The inﬂuence of bioisosteres in drug design: tactical\napplications to address developability problems.Tactics Contemp.\nDrug Des.9 283–381 (2015).\n68. Limban, C. et al. The use of structural alerts to avoid the toxicity of\npharmaceuticals. Toxicol. Rep.5, 943–953 (2018).\n69. Peterson, D. L. & Yalkowsky, S. H. Comparison of two methods for\npredicting aqueous solubility.J. Chem. Inf. Comput. Sci.41,\n1531–1534 (2001).\n70. Sorkun, M. C., Khetan, A. & Er, S. Aqsoldb, a curated reference set of\naqueous solubility and 2d descriptors for a diverse set of compounds.\nSci. Data6\n, 143 (2019).\n71. Walker, M. A. Improvement in aqueous solubility achieved via small\nmolecular changes.Bioorg. Med. Chem. Lett.27, 5100–5108 (2017).\n72. Ishikawa, M. & Hashimoto, Y. Improvement in aqueous solubility in\nsmall molecule drug discovery programs by disruption of molecular\nplanarity and symmetry.J. Med. Chem.54, 1539–1554 (2011).\n73. Yuan, S., Jiao, Z., Quddus, N., Kwon, J. S.-I. & Mashuga, C. V.\nDeveloping quantitative structure–property relationship models to\npredict the upperﬂammability limit using machine learning.Ind. Eng.\nChem. Res.58, 3531–3537 (2019).\n74. Mannan, S. Chapter 8— hazard identiﬁcation. InLees’ Loss Prevention\nin the Process Industries (Fourth Edition), 204–283 (Butterworth-\nHeinemann, Oxford, 2012), fourth edition.https://www.sciencedirect.\ncom/science/article/pii/B9780123971890000082.\n75. Vidal, M., Rogers, W., Holste, J. & Mannan, M. A review of estimation\nmethods forﬂash points andﬂammability limits.Process Saf. Prog.\n23,4 7–55 (2004).\n76. Gharagheizi, F. Prediction of upperﬂammability limit percent of pure\ncompounds from their molecular structures.J. Hazard. Mater.167,\n507–510 (2009).\n77. Pan, Y., Jiang, J., Wang, R., Cao, H. & Cui, Y. Prediction of the upper\nﬂammability limits of organic compounds from molecular structures.\nInd. Eng. Chem. Res.48, 5064–5069 (2009).\n78. Crowl, D. A. & Louvar, J. F.Chemical Process Safety: Fundamentals\nwith Applications(Pearson Education, 2001).\n79. Bai, X., Xie, Y., Zhang, X., Han, H. & Li, J.-R. Evaluation of open-source\nlarge language models for metal–organic frameworks research.J.\nChem. Inf. Model.(2024).\n80. Dubey, A. et al. The llama 3 herd of models. Preprint atarXiv https://\ndoi.org/10.48550/arXiv.2407.21783 (2024).\n81. Touvron, H. et al. Llama 2: open foundation andﬁne-tuned chat\nmodels. Preprint atarXiv https://doi.org/10.48550/arXiv.2307.09288\n(2023).\n82. AI, M. Mixtral of experts.https://mistral.ai/news/mixtral-of-experts/\n(2023).\n83. Zhu, B., Frick, E., Wu, T., Zhu, H. & Jiao, J. Starling-7b: improving llm\nhelpfulness & harmlessness with rlaif.\nIn Proceedings of First\nConference on Language Modelinghttps://openreview.net/forum?\nid=GqDntYTTbk (2024).\n84. Microsoft. Microsoft phi-2. https://ai.azure.com/explore/models/\nmicrosoft-phi-2/version/4/registry/azureml-msr?reloadCount=1\n(2023).\nAcknowledgements\nWe thank the expert evaluators for their contributions to this work.\nG.P.W. acknowledges funding from the EPFL large-scale Solu-\ntions4Sustainability demonstrator project (SusEcoCCUS). P.S.\nacknowledges support from the NCCR Catalysis (grant No. 180544),\na National Center of Competence in Research funded by the Swiss\nNational Science Foundation.\nAuthor contributions\nG.P.W. designed and conducted the experiments. P.S. directed the project.\nBoth authors participated in writing the paper, data analysis and\ninterpretation.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s42004-024-01393-y\n.\nCorrespondenceand requests for materials should be addressed to\nGeemi P. Wellawatte or Philippe Schwaller.\nPeer review informationCommunications Chemistrythanks Jin-Hu Dou\nand the other, anonymous, reviewers for their contribution to the peer review\nof this work.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to\njurisdictional claims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long\nas you give appropriate credit to the original author(s) and the source,\nprovide a link to the Creative Commons licence, and indicate if changes\nwere made. The images or other third party material in this article are\nincluded in the article’s Creative Commons licence, unless indicated\notherwise in a credit line to the material. If material is not included in the\narticle’s Creative Commons licence and your intended use is not permitted\nby statutory regulation or exceeds the permitted use, you will need to\nobtain permission directly from the copyright holder. To view a copy of this\nlicence, visithttp://creativecommons.org/licenses/by/4.0/\n.\n© The Author(s) 2025\nhttps://doi.org/10.1038/s42004-024-01393-y Article\nCommunications Chemistry|            (2025) 8:11 10",
  "topic": "Property (philosophy)",
  "concepts": [
    {
      "name": "Property (philosophy)",
      "score": 0.6968746781349182
    },
    {
      "name": "Computer science",
      "score": 0.6543574333190918
    },
    {
      "name": "Artificial intelligence",
      "score": 0.591086745262146
    },
    {
      "name": "Natural language processing",
      "score": 0.48206788301467896
    },
    {
      "name": "Field (mathematics)",
      "score": 0.47122323513031006
    },
    {
      "name": "Raw data",
      "score": 0.4429779052734375
    },
    {
      "name": "Natural (archaeology)",
      "score": 0.4160733222961426
    },
    {
      "name": "Data science",
      "score": 0.36014705896377563
    },
    {
      "name": "Machine learning",
      "score": 0.3399810791015625
    },
    {
      "name": "Epistemology",
      "score": 0.13385805487632751
    },
    {
      "name": "Mathematics",
      "score": 0.09721958637237549
    },
    {
      "name": "Geography",
      "score": 0.09599685668945312
    },
    {
      "name": "Programming language",
      "score": 0.0648224949836731
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I5124864",
      "name": "École Polytechnique Fédérale de Lausanne",
      "country": "CH"
    }
  ],
  "cited_by": 9
}