{
  "title": "Collateral facilitation in humans and language models",
  "url": "https://openalex.org/W4385573517",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5054612798",
      "name": "James A. Michaelov",
      "affiliations": [
        "University of California, San Diego"
      ]
    },
    {
      "id": "https://openalex.org/A5043344696",
      "name": "Benjamin Bergen",
      "affiliations": [
        "University of California, San Diego"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4292779060",
    "https://openalex.org/W1985982445",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W2794478458",
    "https://openalex.org/W2924784989",
    "https://openalex.org/W2971754107",
    "https://openalex.org/W2997086627",
    "https://openalex.org/W3135427360",
    "https://openalex.org/W2000491180",
    "https://openalex.org/W3114409145",
    "https://openalex.org/W2484899433",
    "https://openalex.org/W2092183144",
    "https://openalex.org/W3200544839",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W2990427812",
    "https://openalex.org/W2933592922",
    "https://openalex.org/W2041221140",
    "https://openalex.org/W3093931479",
    "https://openalex.org/W3004346089",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2974597461",
    "https://openalex.org/W2612205435",
    "https://openalex.org/W2774486220",
    "https://openalex.org/W2986128786",
    "https://openalex.org/W2138640694",
    "https://openalex.org/W2974431682",
    "https://openalex.org/W2905378591",
    "https://openalex.org/W3212496002",
    "https://openalex.org/W2951559648",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W2164418233",
    "https://openalex.org/W3087624537",
    "https://openalex.org/W2921890305",
    "https://openalex.org/W2279316390",
    "https://openalex.org/W2119728020",
    "https://openalex.org/W2189430370",
    "https://openalex.org/W2880029892",
    "https://openalex.org/W4226155321",
    "https://openalex.org/W2259472270",
    "https://openalex.org/W2130987742",
    "https://openalex.org/W2141845152",
    "https://openalex.org/W2582743722",
    "https://openalex.org/W2554838917",
    "https://openalex.org/W4226399820",
    "https://openalex.org/W4229005866",
    "https://openalex.org/W2270070752",
    "https://openalex.org/W3185013521",
    "https://openalex.org/W2787685818",
    "https://openalex.org/W2912958568",
    "https://openalex.org/W2100425115",
    "https://openalex.org/W3102485638",
    "https://openalex.org/W2109058354",
    "https://openalex.org/W2101850707",
    "https://openalex.org/W2963751529",
    "https://openalex.org/W2076666572",
    "https://openalex.org/W3171953676",
    "https://openalex.org/W2090947919",
    "https://openalex.org/W2561299349",
    "https://openalex.org/W2913191925",
    "https://openalex.org/W2037884508",
    "https://openalex.org/W2108010971",
    "https://openalex.org/W2110065044",
    "https://openalex.org/W4226056216",
    "https://openalex.org/W3184030040",
    "https://openalex.org/W1982350233",
    "https://openalex.org/W1951724000",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2888625409",
    "https://openalex.org/W2138649362",
    "https://openalex.org/W1984050661",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W4286988498",
    "https://openalex.org/W3034995113",
    "https://openalex.org/W3103816537",
    "https://openalex.org/W3037273551"
  ],
  "abstract": "Are the predictions of humans and language models affected by similar things? Research suggests that while comprehending language, humans make predictions about upcoming words, with more predictable words being processed more easily. However, evidence also shows that humans display a similar processing advantage for highly anomalous words when these words are semantically related to the preceding context or to the most probable continuation. Using stimuli from 3 psycholinguistic experiments, we find that this is also almost always also the case for 8 contemporary transformer language models (BERT, ALBERT, RoBERTa, XLM-R, GPT-2, GPT-Neo, GPT-J, and XGLM). We then discuss the implications of this phenomenon for our understanding of both human language comprehension and the predictions made by language models.",
  "full_text": "Proceedings of the 26th Conference on Computational Natural Language Learning (CoNLL), pages 13 - 26\nDecember 7-8, 2022 ©2022 Association for Computational Linguistics\nCollateral facilitation in humans and language models\nJames A. Michaelov\nDepartment of Cognitive Science\nUniversity of California, San Diego\nj1michae@ucsd.edu\nBenjamin K. Bergen\nDepartment of Cognitive Science\nUniversity of California, San Diego\nbkbergen@ucsd.edu\nAbstract\nAre the predictions of humans and language\nmodels affected by similar things? Research\nsuggests that while comprehending language,\nhumans make predictions about upcoming\nwords, with more predictable words being pro-\ncessed more easily. However, evidence also\nshows that humans display a similar processing\nadvantage for highly anomalous words when\nthese words are semantically related to the pre-\nceding context or to the most probable contin-\nuation. Using stimuli from 3 psycholinguis-\ntic experiments, we find that this is also al-\nmost always also the case for 8 contemporary\ntransformer language models (BERT, ALBERT,\nRoBERTa, XLM-R, GPT-2, GPT-Neo, GPT-J,\nand XGLM). We then discuss the implications\nof this phenomenon for our understanding of\nboth human language comprehension and the\npredictions made by language models.\n1 Introduction\nHumans process words more easily when they\nmore contextually predictable, whether predictabil-\nity is determined by humans (Fischler and Bloom,\n1979; Brothers and Kuperberg, 2021) or language\nmodels (McDonald and Shillcock, 2003; Levy,\n2008; Smith and Levy, 2013). Work on the N400,\na neural signal of processing difficulty, has pro-\nvided evidence that the neurocognitive system un-\nderlying human language comprehension preacti-\nvates words based on the extent to which they are\npredictable from the preceding context—thus, pre-\ndictable words are easier to process because they\nor their features have already been activated before\nthey are encountered (Kutas and Hillyard, 1984;\nVan Petten and Luka, 2012). This has led many to\nargue that we should consider the human language\ncomprehension system to be engaging in prediction\n(DeLong et al., 2005; Kutas et al., 2011; Van Pet-\nten and Luka, 2012; Bornkessel-Schlesewsky and\nSchlesewsky, 2019; Kuperberg et al., 2020; De-\nLong and Kutas, 2020; Brothers and Kuperberg,\n2021).\nHowever, words that are either semantically re-\nlated to the elements of the preceding context or to\nthe most likely next word are also processed more\neasily, even if they are semantically implausible\nand ostensibly unpredictable. These are known as\nrelated anomaly effects. For an example of the for-\nmer, consider the sentences in (1) that were used as\nexperimental stimuli by Metusalem et al. (2012).\n(1) My friend Mike went mountain biking\nrecently. He lost control for a moment and\nran right into a tree. It’s a good thing he was\nwearing his ______.\n(a) helmet\n(b) dirt\n(c) table\nHelmet is the most predictable continuation of\nthe sentence, as determined based on cloze proba-\nbility (Taylor, 1953, 1957)—the proportion of peo-\nple to fill in a gap in a sentence with a specific\nword. Thus, unsurprisingly, helmet elicited the\nsmallest N400 response, indicating that it is most\neasily processed. Dirt and table are both implau-\nsible continuations, and equally improbable based\non human responses (both have a cloze probability\nof zero). Yet Metusalem et al. (2012) found that\ndirt, which is semantically related to the preceding\ncontext of mountain biking, elicits a smaller N400\nresponse than table, which is not. This suggests\nthat something about dirt’s relation to themountain\nbiking event causes it to be preactivated more than\ntable, despite their seemingly equal implausibility\nand unpredictability.\nThe sentences in (2), used as experimental stim-\nuli by Ito et al. (2016), provide an example of\nthe other previously-discussed form of related\nanomaly—where a word semantically related to\nthe most probable continuation (in this case, that\n13\nwith the highest cloze) is easier to process than\none that is not. Even though tail and tyre are both\nimplausible continuations with a cloze probability\nof zero, Ito et al. (2016) find that tail, which is\nsemantically-related to the highest-cloze continua-\ntion dog, elicits a smaller N400 response than tyre,\nwhich is not.\n(2) Meg will go to the park to walk her ______\ntomorrow.\n(a) dog\n(b) tail\n(c) tyre\nIn sum, words related to elements of the preced-\ning context or to the most probable continuation of\na sequence appear to be more preactivated in the\nbrain than words that are not, even when both are\nhighly anomalous. This effect has been replicated\nmany times (Kutas and Hillyard, 1984; Kutas et al.,\n1984; Kutas, 1993; Federmeier and Kutas, 1999;\nMetusalem et al., 2012; Rommers et al., 2013; Ito\net al., 2016; DeLong et al., 2019; for review see\nDeLong et al., 2019).\nThe key question, therefore, is whether the same\nneurocognitive system underlying the predictability\neffects on the N400 also underlie related anomaly\neffects. Under one account (DeLong et al., 2019;\nDeLong and Kutas, 2020), the predictive system\nthat underlies predictability effects also leads to\nthese related anomalous words being ‘collaterally\nfacilitated’ (DeLong and Kutas, 2020, p. 1045) due\nto their shared semantic features. Under this ac-\ncount, therefore, related anomaly effects can all be\nexplained as by-products of our predictive system\nand the semantic organization of information in the\nbrain. However, there is no direct evidence that\nthis is the case—in fact, given the metabolic costs\nof preactivation (Brothers and Kuperberg, 2021),\nit may intuitively seem unlikely that an efficient\npredictive system would lead to implausible and\notherwise anomalous words being preactivated. In\nfact, many researchers have argued that one or more\nassociative mechanisms are required to explain re-\nlated anomaly and other similar effects (Lau et al.,\n2013; Ito et al., 2016; Frank and Willems, 2017;\nFedermeier, 2021).\nAs systems designed specifically to predict the\nprobability of a word given its context, language\nmodels offer a means to test the viability of the\nformer hypothesis. If language models calcu-\nlate that related but anomalous words are more\npredictable than unrelated anomalous words, this\nwould demonstrate that related anomaly effects\ncan be produced by a system engaged in predic-\ntion alone. This would show that it is possible\nthat related anomalies can be ‘collaterally facili-\ntated’ (DeLong and Kutas, 2020, p. 1045) by a\npredictive mechanism in human language compre-\nhension. Thus, it would remove the need to posit\nadditional associative mechanisms on the basis of\nrelated anomaly effects, which could greatly sim-\nplify our understanding of human language com-\nprehension.\nThis is what we test in the present study. We run\nthe stimuli from 3 psycholinguistic experiments\ncarried out in English (Ito et al., 2016; DeLong\net al., 2019; Metusalem et al., 2012) through 8\ncontemporary transformer language models (De-\nvlin et al., 2019; Radford et al., 2019; Liu et al.,\n2019; Lan et al., 2020; Conneau et al., 2020; Black\net al., 2021; Wang and Komatsuzaki, 2021; Lin\net al., 2021), calculating the surprisal (negative log-\nprobability) of each word for which the N400 was\nmeasured. We then compare whether, in line with\nthe N400 response, anomalous words that are se-\nmantically related to the context have significantly\nlower surprisals than unrelated words.\n2 Related work\nThere have been a wide range of attempts to com-\nputationally model the N400 (Parviz et al., 2011;\nLaszlo and Plaut, 2012; Laszlo and Armstrong,\n2014; Rabovsky and McRae, 2014; Frank et al.,\n2015; Ettinger et al., 2016; Cheyette and Plaut,\n2017; Brouwer et al., 2017; Rabovsky et al., 2018;\nVenhuizen et al., 2019; Fitz and Chang, 2019; Au-\nrnhammer and Frank, 2019; Michaelov and Bergen,\n2020; Merkx and Frank, 2021; Uchida et al., 2021;\nSzewczyk and Federmeier, 2022; Michaelov et al.,\n2022). One of the most successful and influential\napproaches has been to model the N400 using the\nsurprisal calculated from neural language models—\nsurprisal has been found to be a significant predic-\ntor of single-trial N400 data (Frank et al., 2015;\nAurnhammer and Frank, 2019; Merkx and Frank,\n2021; Michaelov et al., 2021; Szewczyk and Feder-\nmeier, 2022; Michaelov et al., 2022), and has been\nfound to be similar to the N400 response in how it is\naffected by a range of experimental manipulations\n(Michaelov and Bergen, 2020; Michaelov et al.,\n2021). A key finding is that better-performing and\nmore sophisticated language models perform better\n14\nat predicting the N400 (Frank et al., 2015; Aurn-\nhammer and Frank, 2019; Michaelov and Bergen,\n2020; Merkx and Frank, 2021; Michaelov et al.,\n2021, 2022). For this reason, we use contemporary\ntransformer language models in the present study.\nWe use experimental stimuli from 3 experiments.\nStimuli from one of these experiments (Ito et al.,\n2016) have been previously used in computational\nanalyses of the N400. This is one of several sets\nthat Michaelov and Bergen (2020) attempt to model\nusing recurrent neural network (RNN) language\nmodels, finding that they can indeed calculate that\nwords related to the highest-cloze continuation are\nmore predictable than unrelated words. In the\npresent study, we test whether this result can be\nreplicated on a larger number of language models,\nand specifically, transformer language models.\nThere has also been work looking at how lan-\nguage models deal with semantic relatedness to the\nhighest-cloze continuation based on stimuli from\nother N400 experiments. Michaelov and Bergen\n(2020), for example, find that in cases where the\nrelated and unrelated words are both plausible, the\nrelated continuations are more strongly predicted\nby RNNs (Gulordava et al., 2018; Jozefowicz et al.,\n2016), in line with the original N400 results (Kutas,\n1993). Michaelov et al. (2021) conceptually repli-\ncate this finding on a different dataset (Bardolph\net al., 2018) using one of the same RNNs (Jozefow-\nicz et al., 2016) and GPT-2 (Radford et al., 2019).\nHowever, these prior efforts differ from the present\nstudy in that they investigate N400s and surprisal to\nwords that are all plausible continuations of the sen-\ntence, and where they both have a low but generally\nnon-zero cloze probability. In the stimuli analyzed\nin the present study, by contrast, both the related\nand unrelated words are anomalous—they have a\ncloze probability of zero, and are implausible con-\ntinuations. Thus, their preactivation does, at least\nintuitively, appear to be more clearly ‘collateral’.\nWe are only aware of one previous study that\ndirectly compares the predictions of transformers\nand the human N400 response on related anomaly\nstimuli. Ettinger (2020) evaluates BERT in terms\nof its similarity to cloze—because the predictions\nof a language model, being incremental, may show\nsimilar effects to those found in the N400 (see also\nMichaelov and Bergen, 2020 for discussion). For\nthis reason, Ettinger (2020) tests how good BERT is\nat predicting the highest-cloze (most probable) con-\ntinuations in the stimuli over anomalous but seman-\ntically related continuations, but does not directly\nlook at the related anomaly effect—whether the\nrelated anomalous continuations are more strongly\npredicted than the unrelated anomalous continu-\nations. Thus, to the best of our knowledge, the\npresent study is the first to investigate whether the\npredictions of transformer language models display\nrelated anomaly effects like humans do.\nFinally, there has been some work investigating\nwhether language models display priming effects\n(e.g. Prasad et al., 2019; Misra et al., 2020; Kass-\nner and Schütze, 2020; Lin et al., 2021; Lindborg\nand Rabovsky, 2021). The effect found by Me-\ntusalem et al. (2012)—that words related to the\nevents described in the context are preactivated\nmore strongly than words that are not—is a form\nof semantic priming, as it results in the increased\npreactivation of a word based on the semantic con-\ntent stimulus that has been recently encountered\n(i.e. the event described in the preceding linguistic\ncontext). Thus, our investigation of the patterns in\nthe prediction of the the stimuli from Metusalem\net al. (2012) is intended to further our knowledge of\npriming in language models—specifically, whether\nthere are systematic ways in which context shapes\nthe extent to which anomalous words are predicted.\n3 General Method\nIn this study, we took the stimuli from a range of ex-\nperiments (Ito et al., 2016; DeLong et al., 2019; Me-\ntusalem et al., 2012) and ran them through a num-\nber of transformer language models. We used the\ntransformers (Wolf et al., 2020) implementations of\nthe (largest and most up-to-date versions of each of\nthe) following models: BERT (Devlin et al., 2019),\nRoBERTa (Liu et al., 2019), ALBERT (Lan et al.,\n2020), XLM-R (Conneau et al., 2020), GPT-2 (Rad-\nford et al., 2019), GPT-Neo (Black et al., 2021),\nGPT-J (Wang and Komatsuzaki, 2021), and XGLM\n(Lin et al., 2021). We chose these models to cover\na number of both autoregressive (GPT-2, GPT-Neo,\nGPT-J, XGLM) and masked (BERT, RoBERTa,\nALBERT, XLM-RoBERTa) language model archi-\ntectures. Given the recent increase in popularity of\nmultilingual language models, we also made sure\nto include one autoregressive (XGLM) and one\nmasked (XLM-RoBERTa) multilingual language\nmodel, in case there is a difference based on the\nnumber of languages that a model is trained on.\nAll experimental stimuli used in the present\nstudy have been made available by the original\n15\nauthors of their respective papers as appendices\nor supplementary materials. In our analysis, we\ntruncated all stimuli to be the preceding context of\nthe critical word (the word for which the N400 was\nmeasured). We then used the language models to\ncalculate the probability of the next word, and neg-\native log-transformed (using a logarithm of base 2,\nfollowing Futrell et al., 2019) these probabilities to\ncalculate the surprisal of each word. For words not\npresent in the vocabulary of each model, we tok-\nenized the word, and then progressively calculated\nthe surprisal of each sub-word token given the pre-\nceding context; with the sum of all the surprisals\n(equivalent to the the negative log-probability of\nthe product of all the probabilities) being used as\nthe total surprisal for the word. In this way, we\ncalculated the surprisal of each critical word given\nits preceding context only.\nAll graphs and statistical analyses were created\nand run in R (R Core Team, 2020) using Rstudio\n(RStudio Team, 2020) and the tidyverse (Wickham\net al., 2019), lme4 (Bates et al., 2015), andlmerTest\n(Kuznetsova et al., 2017) packages. All reported\np-values are corrected for multiple comparisons\nbased on false discovery rate across all statistical\ntests carried out (Benjamini and Hochberg, 1995).\nBecause of this correction procedure, if any models\ndisplay related anomaly effects, this is evidence\nthat prediction alone can account for them.\nAll of the code for running the experi-\nments and carrying out the statistical analyses is\nprovided at https://github.com/jmichaelov/\ncollateral-facilitation.\n4 Experiment 1: Ito et al. (2016)\n4.1 Introduction\nWe begin with Ito et al. (2016), who investigated\nwhether relatedness to the highest-cloze continu-\nation of a given sentence impacts the amplitude\nof the N400 response. They presented human par-\nticipants with experimental stimuli that included\na word that was either the highest-cloze continu-\nation of a sentence, semantically related to that\nhighest-cloze continuation, similar to the highest-\ncloze continuation in terms of their form (e.g. hook\nand book), or unrelated. For the purposes of the\npresent study, we are interested in semantic related-\nness and thus do not consider the formal relatedness\ncondition. Thus, we look at the stimuli from the\nthree experimental conditions exemplified in (3)—\nan example of Predictable, Related, and Unrelated\ncontinuations for one sentence frame.\n(3) Lydia cannot eat anymore as she is so ______\nnow.\n• full (Predictable)\n• half (Related)\n• mild (Unrelated)\nIto et al. (2016) find that related continuations\nelicit a smaller N400 response than unrelated con-\ntinuations. As stated, this finding was successfully\nmodeled using the surprisal of two RNN language\nmodels by Michaelov and Bergen (2020).\nIn the present study, we aim to investigate\nwhether this can be replicated with contemporary\ntransformer language models. Thus far, only one\nstudy (Merkx and Frank, 2021) has directly com-\npared the N400 prediction capabilities of RNNs\nand transformers while matching number of pa-\nrameters, training data, and language modeling\nperformance, finding that transformers are better\npredictors of N400 amplitude overall. We might\ntherefore expect that the transformers used in the\npresent study should model the related anomaly ef-\nfect found by Ito et al. (2016) at least as well as the\nRNNs used by Michaelov and Bergen (2020). How-\never, a key feature of Merkx and Frank’s (2021)\nstudy is that it uses naturalistic stimuli. This makes\nthe experiment more ecologically valid, but as has\nbeen pointed out (Michaelov and Bergen, 2020;\nBrothers and Kuperberg, 2021), this means that we\ncannot tell whether the higher correlation between\nsurprisal and N400 amplitude is due to any factors\nthat we are interested in investigating—Merkx and\nFrank (2021) do not consider how relatedness to a\npreviously-mentioned event or to most predictable\ncontinuation impacts surprisal and the N400. For\nthis reason, it is in fact far from clear that we should\nexpect this specific related anomaly effect to be\nmodeled as well by transformers as by RNNs. How-\never, if it is, this would demonstrate the effect in\ntwo different language model architectures, fur-\nther strengthening the idea that a predictive system\nalone can explain related anomaly effects.\nThus, in the present study, we investigate\nwhether the results of Michaelov and Bergen (2020)\nreplicate beyond the two RNNs tested, and cru-\ncially, whether the results replicate with trans-\nformer language models. Specifically, we test\nwhether the surprisal elicited by implausible stim-\nuli related to the highest-cloze continuation is lower\n16\nGPT-2 (XL) GPT-Neo (2.7B) GPT-J (6B) XGLM (7.5B)\nBERT (Large, WWM) ALBERT (Large) RoBERTa (Large) XLM-R (Large)\nRelated Unrelated Related Unrelated Related Unrelated Related Unrelated\n0\n5\n10\n15\n20\n0\n5\n10\n15\n20\nRelatedness to highest-cloze continuation\nSurprisal\nCondition\nRelated\nUnrelated\nFigure 1: Mean surprisal elicited by each language model for the Ito et al. (2016) stimuli related and unrelated to\nthe most probable (highest-cloze) continuation of each sentence. Error bars indicate standard error.\nModel Test Statistic Corrected p\nBERT F(1, 120) = 7.15 0 .0093\nALBERT F(1, 92) = 20.6 < 0.0001\nRoBERTa F(1, 159) = 60.8 < 0.0001\nXLM-R F(1, 126) = 21.2 < 0.0001\nGPT-2 F(1, 157) = 64.0 < 0.0001\nGPT-Neo F(1, 152) = 64.1 < 0.0001\nGPT-J F(1, 149) = 62.5 < 0.0001\nXGLM F(1, 146) = 72.6 < 0.0001\nTable 1: The results of a Type III ANOV A (using Sat-\nterthwaite’s method for estimating degrees of freedom;\nKuznetsova et al., 2017) on the Ito et al. (2016) stimuli,\ntesting for which language models experimental condi-\ntion (related or unrelated) is a significant predictor of\ntheir surprisal. This is the case for all language models.\nthan the surprisal elicited by implausible stimuli\nunrelated to the highest-cloze continuation.\n4.2 Results\nThe results of the experiment are shown in Fig-\nure 1. As can be seen, numerically, related words\nelicit lower surprisals than unrelated words, indi-\ncating that they were more highly predicted by the\nlanguage models. This in turn suggests that these\nmodels do in fact collaterally predict the related\ncontinuations.\nIn order to test this more directly, we ran sta-\ntistical analyses of the surprisals elicited by the\nlanguage models. This was done by constructing\nlinear mixed-effects regressions for each language\nmodel surprisal with experimental condition as a\nmain effect, and the maximal random effects struc-\nture that would successfully converge for all mod-\nels (see Barr et al., 2013). For all regressions except\nfor that predicting RoBERTa surprisal, this random\neffects structure was a random intercept of sentence\nframe and of critical word. For the RoBERTa sur-\nprisal regression, the latter random intercept was\nremoved due to it causing a singular fit. As creating\nnull models with only the random effects structure\nresulted in singular fits for multiple regressions,\nwe were unable to run likelihood ratio tests to test\nwhether experimental condition—that is, whether\nthe word was semantically related or unrelated to\nthe highest-cloze continuation—was a significant\npredictor of surprisal. For this reason, we instead\ntested whether experimental condition was a signif-\nicant predictor of surprisal by running a Type III\nANOV A using Satterthwaite’s method for estimat-\ning degrees of freedom (Kuznetsova et al., 2017)\non the aforementioned linear mixed-effects mod-\nels that included experimental condition as a fixed\neffect.\nThe results of the tests are shown in Table 1. As\ncan be seen, condition is a significant predictor of\nthe surprisal from every language model, confirm-\n17\nGPT-2 (XL) GPT-Neo (2.7B) GPT-J (6B) XGLM (7.5B)\nBERT (Large, WWM) ALBERT (Large) RoBERTa (Large) XLM-R (Large)\nRelated Unrelated Related Unrelated Related Unrelated Related Unrelated\n0\n10\n20\n0\n10\n20\nRelatedness to highest-cloze continuation\nSurprisal\nCondition\nRelated\nUnrelated\nFigure 2: Mean surprisal elicited by each language model for the DeLong et al. (2019) stimuli related and unrelated\nto the most probable (highest-cloze) continuation of each sentence. Error bars indicate standard error.\ning that language models predict related stimuli to\nbe more likely than unrelated stimuli.\nThe results of this experiment demonstrate that\nall the language models tested—BERT, ALBERT,\nRoBERTa, XLM-R, GPT-2, GPT-Neo, GPT-J, and\nXGLM—display the related anomaly effect in re-\nsponse to the Ito et al. (2016) stimuli. All eight\nmodels predict implausible continuations that are\nrelated to the most probable continuations to be\nmore likely those that are unrelated.\n5 Experiment 2: DeLong et al. (2019)\n5.1 Introduction\nDeLong et al. (2019) also investigated the differ-\nence between the N400 amplitude elicited by im-\nplausible words that are related or unrelated to the\nmost predictable (highest-cloze) continuation. As\nin Ito et al. (2016), these stimuli were chosen such\nthat both related and unrelated words were highly\nimplausbile—in this case, ‘unpredictable words\nwere strategically chosen not to make sense in their\ngiven contexts’ (DeLong et al., 2019, p. 4). These\nstimuli are exemplified by the set shown in (4).\n(4) The commuter drove to work in her ______\nafter breakfast.\n• car (Predictable)\n• brakes (Related)\n• poetry (Unrelated)\nModel Test Statistic Corrected p\nBERT F(1, 159) =< 0.1 0 .9322\nALBERT F(1, 112) = 6.3 0 .0138\nRoBERTa F(1, 159) = 50.7 < 0.0001\nXLM-R F(1, 132) = 18.2 0 .0001\nGPT-2 XL F(1, 134) = 120.7 < 0.0001\nGPT-Neo F(1, 142) = 111.7 < 0.0001\nGPT-J F(1, 141) = 132.6 < 0.0001\nXGLM F(1, 159) = 122.4 < 0.0001\nTable 2: The results of a Type III ANOV A (using Sat-\nterthwaite’s method for estimating degrees of freedom;\nKuznetsova et al., 2017) on the DeLong et al. (2019)\nstimuli, testing for which language models experimental\ncondition (related or unrelated) is a significant predictor\nof their surprisal. This is the case for all language mod-\nels except BERT.\nLike Ito et al. (2016), DeLong et al. (2019) find\nthat overall, related continuations elicit a smaller\nN400 response than unrelated continuations.\n5.2 Results\nAs in Experiment 1, we ran the stimuli from the\noriginal experiment through the 8 language models\nand calculated the surprisal of each critical word.\nThe results of the experiment are shown in Figure 2.\n18\nIn all models except BERT, related stimuli all elicit\nnumerically lower surprisals than unrelated stimuli,\nindicating that they were more highly-predicted by\nthe language models.\nWe again ran the same statistical test as in Exper-\niment 1, testing whether experimental condition (re-\nlated or unrelated to the highest-cloze continuation)\nis a significant predictor of the surprisal elicited by\nthe stimuli in each language model. The ALBERT,\nXLM-R, GPT-2, GPT-Neo, and GPT-J regressions\nhad random intercepts of sentence frame and criti-\ncal word, while the BERT, RoBERTa, and XGLM\nregressions had only random intercepts for sen-\ntence frame. The results of the Type III ANOV A are\nshown in Table 2. Condition is a significant predic-\ntor of the surprisal of every model except BERT—\nin these models, related stimuli are predicted to be\nmore likely continuations of the sentence than un-\nrelated stimuli. Thus, with the exception of BERT,\nwe replicate the findings of Experiment 1.\n6 Experiment 3: Metusalem et al. (2012)\n6.1 Introduction\nMetusalem et al. (2012) investigated the extent to\nwhich relatedness to the event described in the pre-\nceding context impacts the amplitude of the N400\nresponse. Metusalem et al. (2012) presented human\nparticipants with experimental stimuli that included\neither the most probable (highest-cloze) continua-\ntion of a sentence, an implausible continuation that\nwas related to the event described, or an implau-\nsible continuation that was unrelated to the event\ndescribed. All of the implausible stimuli also had a\ncloze probability of zero. The stimuli are exempli-\nfied by the set for a single sentence frame shown\nin (5).\n(5) We’re lucky to live in a town with such a\ngreat art museum. Last week I went to see a\nspecial exhibit. I finally got in after waiting in\na long ______.\n• line (Predictable)\n• painting (Related)\n• toothbrush (Unrelated)\nMetusalem et al. (2012) found that despite their\nimplausibility and improbability (based on cloze),\ncritical words related to the event described in the\ncontext preceding them elicited smaller N400 re-\nsponses than words that were unrelated to the event,\na clear example of a related anomaly effect.\n6.2 Results\nAs in Experiments 1 and 2, we ran the stimuli from\nthe original experiment through the 8 language\nmodels and calculated the surprisal of each critical\nword. The results of the experiment are shown in\nFigure 3. As in Experiment 1, numerically, in all\nmodels related stimuli elicit lower surprisals than\nunrelated surprisals, indicating that they were more\nhighly predicted by the language models.\nGPT-2 (XL) GPT-Neo (2.7B) GPT-J (6B) XGLM (7.5B)\nBERT (Large, WWM) ALBERT (Large) RoBERTa (Large) XLM-R (Large)\nRelated Unrelated Related Unrelated Related Unrelated Related Unrelated\n0\n10\n20\n30\n0\n10\n20\n30\nRelatedness to highest-cloze continuation\nSurprisal\nCondition\nRelated\nUnrelated\nFigure 3: Mean surprisal elicited by each language model for the Metusalem et al. (2012) stimuli related and\nunrelated to the most probable (highest-cloze) continuation of each sentence. Error bars indicate standard error.\n19\nModel Test Statistic Corrected p\nBERT F(1, 29) = 77.1 < 0.0001\nALBERT F(1, 29) = 78.7 < 0.0001\nRoBERTa F(1, 28) = 188.1 < 0.0001\nXLM-R F(1, 34) = 83.4 < 0.0001\nGPT-2 XL F(1, 35) = 211.5 < 0.0001\nGPT-Neo F(1, 42) = 200.1 < 0.0001\nGPT-J F(1, 35) = 265.5 < 0.0001\nXGLM F(1, 33) = 222.5 < 0.0001\nTable 3: The results of a Type III ANOV A (using Sat-\nterthwaite’s method for estimating degrees of freedom;\nKuznetsova et al., 2017) on the Metusalem et al. (2012)\nstimuli, testing for which language models experimental\ncondition (related or unrelated) is a significant predictor\nof their surprisal. This is the case for all language mod-\nels.\nWe again ran the same statistical analyses as in\nExperiments 1 and 2, constructing linear mixed-\neffects regression models, all of which had random\nintercepts of sentence frame and critical word. Us-\ning a Type III ANOV A, we tested whether experi-\nmental condition (related or unrelated to the event\ndescribed in the preceding context) is a significant\npredictor of N400 amplitude. The results are shown\nin Table 3. As can be seen, experimental condition\nwas a significant predictor of the surprisal of all\nmodels.\n7 General Discussion\n7.1 Summary of Results\nIn all but one specific case—BERT in Experiment\n2—experimental condition significantly predicted\nlanguage model surprisal in the same direction as\nhuman N400 responses. The results of Experiments\n1 and 2, therefore demonstrate convincingly that,\nlike humans, language models do tend to predict\nthat anomalous words related to the most probable\ncontinuation are more probable than anomalous\nwords that are not. The results of Experiments\n3, analogously, demonstrate that like humans, lan-\nguage models tend to predict that anomalous words\nrelated to a relevant event described in the pre-\nceding context are more probable than anomalous\nwords that are not. Thus, like the human language\ncomprehension system, language models exhibit\nrelated anomaly effects.\n7.2 Psycholinguistic implications\nThese results have clear implications for psycholin-\nguistic research on the effects of related anomalies\non human language processing. First, a predictive\nsystem can display the effects—in fact, there is\nonly one set of stimuli for which not all models do.\nThis demonstrates the sufficiency of a predictive\nsystem for preactivating related anomalous stimuli\nto a greater degree than unrelated anomalous stim-\nuli. In other words, based on a parsimony criterion,\nthere is no need to posit that related anomaly effects\non human language processing require something\nbeyond a predictive system such as an associative\nsystem, either instead of or in addition to a predic-\ntive one.\nSecond, both kinds of related anomaly effect\nexplored—the reduction in N400 amplitude corre-\nlated with relatedness to the most probable contin-\nuation and that correlated with relatedness to the\nevent in the preceding context—are explainable by\na single mechanism. This may seem counterintu-\nitive, given how intuitively different the effects may\nseem. Yet this finding is consistent with the idea\nin the literature that the two effects can be consid-\nered different variants of the same phenomenon\n(DeLong et al., 2019; DeLong and Kutas, 2020).\nGiven that this study is based on computational\nmodeling, we should note that the results do not\nconstitute direct proof of a neurocognitive predic-\ntive system or of the lack of the involvement of an\nadditional associative mechanism. However, they\nare consistent with such accounts, and open the\ndoor for future research, both computational and\nexperimental. For example, it may be the case that\nother phenomena that have been argued to consti-\ntute evidence for a separate associative mechanism\n(see Federmeier, 2021, for review) may also be ex-\nplainable on the basis of prediction. On the other\nhand, the approach we use here can also be used\nto design stimuli that do not differ in probability in\norder to further test whether prediction can explain\nall related anomaly effects.\n7.3 Implications for NLP\nThe results of the present study demonstrate that re-\nlated anomaly effects occur in contemporary trans-\nformer language models. Based on the present\nstudy, this does not appear to be impacted by\nwhether the model is an autoregressive or masked\nlanguage model; or by whether the model is mono-\n20\nlingual or multilingual. In fact, the only model\nthat does not show the effect every time is BERT,\nthe least powerful model tested (all other models\nare either larger, trained on more data, or both).\nThus, in line with previous research showing that\nhigher-quality language models better predict hu-\nman processing metrics (Merkx and Frank, 2021),\nthe present results suggest that better language mod-\nels are also more likely to display human-like pat-\nterns of prediction.\nThe results of this study also have several im-\nplications for understanding how the predictions\nof humans and language models relate. As has\nbeen previously discussed, some researchers have\nargued that we should evaluate the predictions of\nlanguage models based on cloze probability (Et-\ntinger, 2020). In fact, some have suggested training\nmodels on cloze probabilities (Eisape et al., 2020).\nHowever, the results of this study, along with others\n(Frank et al., 2015; Aurnhammer and Frank, 2019;\nMichaelov and Bergen, 2020; Aurnhammer and\nFrank, 2019; Merkx and Frank, 2021; Szewczyk\nand Federmeier, 2022; Michaelov et al., 2022), sug-\ngest that the predictions of language models are\nhighly correlated with N400 amplitude; and recent\nwork has argued that that the activation states of\ntransformers are highly correlated with activation\nin the brain during language comprehension more\ngenerally (Schrimpf et al., 2020). Thus, while it\nmay be useful for certain tasks to have cloze-like\npredictions, it may be the case that we are gener-\nally more likely to get N400-like predictions from\nlanguage models.\nIf so, this is a cause for both optimism and pes-\nsimism. Given that humans are the gold-standard\nin natural language tasks generally, if a language\nmodel can make predictions that closely match\nthose that humans make as part of language com-\nprehension, this may also suggest that the represen-\ntations learned are at least in some ways function-\nally similar to those that humans use to generate\nthe same predictions. On the other hand, by the\nsame token, it may suggest a limit to the possibil-\nities of language modeling alone—there is much\nmore to language comprehension than the kinds\nof prediction that underlie the N400 response (see,\ne.g., Ferreira and Yang, 2019; DeLong and Kutas,\n2020; Kuperberg et al., 2020).\n8 Conclusion\nIn order to better understand related anomaly ef-\nfects in humans, we investigated whether contem-\nporary transformer language models display them.\nWe found that in all but one case, they do, suggest-\ning that related anomaly effects in both humans\nand language models may be driven by prediction\nalone.\nAcknowledgements\nWe would like to thank the authors of the origi-\nnal N400 experiment papers—Wen-Hsuan Chan,\nMartin Corley, Katherine A. DeLong, Jeffrey L.\nElman, Mary Hare, Aine Ito, Marta Kutas, Andrea\nE. Martin, Ken McRae, Ross Metusalem, Mante\nS. Nieuwland, Martin J. Pickering, and Thomas P.\nUrbach—for making their stimuli available. We\nwould also like to thank the anonymous reviewers\nfor their helpful comments, the other members of\nthe Language and Cognition Lab at UCSD for their\nvaluable discussion, and the San Diego Social Sci-\nences Computing Facility Team for their technical\nassistance. This work was partially supported by\na 2021-2022 Center for Academic Research and\nTraining in Anthropogeny Annette Merle-Smith\nFellowship awarded to James A. Michaelov, and\nthe RTX A5000 used for this research was donated\nby the NVIDIA Corporation.\nReferences\nAdam Amram, Anat Ben David, and Reut Tsarfaty.\n2018. Representations and Architectures in Neural\nSentiment Analysis for Morphologically Rich Lan-\nguages: A Case Study from Modern Hebrew. In\nProceedings of the 27th International Conference on\nComputational Linguistics, pages 2242–2252, Santa\nFe, New Mexico, USA. Association for Computa-\ntional Linguistics.\nChristoph Aurnhammer and Stefan L. Frank. 2019.\nEvaluating information-theoretic measures of word\nprediction in naturalistic sentence reading. Neuropsy-\nchologia, 134:107198.\nMegan Bardolph, Cyma Van Petten, and Seana Coulson.\n2018. Single Trial EEG Data Reveals Sensitivity\nto Conceptual Expectations (N400) and Integrative\nDemands (LPC). In Twelfth Annual Meeting of the\nSociety for the Neurobiology of Language, Quebec\nCity, Canada.\nDale J. Barr, Roger Levy, Christoph Scheepers, and\nHarry J. Tily. 2013. Random effects structure for\nconfirmatory hypothesis testing: Keep it maximal.\nJournal of Memory and Language, 68(3):255–278.\n21\nDouglas Bates, Martin Mächler, Ben Bolker, and Steve\nWalker. 2015. Fitting linear mixed-effects models\nusing lme4. Journal of Statistical Software, 67(1):1–\n48.\nEmily Bender. 2019. The #BenderRule: On naming\nthe languages we study and why it matters. The\nGradient.\nEmily M. Bender. 2009. Linguistically Naïve != Lan-\nguage Independent: Why NLP Needs Linguistic Ty-\npology. In Proceedings of the EACL 2009 Workshop\non the Interaction between Linguistics and Compu-\ntational Linguistics: Virtuous, Vicious or Vacuous?,\npages 26–32, Athens, Greece. Association for Com-\nputational Linguistics.\nEmily M. Bender. 2011. On Achieving and Evaluating\nLanguage-Independence in NLP. Linguistic Issues\nin Language Technology, 6.\nYoav Benjamini and Yosef Hochberg. 1995. Control-\nling the False Discovery Rate: A Practical and Pow-\nerful Approach to Multiple Testing. Journal of the\nRoyal Statistical Society. Series B (Methodological),\n57(1):289–300.\nSid Black, Leo Gao, Phil Wang, Connor Leahy, and\nStella Biderman. 2021. GPT-Neo: Large scale autore-\ngressive language modeling with mesh-tensorflow.\nZenodo.\nIna Bornkessel-Schlesewsky and Matthias Schlesewsky.\n2019. Toward a Neurobiologically Plausible Model\nof Language-Related, Negative Event-Related Poten-\ntials. Frontiers in Psychology, 10.\nTrevor Brothers and Gina R. Kuperberg. 2021. Word\npredictability effects are linear, not logarithmic: Im-\nplications for probabilistic models of sentence com-\nprehension. Journal of Memory and Language ,\n116:104174.\nHarm Brouwer, Matthew W. Crocker, Noortje J. Ven-\nhuizen, and John C. J. Hoeks. 2017. A Neurocompu-\ntational Model of the N400 and the P600 in Language\nProcessing. Cognitive Science, 41(S6):1318–1352.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage Models are Few-Shot Learners. In Ad-\nvances in Neural Information Processing Systems ,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nSamuel J. Cheyette and David C. Plaut. 2017. Modeling\nthe N400 ERP component as transient semantic over-\nactivation within a neural network model of word\ncomprehension. Cognition, 162:153–166.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, An-\ndrew M. Dai, Thanumalayan Sankaranarayana Pil-\nlai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,\nRewon Child, Oleksandr Polozov, Katherine Lee,\nZongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. 2022. PaLM: Scaling Language\nModeling with Pathways.\nJonathan H. Clark, Dan Garrette, Iulia Turc, and John\nWieting. 2022. Canine: Pre-training an Efficient\nTokenization-Free Encoder for Language Represen-\ntation. Transactions of the Association for Computa-\ntional Linguistics, 10:73–91.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\nCross-lingual Representation Learning at Scale. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 8440–\n8451, Online. Association for Computational Lin-\nguistics.\nKatherine A. DeLong, Wen-hsuan Chan, and Marta Ku-\ntas. 2019. Similar time courses for word form and\nmeaning preactivation during sentence comprehen-\nsion. Psychophysiology, 56(4):e13312.\nKatherine A. DeLong and Marta Kutas. 2020. Com-\nprehending surprising sentences: Sensitivity of post-\nN400 positivities to contextual congruity and seman-\ntic relatedness. Language, Cognition and Neuro-\nscience, 35(0):1044–1063.\nKatherine A DeLong, Thomas P Urbach, and Marta\nKutas. 2005. Probabilistic word pre-activation dur-\ning language comprehension inferred from electri-\ncal brain activity. Nature Neuroscience, 8(8):1117–\n1121.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\nDeep Bidirectional Transformers for Language Un-\nderstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n22\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nTiwalayo Eisape, Noga Zaslavsky, and Roger Levy.\n2020. Cloze Distillation: Improving Neural Lan-\nguage Models with Human Next-Word Prediction.\nIn Proceedings of the 24th Conference on Computa-\ntional Natural Language Learning, pages 609–619,\nOnline. Association for Computational Linguistics.\nAllyson Ettinger. 2020. What BERT Is Not: Lessons\nfrom a New Suite of Psycholinguistic Diagnostics for\nLanguage Models. Transactions of the Association\nfor Computational Linguistics, 8:34–48.\nAllyson Ettinger, Naomi Feldman, Philip Resnik, and\nColin Phillips. 2016. Modeling N400 amplitude us-\ning vector space models of word representation. In\nProceedings of the 38th Annual Conference of the\nCognitive Science Society, Philadelphia, USA.\nKara D. Federmeier. 2021. Connecting and considering:\nElectrophysiology provides insights into comprehen-\nsion. Psychophysiology, n/a(n/a):e13940.\nKara D. Federmeier and Marta Kutas. 1999. A Rose\nby Any Other Name: Long-Term Memory Structure\nand Sentence Processing. Journal of Memory and\nLanguage, 41(4):469–495.\nFernanda Ferreira and Zoe Yang. 2019. The Problem\nof Comprehension in Psycholinguistics. Discourse\nProcesses, 56(7):485–495.\nIra Fischler and Paul A. Bloom. 1979. Automatic and at-\ntentional processes in the effects of sentence contexts\non word recognition. Journal of Verbal Learning and\nVerbal Behavior, 18(1):1–20.\nHartmut Fitz and Franklin Chang. 2019. Language\nERPs reflect learning through prediction error propa-\ngation. Cognitive Psychology, 111:15–52.\nStefan L. Frank, Leun J. Otten, Giulia Galli, and\nGabriella Vigliocco. 2015. The ERP response to\nthe amount of information conveyed by words in\nsentences. Brain and Language, 140:1–11.\nStefan L. Frank and Roel M. Willems. 2017. Word\npredictability and semantic similarity show distinct\npatterns of brain activity during language compre-\nhension. Language, Cognition and Neuroscience ,\n32(9):1192–1203.\nRichard Futrell, Ethan Wilcox, Takashi Morita, Peng\nQian, Miguel Ballesteros, and Roger Levy. 2019.\nNeural language models as psycholinguistic subjects:\nRepresentations of syntactic state. In Proceedings of\nthe 2019 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long and\nShort Papers), pages 32–42, Minneapolis, Minnesota.\nAssociation for Computational Linguistics.\nKristina Gulordava, Piotr Bojanowski, Edouard Grave,\nTal Linzen, and Marco Baroni. 2018. Colorless\nGreen Recurrent Networks Dream Hierarchically. In\nProceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\nVolume 1 (Long Papers), pages 1195–1205, New Or-\nleans, Louisiana. Association for Computational Lin-\nguistics.\nAine Ito, Martin Corley, Martin J. Pickering, Andrea E.\nMartin, and Mante S. Nieuwland. 2016. Predicting\nform and meaning: Evidence from brain potentials.\nJournal of Memory and Language, 86:157–171.\nRafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam\nShazeer, and Yonghui Wu. 2016. Exploring the Lim-\nits of Language Modeling. arXiv:1602.02410 [cs].\nNora Kassner and Hinrich Schütze. 2020. Negated and\nMisprimed Probes for Pretrained Language Models:\nBirds Can Talk, But Cannot Fly. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 7811–7818, Online.\nAssociation for Computational Linguistics.\nYoon Kim, Yacine Jernite, David Sontag, and Alexan-\nder M. Rush. 2016. Character-Aware Neural Lan-\nguage Models. In Thirtieth AAAI Conference on\nArtificial Intelligence.\nGina R. Kuperberg, Trevor Brothers, and Edward W.\nWlotko. 2020. A Tale of Two Positivities and the\nN400: Distinct Neural Signatures Are Evoked by\nConfirmed and Violated Predictions at Different Lev-\nels of Representation. Journal of Cognitive Neuro-\nscience, 32(1):12–35.\nMarta Kutas. 1993. In the company of other words:\nElectrophysiological evidence for single-word and\nsentence context effects. Language and Cognitive\nProcesses, 8(4):533–572.\nMarta Kutas, Katherine A. DeLong, and Nathaniel J.\nSmith. 2011. A look around at what lies ahead: Pre-\ndiction and predictability in language processing. In\nMoshe Bar, editor, Predictions in the Brain: Using\nOur Past to Generate a Future, pages 190–207. Ox-\nford University Press, New York, NY , US.\nMarta Kutas and Steven A. Hillyard. 1984. Brain po-\ntentials during reading reflect word expectancy and\nsemantic association. Nature, 307(5947):161–163.\nMarta Kutas, Timothy E Lindamood, and Steven A Hill-\nyard. 1984. Word expectancy and event-related brain\npotentials during sentence processing. In S. Korn-\nblum and J. Requin, editors, Preparatory States and\nProcesses, pages 217–237. Lawrence Erlbaum, Hills-\ndale, NJ.\nAlexandra Kuznetsova, Per B. Brockhoff, and Rune\nH. B. Christensen. 2017. lmerTest Package: Tests in\nLinear Mixed Effects Models. Journal of Statistical\nSoftware, 82:1–26.\n23\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Soricut.\n2020. ALBERT: A Lite BERT for Self-supervised\nLearning of Language Representations. In Interna-\ntional Conference on Learning Representations.\nSarah Laszlo and Blair C. Armstrong. 2014. PSPs and\nERPs: Applying the dynamics of post-synaptic poten-\ntials to individual units in simulation of temporally\nextended Event-Related Potential reading data. Brain\nand Language, 132:22–27.\nSarah Laszlo and David C. Plaut. 2012. A neurally\nplausible Parallel Distributed Processing model of\nEvent-Related Potential word reading data. Brain\nand Language, 120(3):271–281.\nEllen F. Lau, Phillip J. Holcomb, and Gina R. Kuperberg.\n2013. Dissociating N400 Effects of Prediction from\nAssociation in Single-word Contexts. Journal of\nCognitive Neuroscience, 25(3):484–502.\nRoger Levy. 2008. Expectation-based syntactic compre-\nhension. Cognition, 106(3):1126–1177.\nXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu\nWang, Shuohui Chen, Daniel Simig, Myle Ott, Na-\nman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth\nPasunuru, Sam Shleifer, Punit Singh Koura, Vishrav\nChaudhary, Brian O’Horo, Jeff Wang, Luke Zettle-\nmoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoy-\nanov, and Xian Li. 2021. Few-shot Learning with\nMultilingual Language Models. arXiv:2112.10668\n[cs].\nAlma Lindborg and Milena Rabovsky. 2021. Meaning\nin brains and machines: Internal activation update\nin large-scale language model partially reflects the\nN400 brain potential. Proceedings of the Annual\nMeeting of the Cognitive Science Society, 43(43).\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoBERTa: A Robustly Optimized BERT Pretrain-\ning Approach. arXiv:1907.11692 [cs].\nScott A. McDonald and Richard C. Shillcock. 2003.\nEye Movements Reveal the On-Line Computation of\nLexical Probabilities During Reading. Psychological\nScience, 14(6):648–652.\nDanny Merkx and Stefan L. Frank. 2021. Human Sen-\ntence Processing: Recurrence or Attention? In Pro-\nceedings of the Workshop on Cognitive Modeling\nand Computational Linguistics, pages 12–22, Online.\nAssociation for Computational Linguistics.\nRoss Metusalem, Marta Kutas, Thomas P. Urbach, Mary\nHare, Ken McRae, and Jeffrey L. Elman. 2012. Gen-\neralized event knowledge activation during online\nsentence comprehension. Journal of Memory and\nLanguage, 66(4):545–567.\nJames A. Michaelov, Megan D. Bardolph, Seana Coul-\nson, and Benjamin K. Bergen. 2021. Different kinds\nof cognitive plausibility: Why are transformers bet-\nter than RNNs at predicting N400 amplitude? In\nProceedings of the 43rd Annual Meeting of the Cog-\nnitive Science Society, pages 300–306, University of\nVienna, Vienna, Austria (Hybrid).\nJames A. Michaelov and Benjamin K. Bergen. 2020.\nHow well does surprisal explain N400 amplitude\nunder different experimental conditions? In Pro-\nceedings of the 24th Conference on Computational\nNatural Language Learning, pages 652–663, Online.\nAssociation for Computational Linguistics.\nJames A. Michaelov, Seana Coulson, and Benjamin K.\nBergen. 2022. So Cloze yet so Far: N400 Amplitude\nis Better Predicted by Distributional Information than\nHuman Predictability Judgements. IEEE Transac-\ntions on Cognitive and Developmental Systems.\nSabrina J. Mielke. 2016. Language diversity in ACL\n2004 - 2016.\nKanishka Misra, Allyson Ettinger, and Julia Rayz. 2020.\nExploring BERT’s Sensitivity to Lexical Cues using\nTests from Semantic Priming. In Findings of the As-\nsociation for Computational Linguistics: EMNLP\n2020, pages 4625–4635, Online. Association for\nComputational Linguistics.\nRobert Munro. 2015. Languages at ACL this year.\nMehdi Parviz, Mark Johnson, Blake Johnson, and Jon\nBrock. 2011. Using Language Models and Latent\nSemantic Analysis to Characterise the N400m Neu-\nral Response. In Proceedings of the Australasian\nLanguage Technology Association Workshop 2011,\npages 38–46, Canberra, Australia.\nGrusha Prasad, Marten van Schijndel, and Tal Linzen.\n2019. Using Priming to Uncover the Organization\nof Syntactic Representations in Neural Language\nModels. In Proceedings of the 23rd Conference on\nComputational Natural Language Learning (CoNLL),\npages 66–76, Hong Kong, China. Association for\nComputational Linguistics.\nR Core Team. 2020. R: A Language and Environment\nfor Statistical Computing. R Foundation for Statisti-\ncal Computing, Vienna, Austria.\nMilena Rabovsky, Steven S. Hansen, and James L. Mc-\nClelland. 2018. Modelling the N400 brain potential\nas change in a probabilistic representation of mean-\ning. Nature Human Behaviour, 2(9):693–705.\nMilena Rabovsky and Ken McRae. 2014. Simulating\nthe N400 ERP component as semantic network error:\nInsights from a feature-based connectionist attractor\nmodel of word meaning. Cognition, 132(1):68–89.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Lan-\nguage Models are Unsupervised Multitask Learners.\npage 24.\n24\nJoost Rommers, Antje S. Meyer, Peter Praamstra, and\nFalk Huettig. 2013. The contents of predictions in\nsentence comprehension: Activation of the shape of\nobjects before they are referred to. Neuropsycholo-\ngia, 51(3):437–447.\nRStudio Team. 2020. RStudio: Integrated Development\nEnvironment for r. RStudio, PBC., Boston, MA.\nMartin Schrimpf, Idan Blank, Greta Tuckute, Carina\nKauf, Eghbal A. Hosseini, Nancy Kanwisher, Joshua\nTenenbaum, and Evelina Fedorenko. 2020. The\nneural architecture of language: Integrative reverse-\nengineering converges on a model for predictive pro-\ncessing. bioRxiv, page 2020.06.26.174482.\nNathaniel J. Smith and Roger Levy. 2013. The effect\nof word predictability on reading time is logarithmic.\nCognition, 128(3):302–319.\nJakub M. Szewczyk and Kara D. Federmeier. 2022.\nContext-based facilitation of semantic access fol-\nlows both logarithmic and linear functions of stimu-\nlus probability. Journal of Memory and Language,\n123:104311.\nWilson L. Taylor. 1953. “Cloze Procedure”: A New\nTool for Measuring Readability. Journalism Quar-\nterly, 30(4):415–433.\nWilson L. Taylor. 1957. “Cloze” readability scores as in-\ndices of individual differences in comprehension and\naptitude. Journal of Applied Psychology, 41(1):19–\n26.\nRomal Thoppilan, Daniel De Freitas, Jamie Hall,\nNoam Shazeer, Apoorv Kulshreshtha, Heng-Tze\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,\nYaGuang Li, Hongrae Lee, Huaixiu Steven Zheng,\nAmin Ghafouri, Marcelo Menegali, Yanping Huang,\nMaxim Krikun, Dmitry Lepikhin, James Qin, Dehao\nChen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts,\nMaarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-\nChing Chang, Igor Krivokon, Will Rusch, Marc\nPickett, Pranesh Srinivasan, Laichee Man, Kathleen\nMeier-Hellstern, Meredith Ringel Morris, Tulsee\nDoshi, Renelito Delos Santos, Toju Duke, Johnny So-\nraker, Ben Zevenbergen, Vinodkumar Prabhakaran,\nMark Diaz, Ben Hutchinson, Kristen Olson, Ale-\njandra Molina, Erin Hoffman-John, Josh Lee, Lora\nAroyo, Ravi Rajakumar, Alena Butryna, Matthew\nLamm, Viktoriya Kuzmina, Joe Fenton, Aaron Co-\nhen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-\nArcas, Claire Cui, Marian Croak, Ed Chi, and Quoc\nLe. 2022. LaMDA: Language Models for Dialog\nApplications.\nReut Tsarfaty, Djamé Seddah, Sandra Kübler, and\nJoakim Nivre. 2013. Parsing Morphologically Rich\nLanguages: Introduction to the Special Issue. Com-\nputational Linguistics, 39(1):15–22.\nTakahisa Uchida, Nicolas Lair, Hiroshi Ishiguro, and\nPeter Ford Dominey. 2021. A Model of Online\nTemporal-Spatial Integration for Immediacy and\nOverrule in Discourse Comprehension. Neurobiol-\nogy of Language, 2(1):83–105.\nCyma Van Petten and Barbara J. Luka. 2012. Predic-\ntion during language comprehension: Benefits, costs,\nand ERP components. International Journal of Psy-\nchophysiology, 83(2):176–190.\nNoortje J. Venhuizen, Matthew W. Crocker, and Harm\nBrouwer. 2019. Expectation-based Comprehen-\nsion: Modeling the Interaction of World Knowledge\nand Linguistic Experience. Discourse Processes,\n56(3):229–255.\nBen Wang and Aran Komatsuzaki. 2021. GPT-J-6B: A\n6 billion parameter autoregressive language model.\nHadley Wickham, Mara Averick, Jennifer Bryan, Win-\nston Chang, Lucy D’Agostino McGowan, Romain\nFrançois, Garrett Grolemund, Alex Hayes, Lionel\nHenry, Jim Hester, Max Kuhn, Thomas Lin Pedersen,\nEvan Miller, Stephan Milton Bache, Kirill Müller,\nJeroen Ooms, David Robinson, Dana Paige Seidel,\nVitalie Spinu, Kohske Takahashi, Davis Vaughan,\nClaus Wilke, Kara Woo, and Hiroaki Yutani. 2019.\nWelcome to the tidyverse. Journal of Open Source\nSoftware, 4(43):1686.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz,\nJoe Davison, Sam Shleifer, Patrick von Platen, Clara\nMa, Yacine Jernite, Julien Plu, Canwen Xu, Teven\nLe Scao, Sylvain Gugger, Mariama Drame, Quentin\nLhoest, and Alexander Rush. 2020. Transformers:\nState-of-the-Art Natural Language Processing. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38–45, Online. Association\nfor Computational Linguistics.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher De-\nwan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mi-\nhaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel\nSimig, Punit Singh Koura, Anjali Sridhar, Tianlu\nWang, and Luke Zettlemoyer. 2022. OPT: Open Pre-\ntrained Transformer Language Models.\nA Limitations\nAs mentioned the discussion section, one limitation\nof the present study is that while it demonstrates\nthat it is possible for related anomaly effects to\nemerge from a system engaged in prediction alone,\nit does not directly demonstrate that this is what is\noccurring in humans.\nA further limitation is that we model the results\nof three related anomaly experiments out of the\nlarger total number that have been carried out (for\nreview, see DeLong et al., 2019). However, given\nhow consistent related anomaly effects appear to\n25\nbe (DeLong et al., 2019), and how consistent our\nresults are (after statistical correction for multiple\ncomparisons, all three related anomaly effects are\nmodeled by all but one transformer, which only\nfails to model one effect), we do not believe this\npresents a problem for our analysis.\nFinally, the three experiments modeled were all\ncarried out in English. Related anomaly effects\nhave been reported in other languages (DeLong\net al., 2019) such as Dutch (Rommers et al., 2013);\nand these are not modeled in our study. Thus, it\nis an open question whether our results general-\nize to related anomaly effects in languages other\nthan English. However, we also note the evidence\nthat higher-quality models are better at predicting\nN400 amplitude (Merkx and Frank, 2021). For this\nreason, given the overwhelming focus on English\nin computational linguistics (Bender, 2009, 2011;\nTsarfaty et al., 2013; Munro, 2015; Mielke, 2016;\nKim et al., 2016; Amram et al., 2018; Bender, 2019;\nClark et al., 2022), current language model archi-\ntectures are likely to be best suited to predicting\nEnglish—indeed, current state-of-the-art models\nsuch as GPT-3 (Brown et al., 2020), OPT (Zhang\net al., 2022), PaLM (Chowdhery et al., 2022), and\nLaMDA (Thoppilan et al., 2022) are trained mostly\nor only on English data. Thus, while the focus on\nmodeling English may be an issue for the field as a\nwhole, in this case, focusing on experiments carried\nout in English may in fact give us the best possi-\nble chance to evaluate what the human predictive\nsystem could predict.\nB Models used\nThe details of the models used in this study are\nprovided in Table 4.\nModel Name Full Name on the Hugging Face Model Hub Reference\nBERT bert-large-cased-whole-word-masking Devlin et al. (2019)\nALBERT albert-xxlarge-v2 Lan et al. (2020)\nRoBERTa roberta-large Liu et al. (2019)\nXLM-R xlm-roberta-large Conneau et al. (2020)\nGPT-2 XL gpt2-xl Radford et al. (2019)\nGPT-Neo EleutherAI/gpt-neo-2.7B Black et al. (2021)\nGPT-J EleutherAI/gpt-j-6B Wang and Komatsuzaki (2021)\nXGLM facebook/xglm-7.5B Lin et al. (2021)\nTable 4: Transformer langauge models used in the present study. All were accessed using the transformers (Wolf\net al., 2020) package.\n26",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7187505960464478
    },
    {
      "name": "Language model",
      "score": 0.6742092967033386
    },
    {
      "name": "Human language",
      "score": 0.6374871134757996
    },
    {
      "name": "Transformer",
      "score": 0.616828978061676
    },
    {
      "name": "Facilitation",
      "score": 0.588509738445282
    },
    {
      "name": "Comprehension",
      "score": 0.5571783185005188
    },
    {
      "name": "Phenomenon",
      "score": 0.5333765745162964
    },
    {
      "name": "Natural language processing",
      "score": 0.5161412954330444
    },
    {
      "name": "Context (archaeology)",
      "score": 0.4787042438983917
    },
    {
      "name": "Artificial intelligence",
      "score": 0.43066778779029846
    },
    {
      "name": "Cognitive science",
      "score": 0.42724549770355225
    },
    {
      "name": "Linguistics",
      "score": 0.3710264563560486
    },
    {
      "name": "Psychology",
      "score": 0.23197898268699646
    },
    {
      "name": "Neuroscience",
      "score": 0.1036725640296936
    },
    {
      "name": "Epistemology",
      "score": 0.07606583833694458
    },
    {
      "name": "History",
      "score": 0.0730152428150177
    },
    {
      "name": "Programming language",
      "score": 0.06864827871322632
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I36258959",
      "name": "University of California, San Diego",
      "country": "US"
    }
  ]
}