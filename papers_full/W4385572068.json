{
  "title": "Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method",
  "url": "https://openalex.org/W4385572068",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2095829628",
      "name": "Yiming Wang",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2431633693",
      "name": "Zhuosheng Zhang",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2036086788",
      "name": "Rui Wang",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4310625358",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W3196696529",
    "https://openalex.org/W3105214104",
    "https://openalex.org/W4385571140",
    "https://openalex.org/W4309398774",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2130942839",
    "https://openalex.org/W2996264288",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W3205068155",
    "https://openalex.org/W2015014880",
    "https://openalex.org/W2936695845",
    "https://openalex.org/W4287674181",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W2963204221",
    "https://openalex.org/W2962849707",
    "https://openalex.org/W4297435087",
    "https://openalex.org/W3035252911",
    "https://openalex.org/W4385970303",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W4283026156",
    "https://openalex.org/W2971034336",
    "https://openalex.org/W2896739098",
    "https://openalex.org/W2889518897",
    "https://openalex.org/W1560729591",
    "https://openalex.org/W4225353277",
    "https://openalex.org/W4221161695",
    "https://openalex.org/W2123301721",
    "https://openalex.org/W4225934689",
    "https://openalex.org/W4303648904",
    "https://openalex.org/W2962924852",
    "https://openalex.org/W2888482885",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3034383590",
    "https://openalex.org/W3158986179",
    "https://openalex.org/W1826672328",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W2963929190",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4320858112",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4285283725",
    "https://openalex.org/W4226399820",
    "https://openalex.org/W9655565",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2949615363",
    "https://openalex.org/W4225320773",
    "https://openalex.org/W3159259047",
    "https://openalex.org/W2924690340",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W2290526371"
  ],
  "abstract": "Automatic summarization generates concise summaries that contain key ideas of source documents.As the most mainstream datasets for the news sub-domain, CNN/DailyMail and BBC XSum have been widely used for performance benchmarking. However, the reference summaries of those datasets turn out to be noisy, mainly in terms of factual hallucination and information redundancy. To address this challenge, we first annotate new expert-writing Element-aware test sets following the “Lasswell Communication Model” proposed by Lasswell, allowing reference summaries to focus on more fine-grained news elements objectively and comprehensively. Utilizing the new test sets, we observe the surprising zero-shot summary ability of LLMs, which addresses the issue of the inconsistent results between human preference and automatic evaluation metrics of LLMs’ zero-shot summaries in prior work. Further, we propose a Summary Chain-of-Thought (SumCoT) technique to elicit LLMs to generate summaries step by step, which helps them integrate more fine-grained details of source documents into the final summaries that correlate with the human writing mindset. Experimental results show our method outperforms state-of-the-art fine-tuned PLMs and zero-shot LLMs by +4.33/+4.77 in ROUGE-L on the two datasets, respectively. Dataset and code are publicly available at https://github.com/Alsace08/SumCoT.",
  "full_text": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\nVolume 1: Long Papers, pages 8640–8665\nJuly 9-14, 2023 ©2023 Association for Computational Linguistics\nElement-aware Summarization with Large Language Models:\nExpert-aligned Evaluation and Chain-of-Thought Method\nYiming Wang, Zhuosheng Zhang, Rui Wang∗\nShanghai Jiao Tong University\nalsaceym@gmail.com, {zhangzs, wangrui12}@sjtu.edu.cn\nAbstract\nAutomatic summarization generates concise\nsummaries that contain key ideas of source\ndocuments. As the most mainstream datasets\nfor the news sub-domain, CNN/DailyMail and\nBBC XSum have been widely used for per-\nformance benchmarking. However, the refer-\nence summaries of those datasets turn out to\nbe noisy, mainly in terms of factual hallucina-\ntion and information redundancy. To address\nthis challenge, we first annotate new expert-\nwriting Element-aware test sets following the\n“Lasswell Communication Model” proposed\nby Lasswell (1948), allowing reference sum-\nmaries to focus on more fine-grained news el-\nements objectively and comprehensively. Uti-\nlizing the new test sets, we observe the surpris-\ning zero-shot summary ability of LLMs, which\naddresses the issue of the inconsistent results\nbetween human preference and automatic eval-\nuation metrics of LLMs’ zero-shot summaries\nin prior work. Further, we propose a Summary\nChain-of-Thought (SumCoT) technique to\nelicit LLMs to generate summaries step by\nstep, which helps them integrate more fine-\ngrained details of source documents into the\nfinal summaries that correlate with the human\nwriting mindset. Experimental results show our\nmethod outperforms state-of-the-art fine-tuned\nPLMs and zero-shot LLMs by +4.33/+4.77 in\nROUGE-L on the two datasets, respectively.\nDataset and code are publicly available at\nhttps://github.com/Alsace08/SumCoT.\n1 Introduction\nAutomatic summarization is a challenging text gen-\neration task that condenses the source text into\na few coherent and abstract sentences. In recent\nyears, the study of summarization has evolved with\nsupervised learning based on sequence-to-sequence\narchitectures (Sutskever et al., 2014; Vinyals et al.,\n2015; Vaswani et al., 2017) and transfer learn-\ning based on pre-trained language models (De-\n∗ Corresponding author\nOn March 8, Marcin Wasniewski crashed into the back of a lorry on the\nA444 in Coventry when driving a car. Incredibly, he was injured with just\ncuts and bruises and cheated death by just millimeters. Paramedics were\nshocked because of serious damage to the car. This father firmly believed\nthat Jesus saved him.\nElement-aware Summary (Ours)\nEntity Date Event Result\nTrailer 'embedded' into car windscreen in smash on A444 in Coventry.\nImpact would have 'certainly been fatal' if a couple of inches closer to driver.\nParamedics were shocked when Marcin Wasniewski walked out unaided.\nDataset-specific Summary (Original)\nFigure 1: Case comparisons for our Element-aware\nsummary and original dataset-specific summary. News\nelements have been highlighted with different color\nshadows. It is clear that our element-aware summary\ncovers more comprehensive elements, and the logical\nconnection between the elements is smoother.\nvlin et al., 2019; Zhang et al., 2019; Liu et al.,\n2019; Lewis et al., 2020). Existing studies com-\nmonly train or fine-tune language models on large-\nscale corpus (Nallapati et al., 2016; Narayan et al.,\n2018; Koupaee and Wang, 2018; Fabbri et al.,\n2019), so superior performance is often reported\nby measuring the lexical overlap (e.g. ROUGE (Lin,\n2004)) with golden summaries (Zhang et al., 2020a;\nNarayan et al., 2021; Liu et al., 2022b; Narayan\net al., 2022), which reflects the fit degree to these\nstandard datasets. However, some standard datasets\nhave shown to be noise-enriched, mainly in terms\nof information redundancy (Kryscinski et al., 2019)\nand factual hallucination (Maynez et al., 2020).\nMeanwhile, sufficient experiments have shown that\nreference summaries in these standard datasets per-\nform poorly on human assessment dimensions, es-\npecially coherence, consistency, and relevance (Sti-\nennon et al., 2020; Fabbri et al., 2021).\nTo fill this gap, this work releases expert-writing\nElement-aware summary test sets. In professional\nnews writing, core elements such as character, time,\nplace, event, etc., are indispensable. This theory\nnamed “Lasswell Communication Model” was first\n8640\nElement Extraction\nSummarization\nArticle: The 69-year-old's yamaha collided with a Nissan car between handley's corner and barre garroo\ncrossroads at about 17:00 bst on 4 June. Mr. Baker, who was from the island, was airlifted to noble's hospital,\nwhere he later died. (…) He added that investigations are ongoing in relation to the crash. The car driver, who\npolice say was northern irish, was treated in hospital but has been discharged. Another motorcyclist who was\ninjured after the crash has also been released from hospital. (…)\nWhat are the important entities in this document? \nWhat are the important dates in this document? \nWhat events are happening in this document? \nWhat is the result of these events?\nPlease Answer the above questions:\nOn 4 June, Mr. Baker’s motorcycle collided with a car resulting in his death. The car driver and motorcyclist were injured.\n1. The important entities in this document are Mr. Baker, the car driver, and the motorcyclist who was injured.\n2. The important dates in this document are 4 June and the present day.\n3. The events happening in this document are a collision between Mr. Baker’s motorcycle and a car, and the \ninvestigation into the collision.\n4. The result of these events is that Mr. Baker died and the car driver and motorcyclist were injured.\nSource Document Guiding Questions \nfor Prompting\nLLM\nLLM\n2\nFigure 2: Full pipeline and example of our Summary Chain-of-Thought method.\nproposed by Lasswell (1948), and later evolved\ninto the “5W1H” paradigm.1 Following this fine-\ngrained protocol,2 we ask three news experts to\nrewrite summaries of source documents from two\nstandard news datasets — CNN/DailyMail (Nalla-\npati et al., 2016) and BBC XSum(Narayan et al.,\n2018), allowing reference summaries to contain\nnews core elements objectively and comprehen-\nsively3 (See Figure 1 for one example). Utilizing\nthe new test sets, we are surprised to find that the\nzero-shot performance of large language models\n(LLMs) is highly competitive with some strong\nfine-tuned pre-trained models (PLMs), and the per-\nformance of PLMs declines compared to standard\ntest sets. This observation can to some extent ad-\ndress the confusion raised by Goyal et al. (2022)\nthat why GPT-3 generates more human-favored\nsummaries but performs unexpectedly poorly in\nautomatic evaluation metrics — likely due to the\nlimitation of noisy testing domains.\nWe further build a benchmark for the new test\nsets. Inspired by the competitive zero-shot perfor-\nmance of LLMs and chain-of-thought technique\n1who, where, when, why, what, and how. who and where\ncan be packaged as entity. why is usually not independent of\nwhat, so the two can be packaged as event.\n2Some journalists may follow the Inverted Pyramid style\n(Pö ttker, 2003), but this protocol is more about a consideration\nof the full-text layout and is prone to information imbalance\nwithin the text (Koupaee and Wang, 2018).\n3In the era of zero-shot paradigm, LLMs (e.g. GPT-3\n(Brown et al., 2020)) have shown decent performance in sum-\nmarization tasks, so this work focuses on the zero-shot setting\nto only annotate test sets.\n(Wei et al., 2022b; Kojima et al., 2022), we create\nSummary Chain-of-Thought (SumCoT) to elicit\nLLMs to generate summaries step by step (shown\nin Figure 2). Concretely, we first guide LLMs to\nextract the four most core elements for standard-\nized news texts — Entity, Date, Event, Result —\nthrough some manually-set guiding questions. Im-\nmediately after, the guiding questions and corre-\nsponding answers output by LLMs are packaged,\nthey further guide LLMs to focus on more critical\ndetails to generate summaries that better correlate\nwith the element-aware writing pattern.\nOverall, our main contributions are three-fold:\n(i) We construct expert-writing element-aware\nsummary test sets to evaluate general summariza-\ntion systems more objectively (§2).\n(ii) We explore the zero-shot summarization abil-\nity of LLMs on the new test sets and demonstrate\nthat their writing ability cannot be fully reflected\nby standard test sets (§3).\n(iii) We propose a new CoT-based summariza-\ntion technique, which allows the LLMs to generate\nmore fine-grained summaries step by step (§4).\n2 Element-aware Summary Test Set\n2.1 Data Construction\nWe select two standard news summary datasets\n(test sets) as document sources, which are repre-\nsentative in terms of length and abstraction: (i)\nCNN/DailyMail (Nallapati et al., 2016) provides\na large-scale multi-domain news collection, which\n8641\nis representative of single-document datasets. We\nuse the standard splits (Hermann et al., 2015) for\ntest sets; (ii) BBC XSum (Narayan et al., 2018)\nprovides a highly abstracted news collection. It has\none-sentence summaries and is more abstractive\nthan the CNN/DailyMail dataset.\nFor both datasets, we ask three news experts\nto independently write professional summaries for\n200 randomly sampled source documents accord-\ning to a complete writing protocol (introduced\nin §2.2), ensuring comprehensiveness, objectivity,\nand uniformity of writing style. Different from\ncrowd-sourcing, the involvement of professional\nwriters allows higher inter-annotator agreement.\nAlso, to ensure the uniformity of writing style, we\nrequire one of the experts to lead the writing, and\nthe other two to judge the completed summary in\nfour dimensions from the protocol. If there ex-\nist inconsistent opinions, they will revise the sum-\nmary after internal discussion until all pass this\nannotation. Statistically, the annotation duration of\none summary is approximately proportional to the\nlength of source documents. For CNN/DailyMail,\na summary is written in 25-30 minutes on average,\nand for BBC XSum, in 15-20 minutes on average.\n2.2 Writing Protocols\nAnnotators must follow a comprehensive protocol\nwhen writing. Specifically, we divide the proto-\ncol into micro demands and macro demands. The\nformer emphasizes our targets, namely element\nawareness, and the latter guarantees the profession-\nalism and objectivity of the overall writing quality,\nwhich alleviates the simple stacking of elements.\nThe two demands complement each other.\nMicro Demands. All news summaries should\nhave four essential core elements — Entity, Date,\nEvent, and Result — following the “Lasswell Com-\nmunication Model” (Lasswell, 1948), and these el-\nements must be faithful to the source document.\nFor example, when there is no date in the source\ndocument, writers can not add dates to the final\nsummary by force.\nMacro Demands. All news summaries should fo-\ncus on the four dimensions (Gehrmann et al., 2018;\nKryscinski et al., 2019). (i) Fluency: No spelling,\ngrammatical, or syntactic errors within sentences;\n(ii) Coherence: The summary should not be a heap\nof events, and linguistic transition must be smooth\nand logically correct; (iii) Consistency: No hallu-\ncinated facts — neither facts that do not appear in\nReference\nSummary\nCNN/DaliyMail\n% of novel\nuni/bi/trigram\nAvg. summary length of\nwords/sentences\nDataset-specific 17.00/53.91/71.98 50.14/3.59\nElement-aware 20.31/49.72/62.14 51.08/2.71\nReference\nSummary\nBBC XSum\n% of novel\nuni/bi/trigram\nAvg. summary length of\nwords/sentences\nDataset-specific 39.39/87.86/96.95 22.18/1.00\nElement-aware 36.28/70.56/82.36 23.33/1.00\nTable 1: Some statistics of element-aware summaries\ncompared with original dataset-specific summaries.\nNovel n-grams indicates the n-grams that are included\nin the summary but not in the source document.\nor are contrary to the source document are allowed;\n(iv) Relevance: Adequately weigh the importance\nof multiple facts, and find the core concern of the\ntext. Non-core facts can be reduced in length, and\nredundant details are not allowed.\n2.3 Overall Quality\nWe first compare the overall quality of our test\nsets with the original data. Table 1 quantifies\nsome statistics of the element-aware summaries\ncompared with original dataset-specific summaries.\nThe average length of element-aware summaries\nlargely matches the distribution of that of dataset-\nspecific summaries. In terms of abstraction, we\nreport the percentage of novel n-grams that are\nincluded in the summary but not in the source doc-\nument. We note that the percent of novel n-grams\nin element-aware summaries is lower than that of\ndataset-specific summaries but with a reasonable\ngap, which reflects that expert-writing element-\naware summaries would be more faithful to the\nsource documents but not heavily replicate them.4\nWe further hold a vote on two highly subjective\ndimensions — logical coherence and factual im-\nportance, they reflect the professionalism and the\ninformation comprehensiveness of writing. 5 We\nask three annotators to perform preference selec-\ntion on 50 randomly selected instances from both\ndatasets — for each instance, they can select at\nmost one summary that performs better in the two\n4Additionally, factual errors in the dataset-specific sum-\nmaries will result in a spuriously high abstraction to some\ndegree. In contrast, element-aware summaries better trade-off\nabstraction and faithfulness (See Appendix B for examples).\n5Whether the transition between facts is coherent, and\nwhether important facts in the source documents are compre-\nhensive and non-redundant in the summaries.\n8642\n93.3%\n4.0% 2.7%\nLogical Coherence\n82.6%\n12.7%\n4.7%\nFactual Importance\nElement-aware \nSummary\nDataset-specific \nSummary\nNeither\n(a) CNN/DailyMail\n60.7%\n27.3%\n12.0%\nLogical Coherence\n85.3%\n7.3%\n7.4%\nFactual Importance\nElement-aware \nSummary\nDataset-specific \nSummary\nNeither\n(b) BBC XSum\nFigure 3: Average annotator vote distribution for better\nsummaries between dataset-specific and element-aware\nsummaries on “logical coherence” and “factual impor-\ntance” dimensions. It is clear that element-aware sum-\nmaries are more accepted by the public.\ndimensions, respectively, or none if they consider\nboth to be not good.\nFigure 3 shows the vote results. It is clear that\nelement-aware summaries are significantly more\npopularly accepted in both subjective dimensions\nby the public, demonstrating that our summaries\nare more human-favored.\n2.4 Element-aware Characteristic\nIn this part, we will demonstrate that our anno-\ntated summaries have more obvious element-aware\ncharacteristic than the dataset-specific summaries.\nWe ask three annotators to evaluate every\ndocument-summary pair. For each sample, and\nfor i-th annotator (i = 1, 2, 3) and j-th element in\nthe writing protocol (j = 1, 2, 3, 4), we ask this\nannotator to release two sets that separately contain\nall j-th elements in the source document they con-\nsider important and all j-th elements appearing in\nthe summary. The annotator-released sets for the\nsource document and summary are denoted as Aj\ni\nand A′\ni\nj , respectively.\nThen, we compute the Precision and Recall,\nthey separately reflect the accuracy of the core\nelements embedded in the summary and the hit\nrate of the core elements in the source document.\nPrecisionj and Recallj are formulated as:6\n6In extreme situations, when Aj\ni is empty, i.e., the annota-\nCNN/DailyMail\nCore\nElement\nElement-aware Dataset-specific\nP R F1 P R F1\nEntity 0.98 0.96 0.98 0.75 0.63 0.68\nDate 0.89 0.91 0.90 0.74 0.65 0.69\nEvent 0.96 0.95 0.95 0.66 0.55 0.60\nResult 0.95 0.95 0.95 0.49 0.42 0.45\nBBC XSum\nCore\nElement\nElement-aware Dataset-specific\nP R F1 P R F1\nEntity 0.97 0.87 0.92 0.76 0.54 0.63\nDate 0.97 0.95 0.96 0.52 0.45 0.48\nEvent 0.93 0.93 0.93 0.80 0.48 0.60\nResult 0.96 0.98 0.97 0.23 0.18 0.20\nTable 2: The comparison between element-aware and\ndataset-specific test sets over Precision (P), Recall (R),\nand F1 score of all four elements.\nPrecisionj = 1\n3\n3∑\ni=1\n|Aj\ni\n⋂A′\ni\nj |\n|A′\ni\nj |\n, j = 1, 2, 3, 4\nRecallj = 1\n3\n3∑\ni=1\n|Aj\ni\n⋂A′\ni\nj |\n|Aj\ni |\n, j = 1, 2, 3, 4\n(1)\nwhere |·|denotes the number of elements in the set.\nFor Event and Result, a complete lexical overlap is\nunrealistic due to the subjectivity in expression, so\nas long as the same meaning is considered correct.\nWe compare the Precision and Recall between\nelement-aware and dataset-specific test sets, and\ncomputer the average of all document-summary\npairs of a test set. We also compute F1 score (The\nharmonic mean of Precision and Recall) to mea-\nsure the overall level. Results are shown in Table\n2, the comparison shows that our test sets have a\nsignificant advantage in the element-aware char-\nacteristic. The dataset-specific test sets perform\npoorly particularly in the Recall score, meaning\nthat they have ignored many fine-grained details.\n3 Preliminary Comparison: Zero-shot\nLLMs Versus Fine-tuned PLMs\nIn this section, we preliminarily compare exist-\ning strong LLMs and PLMs upon our element-\naware test sets, designed to analyze the general\nsummary capabilities of zero-shot LLMs and fine-\ntuned PLMs from a more fine-grained perspective.\ntor thinks that there is no j-th element in the source document,\nthe Recallj is 1 if this element is also not covered in the sum-\nmary, otherwise 0. Ditto for Precisionj when A′\ni\nj is empty.\n8643\nCNN/DaliyMail\nModel\nRef Element-aware (ours) Dataset-specific (original)\nROUGE-1 ROUGE-2 ROUGE-L BERTSCORE ROUGE-1 ROUGE-2 ROUGE-L BERTSCORE\nBART-BASE 36.06 15.93 33.09 0.8762 38.55 17.57 36.05 0.8779\nBART-LARGE 37.98 18.16 34.30 0.8860 39.01 18.26 37.15 0.8868\nT5-LARGE 37.47 17.66 34.34 0.8768 38.84 18.39 37.01 0.8802\nPEGASUS-LARGE 36.65 17.58 33.84 0.8710 39.11 17.82 36.86 0.8798\n175B GPT-3 37.75 15.20 34.25 0.8905 30.10 8.98 27.51 0.8718\nBBC XSum\nModel\nRef Element-aware (ours) Dataset-specific (original)\nROUGE-1 ROUGE-2 ROUGE-L BERTSCORE ROUGE-1 ROUGE-2 ROUGE-L BERTSCORE\nBART-BASE 21.89 5.13 17.19 0.8663 29.67 10.09 24.46 0.8779\nBART-LARGE 23.79 5.02 17.93 0.8710 33.95 11.29 26.78 0.8880\nT5-LARGE 24.98 6.89 19.46 0.8728 30.79 9.61 24.73 0.8792\nPEGASUS-LARGE 21.35 4.87 17.03 0.8662 35.16 13.21 29.30 0.8888\n175B GPT-3 31.74 10.95 25.42 0.8933 19.99 3.69 15.86 0.8654\nTable 3: Performance comparison of zero-shot LLMs (175B GPT-3) and fine-tuned PLMs (BART, T5, and PEGASU).\nWe separately compare generated summaries of these models with original reference summaries from standard\ndatasets (Dataset-specific) and our reference summaries rewritten by news experts (Element-aware). Results are\nevaluated automatically over ROUGE-1/2/L and BERTSCORE.\n3.1 Experimental Setup\nDataset. We perform experiments on two main-\nstream news datasets CNN/DailyMail and BBC\nXSum introduced in §2.1. For each source doc-\nument on both datasets, we compare summaries\ngenerated by models with dataset-specific (origi-\nnal) and element-aware (ours) reference summaries.\nEach test set includes 200 document-summary\npairs consistent with the annotation number.\nModels. For LLMs, We use 175B-parameter\nGPT-3 (text-davinci-002 version) (Brown et al.,\n2020; Ouyang et al., 2022) for our study. For PLMs,\nwe select B ART (Lewis et al., 2020), T5 (Raffel\net al., 2020) — two strong generation-oriented\nPLMs, and P EGASUS (Zhang et al., 2020a) — a\nsummarization-customized PLM fine-tuned on two\ndatasets separately as the strong baselines.\nImplementation. We follow the official fine-\ntuned models released on the Huggingface for\nPLMs generation. For zero-shot prompts of LLMs,\nWe follow Sanh et al. (2022) and Goyal et al.\n(2022) to set [p] = \"Summarize the above article:\"\nas the standard prompt on CNN/DailyMail. On\nBBC XSum, considering its one-sentence summary\nstyle with extreme generalization, we use sentence-\nconstraint prompt [p] = \"Summarize the above ar-\nticle in one sentence:\". All the source documents\nare truncated to 1024 tokens when using PLMs and\n2048 tokens when using LLMs. See Appendix A\nfor more useful implementation details.\nEvaluation. We evaluate the generated sum-\nmaries using lexical-overlap metrics, specifi-\ncally ROUGE-1/2/L (Lin, 2004), and embedding-\nsimilarity metrics, specifically BERTS CORE\n(Zhang et al., 2020b). Besides, we resort to more\nprecise human studies to evaluate the consistency\nof generated summaries and source documents. See\nAppendix A for more useful evaluation details.\n3.2 Main Results\nLongitudinal Comparison: Language Models.\nFirst, we compare the performance of different\nmodels on the same test set (see columns of Ta-\nble 3). On dataset-specific test sets (the right part),\nthe relative performances among PLMs are basi-\ncally in line with the experimental results in Zhang\net al. (2020a), meaning that our sampled source\ndocuments basically follow the distribution of orig-\ninal test sets. On element-aware test sets (the left\npart), surprisingly, zero-shot GPT-3 performs com-\npetitively with all other fine-tuned PLMs and even\noutperforms other models with a wide margin on\nBBC XSum. These all present that LLMs have more\nfine-grained summary capabilities, and their zero-\nshot evaluation is limited by the original test sets.\nHorizontal Comparison: Test Sets. Next, we\ncompare the performances of the same model on\ndifferent test sets (see rows of Table 3). We\nnote that these fine-tuned PLMs perform worse\non element-aware test sets than they do on dataset-\nspecific test sets, with a particularly salient drop on\n8644\nBBC XSum. In contrast, GPT-3 obtains dramatic\nimprovements on element-aware test sets. Com-\npared with the performances on dataset-specific test\nsets, ROUGE-1/2/L increases by +7.65/+6.22/+6.74\npoints on CNN/DailyMail and +11.75/+7.26/+9.56\npoints on BBC XSum. These contrasting results\ndemonstrate that our annotated test sets pose a chal-\nlenge for PLMs fine-tuned with standard datasets,\nbut LLMs can perform well due to their more fine-\ngrained writing capabilities.\n3.3 Human Study\nHuman studies are conducted as an overall quality\nassessment of human preferences. We use a 7-point\nLikert scale (Likert, 1932) to ask annotators to eval-\nuate four dimensions: Fluency, Coherence, Consis-\ntency, and Relevance (equivalent to macro demands\nin §2.2). Different from baseline-free human stud-\nies, we set the element-aware summaries as the\nbaseline (score 0) and set the scoring range to -3~3.\nA more positive score means higher quality than\nthe element-aware summary and vice versa. For\neach sample, we present the dataset-specific (orig-\ninal), BART-LARGE, T5-LARGE, PEGASU-LARGE\nand 175B GPT-3 summaries to the annotators and\nask them to score one by one.\nAs is shown in Figure 4, GPT-3 summaries out-\nperform almost all other dataset-specific or model-\ngenerated summaries in each dimension, although\nnot yet achieved the level of element-aware sum-\nmaries. All of these results can fully demonstrate\nthat LLMs have great potential for summarization,\nand a higher-quality dataset is key for evaluation.\n4 Towards Element-oriented Summary:\nChain-of-Thought Method\nWe have analyzed the summary writing ability of\nzero-shot GPT-3 and other fine-tuned PLMs in\n§3. We see that GPT-3 performs surprisingly well\non our element-aware test sets. The results com-\npellingly show that GPT-3 has great potential for\nfine-grained zero-shot summary writing. Inspired\nby the prevalence of the chain-of-thought (CoT)\ntechnique in LLMs (Wei et al., 2022b; Kojima et al.,\n2022; Zhang et al., 2022), we can further enhance\nthe summarization ability of LLMs by leveraging\na CoT-based method (SumCoT). SumCoT elicits\nLLMs to focus on news core elements, thereby\ngenerating element-aware summaries step by step.\nThe pipeline and example have been illustrated in\nFigure 2.\n/uni00000016/uni00000011/uni00000013\n/uni00000015/uni00000011/uni00000018\n/uni00000015/uni00000011/uni00000013\n/uni00000014/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013\n/uni00000028/uni0000004f/uni00000048/uni00000050/uni00000048/uni00000051/uni00000057/uni00000010/uni00000044/uni0000005a/uni00000044/uni00000055/uni00000048/uni00000003/uni00000036/uni00000058/uni00000050/uni00000050/uni00000044/uni00000055/uni0000005c\n/uni00000026/uni00000031/uni00000031/uni00000012/uni00000027/uni00000044/uni0000004c/uni0000004f/uni0000005c/uni00000030/uni00000044/uni0000004c/uni0000004f\n/uni00000032/uni00000055/uni0000004c/uni0000004a/uni0000004c/uni00000051/uni00000044/uni0000004f/uni00000025/uni00000024/uni00000035/uni00000037/uni00000037/uni00000018/uni00000033/uni00000028/uni0000002a/uni00000024/uni00000036/uni00000038/uni00000036/uni0000002a/uni00000033/uni00000037/uni00000010/uni00000016\n/uni00000029/uni0000004f/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c/uni00000026/uni00000052/uni0000004b/uni00000048/uni00000055/uni00000048/uni00000051/uni00000046/uni00000048/uni00000026/uni00000052/uni00000051/uni00000056/uni0000004c/uni00000056/uni00000057/uni00000048/uni00000051/uni00000046/uni0000005c/uni00000035/uni00000048/uni0000004f/uni00000048/uni00000059/uni00000044/uni00000051/uni00000046/uni00000048\n/uni00000016/uni00000011/uni00000013\n/uni00000015/uni00000011/uni00000018\n/uni00000015/uni00000011/uni00000013\n/uni00000014/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000018\n/uni00000014/uni00000011/uni00000013\n/uni00000028/uni0000004f/uni00000048/uni00000050/uni00000048/uni00000051/uni00000057/uni00000010/uni00000044/uni0000005a/uni00000044/uni00000055/uni00000048/uni00000003/uni00000036/uni00000058/uni00000050/uni00000050/uni00000044/uni00000055/uni0000005c\n/uni00000025/uni00000025/uni00000026/uni00000003/uni0000003b/uni00000036/uni00000058/uni00000050\n/uni00000028/uni00000059/uni00000044/uni0000004f/uni00000058/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000027/uni0000004c/uni00000050/uni00000048/uni00000051/uni00000056/uni0000004c/uni00000052/uni00000051/uni00000056\n/uni00000024/uni00000059/uni00000048/uni00000055/uni00000044/uni0000004a/uni00000048/uni00000003/uni00000036/uni00000046/uni00000052/uni00000055/uni00000048/uni00000056\nFigure 4: Human evaluation scores of four dimensions\nabout summary quality on the 50-shot CNN/DailyMail\n(the upper part) and BBC XSum(the lower part) datasets.\nMore human study details are shown in Appendix A.2.\n4.1 Two-stage Pipeline\nWe first ask the LLMs to extract core news elements\nin the source document by manually-set guiding\nquestions, and later integrate the information based\non the extracted elements and more details from the\nsource documents. Pipeline details are as follows.\n• Stage 1: Core element extraction. In the first\nstage, we create guiding-question prompts to\nelicit the LLMs to extract four core elements:\nEntity, Date, Event, Result. For the i-th element,\nwe set a simple questionqi to guide the model for\nextracting it (shown in Figure 2), and then con-\ncatenate these questions into Q = [q1, q2, q3, q4].\nLet the source document be S, then the LLMs\ninput in this stage is formulated as [S; Q].\n• Stage 2: Multiple information integration and\nsummarization. We obtain an extraction answer\nA from the LLMs in Stage 1. Next, we integrate\nthe extracted elements and more detailed informa-\ntion from the source document. We concatenate\nthe source document, questions, answer, and a\nsimple prompt [p′]=\"Let’s integrate the above in-\nformation and summarize the article:\" to prompt\nthe LLMs for summary generation.7 The input\nin this stage is formulated as [S; Q; A; [p′]], and\nthe output is the final summary.\n7Similarly, for XSum, [p′]=\"Let’s integrate the above in-\nformation and summarize the article in one sentence:\"\n8645\nGPT-3 Zero-shot Summary (Standard)\nSummarize the above article:\nThe article discusses how Rod Blagojevich, a former Illinois governor, has let his hair go while serving his prison sentence.\nThe photos show the former governor with white hair, rather than the black hair that was his trademark as a politician.\nBlagojevich is currently serving a 14-year sentence at the Federal Correctional Institution Englewood near Denver.\nGPT-3 Zero-shot-cot Summary (Using SumCoT)\nLet’s integrate the above information and summarize the article:\nIn 2008, Rod Blagojevich was arrested for trying to sell Barack Obama’s U.S. Senate seat. He was impeached and removed\nfrom office in 2009, and sentenced to 14 years in prison. He is currently serving his sentence at the Federal Correctional\nInstitution Englewood near Denver. In 2014, his lawyers attempted to appeal his conviction, arguing that a recent Supreme\nCourt ruling supported their view that Blagojevich was engaged in legal, run-of-the-mill political horse trading, not\ncorruption.\nTable 4: Case comparisons between GPT-3 zero-shot summaries before and after using SumCoT. Spans ofEntity,\nDate, Event and Result are separately highlighted in red, yellow, blue and green. Prompts are presented in italics.\nModel CNN/DaliyMail\nROUGE-1 ROUGE-2 ROUGE-L BERTSCORE\nPrevious SOTA in Table 3 37.98 18.16 34.34 0.8905\n175B GPT-3 37.75 15.20 34.25 0.8905\n175B GPT-3 w/ SumCoT 43.03 (↑ 5.05) 19.51 (↑ 1.35) 38.67 (↑ 4.33) 0.9023 (↑ 0.0118)\nModel BBC XSum\nROUGE-1 ROUGE-2 ROUGE-L BERTSCORE\nPrevious SOTA in Table 3 31.74 10.95 25.42 0.8933\n175B GPT-3 31.74 10.95 25.42 0.8933\n175B GPT-3 w/ SumCoT 35.70 (↑ 3.96) 15.31 (↑ 4.36) 30.19 (↑ 4.77) 0.9018 (↑ 0.0085)\nTable 5: Performance comparisons upon element-aware test sets of our method (GPT-3 with SumCoT), standard\nGPT-3, and previous state-of-the-art (SOTA) results in Table 3 over each metric. The↑ and corresponding numbers\non the right of each result of our method represent the increase after comparing with the previous SOTA.\nModel CNN/DailyMail BBC XSum\nFlu/Coh/Con/Rel Flu/Coh/Con/Rel\n175B GPT-3 -0.18/-0.33/-0.37/-0.72-0.19/-0.48/-0.33/-0.56\nw/ SumCoT -0.10/-0.05/-0.23/-0.28-0.11/-0.19/-0.07/-0.22\nTable 6: Human evaluation scores (Scale -3~3,\nand 0 represents the level of element-aware sum-\nmaries) for zero-shot summaries of GPT-3 w/o\nand w/ SumCoT. Flu/Coh/Con/Rel stands for Flu-\nency/Coherence/Consistency/Relevance respectively.\n4.2 Comprehensive Evaluation\nFirst, we visually compare the quality of sum-\nmaries generated by GPT-3 before and after us-\ning SumCoT. As shown in Table 4, it is clear that\nthe summary generated under SumCoT contains\nmore abundant fine-grained elements, saturating\nthe summary text with more key information.\nNext, we perform quantitative evaluations over\nthe same metrics as in §3.1. We mainly com-\npare our method (GPT-3 with SumCoT), standard\nGPT-3, and previous state-of-the-art (SOTA) re-\nsults in Table 3, and updated results are shown\nin Table 5. Compared with the standard GPT-3\nand previous SOTA, GPT-3 with SumCoT obtains\nsalient improvement in all metrics when compared\nwith the element-aware summaries, where ROUGE-\n1/2/L increases by +5.05/+1.35/+4.33 points on\nCNN/DailyMail and +3.96/+4.36/+4.77 points on\nBBC XSum, demonstrating that GPT-3 successfully\nfocuses on more core elements through SumCoT\nand further fits the element-aware writing pattern.\nFinally, we also conduct human studies to com-\npare summaries of GPT-3 w/o and w/ SumCoT.\nResults (as shown in Table 6) indicate that the Sum-\nCoT technique further improves the performance of\nthe standard zero-shot paradigm in all dimensions,\nparticularly coherence and relevance.\n4.3 Better Understanding SumCoT\nHow does SumCoT affect summary writing?\nFirst, we explore the extent to which SumCoT af-\nfects the final summary generation. We compute\nthe coverage, the fraction of extracted elements in\nStage 1 actually appearing in the final summary\ngenerated in Stage 2. Table 7 shows the results\n(see Appendix C.1 for examples), and we observe\n8646\n/uni00000013/uni00000011/uni00000016/uni00000025/uni00000014/uni00000011/uni00000016/uni00000025/uni00000019/uni00000011/uni0000001a/uni00000025/uni00000014/uni0000001a/uni00000018/uni00000025/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000015\n/uni00000013/uni00000011/uni00000017\n/uni00000013/uni00000011/uni00000019\n/uni00000013/uni00000011/uni0000001b\n/uni00000014/uni00000011/uni00000013/uni00000029/uni00000014/uni00000003/uni00000036/uni00000046/uni00000052/uni00000055/uni00000048\n/uni00000028/uni00000051/uni00000057/uni0000004c/uni00000057/uni0000005c\n/uni00000013/uni00000011/uni00000016/uni00000025/uni00000014/uni00000011/uni00000016/uni00000025/uni00000019/uni00000011/uni0000001a/uni00000025/uni00000014/uni0000001a/uni00000018/uni00000025/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000015\n/uni00000013/uni00000011/uni00000017\n/uni00000013/uni00000011/uni00000019\n/uni00000013/uni00000011/uni0000001b\n/uni00000014/uni00000011/uni00000013\n/uni00000027/uni00000044/uni00000057/uni00000048\n/uni00000026/uni00000031/uni00000031/uni00000012/uni00000027/uni00000044/uni0000004c/uni0000004f/uni0000005c/uni00000030/uni00000044/uni0000004c/uni0000004f/uni00000025/uni00000025/uni00000026/uni00000003/uni0000003b/uni00000036/uni00000058/uni00000050\n/uni00000013/uni00000011/uni00000016/uni00000025/uni00000014/uni00000011/uni00000016/uni00000025/uni00000019/uni00000011/uni0000001a/uni00000025/uni00000014/uni0000001a/uni00000018/uni00000025/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000015\n/uni00000013/uni00000011/uni00000017\n/uni00000013/uni00000011/uni00000019\n/uni00000013/uni00000011/uni0000001b\n/uni00000014/uni00000011/uni00000013\n/uni00000028/uni00000059/uni00000048/uni00000051/uni00000057\n/uni00000013/uni00000011/uni00000016/uni00000025/uni00000014/uni00000011/uni00000016/uni00000025/uni00000019/uni00000011/uni0000001a/uni00000025/uni00000014/uni0000001a/uni00000018/uni00000025/uni00000013/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000015\n/uni00000013/uni00000011/uni00000017\n/uni00000013/uni00000011/uni00000019\n/uni00000013/uni00000011/uni0000001b\n/uni00000014/uni00000011/uni00000013\n/uni00000035/uni00000048/uni00000056/uni00000058/uni0000004f/uni00000057\n/uni00000030/uni00000052/uni00000047/uni00000048/uni0000004f/uni00000003/uni00000036/uni0000004c/uni0000005d/uni00000048\nFigure 5: Performance of element extraction for all four core elements with various GPT-3 versions. See Appendix\nC.3 for more model details.\nCNN/DailyMail BBC XSum\nEntity Date Event Result Entity Date Event Result\n0.89 0.55 0.93 0.95 0.80 0.48 0.87 0.66\nTable 7: Coverage, the fraction of extracted elements\nactually appearing in the final summary on two datasets.\nCore\nElement\nCNN/DaliyMail BBC XSum\nP R F1 P R F1\nEntity 0.77 0.89 0.83 0.71 0.98 0.82\nDate 0.46 0.68 0.55 0.43 0.79 0.56\nEvent 0.84 0.82 0.83 0.75 0.90 0.82\nResult 0.74 0.79 0.76 0.66 0.71 0.68\nTable 8: The Precision (P), Recall (R), and F1 for ex-\ntraction of each element.\nthat final summaries are extremely faithful to the\nextracted elements, particularly onCNN/DailyMail.\nOn BBC XSum, the coverages of each element are\nrelatively lower due to the one-sentence style of\nBBC XSum, resulting in further condensation of the\nextracted elements. In addition, the coverage of\nDate is significantly low, probably due to the errors\nof extraction. This will be verified in the next part.\nIs the element extraction accurate and compre-\nhensive? Table 7 demonstrates a strong corre-\nlation between element extraction and summary\ngeneration, so we need to examine the quality of\nelement extraction.8 We compute the Precision,\nRecall and F1 introduced in §2.4. Results (Table\n8) show that extraction achieves an outperforming\nresult except for Date, and Precision are usually\nlower than Recall. See Appendix C.2 for error\ncases, where we conclude: (i) Date hallucination\nis particularly evident for extracting non-existent\ndates; (ii) Element redundancy often occurs.\n8It is noted that if there are no obvious markers (e.g. \"The\nentities are ...\"), the extraction is not considered valid.\nDoes the model size limit SumCoT? We com-\npare the performance of GPT-3 with different ver-\nsions of element extraction. We compute the F1\nscore (shown in Figure 5) for all the elements. We\nfind that when the model size is small, element\nextraction is almost invalid. As the model size in-\ncreases, GPT-3 can extract one by one for all types\nof elements, but the extraction itself has many er-\nrors or redundancies. Only when the model size\nis the largest, the element extraction is human-\napproved (See Appendix C.3 for examples). This\nindicates that the SumCoT technique is also an\nemergent ability of model scale (Wei et al., 2022a),\nand is effective only when the model size is larger.\n5 Related Work and Discussion\n5.1 Summarization: Dataset and Evaluation\nIn the data-driven deep learning era, large-scale\ncorpus crawled from websites for summarization\nis rich, especially the news domain. They can be\ndivided into the single-document setting (Harman\nand Over, 2004; Sandhaus, 2008; Napoles et al.,\n2012; Nallapati et al., 2016; Narayan et al., 2018;\nKoupaee and Wang, 2018; Grusky et al., 2018) and\nthe multi-document setting (Owczarzak and Dang,\n2011; Li et al., 2017; Fabbri et al., 2019) according\nto the source numbers of document clusters. How-\never, some studies pointed out various noises within\nthem, such as poor coherence, information redun-\ndancy, and factual hallucination (Kryscinski et al.,\n2019; Maynez et al., 2020; Fabbri et al., 2021).\nSeveral other studies also corroborated this with\nhuman assessments (Stiennon et al., 2020; Fabbri\net al., 2021).\nSummarization systems are first purely trained\n(Vinyals et al., 2015; Vaswani et al., 2017; Liu et al.,\n2022b; Chen et al., 2022) or fine-tuned (Zhang\net al., 2019; Liu, 2019; Zhang et al., 2020a; Raffel\n8647\net al., 2020; Wang et al., 2022b; Mao et al., 2022)\nwith standard datasets, and then evaluated. The\nmost mainstream automatic evaluation metrics for\nsummarization are reference-based methods, i.e.,\ndirectly comparing the similarity of generated and\ndataset-specific summaries. They can be split into\nlexical overlap methods (Papineni et al., 2002; Lin,\n2004; Banerjee and Lavie, 2005) and semantic simi-\nlarity methods (Ng and Abrecht, 2015; Zhang et al.,\n2020b; Zhao et al., 2019; Sellam et al., 2020; Rei\net al., 2020). Such evaluation is essentially a test of\nthe fit degree to standard datasets. In recent years,\nthe advanced zero-shot paradigm of LLMs makes\ntext generation free of standard datasets (Brown\net al., 2020; Chowdhery et al., 2022; Thoppilan\net al., 2022) but rely on massive pre-trained data,\nmany researchers tend to revisit the quality assess-\nment of summaries generated by LLMs (Liu et al.,\n2022a; Zhang et al., 2023a). However, some stud-\nies demonstrate that automatic evaluation results do\nnot align with human preference in summarization\ntasks (Goyal et al., 2022), similar counter-intuitive\nobservations may pose new challenges for the eval-\nuation in the era of LLMs.\n5.2 Chain-of-Thought Prompting for LLMs\nRecently, intriguing chain-of-thought techniques\nhave greatly improved both the reasoning perfor-\nmance and interpretability of LLMs by decompos-\ning multi-step problems into intermediate steps\n(Nye et al., 2022; Wei et al., 2022b; Kojima et al.,\n2022; Zhang et al., 2022; Wang et al., 2022a; Zhang\net al., 2023b; Shi et al., 2022; Zhou et al., 2022).\nHowever, no prior work has studied CoT in the\nscenario of automatic summarization. To the best\nof our knowledge, we are the first to study chain-\nof-thought prompting for summarization, eliciting\nLLMs to leverage more fine-grained elements from\nsource documents to generate effective summaries.\n6 Conclusion\nIn this work, we construct expert-writing element-\naware summary test sets for CNN/DailyMail and\nBBC XSum, they are specifically designed to as-\nsess the generic summarization capabilities of di-\nverse, powerful language models more thoroughly.\nUpon the fine-grained test sets, we preliminarily\nconduct experiments on zero-shot LLMs and fine-\ntuned PLMs, demonstrating the surprising zero-\nshot summary writing ability of LLMs. Further, we\npropose a CoT-based method, which elicits LLMs\nto focus on core news elements and generate sum-\nmaries step by step. In the future, we hope that our\nwork will inspire further research into harnessing\nLLMs’ potential to mimic human writing processes\nacross various open-ended generative tasks.\nLimitations\nIn terms of the test sets, due to time, labor, and\nfinancial limitations, we are unable to construct\nlarge-scale test sets of the same size as the origi-\nnal, so the domain balance in the test sets is not\nfully considered, but the uniformity of writing style\nmight have slightly alleviated this issue. In terms\nof the method, we empirically explore the possi-\nbility of chain-of-thought application in text gen-\neration. However, due to the stronger openness of\ngenerative tasks compared to pure reasoning tasks,\ngenerated summaries might be more sensitive to\nthe form of chain-of-thought, which is a key point\nworth further optimization.\nEthics Statement\nWe use publicly available source documents from\nexisting general datasets for annotations, so the\nethics issues of the source texts are non-existent.\nFor the generated contents with LLMs, e.g. GPT-\n3, prior work (Brown et al., 2020; Chan, 2022)\nhas elaborated on their inevitable potential toxic-\nity, such as issues of bias and fairness. Moreover,\nthis is the first work to apply the chain-of-thought\ntechnique to open-end generation tasks, so we com-\npletely keep the prompts neutral and task-specific\nto avoid toxic language generation, and there were\nno toxic texts that appeared in our experiments.\nAcknowledgements\nYiming and Rui are with MT-Lab, Department\nof Computer Science and Engineering, School of\nElectronic Information and Electrical Engineering,\nand also with the MoE Key Lab of Artificial In-\ntelligence, AI Institute, Shanghai Jiao Tong Uni-\nversity, Shanghai 200204, China. Rui is supported\nby the General Program of National Natural Sci-\nence Foundation of China (6217020129), Shang-\nhai Pujiang Program (21PJ1406800), Shanghai\nMunicipal Science and Technology Major Project\n(2021SHZDZX0102), Beijing Academy of Artifi-\ncial Intelligence (BAAI) (No. 4), CCF-Baidu Open\nFund (F2022018), and the Alibaba-AIR Program\n(22088682). We also thank the computational re-\nsource from the SJTU student innovation center.\n8648\nReferences\nSatanjeev Banerjee and Alon Lavie. 2005. METEOR:\nAn automatic metric for MT evaluation with im-\nproved correlation with human judgments. In Pro-\nceedings of the ACL Workshop on Intrinsic and Ex-\ntrinsic Evaluation Measures for Machine Transla-\ntion and/or Summarization, pages 65–72, Ann Arbor,\nMichigan. Association for Computational Linguis-\ntics.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems 33:\nAnnual Conference on Neural Information Process-\ning Systems 2020, NeurIPS 2020, December 6-12,\n2020, virtual.\nAnastasia Chan. 2022. Gpt-3 and instructgpt: techno-\nlogical dystopianism, utopianism, and “contextual”\nperspectives in ai ethics and industry. AI and Ethics,\npages 1–12.\nYulong Chen, Yang Liu, Ruochen Xu, Ziyi Yang, Chen-\nguang Zhu, Michael Zeng, and Yue Zhang. 2022.\nUnisumm: Unified few-shot summarization with\nmulti-task pre-training and prefix-tuning. ArXiv\npreprint, abs/2211.09783.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, et al. 2022. Palm: Scaling\nlanguage modeling with pathways. ArXiv preprint,\nabs/2204.02311.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nAlexander Fabbri, Irene Li, Tianwei She, Suyi Li, and\nDragomir Radev. 2019. Multi-news: A large-scale\nmulti-document summarization dataset and abstrac-\ntive hierarchical model. In Proceedings of the 57th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 1074–1084, Florence, Italy. Asso-\nciation for Computational Linguistics.\nAlexander R. Fabbri, Wojciech Kry´sci´nski, Bryan Mc-\nCann, Caiming Xiong, Richard Socher, and Dragomir\nRadev. 2021. SummEval: Re-evaluating summariza-\ntion evaluation. Transactions of the Association for\nComputational Linguistics, 9:391–409.\nSebastian Gehrmann, Yuntian Deng, and Alexander\nRush. 2018. Bottom-up abstractive summarization.\nIn Proceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n4098–4109, Brussels, Belgium. Association for Com-\nputational Linguistics.\nTanya Goyal, Junyi Jessy Li, and Greg Durrett. 2022.\nNews summarization and evaluation in the era of\ngpt-3. ArXiv preprint, abs/2209.12356.\nMax Grusky, Mor Naaman, and Yoav Artzi. 2018.\nNewsroom: A dataset of 1.3 million summaries with\ndiverse extractive strategies. In Proceedings of the\n2018 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, Volume 1 (Long Pa-\npers), pages 708–719, New Orleans, Louisiana. As-\nsociation for Computational Linguistics.\nDonna Harman and Paul Over. 2004. The effects of\nhuman variation in DUC summarization evaluation.\nIn Text Summarization Branches Out, pages 10–17,\nBarcelona, Spain. Association for Computational Lin-\nguistics.\nJunxian He, Wojciech Kry ´sci´nski, Bryan McCann,\nNazneen Rajani, and Caiming Xiong. 2020. Ctrl-\nsum: Towards generic controllable text summariza-\ntion. ArXiv preprint, abs/2012.04281.\nKarl Moritz Hermann, Tomás Kociský, Edward Grefen-\nstette, Lasse Espeholt, Will Kay, Mustafa Suleyman,\nand Phil Blunsom. 2015. Teaching machines to read\nand comprehend. In Advances in Neural Information\nProcessing Systems 28: Annual Conference on Neu-\nral Information Processing Systems 2015, December\n7-12, 2015, Montreal, Quebec, Canada, pages 1693–\n1701.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large\nlanguage models are zero-shot reasoners. ArXiv\npreprint, abs/2205.11916.\nMahnaz Koupaee and William Yang Wang. 2018. Wiki-\nhow: A large scale text summarization dataset. ArXiv\npreprint, abs/1810.09305.\nWojciech Kryscinski, Nitish Shirish Keskar, Bryan Mc-\nCann, Caiming Xiong, and Richard Socher. 2019.\nNeural text summarization: A critical evaluation. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), pages 540–551, Hong\nKong, China. Association for Computational Linguis-\ntics.\nHarold D Lasswell. 1948. The structure and function\nof communication in society. The communication of\nideas, 37(1):136–139.\n8649\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020.\nBART: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and com-\nprehension. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 7871–7880, Online. Association for Computa-\ntional Linguistics.\nPiji Li, Lidong Bing, and Wai Lam. 2017. Reader-aware\nmulti-document summarization: An enhanced model\nand the first dataset. In Proceedings of the Workshop\non New Frontiers in Summarization, pages 91–99,\nCopenhagen, Denmark. Association for Computa-\ntional Linguistics.\nRensis Likert. 1932. A technique for the measurement\nof attitudes. Archives of psychology.\nChin-Yew Lin. 2004. ROUGE: A package for auto-\nmatic evaluation of summaries. In Text Summariza-\ntion Branches Out, pages 74–81, Barcelona, Spain.\nAssociation for Computational Linguistics.\nYang Liu. 2019. Fine-tune bert for extractive summa-\nrization. ArXiv preprint, abs/1903.10318.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. ArXiv preprint, abs/1907.11692.\nYixin Liu, Alexander R Fabbri, Pengfei Liu, Yilun Zhao,\nLinyong Nan, Ruilin Han, Simeng Han, Shafiq Joty,\nChien-Sheng Wu, Caiming Xiong, et al. 2022a. Re-\nvisiting the gold standard: Grounding summarization\nevaluation with robust human evaluation. arXiv e-\nprints, pages arXiv–2212.\nYixin Liu, Pengfei Liu, Dragomir Radev, and Graham\nNeubig. 2022b. BRIO: Bringing order to abstractive\nsummarization. In Proceedings of the 60th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 2890–2903,\nDublin, Ireland. Association for Computational Lin-\nguistics.\nQianren Mao, Jianxin Li, JiaZheng Wang, Xi Li, Peng\nHao, Lihong Wang, and Zheng Wang. 2022. Explic-\nitly modeling importance and coherence for timeline\nsummarization. In ICASSP 2022-2022 IEEE Interna-\ntional Conference on Acoustics, Speech and Signal\nProcessing (ICASSP), pages 8062–8066. IEEE.\nJoshua Maynez, Shashi Narayan, Bernd Bohnet, and\nRyan McDonald. 2020. On faithfulness and factu-\nality in abstractive summarization. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics, pages 1906–1919, On-\nline. Association for Computational Linguistics.\nRamesh Nallapati, Bowen Zhou, Cicero dos Santos,\nÇa˘glar Gulçehre, and Bing Xiang. 2016. Abstrac-\ntive text summarization using sequence-to-sequence\nRNNs and beyond. In Proceedings of the 20th\nSIGNLL Conference on Computational Natural Lan-\nguage Learning, pages 280–290, Berlin, Germany.\nAssociation for Computational Linguistics.\nCourtney Napoles, Matthew Gormley, and Benjamin\nVan Durme. 2012. Annotated Gigaword. In Proceed-\nings of the Joint Workshop on Automatic Knowledge\nBase Construction and Web-scale Knowledge Ex-\ntraction (AKBC-WEKEX), pages 95–100, Montréal,\nCanada. Association for Computational Linguistics.\nShashi Narayan, Shay B. Cohen, and Mirella Lapata.\n2018. Don’t give me the details, just the summary!\ntopic-aware convolutional neural networks for ex-\ntreme summarization. In Proceedings of the 2018\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 1797–1807, Brussels, Bel-\ngium. Association for Computational Linguistics.\nShashi Narayan, Gonçalo Simões, Yao Zhao, Joshua\nMaynez, Dipanjan Das, Michael Collins, and Mirella\nLapata. 2022. A well-composed text is half done!\ncomposition sampling for diverse conditional genera-\ntion. In Proceedings of the 60th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers), pages 1319–1339, Dublin,\nIreland. Association for Computational Linguistics.\nShashi Narayan, Yao Zhao, Joshua Maynez, Gonçalo\nSimões, Vitaly Nikolaev, and Ryan McDonald. 2021.\nPlanning with learned entity prompts for abstractive\nsummarization. Transactions of the Association for\nComputational Linguistics, 9:1475–1492.\nJun-Ping Ng and Viktoria Abrecht. 2015. Better sum-\nmarization evaluation with word embeddings for\nROUGE. In Proceedings of the 2015 Conference\non Empirical Methods in Natural Language Process-\ning, pages 1925–1930, Lisbon, Portugal. Association\nfor Computational Linguistics.\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari,\nHenryk Michalewski, Jacob Austin, David Bieber,\nDavid Dohan, Aitor Lewkowycz, Maarten Bosma,\nDavid Luan, et al. 2022. Show your work: Scratch-\npads for intermediate computation with language\nmodels. In Deep Learning for Code Workshop.\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-\nroll L Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022. Training language models to follow in-\nstructions with human feedback. ArXiv preprint,\nabs/2203.02155.\nKarolina Owczarzak and Hoa Trang Dang. 2011.\nOverview of the tac 2011 summarization track:\nGuided task and aesop task. In Proceedings of the\nText Analysis Conference (TAC 2011), Gaithersburg,\nMaryland, USA, November.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic evalu-\nation of machine translation. In Proceedings of the\n8650\n40th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 311–318, Philadelphia,\nPennsylvania, USA. Association for Computational\nLinguistics.\nHorst Pö ttker. 2003. News and its communicative\nquality: the inverted pyramid—when and why did it\nappear? Journalism Studies, 4(4):501–511.\nColin Raffel, Noam Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020. Exploring the\nlimits of transfer learning with a unified text-to-text\ntransformer. Journal of Machine Learning Research,\n21(140):1–67.\nRicardo Rei, Craig Stewart, Ana C Farinha, and Alon\nLavie. 2020. COMET: A neural framework for MT\nevaluation. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Process-\ning (EMNLP), pages 2685–2702, Online. Association\nfor Computational Linguistics.\nEvan Sandhaus. 2008. The new york times annotated\ncorpus. In Philadelphia: Linguistic Data Consor-\ntium, 2008.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Teven Scao, Arun Raja,\net al. 2022. Multitask prompted training enables\nzero-shot task generalization. In International Con-\nference on Learning Representations.\nThibault Sellam, Dipanjan Das, and Ankur Parikh. 2020.\nBLEURT: Learning robust metrics for text genera-\ntion. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pages\n7881–7892, Online. Association for Computational\nLinguistics.\nFreda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang,\nSuraj Srivats, Soroush V osoughi, Hyung Won Chung,\nYi Tay, Sebastian Ruder, Denny Zhou, et al. 2022.\nLanguage models are multilingual chain-of-thought\nreasoners. ArXiv preprint, abs/2210.03057.\nNisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel M.\nZiegler, Ryan Lowe, Chelsea V oss, Alec Radford,\nDario Amodei, and Paul F. Christiano. 2020. Learn-\ning to summarize with human feedback. In Advances\nin Neural Information Processing Systems 33: An-\nnual Conference on Neural Information Processing\nSystems 2020, NeurIPS 2020, December 6-12, 2020,\nvirtual.\nIlya Sutskever, Oriol Vinyals, and Quoc V . Le. 2014.\nSequence to sequence learning with neural networks.\nIn Advances in Neural Information Processing Sys-\ntems 27: Annual Conference on Neural Information\nProcessing Systems 2014, December 8-13 2014, Mon-\ntreal, Quebec, Canada, pages 3104–3112.\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam\nShazeer, Apoorv Kulshreshtha, Heng-Tze Cheng,\nAlicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al.\n2022. Lamda: Language models for dialog applica-\ntions. ArXiv preprint, abs/2201.08239.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems 30: Annual Conference on Neural\nInformation Processing Systems 2017, December 4-9,\n2017, Long Beach, CA, USA, pages 5998–6008.\nOriol Vinyals, Meire Fortunato, and Navdeep Jaitly.\n2015. Pointer networks. In Advances in Neural\nInformation Processing Systems 28: Annual Confer-\nence on Neural Information Processing Systems 2015,\nDecember 7-12, 2015, Montreal, Quebec, Canada,\npages 2692–2700.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,\nEd Chi, and Denny Zhou. 2022a. Self-consistency\nimproves chain of thought reasoning in language\nmodels. ArXiv preprint, abs/2203.11171.\nYiming Wang, Qianren Mao, Junnan Liu, Weifeng\nJiang, Hongdong Zhu, and Jianxin Li. 2022b. Noise-\ninjected consistency training and entropy-constrained\npseudo labeling for semi-supervised extractive sum-\nmarization. In Proceedings of the 29th International\nConference on Computational Linguistics, pages\n6447–6456, Gyeongju, Republic of Korea. Interna-\ntional Committee on Computational Linguistics.\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,\nBarret Zoph, Sebastian Borgeaud, Dani Yogatama,\nMaarten Bosma, Denny Zhou, Donald Metzler, et al.\n2022a. Emergent abilities of large language models.\nArXiv preprint, abs/2206.07682.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed Chi, Quoc Le, and Denny Zhou. 2022b.\nChain of thought prompting elicits reasoning in large\nlanguage models. ArXiv preprint, abs/2201.11903.\nJingqing Zhang, Yao Zhao, Mohammad Saleh, and Pe-\nter J. Liu. 2020a. PEGASUS: pre-training with ex-\ntracted gap-sentences for abstractive summarization.\nIn Proceedings of the 37th International Conference\non Machine Learning, ICML 2020, 13-18 July 2020,\nVirtual Event, volume 119 ofProceedings of Machine\nLearning Research, pages 11328–11339. PMLR.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020b. Bertscore: Eval-\nuating text generation with BERT. In 8th Inter-\nnational Conference on Learning Representations,\nICLR 2020, Addis Ababa, Ethiopia, April 26-30,\n2020. OpenReview.net.\nTianyi Zhang, Faisal Ladhak, Esin Durmus, Percy\nLiang, Kathleen McKeown, and Tatsunori B\nHashimoto. 2023a. Benchmarking large language\nmodels for news summarization. ArXiv preprint,\nabs/2301.13848.\n8651\nXingxing Zhang, Furu Wei, and Ming Zhou. 2019. HI-\nBERT: Document level pre-training of hierarchical\nbidirectional transformers for document summariza-\ntion. In Proceedings of the 57th Annual Meeting of\nthe Association for Computational Linguistics, pages\n5059–5069, Florence, Italy. Association for Compu-\ntational Linguistics.\nZhuosheng Zhang, Aston Zhang, Mu Li, and Alex\nSmola. 2022. Automatic chain of thought prompt-\ning in large language models. ArXiv preprint,\nabs/2210.03493.\nZhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao,\nGeorge Karypis, and Alex Smola. 2023b. Multi-\nmodal chain-of-thought reasoning in language mod-\nels. ArXiv preprint, abs/2302.00923.\nWei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, Chris-\ntian M. Meyer, and Steffen Eger. 2019. MoverScore:\nText generation evaluating with contextualized em-\nbeddings and earth mover distance. In Proceedings\nof the 2019 Conference on Empirical Methods in\nNatural Language Processing and the 9th Interna-\ntional Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), pages 563–578, Hong\nKong, China. Association for Computational Lin-\nguistics.\nDenny Zhou, Nathanael Schärli, Le Hou, Jason Wei,\nNathan Scales, Xuezhi Wang, Dale Schuurmans,\nOlivier Bousquet, Quoc Le, and Ed Chi. 2022.\nLeast-to-most prompting enables complex reason-\ning in large language models. ArXiv preprint,\nabs/2205.10625.\nA Details of Experimental Setup\nA.1 Main Experiment\nTable 9 report the sources and licenses of artifacts\nand packages we used in this paper.\nA.2 Human Study\nWe randomly select 50 samples for each dataset\nand ask three annotators for these tasks following\nthe setting of most human studies. However, con-\nsidering the unprofessionalism of crowd-sourcing\nevaluations (Usually hiring workers from Amazon\nMechanical Turk platform with a set hourly salary.\nActually, many workers will not work as you ex-\npected, their levels vary widely and uncontrollably.\nHe et al. (2020) have encountered such a situation),\nwe privately contact three reliable annotators to\nconduct the human studies. The first is a Ph.D.\ncandidate in Computer Science, the second is a\nMaster in Film Study, and the last is a graduate\nin Journalism and Communication. Our human\nstudies are conducted in full compliance with the\nwillingness of the invitees and are fully open about\nthe use of the data they annotated. They have been\npaid slightly more than the crowd-sourced hourly\nrate for their work. We use the same configuration\nfor all human studies in this paper, thanks for their\nparticipation!\nB Abstraction and Faithfulness analysis\nfor Summaries\nAbstraction and Faithfulness are normally two op-\nposing properties. For dataset-specific summaries,\ndespite their novel n-grams being higher than\nelement-aware summaries in many cases, they sac-\nrifice factual correctness to some extent, which is a\nfake high-abstraction. Case comparisons are shown\nin Table 10-11.\nC Better Understanding Summary\nChain-of-Thought: Case Study\nC.1 Learn How SumCoT Works\nTable 12-14 presents some cases to visually show\nhow SumCoT affects the final generated summary.\nWe compare GPT-3 zero-shot summaries before\nand after using SumCoT. Core elements have been\nhighlighted in the table. It is clear that sum-\nmaries using SumCoT Cover a large number of\nfine-grained elements extracted by GPT-3 in Stage\n1 that are not in the standard zero-shot summaries.\n8652\nModel URL License\nBART(Lewis et al., 2020)\nhttps://huggingface.co/ainize/bart-base-cnn\nMIT licensehttps://huggingface.co/morenolq/bart-base-xsum\nhttps://huggingface.co/facebook/bart-large-cnn\nhttps://huggingface.co/facebook/bart-large-xsum\nPEGASUS(Zhang et al., 2020a) https://huggingface.co/google/pegasus-cnn_dailymailApache-2.0 licensehttps://huggingface.co/google/pegasus-xsum\nGPT-3 (Zhang et al., 2020a) https://openai.com/api/ N/A\nEvaluation Metric URL License\nROUGE(Lin, 2004) https://github.com/pltrdy/rouge Apache-2.0 license\nBERTSCORE (Zhang et al., 2020b) https://github.com/Tiiiger/bert_score MIT license\nTable 9: The sources and licenses of artifacts and packages we used in this paper (Appendix A.1).\nC.2 Error Analysis for Element Extractions\nTo validate the correctness of element extraction\nof LLMs, we conduct a large number of sampling\nobservations, and summarize the two main issues:\n• Date Hallucination. This issue is mainly caused\nby two aspects: (1) Date elements are not pre-\nsented in many cases, so this requires LLMs to\nquestion date existence rather than provide false\ndates, but LLMs are hardly aware of this situa-\ntion. (2) In more difficult cases, date extraction\ninvolves reasoning (e.g. \" In 2014... Two years\nago...\" →\"In 2012\"), which poses a greater chal-\nlenge for extraction, and causes the sometimes\nfailure of LLMs. Cases are presented in Table\n15-17, these all explain why the F1 score of Date\nis lower than that of the other elements (Table 8).\n• Element Redundancy. LLMs frequently extract\nelements that are faithful to the source document\nbut not important. Cases are presented in Table\n18-19. This explains why the Precision score\nis lower than the Recall score in almost every\nelement (Table 8).\nC.3 Ablation Study of GPT-3 Model Size\nWe try diverse versions of GPT-3 with different\nmodel sizes. Model configurations are as follows:\n• 0.3B-parameter text-ada-001\n• 1.3B-parameter text-babbage-001\n• 6.7B-parameter text-curie-001\n• 175B-parameter text-davinci-002\nThe curve of F1 score of different versions has\nbeen shown in Figure 5, and the case study is pre-\nsented in Table 20.\nD Random Sample Presentation\nWe randomly sample some examples, each con-\ntaining: source document, golden summary, expert-\nwriting summary, GPT-3 zero-shot summary, and\nGPT-3 reasoning-like zero-shot summary. Exam-\nples are shown in Table 21-24.\n8653\nSource Document (CNN/DailyMail)\n(The Hollywood Reporter) Add another fan-favorite character to the cast of next year’s \"X-Men: Apocalypse\" with director\nBryan Singer announcing via Instagram that Olivia Munn will play the telepathic Psylocke in the follow-up to \"X-Men:\nDays of Future Past.\" Singer revealed that the \"Newsroom\" actress would play Betsy Braddock in the movie (presumably\nbefore the confusing and complicated plot twist that saw Psylocke change from a Caucasian former supermodel to a\nJapanese ninja for no immediately obvious reason). Äpocalypseïs currently in production for a summer 2016 release.\nMore: \"X-Men: Apocalypse\" casts fan favorite Jubilee. The comic book’s Psylocke was created by Chris Claremont and\nHerb Trimpe for the British \"Captain Britain\" series, where she appeared throughout the 1970s and ’80s, before joining the\nX-Men in 1987’s \"Uncanny X-Men\" No. 213. Since that time, she has been a mainstay both of the main team and spin-off\nseries including \"Exiles\" and \"X-Force.\" More: What newcomers need to know about Marvel’s \"Secret Wars\". Munn will\njoin a cast that includes James McAvoy, Michael Fassbender and Jennifer Lawrence in the movie, which hits theaters May\n27, 2016. Munn is repped by Creative Artists Agency and Atlas Artists. More: Does the big plot twist in \"Terminator\nGenisys\" blow up the franchise? @The Hollywood Reporter. All rights reserved.\"\nDataset-specific Summary Element-aware Summary\nOlivia Munn will play Psylocke in \"x-men: apocalypse\"\nfilm. Psylocke trended for hours on twitter after director\nBryan Singer announced casting.\nOlivia Munn will play the telepathic Psylocke -created\nby Chris Claremont and Herb Trimpe for the ¨Captain\nBritain¨series - in the ¨X-Men: Apocalypse¨. The movie will\nbe released in May 27, 2016.\n% of novel uni/bi/trigram: 47.61/70.00/84.21 % of novel uni/bi/trigram: 17.65/48.51/62.50\nTable 10: Comparisons between element-aware summaries and dataset-specific summaries in abstraction and\nfaithfulness. Hallucinatory facts are highlighted in orange. We observe that dataset-specific summaries contain\nmore hallucinatory facts despite a higher percentage of novel n-grams (Appendix B).\nSource Document (BBC XSum)\nMore than 350 roma people had lived in the camp on la petite ceinture since mid-2015. Activists said many left early\nahead of the police action. The site belongs to the national rail authority sncf. France has one of europe’s toughest\npolicies towards roma. Most live in camps that are regularly demolished and every year thousands are deported. Amnesty\ninternational urged city authorities to find a lasting housing solution for those evicted in paris - saying they would become\nhomeless in mid-winter. Hundreds of thousands of roma - mostly from romania and bulgaria - have moved to western\neurope since the 1990s. The council of europe, the region ’s main human rights body, warned that evictions were \"\ncounter-productive\" because they disrupted education and healthcare for roma children. Council of europe secretary\ngeneral thorbjorn jagland said it was crucial for french authorities to provide \"adequate alternative accommodation\" for\nthose evicted, particularly as they have decided to take this action during winter.\nDataset-specific Summary Element-aware Summary\nPolice have cleared hundreds of roma people from a slum-\nlike camp built on a disused rail line in north paris.\nEvery year thousands of Roma people are deported by\nFrance, and the region’s main human rights body urges\nFrance to provide alternative accommodation for those\nevicted.\n% of novel uni/bi/trigram: 28.57/85.00/100.00 % of novel uni/bi/trigram: 25.93/53.85/80.00\nTable 11: Comparisons between element-aware summaries and dataset-specific summaries in abstraction and\nfaithfulness. Hallucinatory facts are highlighted in orange. We observe that dataset-specific summaries contain\nmore hallucinatory facts despite a higher percentage of novel n-grams (Appendix B).\n8654\nSource Document (CNN/DailyMail)\nOnce famed for his mop of blacker than black hair, disgraced Democrat Rod Blagojevich, 58, has really let his haircare\nregime go while he serves his prison time. The former Illinois governor has return to his roots while inside and has\nbeen photographed with his still full head of hair a shocking white color rather than the boot polish black that was his\ntrademark as a politician. Blagojevich was infamously caught trying to sell Barack Obama’s U.S. Senate seat when he\nwas elected president in 2008. Fade to gray: Once famed for his mop of blacker than black hair, disgraced Democrat Rod\nBlagojevich, 58, has really let his haircare regime go while he serves his prison time. Back in his days as governor of\nIllinois, Blagojevich was famed for his boot polish black hair. He was impeached and removed from office by the state\nLegislature in early 2009 following his arrest on federal corruption charges. Blagojevich is currently serving a 14-year\nsentence at the Federal Correctional Institution Englewood near Denver. The photos, the first of Blagojevich in prison, were\nfirst published by the National Enquirer. The photos show the former governor sitting at a desk, reading a book and wearing\nglasses and sitting outside in shorts and a wife beater shirt. While he continues to awaiting word on a last-ditch appeal,\nBlagojevich has daily contact with his family and teaches the history of war battles to other inmates, his attorney said. Last\nJuly lawyers attempted to argue that a high court ruling in McCutcheon v. the Federal Election Commission in April 2014\nbolstered their view that Blagojevich was engaged in legal, run-of-the-mill political horse trading, not corruption. The\nMcCutcheon ruling, they argued, found that soliciting contributions crosses the line into corruption only when a politician\nmakes a clear, explicit promise to take official action in return for a donation. Blagojevich is currently serving a 14-year\nsentence at the Federal Correctional Institution Englewood near Denver after he was caught trying to sell Barack Obama’s\nU.S. Senate seat when he was elected president. In that context, defense attorneys said the trial judge was wrong to set a\nlower standard for jurors by telling them, to convict, they only needed to find that Blagojevich sought donations ’knowing\nor believing’ it would be given for some official act. But government attorneys responded saying that Blagojevich’s legal\nteam hadn’t correctly characterized the Supreme Court’s findings in McCutcheon. ’The decision provides no support for\nBlagojevich’s argument on appeal,’ the two-page filing said. ’Nothing in the (McCutcheon) decision suggests that an\nexchange of contributions for specific official acts is quid pro quo corruption only if the arrangement is stated ’explicitly’\nor ’expressly.’ The Chicago-based appellate court has been considering Blagojevich’s appeal for more than a year months.\nIt’s unclear when it might issue a decision.\nGPT-3 Zero-shot Summary (Standard)\nSummarize the above article:\nThe article discusses how Rod Blagojevich, a former Illinois governor, has let his hair go while serving his prison sentence.\nThe photos show the former governor with white hair, rather than the black hair that was his trademark as a politician.\nBlagojevich is currently serving a 14-year sentence at the Federal Correctional Institution Englewood near Denver.\nSummary Chain-of-Thought (Stage 1, Element Extraction)\nWhat are the important entities in this document? What are the important dates in this document? What events are\nhappening in this document? What is the result of these events?\nPlease answer the above questions:\n1. The important entities in this document are Rod Blagojevich, the Federal Correctional Institution Englewood, and the\nNational Enquirer.\n2. The important dates in this document are 2008, 2009, and 2014.\n3. The events in this document are Blagojevich’s arrest and imprisonment, and his appeal of his conviction.\n4. The result of these events is that Blagojevich is currently serving a 14-year sentence in prison.\nGPT-3 Zero-shot-cot Summary (Stage 2, Summary Generation)\nLet’s integrate the above information and summarize the article:\nIn 2008, Rod Blagojevich was arrested for trying to sell Barack Obama’s U.S. Senate seat. He was impeached and removed\nfrom office in 2009, and sentenced to 14 years in prison. He is currently serving his sentence at the Federal Correctional\nInstitution Englewood near Denver. In 2014, his lawyers attempted to appeal his conviction, arguing that a recent Supreme\nCourt ruling supported their view that Blagojevich was engaged in legal, run-of-the-mill political horse trading, not\ncorruption.\nTable 12: More comparisons between GPT-3 zero-shot summaries before and after using SumCoT. Spans ofEntity,\nDate, Event, and Result are separately highlighted in red, yellow, blue and green. Prompts are presented in italics\n(Appendix C.1).\n8655\nSource Document (BBC XSum)\nThe 69-year-old’s yamaha collided with a Nissan car between handley’s corner and barre garroo crossroads at about 17:00\nbst on 4 June. Mr. Baker, who was from the island, was airlifted to noble’s hospital, where he later died. Insp dave dobbie\nsaid \"thoughts and condolences are with Mr. baker’s family\". He added that investigations are ongoing in relation to\nthe crash. The car driver, who police say was northern irish, was treated in hospital but has been discharged. Another\nmotorcyclist who was injured after the crash has also been released from hospital. The collision happened outside of the\nTT racing, which is taking place on the island.\nGPT-3 Zero-shot Summary (Standard)\nSummarize the above article in one sentence:\nThe article discusses a fatal motorcycle collision that occurred on the Isle of Man, and the investigation that is ongoing.\nSummary Chain-of-Thought (Stage 1, Element Extraction)\nWhat are important entities in this document? What are important dates in this document? What events are happening in\nthis document? What is the result of these events?\nPlease answer the above questions:\n1. The important entities in this document are Mr. Baker, the car driver, and the motorcyclist who was injured.\n2. The important dates in this document are 4 June and the present day.\n3. The events happening in this document are a collision between Mr. Baker’s motorcycle and a car, and the investigation\ninto the collision.\n4. The result of these events is that Mr. Baker died and the car driver and motorcyclist were injured.\nGPT-3 Zero-shot-cot Summary (Stage 2, Summary Generation)\nLet’s integrate the above information and summarize the article in one sentence:\nOn 4 June, Mr. Baker’s motorcycle collided with a car, resulting in his death. The car driver and motorcyclist were injured.\nTable 13: More comparisons between GPT-3 zero-shot summaries before and after using SumCoT. Spans ofEntity,\nDate, Event, and Result are separately highlighted in red, yellow, blue and green. Prompts are presented in italics\n(Appendix C.1).\nSource Document (BBC XSum)\nWest midlands police said the man had been detained in reading and the woman in wokingham by counter-terrorism officers\nat about 19:30 bst. The pair, believed to be friends, were taken to a police station in the west midlands for questioning. The\nforce said the arrests had been intelligence-led. the suspects did not pose any imminent threat, a spokesperson added. Supt\nrobin rickard from thames valley police said the arrests \"were part of an ongoing investigation by west midlands counter\nterrorism unit and were pre-planned\". \"Officers from reading and wokingham are providing support and there are searches\ntaking place at the suspects’ home addresses,\" he said.\nGPT-3 Zero-shot Summary (Standard)\nSummarize the above article in one sentence:\nTwo people were arrested in England on suspicion of terrorism.\nSummary Chain-of-Thought (Stage 1, Element Extraction)\nWhat are the important entities in this document? What are the important dates in this document? What events are\nhappening in this document? What is the result of these events?\nPlease answer the above questions:\nThe important entities in this document are the two suspects who were arrested, the police forces who made the arrests,\nand the locations where the arrests took place. The important dates are the day of the arrests (19:30 BST) and the day of\nthe document (20:00 BST). The events happening in this document are the arrests of the two suspects and the searches of\ntheir home addresses. The result of these events is that the two suspects are in police custody and their home addresses are\nbeing searched.\nGPT-3 Zero-shot-cot Summary (Stage 2, Summary Generation)\nLet’s integrate the above information and summarize the article in one sentence:\nOn 19:30 BST, two suspects were arrested by police forces in Reading and Wokingham on intelligence-led grounds, and\ntheir home addresses are currently being searched.\nTable 14: More comparisons between GPT-3 zero-shot summaries before and after using SumCoT. Spans ofEntity,\nDate, Event, and Result are separately highlighted in red, yellow, blue and green. Prompts are presented in italics\n(Appendix C.1).\n8656\nError Type: Date Hallucination\nSource Document (CNN/DailyMail)\nCharity runners taking part in a 10km fun run at the weekend were left exhausted after being sent on an unscheduled\ntwo-mile detour. The blunder was believed to have been caused by a race marshal taking a toilet break during the event,\nmissing 300 runners who should have been directed at a junction point. Instead they continued past the unmanned marshall\npoint and had to run for an extra three kilometres while the other 900 competitors followed the correct route. Scroll down\nfor video Blunder: Charity runners taking part in yesterday’s Bournemouth Bay 10K Run (pictured) were left exhausted\nafter being sent on an unscheduled two-mile detour. The bizarre gaffe happened during yesterday’s Bournemouth Bay\nRun and today the organisers - Bournemouth Borough Council - appealed for those who were affected by the mix-up to\ncontact them for a ’gesture of goodwill.’A local authority spokesman said that it was investigating what happened to the\nmarshal who should have directed runners at a turning point. It was reported that some runners were ’in tears’ while one\ndescribed the event’s organisation as ’shambolic’. Hayley James, who is four months pregnant and from Poole, said: ’To\nhave a race of that scale with only one marshal on a point is inexcusable.’We saw loads of people walking at the end, some\nwere in tears, I felt so sorry for them - I felt like crying at the 10km mark.’Andy Isaac, from Bournemouth, said the event\nwas ’mayhem’ with one point where an elderly woman managed to drive onto the route and was flashing her lights at\noncoming runners. A map shows where up to 300 runners continued along the coastal path after a marshal who was meant\nto direct them on to a turn went to the toilet. Reaction: Two people vent their frustration at the Bournemouth Bay Run on\nTwitter yesterday. It also emerged that water stations ran out of supplies during the race, forcing some runners to drink\nfrom half-empty bottles that had been left on the ground as they battled against dehydration.Commenting on the Daily\nEcho website, one runner said: \"We had a bottle of water at the three mile station, but at the six mile point they had totally\nran out, so nothing. Jon Weaver, head of resort marketing and events at the council, said: ’Unfortunately there was some\nconfusion with marshalling arrangements at one point, but it was a critical point. We apologise unreservedly to those front\nrunners.’In 33 years of running... this is the first time this has happened and as part of our debrief we will be analysing the\narrangements carefully... to learn for 2016.’We understand runners have trained for a long time for the event and it’s hard\nfor them and we do empathise with how they are feeling.’It was hoped that the event would have raised more than £70,000\nfor the British Heart Foundation. Some racers took to Twitter to vent their frustration over the blunder. Rob Kelly wrote:\nReally disappointed in the #BournemouthBayRun 10k that ended up 13k very poor show bad marshalling #wontbeback.’\nAnd Kim Kelly replied: ’Totally agree and never got to do a 5k as they were 45mins behind schedule :(((.’\nWhat are the important entities in this document?\nWhat are the important dates in this document?\nWhat events are happening in this document?\nWhat is the result of these events?\nPlease answer the above questions:\nElement Extraction\n1. The important entities in this document are the charity runners, the race marshal, and the Bournemouth Borough\nCouncil.\n2. The important dates in this document are the date of the race (May 3, 2015) and the date the runners were supposed to\nbe directed at the turning point (May 2, 2015).\n3. The events happening in this document are the charity runners being sent on an unscheduled two-mile detour, and the\nrace marshal taking a toilet break.\n4. The result of these events is that the charity runners were left exhausted after being sent on an unscheduled two-mile\ndetour.\n/enc-37(The dates highlighted in blue are not declared in the source document.)\nTable 15: Element extraction errors of GPT-3. Prompts are presented in italics (Appendix C.2).\n8657\nError Type: Date Hallucination\nSource Document (BBC XSum)\npatrick Bauer and Nathan Byrne helped Karl Robinson’s men complete a perfect smash and grab, cancelling out Zach\nclough’s free-kick. a victory which furthers the Addicks’ own play-off ambitions was made all the more impressive\nconsidering that they were a man short from the 12th minute onwards following lewis page’s red card. after page was sent\noff for a professional foul on josh vela, clough then made the punishment count double with a brilliant free-kick, his ninth\ngoal of the season. but robinson ’s side refused to lie down, equalising on 23 minutes when jake forster-caskey ’s free-kick\nwas turned in at the far post by defender bauer. the Addicks then grabbed a shock lead in first-half stoppage time when\nForster-Caskey led an impressive counter, feeding Byrne to slot the ball under the advancing Ben Alnwick. bolton, now\nwithout a win in their last five games in all competitions, threw all they had at Charlton after that and struck the woodwork\nwhen Andrew Taylor’s cross deflected off Chris Solly. they failed to seriously test goalkeeper Declan rudd in the second\nhalf, however, as they slipped to a second consecutive 2-1 defeat in front of their own fans. Charlton, unbeaten since\nchristmas, have now picked up 11 points from their last five matches to climb to 11th, just six points off a play-off place.\nreport supplied by the press association.\nWhat are the important entities in this document?\nWhat are the important dates in this document?\nWhat events are happening in this document?\nWhat is the result of these events?\nPlease answer the above questions:\nElement Extraction\n1. The important entities in this document are Charlton Athletic, Karl Robinson, Zach Clough, and Ben Alnwick.\n2. The important dates in this document are December 25th and January 23rd.\n3. The events happening in this document are a football match between Charlton Athletic and Bolton Wanderers, and the\naftermath of the match.\n4. The result of these events is that Charlton Athletic won the match 2-1.\n/enc-37(The dates highlighted in blue are not declared in the source document.)\nTable 16: Element extraction errors of GPT-3. Prompts are presented in italics (Appendix C.2).\nError Type: Date Hallucination\nSource Document (BBC XSum)\nclub director Emilio butragueno confirmed FIFA had asked the Spanish federation for documents relating to transfers\nover the last five years. but ragueno said the club was “ absolutely calm ” about its behaviour. fifa handed Barcelona a\ntransfer ban until 2016 after they breached regulations when signing 10 players under the age of 18 in 2013 . in a\nstatement, real Madrid said the majority of the 51 players that world football’s governing body had asked for information\non were exempt from regulations for various reasons. FIFA rules state that international transfers are only permitted for\nplayers who are over the age of 18 - unless the player in question meets one of three qualifying criteria. under-18s can\nmove to a club in a different country if: real claim 10 of the 51 players were Spanish nationals, while 23 foreign players\nhad already been registered with a Spanish club. on Thursday, real completed the # 2.3 m signing of 16-year-old Norway\nmidfielder Martin Odegaard from stromgodset. barcelona are not allowed to sign any players in 2015 after their appeal\nagainst their transfer ban was dismissed in December.\nWhat are the important entities in this document?\nWhat are the important dates in this document?\nWhat events are happening in this document?\nWhat is the result of these events?\nPlease answer the above questions:\nElement Extraction\n1. The important entities in this document are FIFA, Barcelona, and Real Madrid.\n2. The important dates in this document are 2013, when Barcelona was first given a transfer ban, and December of 2014,\nwhen Barcelona’s appeal against the ban was denied.\n3. The events in this document are FIFA’s investigation into Barcelona’s transfer practices, and the eventual imposition of a\ntransfer ban on the club.\n4. The result of these events is that Barcelona is not allowed to sign any players in 2015.\n/enc-37(The date when Barcelona’s appeal against the ban was denied is likely to be December 2013 or December\n2014 deduced from the bolded part of the source document, so the extracted date highlighted in blue is evidence-\ninsufficient.)\nTable 17: Element extraction errors of GPT-3. Prompts are presented in italics (Appendix C.2).\n8658\nError Type: Element Redundancy\nSource Document (BBC XSum)\nthere were concerns about the stability of the building, which has been derelict for years, after the collapse of an internal\nwall last week. contractors began work on Friday night. the environment minister Alex Atwood recommended the\ndemolition in the interests of public safety. mary o’dwyer, chair of Foyle civic trust, said a strategic approach is needed\nfor the future protection of heritage in the city following the demolition . “ many of our members believe that this is a\nvery sad event . “ the factory is part of our industrial heritage and more should have been done to save it . “ others believe\nsomething had to be done because it was a health and safety issue, ” she said . “ we would like to see a consensus and a\nstrategic vision of all of the organizations in the city that have a remit for protecting our heritage. ” Foyle road, which was\nclosed between the lower deck of the Craigavon bridge and john street roundabout, has reopened.\nWhat are the important entities in this document?\nWhat are the important dates in this document?\nWhat events are happening in this document?\nWhat is the result of these events?\nPlease answer the above questions:\nElement Extraction\nThe important entities in this document are the Foyle Civic Trust, the environment minister Alex Atwood, and the\ncontractors who began work on Friday night. The important dates in this document are the collapse of an internal wall last\nweek, and the demolition of the factory on Friday night. The events happening in this document are the demolition of the\nfactory, and the reopening of Foyle Road. The result of these events is that the factory is gone and Foyle Road is open\nagain.\n/enc-37(The elements highlighted in blue is redundent.)\nTable 18: Element extraction errors of GPT-3. Prompts are presented in italics (Appendix C.2).\nError Type: Element Redundancy\nSource Document (BBC XSum)\nsome of those residents had only just returned to their homes after last week’s eruptions. the latest eruption was less\npowerful but sent a large plume of dark grey smoke and ash rising from the crater. calbuco surprised residents of the Los\nLagos region last week by bursting into life after decades of inactivity. the national geology and mines service issued a\nred alert after Thursday’s eruption, warning that the volcano remained unstable. on Friday, residents were warned that\nheavy rain could mix with ash and rock to produce deadly volcanic mudflows. these “ lahars ” can slide down volcanoes\nlike avalanches. the BBC’s Gideon long in Santiago says that whereas the ash last week was blown in a north-easterly\ndirection, this time it is drifting south-east over the town of cochamo. the town has been blanketed in a cloud of smoke and\nash. calbuco is one of the most active volcanoes in chile, having erupted in 1961 and 1972, and many times before that.\nlast week’s eruptions caused the cancellation of flights to and within chile and forced farmers in the area to evacuate their\nlivestock.\nWhat are the important entities in this document?\nWhat are the important dates in this document?\nWhat events are happening in this document?\nWhat is the result of these events?\nPlease answer the above questions:\nElement Extraction\n1. The important entities in this document are the volcano, the residents, and the government.\n2. The important dates in this document are the dates of the eruptions.\n3. The events happening in this document are the eruptions of the volcano and the resulting evacuations.\n4. The result of these events is that the residents have been forced to leave their homes and the area around the volcano is\ncovered in ash.\n/enc-37(The elements highlighted in blue is redundent.)\nTable 19: Element extraction errors of GPT-3. Prompts are presented in italics (Appendix C.2).\n8659\nSource Document (BBC XSum)\nThey say every cloud has a silver lining. At least that’s what one Sydney woman, caught out in this week’s super storm, is\nhoping. With the rain clearing, a woman known only by her email address as MissieSmile21, has taped posters to the city’s\nlight posts to find the ’tall, charming gentleman’ who offered her his umbrella to cross the street.Scroll down for video The\n’Love Call’ notes are posted at traffic lights on Sydney’s George Street near Australia SquareActively looking: Missie Smile\nis hoping the generous stranger will get in contact. The ’Love Call’ notices, posted on George Street at Australia Square in\nSydney’s CBD, are appealing to the man with ’the most beautiful smile’ who was in the area about ’7:10 pm-ish’ on Tuesday\nevening.’I am actively looking for you,’ the poster reads. ’If you’re single, let’s grab a drink together.’ People struggled against\nthe heavy rain and strong winds in the Sydney CBD as the storm lashed NSW on Tuesday this weekMost people gave up on\ntheir umbrellas in winds of more than 100 km/ hr.\nWhat are the important entities in this document?\nWhat are the important dates in this document?\nWhat events are happening in this document?\nWhat is the result of these events?\nPlease answer the above questions:\ntext-ada-001\nThe ’Love Call’ notes are posted at traffic lights on Sydney’s George Street near Australia Square.\nThe ’Love Call’ notices, posted on George Street at Australia Square, are appealing to the man with ’the most beautiful smile’\nwho was in the area about ’7:10 pm-ish’ on Tuesday evening.\nPeople struggled against the heavy rain and strong winds in the Sydney CBD as the storm lashed NSW on Tuesday this week.\nMost people gave up on their umbrellas in winds of more than 100 km/ hr.\nWhat are important dates in this document?\nWhat are important entities in this document?\nWhat are important events in this document?\nPlease answer the above questions:\nThe ’Love Call’ notes are posted at traffic lights on Sydney’s George Street near Australia Square.\nThe ’Love Call’ notices, posted on George Street at Australia Square, are appealing to the man with ’the most beautiful smile’\nwho was in the area about ’7:10 pm-ish’ on Tuesday evening.\nPeople struggled against the heavy rain and strong winds in the Sydney CBD as the storm lash NSW on Tuesday this week.\nMost people gave up on their umbrellas in winds of more than 100 km/ hr.\nWhat is the result of these events?\nPlease answer the above questions:\nAt 7:10 pm on Tuesday evening, a man with the most beautiful smile, known only as MissieSmile21, was in the area near\nAustralia Square.\nThe ’Love Call’ notices, posted on George Street at Australia Square, are appealing to the man with the most beautiful smile\nwho was in the area about ’7:10 pm-ish’ on Tuesday evening.\nPeople struggled against the heavy rain and strong winds in the Sydney CBD as the storm lash NSW on Tuesday this week.\nMost people gave up on their umbrellas in winds of more than 100 km/ hr.\n/enc-37(The extracted information is very confusing and illogical.)\ntext-babbage-001\n1. What is the email address of the woman whoposted the ’Love Call’ notices on Sydney’s George Street near Australia Square?\n2. What is the date of the ’Love Call’ notices?\n3. What is the time of the ’Love Call’ notices?\n4. What is the type of person who was in the area around 7:10 pm-ish on Tuesday evening?\n5. What is the result of the ’Love Call’ notices?\n/enc-37(The model fails to accurately understand the meaning of guiding questions.)\ntext-curie-001\nThe important entities in this document are the poster, the man she is looking for, and the date 7/10/2016. The important dates\nin this document are Tuesday, July 10th. The events in this document are the heavy rain and strong winds. The result of these\nevents is that many people were unable to use their umbrellas and many people were stranded.\n/enc-37(The model understands the guiding questions, but extracts many redundant or false facts shown in blue spans.)\ntext-davinci-002\nThe important entities in this document are MissieSmile21, the tall, charming gentleman, and George Street at Australia Square.\nThe important dates are Tuesday evening and 7:10 pm. The events are the super storm and MissieSmile21’s search for the tall,\ncharming gentleman. The result of these events is unknown.\n/enc-33(The model can accurately extract human-identified core elements from the source document.)\nTable 20: Element extraction results of different GPT-3 versions. Prompts are presented in italics (Appendix C.3).\n8660\nSource Document (CNN/DailyMail)\nA Tory councillor with a history of odd behaviour was told to put down his knife and fork after being caught tucking into a\nroast duck dinner during a council meeting. Jonny Bucknell, 58, was enjoying his meal in the council chamber when a\nLabour rival, Theo Blackwell, spotted him and alerted other councillors. He was forced to put down his cutlery when the\nmayor, Lazzaro Pietragnoli, interrupted the proceedings to tell him off. Taking a stand: Jonny Bucknell is no stranger to\nodd behaviour. In 2013 he slept in his car at the Tory party conference. He now says he wants a rule change so he can eat a\nroast dinner at council meetings. The mayor, who was chairing the meeting of Camden Council in north London, reminded\nthe hungry councillor that eating was banned in the chamber. But the angry diner claims he was unaware eating there\nwas forbidden and said he now aims to campaign for a rule change. The rumpus comes a month after Liberal Democrat\ncouncillor Martin Elengorn was caught playing Scrabble during a Richmond Council budget meeting in south-west London.\nTelling off: Mayor of Camden Council, Lazzaro Pietragnoli, had to tell Mr Bucknell to stop eating. When he first noticed\nhim eating, Mr Blackwell told his fellow councillors: ’It appears that one of our Tory colleagues is consuming a full\nSunday roast dinner in the council chamber. ’Could I ask the borough solicitor to give us advice on eating a full roast\ndinner in the council chamber? It’s a little bit more than a cheeky Snickers.’ The diner was forced to curtail his meal. Mr\nBucknell, who has been a councillor for more than ten years and represents Belsize, Hampstead, told the Evening Standard:\n’I never knew there was a ban on eating in the chamber. ’They should definitely repeal it. There is nothing wrong with\nnibbling from a lunch box if you are being discreet. ’It is not as if a cold meal is going to waft around like a McDonald’s.\n’I will be campaigning for the repealing of the law that says you can’t nibble from a lunch box in the council chamber.’ The\nConservative councillor said the meal, in a plastic box, had travelled home with him after a French snowboarding holiday.\n’The chalet always brought out too much food and I can’t stand wasting food,’ he said. He previously found fame when he\nslept in his V olvo car to save on hotel bills during the Conservative party conference in September 2013. Mr Bucknell said\nat the time it was to make a stand against what he called ’ridiculous prices’. He said the economy would improve if more\npeople were thrifty like him. After the council meeting mayor Lazzaro Pietragnoli said: ’I understand councillors do a\ndifficult job and sometimes don’t get time to eat dinner. ’I also tend to be quite flexible, but having a big meal in front\nof him - that was a bit too much.’ A Camden Council spokesman said: ’It is as the mayor said, standing orders say that\nmembers should not eat in the chamber.’ No eating: The Camden Council chamber where Councillor Bucknell was forced\nto curtail his roast dinner.\nDataset-specifc Summary\nLabour rival alerted colleagues after spotting Councillor tucking into roast. It is not the first time jonny Bucknell, 58, has\ndemonstrated odd behaviour.. In 2013 he slept in his car to make a point while attending Tory conference. Mr Bucknell\nsaid he will campaign for rule change about eating at meetings.\nElement-aware Summary\nJonny Bucknell, a Tory councillor, was found tucking into a roast duck dinner during a council meeting. He now wants a\nrule change to have dinner at council meetings. It is not the first time for his strange behavior. In September 2013, Mr\nBucknell slept in his V olvo car to save on hotel bills during the Conservative party conference to make a stand against what\nhe called ’ridiculous prices’.\nGPT-3 Zero-shot Summary\nA Tory councillor was told to stop eating a roast duck dinner during a council meeting after a Labour rival spotted him and\nalerted other councillors. The councillor, Jonny Bucknell, claims he was unaware that eating in the council chamber was\nforbidden and said he now aims to campaign for a rule change.\nGPT-3 Zero-shot-cot Summary\nIn September 2013, Councillor Jonny Bucknell made headlines when he slept in his car during the Conservative party\nconference in order to save on hotel bills. Recently, he has found himself in the news again after being caught eating a\nroast duck dinner during a council meeting. Councillor Bucknell claims that he was unaware that eating in the council\nchamber was forbidden, and is now campaigning for a rule change so that he can eat during meetings.\nTable 21: Random samples from CNN/DailyMail and BBC XSumdatasets (Appendix D).\n8661\nSource Document (CNN/DailyMail)\nThis is the dramatic moments armed police swoop on a villa where a Briton linked to the gangland murder of a torture\nvictim was arrested. Paul Monk, 54, from Essex, was wanted by Spanish police for questioning over the kidnap and murder\nof Francis Brennan, whose badly decomposed body washed up on a Costa Blanca beach in March last year. He was also\nwanted by the Metropolitan Police on drug offences and had been named on a list of fugitives published as part of the\nNational Crime Agency’s Operation Captura campaign ahead of his detention. This is the dramatic moment that fugitive\nPaul Monk was arrested by heavily armed police in his Alicante villa. Paul Monk, 54, from Essex, was wanted by Spanish\npolice for questioning over the kidnap and murder of Francis Brennan. Spanish police released footage of their dramatic\nswoop. This grab for the video shows them approaching the villa at speed. The police move steathily up the steps of\nMonk’s villa, weapons drawn. Taking no chances: The highly trained, well-armed police moved through the house room\nby room. Paul Monk was on the UK’s most wanted list on suspicion of drug trafficking. Brennan, 25, from Liverpool,\nvanished in the resort of Javea in January last year after being kidnapped by men posing as police. His body was wrapped\nin an industrial-size bin bag with duct tape round it when it appeared on a beach in nearby Orihuela Costa. Civil Guard\nofficers in Alicante confirmed today they believe Monk, from Essex, may be implicated in the violent death and named him\nas an associate of Paul Scott. Scott, 32, was arrested on a charge of conspiracy to import cocaine after being caught trying\nto sneak into Britain in a light aircraft last December. He was also wanted for questioning over Mr Brennan’s murder when\nhe was detained. Guardia Civil described him last night as the suspected mastermind of the crime. Monk was detained at a\nfour-bedroom property in Javea near Alicante as he directed workers laying a marble patio around his swimming pool. An\nimitation firearm with a silencer and nearly ˘00a3100,000 in cash were also found. He is being held in jail and is expected\nto be charged and face trial in Spain over Mr Brennan’s murder before being extradited to the UK to face questioning over\nalleged drugs offences. He has been linked to the handover of one kilo of cocaine in Cockfosters, London, in May 2013\nand the seizure of 24 kilos of cannabis in Colchester in October 2013. A Civil Guard spokesman said: ’He never left his\nhouse as a security measure to avoid being arrested. ’He got other people to bring him food and other things in the villa\nwhere he hid out, leading the life of an authentic fugitive.’ The police raid had air support, with this grab coming from\nfootage of Monk’s villa taken by a helicopter. Wads of money found by armed police after they arrested Monk . Monk is\nbeing held in jail and is expected to be charged and face trial in Spain over Mr Brennan’s murder before being extradited to\nthe UK to face questioning over alleged drugs offences. Spanish police search Monk’s property thoroughly for evidence,\nfinding an imitation gun with a silencer. National Crime Agency detectives took part in the raid on the property along with\nCivil Guard officers. Mr Brennan, from Liverpool, was himself on the run after leaving Britain while awaiting sentence in\nthe UK over the wounding of a man at a Swedish House Mafia music concert in Milton Keynes, Bedfordshire. He travelled\nto the Costa del Sol with his girlfriend towards the end of 2013 after ignoring the advice of his parents to stay in Britain.\nPolice swooped on Scott last year after he flew from Holland to a remote airstrip in Norfolk. He had fake Belgian identity\ndocuments on him and more than ˘00a31,500 in cash. He was jailed in January for plotting to import 40 tonnes of cocaine\ninto Britain. Police described him as the ’last man outstanding in a criminal gang that plotted to smuggle vast quantities of\ncocaine into the UK’ after he was sentenced to 14 years in prison at Liverpool Crown Court. Sorry we are not currently\naccepting comments on this article.\nDataset-specific Summary\nPaul Monk, 54, was wanted by Spanish Police in connection with a murder.. The Essex man is a suspect in the murder of\nFrancis Brennan.. Brennan’s body washed up on a Costa Blanca beach in March last year.. Police released footage of their\nswoop on Monk’s Alicante villa.\nElement-aware Summary\nPaul Monk, 54, from Essex, was wanted by Spanish police for questioning over the kidnap and murder of Francis Brennan,\n25, from Liverpool. Brennan˘2019 body was found on a beach in March last year. Paul Monk was swoop by armed police\non a villa, he will be arrested and face trial in Spain for this murder.\nGPT-3 Zero-shot Summary\nA man wanted for questioning in connection with the murder of a torture victim has been arrested by Spanish police. Paul\nMonk, 54, from Essex, was detained at his villa in Javea near Alicante as he directed workers laying a marble patio around\nhis swimming pool. An imitation firearm with a silencer and nearly ˘00a3100,000 in cash were also found. Monk is being\nheld in jail and is expected to be charged and face trial in Spain over the murder before being extradited to the UK to face\nquestioning over alleged drugs offences.\nGPT-3 Zero-shot-cot Summary\nPaul Monk, 54, from Essex, was arrested by Spanish police in his Alicante villa for questioning over the kidnap and murder\nof Francis Brennan, 25, from Liverpool. Brennan’s body was found in March last year, wrapped in an industrial-size bin\nbag with duct tape round it, on a beach in nearby Orihuela Costa. Monk is being held in jail and is expected to be charged\nand face trial in Spain over Mr Brennan’s murder before being extradited to the UK to face questioning over alleged drugs\noffences.\nTable 22: Random samples from CNN/DailyMail and BBC XSumdatasets (Appendix D).\n8662\nSource Document (BBC XSum)\nThey’ve kicked up a stink with their council, who’ve decided to use the liquid to kill weeds around the city. It’s all part of a\ntrial to get rid of the unwanted plants without using strong chemicals, which some people think aren’t environmentally\nfriendly. But many locals say they’re not happy with the unpleasant pong the trial’s creating. They’ve started a campaign\nand also say they don’t think vinegar is strong enough to kill the weeds. Bristol city council say they’ll continue with their\ntrial, but will keeping track of feedback from the people who live there.\nDataset-specific Summary\nPeople living in bristol have complained about a vinegary whiff in the air.\nElement-aware Summary\nBristol city is conducting a trial to kill weeds with vinegar, but the unpleasant pong makes the locals unhappy, which led to\na conflict between the two.\nGPT-3 Zero-shot Summary\nThe city of Bristol is conducting a trial to see if vinegar can be used as an environmentally friendly weed killer, but many\nlocals are not happy with the strong smell.\nGPT-3 Zero-shot-cot Summary\nThe city council of Bristol is conducting a trial to kill weeds using vinegar, but many locals are unhappy with the unpleasant\nsmell the trial is creating.\nTable 23: Random samples from CNN/DailyMail and BBC XSumdatasets (Appendix D).\nSource Document (BBC XSum)\nCpl Kylo gorman’s medals for service in Afghanistan and at the queen ’s diamond jubilee were taken from his car in\nbolton-le-sands on 4 or 5 January. He said he wasn’t that bothered at first, but the reaction online got me thinking \"it is a\nreally big deal\" . Lancashire police said they were investigating the theft. The port talbot-born 28-year-old, who has served\nfive tours of Afghanistan, said he had left the medals in the car after removing them from a uniform he was having altered.\n\"I didn’t think twice about them. I’m based at raf leeming in north yorkshire during the week and when I came home and\nthe car had been broken into, I realised my medals had gone,\" he said. \"I want my children to be able to look at their dad’s\nmedals and be proud of what I did,\" he added. Cpl gorman, who has also served in the Falklands, Africa and Cyprus, has\nbeen in the RAF for 10 years and is due to leave the armed forces in April.\nDataset-specific Summary\nA RAF airman has made an appeal for the return of two stolen medals after hundreds shared his post about the theft on\nsocial media.\nElement-aware Summary\nCpl Gorman’s medals were stolen on 4 or 5 january, and he has made an appeal for the return. Lancashire police are\ninvestigating the theft.\nGPT-3 Zero-shot Summary\nThe medals of a British serviceman were stolen from his car, and he is now appealing for their return.\nGPT-3 Zero-shot-cot Summary\nCpl Gorman’s medals for service in Afghanistan and at the Queen’s Diamond Jubilee were stolen from his car on 4 or 5\nJanuary, and Lancashire police are investigating the theft.\nTable 24: Random samples from CNN/DailyMail and BBC XSumdatasets (Appendix D).\n8663\nACL 2023 Responsible NLP Checklist\nA For every submission:\n□\u0013 A1. Did you describe the limitations of your work?\nLimitations\n□\u0013 A2. Did you discuss any potential risks of your work?\nEthics Statement\n□\u0013 A3. Do the abstract and introduction summarize the paper’s main claims?\nAbstract 1\n□\u0017 A4. Have you used AI writing assistants when working on this paper?\nLeft blank.\nB □\u0013 Did you use or create scientiﬁc artifacts?\n3 4\n□\u0013 B1. Did you cite the creators of artifacts you used?\n3.1 Appendix A\n□\u0013 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\nAppendix A\n□\u0013 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\nEthics Statement\n□\u0013 B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiﬁes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nEthics Statement\n□\u0013 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\nAppendix\n□\u0013 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiﬁcant, while on small test sets they may not be.\n2.1 2.3\nC □\u0013 Did you run computational experiments?\n3 4\n□\u0013 C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\n3.1 Appendix C.3\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n8664\n□\u0013 C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\n3.1\n□\u0013 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\n3 4\n□\u0013 C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\n3.1\nD □\u0013 Did you use human annotators (e.g., crowdworkers) or research with human participants?\n2 3 4\n□\u0013 D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\n2.2 3.3\n□\u0013 D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants’ demographic\n(e.g., country of residence)?\nAppendix A\n□\u0013 D3. Did you discuss whether and how consent was obtained from people whose data you’re\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nAppendix A\n□\u0013 D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\nEthics Statement\n□\u0013 D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nAppendix A\n8665",
  "topic": "Automatic summarization",
  "concepts": [
    {
      "name": "Automatic summarization",
      "score": 0.8476827144622803
    },
    {
      "name": "Computer science",
      "score": 0.8282909393310547
    },
    {
      "name": "Information retrieval",
      "score": 0.5792216658592224
    },
    {
      "name": "Benchmarking",
      "score": 0.5148893594741821
    },
    {
      "name": "Natural language processing",
      "score": 0.43426939845085144
    },
    {
      "name": "Mainstream",
      "score": 0.4303460717201233
    },
    {
      "name": "Artificial intelligence",
      "score": 0.39920422434806824
    },
    {
      "name": "Data science",
      "score": 0.36507683992385864
    },
    {
      "name": "Marketing",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Theology",
      "score": 0.0
    },
    {
      "name": "Business",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I183067930",
      "name": "Shanghai Jiao Tong University",
      "country": "CN"
    }
  ]
}