{
  "title": "EEG temporal–spatial transformer for person identification",
  "url": "https://openalex.org/W4292731283",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2030255205",
      "name": "Yang Du",
      "affiliations": [
        "Southern Medical University",
        "Nanfang Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2946811729",
      "name": "Yongling Xu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2127456196",
      "name": "Xiaoan Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1947673853",
      "name": "Li Liu",
      "affiliations": [
        "Nanfang Hospital",
        "Southern Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2117351343",
      "name": "Peng-Cheng Ma",
      "affiliations": [
        "Nanfang Hospital",
        "Southern Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2030255205",
      "name": "Yang Du",
      "affiliations": [
        "Nanfang Hospital",
        "Southern Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2946811729",
      "name": "Yongling Xu",
      "affiliations": [
        "Chinese Institute for Brain Research"
      ]
    },
    {
      "id": "https://openalex.org/A2127456196",
      "name": "Xiaoan Wang",
      "affiliations": [
        "Chinese Institute for Brain Research"
      ]
    },
    {
      "id": "https://openalex.org/A1947673853",
      "name": "Li Liu",
      "affiliations": [
        "Nanfang Hospital",
        "Southern Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2117351343",
      "name": "Peng-Cheng Ma",
      "affiliations": [
        "Nanfang Hospital",
        "Southern Medical University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2174850379",
    "https://openalex.org/W2160367574",
    "https://openalex.org/W178227285",
    "https://openalex.org/W2109824782",
    "https://openalex.org/W2011584637",
    "https://openalex.org/W1513213326",
    "https://openalex.org/W2032808202",
    "https://openalex.org/W1981934039",
    "https://openalex.org/W1996748682",
    "https://openalex.org/W2086631192",
    "https://openalex.org/W4237630247",
    "https://openalex.org/W2017193127",
    "https://openalex.org/W2313108227",
    "https://openalex.org/W2914229829",
    "https://openalex.org/W3019900571",
    "https://openalex.org/W3014117730",
    "https://openalex.org/W3017974589",
    "https://openalex.org/W2900992113",
    "https://openalex.org/W2823613278",
    "https://openalex.org/W2925281733",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W3138516171",
    "https://openalex.org/W4200042752",
    "https://openalex.org/W4220904310",
    "https://openalex.org/W4205466227",
    "https://openalex.org/W6600223405",
    "https://openalex.org/W3177342940",
    "https://openalex.org/W4229068725",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W6828894009",
    "https://openalex.org/W2162800060",
    "https://openalex.org/W2151669316",
    "https://openalex.org/W2946344027",
    "https://openalex.org/W2794008059",
    "https://openalex.org/W6605588651",
    "https://openalex.org/W6604662147",
    "https://openalex.org/W6790434664",
    "https://openalex.org/W1983839088",
    "https://openalex.org/W2140085889",
    "https://openalex.org/W1547702425",
    "https://openalex.org/W3103608651",
    "https://openalex.org/W4200165798",
    "https://openalex.org/W3103177978"
  ],
  "abstract": "Abstract An increasing number of studies have been devoted to electroencephalogram (EEG) identity recognition since EEG signals are not easily stolen. Most of the existing studies on EEG person identification have only addressed brain signals in a single state, depending upon specific and repetitive sensory stimuli. However, in reality, human states are diverse and rapidly changing, which limits their practicality in realistic settings. Among many potential solutions, transformer is widely used and achieves an excellent performance in natural language processing, which demonstrates the outstanding ability of the attention mechanism to model temporal signals. In this paper, we propose a transformer-based approach for the EEG person identification task that extracts features in the temporal and spatial domains using a self-attention mechanism. We conduct an extensive study to evaluate the generalization ability of the proposed method among different states. Our method is compared with the most advanced EEG biometrics techniques and the results show that our method reaches state-of-the-art results. Notably, we do not need to extract any features manually.",
  "full_text": "1\nVol.:(0123456789)Scientific Reports |        (2022) 12:14378  | https://doi.org/10.1038/s41598-022-18502-3\nwww.nature.com/scientificreports\nEEG temporal–spatial transformer \nfor person identification\nYang Du1,3, Yongling Xu2,3, Xiaoan Wang2,3*, Li Liu1* & Pengcheng Ma1*\nAn increasing number of studies have been devoted to electroencephalogram (EEG) identity \nrecognition since EEG signals are not easily stolen. Most of the existing studies on EEG person \nidentification have only addressed brain signals in a single state, depending upon specific and \nrepetitive sensory stimuli. However, in reality, human states are diverse and rapidly changing, which \nlimits their practicality in realistic settings. Among many potential solutions, transformer is widely \nused and achieves an excellent performance in natural language processing, which demonstrates the \noutstanding ability of the attention mechanism to model temporal signals. In this paper, we propose \na transformer-based approach for the EEG person identification task that extracts features in the \ntemporal and spatial domains using a self-attention mechanism. We conduct an extensive study to \nevaluate the generalization ability of the proposed method among different states. Our method is \ncompared with the most advanced EEG biometrics techniques and the results show that our method \nreaches state-of-the-art results. Notably, we do not need to extract any features manually.\nIn today’s globalized world of information, the security of personal information has become particularly \n important1, leading to the need for new and more sophisticated identification technologies. Even though exist-\ning identification technologies have widely applied in daily life and accomplished high accuracy, including fin-\ngerprints, iris, or face  recognition2–4 and achieving high recognition accuracy rates. However, the problem with \nthese biometrics is that they can be easily stolen or revealed inadvertently. The security of these technologies is \nnot effectively guaranteed. Compared to conventional biometrics mentioned above, cognitive biometrics has \nattracted more research interest for its security reasons.\nUnlike conventional biometrics, which relies on physiological or behavioral characteristics, cognitive biomet-\nrics is a type of biometrics that measures human brain activity and analyzes how people “think”5. There are vari-\nous human brain activity measurement methods, and these methods are based on different principles to reflect \nbrain activity. Functional magnetic resonance imaging (fMRI) measured the concentration of oxyhemoglobin and \ndeoxyhemoglobin, which can indicate the hemodynamic changes caused by neuronal activity. Positron emission \ntomography (PET) measures neuronal metabolism by injecting a radioactive substance into the subject’s body. \nNear-infrared spectroscopy (NIRS) measures the concentration of oxyhemoglobin and deoxyhemoglobin by the \nintensity of reflection of infrared light from the cerebral cortex to reflect brain activity. Magnetoencephalography \n(MEG) collects the magnetic field generated by brain currents while electroencephalography (EEG) collects the \nelectric fields generated.\nWe chose EEG for the identification task. Compared to other techniques, EEG can be acquired by portable \nand relatively inexpensive  devices6,7. In particular, non-invasive brain–computer interface technology is often \nused to capture EEG signals, which is safer and more convenient than the invasive approaches. The amplitude \nof the EEG signal of normal humans ranges from 10 to 200 µ V , while frequency usually varies between 0.5 and \n40 Hz. It has a high temporal resolution, usually in the order of  milliseconds 5. In terms of spatial resolution, \nEEG reveals a lower spatial resolution due to the size limitation of the acquisition device and the interaction of \nthe electric fields among different brain regions. Y et it is worth noting that individual variability is the basis of \nperson identification, and EEG is no exception. Some  studies8,9 have demonstrated that EEG signals have strong \nindividual variability, especially in alpha  waves10. Consistency is another crucial factor for identification, as this \nbiometrics requires test–retest, which means that the features stably remain invariant across time and  place11,12. \nThe EEG signal is also highly secure. This is especially important for person identification as person identifica-\ntion requires specialized acquisition equipment and amplifiers to collect information. Such personal information \nmust not be inadvertently leaked or accessed remotely. Hence, data security-wise, EEG-based identification is \nreliable since it is more difficult for criminals to exploit. EEG ensures information security through emotion \ndetection. Identification cannot be processed without users’ consent, as nervousness detected by EEG can lead to \nOPEN\n1Big Data Center, Nanfang Hospital, Southern Medical University, Guangzhou 510515, China. 2Brainup Research \nLab, Naolu Technology Co., Ltd., Beijing 100124, China. 3These authors contributed equally: Yang Du, Yongling Xu \nand Xiaoan Wang. *email: wangxiaoan@naolubrain.com; liuli@i.smu.edu.cn; pc.ma@foxmail.com\n2\nVol:.(1234567890)Scientific Reports |        (2022) 12:14378  | https://doi.org/10.1038/s41598-022-18502-3\nwww.nature.com/scientificreports/\nauthentication failure. In addition, while the EEG signal is an internal trait that can only be generated when the \nbrain is active, it naturally carries the function of liveness  detection13. Last but not least, EEG signals are universal, \nand EEG signals can be captured from every individual unless some pathology causes structural damage to the \nbrain that prevents the production of EEG signals.\nIn summary, EEG person identification shows great promise for application. However, most of the current \nresearch only studied the recognition in a single state, which is still unable to guarantee the accuracy and robust-\nness of recognition. Therefore, we applied the attention mechanism to construct a network for identification \ntasks and made great progress. The main contributions of this paper are described below:\n• We propose the transformer encoder-based neural network model ETST, EEG temporal–spatial transformer, \nwhich can commendably extract the information of EEG signals about individual differences in time and \nspace domains well and ensure the accuracy of identification even in the case of cross-state.\n• Extensive experiments are conducted and the results show that our model outperforms all state-of-the-art \nmodels. We investigate the role of temporal and spatial information of EEG signals on the person identifica-\ntion task. In addition, the effect of different position encoding on EEG transformer is investigated.\n• We explore the effect of sample length on our transformer-based model and introduce a data augmentation \nmethod to improve the performance. The method increases the sample size by increasing the overlap rate \nbetween samples in time and an improvement of between 1 and 3% is observed with the strategy finally.\nRelated works\nThe current EEG-based biometrics systems are broadly divided into two approaches. One is to extract distinguish-\nable features first and then utilize traditional machine learning methods for classification, and the other is to \nemploy an end-to-end deep learning approach, which accomplishes both feature extraction and classification. \nKong et al. assume that task-related EEG can be decomposed into two parts, including background EEG (BEEG) \nand residue EEG (REEG). BEEG contains a person’s distinctive features whereas REEG is composed of task-\nevoked EEG and noises. Kong utilized the identification algorithm based on low-rank matrix decomposition \n(LRDM) to decompose the EEG signal and then used the maximum correntropy criterion (MCC) algorithm to \naccomplish the  classification14. Wang et al. argued that the functional connectivity of the brain reflects individual \nspecificity. They computed the connectivity of the EEG signal by calculating metrics of EEG signals as feature \nvectors and then used a discriminant model based on Mahalanobis distance to conduct person  identification15. \nMoctezuma et al. adopted empirical mode decomposition (EMD) to decompose EEG signals into a set of intrinsic \nmode functions (IMFs), and subsequently selected the closest two IMFs and decomposed them into four features. \nIn this way each channel will return eight features. Eventually, they employed support vector machine (SVM) with \nradial basis function (RBF) as a  classifier16. Besides using SVM as a classifier, Alyasseri et al. applied FPA β-hc, \nwhich is a hybrid optimization technique based on binary flower pollination algorithm (FPA) and β-hill climbing \nto extract  features17. Yıldırım et al. constructed a 1D CNN model stacked with multiple layers to extract deep-\nlevel features of EEG signals about individual  specificity18. Wilaiprasitporn et al. tried to combine convolutional \nneural network (CNN) and recurrent neural network (RNN), where CNN is used to extract spatial features and \nRNN is used to extract temporal  features19. Özdenizci et al. tried an adversarial inference approach within a deep \nconvolutional network structure, which is able to learn session-invariant and person discriminative  features20.\nCurrently, Transformer has shown good results in both natural language processing (NLP) and computer \nvision (CV)  fields21–23. Transformer is able to model long-range dependencies and has a faster computation \nspeed compared with RNN or long short-term memory (LSTM) because of its parallel computing characteristic. \nTherefore, Transformer has taken the lead in the NLP field, attracting interest from researchers. However, the \nability of Transformer to process EEG signals has yet to be investigated by scholars. Arjun et al. directly migrated \nViT, which performs well on images, to EEG signals. The EEG signal in 1D was cut into different patches in the \ntime dimension and used as input to the ViT  model24. Lee et al. combined EEGNet and transformer, using an \nEEGNet-based convolutional neural network to obtain the temporal–spectral-spatial  features25. Tao et al. pro-\nposed a gated Transformer, which is a combination of the self-attentive mechanism and the gating mechanism \nin GRU to obtain the information of EEG signals on time  series26. Song et al. proposed a method based on com-\nmon spatial pattern (CSP) to extract the spatial features of the EEG signals along with a self-attention algorithm \nto decode them. This method achieves a state-of-the-art  effect27. These approaches show that the self-attentive \nmechanism can improve the performance of brain–computer interface (BCI) systems. Therefore, we designed \nour model based on the self-attention mechanism.\nMethodology\nIn this paper, we propose an EEG person identification model based on the attention  mechanism21, and the \noverall framework diagram is shown in Fig.  1. Unlike other models, our approach does not require additional \nextraction of artificial features of EEG signals, and only raw EEG signals are used for the identification task. \nConsidering that EEG signal is both continuous in time and functionally connected among channels, we design \nthe model to capture both temporal and spatial features. The model consists of two main parts, containing a \ntemporal transformer encoder (TTE) and a spatial transformer encoder (STE). In the TTE part, we use the atten-\ntion mechanism in time domain to calculate the correlation among sampling points in samples, which is used \nto extract the time-domain features of the EEG. Since there is individual specificity in the coupling relationship \nof channels between individuals, we design the STE part to calculate the spatial domain attention for chan -\nnels to capture the coupling relationship among different channel signals, which enables the model to identify \ndifferent individuals more stably based on the specific coupling relationship. Finally, a simple fully connected \n3\nVol.:(0123456789)Scientific Reports |        (2022) 12:14378  | https://doi.org/10.1038/s41598-022-18502-3\nwww.nature.com/scientificreports/\nlayer is applied to aggregate global information and perform classification. In the following, we will explain the \npreprocessing of raw EEG and components of the ETST model in detail.\nPreprocessing. Before feeding data into ETST, we first processed the raw EEG. The original EEG signal is \nfiltered using a [0.5 42] Hz bandpass filter to remove low and high-frequency noises. We remove the ocular and \nmuscular artifacts using independent component analysis (ICA). The size of each sample is T  × C, where T is \nthe number of sampling points and C is the number of EEG channels. For each sample, the following z-score \nstandardization will be employed over time for each channel:\nwhere t , c in xt,c denotes the sampling point and the channel of the sample, xc denotes the mean of the sample \non channel c and σc denotes the standard deviation of the sample on channel c. After standardization, the mean \nof the data on each channel of the sample is 0 and the standard deviation is 1.\nTemporal transformer encoder. We use temporal correlation, or correlation between two time points, \nto capture the time-domain information of EEG signals. Inspired by the attention  mechanism21, we use multiple \ntransformer blocks to encode the temporal information of the EEG. Instead of convolution focusing on local \ninformation, TTE takes into account the long-distance dependence in time. We directly feed EEG data pre-\nprocessed into the transformer, instead of employing complicated transformations such as  convolutions28,29 or \ntrainable linear  projections24. For a given input X =[ x1 ,x2 ,..., xT ]∈ RT×C  , we compute self-attention in the \ntransformer block to estimate temporal correlations, and then we weight the sum to obtain the new representa-\ntion. Self-attention is computed as follows:\nwhere Q, K, and V are all matrices obtained by linear projections of the input and dk is a scalar factor. To jointly \nattend to information from different representation subspaces at different positions, we adopt the multi-head \nattention  mechanism21 on the input. Each transformer encoder contains two parts: multi-head attention (MHA) \nand multi-layer perceptron (MLP). Each part employs residual  connection30 and layer normalization (LN)31 to \nimprove the speed of training and robustness of the model. Figure  2 illustrates the above calculation process. \nThe TTE part can be expressed by :\nSpatial transformer encoder. The channels in the EEG signal represent the locations of the electrodes on \nthe scalp, and the functional connectivity between different brain regions can be calculated by considering the \ndependencies among different channels. Similar to TTE, in STE we also used the attention mechanism to model \nthe spatial information among different channels. In order to preserve the spatial location information, we added \nthe position encoding of the spatial domain to the input and then fed the result to STE:\n(1)ˆxt,c = xt,c − x c\nσc\n(2)Attention(Q , K , V ) = Softmax\n(QK T\n√dk\n)\nV\n(3)ht\nl = LN\n(\nMHA\n(\nzt\nl−1\n)\n+ zt\nl−1\n)\nl= 1, 2,... ,L\n(4)zt\nl = LN\n(\nMLP\n(\nht\nl\n)\n+ ht\nl\n)\nl= 1, 2,..., L\nFigure 1.  The architecture of the ETST model.\n4\nVol:.(1234567890)Scientific Reports |        (2022) 12:14378  | https://doi.org/10.1038/s41598-022-18502-3\nwww.nature.com/scientificreports/\nwhere tran() represents the transpose operation and the Epos ∈ RC ×T  represents the position encoding. In this \npaper, we use the position encoding in the form of a trigonometric function at a fixed position. zs\n0 denotes the rep-\nresentation with the addition of spatial position information. In the STE, we use a similar structure to that in the \nTTE to learn the spatial information on the different channels of the EEG. The process equation is expressed as:\nClassification layer. The output of the transformer encoder layers, TTE and STE, yield a better representa-\ntion containing both time-domain and space-domain features. ETST learns the time-domain information of the \nEEG data on the different sampling points in TTE. In the subsequent STE, ETST learns the spatial information \namong channels. Then, to fuse the global information in the representation for classification, a simple fully-\nconnected layer with only one layer is used to obtain the final classification output which is optimized using the \ncross-entropy loss function.\nwhere N denotes the number of batch sizes and C denotes the number of categories. yc\nn is the true one hot label, \nˆyc\nn is the predicted probability of the corresponding category.\nEthical approval. This paper does not contain any studies with human or animals participants performed \nby any of the authors.\nExperiments\nDataset. We validate our method on an EEG dataset provided by  PhysioNet32. This dataset was recorded \nusing the BCI2000  system33 and consists of over 1500 1- and 2-min EEG recordings, obtained from 109 subjects. \nThe sampling frequency was 160 Hz. These EEG data were recorded with 64 electrodes, which conformed to the \n10–10 system. Subjects were asked to do motor/imagery tasks while the EEG signal was recorded by the system. \nEach subject completed 14 experimental runs including 2 1-min baseline runs and 12 2-min task runs. In the \nbaseline runs, the EEG signals were recorded while the subjects kept their eyes open (EO) and eyes closed (EC), \nrespectively. In the task runs, subjects were asked to complete four motor/imagery tasks, including actually com-\npleting the corresponding physical action (PHY) or imagine completing the corresponding action (IMA) when \nthe target appeared on the computer, and rest when the target disappeared. Task 1 is to open and clench the cor-\nresponding fist when a target is on the left or right side of the computer screen. Task 2 is to imagine opening and \nclenching the corresponding fist when a target is on the left or right side of the computer screen. Task 3 is to open \nand clench both fists when a target appears on the top or bottom of the computer. Task 4 is to imagine opening \nand clenching both fists when a target appears at the top or bottom of the computer. Each task is repeated for \nthree times, totaling twelve task runs. In our experiments, we use all the subjects in the dataset. A 1-s window \nwith 50% overlap of each channel is used to generate samples. Therefore, the shape of a sample is 160 × 64.\nExperiment design. To make EEG person identification technology realistic and feasible, the stability and \nrobustness of the system must be able to be guaranteed. This also means that the model needs to be able to con-\nsistently and accurately identify subjects by their EEG signals, even if the subjects are in different states, such as \n(5)zs\n0 = tran\n(\nzt\nL\n)\n+ Epos\n(6)hs\nl = LN\n(\nMHA\n(\nzs\nl−1\n)\n+ zs\nl−1\n)\nl= 1, 2,..., L\n(7)zs\nl = LN\n(\nMLP\n(\nhs\nl\n)\n+ hs\nl\n)\nl= 1, 2,..., L\n(8)L =− 1\nN\nN∑\nn=1\nC∑\nc=1\nyc\nnlog\n(\nˆyc\nn\n)\nFigure 2.  (left) The architecture of a transformer encoder. (right) Multi-head attention.\n5\nVol.:(0123456789)Scientific Reports |        (2022) 12:14378  | https://doi.org/10.1038/s41598-022-18502-3\nwww.nature.com/scientificreports/\nhappy or calm, or even thinking about something. We conducted several experiments to verify the effectiveness \nand practicability of ETST on EEG biometrics. The EEG signal in the Physionet Dataset contains four states, \nEO, EC, PHY , and IMA. We designed various experiments based on these four different states to test the perfor-\nmance of ETST in diverse scenarios. The experiments we conducted are described below. \n1. We compared our model with state-of-the-art EEG identification methods and also with traditional neu-\nral network methods such as CNN, MLP , and traditional machine learning methods such as SVM. In the \ncomparison experiments with other methods, we set up three sub-experiments. The first one is training and \ntesting in a single human state, and we conducted training and testing in four states, EC, EO, IMA, and PHY , \nwhich corresponds to the case of EEG person identification in a fixed state. The second one is to train in one \nstate and test in another state, we will train under EC and EO data and test under IMA and PHY . This type of \ntask is the most challenging, and it tests whether the model obtained by training under one EEG paradigm \ncan be generalized to other EEG paradigms. The third one is a mixture of EC, EO, IMA, and PHY datasets \nfor training and testing. For within-state and diverse-states experiments, we randomly divide the dataset \ninto 4:1 as training set and test set respectively.\n2. We performed ablation experiments to explore the effect of each part of the model on the results. Position \nencoding is an important component of the model. The EEG signal contains position information in both \nthe time and space domains. Transformer ensures that the model retains the location information by adding \nposition encoding to the input species. We investigate the effect of adding time-domain position encoding \nand space-domain position encoding on person identification separately. In addition to comparing spatial \nand temporal position encodings, we also conducted ablation experiments on the encoder part of ETST. We \ninvestigated the performance of ETST when removing TTE and STE respectively, to explore the role of each \nencoder part.\n3. In EEG identification methods, there has not been a consensus on the best segmentation length of samples. \nFor example, the segmentation length used by Wang et al. is  1s34, while the segmentation length used by \nThiago Schons et al. is  12s35, and there may be a large gap between the sample segmentation lengths of differ-\nent methods. Therefore, we divided the dataset with different split lengths in our experiments for exploring \nthe performance of ETST with different sample split lengths.\nIn addition to different segmentation lengths, the sample overlap rate also directly affects the size of the resulting \nsample size and the degree of information overlap among different samples. The loss function of Transformer is \nsmoother than that of  CNN36, which potentially makes Transformer more difficult to converge with smaller sam-\nple sizes, resulting in worse performance. Therefore, we design experiments with different sample overlap lengths \nand obtained training datasets with different sample sizes to explore the effect of sample size on our model.\nExperiment detail. All experiments in this paper are performed on NVIDIA TITAN Xp GPU. The number \nof TTE layers, the number of heads of TTE layers, the number of STE layers, and the number of heads of STE lay-\ners in the model are set to 2, 8, 2, and 8, respectively. We use the  AdamW37 optimizer with learning rate, weight \ndecay, and batch size of 4e−5, 1e−6, and 256, respectively, to optimize the network.\nResults and discussion\nEvaluation and comparison with baseline. Currently, EEG-based person identification algorithms \nare broadly classified into two categories. One is the traditional machine learning algorithms, which gener -\nally require manual feature extraction including power spectral density (PSD), auto-regressive coefficient (AR), \nand fuzzy entropy (FuzzEn). Another category is deep learning algorithms, such as CNN-based or RNN-based \nneural network models. In addition, since the concept of graph fits well with the functional connectivity in \nneuroscience, where graph features are used to represent the relationships among brain regions, graph convo-\nlutional neural networks (GCNN) are also gaining popularity in the field of EEG. Wang et al. computed Phase \nLocking Value (PLV) and Pearson’s correlation (COR) as the edge feature between nodes to construct graphs and \nachieved state-of-the-art  results34. We compared our method with other advanced  methods15. Also, we explored \nthe effect of the recent transformer-based models, which combine CNN and  attention38,39. Therefore, we used \nthe aforementioned methods as the baseline, and compared against the results of our model.\nIn the first experiment, we investigated the performance of ETST in the same single state. We trained and \ntested ETST on a single-state dataset to evaluate the mentioned performance.The results are shown in Table  1. \nThe experimental results show that our proposed method outperforms all methods when the data are in the same \nstate , except for one result which is slightly lower than that of GCNN, only 0.2% lower.\nThe EEG signals can vary drastically under different states, for example, delta waves are associated with \nincreased  attention40, alpha waves are related with various cognitive features such as task  performance41, while \nbeta waves are linked to movement or motor  imagery42. But for EEG biometrics to be practical in real life, the \nalgorithm needs to be robust to state changes. In other words, the model should be able to recognize the identity \nof the user in different states. Therefore, in the second experiment, we evaluate the generalization ability of our \nproposed method in different states by training and testing ETST on different datasets. EO and EC data were used \nas training sets and tested on PHY and IMA data, respectively. Table 2 shows the results of this experiment, which \nis the training set and test sets are across different states. The results show that ETST has a significant improve-\nment compared to other methods in the condition of different states. Compared with GCNN, the improvements \nare 10.3% in PHY and 10.27% in IMA. When the states in the training and test sets were different, all methods \nsuffered from performance degradation to a varying degree, with GCNN decreasing by about 13%, SVM by \nabout 40%, and the accuracy of the remaining methods dropping to less than 30%. This indicates that the other \n6\nVol:.(1234567890)Scientific Reports |        (2022) 12:14378  | https://doi.org/10.1038/s41598-022-18502-3\nwww.nature.com/scientificreports/\nmodels are limited to extracting features from the same states and have weak generalization ability for different \nstates. In contrast, the ETST model only decreases by about 3%, which indicates that the ETST is able to extract \nfeatures that are valid across diverse states.\nTo enhance the model’s robustness to various mental states, in addition to the strong generalization ability of \nthe model itself, another approach is to include multiple states in the training set and make the model learn to \nextract features common to all states. Hence, in the third experiment, we included all states in both the training \nand test sets, including EO, EC, PHY , and IMA. ETST achieves close to the best results, as shown in Table  3. \nCompared to results from the previous experiment, the results of this experiment show less decrease in accu-\nracy, and only SVM has a considerable decrease, down to 73%. It shows that different algorithms can achieve \ngood results in case the training and test sets contain all states data. However, this enhancement method is not \napplicable to realistic scenarios. Due to the complexity and variability of human states, it is impossible to contain \ndata of all states in the training set. Therefore, the key to solving the EEG-based person identification problem \nis to improve the generalization ability of the model among different states. And our proposed ETST possesses \na strong generalization ability.\nAblation experiment. In Transformer, self-attention calculates attention weights for all inputs simultane-\nously and sums the weights to obtain the output. In this process, self-attention considers the global information \nand discards the location information of the input data. For EEG data, the signal contains location information \nin both the time and space domains, representing different temporal sampling points and various brain regions, \nrespectively. To investigate the effect of location information in EEG on person identification, we tried retaining \nTable 1.  Results of models training and testing within each human state. Results are accuracy in testing stage \n(average  ±  standard deviation)%. Significant values are in [bold].\nMethod EO EC PHY IMA\nFuzzEn +  SVM34 84.14 ± 0.83 83.73 ± 0.71 77.93 ± 0.59 80.84 ± 0.18\nRaw +  CNN34 96.89 ± 0.77 67.43 ± 47.36 97.96 ± 1.55 97.42 ± 0.83\nGraph + Mahalanobis  distance15 99.07 ± 0.19 97.56 ± 0.24 99.74 ± 0.13 99.61 ± 0.11\nPLV +  GCNN34 99.97 ± 0.03 99.88 ± 0.03 99.99 ± 0.02 100.00 ± 0.00\nLite  transformer38 83.77 ± 17.39 85.57 ± 22.24 99.76 ± 0.01 99.65 ± 0.08\nEA-transformer39 98.45 ± 1.17 98.19 ± 3.14 99.93 ± 0.00 99.90 ± 0.01\nOurs 100.00 ± 0.00 99.96 ± 0.06 99.97 ± 0.01 100.00 ± 0.00\nTable 2.  Results of models training on resting states and testing on diverse states. Results are accuracy in \ntesting stage (average ± standard deviation)%. Significant values are in [bold].\nMethod PHY IMA\nFuzzEn +  SVM34 16.16 ± 0.01 15.61 ± 0.00\nRaw +  CNN34 49.26 ± 3.85 52.51 ± 2.26\nGraph + Mahalanobis  distance15 69.98 ± 0.38 69.47 ± 0.64\nPLV +  GCNN34 85.40 ± 1.62 87.03 ± 2.53\nLite  transformer38 87.37 ± 1.10 89.03 ± 0.73\nEA-transformer39 89.47 ± 0.34 90.66 ± 0.39\nOurs 97.29 ± 0.03 97.45 ± 0.13\nTable 3.  Results of models training on diverse states and testing on diverse states. Results are accuracy in \ntesting stage (average  ±  standard deviation)%. Significant values are in [bold].\nMethod Results\nFuzzEn +  SVM34 73.45 ± 0.10\nRaw +  CNN34 99.85 ± 0.06\nGraph + Mahalanobis  distance15 96.22 ± 0.23\nPLV+GCNN34 99.98 ± 0.02\nLite  transformer38 98.16 ± 0.65\nEA-transformer39 99.90 ± 0.01\nOurs 99.90 ± 0.03\n7\nVol.:(0123456789)Scientific Reports |        (2022) 12:14378  | https://doi.org/10.1038/s41598-022-18502-3\nwww.nature.com/scientificreports/\nthe location information of EEG by adding position encoding to the input of TTE and STE layers, respectively. \nWe compare the effect of adding positional encoding to ETST in the time and space domains under the cross-\nstate dataset, and the results are shown in Table 4. It shows that adding only the spatial position encoding pro-\nduced a better result than that of the temporal position encoding. This model design also yielded the best perfor-\nmance of our model (97% in IMA, 97% in PHY). Adding both temporal and spatial position encoding generated \nthe next best result (96% in IMA, 95% in PHY). We found that the model performance can be improved by \nadding the spatial information, while diminished by adding temporal information. In addition, by observing the \ntraining process of the model, we discovered that adding the location information in the time domain also affects \nthe training efficiency to a certain extent, making the model more likely to converge to worse minima, which \nleads to bad results. We believe that absolute position encoding in the time domain breaks the translation invari-\nance of EEG signals, thus making it more difficult for the model to extract time-domain features. The absolute \nspatial position encoding retains the position information of different channels. Unlike the same sampling point \nthat may appear in different locations in adjacent samples, the channel positions in samples are fixed. Thus, the \ninclusion of absolute position encoding in the space domain could instead improve the model’s ability for spatial \nfeature extraction.\nThe ETST model contains two parts, the TTE layer, and the STE layer, for extracting time-domain and space-\ndomain features, respectively. To illustrate the importance of the two distinct features on the experimental results, \nwe conducted ablation experiments under cross-state for the model to reflect the necessity of each part of our \nmodel. As can be seen in Table  5, we compared the results under the TTE, STE, and TTE + STE models. The \nresults indicate that using only the TTE layer or only the STE layer both make the accuracy significantly lower. \nMoreover, the results show that the TTE layer has a slightly higher classification accuracy than STE (75.19% in \nIMA and 72.98% in PHY vs. 70.22% in IMA and 68.98% in PHY). Therefore, it can be shown that time domain \ninformation is more important than space domain information for person identification. In order to acquire \nEEG temporal and spatial information simultaneously, our model consists of TTE and STE layers, which can \nconsiderably improve the performance of the model and thus achieve the state-of-the-art effect.\nEffect of sample length and sample size. The sample segmentation length varies in previous methods. \nAs a result, some methods may only work with shorter sample segmentation lengths, while others do the oppo-\nsite. The same method with samples of different split lengths may yield widely varying results. To illustrate the \ngeneralizability in sample length of our method, we compared the classification accuracy of the model under dif-\nferent segmentation length samples. It is worth noting that using a longer sample length would result in a smaller \nsample size. For example, the sample size of 5-s segmentation length is only about one-fifth of that of 1-s. From \nFig. 3, the 1-s length sample achieves the best results with the same overlap rate. Also, we can see that the longer \nthe sample length, the lower the classification accuracy. Namuk Park et al. 36 mentioned that for Transformer, \nthe size of the dataset directly affects the final training results due to its smoother loss function, i.e., transformer \nperforms worse with fewer samples.\nWe attempt to increase the number of samples by increasing the overlap rate of the sliding window. Data \naugmentation of the samples is performed using an overlap rate of 80% and the results are compared for differ-\nent training set sizes. As seen in Fig. 3, when we changed the overlap ratio to 80%, and thus enlarged the sample \nsize of the dataset by two times, the model accuracy increased. The 5-s accuracy rises to 95.44%, slightly lower \nby about 2% compared to the 1-s accuracy. This suggests that insufficient sample size of the data worsens the \nperformance of the transformer-based model. In general, regardless of the sample length, our model achieves \nstate-of-the-art results.\nTable 4.  Results of the ETST model with different position encoding. Significant values are in [bold].\nModels PHY IMA\nNon PE 95.84 ± 0.11 96.07 ± 0.03\nWith temporal PE 79.98 ± 13.03 80.89 ± 12.76\nWith spatial PE 97.29 ± 0.03 97.45 ± 0.13\nWith temporal + spatial PE 90.56 ± 1.94 91.20 ± 1.92\nTable 5.  Ablation study on the ETST model (without position encoding). Significant values are in [bold].\nModels PHY IMA\nWith TTE 72.98 ± 0.39 75.19 ± 0.09\nWith STE 68.98 ± 0.34 70.22 ± 0.47\nWith TTE + STE 95.84 ± 0.11 96.07 ± 0.03\n8\nVol:.(1234567890)Scientific Reports |        (2022) 12:14378  | https://doi.org/10.1038/s41598-022-18502-3\nwww.nature.com/scientificreports/\nConclusion\nIn this paper, we propose ETST, a deep learning model based on the attention mechanism. We used a multi-\nheaded attention mechanism to extract the temporal and spatial features of EEG signals. The temporal trans -\nformer encoder in the model is able to extract long-range distinguishable representations, and the spatial trans-\nformer encoder is capable to acquire spatial dependencies among channels, which characterizes the functional \nconnectivity among brain regions. In this way, through several rounds of attention weighting, the model is able \nto focus on the features that are most relevant to the true classification labels. The experimental results indicate \nthat our method achieves state-of-the-art accuracy on person identification, which also validates the feasibil -\nity of EEG on biometrics. The model is also robust to different states. The results of the ablation experiments \nshow that the temporal features have a relatively significant effect on the outcome of the EEG biometrics. It also \ndemonstrates that absolute position encoding in space enhances the model. This indicates that specific channels \nand the correlation among channels can both make an impact on person identification. The experiments demon-\nstrate that longer EEG data lead to a slight decrease in the performance of the attention mechanism. Besides, the \napplication of Transformer in EEG requires sufficient data to ensure its performance. Therefore, it is necessary to \ninvestigate the data argument method for EEG data in future studies. In addition, the choice of hyper-parameters \nfor our model is not yet optimal due to the limitation of time, which leads to the suboptimal model performance.\nThe stability and consistency problems are two key issues in implementing EEG biometrics into practical \napplications, and there is a need to ensure that the model can re-identify users correctly regardless of conditions \nand times. This requires the model to be able to extract time-invariant and state-invariant features. In future \nwork, we will explore new approaches to conduct more effective feature extraction for EEG signals. Potential \nmethods include filtering the alpha band features of EEG signals, which has a strong inter-individual variance \nin the resting state; and selecting the channels with strong correlation to person identification while removing \nthe effect of redundant channels. At the same time, experiments on EEG-based person identification on different \ndays are yet to be conducted.\nData availability\nThe dataset used for this study is publicly available and accessible online at PhysioNet Database [https:// physi  \nonet. org/ conte nt/ eegmm idb/1. 0.0/]32.\nReceived: 11 April 2022; Accepted: 12 August 2022\nReferences\n 1. Soomro, Z. A., Shah, M. H. & Ahmed, J. Information security management needs more holistic approach: A literature review. Int. \nJ. Inf. Manag. 36, 215–225 (2016).\n 2. Cappelli, R., Ferrara, M. & Maltoni, D. Minutia cylinder-code: A new representation and matching technique for fingerprint \nrecognition. IEEE Trans. Pattern Anal. Mach. Intell. 32, 2128–2141 (2010).\n 3. Masek, L. et al. Recognition of Human Iris Patterns for Biometric Identification. Ph.D. thesis, Citeseer (2003).\n 4. Guillaumin, M., Verbeek, J. & Schmid, C. Is that you? Metric learning approaches for face identification. In 2009 IEEE 12th Inter-\nnational Conference on Computer Vision 498–505 (IEEE, 2009).\n 5. Campisi, P . & La Rocca, D. Brain waves for automatic biometric-based user recognition. IEEE Trans. Inf. Forensics Secur. 9, 782–800 \n(2014).\n 6. Tan, D. & Nijholt, A. Brain–computer interfaces and human–computer interaction. In Brain–Computer Interfaces (eds Tan, D. S. \n& Nijholt, A.) 3–19 (Springer, 2010).\n 7. Min, B.-K., Marzelli, M. J. & Y oo, S.-S. Neuroimaging-based approaches in the brain–computer interface. Trends Biotechnol. 28, \n552–560 (2010).\n 8. Berkhout, J. & Walter, D. O. Temporal stability and individual differences in the human EEG: An analysis of variance of spectral \nvalues. IEEE Trans. Biomed. Eng. 3, 165–168 (1968).\n 9. Vogel, F . The genetic basis of the normal human electroencephalogram (EEG). Humangenetik 10, 91–114 (1970).\nFigure 3.  Results of the ETST model in different segment length and overlap.\n9\nVol.:(0123456789)Scientific Reports |        (2022) 12:14378  | https://doi.org/10.1038/s41598-022-18502-3\nwww.nature.com/scientificreports/\n 10. Van Dis, H., Corner, M., Dapper, R., Hanewald, G. & Kok, H. Individual differences in the human electroencephalogram during \nquiet wakefulness. Electroencephalogr. Clin. Neurophysiol. 47, 87–94 (1979).\n 11. Henry, C. E. Electroencephalographic individual differences and their constancy: I. During sleep. J. Exp. Psychol. 29, 117 (1941).\n 12. Henry, C. E. Electroencephalographic individual differences and their constancy: II. During waking. J. Exp. Psychol. 29, 236 (1941).\n 13. Ruiz-Blondet, M. V ., Jin, Z. & Laszlo, S. Cerebre: A novel method for very high accuracy event-related potential biometric iden-\ntification. IEEE Tran. Inf. Forensics Secur. 11, 1618–1629 (2016).\n 14. Kong, X., Kong, W ., Fan, Q., Zhao, Q. & Cichocki, A. Task-independent EEG identification via low-rank matrix decomposition. \nIn 2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 412–419 (IEEE, 2018).\n 15. Wang, M., Hu, J. & Abbass, H. A. Brainprint: EEG biometric identification based on analyzing brain connectivity graphs. Pattern \nRecognit. 105, 107381 (2020).\n 16. Moctezuma, L. A. & Molinas, M. Multi-objective optimization for EEG channel selection and accurate intruder detection in an \nEEG-based subject identification system. Sci. Rep. 10, 1–12 (2020).\n 17. Alyasseri, Z. A. A., Khader, A. T., Al-Betar, M. A. & Alomari, O. A. Person identification using EEG channel selection with hybrid \nflower pollination algorithm. Pattern Recognit. 105, 107393 (2020).\n 18. Yıldırım, Ö., Baloglu, U. B. & Acharya, U. R. A deep convolutional neural network model for automated identification of abnormal \nEEG signals. Neural Comput. Appl. 32, 15857–15868 (2020).\n 19. Wilaiprasitporn, T. et al. Affective EEG-based person identification using the deep learning approach. IEEE Trans. Cognit. Dev. \nSyst. 12, 486–496 (2019).\n 20. Özdenizci, O., Wang, Y ., Koike-Akino, T. & Erdoğmuş, D. Adversarial deep learning in EEG biometrics. IEEE Signal Process. Lett. \n26, 710–714 (2019).\n 21. Vaswani, A. et al. Attention is all you need. In Advances in Neural Information Processing Systems, vol. 30 (2017).\n 22. Dosovitskiy, A. et al. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv: 2010. \n11929 (2020).\n 23. Liu, Z. et al. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF International \nConference on Computer Vision 10012–10022 (2021).\n 24. Arjun, A., Rajpoot, A. S. & Panicker, M. R. Introducing attention mechanism for EEG signals: Emotion recognition with vision \ntransformers. In 2021 43rd Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)  \n5723–5726 (IEEE, 2021).\n 25. Lee, Y .-E. & Lee, S.-H. EEG-transformer: Self-attention from transformer architecture for decoding EEG of imagined speech. In \n2022 10th International Winter Conference on Brain–Computer Interface (BCI) 1–4 (IEEE, 2022).\n 26. Tao, Y . et al. Gated transformer for decoding human brain EEG signals. In 2021 43rd Annual International Conference of the IEEE \nEngineering in Medicine and Biology Society (EMBC) 125–130 (IEEE, 2021).\n 27. Song, Y ., Jia, X., Y ang, L. & Xie, L. Transformer-based spatial-temporal feature learning for EEG decoding. arXiv preprint arXiv: \n2106. 11170 (2021).\n 28. Kostas, D., Aroca-Ouellette, S. & Rudzicz, F . Bendr: Using transformers and a contrastive self-supervised learning task to learn \nfrom massive amounts of EEG data. Front. Hum. Neurosci. 15, 1–15 (2021).\n 29. Bagchi, S. & Bathula, D. R. EEG-convtransformer for single-trial EEG based visual stimulus classification. Pattern Recognit. 129, \n108757 (2022).\n 30. He, K., Zhang, X., Ren, S. & Sun, J. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer \nVision and Pattern Recognition 770–778 (2016).\n 31. Ba, J. L., Kiros, J. R. & Hinton, G. E. Layer normalization. arXiv preprint arXiv: 1607. 06450 (2016).\n 32. Goldberger, A. L. et al. Physiobank, physiotoolkit, and physionet: Components of a new research resource for complex physiologic \nsignals. Circulation 101, e215–e220 (2000).\n 33. Schalk, G., McFarland, D. J., Hinterberger, T., Birbaumer, N. & Wolpaw, J. R. BCI 2000: A general-purpose brain–computer interface \n(BCI) system. IEEE Trans. Biomed. Eng. 51, 1034–1043 (2004).\n 34. Wang, M., El-Fiqi, H., Hu, J. & Abbass, H. A. Convolutional neural networks using dynamic functional connectivity for EEG-based \nperson identification in diverse human states. IEEE Trans. Inf. Forensics Secur. 14, 3259–3272 (2019).\n 35. Schons, T., Moreira, G. J., Silva, P . H., Coelho, V . N. & Luz, E. J. Convolutional network for EEG-based biometric. In Iberoamerican \nCongress on Pattern Recognition, 601–608 (Springer, 2017).\n 36. Park, N. & Kim, S. How do vision transformers work? arXiv preprint arXiv: 2202. 06709 (2022).\n 37. Loshchilov, I. & Hutter, F . Decoupled weight decay regularization. arXiv preprint arXiv: 1711. 05101 (2017).\n 38. Wu, Z., Liu, Z., Lin, J., Lin, Y . & Han, S. Lite transformer with long-short range attention. arXiv preprint arXiv: 2004. 11886 (2020).\n 39. Wang, Y . et al. Evolving attention with residual convolutions. In International Conference on Machine Learning 10971–10980 \n(PMLR, 2021).\n 40. Harmony, T. et al. EEG delta activity: An indicator of attention to internal processing during performance of mental tasks. Int. J. \nPsychophysiol. 24, 161–171 (1996).\n 41. Jann, K., Koenig, T., Dierks, T., Boesch, C. & Federspiel, A. Association of individual resting state EEG alpha frequency and cerebral \nblood flow. Neuroimage 51, 365–372 (2010).\n 42. McFarland, D. J., Miner, L. A., Vaughan, T. M. & Wolpaw, J. R. Mu and beta rhythm topographies during motor imagery and actual \nmovements. Brain Topogr. 12, 177–186 (2000).\nAuthor contributions\nY .D. and Y .X. proposed the method, performed the experiments, and wrote the manuscript. X.W ., L.L., and P .M. \ngave guidance on the experiment and reviewed the manuscript.\nCompeting interests \nThe authors declare no competing interests.\nAdditional information\nCorrespondence and requests for materials should be addressed to X.W ., L.L. or P .M.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\n10\nVol:.(1234567890)Scientific Reports |        (2022) 12:14378  | https://doi.org/10.1038/s41598-022-18502-3\nwww.nature.com/scientificreports/\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from \nthe copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n© The Author(s) 2022",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8066136837005615
    },
    {
      "name": "Electroencephalography",
      "score": 0.7761114835739136
    },
    {
      "name": "Transformer",
      "score": 0.6822021007537842
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5660396218299866
    },
    {
      "name": "Biometrics",
      "score": 0.5629950761795044
    },
    {
      "name": "Generalization",
      "score": 0.47902289032936096
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.47005999088287354
    },
    {
      "name": "Speech recognition",
      "score": 0.45708584785461426
    },
    {
      "name": "Machine learning",
      "score": 0.3405952453613281
    },
    {
      "name": "Neuroscience",
      "score": 0.14649289846420288
    },
    {
      "name": "Psychology",
      "score": 0.0906897783279419
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210103346",
      "name": "Nanfang Hospital",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I58200834",
      "name": "Southern Medical University",
      "country": "CN"
    }
  ]
}