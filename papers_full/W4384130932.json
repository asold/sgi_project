{
    "title": "Transformer Models and Convolutional Networks with Different Activation Functions for Swallow Classification Using Depth Video Data",
    "url": "https://openalex.org/W4384130932",
    "year": 2023,
    "authors": [
        {
            "id": null,
            "name": "Lai, Derek Ka-Hei",
            "affiliations": [
                "Hong Kong Polytechnic University"
            ]
        },
        {
            "id": null,
            "name": "Cheng, Ethan Shiu-Wang",
            "affiliations": [
                "Hong Kong Polytechnic University"
            ]
        },
        {
            "id": null,
            "name": "So, Bryan Pak-Hei",
            "affiliations": [
                "Hong Kong Polytechnic University"
            ]
        },
        {
            "id": null,
            "name": "Mao, Ye-Jiao",
            "affiliations": [
                "Hong Kong Polytechnic University"
            ]
        },
        {
            "id": null,
            "name": "Cheung, Ming-Yan",
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "University of Hong Kong"
            ]
        },
        {
            "id": "https://openalex.org/A3042952903",
            "name": "Cheung Daphne Sze Ki",
            "affiliations": [
                "Hong Kong Polytechnic University"
            ]
        },
        {
            "id": null,
            "name": "Wong, Duo Wai-Chi",
            "affiliations": [
                "Hong Kong Polytechnic University"
            ]
        },
        {
            "id": null,
            "name": "Cheung, James Chung-Wai",
            "affiliations": [
                "Hong Kong Polytechnic University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2768205776",
        "https://openalex.org/W2023002118",
        "https://openalex.org/W2739658573",
        "https://openalex.org/W3111621800",
        "https://openalex.org/W2314996484",
        "https://openalex.org/W2125162604",
        "https://openalex.org/W2160246420",
        "https://openalex.org/W2294662980",
        "https://openalex.org/W2528182051",
        "https://openalex.org/W2097120324",
        "https://openalex.org/W2046537303",
        "https://openalex.org/W4241220453",
        "https://openalex.org/W2086304902",
        "https://openalex.org/W6601020226",
        "https://openalex.org/W1977570898",
        "https://openalex.org/W2125250238",
        "https://openalex.org/W1536973336",
        "https://openalex.org/W4313328820",
        "https://openalex.org/W4382468793",
        "https://openalex.org/W2586884333",
        "https://openalex.org/W1964678094",
        "https://openalex.org/W3082264823",
        "https://openalex.org/W2791514042",
        "https://openalex.org/W2031601906",
        "https://openalex.org/W2090037365",
        "https://openalex.org/W2895586864",
        "https://openalex.org/W2611410710",
        "https://openalex.org/W4296280690",
        "https://openalex.org/W4306743325",
        "https://openalex.org/W3195191735",
        "https://openalex.org/W2089916011",
        "https://openalex.org/W2624958217",
        "https://openalex.org/W3141564595",
        "https://openalex.org/W3009825789",
        "https://openalex.org/W2899318048",
        "https://openalex.org/W4283791586",
        "https://openalex.org/W2507009361",
        "https://openalex.org/W4247811648",
        "https://openalex.org/W2010315761",
        "https://openalex.org/W1677182931",
        "https://openalex.org/W2962834855",
        "https://openalex.org/W3130008318",
        "https://openalex.org/W2107878631",
        "https://openalex.org/W4214612132",
        "https://openalex.org/W2990503944",
        "https://openalex.org/W3034572008",
        "https://openalex.org/W2963155035",
        "https://openalex.org/W1966716734",
        "https://openalex.org/W4226042788",
        "https://openalex.org/W4280522591",
        "https://openalex.org/W2901795049",
        "https://openalex.org/W4319777935",
        "https://openalex.org/W2754998475",
        "https://openalex.org/W2026612570",
        "https://openalex.org/W4226017353",
        "https://openalex.org/W2141212940",
        "https://openalex.org/W2898280479",
        "https://openalex.org/W2786846101",
        "https://openalex.org/W3185107288",
        "https://openalex.org/W2765421612",
        "https://openalex.org/W2948551291",
        "https://openalex.org/W3044709444",
        "https://openalex.org/W6731705896",
        "https://openalex.org/W2086146067",
        "https://openalex.org/W4318486313",
        "https://openalex.org/W4205698889",
        "https://openalex.org/W3000238064",
        "https://openalex.org/W3213509763",
        "https://openalex.org/W2810623657",
        "https://openalex.org/W4213123767",
        "https://openalex.org/W6678059977",
        "https://openalex.org/W2979632005",
        "https://openalex.org/W4319763423",
        "https://openalex.org/W3174828871",
        "https://openalex.org/W2898898181",
        "https://openalex.org/W2120040939",
        "https://openalex.org/W3089670202"
    ],
    "abstract": "Dysphagia is a common geriatric syndrome that might induce serious complications and death. Standard diagnostics using the Videofluoroscopic Swallowing Study (VFSS) or Fiberoptic Evaluation of Swallowing (FEES) are expensive and expose patients to risks, while bedside screening is subjective and might lack reliability. An affordable and accessible instrumented screening is necessary. This study aimed to evaluate the classification performance of Transformer models and convolutional networks in identifying swallowing and non-swallowing tasks through depth video data. Different activation functions (ReLU, LeakyReLU, GELU, ELU, SiLU, and GLU) were then evaluated on the best-performing model. Sixty-five healthy participants (n = 65) were invited to perform swallowing (eating a cracker and drinking water) and non-swallowing tasks (a deep breath and pronouncing vowels: “/eɪ/”, “/iː/”, “/aɪ/”, “/oʊ/”, “/u:/”). Swallowing and non-swallowing were classified by Transformer models (TimeSFormer, Video Vision Transformer (ViViT)), and convolutional neural networks (SlowFast, X3D, and R(2+1)D), respectively. In general, convolutional neural networks outperformed the Transformer models. X3D was the best model with good-to-excellent performance (F1-score: 0.920; adjusted F1-score: 0.885) in classifying swallowing and non-swallowing conditions. Moreover, X3D with its default activation function (ReLU) produced the best results, although LeakyReLU performed better in deep breathing and pronouncing “/aɪ/” tasks. Future studies shall consider collecting more data for pretraining and developing a hyperparameter tuning strategy for activation functions and the high dimensionality video data for Transformer models.",
    "full_text": null
}