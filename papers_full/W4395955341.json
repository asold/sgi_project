{
  "title": "A hybrid approach based on multipath Swin transformer and ConvMixer for white blood cells classification",
  "url": "https://openalex.org/W4395955341",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5080412755",
      "name": "Hüseyin Üzen",
      "affiliations": [
        "Bingöl University"
      ]
    },
    {
      "id": "https://openalex.org/A5088428409",
      "name": "Hüseyin Fırat",
      "affiliations": [
        "Dicle University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3084048731",
    "https://openalex.org/W3179072224",
    "https://openalex.org/W3015930014",
    "https://openalex.org/W4206685736",
    "https://openalex.org/W3127507244",
    "https://openalex.org/W4367057203",
    "https://openalex.org/W4285811075",
    "https://openalex.org/W4307125956",
    "https://openalex.org/W4313570216",
    "https://openalex.org/W4313444241",
    "https://openalex.org/W4319337645",
    "https://openalex.org/W4281778627",
    "https://openalex.org/W4293163051",
    "https://openalex.org/W3138516171",
    "https://openalex.org/W4321232185",
    "https://openalex.org/W3034785488",
    "https://openalex.org/W6811014117",
    "https://openalex.org/W2770156338",
    "https://openalex.org/W2891686988",
    "https://openalex.org/W2910694919",
    "https://openalex.org/W2922911224",
    "https://openalex.org/W3128834636",
    "https://openalex.org/W3210906182",
    "https://openalex.org/W3094085775",
    "https://openalex.org/W2999005247",
    "https://openalex.org/W2981725153",
    "https://openalex.org/W3142761999",
    "https://openalex.org/W4307036886",
    "https://openalex.org/W2810323699",
    "https://openalex.org/W2783733999",
    "https://openalex.org/W3208778761",
    "https://openalex.org/W3032299950",
    "https://openalex.org/W4206204855",
    "https://openalex.org/W4206480139",
    "https://openalex.org/W4288046542",
    "https://openalex.org/W4292728542",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W2612445135",
    "https://openalex.org/W2968859244",
    "https://openalex.org/W4387754389",
    "https://openalex.org/W4367548179",
    "https://openalex.org/W4375868966",
    "https://openalex.org/W4313207645",
    "https://openalex.org/W3203232043",
    "https://openalex.org/W2995149037"
  ],
  "abstract": "Abstract White blood cells (WBC) play an effective role in the body’s defense against parasites, viruses, and bacteria in the human body. Also, WBCs are categorized based on their morphological structures into various subgroups. The number of these WBC types in the blood of non-diseased and diseased people is different. Thus, the study of WBC classification is quite significant for medical diagnosis. Due to the widespread use of deep learning in medical image analysis in recent years, it has also been used in WBC classification. Moreover, the ConvMixer and Swin transformer models, recently introduced, have garnered significant success by attaining efficient long contextual characteristics. Based on this, a new multipath hybrid network is proposed for WBC classification by using ConvMixer and Swin transformer. This proposed model is called Swin Transformer and ConvMixer based Multipath mixer (SC-MP-Mixer). In the SC-MP-Mixer model, firstly, features with strong spatial details are extracted with the ConvMixer. Then Swin transformer effectively handle these features with self-attention mechanism. In addition, the ConvMixer and Swin transformer blocks consist of a multipath structure to obtain better patch representations in the SC-MP-Mixer. To test the performance of the SC-MP-Mixer, experiments were performed on three WBC datasets with 4 (BCCD), 8 (PBC) and 5 (Raabin) classes. The experimental studies resulted in an accuracy of 99.65% for PBC, 98.68% for Raabin, and 95.66% for BCCD. When compared with the studies in the literature and the state-of-the-art models, it was seen that the SC-MP-Mixer had more effective classification results.",
  "full_text": "Üzen and Fırat  \nHealth Information Science and Systems  (2024) 12:33\nhttps://doi.org/10.1007/s13755-024-00291-w\nRESEARCH\n© The Author(s) 2024. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, \nwhich permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate \ncredit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were \nmade. The images or other third party material in this article are included in the article’s Creative Commons licence, unless \nindicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your \nintended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly \nfrom the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\nHealth Information Science \nand Systems\nA hybrid approach based on multipath Swin \ntransformer and ConvMixer for white blood cells \nclassification\nHüseyin Üzen1*   and Hüseyin Fırat2   \nAbstract \nWhite blood cells (WBC) play an effective role in the body’s defense against parasites, viruses, and bacteria in the \nhuman body. Also, WBCs are categorized based on their morphological structures into various subgroups. The num-\nber of these WBC types in the blood of non-diseased and diseased people is different. Thus, the study of WBC classifi-\ncation is quite significant for medical diagnosis. Due to the widespread use of deep learning in medical image analysis \nin recent years, it has also been used in WBC classification. Moreover, the ConvMixer and Swin transformer models, \nrecently introduced, have garnered significant success by attaining efficient long contextual characteristics. Based on \nthis, a new multipath hybrid network is proposed for WBC classification by using ConvMixer and Swin transformer. \nThis proposed model is called Swin Transformer and ConvMixer based Multipath mixer (SC-MP-Mixer). In the SC-\nMP-Mixer model, firstly, features with strong spatial details are extracted with the ConvMixer. Then Swin transformer \neffectively handle these features with self-attention mechanism. In addition, the ConvMixer and Swin transformer \nblocks consist of a multipath structure to obtain better patch representations in the SC-MP-Mixer. To test the perfor-\nmance of the SC-MP-Mixer, experiments were performed on three WBC datasets with 4 (BCCD), 8 (PBC) and 5 (Raabin) \nclasses. The experimental studies resulted in an accuracy of 99.65% for PBC, 98.68% for Raabin, and 95.66% for BCCD. \nWhen compared with the studies in the literature and the state-of-the-art models, it was seen that the SC-MP-Mixer \nhad more effective classification results.\nKeywords: White blood cell classification, Deep learning, Swin transformer, ConvMixer, Multipath mixer\nIntroduction\nBlood cells mainly consist of red blood cells, platelets \nand white blood cells (WBCs) [1]. Of these blood cells, \nWBCs are primarily responsible for the defense of the \nhuman body. They play an active role in the immune sys -\ntem because it protects the human body against various \nmicroorganisms such as parasites, viruses and bacteria \n[2]. WBCs are classified into distinct subgroups based \non their morphological configurations. These subgroups \nencompass Neutrophils, Eosinophils, Basophils, Lym -\nphocytes, Monocytes, Platelets, Erythroblasts and imma -\nture granulocytes such as promyelocytes, myelocytes, \nand metamyelocytes [3]. Each of these subgroups has \nthe role of defending the body against foreign pathogens. \nHence, the count of different WBC subgroups offers sub -\nstantial diagnostic insights into conditions like leukemia, \nAIDS, blood cancer, and anemia [4]. Accurate identifica -\ntion of the appropriate WBC holds considerable clinical \nimportance. The primary responsibility in this realm lies \nin categorizing WBCs within the bloodstream. How -\never, due to the morphological differences in the images \nof WBC subtypes, it is difficult to classify WBC images \ninto subtypes. Initially, classification of WBC images into \nsubtypes was performed with a hematology analyzer with \nthe help of a specialist hematologist. However, since this \nprocess is carried out manually, it is very time consum -\ning and can result in misclassification [5]. Lately, within \nthe realm of medical image analysis, there has been a fre -\nquent utilization of deep learning (DL), notably methods \n*Correspondence:  huzen@bingol.edu.tr\n1 Department of Computer Engineering, Faculty of Engineering \nand Architecture, Bingol University, Bingol, Turkey\nFull list of author information is available at the end of the article\nPage 2 of 19Üzen and Fırat  Health Information Science and Systems (2024) 12:33\nbased on Convolutional Neural Networks (CNNs) [6, \n7]. DL enhances classification accuracy through the \nautomated extraction of features [8]. CNN’s robust self-\nlearning abilities enable the extraction of more profound \nfeatures with richer semantic content from images [9, 10]. \nRecently, studies incorporating CNN-based approaches \nfor WBC classification have emerged and gained wide -\nspread use, diverging from traditional classifiers. How -\never, while CNN-based approaches have achieved success \nin image classification, they heavily rely on local receptive \nfields and pooling operations. They may struggle with the \nhigh intra-class variability and small object sizes in WBC \nimages. Moreover, their focus on local features (or recep-\ntive fields) may limit their ability to capture long-range \ncontextual information, crucial for distinguishing subtle \nmorphological variations among WBC types. This limi -\ntation hinders their potential to comprehensively under -\nstand the input and grasp complex relationships between \nvarious regions of the image. Additionally, CNN architec-\ntures often require meticulous engineering and optimiza-\ntion efforts to achieve optimal performance on specific \ndatasets, thereby reducing their flexibility and adaptabil -\nity. Unlike traditional CNNs that use spatial convolutions \nto extract features from images, the Swin Transformer \nmodel, employing self-attention mechanisms to cap -\nture relationships between different regions of an image, \ncan enhance performance. Additionally, ConvMixer can \neffectively extract local or spatial features from WBC \nimages due to its convolutional layers. Based on this, a \nhybrid approach that uses ConvMixer and Swin trans -\nformer models together is proposed in this study.\nThe Swin transformer and Vision Transformer (ViT) \nmodels, recently introduced, have seen widespread appli-\ncation across numerous studies within the domain of \nmedical image analysis [11–13]. These structures break \ndown the input and convert it into tokens. Then, these \ntokens are transformed into powerful long contextual \nfeatures with their self-attention mechanism. While the \nself-attention mechanism is quite effective in extracting \nlong context information, transformer blocks lose spa -\ntial details [14, 15]. In this context, some studies have \nused transformer blocks in the last layers of network \narchitectures [16, 17]. There are many benefits to adding \ntransformer blocks to the final layers of network archi -\ntectures. Transformers are adept at capturing long-range \ncontextual information within data [18]. But are poor at \ncapturing spatial details such as color and texture [19]. \nIn addition, in traditional CNNs, strong spatial details \nare obtained in the first layers while strong semantic \nfeatures are obtained in the last layers [19, 20]. By add -\ning transformers to the last layer, the model can learn \nmore complex relationships between different parts of \nthe image. Therefore, it can obtain more effective global \nfeatures by processing dense semantic features in the last \nlayer of network architectures. In addition, Transform -\ners focus on specific and relevant features in the pro -\ncessed data [21]. Therefore, giving strong initial features \nto transformer models facilitates the training of weights \nin the self-attention mechanism. Finally, transform -\ners obtain the output by associating all tokens with the \nself-attention mechanism they contain. Therefore, a large \nnumber of tokens increases the transaction cost expo -\nnentially [22]. Therefore, the lower spectral size obtained \nat the end of the network can reduce the transaction cost \nby obtaining a smaller number of tokens. On the other \nhand, Trockman et  al.[22], considering that the main \nsource of success of transformer models is fragmenta -\ntion, presented a new and effective structure with low \nparameters, called ConvMixer. ConvMixer is basically \ninspired by transformer models and aims to extract effec-\ntive features by segmenting the image. Additionally, Con-\nvMixer blocks use depth-separable convolution instead \nof the self-attention mechanism which has high process -\ning costs. Thanks to this structure, it enables to obtain \nstronger spatial features from the input image compared \nto transformers. In addition, they argue [22] that different \npart sizes and core sizes have an impact on performance. \nAlthough depth-separable convolution layers are an effi -\ncient structure with low processing costs, they cannot \nextract global features by directly associating part tokens \nas in the self-attention mechanism. Based on these, a new \nhybrid network architecture was developed using Con -\nvMixer and Swin transformer structures in this study to \nclassify WBCs. In this model, called Swin transformer \nand ConvMixer based Multipath mixer (SC-MP Mixer), \nConvMixer blocks extract features with strong spatial \ndetail, while Swin transformer networks effectively pro -\ncess these features with self-attention mechanism. Also, \nthe proposed model uses a multipath approach to obtain \nbetter patch representations for ConvMixer and Swin \ntransformer blocks. In this approach, ConvMixer and \nSwin transformer blocks are applied in parallel with dif -\nferent patch sizes. In this way, more effective features \ncan be obtained with different patch representations. In \nconclusion, our study’s primary contributions can be out-\nlined as follows:\n1. A new network architecture is designed by combin -\ning ConvMixer and Swin transformer structures in \nthe SC-MP-Mixer model.\n2. Stronger spatial and long-context informaton is \nobtained by using different patch representations in \nthe proposed model.\n3. In experimental studies on three different WBC data-\nsets, the SC-MP-Mixer model has achieved high suc -\ncess against the state-of-the-art models.\nPage 3 of 19\nÜzen and Fırat  Health Information Science and Systems (2024) 12:33\nThe rest of this study is structured accordingly. “Related \nworks” Sect. contains related literature, encompassing \nrecent studies. “Material and method ” , Sect. titled Mate-\nrial and Methods, elaborates on the datasets utilized in \nthe experiments and presents information about the SC-\nMP-Mixer model. “Experimental studies and results” \nSect. will cover the experiments conducted and their out-\ncomes. Lastly, “ Conclusions” Sect. serves as the conclu -\nsion, summarizing our findings and considering future \navenues.\nRelated works\nIn recent years, there have been numerous studies pro -\nposing DL approaches for WBC image analysis in the \nfield of microscobic blood cells. One of the common \nobjectives of these studies is to automate the diagnosis \nof blood diseases using WBC images, which can improve \ndiagnostic accuracy and reduce the workload of hema -\ntologists. Recent studies of blood diseases abnormalities \nwith WBC images have shown that manual evaluation of \nmultiple WBC images is laborious and requires expertise. \nIn this direction, efficient intelligent DL, especially CNN-\nbased methods have been developed to assist hematolo -\ngists in their tasks. Thanks to these methods, correct \ntreatment recommendations are shown by automatically \nextracting the image features through convolutions, pro -\ncessing and analyzing the image data. Also, the use of \nCNN-based methods showed better classification perfor -\nmance in feature extraction, making them cutting edge \nfor deep learning applications. Efficient use of CNN has \ndeveloped tasks related to image classification and recog -\nnition. Some of the studies using CNN in the literature \nare given below.\nShahin et al. [23] introduced a novel approach, WBC -\nsNet, for WBC classification, employing a deep CNN \narchitecture. This method integrates three convolutional \nlayers, two pooling operations, four ReLUs, two fully \nconnected (FC), and Softmax layers. To assess WBCs -\nNet’s classification efficacy, experiments were conducted \nusing a dataset comprising 2551 images featuring 5 dis -\ntinct WBC types. The experimental findings revealed \na classification accuracy of 96.1%. Bani-Hani et  al. [24] \napplied a CNN approach to categorize four categories \nof WBC images: eosinophils, neutrophils, lymphocytes \nand monocytes. Additionally, they employed the genetic \nalgorithm to optimize the hyperparameters within the \nCNN methodology. Upon analyzing the results from \nthe BCCD dataset, an overall accuracy of 91.01% was \nachieved. Tiwari et  al. [25] created a novel CNN struc -\nture for WBC classification. The approach integrates two \nconvolution, pooling, FC, and classification layers. After \napplying this method to a dataset containing around \n13,000 WBC images, a classification accuracy of 78% was \nachieved for four distinct WBC types. Sharma et al. [26] \nperformed experiments employing the LeNet5 model to \nclassify WBCs. The experimental investigations on the \nBCCD dataset, consisting of four classes, resulted in an \naccuracy of 87.93%. Banik et  al. [27] suggested a CNN \nmodel designed for WBC classification, comprising five \nconvolutional layers, three maximum pooling layers, \nand a FC layer. Within this CNN structure, the feature \nmaps from two convolutional layers are merged using \nmaximum pooling before being fed into the FC layer. \nTo evaluate the CNN’s classification prowess, tests were \nconducted using the BCCD dataset, encompassing 4 \nWBC classes. The experimental analysis revealed a clas -\nsification outcome of 90.79%. Yao et  al. [28] introduced \nthe weighted optimized deformable CNN method, com -\nprising two modules, for WBC classification. Evaluating \nthis method’s performance involved conducting experi -\nments using the BCCD dataset, which encompasses four \nWBC classes. The experimental outcomes yielded values \nof 91.6% for precision, recall and F1-score. Sharma et al. \n[29] presented a fast traditional CNN method for WBC \nclassification. This method consists of three convolution \nand three FC layers. However, each convolution layer \nincludes ReLU, max-pooling and dropout layers. When \nthe results of the experimental studies performed on the \nfour-classes BCCD dataset are examined, it is seen that \nthe classification accuracy of 84.64% was obtained. Uçar \n[30] suggested ShuffleNet architecture for WBC classifi -\ncation. With this method, as a result of the experimen -\ntal studies carried out on the eight-class dataset, 97.94% \nclassification accuracy was obtained.\nIn addition to studies using only CNN-based methods, \nanother method used in the literature is the hybrid meth-\nods developed together with CNN for WBC classifica -\ntion. Patil et al. [1] devised a deep hybrid DL technique \nfor WBC classification based on canonical correlation \nanalysis (CCA), integrating LSTM and CNN. Through \nthe CCA, the method extracts diverse, intersecting fea -\ntures from the input image, elevating its accuracy in \ncomparison to similar DL approaches. The classifica -\ntion accuracy obtained from experiments conducted on \nthe BCCD dataset stands at 95.89%. Baydilli et  al. [31] \nintroduced a technique known as capsule networks for \ncategorizing WBCs into five different types. The cap -\nsule networks are fundamentally comprised of two main \ncomponents: an encoder and a decoder. The role of the \ndecoder is to reconstruct the image, whereas the encoder \nis tasked with extracting features from the image and \nperforming classification. The accuracy of this classifi -\ncation was assessed using the LISC dataset, comprising \n263 images of WBCs. The implementation of this method \nrevealed an accuracy of 96.86%. Şengür et al. [32] intro -\nduced a hybrid approach for WBC classification, merging \nPage 4 of 19Üzen and Fırat  Health Information Science and Systems (2024) 12:33\nimage processing techniques with DL. Following the \napplication of diverse image processing methodologies \n(RGB to HSV transformation, conversion from color to \ngrayscale, filtering and thresholding) on WBC images, \nthe WBC classification employed the LSTM technique. \nEvaluating the performance of experiments on the BCCD \ndataset to assess the hybrid method’s classification, an \naccuracy of 92.89% was achieved. Ekiz et  al. [33] devel -\noped a fusion of CNN and Support Vector Machine \n(SVM) to classify WBC images utilizing a BCCD dataset \ncontaining four distinct classes. Their approach led to an \naccuracy of 85.96%.\nSome studies use only pre-trained architectures for \nWBC classification, while others create hybrid meth -\nods using pre-trained architectures and different tech -\nniques. Tseng et  al. [34] used 10 different pre-trained \nCNN architectures to classify six WBC types (segmented \nneutrophil, banded neutrophil, metamyelocyte, mye -\nlocyte, promyelocyte, myeloblast) in a dataset of 26,050 \nWBC images. The accuracy values obtained as a result \nof experimental studies with these 10 different CNN \narchitectures are as follows: DenseNet (85.7%), ResNeSt \n(88.2%), MobileNet (87.0%), InceptionV3 (85.7%), \nResNeXt (87.9%), InceptionResNetV2 (87.0%), RegNetY \n(87.3%), RegNetZ-C (87.5%), RegNetZ-D (88.6%), Con -\nvNeXt (88.0%). Liang et  al. [35] a hybrid method for \nWBC classification, which is a combination of LSTM \nand pre-trained Xception architectures. To evaluate the \nclassification efficacy of their proposed approach, experi -\nments were conducted using the BCCD dataset, which \nencompasses 4 WBC classes. The experimental inves -\ntigations yielded an average accuracy of 90.79%. Fur -\nthermore, within this study’s framework, classification \naccuracy outcomes on the same dataset were observed at \n88.58% for LSTM + ResNet50 + InceptionV3, 89.38% for \nLSTM + ResNet50 and 87.45% for LSTM + InceptionV3. \nYu et al. [36] devised an approach for WBC classification, \namalgamating pre-trained Xception, VGG 16–19, Incep -\ntionV3, and ResNet50 architectures. This hybrid method \nunderwent testing on a dataset comprising 2000 images \nfeaturing seven distinct WBC classes. The attained clas -\nsification accuracy stood at 88.5%. Baby et  al. [37] sug -\ngested a hybrid method consisting of a combination of \nSVM and pre-trained DL architectures for WBC classifi -\ncation. They used Xception, InceptionV3, MobileNetV2, \nDenseNet121 and ResNet50 as feature extractors. They \nalso utilized the extra trees classifier as an intermediate \nstep to select the most selective features. Finally, they uti-\nlized the multi-class SVM for classification. For the per -\nformance analysis of this hybrid method, they performed \nexperiments on a dataset of 431 WBC images contain -\ning 4 classes. According to the experimental studies per -\nformed, the classification accuracy results obtained are as \nfollows: ResNet50 + SVM (90.76%), DenseNet121 + SVM \n(72.3%), MobileNetV2 + SVM (87.69%), Incepi -\ntonV3 + SVM (76.92%), and Xception + SVM (70.26%).\nUpon reviewing the literature, it is evident that CNN-\nbased approaches, CNN-based hybrid methods, and \npretrained models are frequently employed in WBC clas -\nsification. Within the same class, WBCs may exhibit sig -\nnificant morphological differences in terms of size, shape, \ntexture, and nucleus-cytoplasm ratio, which can be cru -\ncial for WBC classification. Primarily, CNNs that focus \non local features may not effectively capture long-range \ndependencies among different image regions. These \ndependencies, critical for distinguishing subtle morpho -\nlogical variations that differentiate WBC types, may not \nbe adequately addressed by CNN-based pretrained mod -\nels or hybrid methods. While additional techniques may \noffer some improvements, the fundamental challenges of \nCNNs may persist. To address the importance of captur -\ning long-range dependencies in WBC classification, this \nstudy proposes a method combining Swin Transformer \nwith ConvMixer. The Swin Transformer component alle-\nviates a significant limitation by capturing long-range \ndependencies among different image regions, enabling \nanalysis of relationships between various parts of WBCs, \nsuch as the size and position of the nucleus relative to the \ncytoplasm. This allows the model to better understand \nthe overall morphology of WBCs, leading to enhanced \ndifferentiation among cell types with subtle differences. \nAdditionally, ConvMixer preserves the strength of CNNs \nin extracting local features from WBC images through its \nconvolutional layers, effectively capturing tissues, shapes, \nand fundamental structures within WBCs. By combining \nConvMixer and Swin Transformer, the model may learn \nmore robust and transferable features even with limited \ntraining data. Leveraging both local features and long-\nterm dependencies, the model can derive more informa -\ntive representations from the data, potentially leading to \nbetter generalization capabilities. To assess the effective -\nness of the proposed model, the BCCD, PBC, and Raabin \nblood cell datasets were utilized. In the BCCD dataset, \nto ensure a fair comparison, the original dataset’s train -\ning and test examples were used as is. However, for the \nPBC and Raabin datasets, they were split into 70% for \ntraining, 15% for testing, and 15% for validation. Through \nextensive experimental studies, accuracy values of 95.66, \n99.65, and 98.68% were achieved for the BCCD, PBC, and \nRaabin datasets, respectively.\nMaterial and method\nSwin transformer (SwTrans)\nTransformers have received a lot of attention in the field \nof natural language processing since they were first pub -\nlished [38, 39]. The highlighting feature of transformers is \nPage 5 of 19\nÜzen and Fırat  Health Information Science and Systems (2024) 12:33\nthat they have a self-attention mechanism that examines \nthe relationship between words. It basically examines the \nrelationship between all words in the mechanism of self-\nattention. In this way, it treats the input as a whole. The \nConvolution layer in CNN architectures processes infor -\nmation as much as the filter size. This situation is defined \nas regionality (locality of convolution operations) in the \nliterature. On the contrary, because it processes all the \ninput as a whole in transformers, it obtains strong global \nsemantic attributes (long-range contextual information) \n[39]. Dosovitskiy et  al. [38] proposed the ViT model to \nadapt transformers to the field of computer vision (CV) \nin 2020. In the ViT model, tokens are obtained by first \nfragmenting the image. Then, global semantic details \n(long-range contextual information) were obtained by \npassing the tokens through the self-attention struc -\nture. In this way, unlike the convolution layers that deal \nwith the relationship (filtering) between certain regions, \nstrong features are obtained with this structure. With the \ndevelopment of the ViT model, transformers have been \nactively applied in the field of CV and have become quite \ncommon recently [14, 38, 40–42].\nAlthough the ViT transformer model gives successful \nresults in image classification, it is time consuming and \ncostly because all parts are associated with each other in \nthe transformer model [16, 38]. It is also stated to be weak \nfor CV problems such as detection and segmentation, as \nall parts are associated together [14, 15, 17]. The SwTrans \n(Fig. 1) is proposed to decrease the computational com -\nplexity of the ViT model and to exhibit a strong trans -\nformer structure for segmentation. In the SwTrans model, \nthe local window model is used when evaluating the rela -\ntionship between the parts. In this way, the self-attention \nmechanism was applied only to the parts inside the win -\ndow instead of all the parts. Then, these windows are \nscrolled and the patches inside the window are changed \nand the process continues. For detailed information, see \n[14, 15, 17].\nAs can be seen in Fig.  1, the SwTrans model consists of \ntwo steps. In the first step, the parts inside the windows \nWindow based MSA (W-MSA) module was applied. In the \nsecond step, the parts inside the window were changed by \nsliding the windows. After scrolling, the Shifted Window \nbased MSA (SW-MSA) module is applied. In this way, \nthe SwTrans model evaluates the relationship between \nthe parts in different regions at a lower cost than the ViT \nmodel. SwTrans output (z) is calculated as in Eq. (1) [14]:\n(1)\nˆzl= WMSA\n(\nLN\n(\nzl−1\n))\n+ zl−1\nzl= MLP\n(\nLN\n(ˆzl\n))\n+ ˆzl\nˆzl+1 = SWMSA (LN (zl)) + zl\nzl+1 = MLP\n(\nLN\n(ˆzl+1\n))\n+ ˆzl+1\nFig. 1 SwTrans BLOCK\nPage 6 of 19Üzen and Fırat  Health Information Science and Systems (2024) 12:33\nIn Eq. (1), zl and zl+1 denote the output feature vector \nof the WMSA and SWMSA, respectively. MLP(.) repre-\nsents multi-layer perceptron. In addition, the multi-layer \nperceptron function is basically the application of fully \nconnected, GELU and dropout layers, respectively.\nConvMixer\nThe ViT model has opened a new era in DL [41, 43]. \nHowever, the self-attention mechanism of the ViT model \nhas second-order complexity. Therefore, the ViT model \nrequires a high level of data and hardware requirements \n[22, 43]. Based on these problems, Trockman et al. [22] \ndeveloped the ConMixer model by researching the per -\nformance source of the ViT model.\nTrockman et al. thought that it could have a high suc -\ncess since it basically used a piece of image instead of \npixels in the ViT model [22]. Starting from this point, he \ndivided the input image into patches, as it did with the \nMLP mixer and the ViT model. It then applied a series \nof convolution operations to the output representing the \npatches. In the ConvMixer model, a convolution is used \nto split the image into patches. In this convolution layer, \nthe kernel and step set the value to the patch size (p). This \nprocess is shown below:\nThe z0 and p given in Eq.  (2) represent the output of \nsplitting the image into patches and the patch size. As \nshown in Eq. (2), after the convolution process, GELU (σ) \nand Batch normalization (BN) layers were applied, \nrespectively. In addition, the number of filters in the con-\nvolution operation is taken as h . As a result of Eq.  (2) \n(2)z0 = BN\n(\nσ\n(\nConv stride:p\nkernal:p\n(\nimage\n)))\noperations, an input image of W × H size and an output \nof  W\np × H\np × h size were obtained. Each array of pixels \n( 1 × 1 × h ) in this output represents different versions of \na patch of size A.\nConvMixer has transferred the z0 output obtained \nin Eq.  (2) output to a depthwise separable convolution \nblock. This convolution block is shown in Eq. (3).\nAs shown in Eq. (3), the depthwise separable convolu -\ntion block consists of two stages. These are, respectively, \ndepthwise convolution and pointwise convolution. After \neach convolution operation, GELU (σ) and BN opera -\ntions were implemented, respectively. Also, as shown in \nEq. (2), the ConvMixer has Residual skip connections as \nin the ViT model.\nProposed method\nIn this study, a new hybrid method based on the popular \nConvMixer and SwTrans is proposed. This model, called \nSwTrans and ConvMixer based Multipath mixer (SC-\nMP-Mixer), is given in Fig. 2.\nIn this section, the SC-MP-Mixer module is discussed \nin three stages. In the first stage, three different Con -\nvMixers were applied parallel to the input image. The \nmain idea here is to extend the notion of patches that the \nConvMixer model is based on. Starting from this point, \nthree different patch sizes were used while obtaining the \npatches. Then ConvMixer was applied for each patch and \nfinally ConvMixer combined the outputs. In the combin -\ning process, element-based aggregation was performed.\n(3)\nzl′=BN\n(\nσ\n(\nDepthWiseConv\n(\nzl−1\n)))\n+ zl−1\nzl = BN (σ (PointWiseConv(zl′)))\nFig. 2 Proposed method\nPage 7 of 19\nÜzen and Fırat  Health Information Science and Systems (2024) 12:33\nIn the second stage of the SC-MP-Mixer model, pow -\nerful long-range contextual information is obtained by \nusing ConvMixer outputs. At this point, the Swin trans -\nformer model, which is more economical than the ViT \nmodel, is used. In addition, as in the first stage, a Swin \ntransformer was applied in two different ways, with patch \nsizes of 2 and 4. The two outputs obtained at the end of \nthe second stage were combined. The final stage of the \nSC-MP-Mixer is the classification stage. GAP (Global \nAverage Pooling) fully connected layer was applied to \nthe feature map obtained at the end of the second stage. \nFinally, the classification prediction output is obtained by \napplying the softmax layer to the fully connected layer \noutput.\nIn the rest of this section, the stages of the SC-MP-\nMixer are discussed in detail.\nStage 1: multipath ConvMixer (MPCM)\nThe main starting point of the ConvMixer model is to \nobtain an affordable and high-performance model by \ntreating the image in patches. However, the selection \nof an effective patch size poses a new problem. Some \nimages, especially images of WBCs, often have a very \nsimilar background. In addition, the object size of the \nobjects in the images is uncertain and homogeneous. \nBased on this problem, the Multipath ConvMixer \n(MPCM) model was developed for the effective patch \nwidth for ConvMixer in the SC-MP-Mixer model. The \nproposed structure is shown in Fig. 3 .\nAs can be seen in Fig.  3, 3 ConvMixer blocks are used \nin parallel in the MPCM model. In the patching block, \nwhich is the first stage of these ConvMixer blocks, the \nimage is divided into patches. The patch size (p) value \nused in this block is 2, 4 and 8, respectively. Then the \npatching output fed the ConvMixer layers. Depthwise \nconvolution and pointwise convolution operations were \nperformed in ConvMixer blocks, respectively. In addi -\ntion, GELU activation and BN layer were applied after \neach convolution operation. There are also resudial \nconnections in the ConvMixer block as shown in Fig.  3. \nIn the MPCM model, the depth value of each Conv -\nMixer block is taken as 4. In addition, the kernel size of \nthe Depthwise convolution is 3 and the filter number of \nthe pointwise convolution is 128 in ConvMixer blocks.\nToward the output of the MPCM model, each Con -\nvMixer outputs feature maps are combined with ele -\nment-wise aggregation operation. For the merging \nprocess, the feature maps of three different sizes were \nfirst brought to the same size as the UpSampling layer. \nFig. 3 Multipath ConvMixer (MPCM)\nPage 8 of 19Üzen and Fırat  Health Information Science and Systems (2024) 12:33\nThen, element-wise aggregation process was applied. \nThis process is formulated as follows:\nIn Eq. (4), FC1 , FC2  and FC3 are the output feature maps \nof the ConvMixer blocks shown in Fig.  3. On the other \nhand, Up s  represents the UpSampling layer with s stride \nvalue. Finally, Foutput is the feature map acquired in the \noutput of the MPCM module.\nStage 2: multipath Swin transformer (multipath \nSwTrans‑MPST)\nThe ConvMixer model has been applied in many studies \nand its superiority has been proven. On the other hand, \nSwTrans models with self-attention mechanisms are very \neffective in obtaining long-range context information. \nTherefore, in the SC-MP-Mixer model, SwTrans blocks \nare used to obtain long-range contextual information \nmodels.\nIn the second stage of the proposed SC-MP-Mixer \nmodel, two SwTrans blocks with different patch sizes \nare used as in the MPCM model. Thanks to this struc -\nture called Multipath SwTrans (MPST) module, it has \nbeen observed that stronger global semantic features are \nobtained (see experimental study). The proposed MPST \nmodel is shown in Fig. 4.\nAs shown in Fig.  4, two different SwTrans blocks are \napplied in parallel in the MPST model. SwTrans blocks \nare based on handling the relationship between patches \n(4)Foutput = FC 1 ⊕ Up s=2(FC 2) ⊕ Up s=4(FC 3)\nusing the self-attention mechanism. Therefore, the input \nimage has to be split into patches. In the Patch Extraction \nprocess suggested in the MPST blog, a convolution pro -\ncess is applied first. The applied convolution operation is \nformulated as in Eq. (5).\nThe k shown in Eq. (5) represents the number of filters. \nThe k value is determined by the formula k = 256/p2 ( p is \npatch size). The main purpose of this formula is to avoid \nexcessive processing cost caused by self-attention applied \nin SwTrans. In the second step of the Patch Extrac -\ntion process, the 112 × 112 × k  feature map is divided \ninto patches of p × p × k size. After fragmentation, \n112/p × 112/p patch was obtained. Finally, each patch \nobtained was vectorized and combined. As a result of the \nprocess, a vectorized feature map of 112/p 112/p × p2k \nwas obtained. Since k value is given as k = 256/p2 , the \np2k result given here is obtained as 256. These operations \nare shown as in Eq. (6).\nThe M feature map shown in Eq. (6) represents the fea -\nture map from which the swin transforms are fed. In the \nMPST model, SwTrans operation was applied to the M \nfeature map twice. Details of the SwTrans are given in \nSect.  “Swin transformer (SwTrans)” . As shown in Fig.  4, \nthe patch size value in the patch extraction process \n(5)L112×112×k = Convk(F112×112×128)\n(6)M 112\np .112\np ×256 = Reshape\n(\npatching\n(\nL112×112 ×k\n))\nFig. 4 Multipath SwTrans (MPST)\nPage 9 of 19\nÜzen and Fırat  Health Information Science and Systems (2024) 12:33\napplied in parallel in the MPST model is taken as 2 and 4, \nrespectively. On the other hand, the number of neurons \nof the MLP in the SwTrans is 256.\nStage 3: Classification\nThe final stage of the proposed SC-MP-Mixer model \nis the classification stage. At this stage, the features \nobtained from the SwTranss were first combined. As \nshown in Fig.  4, a 980 × 256 feature map was obtained \nas a result of the concatenating process. Then, the GAP \nprocess was implemented to the obtained feature map. \nFinally, the FC and softmax layer are used to obtain a \nclassification prediction output. These processes are \nexpressed as follows.\nShown here is the final feature map used for the Fﬁnal \nclassification, measuring 980 × 256. It is a FC layer with c \nneurons used for FCc classification. Finally, the value of c \nrepresents the number of classes.\nThe categorical Cross-Entropy loss function was used \nin training the proposed SC-MP-Mixer architecture. The \nformalization of the Categorical Cross Entropy loss func -\ntion is shown in Eq. (8).\nwhere L denotes the loss value of the classification net -\nwork. Y and P denote the expected and prediction, \nrespectively. M represents the number of classes and k \nrepresents the index of classes.\nBlood cell datasets\nTo evaluate the classification outcomes of our SC-MP-\nMixer model in this study, experiments were conducted \nusing three distinct WBC image datasets. The initial \ndataset, BCCD, encompasses four WBC types: Neutro -\nphils (N), Eosinophils (EO),Lymphocytes (L) and Mono -\ncytes (M). It comprises a total of 12,444 microscopic \nWBC images, each sized at 320 × 240 pixels and format -\nted as RGB images [44]. Within BCCD dataset, individual \nfolders include training and testing images corresponding \n(7)\nFﬁnal = GAP (concat(N 784×256 ,N 196×256 ))\nprediction= Softmax\n(\nFC c\n(\nFﬁnal\n))\n(8)L =−\nM∑\nk\nYklog(Pk)\nto each of the four WBC types. The BCCD encompasses \na total of 12,444 microscopic WBC images, comprising \n2499 N, 2478 M, 2483 L, and 2497 EO images for train -\ning, along with 623 EO, 620 L, 620 M and 624 N images \nfor testing. The second dataset (PBC) originates from \nAnna et al. and is publicly accessible, gathered at the Bar-\ncelona hospital clinic [3]. The PBC dataset encompasses a \ntotal of 17,092 PBC images. These images were captured \nfrom healthy individuals without any pharmacological \ntreatment, infectious diseases, hematological or onco -\nlogical. The images in the PBC dataset are in RGB format, \nsized at 360 × 363 pixels. Moreover, specialized patholo -\ngists at the hospital provided labels for these images. \nThe dataset comprises 8 distinct WBC types, namely N, \nEO, L, M, Basophils (B), Platelets (P), immature granu -\nlocytes (IG) such as promyelocytes, myelocytes, meta -\nmyelocytes and Erythroblasts (ER). The Raabin dataset, \na sizable open-access collection released in 2021, con -\nstitutes the third dataset analyzed in this study [45]. \nWithin this dataset, three distinct sets of cropped WBC \nimages exist: Train, Test-A, and Test-B. While both the \nTrain and Test-A sets underwent labeling by two separate \nexperts, the Test-B images lack comprehensive labeling. \nConsequently, our study focused solely on the Train and \nTest-A sets, sourced from 56 ordinary peripheral blood \nsmears (representing L, M, N, and EO) and one instance \nof chronic myeloid leukemia (representing basophil). \nThe Raabin dataset encompasses five WBC types (M, L, \nEO, N, and B), totaling 14,514 microscopic WBC images. \nAmong these are 212 B, 6231 N, 561 M, 2427 L and 744 \nEO images for training, and 89 B, 322 EO, 1034 L, 234 M \nand 2660 N images for testing purposes. Table  1 con -\ntains details about WBC types and sample images across \nthree datasets. Furthermore, Fig.  5 showcases illustra -\ntive images representing WBC subtypes present in the \nRaabin, PBC, and BCCD datasets.\nExperimental studies and results\nNumerous experimental investigations were conducted \nto meticulously analyze the classification accuracy of our \nSC-MP-Mixer model. This section presents these experi -\nmental studies. Within this section’s progression, initial \nfocus is placed on elaborating the parameter settings. \nSubsequently, the classification performance outcomes \nobtained from experiments conducted on three datasets \nTable 1 Detailed information about the BCCD, PBC and Raabin datasets\nDataset Blood cell types ER P IG M L B EO N Total\nBCCD Number of images – – – 3098 3103 – 3120 3123 12,444\nPBC Number of images 1551 2348 2895 1420 1214 1218 3117 3329 17,092\nRaabin Number of images – – – 795 3461 301 1066 8891 14,514\nPage 10 of 19Üzen and Fırat  Health Information Science and Systems (2024) 12:33\nutilizing our SC-MP-Mixer model are delineated. Lastly, \ncomparisons were drawn with analogous studies found in \nthe existing literature.\nParameter settings\nThe experimental studies utilized BCCD, PBC and Raabin \ndatasets. The BCCD dataset was originally allocated for \n9957 samples in training and 2487 samples in testing. To \nensure a fair comparison, we used the training and test \nexamples in the dataset as is. Additionally, 15% of the \ntraining samples were set aside for validation purposes. \nIn contrast, for the PBC and Raabin datasets, the training \nand test samples were not separated in the original data -\nset, so we partitioned them into specific proportions. The \nPBC and Raabin dataset was divided into 70% training, \n15% validation, and 15% testing.\nThe experimental studies were conducted on a com -\nputer equipped with an Intel i9 processor, 64 GB RAM, \nand an RTX 3080 Ti graphics card. The design of the deep \nlearning model utilized the Python programming lan -\nguage and the Keras-TensorFlow library. In the training \nof deep learning models, a learning rate of 0.0001, a batch \nsize of 16, and 100 epochs were employed. Additionally, \nthe Adam method was used for parameter optimization.\nIn the first stage of the proposed SC-MP-Mixer mod -\nule, 3 different ConvMixers (CM1, CM2, and CM3) were \nused in parallel with the input image. The p (patch size) \nvalues were 2, 4, and 8 for CM1, CM2, and CM3, respec -\ntively. In addition, the number of filters and depth size \nML EO N\nBCCD dataset\nER PI GM\nL B EO N\nPBC dataset\nL M N EO B\nRaabin dataset \nFig. 5 Representative images for WBC subtypes included in the Raabin, PBC, and BCCD datasets\nPage 11 of 19\nÜzen and Fırat  Health Information Science and Systems (2024) 12:33\nused in all ConvMixer models were 128 and 4, respec -\ntively. Additionally, the s values used in the upsampling \nlayers were set to 2 and 4 (see “Proposed method ” or \n“Stage 1: Multipath ConvMixer (MPCM)” Sects.). On the \nother hand, two Swin Transformers were used in the sec-\nond part of the proposed model. The p values here are set \nto 2 and 4, respectively, for the patching process of each \nSwin Transformer (see “Proposed method ” or “Stage 2: \nmultipath Swin transformer (multipath SwTrans-MPST)” \nSects.). Finally, the c values in the classification process \nwere set as 4 for the BCCD dataset, 8 for the PBC data -\nset, and 5 for the Raabin dataset.\nThe evaluation of the SC-MP-Mixer model’s efficiency \nwas performed using criteria such as classification accu -\nracy (Acc), recall (Re), F1-score (F1s) and precision (Pr). \nThese evaluation criteria provide an objective and quan -\ntitative measure of the model’s prediction effectiveness, \nessential for performance assessment and identifying \nareas for improvement. The formulas of these metrics is \ngiven in Eqs. (9–12).\nThe Eqs.  (9–12) derive the true positives (TP), false \npositives (FP), false negatives (FN) and true negatives \n(TN) values from the confusion matrix. They repre -\nsent: FP as the number of WBC inaccurately identified \nas non-target WBC types, FN as the total of incorrectly \nidentified WBC types, TN as the tally of WBC correctly \nrecognized as non-target WBC types and TP as the count \nof correctly identified WBC types.\nExperimental results\nIn this section, the results of the applications on the \nBCCD, PBC and Raabin datasets are included. These \nthree datasets were compared with ResNet (ResNet50, \nResNet101) [46], EfficientNet [47], ConvMixer [22], Swin \nTransformer [14], MobileNet [48] and VGG16 [49] from \nthe literature. The reasons for selecting these methods \nfor comparison are as follows. The proposed model uses \nparallel ConvMixer and Swin Transformer models. In \norder to observe the effect of using only ConvMixer and \nSwin Transformer, the proposed model is first compared \n(9)Acc= TP + TN\nTP + FP + TN + FN\n(10)Pr = TP\nTP + FP\n(11)Re = TP\nTP + FN\n(12)F 1s = 2 ∗ Pr ∗ Re\nPr + Re\nwith these two models. Certain models, including Effi -\ncientNet, MobileNet, ResNet101, ResNet50, and VGG16, \nwere chosen for comparison in the experiments due to \ntheir widespread adoption and established performance \nin the computer vision field. Each of these models rep -\nresents a different architectural paradigm offering vary -\ning balances between model complexity, computational \nefficiency, and accuracy. The VGG16 is a classical deep \nconvolutional neural network architecture characterized \nby its simplicity and uniform architecture. It is widely \nused as a baseline for many computer vision tasks due \nto its effectiveness and ease of implementation. The \nResNet50 and ResNet101 architectures pioneered the use \nof skip connections and achieved superior performance \nby developing very deep network structures. Finally, the \nMobileNet and EfficientNet architectures are efficient \nnetwork architectures with low parameters that utilize \nboth skip connections and depthwise separable convo -\nlution layers. Additionally, the EfficientNet architecture \noffers a powerful network structure by performing layer \noptimization. These network architectures are actively \nused in many studies today, either in their original or \nmodified versions. In addition, they also include skip \nconnections and depthwise separable convolution layers, \nas in our proposed model. Discussions of the results are \nprovided below in subsections.\nClassification results for BCCD\nThe BCCD consists of four classes: N, EO, L and M. \nClass-based results for BCCD are presented in Table  2. \nTable 2 shows that the best results are obtained for class \nL with 99.8% Acc, 99.60% F1s, 99.68% Pr and 99.52% Re. \nThis shows that the model performs extremely well in \nidentifying L class cells, achieving very high accuracy and \nother performance metrics. It also shows that the model \nis very good at both identifying true positives and avoid -\ning false positives, with the model rarely making errors \nfor class L. The proposed model performs well on class M \nwith high Acc (98.47%) and F1s (96.84%). Notably, it has \na perfect Pr (100%), meaning it never classified anything \nelse as M if it wasn’t actually M. However, the Re (93.87%) \nis slightly lower, suggesting there might be some true pos-\nitives from class M that the model missed. The proposed \nTable 2 Class-based results for BCCD (%)\nClasses Acc F1s Pr Re\nEO 92.88 85.53 87.17 83.95\nL 99.8 99.60 99.68 99.52\nM 98.47 96.84 100 93.87\nN 91.48 83.82 80.03 87.98\nMacro results 95.66 91.44 91.72 91.33\nPage 12 of 19Üzen and Fırat  Health Information Science and Systems (2024) 12:33\nmodel exhibits good Acc (92.88%) for the EO class, how -\never, improvements are needed in its F1s (85.53%), Re \n(83.95%), and Pr (87.17%). A slightly higher Pr compared \nto Re suggests that the model might be better at avoid -\ning false positives (misclassifying other classes as EO), \nbut it could potentially miss some true positives (actual \nEO data points). Class N has the lowest performance \namong the other classes. The Acc (91.48%) is still good, \nbut the F1s (83.82%) is the lowest. The Pr (80.03%) is also \nlower than the Re (87.98%), indicating that the model \nmay struggle to distinguish class N from other classes. \nOverall, the proposed model performs well on the BCCD \ndataset, especially on class L. However, improvements \ncould be made in distinguishing classes EO and N from \nother classes, especially in Pr for class N and Re for class \nEO. In additon, Table 3 outlines the application results of \ndifferent models using this dataset. Upon examination of \nTable 3, it is apparent that the proposed SC-MP-Mixer \nachieved the best classification result, boasting an macro \nAcc of 95.66%. Additional evaluation criteria for our SC-\nMP-Mixer method yielded the following results: 91.44% \nF1s, 91.72% Pr, and 91.33% Re. Comparatively, the results \nclosest to the our SC-MP-Mixer model was acquired \nwith EfficientNet, achieving 93.87% Acc and 88.05% F1s. \nSimilarly, ResNet101 attained 93.65% Acc and 87.61% \nF1s. The ResNet50 reached Acc score of 93.14%, while \nthe MobileNet achieved Acc score of 92.22%. The VGG16 \nobtained the lowest scores among pre-trained models. \nWhen comparing pre-trained models with the SC-MP-\nMixer, it produced approximately 3–5% higher scores \nthan the pre-trained models. These results demonstrate \nthe superior effectiveness of the SC-MP-Mixer model \nover pre-trained models. On the other hand, the Swin \nTransformer and ConvMixer structures, representing \nthe latest technological models, achieved Acc scores of \n92.62 and 93.18%, respectively. Despite the Swin Trans -\nformer capturing strong long-context features with the \nlatest transformer technology, it exhibited weaknesses \nagainst the proposed model. This is attributed to trans -\nformer models struggling to capture spatial details from \ninput images and requiring a large number of images for \ntraining. In the SC-MP-Mixer architecture developed \nbased on this, Swin Transformers were fed with features \nobtained from ConvMixer, allowing for numerous and \neffective features through a multi-path approach. Con -\nsequently, the proposed SC-MP-Mixer produced the \nhighest results by leveraging the Swin Transformer and \nConvMixer blocks together.\nClassification results for PBC and Raabin\nThe PBC dataset comprises eight classes: N, EO, B, L, M, \nIG, P and ER. Class-based results for PBC are presented \nin Table  4. Analysing Table  4, we can see that the pro -\nposed method generally performs well in all classes, with \nsome differences. Classes B, EO, L, ER and P achieved \nvery high Acc (over 99.8%) and F1s (over 99%). They also \nhave Pr and Re values close to 100%, indicating that the \nmodel excels in classifying these classes with minimal \nerror. Classes M and N show good Acc (over 98.9%) but \nslightly lower F1s (around 97–99%). The Pr and Re val -\nues for these classes are still quite high, suggesting that \nthe model performs well but may have some room for \nimprovement in distinguishing these classes from others. \nClass IG has the lowest Acc (98.91%) and F1s (96.70%) of \nall classes. In addition, the Pr (96.93%) is slightly higher \nthan the Re (96.48%), indicating that the model may be \nbetter at avoiding false positives for this class, but may \nmiss some true positives. Overall, the model performs \nwell on the PBC dataset, particularly in the B, EO, L, \nER and P classes. Some improvement is needed in the \nIG class, particularly in Re, and potentially in the M \nand N classes. The application results using this dataset \nare summarized in Table  5. According to the Table  5, \nthe most notable classification outcomes were obtained \nwith our proposed SC-MP-Mixer. The SC-MP-Mixer \nTable 3 Classification results of different models for BCCD \n(%)\nBold indicates the best result\nModel Macro Acc F1s Pr Re\nConvMixer 93.18 87.03 90.91 86.36\nEfficientNet 93.87 88.05 90.56 87.73\nMobileNet 92.22 84.52 88.06 84.43\nResNet101 93.65 87.61 89.99 87.29\nResNet50 93.14 86.7 89.73 86.29\nSwinTransformer 92.62 85.36 85.72 85.25\nVGG16 62.53 10.02 6.26 25.05\nProposed\nSC-MP-Mixer\n95.66 91.44 91.72 91.33\nTable 4 Class-based results for PBC (%)\nClasses Acc F1s Pr Re\nB 99.96 99.71 99.42 100\nEO 99.96 99.90 100 99.80\nER 99.84 99.10 99.10 99.10\nIG 98.91 96.70 96.93 96.48\nL 99.88 99.14 100 98.29\nM 99.61 97.68 96.33 99.06\nN 99.02 97.45 97.55 97.35\nP 100 100 100 100\nMacro results 99.65 98.71 98.67 98.76\nPage 13 of 19\nÜzen and Fırat  Health Information Science and Systems (2024) 12:33\ndemonstrated impressive performance, achieving 99.65% \nAcc, 98.71% F1s, 98.67% Pr, and 98.76% Re values. In \ncomparison, the methods that closely approached the \nperformance of the proposed SC-MP-Mixer on this data-\nset were ResNet50 and VGG16. ResNet50 achieved a \n99.53% Acc score, while VGG16 obtained a 99.59% Acc \nscore. Additionally, the EfficientNet, MobileNet, and \nResNet101 models provided Acc scores of 99.51, 99.04, \nand 99.35%, respectively. On the other hand, ConvMixer \n(98.51%) and SwinTransformer (97.9%) yielded the lowest \nAcc scores. However, the SC-MP-Mixer, utilizing both \nConvMixer and SwinTransformer in tandem and sup -\nported by a multi-path (parallel) application and a differ -\nent patch size approach, outperformed ConvMixer and \nSwinTransformer by 1.14 and 1.75%, respectively.\nThe Raabin dataset comprises five classes: N, EO, B, \nL and M. Class-based results for Raabin are presented \nin Table 6. When analysing Table  6, the performance of \nthe model varies according to the classes in this data -\nset. Class N achieves the highest F1s (98.55%) with very \nclose Pr (98.40%) and Re (98.70%). This suggests that \nthe model is good at identifying and correctly classify -\ning class N with minimal error. Compared to class N, \nclasses B and EO have good accuracy (over 99%) but \nlower F1 values (around 94–98%). While the preci -\nsion for class B is excellent (100%), the recall is lower \n(96.30%), indicating that the model may miss some true \npositives (B) but is successful in avoiding false positives. \nSimilarly, Pr and Re are lower in the EO class. Class L \nhas the lowest Acc value, while class M has the lowest \nPr, Re and F1s values. This indicates that the model has \ndifficulty distinguishing class M from the others and \nmay make more errors in its classifications. Overall, \nthe model seems to give a balanced result of class N in \nall evaluation metrics in the Raabin dataset. Although \nthe highest Acc value was obtained in class B, it gave \nlower results than class N, especially in F1s and Re. It \nis clear that the model needs improvement, especially \nfor class M. In addition, The experimental results using \nthis dataset are summarized in Table  7. According to \nthe Table  7, the most notable classification outcomes \nwere obtained with our proposed SC-MP-Mixer. The \nSC-MP-Mixer demonstrated impressive performance, \nachieving 98.68% Acc, 94.42% F1s, 94.34% Pr, and \n94.63% Re values. The closest result to the proposed \nSC-MP-Mixer was achieved in MobileNet with 97.71% \nAcc, 93.86% F1s, 93.79% Pr, and a 93.96% Re. When \ncompared to MobileNet, the proposed SC-MP-Mixer \nseems to yield superior results by 0.97% in Acc, 0.56% \nin F1s, 0.55% in Pr, and 0.67% in Re. Furthermore, when \npitted against ConvMixer, the suggested SC-MP-Mixer \nattains notably improved outcomes with an increase of \n21.33% in Acc, 37.95% in F1s, 27.56% in Pr, and 38.14% \nin Re. Likewise, in comparison to the SwTrans, the SC-\nMP-Mixer achieves superior results with a marginal \nuptick of 2.13% in Acc, 0.8% in F1s, 0.82% in Pr, and \n0.91% in Re. Against other methodologies, the SC-MP-\nMixer surpasses EfficientNet by 31.25% in Acc, 44.34% \nin F1s, 45.06% in Pr, and 37.68% in Re. Correspond -\ningly, it outperforms ResNet101 with a slight increase \nof 2.12% in Acc, 2.34% in F1s, 3.71% in Pr, and 1.05% in \nRe, surpasses ResNet50 with 2.17% higher Acc, 2.87% \nhigher F1s, 4.97% higher Pr, and 0.79% higher Re, and \nTable 5 Classification results of different models for PBC \n(%)\nBold indicates the best result\nModel Macro Acc F1s Pr Re\nConvMixer 98.51 93.26 93.6 93.53\nEfficientNet 99.51 98.02 97.88 98.25\nMobileNet 99.04 96.07 96.25 95.98\nResNet101 99.35 97.08 97.25 96.97\nResNet50 99.53 98.29 98.25 98.33\nSwinTransformer 97.9 90.35 91.78 90.75\nVGG16 99.59 98.33 98.39 98.28\nProposed\nSC-MP-Mixer\n99.65 98.71 98.67 98.76\nTable 6 Class-based results for Raabin (%)\nClasses Acc F1s Pr Re\nB 99.91 98.12 100 96.30\nEO 99.27 94.84 96.08 93.63\nL 97.75 95.31 96.51 94.14\nM 98.21 85.28 80.71 90.4\nN 98.25 98.55 98.40 98.70\nMacro results 98.68 94.42 94.34 94.63\nTable 7 Classification results of different models for \nRaabin (%)\nBold indicates the best result\nModel Macro Acc F1s Pr Re\nConvMixer 77.35 56.47 66.78 56.49\nEfficientNet 67.43 50.08 49.28 56.95\nMobileNet 97.71 93.86 93.79 93.96\nResNet101 96.56 92.08 90.63 93.58\nResNet50 96.51 91.55 89.37 93.84\nSwinTransformer 96.55 93.62 93.52 93.72\nVGG16 61.60 25.37 29.79 36.05\nProposed\nSC-MP-Mixer\n98.68 94.42 94.34 94.63\nPage 14 of 19Üzen and Fırat  Health Information Science and Systems (2024) 12:33\noutshines VGG16 with a significant lead of 37.08% in \nAcc, 69.05% in F1s, 64.55% in Pr, and 58.58% in Re.\nThe confusion matrices obtained from the experimen -\ntal studies conducted using the proposed SC-MP-Mixer \nwith all three datasets are presented in Fig.  6. Accord -\ning to Fig.  6, the proposed SC-MP-Mixer correctly pre -\ndicted all 172 B images, 492 out of 493 EO images, 221 \nout of 223 ER images, 411 out of 426 IG images, 172 out \nof 175 L images, 210 out of 212 M images, 478 out of 491 \nN images, and all 372 P images in the PBC dataset. Simi -\nlarly, in the Raabin dataset, it correctly predicted 52 out \nof 54 B images, 147 out of 157 EO images, 498 out of 529 \nL images, 113 out of 125 M images, and 1295 out of 1312 \nN images. Finally, within the BCCD dataset consisting of \n4 classes, it correctly predicted 523 out of 623 EO images, \n617 out of 620 L images, 582 out of 620 M images, and \n549 out of 624 N images. Considering the total correctly \npredicted images, class-specific accuracy values for \neach dataset are provided in Table  2 for BCCD, Table  4 \nfor PBC, and Table  6 for Raabin. The macro Acc values \nobtained using the proposed SC-MP-Mixer for BCCD, \nPBC, and Raabin datasets are as follows: 95.66, 99.65, and \n98.68%, respectively.\nAblation analysis\nThe proposed SC-MP-Mixer model comprises a com -\nbination of Multipath SwTrans (MPST) and Multipath \nConvMixer (MPCM) architectures. While the MPCM \nstructure consists of three parallel ConvMixer blocks, the \nMPST structure comprises two parallel SwTrans blocks. \nFig. 6 Confusion matrices obtained for each data set using the proposed SC-MP-Mixer. The x-axis and y-axis of the complexity matrices indicate the \npredicted label and the true label, respectively\nPage 15 of 19\nÜzen and Fırat  Health Information Science and Systems (2024) 12:33\nThe individual impact of each component within the \nproposed SC-MP-Mixer model on classification results \n(Acc, Pr, Re, and F1s) has been examined and presented \nin Table  8. Model 1 contains only ConvMixer, Model 2 \nincludes solely SwTrans, Model 3 incorporates solely the \nMPCM structure, Model 4 integrates both MPCM and \nSwTrans, Model 5 contains only MPST, Model 6 is the \ncombination of ConvMixer and MPST, and finally, Model \n7 encompasses the components within the proposed SC-\nMP-Mixer model.\nAnalysing Table  8, the lowest classification results are \nobtained when the ConvMixer (Model 1) and SwTrans \n(Model 2) models are used alone. When comparing the \nresults between Model 1 and Model 3 in Table  8, Model \n3 has yielded a respective improvement of 0.06%, 0.26%, \nand 19.99% in accuracy for the BCCD, PBC, and Raabin \ndatasets compared to Model 1. These outcomes indi -\ncate that the MPCM structure is more effective than a \nsingle ConvMixer block. MPST (Model 5), when used \nalone, achieves lower accuracy compared to models \nwith other components except for ConvMixer only and \nSwTrans only. However, the inclusion of MPST with \nConvMixer (Models 6 and 7) improves performance \nfor BCCD, PBC and Raabin. This suggests that MPST, \nwhen combined with ConvMixer, may be helpful in \naddressing certain aspects of the data. Furthermore, \nincluding ConvMixer consistently improves perfor -\nmance across all datasets. This suggests that Conv -\nMixer effectively extracts important features from the \nimages. Moreover, in Model 4, augmenting the SwTrans \nmodel to the MPCM model exhibits further enhance -\nment: the accuracy values increase by 1.15, 0.77, and \n1.1% for the BCCD, PBC, and Raabin datasets, respec -\ntively. Introducing the MPST block instead of a single \nSwTrans model alongside the MPCM model leads to \nan increase in accuracy by 1.27, 0.11, and 0.24% for the \nBCCD, PBC, and Raabin datasets, respectively. When \nall models are analyzed, it is seen that Model 7, the \nTable 8 Results of ablation analysis\nModel ConvMixer MPCM SwTrans MPST BCCD (%) PBC (%) Raabin (%)\nModel 1 X – – – Acc = 93.18 Acc = 98.51 Acc = 77.35\nPr = 90.91 Pr = 93.6 Pr = 66.78\nRe = 86.36 Re = 93.53 Re = 56.49\nF1s = 87.03 F1s = 93.26 F1s = 56.47\nModel 2 – – X – Acc = 92.62 Acc = 97.9 Acc = 96.55\nPr = 85.72 Pr = 91.78 Pr = 93.52\nRe = 85.25 Re = 90.75 Re = 93.72\nF1s = 85.36 F1s = 90.35 F1s = 93.62\nModel 3 – X – – Acc = 93.24 Acc = 98.77 Acc = 97.34\nPr = 90.14 Pr = 97.74 Pr = 92.25\nRe = 89.48 Re = 97.59 Re = 92.46\nF1s = 89.81 F1s = 97.66 F1s = 92.35\nModel 4 – X X Acc = 94.39 Acc = 99.54 Acc = 98.44\nPr = 90.43 Pr = 98.48 Pr = 92.88\nRe = 89.99 Re = 98.19 Re = 93.14\nF1s = 90.21 F1s = 98.33 F1s = 93.01\nModel 5 – – – X Acc = 93.12 Acc = 98.64 Acc = 97.18\nPr = 89.20 Pr = 97.87 Pr = 91.47\nRe = 88.79 Re = 97.28 Re = 91.65\nF1s = 88.99 F1s = 97.57 F1s = 91.56\nModel 6 X – – X Acc = 94.08 Acc = 99.04 Acc = 98.01\nPr = 90.12 Pr = 98.11 Pr = 91.96\nRe = 89.65 Re = 97.99 Re = 91.37\nF1s = 89.88 F1s = 98.05 F1s = 91.66\nModel 7 – X – X Acc = 95.66 Acc = 99.65 Acc = 98.68\nPr = 91.72 Pr = 98.67 Pr = 94.34\nRe = 91.33 Re = 98.76 Re = 94.63\nF1s = 91.44 F1s = 98.71 F1s = 94.42\nPage 16 of 19Üzen and Fırat  Health Information Science and Systems (2024) 12:33\nproposed SC-MP-Mixer model, achieves the most suc -\ncessful results in all evaluation metrics in all datasets.\nComparison analysis with different models in the literature\nTo demonstrate the effectiveness of our SC-MP-Mixer \nmodel, we compared it with different studies from the \nliterature. The comparison results are shown in Table  9. \nIn these comparisons, our proposed model was repeated \n4 times, and its standard deviation was calculated and \nadded to this table. When Table  9 is examined, it is seen \nthat the SC-MP-Mixer method achieved the best results \nin BCCD, PBC and Raabin datasets. In the BCCD dataset, \nour SC-MP-Mixer method achieved 95.66% macro Acc. \nIn this dataset, the closest result to the SC-MP-Mixer \nmethod was found with the proposed Canonical Corre -\nlation Analysis (CCA)—(InceptionV3 + LSTM) method \nby Patil et al. [1] with 91.06%. The SC-MP-Mixer method \ngives 4.6% better results. In addition, Patil et  al. [1] \nfound an Acc of 89.85% when using VGG16 in conjunc -\ntion with LSTM. The SC-MP-Mixer method achieved a \n5.81% higher Acc value than VGG16 + LSTM. Similarly, \nour SC-MP-Mixer method has 4.65% better Acc than \nBani-Hani et al. [24] method (CNN + Genetic Algorithm) \nand 4.87% better than Liang et  al. [35] method (Xcep -\ntion + LSTM). Moreover, our SC-MP-Mixer achieved \n8.21% higher Acc than InceptionV3 + LSTM proposed \nby Liang et al. [35] 6.28% higher than ResNet50 + LSTM, \nand 7.08% higher than Xception + ResNet50 + LSTM. \nThe SC-MP-Mixer method achieved 9.7% higher Acc \nthan the CNN + SVM developed by Ekiz et al. [33], 7.73% \nhigher than LeNet5 developed by Sharma et al. [26], and \n4.87% higher than the Fused CNN presented by Banik \net al. [27].\nIn the PBC dataset, our SC-MP-Mixer model achieved \n99.65% Acc. Our SC-MP-Mixer model achieved 0.66% bet-\nter results than the proposed method by Uçar et  al. [30]. \nSimilarly, it obtained 2.6% better accuracy than the pro -\nposed VGG16 method by Acevedo et al. [50] and 3.6% bet-\nter than the InceptionV3 proposed by Acevedo et al. [50]. \nMoreover, our SC-MP-Mixer model achieved Acc values \nthat were 0.35% higher than the Capsule network-based \nmodel suggested by Long et al. [51], 0.76% higher than the \nTable 9 Comparison classification results with different models in the literature\nBold indicates the best result\nStudy Methodology Dataset Class Acc (%)\nPatil et al. [1] CCA—(VGG16 + LSTM) BCCD 4 89.85\nPatil et al. [1] CCA—(InceptionV3 + LSTM) BCCD 4 91.06\nBani-Hani et al. [24] CNN + Genetic Algorithm BCCD 4 91.01\nLiang et al. [35] InceptionV3 + LSTM BCCD 4 87.45\nLiang et al. [35] ResNet50 + LSTM BCCD 4 89.38\nLiang et al. [35] Xception + LSTM BCCD 4 90.79\nLiang et al. [35] Xception + ResNet50 + LSTM BCCD 4 88.58\nEkiz et al. [33] CNN + SVM BCCD 4 85.96\nSharma et al. [26] LeNet5 BCCD 4 87.93\nBanik et al. [27] Fused CNN BCCD 4 90.79\nSharma et al. [29] a fast traditional CNN BCCD 4 84.64\nYildirim et al. [57] GoogleNet, DenseNet, AlexNet, ResNet50 + Filters (Gauss and Median) BCCD 4 75.21–83.44\nVatathanavaro et al. [58] VGG16, ResNet50 BCCD 4 72.07–88.29\nOur method SC-MP-Mixer BCCD 4 95.66 ± 0.19\nUçar et al. [30] ShuffleNet PBC 8 97.94\nAcevedo et al. [50] VGG16 PBC 8 96.00\nAcevedo et al. [50] InceptionV3 PBC 8 95.00\nLong et al. [51] Capsule network based model PBC 8 99.3\nFırat [52] Modified Inception Module PBC 8 98.89\nAtıcı et al. [53] R-CNN Based Segmentation and Classification PBC 8 99.31\nOur method SC-MP-Mixer PBC 8 99.65 ± 0.11\nJiang et al. [45] Discriminative region detection assisted feature aggregation network Raabin 5 95.17\nAkalin et al. [55] The hybrid use of Detectron2 and YOLOv5 Raabin 5 98.00\nTsutsui et al. [54] ViT-Base-16 Raabin 5 98.33\nTavakoli et al. [56] SVM classifier Raabin 5 94.65\nOur method SC-MP-Mixer Raabin 5 98.68 ± 0.17\nPage 17 of 19\nÜzen and Fırat  Health Information Science and Systems (2024) 12:33\nModified Inception-based module developed by Fırat [52], \nand finally, 0.34% higher than the R-CNN-based classifi -\ncation presented by Atıcı et  al. [53]. SC-MP-Mixer model \nachieved an Acc of 98.68% with the Raabin, which was \nanother dataset used in the experimental studies. When \ncompared to different studies using the Raabin, SC-MP-\nMixer model shows the closest Acc value to our model at \n98.33%, achieved by the ViT-Base-16 model developed by \nTsutsui et al. [54]. However, our SC-MP-Mixer model out-\nperformed the ViT-Base-16 model by 0.35% in Acc. Upon \nfurther examination of other models, our SC-MP-Mixer \nmodel obtained Acc values that were 3.51% higher than the \nDiscriminative Region Detection Assisted Feature Aggre-\ngation Network model presented by Jiang et al. [45], 0.68% \nhigher than the hybrid use of Detectron2 and YOLOv5 \nmodel developed by Akalin et  al. [55], and 4.03% higher \nthan the SVM used by Tavakoli et al. [56]. When all mod-\nels in Table 9 are compared, it’s evident that SC-MP-Mixer \nmodel outperformed the studies in the literature across all \nthree datasets, yielding significantly better results.\nConclusions\nIn this study, a novel DL-based model is proposed for \nWBC classification. The proposed model is a new hybrid \nmodel based on ConvMixer and Swin transformer archi -\ntectures. This hybrid model is called Multipath mixer \n(SC-MP-Mixer) based on Swin Transformer and Con -\nvMixer. In our SC-MP-Mixer model, ConvMixer blocks \nextract features with strong spatial detail, while Swin \ntransformer networks effectively handle these features \nwith self-attention mechanism. Also, our SC-MP-Mixer \nmodel offers a multipath approach to get better patch \nrepresentations for ConvMixer and Swin transformer \nblocks. In this approach, ConvMixer and Swin trans -\nformer blocks are applied in parallel with different patch \nsizes. In this way, more effective features can be obtained \nwith different patch representations. Experimental stud -\nies were carried out on three different WBC datasets \n(BCCD, PBC and Raabin) to test the performance of the \nour SC-MP-Mixer model. These datasets are BCCD con -\nsisting of 4 classes (EO, L, M and N), PBC consisting of \n8 classes (N, EO, B, L, M, IG, P , ER) and Raabin consist -\ning of 5 classes (B, EO, L, M and N). Our SC-MP-Mixer \nmethod obtained 99.65% macro Acc, 98.71% F1s, 98.67% \nPr, 98.76% Re with PBC, while 95.66% macro Acc, 91.44% \nF1s, 91.72% Pr, 91.33% Re with BCCD value has been \nobtained. In addition, 98.68% Acc, 94.42% F1s, 94.34% Pr \nand 94.63% Re values were obtained with the Raabin. Our \nSC-MP-Mixer model has been compared with the meth -\nods using these three datasets in the literature. As a result \nof the comparison, it was seen that our SC-MP-Mixer \nmodel achieved better classification results than other \nmethods. These findings suggest that our SC-MP-Mixer \nmodel shows promise as an alternative approach in \nclinical experiments due to its capacity to efficiently and \naccurately extract WBC features for classification pur -\nposes. In future studies, the primary aim is to develop \nnew models that will increase the accuracy values on the \nBCCD and Raabin datasets. Additionally, collaborations \nwith expert physicians will involve work on private data -\nsets, with plans to develop a software that will be made \navailable for use by these expert doctors.\nFunding\nThis research did not receive any specific grant from funding agencies in the \npublic, commercial, or not for-profit sectors.\nData availability\nData will be made available on request.\nDeclarations\nCompeting interest\nThe authors declare that they have no known competing financial interests \nor personal relationships that could have appeared to influence the work \nreported in this paper.\nAuthor details\n1 Department of Computer Engineering, Faculty of Engineering and Architec-\nture, Bingol University, Bingol, Turkey. 2 Department of Computer Engineering, \nFaculty of Engineering, Dicle University, Diyarbakır, Turkey. \nReceived: 18 January 2024   Accepted: 16 April 2024\nPublished: 28 April 2024\nReferences\n 1. Patil AM, Patil MD, Birajdar GK. White blood cells image classifica-\ntion using deep learning with canonical correlation analysis. IRBM. \n2021;42:378–89.\n 2. Khan A, Eker A, Chefranov A, Demirel H. White blood cell type identifica-\ntion using multi-layer convolutional features with an extreme-learning \nmachine. Biomed Signal Process Control. 2021;69:102932.\n 3. Acevedo A, Merino A, Alférez S, Molina Á, Boldú L, Rodellar J. A dataset of \nmicroscopic peripheral blood cell images for development of automatic \nrecognition systems. Data Brief. 2020;30:105474.\n 4. Cheuque C, Querales M, León R, Salas R, Torres R. An efficient multi-level \nconvolutional neural network approach for white blood cells classifica-\ntion. Diagnostics. 2022;12:1–15.\n 5. Long F, Peng JJ, Song W, Xia X, Sang J. BloodCaps: a capsule network \nbased model for the multiclassification of human peripheral blood cells. \nComput Methods Programs Biomed. 2021;202.\n 6. Wu L, Huang L, Li M, Xiong Z, Liu D, Liu Y, et al. Differential diagnosis \nof secondary hypertension based on deep learning. Artif Intell Med. \n2023;141:102554.\n 7. Rashid M, Ramakrishnan M, Chandran VP , Nandish S, Nair S, Shanbhag \nV, et al. Artificial intelligence in acute respiratory distress syndrome: a \nsystematic review. Artif Intell Med. 2022;131:102361.\n 8. Firat H, Asker ME, Bayindir Mİ, Hanbay D. 3D residual spatial–spectral con-\nvolution network for hyperspectral remote sensing image classification. \nNeural Comput Appl. 2022;8.\n 9. Dayı B, Üzen H, Çiçek İB, Duman ŞB. A novel deep learning-based \napproach for segmentation of different type caries lesions on panoramic \nradiographs. Diagnostics. 2023;13:202.\n 10. Bütün E, Uçan M, Kaya M. Automatic detection of cancer metastasis \nin lymph node using deep learning. Biomed Signal Process Control. \n2023;82:104564.\nPage 18 of 19Üzen and Fırat  Health Information Science and Systems (2024) 12:33\n 11. Shankar V, Yousefi E, Manashty A, Blair D, Teegapuram D. Clinical-GAN: \ntrajectory forecasting of clinical events using transformer and generative \nadversarial networks. Artif Intell Med. 2023;138:102507.\n 12. Karimi D, Gholipour A. Diffusion tensor estimation with transformer \nneural networks. Artif Intell Med. 2022;130:102330.\n 13. He K, Gan C, Li Z, Rekik I, Yin Z, Ji W, et al. Transformers in medical image \nanalysis. Intell Med. 2023;3:59–78.\n 14. Liu Z, Lin Y, Cao Y, Hu H, Wei Y, Zhang Z, et al. Swin transformer: hierarchi-\ncal vision transformer using shifted windows. Proc IEEE Int Conf Comput \nVis. 2021;9992–10002.\n 15. Lin A, Chen B, Xu J, Zhang Z, Lu G, Zhang D. DS-TransUNet: dual Swin \ntransformer U-Net for medical image segmentation. IEEE Trans Instrum \nMeas. 2022;71:1–13.\n 16. Chen J, Lu Y, Yu Q, Luo X, Adeli E, Wang Y, et al. TransUNet: transformers \nmake strong encoders for medical ımage segmentation. 2021;1–13.\n 17. Cao H, Wang Y, Chen J, Jiang D, Zhang X, Tian Q, et al. Swin-Unet: Unet-\nlike pure transformer for medical ımage segmentation. 2023;205–218.\n 18. Liu Z, Lin Y, Cao Y, Hu H, Wei Y, Zhang Z, et al. Swin transformer: hierarchi-\ncal vision transformer using shifted windows. Proc IEEE Int Conf Comput \nVis. 2021;9992–10002 [cited 2023 May 18]. Available from: https:// arxiv. \norg/ abs/ 2103. 14030 v2\n 19. Chen J, Lu Y, Yu Q, Luo X, Adeli E, Wang Y, et al. TransUNet: transformers \nmake strong encoders for medical ımage segmentation. 2021. [cited \n2023 May 18]. Available from: https:// arxiv. org/ abs/ 2102. 04306 v1\n 20. Baheti B, Innani S, Gajre S, Talbar S. Eff-UNet: a novel architecture for \nsemantic segmentation in unstructured environment. IEEE computer \nsociety conference on computer vision and pattern recognition work-\nshops. 2020;2020 June:1473–1481.\n 21. Dosovitskiy A, Beyer L, Kolesnikov A, Weissenborn D, Zhai X, Unterthiner T, \net al. An Image is Worth 16x16 Words: transformers for ımage recognition \nat scale. 2020 [cited 2023 May 18]. Available from: https:// arxiv. org/ abs/ \n2010. 11929 v2\n 22. Trockman A, Kolter JZ. Patches are all you need? 2022. [cited 2023 May \n19]. Available from: http:// arxiv. org/ abs/ 2201. 09792\n 23. Shahin AI, Guo Y, Amin KM, Sharawi AA. White blood cells identification \nsystem based on convolutional deep neural learning networks. Comput \nMethods Programs Biomed. 2019;168:69–80.\n 24. Bani-Hani D, Khan N, Alsultan F, Karanjkar S, Nagarur N. Classification \nof leucocytes using convolutional neural network optimized through \ngenetic algorithm. In Proceedings of the 7th annual world conference of \nthe society for ındustrial and systems engineering, vol. 10. 2018, pp. 1–7. \nBinghamton.\n 25. Tiwari P , Qian J, Li Q, Wang B, Gupta D, Khanna A, et al. Detection of \nsubtype blood cells using deep learning. Cogn Syst Res. 2018;52:1036–44.\n 26. Sharma M, Bhave A, Janghel RR. White blood cell classification using \nconvolutional neural network. Adv Intell Syst Comput. 2019;900:135–43.\n 27. Banik PP , Saha R, Kim KD. Fused convolutional neural network for white \nblood cell image classification. Int Conf Artif Intell Inf Commun (ICAIIC). \n2019;2019:22–4.\n 28. Yao X, Sun K, Bu X, Zhao C, Jin Y. Classification of white blood cells using \nweighted optimized deformable convolutional neural networks. Artif \nCells Nanomed Biotechnol. 2021;49:147–55.\n 29. Sharma A, Thomas SC, Sah A, Abhyankar VV, Singh VK, Prakash S. White \nblood cells subtypes classification using fast traditional convolutional \nneural network. In Proceedings of the 2021 ınternational conference \non emerging techniques in computational ıntelligence, ICETCI 2021. \n2021;113–7.\n 30. Uçar F. Deep learning approach to cell classification in human peripheral \nblood. In 2020 5th ınternational conference on computer science and \nengineering (UBMK). 2020, p. 383–7.\n 31 Baydilli YY, Atila Ü. Classification of white blood cells using capsule net-\nworks. Computerized Med Imaging Graphics. 2020;80:101699.\n 32. Sengur A, Akbulut Y, Budak U, Comert Z. White blood cell classification \nbased on shape and deep features. In: 2019 ınternational conference on \nartificial ıntelligence and data processing symposium, IDAP 2019. 2019.\n 33. Ekİz A. ESA ve Kon-DVM Modelleri Kullanarak Beyaz Kan Hücrelerinin \nSınıflandırılması. In 29th signal processing and communications applica-\ntions conference (SIU). 2021;2021–2024.\n 34. Tseng TR, Huang HM. Classification of peripheral blood neutrophils using \ndeep learning. Cytometry Part A. 2022;1–9.\n 35. Liang G, Hong H, Xie W, Zheng L. Combining convolutional neural \nnetwork with recursive neural network for blood cell image classification. \nIEEE Access. 2018;6:36188–97.\n 36. Yu W, Chang J, Yang C, Zhang L, Shen H, Xia Y, et al. Automatic clas-\nsification of leukocytes using deep neural network. Proc Int Conf ASIC. \n2017;2017:1041–4.\n 37. Baby D, Devaraj SJ, Hemanth J, Anishin Raj MM. Leukocyte classification \nbased on feature selection using extra trees classifier: a transfer learning \napproach. Turk J Electr Eng Comput Sci. 2021;29:2742–57.\n 38. Dosovitskiy A, Beyer L, Kolesnikov A, Weissenborn D, Zhai X, Unterthiner \nT, et al. An ımage is worth 16 × 16 words: transformers for ımage recogni-\ntion at scale. ICLR; 2021.\n 39. Devlin J, Chang MW, Lee K, Toutanova K. BERT: pre-training of deep \nbidirectional transformers for language understanding. NAACL HLT \n2019–2019 conference of the North American chapter of the association \nfor computational linguistics: human language technologies—proceed-\nings of the conference. 2019;1:4171–86.\n 40. Farahani M, Gharachorloo M, Farahani M, Manthouri M. ParsBERT: \ntransformer-based model for Persian language understanding. Neural \nProcess Lett. 2021;53:3831–47.\n 41. Zhuang X, Liu F, Hou J, Hao J, Cai X. Transformer-based interactive multi-\nmodal attention network for video sentiment detection. Neural Process \nLett. 2022;54:1943–60.\n 42. Meng L, Tan W, Ma J, Wang R, Yin X, Zhang Y. Enhancing dynamic ECG \nheartbeat classification with lightweight transformer model. Artif Intell \nMed. 2022;124:102236.\n 43. Üzen H, Türkoğlu M, Yanikoglu B, Hanbay D. Swin-MFINet: Swin trans-\nformer based multi-feature integration network for detection of pixel-\nlevel surface defects. Expert Syst Appl. 2022;209.\n 44. Mooney P . Blood cell ımages. 2018. [cited 2022 Jan 30]. Available from: \nwww. kaggle. com/ pault imoth ymoon ey/ blood- cells\n 45. Jiang L, Tang C, Zhou H. White blood cell classification via a discrimina-\ntive region detection assisted feature aggregation network. Biomedical \nOptics Express, 2023;13(10):5246–60. [cited 2023 Dec 21]. Available from: \nhttps:// opg. optica. org/ viewm edia. cfm? uri= boe- 13- 10- 5246& seq= 0& \nhtml= true\n 46. He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. \nIn Proceedings of the IEEE computer society conference on computer \nvision and pattern recognition. IEEE Computer Society, 2016, pp. \n770–778.\n 47. Tan M, Le Q V. EfficientNet: Rethinking model scaling for convolutional \nneural networks. In 36th ınternational conference on machine learning, \nICML 2019. 2019:10691–700.\n 48. Howard AG, Zhu M, Chen B, Kalenichenko D, Wang W, Weyand T, et al. \nMobileNets: efficient convolutional neural networks for mobile vision \napplications, 2017.\n 49. Simonyan K, Zisserman A. Very deep convolutional networks for large-\nscale image recognition. In: 3rd ınternational conference on learning \nrepresentations, ICLR 2015—conference track proceedings. 2015;1–14.\n 50. Acevedo A, Alférez S, Merino A, Puigví L, Rodellar J. Recognition of \nperipheral blood cell images using convolutional neural networks. Com-\nput Methods Programs Biomed. 2019;180:105020.\n 51. Long F, Peng JJ, Song W, Xia X, Sang J. BloodCaps: a capsule network \nbased model for the multi classification of human peripheral blood cells. \nComput Methods Programs Biomed. 2021;202:105972.\n 52. FIRAT H. Modifiye Edilmiş Inception Modülü Kullanılarak İnsan Perif-\nerik Kan Hücrelerinin Çoklu Sınıflandırılması. Mühendislik Bilimleri ve \nAraştırmaları Dergisi. 2023;5:272–284. Available from: https:// dergi park. \norg. tr/ en/ pub/ bjesr/ issue/ 80486/ 13026 85\n 53. Atıcı H, Erdinç Koçer H. Mask R-CNN based segmentation and classifica-\ntion of blood smear ımages. Gazi J Eng Sci. 2023;9:128–43. [cited 2023 \nDec 21]. Available from: https:// dergi park. org. tr/ en/ pub/ gmbd/ issue/ \n77081/ 11366 37\n 54. Tsutsui S, Su Z, Wen B. Benchmarking white blood cell classification under \ndomain shift. 2023;1–5. [cited 2023 Dec 21]. Available from: https:// arxiv. \norg/ abs/ 2303. 01777 v2\n 55. Akalin F, Yumuşak N. Detection and classification of white blood cells \nwith an improved deep learning-based approach. [cited 2023 Dec 21]. \nAvailable from: https:// doi. org/ 10. 55730/ 1300- 0632. 3965\n 56. Tavakoli S, Ghaffari A, Kouzehkanan ZM, Hosseini R. New segmentation \nand feature extraction algorithm for classification of white blood cells \nPage 19 of 19\nÜzen and Fırat  Health Information Science and Systems (2024) 12:33\nin peripheral smear images. Sci Rep. 2021;11:1–13. [cited 2023 Dec 21]. \nAvailable from: https:// www. nature. com/ artic les/ s41598- 021- 98599-0\n 57. Yildirim M, Çinar A. Classification of white blood cells by deep learn-\ning methods for diagnosing disease. Revue d’Intelligence Artificielle. \n2019;33:335–40.\n 58. Vatathanavaro S, Tungjitnob S, Pasupa K. White blood cell classification: \na comparison between VGG-16 and ResNet-50 Models. In: The 6th joint \nsymposium on computational ıntelligence (JSCI6), Bangkok, 2018.\nPublisher’s Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.6656515002250671
    },
    {
      "name": "Multipath propagation",
      "score": 0.5196920037269592
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4866214692592621
    },
    {
      "name": "Computer science",
      "score": 0.459108829498291
    },
    {
      "name": "Blood smear",
      "score": 0.45732131600379944
    },
    {
      "name": "Deep learning",
      "score": 0.42181625962257385
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.4106703996658325
    },
    {
      "name": "Electronic engineering",
      "score": 0.3496314287185669
    },
    {
      "name": "Engineering",
      "score": 0.32042932510375977
    },
    {
      "name": "Medicine",
      "score": 0.25190675258636475
    },
    {
      "name": "Electrical engineering",
      "score": 0.1869868040084839
    },
    {
      "name": "Immunology",
      "score": 0.1794653832912445
    },
    {
      "name": "Computer network",
      "score": 0.15235254168510437
    },
    {
      "name": "Malaria",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Channel (broadcasting)",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I147699246",
      "name": "Bingöl University",
      "country": "TR"
    },
    {
      "id": "https://openalex.org/I123466251",
      "name": "Dicle University",
      "country": "TR"
    }
  ],
  "cited_by": 15
}