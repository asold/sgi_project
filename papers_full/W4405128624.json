{
  "title": "Hyena architecture enables fast and efficient protein language modeling",
  "url": "https://openalex.org/W4405128624",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2096655620",
      "name": "Yiming Zhang",
      "affiliations": [
        "National Institute of Information and Communications Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2288586412",
      "name": "Bian Bian",
      "affiliations": [
        "National Institute of Advanced Industrial Science and Technology",
        "The University of Tokyo",
        "Kitasato University"
      ]
    },
    {
      "id": "https://openalex.org/A2165400638",
      "name": "Manabu Okumura",
      "affiliations": [
        "National Institute of Information and Communications Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4291021611",
    "https://openalex.org/W4392307869",
    "https://openalex.org/W4392696349",
    "https://openalex.org/W4387601539",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3177500196",
    "https://openalex.org/W4302011318",
    "https://openalex.org/W4323654151",
    "https://openalex.org/W3033529678",
    "https://openalex.org/W4312847199",
    "https://openalex.org/W4287556952",
    "https://openalex.org/W3015468748",
    "https://openalex.org/W4297243391",
    "https://openalex.org/W4309793872",
    "https://openalex.org/W4313485929",
    "https://openalex.org/W3034573343",
    "https://openalex.org/W2147526198",
    "https://openalex.org/W4205773061",
    "https://openalex.org/W2379594833",
    "https://openalex.org/W4367315849",
    "https://openalex.org/W4392034553",
    "https://openalex.org/W2003890287",
    "https://openalex.org/W2527759989",
    "https://openalex.org/W3198971594",
    "https://openalex.org/W2794004073",
    "https://openalex.org/W2912990441",
    "https://openalex.org/W2521169042",
    "https://openalex.org/W2940459311",
    "https://openalex.org/W2119859604",
    "https://openalex.org/W2732139758",
    "https://openalex.org/W3003110834",
    "https://openalex.org/W3167717463",
    "https://openalex.org/W3189053267",
    "https://openalex.org/W4391316987",
    "https://openalex.org/W4382501959",
    "https://openalex.org/W4310557809",
    "https://openalex.org/W4327550249",
    "https://openalex.org/W3146944767",
    "https://openalex.org/W4392351837",
    "https://openalex.org/W3111174583",
    "https://openalex.org/W3095583226",
    "https://openalex.org/W2735621019",
    "https://openalex.org/W2252523470",
    "https://openalex.org/W2075644998",
    "https://openalex.org/W2908510526",
    "https://openalex.org/W2102461176",
    "https://openalex.org/W2949342052",
    "https://openalex.org/W3037798801"
  ],
  "abstract": "Abstract The emergence of self‐supervised deep language models has revolutionized natural language processing tasks and has recently extended its applications to biological sequence analysis. Traditional language models, primarily based on Transformer architectures, demonstrate substantial effectiveness in various applications. However, these models are inherently constrained by the attention mechanism's quadratic computational complexity, , which limits their efficiency and leads to high computational costs. To address these limitations, we introduce ProtHyena, a novel approach that leverages the Hyena operator in protein language modeling. This innovative methodology alternates between subquadratic long convolutions and element‐wise gating operations, which circumvents the constraints imposed by attention mechanisms and reduces computational complexity to subquadratic levels. This enables faster and more memory‐efficient modeling of protein sequences. ProtHyena can achieve state‐of‐the‐art results and comparable performance in 8 downstream tasks, including protein engineering (protein fluorescence and stability prediction), protein property prediction (neuropeptide cleavage, signal peptide, solubility, disorder, gene function prediction), protein structure prediction, with only 1.6 M parameters. The architecture of ProtHyena represents a highly efficient solution for protein language modeling, offering a promising avenue for fast and efficient analysis of protein sequences.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7666171193122864
    },
    {
      "name": "Language model",
      "score": 0.5157754421234131
    },
    {
      "name": "Computational complexity theory",
      "score": 0.5012404918670654
    },
    {
      "name": "Artificial intelligence",
      "score": 0.429340124130249
    },
    {
      "name": "Theoretical computer science",
      "score": 0.40622326731681824
    },
    {
      "name": "Machine learning",
      "score": 0.35174477100372314
    },
    {
      "name": "Algorithm",
      "score": 0.2900475859642029
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4400009020",
      "name": "Institute of Science Tokyo",
      "country": null
    },
    {
      "id": "https://openalex.org/I64189623",
      "name": "Kitasato University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I73613424",
      "name": "National Institute of Advanced Industrial Science and Technology",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I74801974",
      "name": "The University of Tokyo",
      "country": "JP"
    }
  ]
}