{
  "title": "A study of generative large language model for medical research and healthcare",
  "url": "https://openalex.org/W4388725043",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2053153884",
      "name": "Cheng Peng",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2104885275",
      "name": "Xi Yang",
      "affiliations": [
        "University of Florida Health",
        "UF Health Cancer Center",
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2562588504",
      "name": "Aokun Chen",
      "affiliations": [
        "University of Florida",
        "UF Health Cancer Center",
        "University of Florida Health"
      ]
    },
    {
      "id": "https://openalex.org/A2658025527",
      "name": "Kaleb E. Smith",
      "affiliations": [
        "Nvidia (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A4313872569",
      "name": "Nima PourNejatian",
      "affiliations": [
        "Nvidia (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A4284724095",
      "name": "Anthony B Costa",
      "affiliations": [
        "Nvidia (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2153871117",
      "name": "Cheryl Martin",
      "affiliations": [
        "Nvidia (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2151813069",
      "name": "Mona G. Flores",
      "affiliations": [
        "Nvidia (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A1985094872",
      "name": "Ying Zhang",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A1711072056",
      "name": "Tanja Magoč",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2803212715",
      "name": "Gloria Lipori",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2673619806",
      "name": "Duane A Mitchell",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": null,
      "name": "Naykky S. Ospina",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2518493606",
      "name": "Mustafa M. Ahmed",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2063760299",
      "name": "William R. Hogan",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A4202335738",
      "name": "Elizabeth A Shenkman",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2116565376",
      "name": "Yi Guo",
      "affiliations": [
        "UF Health Cancer Center",
        "University of Florida Health",
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A1985857611",
      "name": "Jiang Bian",
      "affiliations": [
        "University of Florida",
        "University of Florida Health",
        "UF Health Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2101355887",
      "name": "Yonghui Wu",
      "affiliations": [
        "UF Health Cancer Center",
        "University of Florida Health",
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2053153884",
      "name": "Cheng Peng",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2104885275",
      "name": "Xi Yang",
      "affiliations": [
        "University of Florida Health",
        "UF Health Cancer Center",
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2562588504",
      "name": "Aokun Chen",
      "affiliations": [
        "University of Florida Health",
        "UF Health Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2658025527",
      "name": "Kaleb E. Smith",
      "affiliations": [
        "Nvidia (United States)",
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A4313872569",
      "name": "Nima PourNejatian",
      "affiliations": [
        "Nvidia (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A4284724095",
      "name": "Anthony B Costa",
      "affiliations": [
        "Nvidia (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2153871117",
      "name": "Cheryl Martin",
      "affiliations": [
        "Nvidia (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2151813069",
      "name": "Mona G. Flores",
      "affiliations": [
        "Nvidia (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A1985094872",
      "name": "Ying Zhang",
      "affiliations": [
        "University of Florida Health",
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A1711072056",
      "name": "Tanja Magoč",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2803212715",
      "name": "Gloria Lipori",
      "affiliations": [
        "University of Florida",
        null
      ]
    },
    {
      "id": "https://openalex.org/A2673619806",
      "name": "Duane A Mitchell",
      "affiliations": [
        null
      ]
    },
    {
      "id": null,
      "name": "Naykky S. Ospina",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2518493606",
      "name": "Mustafa M. Ahmed",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2063760299",
      "name": "William R. Hogan",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A4202335738",
      "name": "Elizabeth A Shenkman",
      "affiliations": [
        "University of Florida"
      ]
    },
    {
      "id": "https://openalex.org/A2116565376",
      "name": "Yi Guo",
      "affiliations": [
        "UF Health Cancer Center",
        "University of Florida",
        "University of Florida Health"
      ]
    },
    {
      "id": "https://openalex.org/A1985857611",
      "name": "Jiang Bian",
      "affiliations": [
        "University of Florida",
        "University of Florida Health",
        "UF Health Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2101355887",
      "name": "Yonghui Wu",
      "affiliations": [
        "University of Florida Health",
        "University of Florida",
        "UF Health Cancer Center"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4361289889",
    "https://openalex.org/W4319301505",
    "https://openalex.org/W4323350039",
    "https://openalex.org/W4320920036",
    "https://openalex.org/W4324370593",
    "https://openalex.org/W4323050332",
    "https://openalex.org/W4353015365",
    "https://openalex.org/W3112631310",
    "https://openalex.org/W4367186868",
    "https://openalex.org/W3185341429",
    "https://openalex.org/W4312220150",
    "https://openalex.org/W3095319910",
    "https://openalex.org/W4297253404",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W4245160364",
    "https://openalex.org/W4385381606",
    "https://openalex.org/W2396881363",
    "https://openalex.org/W3209293071",
    "https://openalex.org/W3178751578",
    "https://openalex.org/W3214342214",
    "https://openalex.org/W4380591192",
    "https://openalex.org/W4220962859",
    "https://openalex.org/W2802884616",
    "https://openalex.org/W2968956882",
    "https://openalex.org/W4379769651",
    "https://openalex.org/W4365458667",
    "https://openalex.org/W2893425640",
    "https://openalex.org/W2993961432",
    "https://openalex.org/W3174770825",
    "https://openalex.org/W2170189740",
    "https://openalex.org/W2346452181",
    "https://openalex.org/W3202242582",
    "https://openalex.org/W2970482702",
    "https://openalex.org/W3088056511",
    "https://openalex.org/W2803267010",
    "https://openalex.org/W6636364444",
    "https://openalex.org/W1996445490"
  ],
  "abstract": "Abstract There are enormous enthusiasm and concerns in applying large language models (LLMs) to healthcare. Yet current assumptions are based on general-purpose LLMs such as ChatGPT, which are not developed for medical use. This study develops a generative clinical LLM, GatorTronGPT, using 277 billion words of text including (1) 82 billion words of clinical text from 126 clinical departments and approximately 2 million patients at the University of Florida Health and (2) 195 billion words of diverse general English text. We train GatorTronGPT using a GPT-3 architecture with up to 20 billion parameters and evaluate its utility for biomedical natural language processing (NLP) and healthcare text generation. GatorTronGPT improves biomedical natural language processing. We apply GatorTronGPT to generate 20 billion words of synthetic text. Synthetic NLP models trained using synthetic text generated by GatorTronGPT outperform models trained using real-world clinical text. Physicians’ Turing test using 1 (worst) to 9 (best) scale shows that there are no significant differences in linguistic readability ( p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical relevance ( p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that physicians cannot differentiate them ( p &lt; 0.001). This study provides insights into the opportunities and challenges of LLMs for medical research and healthcare.",
  "full_text": "ARTICLE OPEN\nA study of generative large language model for medical\nresearch and healthcare\nCheng Peng 1, Xi Yang1,2, Aokun Chen1,2, Kaleb E. Smith3, Nima PourNejatian3, Anthony B. Costa3, Cheryl Martin3, Mona G. Flores 3,\nYing Zhang 4, Tanja Magoc5, Gloria Lipori 5,6, Duane A. Mitchell 6, Naykky S. Ospina7, Mustafa M. Ahmed8, William R. Hogan 1,\nElizabeth A. Shenkman 1, Yi Guo 1,2, Jiang Bian 1,2 and Yonghui Wu 1,2 ✉\nThere are enormous enthusiasm and concerns in applying large language models (LLMs) to healthcare. Yet current assumptions are\nbased on general-purpose LLMs such as ChatGPT, which are not developed for medical use. This study develops a generative\nclinical LLM, GatorTronGPT, using 277 billion words of text including (1) 82 billion words of clinical text from 126 clinical\ndepartments and approximately 2 million patients at the University of Florida Health and (2) 195 billion words of diverse general\nEnglish text. We train GatorTronGPT using a GPT-3 architecture with up to 20 billion parameters and evaluate its utility for\nbiomedical natural language processing (NLP) and healthcare text generation. GatorTronGPT improves biomedical natural\nlanguage processing. We apply GatorTronGPT to generate 20 billion words of synthetic text. Synthetic NLP models trained using\nsynthetic text generated by GatorTronGPT outperform models trained using real-world clinical text. Physicians’Turing test using 1\n(worst) to 9 (best) scale shows that there are no signiﬁcant differences in linguistic readability (p = 0.22; 6.57 of GatorTronGPT\ncompared with 6.93 of human) and clinical relevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that\nphysicians cannot differentiate them (p < 0.001). This study provides insights into the opportunities and challenges of LLMs for\nmedical research and healthcare.\nnpj Digital Medicine          (2023) 6:210 ; https://doi.org/10.1038/s41746-023-00958-w\nINTRODUCTION\nGenerative large language models (LLMs) such as the ChatGPT\n1\nhave surprised the world by answering questions conversationally\nand generating textual content such as emails, articles, and even\ncomputer codes, triggering enormous enthusiasm in applying\nLLMs to healthcare2–4. People are enthusiastic about LLMs in the\npotential to facilitate documentation of patient reports (e.g., a\nprogress report)3,4, improving diagnostic accuracy5, and assisting\nin various clinical care6,7, while at the same time concerning the\nhallucinations and fabrications7,8, bias and stereotype9, and risks\nof patient privacy and ethics10. Yet, this enthusiasm and concerns\nare based on ChatGPT, which is not designed for healthcare use1.\nUntil now, it is unclear how this disruptive technology can help\nmedical research and potentially improve the quality of\nhealthcare.\nLanguage model is a simple statistical distribution used in\nnatural language processing (NLP) to formulate the probability of\na sequence of words or the next word in a sequence. Surprisingly,\nwhen it is used as a learning objective to train a speciﬁc neural\nnetwork architecture named transformer, and when the model\nsize is very large such as billions or hundreds of billions of\nparameters, important arti ﬁcial intelligence (AI) emerges. For\nexample, LLMs can learn knowledge from one task and apply it to\nanother task (i.e., transfer learning), learn from very few labeled\nsamples (i.e., few-shot learning), and learn without human-labeled\nsamples (i.e., zero-shot learning)11–13. The LLM pretrained using\ndecoder-only transformer such as GPT-3 is known as generative\nLLM as it can generate human-like text. The conversational ability\nof LLMs is achieved using prompt-based text generation14, the key\ntechnology guiding LLMs to generate reasonable answers and\ncontextual contents.\nThis study aims to develop a generative LLM using real-world\nclinical text and evaluate its utility for medical research and\nhealthcare. We train GatorTronGPT using 82 billion words of de-\nidentiﬁed clinical text\n15 from University of Florida (UF) Health and\n195 billion diverse English words from the Pile16 dataset. We train\nGatorTronGPT from scratch using the GPT-317 architecture. We\nformulate biomedical relation extraction and question answering\nusing a uniﬁed text generation architecture\n18 to evaluate how\nGatorTronGPT could beneﬁt medical research using 6 benchmark\ndatasets. To examine the utility of text generation in the clinical\ndomain, we apply GatorTronGPT to generate 20 billion words of\nsynthetic clinical text, which are used to train synthetic NLP\nmodels using BERT\n19 architecture, denoted as GatorTronS ( ‘S’\nstands for synthetic). We compare GatorTronS models with\nGatorTron\n15, a clinical NLP model trained using real-world 90\nbillion words of text, to test the hypothesis that generative clinical\nLLMs can be used to generate synthetic clinical text for medical\nresearch. To test if LLMs could be used in healthcare, two internal\nmedicine subspecialists from endocrinology (NSO) and cardiology\n(MMA) manually evaluate clinical paragraphs written by Gator-\nTronGPT compared with real-world paragraphs written by UF\nHealth physicians. Figure1 shows an overview of the study design.\n1Department of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, FL, USA.2Cancer Informatics Shared Resource, University of\nFlorida Health Cancer Center, Gainesville, FL, USA.3NVIDIA, Santa Clara, CA, USA.4Research Computing, University of Florida, Gainesville, FL, USA.5Integrated Data Repository\nResearch Services, University of Florida, Gainesville, FL, USA. 6Lillian S. Wells Department of Neurosurgery, Clinical and Translational Science Institute, University of\nFlorida, Gainesville, FL, USA.7Division of Endocrinology, Department of Medicine, College of Medicine, University of Florida, Gainesville, FL, USA.8Division of Cardiovascular\nMedicine, Department of Medicine, College of Medicine, University of Florida, Gainesville, FL, USA. Xi Yangﬁnished this work when he was a full-time employee at the University\nof Florida. ✉email: yonghui.wu@uﬂ.edu\nwww.nature.com/npjdigitalmed\nPublished in partnership with Seoul National University Bundang Hospital\n1234567890():,;\nThis study provides valuable insights into the opportunities and\nchallenges of LLMs for medical research and healthcare.\nRESULTS\nTraining of GatorTronGPT from scratch\nTraining the 5 billion GatorTronGPT model used approximately 6\ndays and the 20 billion model used about 20 days on 560 A100\n80 G GPUs from 70 NVIDIA DGX nodes using the NVIDIA SuperPOD\nreference cluster architecture. Figure 2 shows the training and\nvalidation loss. Table 1 compares GatorTronGPT with GatorTronS\nand GatorTron on model architecture, training dataset, parameter\nsize, and whether the model is a generative LLM, to help\ndifferentiate the three LLMs.\nGatorTronGPT for Biomedical natural language processing\nTable 2a compares GatorTronGPT with four existing biomedical\ntransformer models on end-to-end relation extraction of drug-\ndrug interaction, chemical-disease relation, and drug-target\ninteraction. GatorTronGPT outperformed all existing models, with\nthe best F1-score of 0.500, 0.494, and 0.419, respectively.\nGatorTronGPT improved state-of-the-art by 3–10% compared with\nthe second-best BioGPT\n18 model. We consistently observed\nperformance improvement when scaling up the size of Gator-\nTronGPT. Table 2b compares GatorTronGPT with six existing\nbiomedical transformers using three benchmark datasets for\nbiomedical question answering. The GatorTronGPT model with 20\nbillion parameters tied with BioLinkBERT on the MedQA dataset\nachieving the best performance of 0.451. GatorTronGPT also\nachieved the second-best performance of 0.776 for the Pub-\nMedQA dataset compared with the best performance of 0.782\nfrom BioGPT. The performance of GatorTronGPT on the MedMCQA\ndataset was lower than a much larger LLM, Galactica, with 120\nbillion parameters.\nEvaluation of GatorTronS\nTables 3 and 4 compare GatorTronS trained with different sizes of\nsynthetic clinical text with ClinicalBERT and GatorTron\n15. For\nclinical concept extraction, GatorTronS, trained using 20 billion\nand 5 billion synthetic clinical text, achieved the best F1-score for\nFig. 1 Develop a clinical generative large language model, GatorTronGPT, for biomedical natural language processing, clinical text\ngeneration, and healthcare text evaluation. aTrain GatorTronGPT from scratch using GPT-3 architecture with up to 20 billion parameters.\nb Solve biomedical relation extraction and question answering using a uni ﬁed P-tuning base text generation architecture. c Apply\nGatorTronGPT to generate 20 billion words of synthetic clinical text, which was used to train synthetic natural language processing model,\nGatorTronS. d Turing evaluation of 30 paragraphs of text written by GatorTronGPT mixed with 30 real-world paragraphs written by UF Health\nphysicians. TrM transformer unit; B billion.\nab\nFig. 2 Training loss and validation loss for GatorTronGPT 5 billion and 20 billion models. aTraining loss. b Validation loss.\nC. Peng et al.\n2\nnpj Digital Medicine (2023)   210 Published in partnership with Seoul National University Bundang Hospital\n1234567890():,;\nthe three benchmark datasets. GatorTronS outperformed the\noriginal GatorTron model by >1% F1-score on all three benchmark\ndatasets. For medical relation extraction, the GatorTronS trained\nusing 10 billion synthetic clinical text achieved the best F1-score\nof 0.962 on the 2018 n2c2 challenge benchmark dataset, which is\ncomparable with the original GatorTron model (0.960). For\nsemantic textual similarity and natural language inference,\nGatorTronS achieved the best evaluation scores, outperforming\nthe original GatorTron by >1%. For question answering using\nemrQA dataset, GatorTronS outperformed the original GatorTron\nmodel trained using real-world clinical text by >1%. The\ncomparison results show that a minimum of 5 billion words of\nsynthetic clinical text are required to train a synthetic model with\ncomparable performance to GatorTron, a transformer trained\nusing 82 billion words of real-world UF Health clinical text. Figure3\ncompares GatorTronS models trained with different sizes of\nsynthetic text using line plots. We observed consistent\nperformance improvements from all eight datasets by increasing\nthe size of synthetic text from 1 billion to 5 billion words. The\nimprovements are not consistent when increasing the data size\nfrom 5 billion up to 20 billion words.\nPhysicians’ Turing test\nThe Turing test results show that, on average, less than half\n(49.2%) of the clinical notes were identiﬁed correctly, including\n36.7% of the synthetic notes and 61.7% of the human notes\n(Table 5a). Among the 30 synthetic notes written by Gator-\nTronGPT, 9 (30.0%) and 13 (43.4%) were correctly labeled as‘AI’by\nthe two physicians, respectively. Among the 30 human notes\nwritten by physicians, 17 (56.7%) and 20 (66.7%) were correctly\nlabeled as ‘Human’, respectively. Considering GatorTronGPT was\nconsidered as a human for more than 30% of the instances (the\ncriteria from Turing test)\n20, GatorTronGPT passed the Turing test\nTable 1. Comparison of GatorTronGPT, GatorTronS, and GatorTron.\nModel Architecture Training dataset Parameters Generative or not\nGatorTronGPT GPT3-based\nDecoder architecture\n82 billion clinical words,\n195 billion diverse English words\n5 billion,\n20 billion\nGenerative LLM\nGatorTronS BERT-based\nEncoder architecture\n20 billion words of synthetic clinical text generated by\nGatorTronGPT\n345 million Non-generative LLM\nGatorTron BERT-based Encoder\narchitecture\n82 billion clinical words, 6 billion words from PubMed,\n2.5 billion words from Wikipedia,\n0.5 billion words from MIMIC III\n345 million,\n3.9 billion,\n8.9 billion\nNon-generative LLM\nTable 2. Comparison of GatorTronGPT with existing transformer models for (a) biomedical relation extraction and (b) question answering.\na\nBiomedical Relation extraction\nDDI BC5CDR KD-DTI\nModel Pre Rec F1 Pre Rec F1 Pre Rec F1\nGPT-2_medium 0.234 0.319 0.247 0.439 0.326 0.374 0.305 0.279 0.285\nREBEL 0.354 0.286 0.283 0.343 0.395 0.367 0.324 0.296 0.304\nREBEL-pt 0.465 0.396 0.406 0.409 0.212 0.279 0.357 0.326 0.333\nBioGPT 0.417 0.448 0.408 0.494 0.412 0.450 0.400 0.397 0.384\nGatorTronGPT-5B 0.466 0.518 0.491 0.587 0.434 0.472 0.422 0.436 0.412\nGatorTronGPT-20B 0.476 0.521 0.500 0.543 0.499 0.494 0.422 0.440 0.419\nb\nQuestion answering\nPubMedQA MedQA (USMLE) MedMCQA\nModel Accuracy Accuracy Accuracy\nPubMedBERT 0.558 0.381 NA\nBioELECTRa 0.642 NA NA\nBioLinkBERT 0.702 0.451 NA\nGPT-2 0.750 0.333 NA\nBioGPT 0.782 NA NA\nGalactica_120B 0.776 0.444 0.529\nGatorTronGPT-5B 0.758 0.402 0.358\nGatorTronGPT-20B 0.776 0.451 0.429\nThe best evaluation scores are bolded.\nDDI drug-drug interaction,BC5CDR BioCreative V chemical-disease relation,KD-DTI drug-target interaction,B billion parameters,NA performance not reported.\nC. Peng et al.\n3\nPublished in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2023)   210 \n(p < 0.001). Table 5b summarizes the means and standard\ndeviations of the linguistic readability and clinical relevance and\nconsistency. Statistical tests show that there is no signi ﬁcant\ndifference between notes written by GatorTronGPT and human\nphysicians in both linguistic readability ( p = 0.22) and clinical\nrelevance and consistency ( p = 0.91). Table 5c shows two\nexamples written by GatorTronGPT; more examples are provided\nin Supplementary Table S1. Percent agreement and interrater\nTable 3. Comparison of GatorTronS with existing transformer-based LLMs for clinical concept extraction and medical relation extraction.\nClinical concept extraction Medical relation extraction\n2010 i2b220 2012 i2b221 2018 n2c222 2018 n2c222\nTransformer Precision Recall F1 score Precision Recall F1 score Precision Recall F1 score Precision Recall F1 score\nClinicalBERT NA NA 0.878 NA NA 0.789 0.859 0.883 0.871 0.968 0.941 0.954\nGatorTron, 90B 0.875 0.904 0.889 0.764 0.822 0.792 0.876 0.904 0.890 0.972 0.948 0.960\nGatorTronS, 1B 0.874 0.907 0.890 0.753 0.812 0.781 0.871 0.892 0.882 0.971 0.945 0.958\nGatorTronS, 5B 0.879 0.909 0.894 0.777 0.823 0.799 0.899 0.903 0.901 0.974 0.949 0.962\nGatorTronS, 10B 0.882 0.911 0.896 0.765 0.823 0.793 0.887 0.904 0.895 0.974 0.950 0.962\nGatorTronS, 20B 0.889 0.911 0.899 0.784 0.836 0.809 0.892 0.907 0.900 0.975 0.947 0.961\nB billion words of text Clinical concepts in 2010 i2b2 and 2012 i2b2 challenges: problems, treatments, lab tests; clinical concepts in 2018 n2c2 challenge: drugs,\nadverse events, and drug-related attributes (e.g., dose). Medical relation in 2018 n2c2 challenge: drug induced adverse events; B: billion words oftext. Best\nevaluation scores are bolded. NA: scores not reported.\nTable 4. Comparison of GatorTronS with existing transformer-based LLMs for semantic textual similarity, natural language inference, and question\nanswering.\nSemantic textual similarity Natural language inference Question answering\n2019 n2c223 MedNLI24 emrQA Medication25 emrQA Relation25\nTransformer Pearson correlation Accuracy F1 score Exact Match F1 score Exact Match\nClinicalBERT 0.879 0.827 0.691 0.241 0.931 0.853\nGatorTron, 90B 0.881 0.867 0.718 0.298 0.954 0.903\nGatorTronS, 1B 0.853 0.851 0.702 0.288 0.965 0.924\nGatorTronS, 5B 0.888 0.882 0.726 0.305 0.968 0.926\nGatorTronS, 10B 0.893 0.886 0.728 0.311 0.972 0.929\nGatorTronS, 20B 0.898 0.885 0.726 0.307 0.973 0.927\nB: billion words of text. The best evaluation scores are bolded.\nFig. 3 Comparison of GatorTronS models trained with 1, 5, 10, and 20 billion words of synthetic text on eight benchmark datasets.B\nbillion words of text.\nC. Peng et al.\n4\nnpj Digital Medicine (2023)   210 Published in partnership with Seoul National University Bundang Hospital\nreliability were found to be good or excellent, as summarized in\nSupplementary Tables S2 and S3.\nDISCUSSION\nThis study develops a generative clinical LLM, GatorTronGPT, using\nthe GPT-3 architecture13 with 277 billion words of mixed clinical\nand English text. GatorTronGPT achieves state-of-the-art perfor-\nmance for four out of six biomedical NLP benchmark datasets. Our\nprevious GatorTron\n15 model, trained using an encoder-only BERT\narchitecture with 8.9 billion parameters, also achieved state-of-\nthe-art performance on six clinical NLP benchmark datasets. The\ntwo studies demonstrate the beneﬁt of LLMs for biomedical and\nclinical research. GatorTronGPT can generate synthetic clinical text\nfor developing synthetic clinical NLP models (i.e., GatorTronS),\nwhich achieve better or comparable performance to GatorTron, an\nNLP model trained using real-world clinical text, demonstrating\nthe utility of synthetic clinical text generation. The physicians ’\nTuring test show that GatorTronGPT can generate clinical text with\ncomparable linguistic readability and clinical relevance to real-\nworld clinical notes. This study provides valuable insights into the\nopportunities and challenges of generative LLMs for medical\nresearch and healthcare.\nWe discover an important utility of synthetic clinical text\ngeneration. To date, there has been a gap in accessing and\nsharing large-scale clinical text and clinical LLMs due to the\nsensitive nature of clinical text and the fact that automatic de-\nidentiﬁcation systems cannot remove 100% protected health\nTable 5. Turing test results.\na.\nGround truth\nAI (n = 30) Human ( n = 30) Total ( n = 60)\nPhysician 1 9 (30.0%) 17 (56.7%) 26 (43.3%)\nPhysician 2 13 (43.3%) 20 (66.7%) 33 (55%)\nOverall 11 (36.7%) 18.5 (61.7%) 29.5 (49.2%)\np-value <0.001 =0.104 <0.001\nb.\nGround truth\nAI (n= 30) Human (n = 30) p-value\nReadability 6.57 (1.22) 6.93 (1.09) 0.22\nClinical relevance 7.00 (1.23) 6.97 (1.07) 0.91\nc.\nExample 1 (Passed Turing test): HISTORY OF PRESENT ILLNESS: Ms. [**NAME**] is a [**AGE**]-year-old female with prior history of left breast cancer\nwho is referred to the [**LOCATION**] Clinic to discuss surgical management of her left lung nodule which was picked up on CT scanning for\nsurveillance. The patient’s chest CT obtained at an outside institution showed an incidentalﬁnding of a left lower lobe pleural nodule, which she\nbrought with her to clinic today for further review. Ms. [**Name**] reports to be doing well, with no change in her baseline level of shortness of\nbreath, but denies any difﬁculty breathing, cough or hemoptysis. She feels essentially back to baseline and plays golf one day a week. Otherwise, Ms.\n[**NAME **] has no other pulmonary complaints and has never smoked tobacco or inhaled second hand smoke. She does report several years of\nintermittent reﬂux, which worsened after eating rough foods. She underwent an upper GI study for this, which showed a small hiatal hernia as well as\na moderate-sized sliding hiatal hernia. She subsequently underwent an abdominal CT for evaluation for mesenteric ischemia and was felt to have a\ndilated pancreatic duct. Due to suspected head pathology on imaging (although theﬁnal report is pending), she underwent an MRI, which conﬁrmed\nno pancreatic pathology. Given this, Ms. [**NAME **] has been trying to avoid fatty and fried foods, which has improved her reﬂux. Ms. [**NAME **]\ndoes report recent onset of sleep apnea, for which she is using CPAP every night for the last month. She tolerates this well without complaints of dry\nmouth, gasping for air, or undue sleepiness. Ms. [**NAME **] was seen in our outpatient [**LOCATION**] clinic on [**DATE**] at which time it was\ndetermined that in order to obtain a tissue diagnosis of this left lower lobe lesion a VATS approach would be utilized. She presents today for further\npre-operative planning. Currently, Ms. [**NAME**] denies any pulmonary symptoms, fevers, chills, cough or weight loss. PAST MEDICAL HISTORY: 1.\nCARDIAC RISK FACTORS: Hypertension, Hyperlipidemia 2. CARDIAC HISTORY: None 3. OTHER PAST MEDICAL HISTORY: Left lower lobe pulmonary\nnodule\nExample 2 (Failed Turing test): Assessment: ICD-9-CM 1. Pain in joint, pelvic region and thigh, unspeciﬁed laterality 719.45 fentaNYL (DURAGESIC) 75\nMCG/HR HYDROcodone-acetaminophen (VICODIN HP) 5-300 MG Tablet 2. Migraine NOS/not Intrcbl 346.90 SUMAtriptan Succinate 3. Bone Pain\nArthritis 333.90 Dexamethasone Sodium Phosphate 4. Bipolar disorder 296.80 traZODone (DESYREL) 100 MG Tablet prazosin (MINIPRESS) 2 MG\ncapsule carvedilol (COREG) 3.125 MG tablet isosorbide mononitrate (IMDUR) 30 MG CR tablet Refer to Psychiatry clopidogrel (PLAVIX) 75 MG tablet\nSUMAtriptan Succinate 5. ASTHMA UNSPECIFIED 493.90 albuterol (PROAIR HFA;VENTOLIN HFA) 108 (90 BASE) MCG/ACT inhaler 6. Major depressive\ndisorder, single episode, unspeciﬁed 296.20 DULoxetine (CYMBALTA) 60 MG capsule Refer to Psychiatry amitriptyline (ELAVIL) 25 MG tablet\ntraZODone (DESYREL) 100 MG Tablet 7. POST-SURGICAL VARICOSE VEINS of LOWER EXTREMITIES 454.9 fentaNYL (DURAGESIC) 75 MCG/HR 8. Other\nand unspeciﬁed hyperlipidemia 272.4 simvastatin (ZOCOR) 40 MG tablet COMPREHENSIVE METABOLIC PANEL 9. PND (post-nasal drip) 784.91\nloratadine (CLARITIN) 10 MG tablet 10. Bipolar I disorder, single manic episode, unspeciﬁed 296.00 clonazePAM (KlonoPIN) 1 MG tablet Refer to\nPsychiatry 11. Allergic rhinitis 477.9 loratadine (CLARITIN) 10 MG tablet 12. Grief reaction 309.0 traZODone (DESYREL) 100 MG Tablet 13. Encounter for\nlong-term (current) use of other medications V58.69 methocarbamol (ROBAXIN) 750 MG tablet COMPREHENSIVE METABOLIC PANEL 14. GERD\n(gastroesophageal reﬂux disease) 530.81 lansoprazole (PRE\na. Number and percentage of correctly identiﬁed notes; p-values were calculated using Chi-squared test. b. Means and standard deviations of the quality\nmeasures; p-values were calculated usingT-test. c. Two examples of synthetic clinical text generated by GatorTronGPT. The text generation stops at maximum\n512 tokens. Pass Turing test: both physicians labeled as“Human”; Fail Turing Test: both physicians labeled as“AI”.\nC. Peng et al.\n5\nPublished in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2023)   210 \ninformation (PHI). Not surprisingly, a recent study21 on clinical\nfoundation models point out that most LLMs in the medical\ndomain are trained using“small, narrowly-scoped” clinical dataset\nwith limited note types (e.g., MIMIC 22)o r “broad, public ”\nbiomedical literature (e.g., PubMed) that has limited insights to\nhealthcare. Generative LLMs can provide large-scale synthetic\nclinical text to ﬁll the gap. We compare the synthetic text with\nreal-world clinical text to examine why GatorTronS, a transformer\nmodel trained using a much smaller (e.g., 5 billion words)\nsynthetic clinical text corpus, could achieve better or comparable\nperformance to GatorTron\n15, a transformer model trained using a\nmuch larger (90 billion words) real-world clinical text corpus. We\nidentify potential reasons including (1) real-world clinical text has\nsigniﬁcant redundancies, which is a well-known characteristic of\nclinical narratives\n23, and (2) GatorTronGPT generates more diverse\nsynthetic clinical text. We randomly sample a subset of real-world\nclinical notes with number of words comparable to the synthetic\ntext (i.e., 20 billion words) to compare the coverage of unigrams\n(i.e., individual tokens) and bigrams (i.e., two consecutive tokens).\nThe comparison results show that the synthetic text generated by\nGatorTronGPT contain remarkably more diverse unigrams (40.43\nmillion : 4.82 million, ratios are reported as “synthetic” : “real\nnotes”) and bigrams (416.35 million : 62.51 million); the synthetic\ntext also has higher entropy than the real-world clinical text (4.97:\n4.95). Supplementary Table S4 provides detailed comparison\nresults and examples. A previous study\n24 has reported that by\naugmenting real-world clinical training data using additional\nhuman annotated synthetic text generated by a smaller gen-\nerative LLM, GPT-2, NLP models can achieve better performance.\nOur study further demonstrates that, without additional human\nannotation and augmentation of training data, a larger clinical\nGPT-3 model can generate synthetic clinical text to train synthetic\nNLP models outperforming NLP models trained using real-world\nclinical text. Text generation using generative LLMs could mitigate\nthe risk of exposing patient privacy and improve accessing and\nsharing of large-scale clinical text and NLP models, thus enabling\nthe next generation of clinical text analytics using synthetic clinical\ntext.\nGenerative LLMs aspire to become a“Uniﬁed Field Theory” to\nunify most fundamental NLP tasks using a single model\narchitecture. It might be still early to judge if LLMs will become\nthe one and only foundation model\n12 for NLP, but it looks like we\nare closer than ever. Generative LLMs have the potential to impact\nmedical research in many aspects. In addition to performance\nimprovement demonstrated in this study, generative LLMs\nprovide a uniﬁed solution using prompt-based text generation\n25,\nwhich leads to a new paradigm of“one model for all NLP tasks”\nand has better few-shot learning and transfer learning ability to\ndeliver portable clinical NLP systems 13,26. The evaluation of\nGatorTronGPT shows that clinical LLMs can be used to generate\nclinical-relevant content with the potential to help document\n3 and\ncode patient information in EHR systems, thus reducing the\nextensively onerous documentation burden for clinicians27–29. The\nprompt-based text generation of LLMs can potentially help\ncompose treatment plans by integrating instructions from clinical\nguidelines and patients’ historical records in EHRs. The conversa-\ntional ability of LLMs provides opportunities to develop intelligent\nEHR systems with human-like communication\n2, where healthcare\nproviders, patients, and other stakeholders can communicate in an\nintelligent electronic health record (EHR) system. Industry\nstakeholders such as Epic and Nuance have been reported to be\nexploring these potentials\n30,31.\nOur Turing test focuses on (1) linguistic readability; (2) clinical\nrelevance; and (3) physicians’ability to differentiate synthetic and\nhuman notes. The statistical tests show that there are no\nsigniﬁcant differences in linguistic readability (p = 0.22; 6.57 of\nGatorTronGPT compared with 6.93 of human) or clinical relevance\n(p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human).\nFurther, physicians cannot differentiate them (p < 0.001), suggest-\ning the potential utility of GatorTronGPT for text generation in\nhealthcare. Two physician evaluatorsﬁnd that the texts written by\nGatorTronGPT generally lack clinical logic, indicating that more\nresearch and development are needed to make this technology\nmature for healthcare. Our Turing test focuses on statistical\ndifferences not utility in real-world clinical practice, which should\nbe examined in future studies when this technology matures. A\nrecent study\n32 examined an LLM developed at New York\nUniversity, i.e., NYUTron, and our previously developed Gator-\nTron15 for prediction of readmission, in-hospital mortality,\ncomorbidity, length of stay, and insurance denial, demonstrating\nthe potential utility of LLMs in healthcare.\nWhile LLMs are promising for healthcare applications, much\nmore research and development are needed to achieve this goal.\nCurrent general-purpose LLMs are designed for conversation as a\nchatbot outside of healthcare. Therefore, the current use of\nChatGPT for healthcare is more like a typical case of intended use\nversus actual use as described in the medical device regulation\n33.\nDomain-speciﬁc LLMs are needed for clinical applications. Due to\nthe noisy data and probabilistic nature of text generation, LLMs\nare prone to confabulation or hallucination, which is dangerous\nfor healthcare. In this study, we adopted robust decoding\nstrategies (e.g., nucleus sampling) to alleviate potential off-target\ntext generation. Researchers are exploring solutions such as\nreinforcement learning from human feedback (RLHF)\n34 to reduce\nhallucinations, but it is still a not yet solved limitation of current\nLLMs. Future studies should explore strategies to better control\nthe hallucinations at a minimal level to ensure the safety of using\nLLMs in healthcare. The security and risk of LLMs must be carefully\nexamined in healthcare settings. We applied a de-identiﬁcation\nsystem to remove PHIs from UF Health notes before training\nGatorTronGPT, future studies should carefully examine if Gator-\nTronGPT has potential risk of speaking out PHIs and quantify the\npotential risk of re-identify real-world patients. Synthetic data,\nthough generated by AI models, may still mirror the characteristics\nof its source material (e.g., UF health clinical notes). For example,\nChatGPT has been reported to accidentally leak sensitive business\ndata from a private company\n35. In addition, people are increas-\ningly aware of the potential bias of AI applications in healthcare.\nBias inherited from the original training data may be imitated and\nsometimes even ampli ﬁed by AI models, which may cause\nsystematic bias to speciﬁc patient groups\n36. Future studies should\nexplore strategies to mitigate potential bias and ensure fairness of\nLLM applications. Like any medical AI applications, it is necessary\nto carefully examine this disruptive new technology to guide its\napplication and make it“approved ” AI-enabled medical tool\n37.\nMETHODS\nWe developed GatorTronGPT using 82 billion words of de-\nidentiﬁed clinical text15 from the University of Florida (UF) Health\nand 195 billion diverse English words from the Pile16 dataset. We\ntrained GatorTronGPT from scratch using the GPT-317 architecture\n(used by ChatGPT). We formulated biomedical relation extraction\nand question answering using a uniﬁed text generation archi-\ntecture18 and evaluated GatorTronGPT using 6 biomedical bench-\nmark datasets. To examine the utility of text generation, we\napplied GatorTronGPT to generate 20 billion words of synthetic\nclinical text, which were used to train synthetic NLP models,\ndenoted as GatorTronS (“S” stands for synthetic). We compared\nGatorTronS with GatorTron\n15, a clinical NLP model trained with the\nsame architecture but using real-world clinical text. To test if LLMs\ncould generate text for healthcare settings, two internal medicine\nsubspecialists from endocrinology (NSO) and cardiology (MMA)\nmanually evaluated 60 clinical paragraphs including 30 para-\ngraphs written by GatorTronGPT randomly mixed with 30 real-\nC. Peng et al.\n6\nnpj Digital Medicine (2023)   210 Published in partnership with Seoul National University Bundang Hospital\nworld paragraphs written by UF Health physicians. Figure1 shows\nan overview of the study design.\nData source\nThis study used 82 billion words of clinical narratives from UF\nHealth Integrated Data Repository (IDR) and 195 billion words of\ndiverse English words from the Pile 16 corpus. This study was\napproved by the University of Florida Institutional Review Board\nunder IRB202102223; the need for patient consent was waived. At\nUF Health, we collected approximately 290 million clinical notes\nfrom 2011–2021 from over 126 departments, approximately 2\nmillion patients and 50 million encounters from inpatient,\noutpatient, and emergency settings\n15. We merged the UF Health\nclinical corpus with the Pile16 dataset to generate a large corpus\nwith 277 billion words. We performed minimal preprocessing for\nthe Pile dataset and applied a de-identiﬁcation system to remove\n18 PHI categories deﬁned in the Health Insurance Portability and\nAccountability Act (HIPAA) from the UF Health notes.\nPreprocessing and de-identiﬁcation of clinical text\nFollowing our previous study15, we performed a minimal preproces-\nsing procedure. First, we removed all empty notes and the notes\nwith less than 10 characters followed by performing a deduplication\nat the note level using the exact string match strategy. Then, we\nleveraged an internally developed preprocessing tool ( https://\ngithub.com/uf-hobi-informatics-lab/NLPreprocessing)t on o r m a l i z e\nthe clinical text. The normalization processing consists of three steps\nincluding (1) unifying all text into UTF-8 encoding, removing illegal\nUTF-8 strings, and removing HTML/XML tags if any; (2) sentence\nboundary detection where we normalize the clinical notes into\nsentences; (3) word tokenization where we used heuristic rules to\nseparate punctuation and special symbols (e.g., slash, parenthesis)\nfrom words (e.g., converting“(HbA1c)” to “(HbA1c)” and “excision/\nchemo” to “excision/chemo”)a n d ﬁxing concatenations (e.g.,\nmissing white space like converting“CancerScreening ” to “Cancer\nScreening”). After preprocessing, we performed another deduplica-\ntion at the sentence level using the exact string match strategy.\nTo de-identiﬁed the UF Health clinical notes, we adopted an\ninternally developed de-identiﬁcation system which consists of\nan LSTM-CRFs based model and a postprocessing module\nreplacing system-detected protected health information (PHI)\nentities with dummy strings (e.g., replace patients’ names with\n[**NAME**]). We adopted the safe-harbor method to identify 18\nPHI categories deﬁned in the Health Insurance Portability and\nAccountability Act (HIPAA). The LSTM-CRFs model for PHI\ndetection was trained using the publicly available 2014 i2b2\nde-identiﬁcation datasets and an internal dataset with over 1100\nclinical notes from UF Health annotated for PHI removal (named\nas UF-deid-dataset; not publicly available due to IRB restrictions).\nAfter three years of continuous customization and improvement\nat UF Health, the current model achieved an overall F1 score of\n97.98% (precision of 96.27% and recall of 99.76%) on the UF-\ndeid-dataset test set, which means our de-identiﬁcation system\ncan remove 99.76% of all PHIs. Detailed information about the\ndevelopment of the de-identi ﬁcation system can be accessed\nfrom our previous paper\n38.\nTrain GatorTronGPT from scratch\nWe trained GatorTronGPT using 5 billion parameters and 20 billion\nparameters and determined the number of layers, hidden sizes,\nand number of attention heads according to the guidelines for\noptimal depth-to-width parameter allocation proposed by ref.\n39\nas well as our previous experience in developing GatorTron15. The\n5 billion model has 24 layers, hidden size of 4,096, and number of\nattention heads of 32; the 20 billion model has 44 layers, hidden\nsize of 6144, and number of attention heads of 48. We trained the\n5 billion model using a 2-way tensor model parallel with a batch\nsize of 1120 and learning rate of 1.200E-05. We trained the 20\nbillion model using an 8-way tensor model parallel with a batch\nsize of 560 and a learning rate of 1.000E-05. We adopted a dropout\nrate of 0.1. We inherited the GPT-3 architecture implemented in\nthe MegaTron-LM\n40 and trained GatorTronGPT models from\nscratch with the default GPT-3 loss function13. We used a total\nnumber of 560 NVIDIA DGX A100 GPUs from 70 superPOD nodes\nat UF’s HiPerGator-AI cluster to train GatorTronGPT by leveraging\nboth data-level and model-level parallelisms implemented by the\nMegatron-LM package\n40. (See https://github.com/NVIDIA/\nMegatron-LM for more details) We monitored the training\nprogress by training loss and validation loss using 3% of the data\nand stopped the training when there was no improvement.\nGatorTronGPT for biomedical relation extraction and question\nanswering\nEnd-to-end relation extraction is an NLP task to identify the triplets\n<concept1, concept2, relation > from biomedical text. Question\nanswering is to identify theanswer for a given question and the\ncontext. Following previous studies\n18,41, we approached the two\ntasks using a uniﬁed prompt-based text generation architecture.\nSpeciﬁcally, we adopted aﬁxed-LLM prompt-tuning strategy42 to\nattach a continuous embedding (i.e., virtue tokens) to the input\nsequence [virtual tokens; x; y] as a soft prompt to control the text\ngeneration; the LLM was not changed during training. We provide\ndetails in the Supplement.\nEnd-to-end biomedical relation extraction. We compared the two\nGatorTronGPT models with four existing transformer models\nincluding GPT-2\n43, REBEL, REBEL-pt 25, and BioGPT 18 on three\nbiomedical tasks for end-to-end relation extraction using three\nbenchmark datasets including drug-drug interaction 44 (DDI),\nBioCreative V chemical-disease relation 45 (BC5CDR), and drug-\ntarget interaction46 (KD-DTI).\nGPT-2. GPT-2 was trained using text data from 8 million\nwebpages with 1.5 billion parameters, which is a scale-up of the\nﬁrst generation of GPT45 model. The GPT model outperformed\nprevious transformer models on 9 out of 12 NLP tasks, whereas,\nthe GPT-2 model further demonstrated text generation ability,\nwhich laid foundation for complex NLP tasks such as machine\nreading comprehension and question answering.\nREBEL and REBEL-pt. REBEL is a transformer model based on the\nBART architecture designed for end-to-end relation extraction\nusing sequence-to-sequence modeling, which outperformed\nprevious relation extraction models based on classi ﬁcations.\nREBEL-pt is an enhanced version of REBEL by furtherﬁne-tuning\nit using the triplets derived using Wikipedia hyperlinks.\nBioGPT. BioGPT is a domain-speci ﬁc generative transformer-\nbased LLM developed using the GPT-2 architecture and the\nPubmed biomedical literature, which achieved good performance\nin NLP tasks including relation extraction and question answering\nin the biomedical domain.\nFollowing the previous study\n18, we formulated both biomedical\nrelation extraction and question answering as a prompt-based text\ngeneration model and applied prompt-tuning (p-tuning) algorithms.\nWe concatenate learnable soft prompts (also called virtual prompt\nembeddings) with the word embeddings from thecontext (i.e., input\nsentence). The sample sequence is constructed as [prompt, context,\nrelation], where the prompt is generated using a LSTM model and\nthe relation is the gold standard label including the head entity, tail\nentity, and their relation type. During the inference, thecontext and\nthe prompt are used as the input for our GatorTronGPT model to\ncondition and let the model generate the relations. We converted\nC. Peng et al.\n7\nPublished in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2023)   210 \nthe original relation triplets into a sequence representation. For\nexample, there is an“agonist” relation between a drug -“Igmesine”\nand a target“Opioid receptor sigma 1”, which was converted as:“the\nrelation between [ Igmesine]a n d[ Opioid receptor sigma 1 ]i s\n[agonist]”. Thus, the relation extraction can be solved as a text\ngeneration. During inference, we converted the generated text back\nto triplets for evaluation. We ﬁne-tuned and evaluated our\nGatorTronGPT on the end-to-end relation extraction task across\nfour biomedical datasets: BC5CDR (chemical–disease–relation extrac-\ntion), KD-DTI (drug–target–interaction extraction), DDI (drug–drug–\ninteraction extraction) and 2018 n2c2 (Drug-ADE-relation extraction).\nThe precision, recall, and F1 score were used for evaluation.\nBiomedical question answering. We compared GatorTronGPT with\nsix existing transformer models using three widely used bench-\nmark dataset including PubMedQA\n47— a biomedical question\nanswering dataset collected from PubMed abstracts, which\nrequires answering questions with ‘yes/no/maybe’ ;\nMedMCQA48— a large-scale multi-choice question answering\ndataset designed to address real world medical entrance exam\nquestions covering 2400 healthcare topics and 21 medical\nsubjects; and MedQA-USMLE\n49— a multi-choice dataset collected\nfrom the professional medical board exams. These datasets have\nbeen widely used to evaluate LLMs\n18,47–49.\nGiven a question, a context, and candidate answers, we\nconcatenated the context and the candidate answers into a\nsource sequence and compose the target sequence as: “the\nanswer to the question given possible options is:”, “answer”: “C”.\nThen, we adopted soft prompts instead of hard prompts\n(manually designed clear text phrases) in p-tuning. Speciﬁcally,\nwe used a randomly initiated continuous embedding as soft\nprompts, which were ﬁne-tuned in the training. For the\nPubMedQA dataset, we explored the provided artiﬁcially gener-\nated text data. Speci ﬁcally, we automatically labeled the\ngenerated text using our p-tuning model developed using the\ntraining set and experimented to feedback different proportion of\nauto-labeled data into training. The best performance was\nachieved by using 5% of the auto-labeled artiﬁcially generated\ntext data. For p-tuning, we used the implementation in NVIDIA\nNeMo\n50, which is optimized for LLMs. We used the following\nparameters in our p-tuning: a global batch size of 32, virtual\ntokens for p-tuning 15, encoder MLP with encoder hidden size of\n2048, max sequence length of 4096 for PubMedQA (long\nabstracts), 2048 for MedMCQA and MedQA-USMLE, and a fused\nAdam optimizer with a learning rate of 1e-4 and a weight decay of\n0·01, betas of 0·9 and 0·98, a cosine annealing scheduler\nmonitoring validation loss with a 50 step warm up. For example,\nthe below is a prompt we used for MedQA-USMLE.\n{“taskname”: “usmle-qa”, “prompt”: “QUESTION: A 23-year-\nold man comes to the physician for evaluation of decreased\nhearing, dizziness, and ringing in his right ear for the past\n6 months. Physical examination shows multiple soft, yellow\nplaques and papules on his arms, chest, and back. There is\nsensorineural hearing loss and weakness of facial muscles\nbilaterally. His gait is unsteady. An MRI of the brain shows a\n3-cm mass near the right internal auditory meatus and a\n2-cm mass at the left cerebellopontine angle. The abnormal\ncells in these masses are most likely derived from which of\nthe following embryological structures?\\nMULTIPLE\nCHOICES: (A) Neural tube\\n(B) Surface ectoderm\\n(C) Neural\ncrest\\n(D) Notochord\\nTARGET: the answer to the question\ngiven possible options is:“, “answer”: “C”}\nGatorTronGPT for synthetic clinical text generation. We sought to\ntest the hypothesis that LLMs can generate synthetic clinical text\nto train synthetic NLP models useful for medical research. We\napplied GatorTronGPT to generate synthetic clinical text according\nto a set of seeds without anyﬁne-tuning, which is a typical zero-\nshot learning setting. Then, using the generated synthetic clinical\ntext, we trained synthetic transformer-based NLP models using\nour previous BERT-based GatorTron architecture\n15, denoted as\nGatorTronS ( ‘S’ stands for synthetic). We trained GatorTronS\nmodels using different sizes of synthetic clinical text and\ncompared them with the original GatorTron model trained using\nUF Health clinical text. To make it comparable, we trained\nGatorTronS using the same architecture and number of para-\nmeters (i.e., 345 million) as GatorTron\n15. We provide detailed\ninformation in the Supplement.\nSynthetic clinical text generation . Following previous studies 51,\nwe approached synthetic clinical text generation using an iterative\nsampling algorithm and applied top-p (i.e., nucleus sampling)\nsampling and temperature sampling to balance the diversity and\nquality of text generation\n51. We approached the synthetic clinical\ntext generation as an open-ended text-to-text generation task52,53,\nwhere the generated clinical text is restricted by the context (e.g.,\nthe prompts). Speci ﬁcally, given a sequence of m tokens\nXpre ¼ x1x2:::xm as input context, the task is to generate the next\nn continuation tokens Xcont ¼ xmþ1xmþ2:::xmþn until reaching the\nmax length of 512 tokens. We generate text through iteratively\nsampling from the pre-trained language model GatorTronGPT one\ntoken at a time by conditioning on the preceding context:\nPðxcontjxpreÞ¼\nYmþn\ni¼mþ1\nPðxijx1:::xi/C0 1Þ (1)\nwhere Pðxi jx1 ¼xi/C0 1Þ is the next token distribution. We adoptTop-\np (nucleus) sampling54 during sampling to select words whose\ncumulative probability exceeds a predeﬁned threshold p.X\nx2VðpÞ\nPðxjx1:i/C0 1Þ/C21 p (2)\nwhere VðpÞ is the top-p vocabulary used to sample the next word.\nThis approach dynamically adapts the number of words con-\nsidered at each step based on their probabilities, balancing\ndiversity and coherence of the generated text.\nWe set the parameter of top-p sampling at 0.9 and the\nparameter for temperature sampling at 1.2 according to our\nempirical assessment. We sampled the beginning 15 tokens from\nall sections of the de-identi ﬁed notes from the MIMIC III\ndatabase\n22 and generated approximately 8 million prompts. We\nalso tried several random seeds in GatorTronGPT to generate\nmultiple documents from one prompt. We controlled Gator-\nTronGPT to generate a maximum length of 512 tokens.\nSynthetic NLP model development. We applied GatorTronGPT to\ngenerate different sizes of synthetic clinical text including 1 billion,\n5 billion, 10 billion, and 20 billion words of clinical text and\ndeveloped corresponding synthetic NLP models, denoted as\nGatorTronS. Following our previous study\n15, we trained Gator-\nTronS using the same architecture of GatorTron – a BERT\narchitecture with 345 million parameters.\nComparison with existing transformer models . We compared\nGatorTronS models with ClinicalBERT 55— an existing clinical\ntransformer model and GatorTron15, the current largest clinical\ntransformer model trained using >90 billion words of text, using 5\nclinical NLP tasks including clinical concept extraction, medical\nrelation extraction, semantic textual similarity, natural language\ninference, and question answering.\nTuring test of text generation for healthcare settings. We randomly\nsampled 30 narrative sections from real-world UF Health clinical\nC. Peng et al.\n8\nnpj Digital Medicine (2023)   210 Published in partnership with Seoul National University Bundang Hospital\nnotes, including“past medical history”, “history of present illness”,\n“assessment/plan”, and “chief complaint ”. For each of the\n30 sections, we extracted the beginning 15 tokens as a seed for\nGatorTronGPT to generate a synthetic paragraph up to 512 tokens.\nWe cut off the 30 real-world clinical sections to 512 tokens,\nremoved all format information, and randomly mixed them with\n30 synthetic sections written by GatorTronGPT. Two UF Health\nphysicians (NSO, MMA) manually reviewed the 60 paragraphs of\nnotes to evaluate: (1) linguistic readability on a 1(worst) to 9 (best)\nscale, (2) clinical relevance and consistency on a 1 to 9 scale, (3)\ndetermine if it was written by a human physician or GatorTronGPT.\nPercent agreement and Gwet’sA C\n1 were calculated to evaluate\ninterrater reliability56.\nDATA AVAILABILITY\nThe benchmark datasets that support theﬁndings of this study are available from the\nofﬁcial websites of natural language processing challenges with Data Use\nAgreements. More speciﬁcally: 1. i2b2 2010, 2012 datasets and n2c2 2018, 2019\ndatasets: https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/. 2. MedNLI dataset:\nhttps://physionet.org/content/mednli/1.0.0/. 3. emrQA dataset: https://github.com/\npanushri25/emrQA#download-dataset. 4. The Pile dataset:https://pile.eleuther.ai/.5 .\nUF Health IDR clinical notes are not open to the public due to patient privacy\ninformation. The GatorTronS, and GatorTron models are available as open-source\nresources. The synthetic clinical transformer model, GatorTronS, is available from:\nhttps://huggingface.co/UFNLP/gatortronS. The GatorTron model trained using real-\nworld clinical text is available:https://huggingface.co/UFNLP/gatortron-base.\nCODE AVAILABILITY\nThe computer codes to train GatorTronGPT models are available from: https://\ngithub.com/NVIDIA/Megatron-LM/blob/main/pretrain_gpt.py. The scripts used for\ndata preprocessing, vocabulary training and other utilities are available from:https://\ngithub.com/uf-hobi-informatics-lab/GatorTronGPT. The computer codes to train\nGatorTronS models are available from: https://github.com/NVIDIA/Megatron-LM\nand https://github.com/NVIDIA/NeMo. The computer codes for preprocessing of text\ndata are available from:https://github.com/uf-hobi-informatics-lab/NLPreprocessing.\nReceived: 5 June 2023; Accepted: 1 November 2023;\nREFERENCES\n1. Introducing ChatGPT. https://openai.com/blog/chatgpt.\n2. Lee, P., Bubeck, S. & Petro, J. Beneﬁts, limits, and risks of GPT-4 as an AI chatbot\nfor medicine. N. Engl. J. Med.388, 1233–1239 (2023).\n3. Patel, S. B. & Lam, K. ChatGPT: the future of discharge summaries?Lancet Digit\nHealth 5, e107–e108 (2023).\n4. Ali, S. R., Dobbs, T. D., Hutchings, H. A. & Whitaker, I. S. Using ChatGPT to write\npatient clinic letters.Lancet Digit Health5, e179–e181 (2023).\n5. Hirosawa, T. et al. Diagnostic accuracy of differential-diagnosis lists generated by\ngenerative pretrained transformer 3 chatbot for clinical vignettes with common\nchief complaints: a pilot study.Int. J. Environ. Res. Public Health20, 3378 (2023).\n6. Grünebaum, A., Chervenak, J., Pollet, S. L., Katz, A. & Chervenak, F. A. The Exciting\nPotential for ChatGPT in Obstetrics and Gynecology. Am. J. Obstet. Gynecol .\nhttps://doi.org/10.1016/j.ajog.2023.03.009 (2023).\n7. Cascella, M., Montomoli, J., Bellini, V. & Bignami, E. Evaluating the feasibility of\nChatGPT in healthcare: an analysis of multiple clinical and research scenarios.J.\nMed. Syst. 47, 33 (2023).\n8. Azamﬁrei, R., Kudchadkar, S. R. & Fackler, J. Large language models and the perils\nof their hallucinations.Crit. Care 27, 120 (2023).\n9. Straw, I. & Callison-Burch, C. Artiﬁcial Intelligence in mental health and the biases\nof language based models.PLoS One 15, e0240376 (2020).\n10. Li, H. et al. Ethics of large language models in medicine and medical research.\nLancet Digital Healthhttps://doi.org/10.1016/S2589-7500(23)00083-3 (2023).\n11. Kojima, T., Gu, S. S., Reid, M., Matsuo, Y. & Iwasawa, Y. Large Language Models are\nZero-Shot Reasoners. Adv. Neural Inf. Process. Syst. 35, 22199–213 (2022).\n12. Bommasani, R. et al. On the opportunities and risks of foundation models.arXiv\npreprint arXiv:2108.07258 (2021).\n13. Brown, T., Mann, B. & Ryder, N. Language models are few-shot learners.Adv.\nNeural Inf. Process. Syst.33, 1877–1901 (2020).\n14. Liu, P. et al. Pre-train, prompt, and predict: a systematic survey of prompting\nmethods in natural language processing.ACM Comput. Surv.55,1 –35 (2023).\n15. Yang, X. et al. A large language model for electronic health records.NPJ Digit.\nMed. 5, 194 (2022).\n16. Gao, L. et al. The Pile: an 800GB Dataset of Diverse Text for Language Modeling.\narXiv:2101.00027 (2020).\n17. Floridi, L. & Chiriatti, M. GPT-3: its nature, scope, limits, and consequences.Minds\nMach. 30, 681–694 (2020).\n18. Luo, R. et al. BioGPT: generative pre-trained transformer for biomedical text\ngeneration and mining.Brief. Bioinform. 23, bbac409 (2022).\n19. Devlin, J., Chang, M.-W., Lee, K. & Toutanova, K. BERT: pre-training of deep\nbidirectional transformers for language understanding. inProceedings of the 2019\nConference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\n4171–4186 (Association for Computational Linguistics, 2019). https://doi.org/\n10.18653/v1/N19-1423.\n20. Mohammed, M., Khan, M. B. & Bashier, E. B. M. Machine Learning (CRC Press,\n2016). https://doi.org/10.1201/9781315371658.\n21. Wornow, M. et al. The shaky foundations of large language models and foun-\ndation models for electronic health records.NPJ Digit Med.6, 135 (2023).\n22. Johnson, A. E. W. et al. MIMIC-III, a freely accessible critical care database.Sci. Data\n3, 160035 (2016).\n23. Searle, T., Ibrahim, Z., Teo, J. & Dobson, R. Estimating redundancy in clinical text.J.\nBiomed. Inform. 124, 103938 (2021).\n24. Li, J. et al. Are synthetic clinical notes useful for real natural language processing\ntasks: a case study on clinical entity recognition.J. Am. Med. Inform. Assoc.28,\n2193–2201 (2021).\n25. Huguet Cabot, P.-L. & Navigli, R. REBEL: relation extraction by end-to-end lan-\nguage generation. in Findings of the Association for Computational Linguistics:\nEMNLP 20212370–2381 (Association for Computational Linguistics, 2021).https://\ndoi.org/10.18653/v1/2021.ﬁndings-emnlp.204.\n26. Peng, C. et al. Clinical concept and relation extraction using prompt-based\nmachine reading comprehension. J. Am. Med. Inform. Assoc . https://doi.org/\n10.1093/jamia/ocad107 (2023).\n27. Gaffney, A. et al. Medical documentation burden among US ofﬁce-based physi-\ncians in 2019: a national study.JAMA Intern. Med.182, 564–566 (2022).\n28. Downing, N. L., Bates, D. W. & Longhurst, C. A. Physician burnout in the electronic\nhealth record era: are we ignoring the real cause?Ann. Intern. Med.169, 50 (2018).\n29. Kroth, P. J. et al. Association of electronic health record design and use factors\nwith clinician stress and burnout.JAMA Netw. Open2, e199609 (2019).\n30. Diaz, N. Epic to use Microsoft ’s GPT-4 in EHRs. https://\nwww.beckershospitalreview.com/ehrs/epic-to-use-microsofts-open-ai-in-\nehrs.html.\n31. Trang, B. We’re getting much more aggressive’: Microsoft’s Nuance adds GPT-4 AI\nto its medical note-taking tool.https://www.statnews.com/2023/03/20/microsoft-\nnuance-gpt4-dax-chatgpt/.\n32. Jiang, L. Y. et al. Health system-scale language models are all-purpose prediction\nengines. Nature 619, 357–362 (2023).\n33. Kleesiek, J., Wu, Y., Stiglic, G., Egger, J. & Bian, J. An opinion on ChatGPT in health\ncare-written by humans only. J. Nucl. Med . https://doi.org/10.2967/\njnumed.123.265687 (2023).\n34. Ouyang, L. et al. Training language models to follow instructions with human\nfeedback. arXiv [cs.CL] (2022).\n35. Ray, S. Samsung bans ChatGPT among employees after sensitive code leak.\nForbes Magazine (2023).\n36. Caliskan, A., Bryson, J. J. & Narayanan, A. Semantics derived automatically from\nlanguage corpora contain human-like biases.Science 356, 183–186 (2017).\n37. Center for Devices & Radiological Health. Arti ﬁcial Intelligence and Machine\nLearning in Software as a Medical Device. U.S. Food and Drug Administration\nhttps://www.fda.gov/medical-devices/software-medical-device-samd/artiﬁcial-\nintelligence-and-machine-learning-software-medical-device.\n38. Yang, X. et al. A study of deep learning methods for de-identiﬁcation of clinical\nnotes in cross-institute settings.BMC Med. Inform. Decis. Mak.19, 232 (2019).\n39. Levine, Y., Wies, N., Sharir, O., Bata, H. & Shashua, A. The depth-to-width interplay\nin self-attention. arXiv [cs.LG] (2020).\n40. Shoeybi, M. et al. Megatron-LM: training multi-billion parameter language models\nusing model parallelism.arXiv [cs.CL] (2019).\n41. Li, X. L. & Liang, P. Preﬁx-tuning: optimizing continuous prompts for generation.\nin Proceedings of the 59th Annual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Conference on Natural Language Pro-\ncessing (Volume 1: Long Papers) 4582–4597 (Association for Computational Lin-\nguistics, 2021). https://doi.org/10.18653/v1/2021.acl-long.353.\n42. Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H. & Neubig, G. Pre-train, prompt, and\npredict: A systematic survey of prompting methods in natural language pro-\ncessing. ACM Computing Surveys. 59,1 –35 (2023).\nC. Peng et al.\n9\nPublished in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2023)   210 \n43. Radford A., Wu J., Child R., Luan D. & Amodei D. Language models are unsu-\npervised multitask learners.OpenAI, 1, (2019)\n44. The ddi corpus: An annotated corpus with pharmacological sub-stances and drug-\ndrug interactions. J. Biomed. Inform. 46, 914–920 (2013).\n45. Li, J. et al. BioCreative V CDR task corpus: a resource for chemical disease relation\nextraction. Database (Oxf.) 2016, baw068 (2016).\n46. Hou, Y. et al. Discovering drug–target interaction knowledge from biomedical\nliterature. Bioinformatics 38, 5100–5107 (2022).\n47. Jin, Q., Dhingra, B., Liu, Z., Cohen, W. & Lu, X. PubMedQA: a dataset for biomedical\nresearch question answering. inProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP) (Association for Computational\nLinguistics, 2019). https://doi.org/10.18653/v1/d19-1259.\n48. Singhal, K. et al. Large language models encode clinical knowledge.arXiv [cs.CL]\n(2022).\n49. Jin, D. et al. What disease does this patient have? A large-scale open domain\nquestion answering dataset from medical exams.NATO Adv. Sci. Inst. E Appl. Sci.\n11, 6421 (2021).\n50. NeMo: NeMo: a toolkit for conversationalAI. (NVIDIA GitHub).\n51. Holtzman A., Buys J., Forbes M. & Choi Y. The curious case of neural text\ndegeneration. arXiv preprint arXiv:1904.09751 (2019).\n52. Clark, E., Ji, Y. & Smith, N. A. Neural text generation in stories using entity\nrepresentations as context. in Proceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Lan-\nguage Technologies, Volume 1 (Long Papers) 2250–2260 (Association for Com-\nputational Linguistics, 2018).https://doi.org/10.18653/v1/N18-1204.\n53. Celikyilmaz, A., Clark, E. & Gao, J. Evaluation of text generation: a survey.arXiv\npreprint arXiv:2006.14799 (2020).\n54. Holtzman, A., Buys, J., Du, L., Forbes, M. & Choi, Y. The curious case of neural text\ndegeneration. arXiv preprint arXiv:1904.09751 (2019).\n55. Huang, K., Altosaar, J. & Ranganath, R. ClinicalBERT: modeling clinical notes and\npredicting hospital readmission.arXiv preprint arXiv:1904.05342 (2019).\n56. Wongpakaran, N., Wongpakaran, T., Wedding, D. & Gwet, K. L. A comparison of\nCohen’s Kappa and Gwet’s AC1 when calculating inter-rater reliability coefﬁ-\ncients: a study conducted with personality disorder samples. BMC Med. Res.\nMethodol. 13, 61 (2013).\nACKNOWLEDGEMENTS\nThis study was partially supported by a Patient-Centered Outcomes Research Institute®\n(PCORI®) Award (ME-2018C3-14754), a grant from the National Cancer Institute,\n1R01CA246418, grants from the National Institute on Aging, NIA R56AG069880 and\n1R01AG080624, and the Cancer Informatics and eHealth core jointly supported by the UF\nHealth Cancer Center and the UF Clinical and Translational Science Institute. The content is\nsolely the responsibility of the authorsand does not necessarily represent the ofﬁcial views\nof the funding institutions. We would like to thank the UF Research Computing team, led\nby Dr. Erik Deumens, for providing computingpower through UF HiperGator-AI cluster.\nAUTHOR CONTRIBUTIONS\nY.W., J.B., X.Y., N.P., A.B.C., and M.G.F. were responsible for the overall design,\ndevelopment, and evaluation of this study. X.Y., C.P., A.C., and K.E.S. had full access to\nall the data in the study and takes responsibility for the integrity of the data and the\naccuracy of the data analysis. Y.G. and Y.W. designed the Turing evaluation of\nsynthetic clinical text generated by GatorTronGPT. N.S.O. and M.M.A. are the two\nhuman physicians who performed Turing test. Y.W., X.Y., K.E.S., C.P., Y.G., and J.B. did\nthe bulk of the writing, W.H., E.A.S., D.A.M., T.M., C.A.H., A.B.C., and G.L. also\ncontributed to writing and editing of this manuscript. All authors reviewed the\nmanuscript critically for scientiﬁc content, and all authors gaveﬁnal approval of the\nmanuscript for publication.\nCOMPETING INTERESTS\nK.E.S., N.P.N., A.B.C., C.M., and M.G.F. are employed by NVIDIA. There are no other\ncompeting ﬁnancial or non-ﬁnancial interests. The work presented in this study was\nconducted exclusively within the University of Florida Health.\nADDITIONAL INFORMATION\nSupplementary information The online version contains supplementary material\navailable at https://doi.org/10.1038/s41746-023-00958-w.\nCorrespondence and requests for materials should be addressed to Yonghui Wu.\nReprints and permission information is available at http://www.nature.com/\nreprints\nPublisher’s noteSpringer Nature remains neutral with regard to jurisdictional claims\nin published maps and institutional afﬁliations.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give\nappropriate credit to the original author(s) and the source, provide a link to the Creative\nCommons license, and indicate if changes were made. The images or other third party\nmaterial in this article are included in the article’s Creative Commons license, unless\nindicated otherwise in a credit line to the material. If material is not included in the\narticle’s Creative Commons license and your intended use is not permitted by statutory\nregulation or exceeds the permitted use, you will need to obtain permission directly\nfrom the copyright holder. To view a copy of this license, visit http://\ncreativecommons.org/licenses/by/4.0/.\n© The Author(s) 2023\nC. Peng et al.\n10\nnpj Digital Medicine (2023)   210 Published in partnership with Seoul National University Bundang Hospital",
  "topic": "Readability",
  "concepts": [
    {
      "name": "Readability",
      "score": 0.7475369572639465
    },
    {
      "name": "Enthusiasm",
      "score": 0.7134647369384766
    },
    {
      "name": "Health care",
      "score": 0.5721784234046936
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5159240961074829
    },
    {
      "name": "Test (biology)",
      "score": 0.5158711671829224
    },
    {
      "name": "Relevance (law)",
      "score": 0.502286434173584
    },
    {
      "name": "Computer science",
      "score": 0.42564627528190613
    },
    {
      "name": "Natural language processing",
      "score": 0.42298266291618347
    },
    {
      "name": "Scale (ratio)",
      "score": 0.416521281003952
    },
    {
      "name": "Psychology",
      "score": 0.32250702381134033
    },
    {
      "name": "Political science",
      "score": 0.14843550324440002
    },
    {
      "name": "Geography",
      "score": 0.1388990879058838
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Social psychology",
      "score": 0.0
    },
    {
      "name": "Cartography",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I33213144",
      "name": "University of Florida",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210127875",
      "name": "Nvidia (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4390039331",
      "name": "UF Health Cancer Center",
      "country": null
    },
    {
      "id": "https://openalex.org/I2800717037",
      "name": "University of Florida Health",
      "country": "US"
    }
  ]
}