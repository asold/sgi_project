{
    "title": "Self-Supervised Transformer for Sparse and Irregularly Sampled Multivariate Clinical Time-Series",
    "url": "https://openalex.org/W4283370926",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A3192518390",
            "name": "Sindhu Tipirneni",
            "affiliations": [
                "Virginia Tech"
            ]
        },
        {
            "id": "https://openalex.org/A2100435683",
            "name": "Chandan K. Reddy",
            "affiliations": [
                "Virginia Tech"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2742491462",
        "https://openalex.org/W2964010366",
        "https://openalex.org/W2907097276",
        "https://openalex.org/W2764030410",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W2162800060",
        "https://openalex.org/W3023534255",
        "https://openalex.org/W3023371261",
        "https://openalex.org/W2396881363",
        "https://openalex.org/W3035725276",
        "https://openalex.org/W2158677029",
        "https://openalex.org/W1502922572",
        "https://openalex.org/W2963532813",
        "https://openalex.org/W2997353686",
        "https://openalex.org/W3080826732",
        "https://openalex.org/W3188872815",
        "https://openalex.org/W3080987150",
        "https://openalex.org/W2560674852"
    ],
    "abstract": "Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals. Existing approaches for learning representations in this domain handle these challenges by either aggregation or imputation of values, which in-turn suppresses the fine-grained information and adds undesirable noise/overhead into the machine learning model. To tackle this problem, we propose a S elf-supervised Tra nsformer for T ime- S eries (STraTS) model, which overcomes these pitfalls by treating time-series as a set of observation triplets instead of using the standard dense matrix representation. It employs a novel Continuous Value Embedding technique to encode continuous time and variable values without the need for discretization. It is composed of a Transformer component with multi-head attention layers, which enable it to learn contextual triplet embeddings while avoiding the problems of recurrence and vanishing gradients that occur in recurrent architectures. In addition, to tackle the problem of limited availability of labeled data (which is typically observed in many healthcare applications), STraTS utilizes self-supervision by leveraging unlabeled data to learn better representations by using time-series forecasting as an auxiliary proxy task. Experiments on real-world multivariate clinical time-series benchmark datasets demonstrate that STraTS has better prediction performance than state-of-the-art methods for mortality prediction, especially when labeled data is limited. Finally, we also present an interpretable version of STraTS, which can identify important measurements in the time-series data. Our data preprocessing and model implementation codes are available at https://github.com/sindhura97/STraTS .",
    "full_text": null
}