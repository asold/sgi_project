{
  "title": "Memory Matters: The Need to Improve Long-Term Memory in LLM-Agents",
  "url": "https://openalex.org/W4391116828",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A1874129615",
      "name": "Kostas Hatalis",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3127166906",
      "name": "Despina Christou",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2140593798",
      "name": "Joshua Myers",
      "affiliations": [
        "Applied Research Associates"
      ]
    },
    {
      "id": "https://openalex.org/A1977601872",
      "name": "Steven Jones",
      "affiliations": [
        "Cambridge Cognition (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A2141656734",
      "name": "Keith Lambert",
      "affiliations": [
        "Family Life Association of Swaziland"
      ]
    },
    {
      "id": "https://openalex.org/A4272714247",
      "name": "Adam Amos‐Binks",
      "affiliations": [
        "Applied Research Associates"
      ]
    },
    {
      "id": null,
      "name": "Zohreh Dannenhauer",
      "affiliations": [
        "Metron (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A249572408",
      "name": "Dustin Dannenhauer",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1874129615",
      "name": "Kostas Hatalis",
      "affiliations": [
        "Lehigh Valley Health Network"
      ]
    },
    {
      "id": "https://openalex.org/A3127166906",
      "name": "Despina Christou",
      "affiliations": [
        "Lehigh Valley Health Network"
      ]
    },
    {
      "id": "https://openalex.org/A2140593798",
      "name": "Joshua Myers",
      "affiliations": [
        "Applied Research Associates (United States)",
        "Applied Research Associates"
      ]
    },
    {
      "id": "https://openalex.org/A1977601872",
      "name": "Steven Jones",
      "affiliations": [
        "Ann Arbor Center for Independent Living"
      ]
    },
    {
      "id": "https://openalex.org/A2141656734",
      "name": "Keith Lambert",
      "affiliations": [
        "Malaysian Cocoa Board"
      ]
    },
    {
      "id": "https://openalex.org/A4272714247",
      "name": "Adam Amos‐Binks",
      "affiliations": [
        "Applied Research Associates",
        "Applied Research Associates (United States)"
      ]
    },
    {
      "id": null,
      "name": "Zohreh Dannenhauer",
      "affiliations": [
        "Metron (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A249572408",
      "name": "Dustin Dannenhauer",
      "affiliations": [
        "Lehigh Valley Health Network"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4296706399",
    "https://openalex.org/W4381988561",
    "https://openalex.org/W6743716967",
    "https://openalex.org/W2779578326",
    "https://openalex.org/W2224049000",
    "https://openalex.org/W4304194220",
    "https://openalex.org/W4225405251",
    "https://openalex.org/W4387835442",
    "https://openalex.org/W4292958252",
    "https://openalex.org/W4378505261",
    "https://openalex.org/W4365597205"
  ],
  "abstract": "In this paper, we provide a review of the current efforts to develop LLM agents, which are autonomous agents that leverage large language models. We examine the memory management approaches used in these agents. One crucial aspect of these agents is their long-term memory, which is often implemented using vector databases. We describe how vector databases are utilized to store and retrieve information in LLM agents. Moreover we highlight open problems, such as the separation of different types of memories and the management of memory over the agent's lifetime. Lastly, we propose several topics for future research to address these challenges and further enhance the capabilities of LLM agents, including the use of metadata in procedural and semantic memory and the integration of external knowledge sources with vector databases.",
  "full_text": "Memory Matters: The Need to Improve Long-Term Memory in LLM Agents\nKostas Hatalis1, Despina Christou1, Joshua Myers2, Steven Jones3, Keith Lambert4, Adam\nAmos-Binks2, Zohreh Dannenhauer5, Dustin Dannenhauer1\n1 GoCharlie.ai, Allentown PA 18106\n2 Applied Research Associates, Inc., Raleigh, NC 27616\n3 Center for Integrated Cognition, Ann Arbor, MI 48105\n4 Cocoa AI, Chicago, IL 60642\n5 Metron, Inc., Reston, V A 20190\nkostas@gocharlie.ai, despina@gocharlie.ai, jamyers@ara.com, steven.jones@cic.iqmri.org, keith@gococoa.ai,\naamosbinks@ara.com, dannenhauerz@metsci.com\nAbstract\nIn this paper, we provide a review of the current efforts to de-\nvelop LLM agents, which are autonomous agents that lever-\nage large language models. We examine the memory man-\nagement approaches used in these agents. One crucial aspect\nof these agents is their long-term memory, which is often\nimplemented using vector databases. We describe how vec-\ntor databases are utilized to store and retrieve information in\nLLM agents. Moreover we highlight open problems, such as\nthe separation of different types of memories and the manage-\nment of memory over the agent’s lifetime. Lastly, we propose\nseveral topics for future research to address these challenges\nand further enhance the capabilities of LLM agents, includ-\ning the use of metadata in procedural and semantic memory\nand the integration of external knowledge sources with vector\ndatabases.\nIntroduction\nOver the last year, there has been considerable interest in au-\ntonomous agents capable of leveraging large language mod-\nels (LLMs). LLMs are evolving at a rapid pace, each with\ntheir own trade-off between size, training cost, and latent\nrepresentation thanks to the availability of large corpuses of\ntext and the development of the attention mechanism. Their\nlarge knowledge bases and general reasoning are bootstrap-\nping the deployment of specialized chat agents, coding assis-\ntants (e.g., copilot (GitHub 2023)), and technical question-\nanswering (e.g., AskYourPDF (AskYourPDF 2023)). We re-\nfer to any agent system that relies on an LLM, in capacities\nbeyond human-machine interfaces (such as task decomposi-\ntion, planning, or task execution), as an LLM agent.\nPairing LLMs with autonomy requires memory systems.\nThese memory systems ensure that interactions are coher-\nent, contextual, and efficient and that the system can learn\nand adapt over time. Efforts like Auto-GPT (Significant-\nGravitas 2023) ask a human user to describe a goal in\nnatural language and proceed to decompose the task into\nsubtasks that are then executed via terminal commands\nand API calls. Information from earlier executions of sub-\ntasks is stored as memories to accomplish future subtasks.\nCopyright © 2023, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nShort-term memory was implemented by prepending pre-\nvious subtask prompts and results to subsequent subtask\ncalls. Since LLMs have fixed-size context windows, com-\nplex tasks quickly generate more information than can fit\nwithin these limits. Long-term memory solutions currently\nimplemented via vector databases have significant limita-\ntions. We review the current efforts to develop LLM agents,\ndescribe their use of vector databases for long-term memory,\nidentify open problems in using vector databases as long-\nterm memory, and propose topics for future work.\nRecent LLM Agents\nLLM agents are a recent but rapidly evolving trend. These\nagents independently perform tasks, create new ones, prior-\nitize them, and adapt to changing requirements to achieve\na specific objective. LLMs, such as GPT-4, serve as the\ncore controller for these agents. Most LLM agents utilize a\nframework containing at least the following components, all\nimplemented as LLM API calls with different prompts: plan-\nning, task execution, memory management, and tool use.\nPlanning decomposes complex high-level tasks into\nsmaller, simpler sub-tasks recursively until sub-tasks are ex-\necutable. Once the original high-level task is fully decom-\nposed into executable sub-tasks, task execution proceeds se-\nquentially. Each task attempt is checked for success and is\nre-tried until it succeeds, enabling limited adaptation ca-\npabilities. Memory management addresses short-term and\nlong-term information storage outside of LLM’s context\nwindow, allowing agents to retain context-specific knowl-\nedge and recall past experiences. API calls to external tools\nenable LLM agents to access real-time information, execute\ncode, and leverage proprietary databases.\nA formal example of such a framework is MRKL (Mod-\nular Reasoning, Knowledge, and Language) (Karpas et al.\n2022), a neuro-symbolic architecture for autonomous agents\nthat combines the power of LLMs with expert modules. The\nLLM acts as a central controller, routing inquiries to the\nmost suitable expert module based on its understanding of\nthe task and the capabilities of the modules. These modules\ncan be neural or symbolic, providing the agent with diverse\ntools for handling different tasks. MRKL enables agents to\nleverage both neural and symbolic reasoning, allowing them\nto tackle complex problems effectively.\nAAAI Fall Symposium Series (FSS-23)\n277\nSeveral examples of autonomous agents with LLMs have\ngarnered noteworthy attention. One of the most well-known\nexamples is Auto-GPT (Significant-Gravitas 2023). Auto-\nGPT leverages GPT-4 as its controller and operates with\nminimal user input. It employs a self-assigned goal-oriented\napproach to break down objectives into sub-tasks and uses\nvarious tools to achieve them. Noteworthy capabilities in-\nclude writing, debugging, testing, and editing code. How-\never, challenges persist, such as confabulatory tendencies\nand difficulty in task focus and contextual understanding.\nOther examples are BabyAGI (Nakajima 2023) and\nSmartGPT (Corman 2023), which demonstrate AI-powered\ntask management systems. BabyAGI utilizes LLMs like\nOpenAI and vector databases like Chroma or Weaviate to\ngenerate, prioritize, and execute tasks. By leveraging LLMs’\nnatural language processing capabilities, BabyAGI creates\nnew tasks based on an objective and the results of previ-\nous tasks, enabling it to adapt and evolve based on chang-\ning requirements. SmartGPT, on the other hand, focuses on\nenabling LLMs to complete complex tasks without user in-\nput. It achieves this by breaking tasks into minor problems,\ncollecting information from external sources, and leveraging\nthe internet.\nGPT-Engineer (Osika 2023) is an open-platform project\nthat aims to make it easy for developers to build and ex-\ntend their own autonomous agents. By generating an entire\ncodebase based on a user-defined prompt, GPT-Engineer en-\nables developers to customize the behavior of their agents\naccording to their specific needs. This project highlights the\npotential of LLMs in code generation and the creation of\npersonalized code-generation toolboxes.\nThe agents mentioned above are considered generalist\nagents to be used to solve open ended problems. ChemCrow\n(Bran et al. 2023) is an example of a domain-specific LLM\nagent. It utilizes LLMs augmented with expert-designed\ntools to accomplish organic synthesis, drug discovery, and\nmaterials design tasks. By combining LLMs with special-\nized tools, ChemCrow demonstrates the potential of au-\ntonomous agents in specific domains and showcases how\nLLMs can be integrated with existing expert knowledge.\nGenerative Agents (Park et al. 2023) takes a unique ap-\nproach by creating a sandbox environment where multiple\nvirtual characters, controlled by LLM-powered agents, in-\nteract with each other. Inspired by The Sims, this experi-\nment combines LLMs with memory, planning, and reflection\nmechanisms to simulate believable human behavior. Gener-\native Agents highlights the potential of autonomous agents\nin interactive applications and the integration of LLMs in\ncreating realistic virtual environments.\nLong-Term Memory via Vector Databases\nThe common model of cognition (Laird, Lebiere, and\nRosenbloom 2017) is both a theoretical description of the\nmemory systems that underlie human cognition (Hake, Sib-\nert, and Stocco 2022) and a description of real computational\nsystems (cognitive architectures) used to implement intel-\nligent agents. The common model distinguishes between\nlong-term memory and working memory and is depicted in\nFigure 1. Working memory represents the current situation,\nEpisodic MemorySemantic Memory\nLong-term Declarative Memories\nProcedural\nLong-term Memory\nFigure 1: The common model of cognition, altered to distin-\nguish between episodic and semantic memory. (Jones and\nLaird 2023)\nincluding the state of current reasoning and abstractions of\nthe ongoing physical situation of the agent’s embodiment.\nLong-term memory (LTM) systems alter an agent’s behav-\nior by changing the contents of working memory, which can\nlead to changes to the abstract representations that control\nembodiment. Long-term memory is subdivided into proce-\ndural, semantic, and episodic memory. These memory sys-\ntems must operate incrementally and in real time, maintain-\ning reactivity to environmental changes.\nOne approach to leveraging LLMs is to attach a queryable\nLLM module to a cognitive architecture. In this approach,\nthe cognitive architecture’s long-term memory systems can\nstore knowledge learned from interpreting LLM responses\n(Kirk et al. 2022). However, this differs from LLM agents\ndescribed above that put the LLM more in control. Another\npotential approach is to more directly attach LLMs to spe-\ncific cognitive architecture long-term memory modules, but\nit is unclear how, given cognitive architecture assumptions\non the forms of mental representations and grounding to an\nembodiment where LLMs alone do not provide a theory of\nmental representations or grounding.\nWe propose that LLM agents can potentially align with\nthe functionality described in the common model of cog-\nnition, then review implementations of long-term memory\nfor these agents. An LLM context window can abstractly\nfunction similarly to working memory. LLM agents can use\na description of the current situation and retrieve contents\nof a long-term memory store to populate a prompt tem-\nplate. Then, a prompt template program and LLM collec-\ntively function similarly to procedural memory by creating\nprompts and responses to alter the contents of a context\nwindow over time. Storage of these contents over time (es-\npecially to timescales beyond what a context window can\nsupport) to an external database can provide episodic mem-\nory storage. Additionally, derived facts (either mined from\nepisodic memory or reasoned) can be stored separately as\nsemantic memory. We now describe how vector databases\nin implemented LLM agents support long-term memory ca-\npabilities, followed by risks and limitations.\n278\nVector Databases\nVector embeddings have become a popular representation\nfor memories because transformer neural network LLMs use\nvector embeddings natively. Input data as raw text is run\nthrough an encoder network that embeds the data in a fixed-\ndimensional space. These embeddings represent data such\nthat distance-based measures can be used to retrieve similar\ndata.\nA vector database is designed to support data storage and\nretrieval in an embedding representation rather than more\nstructured, scalar data in traditional relational databases.\nQueries for vector databases rely on similarity matching to\nreturn the top-k matches, using algorithms such as cosine\nsimilarity, euclidean distance, or dot product. Metadata can\nbe added as an additional filtering step 1 that offers condi-\ntional logic filters on top of similarity measure-based re-\ntrieval (e.g., the year metadata field must be greater than\nor equal to’2020’).\nOne instance of a vector database being used to augment\nan LLM is Teenage-AGI (Pixel 2023). In this implemen-\ntation, each ”thought” and memory that the LLM outputs\nor perceives is stored in a respective Pinecone vector DB.\nWhenever a new thought or perception is processed, both\ndatabases are queried for the top-k matches, and these are\nadded to the context for the LLM prompt (aka the LLM\nagent’s working memory). This allows the LLM to attend to\nprevious experiences related to the current thought or mem-\nory, which often improves the accuracy and meaningfulness\nof the output as seen in research on few-shot prompting.\nAnother instance of an LLM agent utilizing a vector\ndatabase is V oyager, an “LLM-powered embodied lifelong\nlearning agent” (Wang et al. 2023), which acts in Minecraft.\nDescriptions of skills (computer programs that interact with\nthe Minecraft engine) that an agent has learned are retained\nin a vector database and a GPT model is used to generate\nplans. Plans and a description of the environment are embed-\nded and the closest skills in the db are retrieved. The skills\nare refined through iterative prompting until they are cor-\nrect, and plans are generated by chain-of-thought prompting\n(Zhang et al. 2022) with the agent’s current state as context.\nThe two previous approaches to enhancing LLM agent\nperformance with vectors databases add different types of\nmemory to the agent. In the case of Teenage-AGI, the\ndatabase contains declarative and episodic memories (em-\nbeddings of previous experiences and thoughts) while in the\ncase of V oyager, the database contains procedural memories\n(embeddings of descriptions of skills).\nIn both cases, the database quickly retrieves relevant ma-\nterial to the current state and task even though what the in-\nformation is used for is different (informing context vs de-\nciding what skills to use). These approaches are similar to\nKahneman’s System 1 (Kahneman 2011) – the fast, associa-\ntive, and intuitive part of human consciousness. However,\nwithout a proper analog to the logical and slower System 2,\nunderlying issues with LLM agents such as hallucinations\nand irrational planning will continue to plague both the data\n1https://docs.pinecone.io/docs/metadata-filtering\nstored in long-term memory and the executive functioning\nand planning of the agent.\nFundamental Problems\nSeparation between types of memories: Poor retrieval\nmay occur if all types of long-term memory (procedural,\nepisodic, and semantic) are stored in the same vector\ndatabase. For example, an agent could have the knowledge\nthat the Earth is a globe stored in its semantic memory\nbut have recently concluded a debate on the flatness of the\nEarth. The episodic memories of an argument that the Earth\nis flat are directly inconsistent with the agent’s semantic\nmemory. Therefore memories must be segregated based on\ntype.\nInfinite subtask loop: Current LLM agents can become\nstuck trying to revisit the same sub-task over and over. This\nusually happens when a subtask fails and the LLM suggests\none or more alternative solutions that also fail. With each\nfailure, the LLM keeps suggesting from a fixed set of\nsolutions without trying something new. Episodic memory\noffers a way to detect if failures are reoccuring, since each\nfailure is stored in the long-term memory. Simpler solutions,\nsuch as dev-GPT 2 count the number of failures per subtask\nstrategy and try a new strategy after 10 failures.\nLifelong Memory Management: LLM agents will accu-\nmulate many memories as they solve tasks over their life-\ntime. Vector databases offer performance features such as\nindexing, scaling, and metadata-filtered queries, but don’t\naddress issues such as how the agent’s information flow is\nsegmented or how memories are organized under metadata\ncategories. Continuously stored memories will result in a\nmore complete agent history at the cost of space and time for\nretrieval. Solutions to forgetting such as (Mart ´ınez-Plumed\net al. 2015) may be required to maintain performance over\nmany tasks.\nConclusions and Future Work\nWe review recent efforts to develop LLM agents: agents that\nuse LLMs in capacities beyond human-machine interfaces\nsuch as problem solving. Agents rely on information over\nvarious time horizons to accomplish complex, multi-step\ntasks. We discuss how short-term memory and long-term\nmemory are currently being used in LLM agents by refer-\nencing the common model of cognition (Laird, Lebiere, and\nRosenbloom 2017), and elaborate on the risks with using\nvector-databases for long-term memory.\nIn future work, exploring the development of learning\nmechanisms for metadata in both procedural and semantic\nmemory would be valuable. This would involve investigat-\ning how the agent can autonomously learn and update meta-\ndata attributes based on experiences and interactions with\nthe environment. For procedural memory, the agent could\nlearn metadata attributes such as the success rates, reliability\nscores, or preferences of different actions, allowing it to pri-\noritize and adapt its decision-making process. Similarly, for\n2https://github.com/jina-ai/dev-gpt\n279\nsemantic memory, the agent could learn metadata attributes\nthat capture the occurrence frequencies, probabilistic infor-\nmation, or temporal context of concepts and relationships,\nenabling more efficient retrieval and utilization of memories.\nGeneralizing these, future work could explore the capacity\nof LLM agents to use metamemory judgments to deliber-\nately alter memory indexing.\nIt would also be beneficial to investigate the integration of\nmetadata attributes with external knowledge sources, such\nas ontologies or knowledge graphs. An agent could lever-\nage these sources’ rich semantic relationships and structured\ninformation by linking the LTM with external knowledge\nbases. This integration could enable more comprehensive\nand accurate metadata attributes, as well as facilitate the rea-\nsoning and inference capabilities of the LLM. For instance,\nan agent could use the metadata attributes to perform se-\nmantic searches or traverse the knowledge graph to retrieve\nrelated concepts and relationships. This would enhance\nan agent’s ability to contextualize and interpret memories\nwithin a broader knowledge framework, leading to more ro-\nbust decision-making and problem-solving capabilities. Re-\ncent approaches such as OntoGPT and graphGPT look to\nachieve semantic parsing and node generation through the\nuse of LLMs to create the Knowledge base/ontology from\nwhich an episodic or declarative LTM grounding can take\nplace.\nReferences\nAskYourPDF. 2023. AskYourPDF. https://askyourpdf.com/.\nAccessed: 2023-09-21.\nBran, A. M.; Cox, S.; White, A. D.; and Schwaller, P. 2023.\nChemCrow: Augmenting large-language models with chem-\nistry tools. arXiv preprint arXiv:2304.05376.\nCorman. 2023. SmartGPT. https://github.com/Cormanz/\nsmartgpt. Accessed: 2023-09-12.\nGitHub. 2023. GitHub Copilot. https://github.com/features/\ncopilot. Accessed: 2023-09-19.\nHake, H. S.; Sibert, C.; and Stocco, A. 2022. Inferring a\nCognitive Architecture from Multitask Neuroimaging Data:\nA Data-Driven Test of the Common Model of Cognition Us-\ning Granger Causality. Topics in Cognitive Science, 14(4):\n845–859.\nJones, S. J.; and Laird, J. E. 2023. A cognitive architecture\ntheory of anticipatory thinking. AI Magazine.\nKahneman, D. 2011. Thinking, Fast and Slow.Macmillan.\nISBN 978-1-4299-6935-2.\nKarpas, E.; Abend, O.; Belinkov, Y .; Lenz, B.; Lieber, O.;\nRatner, N.; Shoham, Y .; Bata, H.; Levine, Y .; Leyton-Brown,\nK.; et al. 2022. MRKL Systems: A modular, neuro-symbolic\narchitecture that combines large language models, external\nknowledge sources and discrete reasoning. arXiv preprint\narXiv:2205.00445.\nKirk, J. R.; Wray, R. E.; Lindes, P.; and Laird, J. E. 2022.\nEvaluating diverse knowledge sources for online one-shot\nlearning of novel tasks. arXiv preprint arXiv:2208.09554.\nLaird, J. E.; Lebiere, C.; and Rosenbloom, P. S. 2017. A\nstandard model of the mind: Toward a common computa-\ntional framework across artificial intelligence, cognitive sci-\nence, neuroscience, and robotics. Ai Magazine, 38(4): 13–\n26.\nMart´ınez-Plumed, F.; Ferri, C.; Hern ´andez-Orallo, J.; and\nRamirez-Quintana, M. J. 2015. Knowledge acquisition with\nforgetting: an incremental and developmental setting.Adap-\ntive Behavior, 23(5): 283–299.\nNakajima, Y . 2023. BabyAGI. https://github.com/\nyoheinakajima/babyagi. Accessed: 2023-09-13.\nOsika, A. 2023. GPT Engineer. https://github.com/\nAntonOsika/gpt-engineer. Accessed: 2023-09-22.\nPark, J. S.; O’Brien, J. C.; Cai, C. J.; Morris, M. R.;\nLiang, P.; and Bernstein, M. S. 2023. Generative agents:\nInteractive simulacra of human behavior. arXiv preprint\narXiv:2304.03442.\nPixel, S. 2023. Teenage-AGI. https://github.com/seanpixel/\nTeenage-AGI. Accessed: 2023-09-19.\nSignificant-Gravitas. 2023. Auto-GPT: An Autonomous\nGPT-4 Experiment. https://github.com/Significant-Gravitas/\nAuto-GPT. Accessed: 2023-09-18.\nWang, G.; Xie, Y .; Jiang, Y .; Mandlekar, A.; Xiao, C.; Zhu,\nY .; Fan, L.; and Anandkumar, A. 2023. V oyager: An open-\nended embodied agent with large language models. arXiv\npreprint arXiv:2305.16291.\nZhang, Z.; Zhang, A.; Li, M.; and Smola, A. 2022. Auto-\nmatic Chain of Thought Prompting in Large Language Mod-\nels. In The Eleventh International Conference on Learning\nRepresentations.\n280",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7972039580345154
    },
    {
      "name": "Metadata",
      "score": 0.6891946792602539
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.6771976351737976
    },
    {
      "name": "Semantic memory",
      "score": 0.4798262119293213
    },
    {
      "name": "Term (time)",
      "score": 0.4598120152950287
    },
    {
      "name": "Data science",
      "score": 0.3889702260494232
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3293030261993408
    },
    {
      "name": "World Wide Web",
      "score": 0.2814252972602844
    },
    {
      "name": "Cognition",
      "score": 0.11785638332366943
    },
    {
      "name": "Psychology",
      "score": 0.08551910519599915
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ]
}