{
  "title": "Comparative Analysis of Deep Natural Networks and Large Language Models for Aspect-Based Sentiment Analysis",
  "url": "https://openalex.org/W4394897028",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3136804330",
      "name": "Nimra Mughal",
      "affiliations": [
        "Sukkur IBA University"
      ]
    },
    {
      "id": "https://openalex.org/A1599351031",
      "name": "Ghulam Mujtaba",
      "affiliations": [
        "Sukkur IBA University"
      ]
    },
    {
      "id": "https://openalex.org/A2728169235",
      "name": "Sarang Shaikh",
      "affiliations": [
        "Norwegian University of Science and Technology"
      ]
    },
    {
      "id": null,
      "name": "Aveenash Kumar",
      "affiliations": [
        "Lear (Spain)",
        "Lear (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2945788795",
      "name": "Sher Muhammad Daudpota",
      "affiliations": [
        "Sukkur IBA University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2496936287",
    "https://openalex.org/W3097904859",
    "https://openalex.org/W3140854437",
    "https://openalex.org/W3027304069",
    "https://openalex.org/W4242850272",
    "https://openalex.org/W4200182268",
    "https://openalex.org/W4205256657",
    "https://openalex.org/W2944851425",
    "https://openalex.org/W3095319910",
    "https://openalex.org/W6792439368",
    "https://openalex.org/W4362670371",
    "https://openalex.org/W2971014768",
    "https://openalex.org/W2754300949",
    "https://openalex.org/W2251124635",
    "https://openalex.org/W2251294039",
    "https://openalex.org/W2465978385",
    "https://openalex.org/W6728469146",
    "https://openalex.org/W3168997536",
    "https://openalex.org/W4306955484",
    "https://openalex.org/W6792212342",
    "https://openalex.org/W3140931699",
    "https://openalex.org/W2807614059",
    "https://openalex.org/W3080910531",
    "https://openalex.org/W2911752708",
    "https://openalex.org/W2903712410",
    "https://openalex.org/W2914820290",
    "https://openalex.org/W3183968703",
    "https://openalex.org/W6769318315",
    "https://openalex.org/W3194284871",
    "https://openalex.org/W4312552362",
    "https://openalex.org/W4307297747",
    "https://openalex.org/W4391136507",
    "https://openalex.org/W3095113840",
    "https://openalex.org/W3217017905",
    "https://openalex.org/W6784917616",
    "https://openalex.org/W4214566303",
    "https://openalex.org/W6677635683",
    "https://openalex.org/W2947851192",
    "https://openalex.org/W4400134761",
    "https://openalex.org/W6811515478",
    "https://openalex.org/W1964940342",
    "https://openalex.org/W2072462334",
    "https://openalex.org/W2072379976",
    "https://openalex.org/W2126975755",
    "https://openalex.org/W3187669469",
    "https://openalex.org/W4324370640",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2946417913",
    "https://openalex.org/W3112103703",
    "https://openalex.org/W3083485178",
    "https://openalex.org/W4320495408",
    "https://openalex.org/W4390283300",
    "https://openalex.org/W4391023809",
    "https://openalex.org/W4287888651",
    "https://openalex.org/W6810166228",
    "https://openalex.org/W2963274454",
    "https://openalex.org/W2473567461",
    "https://openalex.org/W4283316206",
    "https://openalex.org/W6760568010",
    "https://openalex.org/W3008193129",
    "https://openalex.org/W3201132216",
    "https://openalex.org/W3100880133",
    "https://openalex.org/W6691459498",
    "https://openalex.org/W6640511754",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2562607067",
    "https://openalex.org/W2953297087",
    "https://openalex.org/W4387849048",
    "https://openalex.org/W6802296084",
    "https://openalex.org/W4236209210",
    "https://openalex.org/W3138918333",
    "https://openalex.org/W4312497925",
    "https://openalex.org/W3122420389",
    "https://openalex.org/W2969743835",
    "https://openalex.org/W6847076894",
    "https://openalex.org/W2170505850",
    "https://openalex.org/W3013708524",
    "https://openalex.org/W6844088532",
    "https://openalex.org/W6850299220",
    "https://openalex.org/W132374903",
    "https://openalex.org/W3205736875",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W3106996681",
    "https://openalex.org/W3137483769",
    "https://openalex.org/W4223927974",
    "https://openalex.org/W4298178373",
    "https://openalex.org/W4401042146",
    "https://openalex.org/W2116034247",
    "https://openalex.org/W3139580003"
  ],
  "abstract": "Sentiment analysis is essential for comprehending public opinion, particularly when considering e-commerce and the expansion of online businesses. Early approaches treated sentiment analysis as a document or sentence-level classification problem, lacking the ability to capture nuanced opinions about specific aspects. This limitation was addressed by the development of aspect-based sentiment analysis (ABSA), which links sentiment to specific aspects that are mentioned explicitly or implicitly in the review. ABSA is relatively a recent field of sentiment analysis and the existing models for ABSA face three main challenges, including domain-specificity, reliance on labeled data, and a lack of exploration into the potential of newer large language models (LLMs) such as GPT, PaLM, and T5. Leveraging a diverse set of datasets, including DOTSA, MAMS, and SemEval16, we evaluate the performance of prominent models such as ATAE-LSTM, flan-t5-large-absa, DeBERTa, PaLM, and GPT-3.5-Turbo. Our findings reveal nuanced strengths and weaknesses of these models across different domains, with DeBERTa emerging as consistently high-performing and PaLM demonstrating remarkable competitiveness for aspect term sentiment analysis (ATSA) tasks. In addition, the PaLM demonstrates competitive performance for all the domains that were used in the experiments including the restaurant, hotel, books, clothing, and laptop reviews. Notably, the analysis underscores the models&#x2019; domain sensitivity, shedding light on their varying efficacy for both ATSA and ACSA tasks. These insights contribute to a deeper understanding of model applicability and highlight potential areas for improvement in ABSA research and development.",
  "full_text": "Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.\nDigital Object Identifier 10.1109/ACCESS.2023.DOI\nComparative Analysis of Deep Natural\nNetworks and Large Language Models\nfor Aspect-Based Sentiment Analysis\nNIMRA MUGHAL1, GHULAM MUJTABA1, AVEENASH KUMAR3, and SHER MUHAMMAD\nDAUDPOTA2,\n1Center of Excellence for Robotics, Artificial Intelligence, and Block Chain, Department of Computer Science, Sukkur IBA University, Sukkur,65200, Sindh,\nPakistan\n2Department of Computer Science, Sukkur IBA University, Sukkur,65200, Sindh, Pakistan\n3Data Scientist at Learners.ai, 100, 2 Toronto St Suite#284, Toronto, Ontario, M5C 2B5, Canada\nCorresponding author: Nimra Mughal (e-mail: nimra.mscsf19@iba-suk.edu.pk)\nThis work was supported by the National Research Program for Universities (NRPU), Higher Education Commission, Pakistan under\nProject Ref No. 20-14457/NRPU/R&D/HEC/2021-2020.\nABSTRACT Sentiment analysis is essential for comprehending public opinion, particularly when con-\nsidering e-commerce and the expansion of online businesses. Early approaches treated sentiment analysis\nas a document or sentence-level classification problem, lacking the ability to capture nuanced opinions\nabout specific aspects. This limitation was addressed by the development of aspect-based sentiment analysis\n(ABSA), which links sentiment to specific aspects that are mentioned explicitly or implicitly in the review.\nABSA is relatively a new field of sentiment analysis and the existing models for ABSA face three main\nchallenges, including domain-specificity, reliance on labeled data, and a lack of exploration into the\npotential of newer large language models (LLMs) such as GPT, PaLM, and T5. Leveraging a diverse set\nof datasets, including DOTSA, MAMS, and SemEval16, we evaluate the performance of prominent models\nsuch as ATAE-LSTM, flan-t5-large-absa, Deberta, PaLM, and GPT-3.5-Turbo. Our findings reveal nuanced\nstrengths and weaknesses of these models across different domains, with Deberta emerging as consistently\nhigh-performing and PaLM demonstrating remarkable competitiveness for aspect term sentiment analysis\n(ATSA) tasks. In addition, the PaLM demonstrates competitive performance for all the domains that were\nused in the experiments including the restaurant, hotel, books, clothing, and movie reviews. Notably, the\nanalysis underscores the models’ domain sensitivity, shedding light on their varying efficacy for both ATSA\nand ACSA tasks. These insights contribute to a deeper understanding of model applicability and highlight\npotential areas for improvement in ABSA research and development.\nINDEX TERMS aspect-based sentiment analysis (ABSA), large language model (LLM), GPT, PaLM,\nBERT\nI. INTRODUCTION\nThe ever-expanding influence of e-commerce, driven by the\nrapid growth of online retail giants like Amazon, Walmart,\nand Alibaba, has cultivated a thriving ecosystem of customer\nreview platforms encompassing a wide array of services\nand products [27], [60]. With consumers freely sharing their\nthoughts and feedback, the digital landscape has witnessed\nan exponential surge in data generation. This surge primarily\ncomprises unstructured textual customer reviews, posing an\nintricate challenge for businesses when it comes to analysis\n[55].\nThe conventional manual examination of such an extensive\ndataset is both time-intensive and, given its scale, nearly\nimpossible. Automatic sentiment analysis proves to be a\nvery useful tool in addressing this problem [3]. Sentiment\nanalysis refers to the process of text classification based on\nits overall emotional tone, negative, positive, or occasion-\nally neutral. It is also known as opinion mining. Based on\nthe subjective expressions and subtle emotional undertones\npresent in the text, these categories have been established\n[39]. It’s interesting to note that many existing sentiment\nanalysis techniques assume a particular sentence or text to\nVOLUME 4, 2016 1\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nhave a constant and consistent sentiment, which is not always\nthe case in real-world scenarios [31]. For instance, consider\nthe following hotel review: \"The hotel staff were extremely\nwelcoming and accommodating, but the room was in dire\nneed of renovation.\" In this case, the sentiment within a single\nreview contains both positive (toward the staff) and negative\n(toward the room condition), illustrating the complexity of\nsentiment in real-world texts. Hence, fine-grained-level sen-\ntiment analysis is required to cater to such challenges.\nSentiment analysis can be broadly categorized into three\nlevels: document-level, sentence-level, and aspect-level anal-\nysis [6]. At the document level, the primary focus is on sum-\nmarizing the sentiments expressed in a review to determine\nwhether they predominantly carry a positive or negative sen-\ntiment. In contrast, sentence-level analysis is concerned with\nevaluating the sentiments expressed in individual sentences.\nAspect-based sentiment analysis (ABSA), on the other hand,\ndelves into a fine-grained examination of opinions directed\ntoward specific terms or categories, commonly known as\ntargets [62]. Sentence-level and document-level sentiment\nanalysis tasks have been a long-established area of research\nin natural language processing(NLP). With the advent of\nDeep learning models, such as LSTM [76], GPT-3 [18], and\nBidirectional Encoder Representations from Transformers\n(BERT) [26], these two tasks of sentiment analysis have\nwitnessed remarkable advancements. However, the ABSA is\na relatively recent task that has become popular very quickly\nand is evolving quickly [6].\nABSA is further divided into subtasks such as aspect term\nextraction (ATE), aspect term sentiment analysis (ATSA),\naspect category detection (ACD), and aspect category senti-\nment analysis (ACSA) [15]. ATSA focuses on predicting the\nsentiment polarity of specific terms mentioned in a review.\nOn the other hand, ACSA aims at predicting the sentiment\nof broader categories that may not be explicitly mentioned\nin the review [23]. For example, let’s consider the restaurant\nreview: \"The management was extremely welcoming and\naccommodating, but the food taste was not up to the mark.\"\nIn this case, ATSA would analyze the sentiment towards the\nterms \"management\" and \"food taste.\" In contrast, ACSA\nwould aim to predict the sentiment regarding broader cat-\negories such as \"food quality\" and \"staff\" which are not\nexplicitly mentioned in the review but can be inferred based\non the context. ACSA and ATSA are pivotal tasks in the era\nof Web 3.0, where online reviews play a vital role in shaping\nthe growth of any company. Hence, companies are more often\ninterested in figuring out the customers’ sentiments about\ntargeted terms or categories to improve their services [41].\nFor example, the restaurant owner may be interested in fig-\nuring out the customer’s sentiments about the two categories\nnamely, food quality and staff behavior.\nABSA is a relatively new field that has gained widespread\npopularity and is undergoing rapid transformations due to\nmany real-world applications [6]. A notable progression in\nthe field pertains to the evolution of utilized datasets. In the\nearly stages of ABSA research, authors frequently engaged in\nscraping and compiling their own datasets from the web [42].\nHowever, a pivotal shift occurred when researchers began\nadopting standardized datasets, such as Twitter [17], laptop\nand restaurant datasets from SemEval-2014, SemEval-2015\n[48], and SemEval-2016[49] challenges, and Sentihood [52]\ndataset. With the rise of Deep learning (DL) and remarkable\nperformance in various natural language processing (NLP),\nrecurrent neural network (RNN) [76], convolution neural\nnetworks (CNN) [29], and Transformers-based [30] based\nmodels have been widely utilized by researchers for ABSA\nsubtasks.\nAccording to recent surveys [62], [6], and [15] conducted\nin 2022 and 2023 respectively, CNN-based models (Sadr\net al. [51]; Wang et al. [66]), RNN-based models that in-\nvolve LSTM (Do [16]), and GRU (Setiawan et al. [54]),\nAttention-based LSTM models (Zeng et al. [78]; Nguyen\nand Le Nguyen [43]; Yang et al. [72]), and transformer-\nbased models (Kumar et al. [28]; Hoang et al. [20]; Peng\net al. [46]; Phan et al. [47]) are widely used for aspect based\nsentiment analysis for state-of-the-art datasets in mentioned\nabove. However, there are three major limitations highlighted\nby the surveys of Trisna and Jie [62], Brauwers and Frasincar\n[6], and Dhanith and Prabha [15] for ATSA and ACSA tasks\nare:\n1) Each dataset employs a unique DL model to enhance\nperformance. Hence, DL models tailored for specific\ndomains exhibit limited generalizability across differ-\nent domains.\n2) These models have a high reliance on labeled dataset,\nand the scarcity of such dataset adversely impacts the\nperformance of DL models in ABSA sub-tasks.\n3) These DL models predominantly focus on explicit\nemotions in text, neglecting the nuanced realm of im-\nplicit emotions.\nTo overcome the above-mentioned limitations, a few stud-\nies have been recently published in 2023 that proposed\nhybrid BERT models. For instance, Mewada and Dewang\n[38] proposed a hybrid model for ABSA using synthetic\nattention in a BERT with the incorporation of extreme gra-\ndient boosting(SA-BERT-XGBoost) which outperforms base\nmodels in terms of accuracy and time efficiency with the\nhighest accuracy of 93.71%) on the restaurant16[49] dataset.\nHowever, it is noteworthy that the SA-BERT-XGBoost does\nnot assess the dependency relationship of sentences, leaving\nthis aspect as a potential avenue for future exploration by\nresearchers in the field. In addition, SA-BERT-XGBoost was\ntrained and tested on restaurant and laptop datasets from\nSemEval challenges (Pontiki et al. [48], Pontiki et al. [49])\nwhich can be further extended for multi-domains.\nAlthough BERT models have been extensively studied for\nABSA, there is a lack of exploration into the potential of\nnewer generative pre-trained transformers (GPT) [18] and\nother large language models (LLM)[7]. The existing models\npredominantly focus on explicit emotions, overlooking the\nnuanced realm of implicit emotions.\n2 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nHence, to overcome the limitations of existing models, this\nstudy explores the potential of LLMs for ABSA subtasks. In\naddition, we perform a comparative analysis of various state-\nof-art models with the recently proposed BERT base models.\nFinally, we execute various analyses on standardized datasets\nas well as the recently published multi-domain datasets.\nThis research study investigates to answer three research\nquestions:\n• RQ1: To what extent can available ABSA models gen-\neralize their aspect-based sentiment analysis capabilities\nto unseen aspects or domains?\n• RQ2: To what extent can pre-trained LLM (e.g. GPT-\n3, and PaLM) generalize their ABSA capabilities to\nunseen aspects or domains?\n• RQ3: How does the performance of LLMs (e.g. GPT-3,\nand PaLM), in aspect-based sentiment analysis compare\nto domain-specific models trained from scratch, con-\nsidering overall accuracy, F1-score, and computational\nefficiency?\n• RQ4: Are there any aspects or domains where LLMs\nshow superior performance compared to the domain-\nspecific models, and how does this relate to the com-\nputational resources required?\nThis research study conducts a comprehensive review of\nsentiment analysis datasets tailored for ABSA tasks, ana-\nlyzing baseline accuracies achieved across these datasets.\nAdditionally, it undertakes a rigorous evaluation of the latest\ndeep-learning models applied to both ATSA and ACSA tasks,\nutilizing established benchmark datasets. The study goes\nfurther to draw a comparison between the performance of\nABSA models and LLMs in terms of accuracy, f1-score,\nand computational resources. In essence, the methodology\noutlined in this study serves to identify key opportunities,\ndiscuss prerequisites for future advancements, and explore\nthe potential of LLMs that could lead to substantial enhance-\nments in ABSA.\nThe key contributions of this study include:\n• Explanation of benchmark and recently proposed\ndatasets for ABSA tasks, accompanied by reported\nbaseline accuracy.\n• Systematic evaluation of recent and state-of-the-art deep\nlearning models for ABSA tasks utilizing benchmark\ndatasets\n• Performance comparison between ABSA models and\nLLMs on the benchmark datasets for ABSA.\n• An insightful evaluation highlighting the existing chal-\nlenges faced by current deep-learning algorithms in\naddressing ABSA tasks, coupled with a presentation\nof potential future directions for research and develop-\nments.\nThe subsequent sections of this study follow a defined\nstructure: Section II explores benchmarks ABSA datasets\nand models in the literature, Section III focuses on dataset\nacquisition, model selection, and evaluation metrics, Section\nIV evaluates the results of the discussed models, Section IV\ndiscussed the key findings and also presents the suggestions\nand recommendations, and the paper concludes in Section VI\nalong with the future research directions.\nII. LITERATURE REVIEW\nIn this section, we provide a comprehensive literature re-\nview on aspect-based sentiment analysis(ABSA). Specifi-\ncally, we examine the evolution of ABSA systems based\non statistical models [13], machine learning models [67],\nand deep learning models [65]. Furthermore, we investigate\nthe applications of transformer-based models [70], [34] in\nthe context of ABSA. Additionally, we explore the existing\nlarge language models (LLMs) that can be utilized for ABSA\nsubtasks namely ATSA and ACSA. By synthesizing the\ncurrent literature, we identify the research gap and propose\nfuture directions to enhance the accuracy, effectiveness, and\nefficiency of ABSA subtasks with the provision of LLM.\nA. EVOLUTION OF ABSA\nEarly approaches to sentiment analysis treated the task as\na sentence-level or document-level classification problem,\nwhere the overall sentiment of the entire text or the sen-\ntence was determined [22]. However, this approach could not\ncapture nuanced opinions about specific aspects or entities\nmentioned in the text. ABSA emerged as a response to this\nlimitation, aiming to provide a more detailed understanding\nof sentiment by associating it with particular aspects or fea-\ntures. ABSA has gained prominence due to its applications\nin understanding user opinions about products, services, or\ntopics in a more granular manner. The two broader categories\nof ABSA models are machine-learning (ML), and deep-\nlearning (DL) models, as outlined by Zhou et al. [80] in 2019.\n1) ML Techniques\nMachine Learning (ML) is a branch of Artificial Intelligence\n(AI) dedicated to creating algorithms and statistical models.\nML empowers computers to learn and make predictions,\nor decisions without requiring explicit programming. [37].\nThe application of ML techniques marked a significant ad-\nvancement in ABSA. Supervised learning models, such as\nNaïve Bayesian [69], Support Vector Machine (SVM) [44],\nand Artificial Neural Networks (ANN) [1], were employed\nfor ABSA subtasks classification [63]. Feature engineering\nplayed a crucial role in these models, with researchers ex-\ntracting relevant features from the text, such as n-grams, bag-\nof-words, part-of-speech, syntactic structures, and sentiment\nlexicons [71]. The performance of these methods heavily\nrelies on manually crafted features, which unfortunately are\nlabor-intensive and comparatively less effective. Hence, re-\nsearchers explored revolutionary DL techniques for ABSA\nsubtasks in recent years.\n2) DL Techniques\nPropelled by rapid advancements in neural network tech-\nniques, Deep Neural Networks (DNNs) have achieved re-\nmarkable success in various applications. This success has\nVOLUME 4, 2016 3\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nled ABSA research to transition from feature-based tech-\nniques to DNN methods. The rise of DNN architectures, such\nas recurrent neural networks (RNNs) [76], convolutional\nneural networks (CNNs) [29], and transformers [30] brought\nabout a paradigm shift in ABSA. Wang et al. [66] proposed\na unified position-aware convolutional neural network (UP-\nCNN) for ATSA and ACSA tasks. This study utilized the\nRestaurant and Laptop datasets from SemEval-2014-Task-\n4[48], MAMS-Term[23], and Twitter [17] datasets for ATSA.\nWhereas, for the ACSA task, Resstaurant-14, and Restaurant-\nlarge were utilized from the SemEval challenges from the\nyear 2014-2016, and the MAMS-Category[23] dataset. In\naddition to that, an RNN-based model that involves long\nshort-term memory (LSTM) was proposed by Do [16], and\na gated recurrent unit (GRU) was also proposed by Setiawan\net al. [54]. These models have shown enhanced performance\nin capturing contextual information and learning intricate\npatterns within textual data[79]. Attention-based LSTM and\nCNN models have been widely proposed for ABSA. For\ninstance, Sadr et al. [51] proposed the attention-based CNN\nmodel. and attention-based LSTM models were proposed by\nZeng et al. [78], Nguyen and Le Nguyen [43], and Yang et al.\n[72].\nThe ability of neural networks to automatically learn hier-\narchical representations contributed to their success in ABSA\nsubtasks. This shift from traditional feature-based methods to\ndiverse DNN architectures reflects the substantial progress in\nneural network research and its applicability to ABSA sub-\ntasks. Each of these DNN-based approaches brings unique\nstrengths to the table, contributing to the evolving landscape\nof ABSA. However, there were two main limitations of\nthe LSTM and CNN models. First, the model trained done\none dataset was not performing well for other datasets and\ndomains. Secondly, these models were struggling to achieve\na remarkable performance in terms of accuracy. Hence,\ntransformer-based models were proposed in recent years for\nABSA tasks.\nB. TRANSFORMER-BASED MODELS\nThe development of transformer architectures, as demon-\nstrated by models such as BERT (Bidirectional Encoder\nRepresentations from Transformers), was another signifi-\ncant advancement in ABSA. Transformer models performed\nexceptionally well in sentiment analysis and other natural\nlanguage processing tasks, outperforming earlier methods\nin the capture of long-range dependencies and contextual\ninformation [30]. Fine-tuning pre-trained transformer models\nfor aspect-based sentiment analysis tasks became a common\npractice, allowing models to leverage large-scale pre-training\non diverse textual data [8].\nTransformers possess a self-attention mechanism that al-\nlows them to recognize word dependencies within a text.\nUnlike recurrent neural networks (RNNs), which process\nsequences sequentially, transformers can process words in\nparallel. The self-attention mechanism can be represented by\nthe following equation:\nAttention(Q, K, V) =softmax\n\u0012QKT\n√dk\n\u0013\n· V\nIn this case, the matrix representing the query vectors is la-\nbeled as Q, the key vectors are denoted by matrix K, and the\nvalue vectors are expressed through matrix V . The similarity\nbetween query-key pairs is determined by the product of Q\nand KT . This factor is scaled by the √dk factor, which is\nthe square root of the dimensionality ( dk) of the query/key\nvectors. The attention output is obtained by multiplying the\nattention weights element-wise with V after the softmax\nfunction has been applied. [64].\nFigure 1 illustrates how an encoder and a decoder make up\na transformer’s architecture. A series of symbol representa-\ntions (x1,··· ,xn) is mapped by the encoder to a series of con-\ntinuous representations (z=( z1,··· ,zn)). Once z is provided,\nthe decoder proceeds to create a symbol output sequence\n(y1,··· ,ym) by producing each element incrementally. [64].\nIn the context of ABSA, the encoder takes the review and\naspect as input and encodes it into a high-dimensional repre-\nsentation. On the other hand, the decoder produces the out-\nput, such as sentiment polarity. The self-attention mechanism\nof transformers enables both the encoder and the decoder\nto record global dependencies for the review and facilitate\neffective information flow [30].\nFIGURE 1: Transformer Architecture [64]\n1) BERT\nBERT (Transformers Bidirectional Encoder Representations)\nis a powerful transformer-based model that has revolu-\ntionized natural language processing tasks. It includes bi-\ndirectional context understanding through the Transformer\narchitecture [59]. BERT has achieved exceptional perfor-\nmance across various domains of NLP such as sentiment\nanalysis, text classification, question answering, and machine\n4 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\ntranslation. BERT’s contextual understanding of language\nhas led to improved search engines, chatbots, and virtual\nassistants, enabling more accurate responses and better user\nexperiences [26]. Although BERT-based models have shown\nremarkable success in ABSA, challenges persist, including\nthe need for domain-specific pre-training, handling ambigu-\nous contexts, and addressing the scarcity of labeled data for\nspecific domains. Hence, to overcome these limitations, large\nlanguage models (LLMs) such as PaLM API, GPT-3, and\nflan-t5 can be used for ABSA subtasks. .\n2) GPT\nGPT is a state-of-the-art LLM and probably a watershed\nmoment in the natural language processing (NLP) field [14].\nDeveloped by OpenAI, GPT employs a transformer archi-\ntecture to generate coherent and contextually accurate text.\nGPT is capable of producing fluent text outputs such as\nlanguage translation, text generation, and question answering\nin a human-like manner as it has been refined by using\na large text data corpus for various NLP tasks [18]. GPT-\n1, GPT-2 [11], and GPT-3 [14] have been made available\nby OpenAI 1. Moreover, the latest innovation of ChatGPT 2\nstunned everyone with its sophisticated features and quickly\nrose to the top of social media and news outlets. The\nChatGPT is uniquely capable of accomplishing divers tasks\nfrom customer reviews datasets such as sentiment analysis,\ntext summarization, and text classification, offensive word\ndetection, etc [32], [18]. While ChatGPT has demonstrated\nremarkable language generation capabilities and has been\napplied to various NLP tasks, its implementation for ABSA\nremains limited and requires further scientific inquiry.\nTo the best of our knowledge, no study has been conducted\nto explore the potential of GPT and other LLMs for ABSA\nsystems. The latest LLM models have not yet been explored\nthoroughly in the ABSA domain. To the best of our knowl-\nedge, our study is a first attempt that explore the ability of\nLLMs for the ABSA domain.\nIII. METHODOLOGY\nIn this section, we discuss the methodology employed to sys-\ntematically evaluate the performance of LLMs for two mains\ntasks of ABSA. Four main steps are carried out on the ac-\nquired datasets, as depicted in Figure 2. First, we acquire the\nstate-of-the-art datasets for two subtasks of ABSA namely,\nAspect Term Sentiment Analysis (ATSA) and Aspect Cate-\ngory Sentiment Analysis (ACSA). Secondly, we trained the\nstate-of-the-art LSTM-based models on the acquired dataset\nto get the baseline results for these datasets. Next, we eval-\nuated the results of BERT-based ABSA models that were\nrecently proposed in the literature. Afterward, we designed\na prompt for the GPT-3.5-turbo 3 and Google Bard 4 model\n1https://openai.com/\n2https://chat.openai.com/\n3https://platform.openai.com/docs/models\n4https://bard.google.com/\nTABLE 1: Summary of benchmark user review Datasets for\nABSA tasks\nDataset Year Domain Tasks Train Val Test\nSemEval2016[49] 2016\nRestaurant ACSA 2507 - 859\nRestaurant ATSA 1880 - 650\nLaptop ACSA 2909 - 801\nSentihood [52] 2016 Neighbourhood ACSA 3401 840 1679\nMAMS[23] 2019 Restaurant ACSA 7090 888 901\nRestaurant ATSA 11186 1332 1336\nY ASO [61] 2022 Multi-domain ATSA 1302 0 332\nDOTSA[35] 2022\nBooks ATSA 1711 342 368\nClothing ATSA 942 177 196\nRestaurant ATSA 3330 712 682\nHotel ATSA 2373 498 549\nthrough prompt-engineering methods to evaluate the poten-\ntial of LLMs for ACSA and ATSA tasks. Finally, we con-\nducted a comparison between the baseline results obtained\nfrom LSTM-based models and the best results achieved by\nrecently proposed aspect-based sentiment analysis (ABSA)\nmodels and Large Language Models (LLMs) available to\ndate. The subsequent sections present a detailed description\nof the methodology from data acquisition to results analysis.\nA. TASK DESCRIPTION\nThis study is focused on two main subtasks of ABSA,\nnamely, aspect category sentiment analysis (ACSA) and as-\npect term sentiment analysis (ATSA) [23]. ATSA is defined\nas predicting the sentiment of any aspect term At that is\npart of the review. Given a review R = {ws1, . . . , wsn}, an\naspect term At = {w1\na1, . . . , wm\na1}, ATSA aims at predicting\nthe sentiment polarity y ∈ {1, . . . , C} of the At in the\nreview R. In contrast, ACSA is defined as predicting the sen-\ntiment of any aspect category Ac that is Entity-Atribute pair\nfrom the predefined Entities and Attributes. For instance, the\ncategories for restaurant dataset can be food-quality, food-\nprice, food-taste etc. Given a review R = {ws1, . . . , wsn},\nan aspect category Ac, ACSA aims to predict the sentiment\npolarity y ∈ {1, . . . , C} of review R with respect to Ac\nB. DATASET ACQUISITION\nIn this study, we used state-of-the-art customer review\ndatasets for ABSA subtasks that are publicly available and\nwidely used for ABSA subtasks. In addition, we also used\nthe recently published dataset in the field of ABSA. In total,\nfive different datasets are used to evaluate the performance of\nLLMs for ABSA subtasks. Table 1 summarizes the datasets\nthat are used and the subsequent sections describe the details\nof these datasets.\nVOLUME 4, 2016 5\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nFIGURE 2: Methodology for LLM evaluation for ABSA subtasks\n1) SemEval2016-Task5\nThe SemEval-2016 Task5 is a shared task on aspect-based\nsentiment analysis (ABSA) which is further divided into\nsubtasks. The datasets were divided into subtasks, includ-\ning sentence-level and text-level ABSA and annotated with\naspects, opinions, and polarities[49]. However, this study is\nfocused on two subtasks; subtask 2: Aspect Term Polarity\n(ATP) or ATSA - determining the polarity/sentiment of each\naspect term [33], subtask 3: Aspect Category Polarity (ACP)\nor ACSA - determining the polarity/sentiment of each aspect\ncategory in a given sentence or text[36], [9]. The dataset\nincludes training and testing sets for 8 languages and 7\ndomains, consisting of 19 training datasets and 20 testing\ndatasets. Additionally, a standardized evaluation procedure is\nprovided.\nThe datasets were provided in various languages, includ-\ning English, Dutch, French, Russian, Spanish, Turkish, and\nChinese. The domains of the datasets included restaurants,\nhotels, consumer electronics, laptops, and museums. How-\never, this study is focused on identifying the sentiment of the\nprovided term or category from English sentences. Hence,\nwe used the datasets of restaurants and laptop domains that\nare based on the English language. The dataset for the restau-\nrants domain consisted of 440 review texts (2675 sentences).\nIn the context of the ACSA task, the dataset comprises a\ntotal of 3366 E#A, polarity tuples that have been manually\nannotated. The category of aspect term is denoted by E#A\n(Entity#Aspect) pair where E and A must be selected from\npredetermined inventories of entity types (e.g., \"restaurant,\"\n\"food\") and attribute labels (e.g., \"price,\" \"quality\").\nThe train test split for these tuples is shown in table 1,\n2507 training tuples, and 859 test tuples. Similarly, in the\ncontext of the ATSA task, the dataset contains 2530 manually\nannotated OT, polarity tuples. Here OT represents the opinion\nterms that are the linguistic expression used in the given text\nto refer to the reviewed entity E E#A pair. The train/test split\nfor these tuples are shown in table 1, 1880 train tuples, and\n650 test tuples.\n2) Sentihood\nThe SentiHood dataset is designed for targeted aspect-based\nsentiment analysis specifically focused on urban neighbor-\nhoods. It was created and provided by Saeidi et al. [52].The\ndataset was derived from a question-answering (QA) plat-\nform where users engage in discussions about urban neigh-\nborhoods. It comprises units of text that frequently reference\nmultiple aspects of one or more neighborhoods. The de-\nfined aspects in the SentiHood dataset encompass general at-\ntributes, price, safety, transit location, tourist spots, nightlife,\nshopping, and dining. It contains annotations for sentiment\npolarity and aspect category for each unit of text. It is the first\ndataset to use a generic social media platform, in this case, a\nQA platform, for fine-grained opinion mining. The dataset\nhas been used in various research studies related to aspect-\nbased sentiment analysis and opinion mining. [58], [2]\n3) MAMS\nThe MAMS dataset is a challenge dataset for aspect-based\nsentiment analysis (ABSA), in which each sentence con-\ntains at least two different aspects with different sentiment\npolarities. It is designed to handle aspect-based sentiment\nanalysis tasks that involve multiple aspects and sentiments in\na single sentence. The dataset contains two versions: one for\naspect-term sentiment analysis (ATSA) and one for aspect-\ncategory sentiment analysis (ACSA). The dataset is available\non GitHub 5, and it has been used in research studies such as\n5https://github.com/siat-nlp/MAMS-for-ABSA\n6 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\n\"A Challenge Dataset and Effective Models for aspect-based\nsentiment analysis\" 6. The dataset is written in a \"standard\"\n(flexible structural) model and has a separation between\nmodel code and database. The statistics of the MAMS dataset\nare presented in 1.\n4) YASO\nY ASO is a targeted sentiment analysis evaluation dataset for\nopen-domain reviews[45], [61]. It is a crowd-sourced dataset\ncontaining more than 2,000 English user comments extracted\nfrom Yelp 7, Amazon [24], Stanford Sentiment Treebank\n(SST)[56], and OPINOSIS [19]. The dataset contains 2215\nannotated sentences, which is on par with the size of existing\ntest sets. It includes all candidate targets, not just valid ones,\neach marked with its confidence, sentiment label (including\nraw annotation counts), and span. The Y ASO dataset is\nnot limited to any particular review domain, thus providing\na broader perspective for open-domain targeted sentiment\nanalysis (TSA). However, some major domains were iden-\ntified by the authors in [61], as follows: 400 sentences were\ncategorized as restaurants, 412 as electronics, 161 as hotels,\n144 as automotive, 500 as movies, and the remaining 596)\nsentences were labeled as others. Whereas, the domain label\nis not publicly available with the dataset.\n5) DOTSA\nDOTSA is a diverse dataset that encompasses six distinct do-\nmains, including book reviews, clothing reviews, restaurant\nreviews, hotel reviews, financial news, and social media data\n[35]. The dataset sources are as follows:\n• Books and Clothing: The dataset includes 986 book\nreviews and 928 clothing reviews, randomly selected\nfrom the 5-core version of a publicly available dataset.\n• Restaurant: Restaurant reviews were collected in Boston\nfrom Yelp (as of April 17, 2021). The dataset comprises\n940 reviews, specifically selected from restaurant-\nrelated content.\n• Hotels: Hotel reviews from Boston, collected via Airbnb\n(as of February 19, 2021), contributed 1029 reviews\nselected at random.\n• Social Media: A sample of 1194 sentences was chosen\nfrom social media data, and annotators assessed senti-\nment from an investor’s perspective.\n• Business News: The business news dataset consists\nof 936 news articles collected from Reuters and\nBloomberg. Reuters News was collected between\nMarch 2021 and April 2021, yielding 498 instances,\nwhile Bloomberg News was gathered from October\n2006 to November 2013, resulting in 438 samples.\nC. STATE-OF-THE-ART LSTM-BASED MODELS\nThe Long Short-Term Memory (LSTM) Network, developed\nby Hochreiter and Schmidhuber [21] in 1997, excels in\n6https://aclanthology.org/D19-1654/\n7https://www.yelp.com/dataset\ncomparison to traditional feedforward neural networks. It\nadeptly handles both individual data points and sequences\ndue to its incorporation of feedback connections. The LSTM\narchitecture consists of three gates (input, forget, and output)\nand a cell memory state.\nIn summary, the LSTM cell computations are expressed\nas:\nit = σ(Wiixt + bii + Whiht−1 + bhi)\nft = σ(Wif xt + bif + Whf ht−1 + bhf )\not = σ(Wioxt + bio + Whoht−1 + bho)\ngt = tanh(Wigxt + big + Whght−1 + bhg)\nct = ft ⊙ ct−1 + it ⊙ gt\nht = ot ⊙ tanh(ct)\nHere, it is the input gate, ft is the forget gate, ot is the\noutput gate, gt is the cell input, ct is the cell state, and ht is\nthe hidden state at time t. The sigmoid function σ is applied\nelement-wise, ⊙ denotes element-wise multiplication, and\nthe weights and biases are represented accordingly.\nFIGURE 3: Architecture of standard LSTM (Wang et al.\n[68])\nIn this study, we used three variations of LSTM-based\nmodels to establish the baseline results for all the datasets\nnamely, LSTM with aspect embedding (AE-LSTM)[68],\nAttention-based LSTM (AT-LSTM)[5], Attention-based\nLSTM with Aspect embedding(ATAE-LSTM)[5]. These\nLSTM-based models are widely used in the domain of ABSA\n[15]. The subsequent sections describe the architecture of\nthese models.\n1) AE-LSTM\nAE-LSTM (Aspect-Enhanced Long Short-Term Memory)\nwas proposed by Wang et al. [68]. This is a neural network\nmodel designed for aspect-based sentiment analysis, a task\ninvolving the classification of sentiment polarity in a text\nbased on a specified aspect or feature. The model leverages\ntwo input layers for the main text sequence and the identified\naspect, employing word embeddings and a spatial dropout\nto capture textual information as shown in Figure 4. The\naspect is similarly embedded and broadcasted across the text\nsequence for effective fusion. The concatenated embeddings\nundergo processing by an LSTM layer, enabling the model\nto capture sequential patterns. A subsequent dense layer\nwith ReLU activation is employed for non-linear feature\nVOLUME 4, 2016 7\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nextraction, culminating in a final dense layer with softmax\nactivation for sentiment classification. This model is particu-\nlarly promising for nuanced sentiment analysis, allowing for\na more granular understanding of sentiment variations across\ndifferent aspects within a given text.\nFIGURE 4: Architecture for AE-LSTM\n2) AT -LSTM\nThe AT-LSTM (Attention-based Long Short-Term Memory)\nneural network architecture proposed here is specifically de-\nsigned for aspect-based sentiment analysis, aiming to classify\nsentiment polarity in a given text concerning a specified\naspect or feature Wang et al. [68]. The model incorporates\ntwo input layers: one for the main text sequence (input-\ntext) and the other for the identified aspect (input-aspect).\nWord embeddings are applied to the text sequence using\nspatial dropout, and a similar embedding process is employed\nfor the aspect. The aspect information is then broadcasted\nacross the text sequence through flattening and repetition\noperations. Subsequently, an LSTM layer processes the text\nembeddings, generating hidden vectors for each word in the\nsequence as shown in Figure 5. The attention mechanism\nis introduced through the concatenation of hidden vectors\nand repeated aspect embeddings. The attention weights are\ncomputed, enabling the model to focus on relevant parts of\nthe input sequence. The attended hidden vectors are then\naggregated, and a dense layer with ReLU activation captures\nnon-linear patterns. The final output layer, with softmax\nactivation, provides the binary sentiment classification. This\nAT-LSTM model holds promise for aspect-aware sentiment\nanalysis, offering an interpretable approach by emphasizing\ncrucial aspects within the input text.\n3) ATAE-LSTM\nThe ATAE-LSTM (Attention-based LSTM with Aspect Em-\nbedding) neural network architecture presented here is tai-\nlored for aspect-based sentiment analysis, a task focused on\ndiscerning sentiment polarity in a given text concerning a\ndesignated aspect or feature Wang et al. [68]. The model\nFIGURE 5: Architecture for AE-LSTM\ncomprises two input layers: input-text for the main text\nsequence and input-aspect for the aspect of interest. Word\nembeddings are employed to represent words in the text\nsequence, with spatial dropout applied to prevent overfitting.\nAspect embeddings are similarly utilized. The aspect infor-\nmation is then broadcasted across the text sequence through\nflattening and repetition operations. The concatenated input\nis processed by an LSTM layer as shown in Figure 6,\nproducing hidden vectors for each word and capturing the\nfinal hidden state. An attention mechanism is introduced by\nconcatenating the hidden vectors and repeated aspect embed-\ndings, generating attention weights that emphasize relevant\nportions of the sequence. The attended hidden vectors are\naggregated and processed through dense layers with hyper-\nbolic tangent activation, offering an interpretable approach to\nsentiment analysis by incorporating specific aspects within\nthe input text. The final output layer, employing softmax\nactivation, provides a binary sentiment classification, reflect-\ning the probability distribution over positive and negative\nsentiments.\nD. FINE-TUNED ABSA MODELS\nIn this study, have used two widely known models for ABSA\nsubtasks namely, deberta-v3-base-ABSA-v1.18, and flan-t5-\nlarge-ABSA9. These two models have recently proposed\nin the domain of ABSA and are widely used by many\nresearchers for ABSA subtasks. The subsequent sections\ndescribe the details of these two models.\n8https://huggingface.co/yangheng/deberta-v3-base-ABSA-v1.1\n9https://huggingface.co/shorthillsai/flan-t5-large-ABSA\n8 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nFIGURE 6: Architecture for ATAE-LSTM\n1) DeBERTa-v3-base-ABSA-v1.1\nDeBERTa-v3-base-ABSA-v1.110 is a model for aspect-based\nsentiment analysis (ABSA) that is trained with English\ndatasets from ABSA Datasets 11. It is based on the FAST-\nLCF-BERT model with Microsoft/DeBERTa-v3-base, which\ncomes from PyABSA [75], [74]. The model is trained with\n30k+ ABSA samples and fine-tuned with 180k examples for\nthe ABSA dataset including SemEval-2014 Task 4 (Laptop14\nand Restaurant14)[25], SemEval-2016 Task 5(Restaurant-\n16)[49], MAMS[23], Television[12], and TShirt[50], [40].\nHowever, the base model, LCF-BERT is an ABSA model that\nenhances sentiment polarity predictions by focusing more on\nlocal context words through the use of a Local Context Focus\n(LCF) mechanism[77]. The main architecture of LCF-BERT\nis shown in Figure 7. There are three primary components of\nthis model:\n1) Local Context Focus (LCF) Mechanism: It forms the\nbasis of the LCF-BERT model. The Context Features\nDynamic Weighted (CDW) and Context Features Dy-\nnamic Mask (CDM) layers are utilized to dynamically\nmodify the context word weights according to their\nsignificance to the aspect. This guarantees that the\nmodel concentrates more on the words that are most\nlikely to affect the aspect’s sentiment polarity.\n2) BERT-shared Layer: Long-term dependencies between\nlocal and global contexts are captured using the BERT-\n10https://github.com/microsoft/DeBERTa\n11https://github.com/yangheng95/ABSADatasets\nFIGURE 7: Architecture of LCF-BERT. MH Self-Attention:\nMulti-Head Self-Attention.\nshared layer. By extracting contextual representations\nof words using the pre-trained BERT parameters, the\nmodel is able to comprehend the relationships between\nwords throughout the entire sentence or document.\n3) Aspect Sentiment Prediction: This part predicts the\nsentiment polarity of an aspect by using the BERT-\nshared layer’s output and the LCF mechanism’s output\nas inputs. A classification layer is utilized to designate\na sentiment label (e.g. g. , neutral, or negative) to the\naspect.\n2) FLAN-T5-large-ABSA\nFLAN-T5-large-ABSA is a fine-tuned version of FLAN-T5-\nlarge12 on a custom dataset prepared by GPT-4 and verified\nby a human. flan-t5-large was developed by Google AI\nand was first introduced in the paper \"Scaling Instruction-\nFinetuned Language Models\" [10]. The paper demonstrates\nthat FLAN-T5-large can achieve state-of-the-art results on a\nvariety of NLP tasks, including natural language inference,\nquestion answering, and summarization.\nThe following are some of flan-t5-large’s main character-\nistics:\n1) Fine-tuning instructions: FLAN-T5-large was trained\non a set of instructions to improve its comprehension\nand compliance with them.\n2) Large size: With 780M parameters, the FLAN-T5-\nlarge language model is large and capable of capturing\nmore intricate word-sentence relationships.\nE. LLMS\nIn this study, we have utilized two main LLM models that\nare widely used and very famous, namely GPT-3.5-turbo 13\nand PaLM bison-001 model 14. GPT-3.5-turbo was released\non 23 March, 2023 by OpenAI15 community. This is the latest\nand most powerful model of GPT that allows access through\nAPI keys.\nIn addition, we used the text-bison-001 model by Google-\ngenerativeai and makersuite 16. By utilizing these models,\n12https://huggingface.co/google/flan-t5-large\n13https://openai.com/\n14https://developers.generativeai.google/products/makersuite\n15https://openai.com/\n16https://developers.generativeai.google/products/makersuite\nVOLUME 4, 2016 9\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nwe predicted the sentiment/polaity for each aspect category\nor aspect term for provided review to further enhance the\neffectiveness of LLMs for ACSA and ATSA tasks. API\nrequests were sent with parameters and prompt engineering\nusing Python 3.9. The cost for using OpenAI’s API is $0.002\nper 1000 tokens. However, the web version of same GPT\nmodel is completely free. In contrast, google’s PaLM API\nis free as of now.\n1) Prompt Design\nWhile writing the GPT prompt, we followed the prompt\nengineering techniques by writing a structured prompt for\nABSA subtasks. The prompt accepts the review and a list\nof aspect categories and aspect terms, and it provides the\nsentiment of each provided sentiment into three classes, i.e.\npositive, negative and neutral. The prompt structure is shown\nin Figure 8.\nFIGURE 8: Prompt used in this study\nF. EXPERIMENTAL SETUP\nExperiments were performed for the three categories of\nmodels namely, LSTM-based, Transformer-based, and LLM\nmodels. The three LSTM-based models described in the\naforementioned sections i.e. AE-LSTM, AT-LSTM, and\nATAE-LSTM, were trained on each of the given datasets.\nMoreover, a total of 36 analyses were executed to assess the\nperformance of the trained models under in-domain settings.\nThis entailed subjecting the trained models to evaluation on\nthe same dataset domain that was utilized during the training\nphase. Afterwards, the most suitable model with the highest\nperformance was used to evaluate the performance for cross-\ndomain settings. These entailed subjecting the trained models\nto evaluation on the different domains that were not utilized\nduring the training phase. These analyses, conducted both\nwithin the domain and across domains, aimed to verify the\nextent to which LSTM-based models could generalize their\nsentiment analysis capabilities to unseen aspects or domains.\nApart from LSTM-based models discussed in the above\nsections, the Python 3.9 version was used to make the API\ncalls to the LLMs(Bard, and GPT-3.5-turbo) to retrieve the\nsentiments for the provided review and aspect categories or\naspect terms. Further, Regular expressions were used to ex-\ntract the sentiments only and discard any unwanted characters\nfrom the API responses. Further, a confusion matrix was\nused to compare the predicted sentiment list with the actual\nsentiment list. By comparing the predicted sentiment to the\nactual sentiment for each given term or category, we can\nidentify specific patterns of misclassification. Moreover, the\nperformance of the above-mentioned models was evaluated\nusing the weighted F-measure and overall accuracy. These\nmeasures were used to assign equivalent weight to the irreg-\nularly distributed Classes in the collected dataset [57].\nIV. RESULTS\nThis section presents a detailed analysis of the results pro-\nduced by the various models that are discussed in the afore-\nmentioned sections. Table 6 summarized the results pro-\nduced by all the mentioned models. The subsequent sessions\npresent detailed analyses of all the experiments that were\nperformed on the acquired datasets.\nA. PERFORMANCE ANALYSIS OF LSTM-BASED\nMODELS\nThis section describes the analyses for both, the in-domain\nand cross-domain settings for LSTM-based models. The\noverall accuracy and F-measureW of 33 analyses (11 datasets\nvariants and 3 LSTM-based models) are shown in Table 2 for\nin-domain settings. The values in bold font show the highest\nvalues in these tables. From these tables, the performance\nvariation can be seen among the three models. In all 36\nanalyses, the highest overall accuracy, and F-measureW were\nachieved by the ATAE-LSTM model for ATSA and ACSA\ntasks for most of the datasets and domains. However, there\nwere only two domains of the DOTSA dataset specifically\nfor restaurants, and hotels domains where AT-LSTM showed\nthe highest performance. Hence, the ATAE-LSTM model\nwas further utilized to execute the analyses for cross-domain\nsettings.\nFor cross-domain settings, the model trained on one\ndataset’s domain was evaluated on the remaining domains\nand datasets. These analyses were executed to validate the\nextent to which the ATAE-LSTM model could generalize its\ncapabilities to unseen domains.\nThe overall accuracy of ATAE-LSTM for ATSA task with\ncross-domain settings is shown in Table 3. The results re-\nvealed that the model trained in one domain was not provid-\ning comparable results for other domains except for a few\ncases. Remarkably, aside from the Y ASO dataset, models\ntrained on the Books and Clothing datasets did not perform\ncomparably well in other domains. The Y ASO dataset’s rela-\ntively close results can be explained by the fact that a sizeable\nportion of the dataset is classified as \"movie,\" while another\nsizeable portion is classified as \"others.\". This similarity in\nlabeling suggests that there may be analogous patterns in\nword embeddings between book and movie reviews.\nOn the other hand, it is also noteworthy that the model\ntrained on the hotel domain yielded comparable results for\n10 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nTABLE 2: Evaluation of all LSTM-based models(Accuracy and F1-score), The best results are highlighted in bold\nDataset Domain Task AE-LSTM AT-LSTM ATAE-LSTM\nAcc F1 Acc F1 Acc F1\nDOTSA\nBooks ATSA 64.1 57.0 66.6 53.2 69.6 67.3\nClothing ATSA 63.8 54.1 61.7 54.1 62.8 60.6\nHotels ATSA 88.0 86.3 90.2 88.2 86.7 86.4\nRestaurant ATSA 75.4 64.8 75.4 64.8 70.1 69.9\nMAMS Restaurant ACSA 59.3 57.3 43.6 26.5 63.9 63.1\nRestaurant ATSA 57.8 57.3 45.4 28.4 63.3 62.9\nSemEval2016\nLaptops ACSA 60.9 62.0 62.1 58.6 68.7 68.8\nRestaurants ACSA 69.9 67.3 70.1 70.8 80.3 79.0\nRestaurants ATSA 74.9 59.8 74.3 63.4 80.9 80.1\nSentihood Neighbourhood ACSA 79.7 79.3 72.5 60.9 84.0 83.6\nY ASO Multi-domain ATSA 61.1 63.0 77.5 67.7 86.2 85.7\nTABLE 3: Overall accuracy of ATAE-LSTM for ATSA task with cross-domain setting\nDataset/\nDomain\nDOTSA\n/Books\nDOTSA/\nClothing\nDOTSA/\nHotels\nDOTSA/\nRestaurant\nMAMS/\nRestaurant\nSemEval16/\nRestaurant\nYASO/\nMulti\nDOTSA/\nBooks 70.92 52.55 58.68 65.68 32.26 56.46 72.99\nDOTSA/\nColthing 61.41 60.2 56.7 58.32 30.76 54.69 71.49\nDOTSA/\nHotels 64.13 52.55 85.61 73.13 30.23 74.92 76.84\nDOTSA/\nRestaurant 65.39\nMAMS/\nRestaurant 33.42 36.73 50.63 45.6 62.64 53.07 48.87\nSemEval16/\nRestaurant 55.16 53.57 75.59 67.44 36.75 81.53 81.99\nYASO/\nMulti 60.86 61.73 75.77 61.73 32.41 72 85.2\nrestaurant and hotel domains which are related domains with\nsimilarities. Similarly, the model trained on the restaurant\ndomain showed comparable performance for the restaurant\nand hotel datasets. Hence, it was concluded from the results\nthat there is still a need for more labeled datasets that contain\ndiverse domains that can yield comparable results for various\ndomains such as books, clothes, and others. However, label-\ning such a huge dataset is still an open research question.\nThe overall accuracy of ATAE-LSTM for cross-domain\nsettings for the ACSA task is shown in Table 4. The results\nrevealed a similar pattern as of ATSA that is mentioned\nin the above paragraph. The model trained in one domain\ndid not provide comparable results for other domains. How-\never, it is noteworthy that the model trained on the Se-\nmEval16/Restaurant domain did not yield comparable results\nfor the MAMS dataset which also contains the restaurant\nreview dataset. The possible reason for this is the list of cate-\ngories that are mentioned in these two datasets. Furthermore,\nthe MAMS dataset is more challenging as compared to the\nSemEval16/Restaurant.\nOn the other hand, when the model was trained on the\nMAMS dataset, the accuracy was improved MAMS whereas\nTABLE 4: Overall accuracy of ATAE-LSTM for ACSA task\nwith cross-domain setting\nDataset/\nDomain\nSentihood/\nNeighborhood\nSemEval16/\nRestaurant\nSemEval16/\nLaptop MAMS\nSentihood/\nNeighborhood 83.5 69.49 60.92 30.29\nSemEval16/\nRestaurant 69.44 80.9 62.79 38.4\nSemEval16/\nLaptop 58.72 67.63 68.16 32.18\nMAMS 41.21 44.7 44.44 63.81\nthe accuracy was still low for SemEval16/Restaurant. Hence,\nit was concluded from the overall results that there is no\ndataset available in the literature for ACSA tasks that can\nyield comparable accuracies for various domains. There is a\nneed for a large-scale dataset that contains aspect categories\nfor various domains or a model that can perform well for all\nthe domains without requiring a huge dataset for training.\nVOLUME 4, 2016 11\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nB. PERFORMANCE ANALYSIS OF FINE-TUNED ABSA\nMODELS\nThis section discusses the results of ABSA models that are\nrecently been proposed and fine-tuned on ABSA datasets.\nDeBERTa-v3-base-ABSA-v1.1 fine-tuned with 180k exam-\nples for the ABSA dataset including SemEval challenge of\ndatasets form 2014 and 2016 (Laptop14 and Restaurant14,\nRestaurant-16) [25], [49], MAMS[23], Television[12], and\nTShirt[50], [40]. Overall, this model is mainly fine-tuned in\nthe Restaurant, Laptop, Tshirt, and Television domains. Sim-\nilarly, flan-t5-large-ABSA is fine-tuned on a custom dataset\nprepared by GPT-4 and verified by a human[10]. However,\nthe domains of GPT-4 generated reviews are not explicitly\nmentioned. To evaluate the generalizability of these fine-\ntuned ABSA models, 22 analyses (11 dataset variants and\n2 models) were executed. The overall accuracy and F1-score\nof fine-tuned models are shown in Table 5.\nThe analysis results indicate that DeBERTa-v3-base-\nABSA-v1.1 outperformed the flan-t5-large-ABSA both in\nterms of overall accuracy and f1-score. Notably, DeBERTa\nwas trained on diverse ABSA datasets, including MAMS,\nSentihood, and SemEval16. In contrast, flan-t5 was specif-\nically trained and fine-tuned on a custom dataset that was\ngenerated from GPT-4. This implies that the performance\nof flan-t5 is solely reliant on the quality of the dataset,\nwhile DeBERTa’s substantial success can be attributed to the\nutilization of standard datasets during training.\nDeBERTa has exhibited exceptional results for the ATSA\ntask, particularly excelling in the Hotels and Restaurant\ndomains across various datasets. Notably, it achieved re-\nmarkable overall accuracies of 93.1%, 83.7%, 83.8%,\nand 84.5%, along with corresponding impressive f1-scores\nof 91.1%, 79.9%, 83.8%, and 82.1% for the DOT-\nSA/Hotel, DOTSARestaurant, MAMS/Restaurant, and Se-\nmEval16/Restaurant datasets, respectively.\nDespite these remarkable achievements, it is essential to\nhighlight that while DeBERTa excelled in well-established\ndomains used during its training, its performance was com-\nparatively lower for new or unseen domains, such as Books\nand Clothing from DOTSA. In addition, the results also\nrevealed that DeBERTa’s performance exhibited relative lim-\nitations for the ACSA task the target is the detect the senti-\nment of aspect categories that are not necessarily mentioned\nin the review. This emphasizes the ongoing necessity for a\nmodel capable of generalizing its capabilities to unexplored\ndomains without an extensive reliance on labeled datasets,\nwhich can be a laborious undertaking. Hence, LLMs can be\nutilized to overcome such limitations of the ABSA models\nC. PERFORMANCE ANALYSIS OF LLMS\nThis section discusses the results of PaLM and GPT-3.5-\nTurbo LLMs for ATSA and ACSA tasks. A comprehensive\nevaluation of the performance of these LLMs was conducted,\nencompassing 22 analyses involving 11 dataset variants and\n2 models. The overall accuracy and f1-score for both ATSA\nand ACSA are presented in Table6, Table7, Table8, and\nTABLE 5: Evaluation of all fine-tuned ABSA mod-\nels(Accuracy and F1-score), The best results are highlighted\nin bold\nDataset Domain Task Flan-t5 DeBERTa\nAcc F1 Acc F1\nDOTSA\nBooks ATSA 68.5 69.6 74.7 70.3\nClothing ATSA 74.0 75.5 78.6 70.6\nHotels ATSA 90.2 90.9 93.1 91.1\nRestaurant ATSA 79.5 79.7 83.7 79.9\nMAMS Restaurant ACSA 49.4 47.5 77.4 77.2\nRestaurant ATSA 52.6 51.0 83.8 83.8\nSemEval2016\nLaptops ACSA 68.8 75.9 81.9 79.0\nRestaurants ACSA 85.0 87.4 83.5 80.7\nRestaurants ATSA 84.5 87.6 84.6 82.1\nSentihood NeighbourhoodACSA 52.3 66.3 87.6 87.4\nY ASO Multi-\ndomain\nATSA 83.5 90.2 95.3 95.3\nTable9 respectively. These tables also include a compara-\ntive analysis of LLMs with baseline studies, providing a\nbroader context for understanding the models’ performance.\nThe subsequent sections discuss the comparative analysis\nof LLMs, offering insights into their strengths and areas of\nimprovement.\n1) Comparative analysis for ATSA task\nThe overall accuracy, and f1-score of baseline studies and\nthe LLM models for ATSA tasks are summarized in Table\n6 and Table 7. Notably, our investigation reveals that PaLM\nconsistently demonstrates remarkable performance across di-\nverse domains, occasionally surpassing DeBERTa—a model\nacknowledged for its recent advancements and trained on\nmultiple Aspect-Based Sentiment Analysis (ABSA) datasets.\nThis noteworthy trend underscores PaLM’s robustness and\ncompetitiveness, especially in comparison to the latest devel-\nopments in ABSA models. Specifically, our findings indicate\nthat PaLM yields comparable results to DeBERTa for all do-\nmains of DOTSA[35] dataset. Particularly PaLM’s efficacy\nis impressive in domains such as Hotels and Restaurants,\nwhere its accuracy often outshines that of DeBERTa. In addi-\ntion, it also beats the baseline accuracy for all the domains\nof DOTSA with 93.1% and 82.8% accuracy for hotel and\nrestaurant domains respectively. Furthermore, PaLM yielded\nexceptional results for SemEval16/Restaurant Pontiki et al.\n[49] and Y ASOToledo-Ronen et al. [61] dataset also and\noutshined the performance of DeBERTa as well as the base-\nline accuracy. Particularly, PaLM yielded 93.5% and 98.1%\naccuracy for SemEval16/Restaurant and Y ASO datasets re-\nspectively.\nHowever, it is essential to acknowledge that, unlike other\ndomains, PaLM faces challenges in the \"MAMS\" dataset,\nwhere its performance is notably lower than DeBERTa. On\n12 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nTABLE 6: Overall accuracy comparison of LLMs for ATSA task\nDataset Domain Baseline ATAE-LSTM DeBERTa PaLM GPT-3.5\nDOTSA[35]\nBooks 31.9[35] 69.6 74.7 79.2 71.9\nClothing 43.1[35] 62.8 78.6 77.6 69.4\nHotels 37.1[35] 86.7 93.1 93.1 87.4\nRestaurant 20.8[35] 70.1 83.7 82.8 79.5\nMAMS[23] Restaurant 84.5[4] 63.3 83.8 48.8 61.8\nSemEval16[49] Restaurant 90.3[73] 80.9 84.6 93.5 88.8\nY ASO[61] Multi 53.7[61] 86.2 95.3 98.1 91.3\nTABLE 7: F1-score Comparison of LLMs for ATSA task\nDataset Domain Baseline ATAE-LSTM DeBERTa PaLM GPT-3.5\nDOTSA\nBooks 31.9 67.3 70.3 74.8 72.5\nClothing 43.1 60.6 70.6 69.7 68.8\nHotels 37.1 86.4 91.1 91.8 88.6\nRestaurant 20.8 69.9 79.9 81.7 81.9\nMAMS Restaurant 83.7 62.9 83.8 35.1 61.2\nSemEval16 Restaurant 85.6 80.1 82.1 91.8 90.5\nY ASO Multi 85.5 85.7 95.3 98.2 94.6\nthe other hand, GPT-3.5 yielded better accuracy for the\nMAMS dataset as compared to PaLM. It exhibits the compa-\nrable results that were achieved by the ATAE-LSTM model\nwhich is specifically trained on the MAMS dataset. It is also\nnoticeable that the accuracy of the ATAE-LSTM model was\nvery low for cross-domain settings as presented in Table 3.\nhsldjfh Hence, the utilization of PaLM eliminates the training\nstep by yielding similar results that were achieved by training\nthe model which requires a large set of labeled datasets.\nWhile PaLM excels in several domains, its limitations in\nthe \"MAMS\" dataset warrant careful consideration and may\nsuggest areas for improvement or adaptation. Nonetheless,\nfor the MAMS dataset, GPT-3.5 yielded comparable results\nconcerning baseline and ATAE-LSTM. More robust LLMs\nsuch as GPT-4 can be explored in the future to achieve\nsignificant results for challenging datasets such as MAMS.\nThese findings contribute valuable insights for researchers\nand practitioners navigating the selection of ABSA models,\nurging a nuanced evaluation that goes beyond overall perfor-\nmance to encompass domain-specific intricacies.\n2) Comparative analysis for ACSA task\nThe overall accuracy and F1-score comparisons between\nbaseline studies and LLM models for ACSA are presented\nin Table 8 and Table 9. PaLM LLM consistently exhibits\ncommendable performance across various domains and out-\nperforms the DeBERTa in terms of overall accuracy and\nf-score. This observation underscores PaLM’s robustness\nand competitiveness for ACSA task as compared to the\nlatest advancements in ABSA models. Particularly PaLM’s\nefficacy is impressive in domains such as Hotels, Restau-\nrants, and neighborhood domains, where its accuracy and f-\nscore outshine that of DeBERTa. In addition, it also beats\nthe baseline accuracy for Sentihood [52], and SemEval16\nPontiki et al. [49] with 90.7%, 91.0%, and 92.7% accu-\nracy for Sentihood/neighborhood, SemEval16/Laptop and\nSemEval16/Restaurant domains respectively. Furthermore,\nin terms of f-score PaLM’s performance is also outstanding\nwith 90.9%, 88.7%, and 90.9% f-score for Sentihood/neigh-\nborhood, SemEval16/Laptop, and SemEval16/Restaurant do-\nmains respectively.\nV. DISCUSSION\nFrom the outcomes of our experiments, we derive important\nkey findings and suggestions for ABSA tasks across various\ndomains that are discussed in subsequent sections.\nVOLUME 4, 2016 13\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nTABLE 8: Overall accuracy comparison of LLMs for ACSA task\nDataset Domain Baseline ATAE-LSTM DeBERTa PaLM GPT-3.5\nSentihood[52] Neighbourhood 93.3[58] 84.0 87.6 90.7 67.8\nSemEval16[49] Laptop 88.4 [53] 68.7 81.9 91.0 67.8\nRestaurant 84.0[23] 80.3 83.5 92.7 81.1\nMAMS[23] Restaurant 74.0 [23] 63.9 77.4 55.8 64.5\nTABLE 9: F1-score Comparison of LLMs for ACSA task\nDataset Domain Baseline ATAE-LSTM DeBERTa PaLM GPT-3.5\nSentihood Neighbourhood 87.9 83.6 87.4 90.9 65.4\nSemEval16 Laptop - 68.8 79.0 88.7 75.4\nRestaurant - 79.0 80.7 90.9 85.7\nMAMS Restaurant - 63.1 77.2 48.4 64.4\nA. LSTM-BASED MODELS\nThe ATAE-LSTM model consistently outperformed others\nfor in-domain settings. However, challenges in cross-domain\nsettings, especially for models trained on specific domains\nlike Books and Clothing, struggled to perform well in unseen\ndomains. Notably, the model trained on the hotel domain\ndemonstrated comparable results for both restaurant and\nhotel domains, indicating the shared sentiment expressions\nbetween closely related domains. These findings emphasize\nthe importance of addressing domain-specific nuances and\nprompt further exploration into tailored model architectures.\nThere is a need to develop diverse datasets and explore\nalternative architectures to improve sentiment analysis model\nrobustness.\nB. FINE-TUNED ABSA MODELS\nDeBERTa-v3-base-ABSA-v1.1, fine-tuned on diverse ABSA\ndatasets including MAMSJiang et al. [23], SentihoodSaeidi\net al. [52], and SemEval16Pontiki et al. [49], outperformed\nflan-t5-large-ABSA. DeBERTa’s extensive training on stan-\ndard datasets led to superior overall accuracy and F1-score.\nWhile excelling in established domains like Hotels and\nRestaurants for ATSA tasks, DeBERTa faced limitations in\nnew or unseen domains, like Books and Clothing from the\nDOTSA dataset. This emphasizes the need for ABSA models\nwith broad generalization capabilities across diverse domains\nwithout an exhaustive dependence on labeled datasets. Fur-\nthermore, the results also highlighted DeBERTa’s relative\nshortcomings in the ACSA task, emphasizing the need for\nmodels capable of detecting sentiment in aspect categories\nnot explicitly mentioned in the reviews.\nC. LLM\nIn terms of both, ATSA and ACSA tasks, PaLM consis-\ntently exhibits commendable performance, outperforming\nDeBERTa in both overall accuracy and F1-score across var-\nious domains. However, challenges arise in the \"MAMS\",\nwhere its performance falls notably behind. This underscores\nthe need for continued refinement to ensure the model’s\nadaptability to various and challenging datasets such as\nMAMS with multiple aspects and multiple sentiments in\na single review. Interestingly, GPT-3.5 exhibits promise,\nparticularly in challenging datasets such as MAMS, where\nits results compete favorably with specialized models like\nATAE-LSTM. Notably, these results are encouraging as they\nwere achieved without prior training or labeled datasets.\nVI. CONCLUSION AND FUTURE RESEARCH\nDIRECTIONS\nIn this study, we conducted a comparative analysis of ABSA\nmodels, comparing the performance of baseline studies\nLLMs approaches across various datasets and domains. Our\nfindings highlight the consistent and remarkable performance\nof the PaLM model, which often surpassed DeBERTa, a\nmodel recognized for recent advancements in ABSA and\ntrained on multiple ABSA datasets. PaLM demonstrated\ncommendable efficacy across diverse domains. The model\noutperformed not only DeBERTa but also baseline accu-\nracy. However, it is crucial to acknowledge the challenges\nfaced by PaLM in the \"MAMS\" dataset, where its perfor-\nmance was notably lower than that of DeBERTa. GPT-3.5,\non the other hand, yielded better accuracy for the MAMS\ndataset, comparable to the results achieved by the ATAE-\nLSTM model specifically trained on MAMS. These find-\n14 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nings underscore the complexity of model performance in\ndifferent domains and highlight the need for nuanced eval-\nuations beyond overall accuracy. The limitations observed\nin the \"MAMS\" dataset prompt consideration for poten-\ntial improvements or adaptations, and the exploration of\nmore robust Language Models, such as GPT-4, may offer\npromising avenues for future research. Our study contributes\nvaluable insights for researchers and practitioners navigating\nthe selection of ABSA models, emphasizing the importance\nof domain-specific considerations. Leveraging LLMs like\nPaLM and GPT-3.5 eliminates the requirement for labeled\ndatasets in ABSA tasks, streamlining the training process and\nmitigating the need for high-computation machines across\ndomains. While PaLM emerges as a robust performer across\nvarious domains, the nuanced challenges posed by specific\ndatasets, like \"MAMS,\" underscore the evolving nature of\nABSA tasks. Continued research and exploration of LLMs\nhold the key to addressing these challenges and further en-\nhancing the field of ABSA. Subsequent research endeavors\ncould explore the evaluation of more advanced LLMs, like\nGPT-4, to further enhance ABSA capabilities, particularly\nwhen dealing with challenging datasets.\nVII. ACKNOWLEDGEMENT\nThis work was supported by the National Research\nProgram for Universities (NRPU), Higher Education\nCommission, Pakistan under Project Ref No. 20-\n14457/NRPU/R&D/HEC/2021-2020.\nREFERENCES\n[1] S Agatonovic-Kustrin and Rosemary Beresford. Basic\nconcepts of artificial neural network (ann) modeling\nand its application in pharmaceutical research. Journal\nof pharmaceutical and biomedical analysis, 22(5):717–\n727, 2000.\n[2] Md Shad Akhtar, Tarun Garg, and Asif Ekbal.\nMulti-task learning for aspect term extraction and\naspect sentiment classification. Neurocomputing,\n398:247–256, 2020. ISSN 0925-2312. . URL\nhttps://www.sciencedirect.com/science/article/pii/S0925231220302897.\n[3] Laith Alzubaidi, Jinglan Zhang, Amjad J Humaidi,\nAyad Al-Dujaili, Ye Duan, Omran Al-Shamma, José\nSantamaría, Mohammed A Fadhel, Muthana Al-\nAmidie, and Laith Farhan. Review of deep learning:\nConcepts, cnn architectures, challenges, applications,\nfuture directions. Journal of big Data, 8:1–74, 2021.\n[4] Xuefeng Bai, Pengbo Liu, and Yue Zhang. Investi-\ngating typed syntactic dependencies for targeted sen-\ntiment classification using graph attention neural net-\nwork. IEEE/ACM Transactions on Audio, Speech, and\nLanguage Processing, 29:503–514, 2021. .\n[5] Lingxian Bao, Patrik Lambert, and Toni Badia. At-\ntention and lexicon regularized lstm for aspect-based\nsentiment analysis. In Proceedings of the 57th annual\nmeeting of the association for computational linguis-\ntics: student research workshop, pages 253–259, 2019.\n[6] Gianni Brauwers and Flavius Frasincar. A survey on\naspect-based sentiment classification. ACM Computing\nSurveys, 55(4):1–37, 2022.\n[7] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu,\nKaijie Zhu, Hao Chen, Linyi Yang, Xiaoyuan Yi,\nCunxiang Wang, Yidong Wang, et al. A survey on\nevaluation of large language models. arXiv preprint\narXiv:2307.03109, 2023.\n[8] Martin R Chavez, Thomas S Butler, Patricia Rekawek,\nHye Heo, and Wendy L Kinzler. Chat generative\npre-trained transformer: why we should embrace this\ntechnology. American Journal of Obstetrics and Gyne-\ncology, 228(6):706–711, 2023.\n[9] Siva Uday Sampreeth Chebolu, Paolo Rosso, Sudipta\nKar, and Thamar Solorio. Survey on aspect category\ndetection. ACM Computing Surveys, 55(7):1–37, 2022.\n[10] Hyung Won Chung, Le Hou, Shayne Longpre, Barret\nZoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, et al.\nScaling instruction-finetuned language models. arXiv\npreprint arXiv:2210.11416, 2022.\n[11] Vanya Cohen and Aaron Gokaslan. Opengpt-2: Open\nlanguage models and implications of generated text.\nXRDS: Crossroads, The ACM Magazine for Students,\n27(1):26–30, 2020.\n[12] Thavisha Cooray, Geethika Perera, Archchana Kugath-\nasan, and Jesuthasan Alosius. Aspect-based sentiment\nanalysis: movie and television series reviews. In Inter-\nnational Workshop on Advanced Imaging Technology\n(IW AIT) 2021, volume 11766, pages 615–620. SPIE,\n2021.\n[13] Robert G Cowell, Philip Dawid, Steffen L Lauritzen,\nand David J Spiegelhalter. Probabilistic networks\nand expert systems: Exact computational methods for\nBayesian networks. Springer Science & Business Me-\ndia, 2007.\n[14] Robert Dale. Gpt-3: What’s it good for? Natural\nLanguage Engineering, 27(1):113–118, 2021.\n[15] PR Joe Dhanith and KS Sakunthala Prabha. A crit-\nical empirical evaluation of deep learning models for\nsolving aspect based sentiment analysis. Artificial\nIntelligence Review, pages 1–60, 2023.\n[16] Binh Thanh Do. Aspect-based sentiment analysis us-\ning bitmask bidirectional long short term memory net-\nworks. In The thirty-first international flairs conference,\n2018.\n[17] Li Dong, Furu Wei, Chuanqi Tan, Duyu Tang, Ming\nZhou, and Ke Xu. Adaptive recursive neural network\nfor target-dependent twitter sentiment classification. In\nProceedings of the 52nd annual meeting of the asso-\nciation for computational linguistics (volume 2: Short\npapers), pages 49–54, 2014.\n[18] Luciano Floridi and Massimo Chiriatti. Gpt-3: Its\nnature, scope, limits, and consequences. Minds and\nMachines, 30:681–694, 2020.\n[19] Kavita Ganesan, ChengXiang Zhai, and Jiawei Han.\nVOLUME 4, 2016 15\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nOpinosis: A graph based approach to abstractive sum-\nmarization of highly redundant opinions. In Proceed-\nings of the 23rd international conference on computa-\ntional linguistics (Coling 2010), pages 340–348, 2010.\n[20] Mickel Hoang, Oskar Alija Bihorac, and Jacobo\nRouces. Aspect-based sentiment analysis using bert. In\nProceedings of the 22nd nordic conference on compu-\ntational linguistics, pages 187–196, 2019.\n[21] Sepp Hochreiter and Jürgen Schmidhuber. Long short-\nterm memory. Neural computation, 9(8):1735–1780,\n1997.\n[22] VS Jagtap and Karishma Pawar. Analysis of differ-\nent approaches to sentence-level sentiment classifica-\ntion. International Journal of Scientific Engineering and\nTechnology, 2(3):164–170, 2013.\n[23] Qingnan Jiang, Lei Chen, Ruifeng Xu, Xiang Ao, and\nMin Yang. A challenge dataset and effective models\nfor aspect-based sentiment analysis. In Proceedings\nof the 2019 conference on empirical methods in natu-\nral language processing and the 9th international joint\nconference on natural language processing (EMNLP-\nIJCNLP), pages 6280–6285, 2019.\n[24] Phillip Keung, Yichao Lu, György Szarvas, and Noah A\nSmith. The multilingual amazon reviews corpus. arXiv\npreprint arXiv:2010.02573, 2020.\n[25] DK Kirange, Ratnadeep R Deshmukh, and MDK Ki-\nrange. Aspect based sentiment analysis semeval-2014\ntask 4. Asian Journal of Computer Science and Infor-\nmation Technology (AJCSIT) V ol, 4, 2014.\n[26] MV Koroteev. Bert: a review of applications in natural\nlanguage processing and understanding. arXiv preprint\narXiv:2103.11943, 2021.\n[27] Suresh Kotha and Sandip Basu. Amazon and ebay:\nOnline retailers as market makers. The market makers:\nHow retailers are reshaping the global economy, pages\n155–180, 2011.\n[28] Avinash Kumar, Pranjal Gupta, Raghunathan Balan,\nLalita Bhanu Murthy Neti, and Aruna Malapati. Bert\nbased semi-supervised hybrid approach for aspect and\nsentiment classification. Neural Processing Letters, 53:\n4207–4224, 2021.\n[29] Zewen Li, Fan Liu, Wenjie Yang, Shouheng Peng, and\nJun Zhou. A survey of convolutional neural networks:\nanalysis, applications, and prospects. IEEE transactions\non neural networks and learning systems, 2021.\n[30] Tianyang Lin, Yuxin Wang, Xiangyang Liu, and Xipeng\nQiu. A survey of transformers. AI Open, 2022.\n[31] Bing Liu et al. Sentiment analysis and subjectivity.\nHandbook of natural language processing, 2(2010):\n627–666, 2010.\n[32] Brady D Lund and Ting Wang. Chatting about chatgpt:\nhow may ai and gpt impact academia and libraries?\nLibrary Hi Tech News, 40(3):26–29, 2023.\n[33] Huaishao Luo, Tianrui Li, Bing Liu, and Junbo Zhang.\nDoer: Dual cross-shared rnn for aspect term-polarity co-\nextraction. arXiv preprint arXiv:1906.01794, 2019.\n[34] Wenqing Luo, Wei Zhang, and Yihang Zhao. A survey\nof transformer and gnn for aspect-based sentiment anal-\nysis. In 2021 International Conference on Computer In-\nformation Science and Artificial Intelligence (CISAI),\npages 353–357. IEEE, 2021.\n[35] Yun Luo, Hongjie Cai, Linyi Yang, Yanxia Qin,\nRui Xia, and Yue Zhang. Challenges for open-\ndomain targeted sentiment analysis. arXiv preprint\narXiv:2204.06893, 2022.\n[36] Jakub Machá ˇcek. Butknot at semeval-2016 task 5:\nsupervised machine learning with term substitution ap-\nproach in aspect category detection. In Proceedings of\nthe 10th International Workshop on Semantic Evalua-\ntion (SemEval-2016), pages 301–305, 2016.\n[37] Batta Mahesh. Machine learning algorithms-a re-\nview. International Journal of Science and Research\n(IJSR).[Internet], 9:381–386, 2020.\n[38] Arvind Mewada and Rupesh Kumar Dewang. Sa-asba:\nA hybrid model for aspect-based sentiment analysis\nusing synthetic attention in pre-trained language bert\nmodel with extreme gradient boosting. The Journal of\nSupercomputing, 79(5):5516–5551, 2023.\n[39] Saif M Mohammad. Sentiment analysis: Detecting va-\nlence, emotions, and other affectual states from text. In\nEmotion measurement, pages 201–237. Elsevier, 2016.\n[40] Rajdeep Mukherjee, Shreyas Shetty, Subrata Chat-\ntopadhyay, Subhadeep Maji, Samik Datta, and Pawan\nGoyal. Reproducibility, replicability and beyond: As-\nsessing production readiness of aspect based sentiment\nanalysis in the wild. In Advances in Information\nRetrieval: 43rd European Conference on IR Research,\nECIR 2021, Virtual Event, March 28–April 1, 2021,\nProceedings, Part II 43, pages 92–106. Springer, 2021.\n[41] Zarmeen Nasim and Sajjad Haider. Absa toolkit: An\nopen source tool for aspect based sentiment analysis.\nInternational Journal on Artificial Intelligence Tools, 26\n(06):1750023, 2017.\n[42] Zarmeen Nasim and Sajjad Haider. Absa toolkit: An\nopen source tool for aspect based sentiment analysis.\nInternational Journal on Artificial Intelligence Tools, 26\n(06):1750023, 2017.\n[43] Huy Thanh Nguyen and Minh Le Nguyen. Effective\nattention networks for aspect-level sentiment classi-\nfication. In 2018 10th International Conference on\nKnowledge and Systems Engineering (KSE), pages 25–\n30. IEEE, 2018.\n[44] William S Noble. What is a support vector machine?\nNature biotechnology, 24(12):1565–1567, 2006.\n[45] Matan Orbach, Orith Toledo-Ronen, Artem Spector,\nRanit Aharonov, Yoav Katz, and Noam Slonim.\nY ASO: A targeted sentiment analysis evaluation\ndataset for open-domain reviews. In Marie-Francine\nMoens, Xuanjing Huang, Lucia Specia, and Scott\nWen-tau Yih, editors, Proceedings of the 2021\nConference on Empirical Methods in Natural\nLanguage Processing, pages 9154–9173, Online\n16 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nand Punta Cana, Dominican Republic, November 2021.\nAssociation for Computational Linguistics. . URL\nhttps://aclanthology.org/2021.emnlp-main.721.\n[46] Yuqing Peng, Tengfei Xiao, and Hongtao Yuan. Coop-\nerative gating network based on a single bert encoder\nfor aspect term sentiment analysis. Applied Intelli-\ngence, 52(5):5867–5879, 2022.\n[47] Huyen Trang Phan, Ngoc Thanh Nguyen, and Dosam\nHwang. Aspect-level sentiment analysis using cnn over\nbert-gcn. IEEE Access, 10:110402–110409, 2022.\n[48] Maria Pontiki, Dimitrios Galanis, Harris Papageor-\ngiou, Suresh Manandhar, and Ion Androutsopoulos.\nSemeval-2015 task 12: Aspect based sentiment analy-\nsis. In Proceedings of the 9th international workshop on\nsemantic evaluation (SemEval 2015), pages 486–495,\n2015.\n[49] Maria Pontiki, Dimitris Galanis, Haris Papageorgiou,\nIon Androutsopoulos, Suresh Manandhar, Mohammed\nAL-Smadi, Mahmoud Al-Ayyoub, Yanyan Zhao, Bing\nQin, Orphée De Clercq, et al. Semeval-2016 task\n5: Aspect based sentiment analysis. In ProWorkshop\non Semantic Evaluation (SemEval-2016), pages 19–30.\nAssociation for Computational Linguistics, 2016.\n[50] Sampath Rajapaksha and Surangika Ranathunga. As-\npect detection in sportswear apparel reviews for opin-\nion mining. In 2022 Moratuwa Engineering Research\nConference (MERCon), pages 1–6. IEEE, 2022.\n[51] Hossein Sadr, Mir M Pedram, and Mohammad Tesh-\nnehlab. Convolutional neural network equipped with\nattention mechanism and transfer learning for enhanc-\ning performance of sentiment analysis. Journal of AI\nand data mining, 9(2):141–151, 2021.\n[52] Marzieh Saeidi, Guillaume Bouchard, Maria Liakata,\nand Sebastian Riedel. SentiHood: Targeted aspect\nbased sentiment analysis dataset for urban neighbour-\nhoods. In Yuji Matsumoto and Rashmi Prasad, editors,\nProceedings of COLING 2016, the 26th International\nConference on Computational Linguistics: Technical\nPapers, pages 1546–1556, Osaka, Japan, December\n2016. The COLING 2016 Organizing Committee. URL\nhttps://aclanthology.org/C16-1146.\n[53] Kevin Scaria, Himanshu Gupta, Saurabh Arjun Sawant,\nSwaroop Mishra, and Chitta Baral. Instructabsa: In-\nstruction learning for aspect based sentiment analysis.\narXiv preprint arXiv:2302.08624, 2023.\n[54] Esther Irawati Setiawan, Ferry Ferry, Joan Santoso,\nSurya Sumpeno, Kimiya Fujisawa, and Mauridhi Hery\nPurnomo. Bidirectional gru for targeted aspect-based\nsentiment analysis based on character-enhanced token-\nembedding and multi-level attention. International\nJournal of Intelligent Engineering & Systems, 13(5),\n2020.\n[55] Galit Shmueli, Peter C Bruce, Inbal Yahav, Nitin R\nPatel, and Kenneth C Lichtendahl Jr. Data mining for\nbusiness analytics: concepts, techniques, and applica-\ntions in R. John Wiley & Sons, 2017.\n[56] Richard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D Manning, Andrew Y Ng, and\nChristopher Potts. Recursive deep models for semantic\ncompositionality over a sentiment treebank. In Proceed-\nings of the 2013 conference on empirical methods in\nnatural language processing, pages 1631–1642, 2013.\n[57] Marina Sokolova and Guy Lapalme. A systematic\nanalysis of performance measures for classification\ntasks. Information processing & management, 45(4):\n427–437, 2009.\n[58] Chi Sun, Luyao Huang, and Xipeng Qiu. Utiliz-\ning BERT for aspect-based sentiment analysis via\nconstructing auxiliary sentence. In Jill Burstein,\nChristy Doran, and Thamar Solorio, editors, Pro-\nceedings of the 2019 Conference of the North\nAmerican Chapter of the Association for Compu-\ntational Linguistics: Human Language Technologies,\nV olume 1 (Long and Short Papers), pages 380–\n385, Minneapolis, Minnesota, June 2019. Associ-\nation for Computational Linguistics. . URL\nhttps://aclanthology.org/N19-1035.\n[59] Ian Tenney, Dipanjan Das, and Ellie Pavlick. Bert\nrediscovers the classical nlp pipeline. arXiv preprint\narXiv:1905.05950, 2019.\n[60] Yenni Tim, Lili Cui, and Zhenzhong Sheng. Digital\nresilience: How rural communities leapfrogged into\nsustainable development. Information Systems Journal,\n31(2):323–345, 2021.\n[61] Orith Toledo-Ronen, Matan Orbach, Yoav Katz,\nand Noam Slonim. Multi-domain targeted\nsentiment analysis. In Marine Carpuat, Marie-\nCatherine de Marneffe, and Ivan Vladimir\nMeza Ruiz, editors, Proceedings of the 2022\nConference of the North American Chapter of\nthe Association for Computational Linguistics:\nHuman Language Technologies, pages 2751–2762,\nSeattle, United States, July 2022. Association\nfor Computational Linguistics. . URL\nhttps://aclanthology.org/2022.naacl-main.198.\n[62] Komang Wahyu Trisna and Huang Jin Jie. Deep learn-\ning approach for aspect-based sentiment classification:\na comparative review. Applied Artificial Intelligence,\n36(1):2014186, 2022.\n[63] Raisa Varghese and M Jayasree. Aspect based senti-\nment analysis using support vector machine classifier.\nIn 2013 international conference on advances in com-\nputing, communications and informatics (ICACCI),\npages 1581–1586. IEEE, 2013.\n[64] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. Attention is all you need.\nAdvances in neural information processing systems, 30,\n2017.\n[65] Jie Wang, Bingxin Xu, and Yujie Zu. Deep learning\nfor aspect-based sentiment analysis. In 2021 Interna-\ntional Conference on Machine Learning and Intelligent\nVOLUME 4, 2016 17\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nSystems Engineering (MLISE), pages 267–271. IEEE,\n2021.\n[66] Xinyi Wang, Feng Li, Zequn Zhang, Guangluan Xu,\nJingyuan Zhang, and Xian Sun. A unified position-\naware convolutional neural network for aspect based\nsentiment analysis. Neurocomputing, 450:91–103,\n2021.\n[67] Yanyan Wang, Qun Chen, Jiquan Shen, Boyi Hou,\nMurtadha Ahmed, and Zhanhuai Li. Aspect-level\nsentiment analysis based on gradual machine learning.\nKnowledge-Based Systems, 212:106509, 2021.\n[68] Yequan Wang, Minlie Huang, Xiaoyan Zhu, and\nLi Zhao. Attention-based lstm for aspect-level senti-\nment classification. In Proceedings of the 2016 confer-\nence on empirical methods in natural language process-\ning, pages 606–615, 2016.\n[69] Geoffrey I Webb, Eamonn Keogh, and Risto Miikku-\nlainen. Naïve bayes. Encyclopedia of machine learning,\n15(1):713–714, 2010.\n[70] Hu Xu, Lei Shu, Philip Yu, and Bing Liu.\nUnderstanding pre-trained BERT for aspect-based\nsentiment analysis. In Donia Scott, Nuria Bel,\nand Chengqing Zong, editors, Proceedings of the\n28th International Conference on Computational\nLinguistics, pages 244–250, Barcelona, Spain\n(Online), December 2020. International Committee\non Computational Linguistics. . URL\nhttps://aclanthology.org/2020.coling-main.21.\n[71] Yan Xu, Kai Hong, Junichi Tsujii, and Eric I-Chao\nChang. Feature engineering combined with machine\nlearning and rule-based methods for structured informa-\ntion extraction from narrative clinical discharge sum-\nmaries. Journal of the American Medical Informatics\nAssociation, 19(5):824–832, 2012.\n[72] Chao Yang, Hefeng Zhang, Bin Jiang, and Keqin Li.\nAspect-based sentiment analysis with alternating coat-\ntention networks. Information Processing & Manage-\nment, 56(3):463–478, 2019.\n[73] Heng Yang and Ke Li. Improving implicit sentiment\nlearning via local sentiment aggregation. arXiv preprint\narXiv:2110.08604, 2021.\n[74] Heng Yang, Biqing Zeng, Mayi Xu, and Tianxing\nWang. Back to reality: Leveraging pattern-driven\nmodeling to enable affordable sentiment dependency\nlearning. CoRR, abs/2110.08604, 2021. URL\nhttps://arxiv.org/abs/2110.08604.\n[75] Heng Yang, Chen Zhang, and Ke Li. Pyabsa: A\nmodularized framework for reproducible aspect-based\nsentiment analysis. In Proceedings of the 32nd ACM In-\nternational Conference on Information and Knowledge\nManagement, pages 5117–5122, 2023.\n[76] Yong Yu, Xiaosheng Si, Changhua Hu, and Jianxun\nZhang. A review of recurrent neural networks: Lstm\ncells and network architectures. Neural computation,\n31(7):1235–1270, 2019.\n[77] Biqing Zeng, Heng Yang, Ruyang Xu, Wu Zhou, and\nXuli Han. Lcf: A local context focus mechanism\nfor aspect-based sentiment classification. Applied\nSciences, 9(16), 2019. ISSN 2076-3417. URL\nhttps://www.mdpi.com/2076-3417/9/16/3389.\n[78] Jiangfeng Zeng, Xiao Ma, and Ke Zhou. Enhancing\nattention-based lstm with position context for aspect-\nlevel sentiment classification. IEEE Access, 7:20462–\n20471, 2019.\n[79] You Zhang, Jin Wang, and Xuejie Zhang. Conciseness\nis better: Recurrent attention lstm model for document-\nlevel sentiment analysis. Neurocomputing, 462:101–\n112, 2021.\n[80] Jie Zhou, Jimmy Xiangji Huang, Qin Chen, Qinmin Vi-\nvian Hu, Tingting Wang, and Liang He. Deep learning\nfor aspect-level sentiment classification: Survey, vision,\nand challenges. IEEE access, 7:78454–78483, 2019.\nNIMRA MUGHAL received the master’s degree\n(Hons.) in computer science from Sukkur IBA\nUniversity, Sukkur, Pakistan, in 2022. Currently,\nshe holds the position of Researcher in Artificial\nIntelligence at Sukkur IBA University. In addi-\ntion to her role in Artificial Intelligence, She also\nserves as a visiting faculty member at Computer\nScience department of Sukkur IBA. Prior to join-\ning Sukkur IBA University, she worked with re-\nputed colleges as a Subject Specialist, Computer\nScience. She has sound experience in teaching and research. Her research\ninterests include deep learning, machine learning, text mining, natural lan-\nguage processing, and computer vision.\nGHULAM MUJTABA received the master’s de-\ngree (Hons.) in computer science from FAST Na-\ntional University, Karachi, Pakistan, and the Ph.D.\ndegree from the Faculty of Computer Science and\nInformation Technology, University of Malaya,\nKuala Lumpur, Malaysia. He has received the gold\nmedal for his master’s degree. He has been an\nAssociate Professor with Sukkur IBA University,\nSukkur, Pakistan, since 2006. Prior to joining\nSukkur IBA University, he was with a well-known\nsoft ware house in Karachi for four years. He has vast experience in teaching\nand research. He has also published several articles in academic journals\nindexed in well-reputed databases, such as ISI and Scopus. His research\ninterests include machine learning, online social networking, text mining,\ndeep learning, and information retrieval.\n18 VOLUME 4, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nNimra Mughalet al.: Comparative Analysis of Deep Natural Networks and LLMs for ABSA\nAVEENASH KUMAR received the Bachelor’s\nDegree from the Sukkur IBA University, Pak-\nistan, in 2023. He is currently working as a Data\nScinetist at Learners.ai His research interests in-\nclude in deep learning, natural language process-\ning, and signal processing.\nSHER MUHAMMAD DAUDPOTAreceived the\nmaster’s and Ph.D. degrees from the Asian Insti-\ntute of Technology, Thailand, in 2008 and 2012,\nrespectively. He is currently a Professor of com-\nputer science with Sukkur IBA University, Pak-\nistan. Alongside his computer science contribu-\ntion, he is also a Quality Assurance Expert in\nhigher education. He has reviewed more than 50\nuniversities in Pakistan for quality assurance on\nbehalf of the Higher Education Commission in\nthe role of an Educational Quality Reviewer. He is the author of more\nthan 35 peer-reviewed journals and conference publications. His research\ninterests include deep learning, natural language processing, video, and\nsignal processing.\nVOLUME 4, 2016 19\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3386969\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7641288042068481
    },
    {
      "name": "Natural language processing",
      "score": 0.5759453177452087
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5113213062286377
    },
    {
      "name": "Sentiment analysis",
      "score": 0.5111106038093567
    },
    {
      "name": "Natural language",
      "score": 0.4482630491256714
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I68288478",
      "name": "Sukkur IBA University",
      "country": "PK"
    },
    {
      "id": "https://openalex.org/I204778367",
      "name": "Norwegian University of Science and Technology",
      "country": "NO"
    },
    {
      "id": "https://openalex.org/I4210117871",
      "name": "Systems, Applications & Products in Data Processing (Canada)",
      "country": "CA"
    }
  ]
}