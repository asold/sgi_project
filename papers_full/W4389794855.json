{
    "title": "Structure-conditioned masked language models for protein sequence design generalize beyond the native sequence space",
    "url": "https://openalex.org/W4389794855",
    "year": 2023,
    "authors": [
        {
            "id": null,
            "name": "Akpinaroglu, Deniz",
            "affiliations": [
                "University of California, San Francisco",
                "University of California, Berkeley"
            ]
        },
        {
            "id": "https://openalex.org/A4289304206",
            "name": "Kortemme, Tanja",
            "affiliations": [
                "Quantitative BioSciences",
                "Chan Zuckerberg Initiative (United States)",
                "University of California, Berkeley",
                "University of California, San Francisco"
            ]
        },
        {
            "id": null,
            "name": "Akpinaroglu, Deniz",
            "affiliations": [
                "University of California, San Francisco"
            ]
        },
        {
            "id": "https://openalex.org/A4289304206",
            "name": "Kortemme, Tanja",
            "affiliations": [
                "University of California, San Francisco"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3177828909",
        "https://openalex.org/W3186179742",
        "https://openalex.org/W4327550249",
        "https://openalex.org/W3216341763",
        "https://openalex.org/W4286488966",
        "https://openalex.org/W4281702815",
        "https://openalex.org/W4311179098",
        "https://openalex.org/W4383957026",
        "https://openalex.org/W4319452608",
        "https://openalex.org/W4296031103",
        "https://openalex.org/W4296032638",
        "https://openalex.org/W4297433310",
        "https://openalex.org/W3106745904",
        "https://openalex.org/W2957874522",
        "https://openalex.org/W1969644422",
        "https://openalex.org/W2121627241",
        "https://openalex.org/W4309643848",
        "https://openalex.org/W4281790889",
        "https://openalex.org/W2069602336"
    ],
    "abstract": "Machine learning has revolutionized computational protein design, enabling significant progress in protein backbone generation and sequence design. Here, we introduce Frame2seq, a structure-conditioned masked language model for protein sequence design. Frame2seq generates sequences in a single pass, achieves 49.1% sequence recovery on the CATH 4.2 test dataset, and accurately estimates the error in its own predictions, outperforming the autoregressive ProteinMPNN model with over six times faster inference. To probe the ability of Frame2seq to generate novel designs beyond the native-like sequence space it was trained on, we experimentally test 26 Frame2seq designs for de novo backbones with low identity to the starting sequences. We show that Frame2seq successfully designs soluble (22/26), monomeric, folded, and stable proteins (17/26), including a design with 0% sequence identity to native. The speed and accuracy of Frame2seq will accelerate exploration of novel sequence space across diverse design tasks, including challenging applications such as multi-objective optimization.",
    "full_text": null
}