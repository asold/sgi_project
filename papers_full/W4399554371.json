{
  "title": "Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course",
  "url": "https://openalex.org/W4399554371",
  "year": 2024,
  "authors": [
    {
      "id": null,
      "name": "Padiyath, Aadarsh",
      "affiliations": [
        "Michigan United",
        "University of Michiganâ€“Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2433561683",
      "name": "Hou, Xinying",
      "affiliations": [
        "University of Michiganâ€“Ann Arbor",
        "Michigan United"
      ]
    },
    {
      "id": null,
      "name": "Pang, Amy",
      "affiliations": [
        "University of Michiganâ€“Ann Arbor"
      ]
    },
    {
      "id": null,
      "name": "Vargas, Diego Viramontes",
      "affiliations": [
        "University of Michiganâ€“Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A3162399056",
      "name": "Gu Xingjian",
      "affiliations": [
        "University of Michiganâ€“Ann Arbor"
      ]
    },
    {
      "id": null,
      "name": "Nelson-Fromm, Tamara",
      "affiliations": [
        "Michigan United",
        "University of Michiganâ€“Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2743618737",
      "name": "Wu Zihan",
      "affiliations": [
        "University of Michiganâ€“Ann Arbor",
        "Michigan United"
      ]
    },
    {
      "id": "https://openalex.org/A3161224177",
      "name": "Guzdial Mark",
      "affiliations": [
        "Michigan United",
        "University of Michiganâ€“Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A3175052357",
      "name": "Ericson Barbara",
      "affiliations": [
        "University of Michiganâ€“Ann Arbor",
        "Michigan United"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6819083493",
    "https://openalex.org/W4362659486",
    "https://openalex.org/W4323033785",
    "https://openalex.org/W2917563899",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W2016226370",
    "https://openalex.org/W2283235026",
    "https://openalex.org/W2134574130",
    "https://openalex.org/W2020985469",
    "https://openalex.org/W1964782406",
    "https://openalex.org/W4289814940",
    "https://openalex.org/W4382654251",
    "https://openalex.org/W4390985631",
    "https://openalex.org/W2148781867",
    "https://openalex.org/W3009875955",
    "https://openalex.org/W4390315320",
    "https://openalex.org/W4211263275",
    "https://openalex.org/W4376117451",
    "https://openalex.org/W4366605526",
    "https://openalex.org/W4390490759",
    "https://openalex.org/W4389260745",
    "https://openalex.org/W4390833780",
    "https://openalex.org/W4400642896",
    "https://openalex.org/W4321162272",
    "https://openalex.org/W4391584367",
    "https://openalex.org/W4396833177",
    "https://openalex.org/W4386584937",
    "https://openalex.org/W2516983423",
    "https://openalex.org/W2090782242",
    "https://openalex.org/W4391584331",
    "https://openalex.org/W4289731443",
    "https://openalex.org/W3195710064",
    "https://openalex.org/W2918128486",
    "https://openalex.org/W4318658857",
    "https://openalex.org/W3156467727",
    "https://openalex.org/W4392564557",
    "https://openalex.org/W2109005014",
    "https://openalex.org/W4392542704",
    "https://openalex.org/W3112677505",
    "https://openalex.org/W3048016185",
    "https://openalex.org/W4390315357",
    "https://openalex.org/W4386099272",
    "https://openalex.org/W3009228731",
    "https://openalex.org/W2112031352",
    "https://openalex.org/W4392564446",
    "https://openalex.org/W2974671914",
    "https://openalex.org/W4381587445",
    "https://openalex.org/W3009245502",
    "https://openalex.org/W3047894037",
    "https://openalex.org/W2055191767",
    "https://openalex.org/W2766599972",
    "https://openalex.org/W2900923163",
    "https://openalex.org/W2279187984",
    "https://openalex.org/W4393967925",
    "https://openalex.org/W4384461076",
    "https://openalex.org/W2029080137",
    "https://openalex.org/W1511502075",
    "https://openalex.org/W414755498",
    "https://openalex.org/W3098231782",
    "https://openalex.org/W314228717",
    "https://openalex.org/W4233919019",
    "https://openalex.org/W4250545357",
    "https://openalex.org/W1884921489",
    "https://openalex.org/W1537547771",
    "https://openalex.org/W4283745323",
    "https://openalex.org/W3021922473"
  ],
  "abstract": "The capability of large language models (LLMs) to generate, debug, and\\nexplain code has sparked the interest of researchers and educators in\\nundergraduate programming, with many anticipating their transformative\\npotential in programming education. However, decisions about why and how to use\\nLLMs in programming education may involve more than just the assessment of an\\nLLM's technical capabilities. Using the social shaping of technology theory as\\na guiding framework, our study explores how students' social perceptions\\ninfluence their own LLM usage. We then examine the correlation of self-reported\\nLLM usage with students' self-efficacy and midterm performances in an\\nundergraduate programming course. Triangulating data from an anonymous\\nend-of-course student survey (n = 158), a mid-course self-efficacy survey\\n(n=158), student interviews (n = 10), self-reported LLM usage on homework, and\\nmidterm performances, we discovered that students' use of LLMs was associated\\nwith their expectations for their future careers and their perceptions of peer\\nusage. Additionally, early self-reported LLM usage in our context correlated\\nwith lower self-efficacy and lower midterm scores, while students' perceived\\nover-reliance on LLMs, rather than their usage itself, correlated with\\ndecreased self-efficacy later in the course.\\n",
  "full_text": "Insights from Social Shaping Theory: The Appropriation of Large\nLanguage Models in an Undergraduate Programming Course\nAadarsh Padiyath\nUniversity of Michigan\nAnn Arbor, USA\naadarsh@umich.edu\nXinying Hou\nUniversity of Michigan\nAnn Arbor, USA\nxyhou@umich.edu\nAmy Pang\nUniversity of Michigan\nAnn Arbor, USA\namypang@umich.edu\nDiego Viramontes Vargas\nUniversity of Michigan\nAnn Arbor, USA\ndvvargas@umich.edu\nXingjian Gu\nUniversity of Michigan\nAnn Arbor, USA\nxjgu@umich.edu\nTamara Nelson-Fromm\nUniversity of Michigan\nAnn Arbor, USA\ntamaranf@umich.edu\nZihan Wu\nUniversity of Michigan\nAnn Arbor, USA\nziwu@umich.edu\nMark Guzdial\nUniversity of Michigan\nAnn Arbor, USA\nmjguz@umich.edu\nBarbara Ericson\nUniversity of Michigan\nAnn Arbor, USA\nbarbarer@umich.edu\nABSTRACT\nThe capability of large language models (LLMs) to generate, debug,\nand explain code has sparked the interest of researchers and educa-\ntors in undergraduate programming, with many anticipating their\ntransformative potential in programming education. However, de-\ncisions about why and how to use LLMs in programming education\nmay involve more than just the assessment of an LLMâ€™s technical\ncapabilities. Using the social shaping of technology theory as a guid-\ning framework, our study explores how studentsâ€™ social perceptions\ninfluence their own LLM usage. We then examine the correlation of\nself-reported LLM usage with studentsâ€™ self-efficacy and midterm\nperformances in an undergraduate programming course. Triangu-\nlating data from an anonymous end-of-course student survey (n =\n158), a mid-course self-efficacy survey (n=158), student interviews\n(n = 10), self-reported LLM usage on homework, and midterm per-\nformances, we discovered that studentsâ€™ use of LLMs was associated\nwith their expectations for their future careers and their percep-\ntions of peer usage. Additionally, early self-reported LLM usage in\nour context correlated with lower self-efficacy and lower midterm\nscores, while studentsâ€™ perceived over-reliance on LLMs, rather\nthan their usage itself, correlated with decreased self-efficacy later\nin the course.\nCCS CONCEPTS\nâ€¢ Social and professional topics â†’Computing education ;\nComputer science education ; CS1; â€¢ Human-centered com-\nputing â†’Field studies.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia\nÂ© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0475-8/24/08. . . $15.00\nhttps://doi.org/10.1145/3632620.3671098\nKEYWORDS\nLarge Language Models, Generative AI, Self-Efficacy, Social Shaping\nTheory, Technology Appropriation Model\nACM Reference Format:\nAadarsh Padiyath, Xinying Hou, Amy Pang, Diego Viramontes Vargas,\nXingjian Gu, Tamara Nelson-Fromm, Zihan Wu, Mark Guzdial, and Barbara\nEricson. 2024. Insights from Social Shaping Theory: The Appropriation of\nLarge Language Models in an Undergraduate Programming Course. InACM\nConference on International Computing Education Research V.1 (ICER â€™24 Vol.\n1), August 13â€“15, 2024, Melbourne, VIC, Australia. ACM, New York, NY, USA,\n17 pages. https://doi.org/10.1145/3632620.3671098\n1 INTRODUCTION\nThe ability of large language models (LLMs) to solve programming\nproblems has sparked calls for undergraduate programming cur-\nriculum changes [7, 23, 24, 31, 67]. Often, these pro-LLM arguments\nfocus on the capabilities, availability, and usability of LLMs. This\nperspective demonstrates technological determinism â€“ implying the\ncapabilities of technology itself should guide the direction of edu-\ncational reforms [19, 62, 79]. Although LLMs may have significant\ncapabilities, technological determinism overlooks the influential so-\ncial and cultural dimensions of technology adoption and use [76, 89].\nDecisions about the use of LLMs in education are nuanced and\nshaped by more than just their capabilities; they also involve educa-\ntorsâ€™ and studentsâ€™ preferences, goals, and the broader educational\ncontext [47]. History has shown that predicting a technologyâ€™s suc-\ncess based solely on its capabilities can be misguided. Ames and\nReich argue that initiatives like â€˜One Laptop per Childâ€™ and Massive\nOpen Online Courses (MOOCs) were driven by determinist ethos,\nand fell short on their goals of democratizing and revolutionizing\neducation at scale [ 1, 71]. They suggest this was, in part, due to\ninsufficient consideration of social and individual factors [71, 76].\nUndergraduate programming classrooms are valuable contexts\nfor investigating the social and individual dynamics of LLM use. The\ndiversity of studentsâ€™ goals within these environments [14, 20, 26]\nprovides a unique opportunity to study how social perceptions\ninfluence studentsâ€™ decisions to use LLMs and how they perceive\narXiv:2406.06451v1  [cs.HC]  10 Jun 2024\nICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia Padiyath, et al.\nthe toolsâ€™ impact on their programming education. Understanding\nthat technology is both shaped by and shapes societal practices,\nour paper employs the social shaping of technology (SST) theory\n[89] to frame the study. SST stands in contrast to technological\ndeterminism by positing an interactive and cyclical, as opposed\nto sequential or optimal, approach to understanding the develop-\nment and use of technology [89]. According to SST, societal groups\nare not mere passive consumers of technological innovations; they\nhave agency and substantially shape the ways technology is ap-\npropriated. Conversely, technology is not a neutral tool; it exerts a\nconsiderable influence on the behaviors of these groups. Using SST\ntheory, we examine how social factors influence the use of LLMs in\nan introductory programming course and their impact on student\nself-perception and learning outcomes. Our research is guided by\nthe following research questions:\nRQ1: How do social perceptions influence the usage of Large\nLanguage Models in an undergraduate intermediate-level program-\nming course?\nRQ2: How does LLM usage relate to programming self-efficacy\nand midterm scores among undergraduate students in an intermediate-\nlevel programming course?\nTo address these questions, we employ a mixed-methods study\nof an intermediate-level undergraduate programming course incor-\nporating an anonymous student survey, student interviews, and\na regression analysis of midterm performance data with studentsâ€™\nself-reported use of LLMs on homework. Our findings aim to pro-\nvide evidence of the social dynamics surrounding LLM usage in\ncoursework and its implications for the undergraduate program-\nming learning experience.\n2 LITERATURE REVIEW\n2.1 LLMs in Programming Education\nLLMs are a class of machine learning models that probabilistically\ngenerate natural language and code by learning statistical relation-\nships from text documents [ 9]. Especially popular are OpenAIâ€™s\ngenerative pre-trained transformer (GPT) models, currently avail-\nable as ChatGPT1 (as of March 1, 2024 the free version is known\nas GPT-3.5, and a $20 per month more advanced version is known\nas GPT-4) and Github Copilot2. The capability of these models to\ngenerate, document, and explain code has led researchers to explore\ntheir possible uses in computing education [67].\nInvestigations into LLMsâ€™ capabilities highlight opportunities\nand drawbacks when applying them in programming education\n[31, 67]. However, a significant limitation of using these tools for\neducational purposes is that they were not originally designed with\nprogramming instruction in mind [63]. As such, several research\nefforts have focused on adapting the tool for scaffolding program-\nming education, often by restricting its ability to produce code or\ngive â€˜the answer, â€™ while still providing useful aid [45, 51, 55], or by\nusing LLMâ€™s ability to power more sophisticated scaffolding mech-\nanisms [41, 42]. Yet, even when this limited version is provided,\nmany students may opt to use the original version instead [45].\nIn formal educational settings, students are often not required\nto use LLMs, but some make the personal choice to do so [ 67].\n1https://openai.com/blog/chatgpt\n2https://github.com/features/copilot\nRecent surveys and interview studies discuss possible technical\naspects (usage patterns [5, 33, 67, 69] or broader affordances and\nconstraints of LLM use [ 33, 91, 92]) or structural aspects (issues\nof academic misconduct/unauthorized use [ 48, 67, 69, 74, 92]) of\nLLMs in programming classrooms. However, researchers have yet\nto investigate the social and cultural dimensions of studentsâ€™ LLM\nadoption and use. Our study specifically investigates these social\ndynamics surrounding LLMs.\nAlthough previous studies have investigated novice use of modi-\nfied LLM assistants [33, 69], relatively few have explored the effects\nof using the LLMs in novice studentsâ€™ programming education\n[43, 44]. Early studies [43, 44] have investigated how self-regulated\nlearners use LLMs for code generation, finding patterns of tool use\nthat can lead to over-reliance such as generating entire solutions\nto programming problems without engaging with the generated\ncode. However, the effects of LLM usage on studentsâ€™ self-efficacy\nand their perceptions of learning outcomes are not yet understood.\nAssessing the impact of LLMs on these factors is essential, as they\nsignificantly influence and predict persistence in the field of com-\nputing [50].\n2.2 Self-efficacy in CS Education\nSelf-efficacy refers to individualsâ€™ subjective evaluations of their\nown capabilities to successfully perform an activity [4]. Self-efficacy\nhas been found to play an important role in learning as it can impact\nstudentsâ€™ persistence on a learning task, and attitudes when facing\nlearning obstacles [3, 22, 38]. In CS education, studentsâ€™ self-efficacy\nrefers to their perception of competence to complete CS courses\nand finish programming tasks [ 54, 66, 86, 88, 93]. Studentsâ€™ CS\nself-efficacy may vary according to major, gender, and racial and\nethnic groups [61, 65]. In this work, we compared our classroom\nwith historical patterns of self-efficacy using regression analysis\nwith predictors of gender, under-represented-minority-status, and\nexperience to validate if our sample follows broader self-efficacy\ntrends.\nPrevious research has demonstrated relationships between stu-\ndentsâ€™ self-efficacy and help-seeking behavior in CS classrooms.\nSpecifically, Cheong et al. [18] reported that studentsâ€™ instrumental\nhelp-seeking, where they request only the amount of help they\nneed to complete the task individually [58], was positively corre-\nlated with their self-efficacy beliefs. However, studentsâ€™ executive\nhelp-seeking, in which they wish to have the task solved for them\n[58], was negatively correlated with studentsâ€™ self-efficacy [ 18].\nGiven that LLM tools can become new valuable help-seeking re-\nsources [39], we investigated the relationship between studentsâ€™\nself-efficacy and their use of LLM tools when working on program-\nming assignments.\n2.3 Social Shaping of Technology and Society\nDiscussions of technologyâ€™s influence on education are often based\non the perspective known astechnological determinism [62, 79]. This\nviewpoint suggests that the inherent capabilities of a certain tech-\nnology will inevitably shape human behavior and society [81]. For\nexample, the belief that the capacity of LLMs to generate code neces-\nsitates sweeping changes to programming pedagogy and curricula\n[24, 32]. Additionally, the belief that the convenience of quickly\nThe Appropriation of LLMs in an Undergraduate Programming Course ICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia\nproduced code will necessarily crush studentsâ€™ motivation to solve\nproblems or learn independently [24, 46, 48].\nHowever, others argue that deterministic thinking discounts\nthe vital role that social context plays in the integration of new\ntechnologies [47, 89]. It also downplays human agency in shaping\nsocietal impacts of these technologies [6, 47, 81, 90]. Raw technical\ncapacities are not the sole determiners of LLMsâ€™ use and effects.\nUltimately, human decision â€“ instructorsâ€™, studentsâ€™, and othersâ€™ â€“\nshapes how we incorporate a technology into our learning practices\nor reject it. Factors such as studentsâ€™ access, prior experience, goals,\nand support systems may play a crucial role in determining whether\nLLMs hinder, alter, or enhance learning processes. Similarly, the\nintegration of LLMs by instructors is strongly influenced by their\neducational values and beliefs [48, 90]. The theory of social shap-\ning of technology (SST) argues that societal structures and forces\nsignificantly influence how technologies like LLMs are designed,\ndisseminated, and appropriated [6, 57, 81, 89].\nMackay and Gillespie conceptualize social shaping theory as\nthree distinct (but not sequential) spheres: (1) conception, inven-\ntion, development and design; (2) marketing; and (3) appropriation\nby users [57]. The first sphere focuses on how technologies are\nfunctionally and symbolically encoded by designers to afford cer-\ntain ends, and how ideology plays a central role in these processes.\nThe second sphere sees marketing as crucial to the social shaping\nprocess, as it creates demand for technologies and informs their\ncontinued development. The third sphere emphasizes the social\nappropriation of technologies by users in ways that can differ from\nthe intentions of designers and marketers, as users bring their own\ninterpretations and uses to technologies. In our context, we focus\non the third sphere, the appropriation of LLMs in an undergraduate\nprogramming course.\nWe utilize the technology appropriation model [16, 17], as shown\nin Figure 1, to conceptualize our research context and findings. Car-\nroll et al. describes the transformation of technology-as-designed\ninto technology-in-use through this process of appropriation. This\nprocess begins with a filter of attractors and repellents that deter-\nmine whether a user will start experimenting with and evaluating\nthe technology, or choose not to adopt it at all (non-appropriation).\nIf the user does decide to explore the technology, the process of\nappropriation involves an assessment of the technology against\nvarious appropriation criteria . If the technology is a good fit for the\nuserâ€™s requirements, it will be appropriated and integrated into the\nuserâ€™s practices, becoming technology-in-use. However, if negative\nperceptions of the technology (disappropriation criteria ) outweigh\nthe benefits, the user may reject or disappropriate the technology.\nOnce appropriated, continued use is maintained throughreinforcers:\nhigher-order drivers that satisfy the userâ€™s deeper needs and moti-\nvations [17].\nThis contrasts with popular models of technology adoption such\nas the Technology Acceptance Model [21] and Diffusion of Innova-\ntion theory [73], which have been criticized for emphasizing the\nadoption of a static artifact and not accounting for the evolving\ninteraction between users and technology post-adoption [56, 72].\nIn reality, users of technology often have the agency to modify an\ninnovation to better serve their purposes, even after the artifact has\nbeen produced [16], resulting in the technology-in-use differing\nfrom the technology-as-designed. For example, the modern bicy-\ncle - originally designed for transportation - became a symbol of\nempowerment in first-wave feminism and is a medium for class\nexpression through accessories [13, 60].\n3 METHODS\nOur study was conducted in the context of an undergraduate Python\ncourse. We began with an anonymous survey to understand stu-\ndentsâ€™ broad attitudes towards and perceptions around LLMs, fol-\nlowed by semi-structured interviews for deeper insights, and ended\nwith a regression analysis of midterm performance with self-reported\nuse of LLMs on homework. We chose this sequence of methods to\nfirst understand the landscape and find general patterns we then ex-\nplored in depth during interviews. Finally, the analysis of midterm\nperformance was conducted post-semester, due to a stipulation of\nour universityâ€™s institutional review board.\n3.1 Context\n3.1.1 Course Overview. This study was conducted during the Fall\n2023 semester of the \"Data-Oriented Programming\" course offered\nby the School of Information (SI) at the University of Michigan,\na large public institution in the Midwest United States. The SI In-\nformation Science major differs from the College of Engineeringâ€™s\nComputer Science (CS) major at the University of Michigan in\nseveral ways. The Information Science degree emphasizes the ap-\nplication and management of data and information in real-world\ncontexts, while the CS degree focuses more on the theoretical and\ntechnical side of computing and software development. Anecdo-\ntally, undergraduate SI students typically envision themselves as\nfuture UX designers, data scientists, or conversational programmers\n(students who â€œwant to communicate effectively about the inter-\nnals of software, but not write code themselvesâ€ [ 20]); whereas\nundergraduate CS students typically envision themselves as future\nsoftware developers. This course was specifically chosen due to its\nuse of Python, a common first language among CS1 courses [8], and\nits unique set of students across various academic disciplines. The\ncourse aims to develop intermediate Python programming knowl-\nedge (variables, loops, strings, functions, basics of object-oriented\nprogramming) and introduce students to various elements of data\nscience (input/output, regular expressions, databases, APIs, JSON,\nBeautifulSoup, Matplotlib). During the semester this course was\nconducted, it was taught by one instructor alongside five graduate\nteaching assistants (TAs) and nine undergraduate TAs. Every week-\nday, office hours of at least two hours were scheduled over Zoom\nand/or in-person, and each session was staffed by a minimum of\ntwo TAs.\nTo enroll in this course, students must have passed an introduc-\ntory programming course. As this course satisfies elective require-\nments across multiple programs, it attracts students from multiple\ndisciplines. While SI majors, for whom the course is a requirement,\ntypically constitute the majority of the class (~50%), there is often\nrepresentation from CS (~20%) and Business Administration majors\n(~20%). Notably, CS students typically use this course to develop\nPython programming expertise, as the CS course sequence is taught\nusing the C++ language.\nICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia Padiyath, et al.\nFigure 1: The technology appropriation conceptual model (diagram modified and annotated for clarity from [17]).\nIn this context, an important aspect to consider is that the Uni-\nversity of Michigan provided free access to several generative AI\nmodels throughout the duration of this study including GPT-4,\nLlama 2 (7b), GPT-3.5, and Open Journey for all students and in-\nstructors through a custom user interface hosted by the university.\n3.1.2 Course Homework and Midterms. Each homework assign-\nment (8 total) and project (2 total) asked students to fix bugs and/or\ncreate several functions from scratch (see [64] for an example home-\nwork project). Note that prior work has found homework instruc-\ntions in a similar style can be used to generate code from LLMs\nrather quickly [77].\nTwo midterm exams were taken through the courseâ€™s custom\ninteractive Runestone e-book [29] but proctored in-person, unless\na student had learning, illness, or other accommodations. Students\nwere not allowed to use any outside resources (such as the inter-\nnet and generative AI) while taking the exam other than a single\nsheet of 8.5 by 11 inch paper with notes (front and back). Midterms\nwere a mix of multiple-choice (including both single-select and\nmultiple-select) questions, fill-in-the-blank questions, Parsons prob-\nlems (mixed-up lines of code that students must place in order to\naccomplish a given task) [30], and write-code questions. Each ques-\ntion was auto-graded by percent correct, and totaled to 200 points.\nQuestions tested concepts covered in lectures and homework as-\nsignments.\n3.1.3 Generative AI Policy. Our universityâ€™s approach to address-\ning generative AI is decentralized, with each instructor implement-\ning their own policies. SI is committed to fostering a culture of\ncollaborative and agentic learning. In this course, we extended our\ndefinition of collaboration to include the use of generative AI since\nit can provide simple help at scale, students may use it in their\nfuture careers, and because it is freely available from the univer-\nsity. Given the limited understanding of the impact of LLMs on\nprogramming education, we encouraged critical engagement with\nthese tools by discussing their limitations and ethical implications\nin class. To address plagiarism concerns, we required students to\ncite if and how they used LLMs in their assignments. Students were\nauthorized to use these tools to explain or debug code, but were\nexplicitly dissuaded from using them to generate a complete an-\nswer. Additionally, we emphasized the responsibility of students to\nunderstand their code by forbidding the use of LLMs on midterm\nexams. The following quote is from the course syllabus:\nWorking with another person on homework is\nokay, but donâ€™t just copy someone elseâ€™s work.\nEach person must contribute an equal amount\nto the code when you work with other people.You\nmust list who you worked with on your homework in\nyour code. If we find that your code is identical to\nanother personâ€™s and you didnâ€™t list that person as\nsomeone you worked with then you will receive a\n0 on that work. You can also use generative AI like\nChatGPT, but must list that as a thing you worked with\nand what it helped you with. You must understand the\ncode that you submit. Remember that generative AI can\ncreate incorrect code and that you are responsible for\nthe correctness of the submitted code.\nNote that this is in stark contrast to the CS department policy\non collaboration (which includes generative AI). Syllabi for intro-\nductory programming courses in the CS department contain the\nfollowing:\nThe following are considered Honor Code violations:\nâ€¢Copying or deriving portions of your code from\nothersâ€™ solutions. This includes solutions from any\nsource, including AI-generated solutions .\nâ€¢Collaborating to write your code so that your solu-\ntions are identifiably similar.\n3.2 Survey\n3.2.1 Overview. During the final week of in-person classes for the\nFall 2023 semester, we conducted an anonymous survey exploring\nstudentsâ€™ attitudes, perceptions, and use of LLMs. This survey was\nlaunched after all instructional sessions but before final project\npresentations had been completed. It remained open to responses\nfor eleven days, after presentations concluded. Our goal for the\nsurvey was to ensure participation from a representative sample\nof students in the course. To achieve this, we posted an announce-\nment and assignment with a link to the survey on the online class\nmanagement system (CMS) used by all students. Students were also\nreminded to complete it during the final project presentation period.\nIn the call to participate, students were made aware of the surveyâ€™s\ngoal: â€œto explore the use (or non-use) of LLMs such as ChatGPT\nThe Appropriation of LLMs in an Undergraduate Programming Course ICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia\nin programming classes. \" To encourage participation from a range\nof students, students who completed the survey received 10 class\npoints and were entered into a raffle for a chance to win one of 25\n$20 gift cards.\n3.2.2 Survey Materials. An initial group of 30 questions were de-\nveloped. Questions were generated based on our research questions\nas well as derived from previous surveys on student and instructor\nperceptions regarding LLM use (such as [67]).\nSix think-aloud pilot surveys using a convenience sample of\nCS first-year undergraduates resulted in the refinement of these\nquestions for clarity and evidence for face validity. This process\nresulted in the final survey consisting of 25 questions, in addition to\nfive self-efficacy questions (adapted from [59], a scale with evidence\nfor validity and reliability) and 13 demographic questions 3. All\nquestions were mandatory. Beside self-efficacy and demographic\nquestions, the survey was divided into four sections.\nâ€¢The first section included questions regarding respondentsâ€™\nfamiliarity with LLM tools.\nâ€¢The second section included questions about how the respon-\ndent uses LLM tools and their perception of their classmates\nuse of LLM tools.\nâ€¢The third section included questions about why the respon-\ndent might use LLM tools.\nâ€¢The fourth section included questions about any concerns\nrespondents may have with LLM tools.\n3.2.3 Data Analysis. Factors were analyzed using regressions to\nexamine the relationships across and within the respondents. Us-\ning regression analysis [27] allows us to control for the influence\nof other factors in each regression. When possible, we attempt to\ncontrol for major and self-efficacy to address omitted variable bias.\nThis mitigates the confounding effect of these variables. Our re-\nsearch team validated each regression and its assumptions with our\nuniversityâ€™s statistics consultants - experts in regression analysis.\nOur analysis was completed using the software StataSE.\n3.3 Midterm Performance\nAfter the completion of the course, we created a dataset marking\neach of the studentsâ€™ (N=203) citations of LLM use in each home-\nwork assignment and project, their midterm scores, the answers\nto a 20-question 7-point Likert scale self-efficacy survey (adapted\nfrom Introductory Programming Self-Efficacy Scale (IPSES) [82], a\nscale with evidence for validity and reliability - with lower scores\nindicating low programming self-efficacy and higher scores indicat-\ning high programming self-efficacy) taken during the third week of\nthe course, and their declared majors.\n3.4 Student Interviews\n3.4.1 Overview. Following the survey, we wanted to explore the\ncontexts surrounding studentsâ€™ adoption and the effects of LLM use\nvia semi-structured interviews. These interviews aimed to further\nexplore studentsâ€™ attitudes and experiences regarding their use, or\nnon-use, of AI tools, such as ChatGPT, within the programming\nclassroom. In the first week of the following semester, three weeks\n3The full survey questions are provided here: https://tinyurl.com/LLMSurveyProtocol\nafter the survey closed, an announcement to recruit interview par-\nticipants was posted on the course CMS. Students were informed\nthat the objective of the interview was to â€˜understand their expe-\nriences and opinions about the use of ChatGPT in Data-Oriented\nProgramming. â€™ They were assured that all responses would be kept\nconfidential. As an incentive to participate, students were sent a\n$20 gift card upon completion of the 30-45 minute interview.\nThe interview questions were designed to gain a deeper under-\nstanding of trends highlighted in the survey analysis. Three pilot\ninterviews with a convenience sample of students helped refine\nquestions for clarity and provide evidence for face validity. Inter-\nviews were conducted online through Zoom videoconferencing.\nInterviewees were asked prior to the interview for permission to\nrecord, and recorded interviews were transcribed by Zoom in full\nand inspected by the first author for accuracy.\n3.4.2 Data Analysis. Our interview analysis was guided by a com-\nbination of content analysis [36] and structural coding [75]. The\ninitial content analysis determined prevalent sources of influence\nwhich contributed to our structural coding framework. Our code-\nbook of student influences is provided in Table 1. In applying this\ncodebook, the first and second authors coded the data indepen-\ndently [75]. Then, they jointly reviewed their respective coding\nto assess agreement, collaboratively discussing and resolving any\ndisagreements. Disagreements were rare, with the main issue being\nhow to label the impact of intervieweesâ€™ perceptions of their career\ngoals. They resolved this by changing the initial structural code\nfrom â€œinfluence from long-term goals\" to â€œinfluence from career\nperceptions\" for greater clarity. Then, they categorized participants\nbased on their respective majors and experience levels. Finally, they\njointly discussed within-group and between-group comparisons of\nstructural codes [75].\n3.5 Participants\n3.5.1 Survey Participants. With the participation of 158 out of a\ntotal sample of 203 students (a response rate of 78%), our sample\nwas relatively representative compared to the class demographics\nobtained from the Universityâ€™s database.\nWhen analyzing survey data results by self-efficacy, we found\nCronbachâ€™s ğ›¼ was internally reliable with ğ›¼ = .93. With five ques-\ntions total, each on a 5-point Likert scale, we averaged each re-\nspondentâ€™s self-efficacy ratings for the 5 questions to form each\nstudentâ€™s self-efficacy score (as done in previous research [30, 40]).\nTo investigate whether our dataset follows broader patterns of self-\nefficacy, we conducted a regression to predict self-efficacy with\nthe following predictors: major (CS, Information, or Other), gen-\nder4 (Men or Women), whether students are underrepresented\nminorities (URM: Hispanic/Latine, Black, Native American, Pacific\nIslander), and college-level programming experience (no experience,\n1-2 courses, or 3+ courses). We found correlations in our regression\n(ğ‘…2 = .18, F(6, 136) = 4.87, p < .001) that align with prior analyses of\nprogramming studentsâ€™ self-efficacy [61]: A significant predictor of\nhigher self-efficacy among our sample was having taken three or\n4No respondents identified as non-binary.\nICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia Padiyath, et al.\nStructural Code Interpretation Exemplar Quote\nInfluence from Career Perception\nPerception regarding their future ca-\nreer that influences how they per-\nceive/use LLMs.\n\"I do wanna become like a good software\ndeveloper. So I canâ€™t be too reliant on\nChatGPT, but like even like the best soft-\nware developers, Iâ€™m sure, are like putting\ntheir errors into ChatGPT. \"\nInfluence from Peer Perception Perception of peers that influence\nhow they perceive/use LLMs.\n\"Thereâ€™s not really a way for the college\nto find out that you like used it, so Iâ€™m\nsure people are still using it. \"\nInfluence from Self-Perception A self-perception that influences\nhow they perceive/use LLMs.\n\"I think Iâ€™m not over-reliant because I\nwrite the base or like my draft myself. \"\nTable 1: The structural codes pertaining to our research questions used for interview transcript analysis.\nmore college-level programming courses as compared to those with-\nout any college-level experience (ğ›½ = .83,ğ‘¡(6,136)= 2.00,ğ‘ = .047),\nregardless of major, gender, and URM-status.\n3.5.2 Midterm Performance Data. The non-anonymous self-efficacy\nsurvey was taken in the third week of the course and had a response\nrate of 78% (158/203). We found the data was internally reliable\nwith Cronbachâ€™s ğ›¼ = .96. With 20 questions total, each on a 7-point\nLikert scale, we averaged each respondentâ€™s self-efficacy ratings\nover the questions to form each studentâ€™s self-efficacy score. This\nwas then matched with their midterm scores and LLM use cita-\ntions to create the midterm performance dataset. LLM Citations\nthroughout the course are visualized in Figure 2.\n3.5.3 Interview Participants. Ten students expressed an interest\nin participating in the interview study. Their background details\nare presented in Table 2. Experience (high or low) was determined\nfrom the number of programming classes the student had previ-\nously taken (having taken two or more programming classes was\ncategorized as â€˜highâ€™ experience).\n4 RESULTS\nThe exploration of our results was driven by our research ques-\ntions. We present our findings in related sections for clarity. When\npresenting quotes, ellipses are used for removed text, and square\nbrackets are used for inserting relevant context.\n4.1 Social Perceptions and LLM Adoption\nThrough the process of content analysis, we uncovered two social\nperceptions affecting studentsâ€™ appropriation of LLMs in our con-\ntext: perceptions of their future careers , and perceptions of their peersâ€™\nusage.\n4.1.1 Career Perceptions and LLM Usage. Survey data relating to\ncareer perceptions and to preferences towards LLMs in learning\nwas analyzed using a regression, shown in Table 3. The results\nrevealed that students who believed over-reliance on LLM tools\nwould hurt their job prospects in programming careers also tended\nto prefer learning programming skills themselves, rather than a\npreference towards learning programming through the use of LLM\ntools, regardless of major and self-efficacy.\nTo gain a more detailed understanding of how career perceptions\nmay influence LLM usage, we asked interviewees when and why\nthey decided to use LLMs in Data-Oriented Programming. Among\nthe explanations interviewees gave, many discussed their future\ncareer expectations influencing their approach to using LLMs. For\nexample, those targeting software development roles believed LLM\nskills to be essential, anticipating widespread industry use.\nI think [LLMs are] gonna be used in the field, and if\nsomeone wants to go in that field, they should know\nhow to use it like appropriately. - P7, CS Major, High\nExperience\nThis perspective may have motivated these students to engage\nwith LLMs as a way to prepare for their anticipated professional\nneeds.\nHowever, those who did not view programming as central to\ntheir future work tended toward using LLMs to minimize their\nengagement with programming concepts they perceived as less\nrelevant to their professional goals. Additionally, these intervie-\nwees predict that LLMs will be a mainstay in the future workplace,\ndriving some to use them in class.\nI just kinda wanted to like, get through this class ... I\ndonâ€™t really care that much about coding concepts, you\nknow. Like to me, itâ€™s just a class. So I guess that might\nhave impacted the way I approach this class as well ...\nI feel like the stakes for me are not that high as like, a\nsoftware engineer? You know, like cause I just donâ€™t see\nmyself using these concepts that much in the future. -\nP4, Information Major, Low Experience\nWhen youâ€™re at a job at like a company, theyâ€™re not\ngonna be like, â€˜donâ€™t use ChatGPT. â€™ So like, if itâ€™s ac-\ncessible in the real world, why not in the class? - P1,\nBusiness + Information Majors, Low Experience\nThis may suggest that these students may have used LLMs as\na tool to bypass learning material they believe is not valuable for\ntheir future careers, providing more nuance to the survey finding\nthat career perceptions influence studentsâ€™ approach to learning\nprogramming.\nInterestingly, even among students targeting software devel-\nopment careers, some reported using LLMs selectively based on\ntheir perceptions of the relevance of specific topics to their future\nThe Appropriation of LLMs in an Undergraduate Programming Course ICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia\nFigure 2: Ratio of students citing LLM usage per each homework assignment/project.\nParticipant ID Major Experience Pronouns\nP1 Business + Information Low he/him\nP2 Business + Psychology Low he/him\nP3 Business + Information Low she/her\nP4 Information Low she/her\nP5 Information Low she/her\nP6 Information High she/her\nP7 CS High she/her\nP8 CS High he/him\nP9 CS High he/him\nP10 CS High he/him\nTable 2: Backgrounds of Interviewees.\n\"I would rather learn how to use an LLM AI tool like Chat-\nGPT to generate code than learn programming skills my-\nself. \"\nCoefficient Std. err. t P>|t| Std. ğ›½\n\"Over-relying on LLM AI tools like ChatGPT could nega-\ntively impact my ability to get a programming job. \"\n-.168 .0846 -1.99 .049 -.156\nMajor (Ref. gp.: Information)\nComputer Science -.320 .241 -1.33 .186 -.110\nOther -.452 .231 -1.96 .052 -.157\nSelf Efficacy (End of Course) -.228 .114 -1.99 .048 -.162\nConstant 4.038 .504 8.00 <.001\nN = 158\nF(4, 153) = 4.01\nProb > F = 0.0040\nğ‘…2 = 0.09\nTable 3: To investigate the relationship between perceptions of LLMsâ€™ career impacts and attitudes towards LLMs in programming,\nwe conducted the following regression equation: ğ¿ğ¿ğ‘€ğ‘œğ‘Ÿğ‘ƒğ‘Ÿğ‘œğ‘”ğ‘Ÿğ‘ğ‘šğ‘šğ‘–ğ‘›ğ‘” ğ‘  = ğ›½0 +ğ›½1ğ‘‚ğ‘…ğ¶ğ‘ğ‘Ÿğ‘’ğ‘’ğ‘Ÿğ‘  +ğ›½2ğ‘ğ‘ ğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğ›½3ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğ›½3ğ‘†ğ¸ğ‘  +ğœ–ğ‘  .\nğ¿ğ¿ğ‘€ğ‘œğ‘Ÿğ‘ƒğ‘Ÿğ‘œğ‘”ğ‘Ÿğ‘ğ‘šğ‘šğ‘–ğ‘›ğ‘” ğ‘  represents a continuous variable on a 5-point Likert scale regarding studentsâ€™ agreement with the statement,\n\"I would rather learn how to use an LLM AI tool like ChatGPT to generate code than learn programming skills myself.\" ğ‘‚ğ‘…ğ¶ğ‘ğ‘Ÿğ‘’ğ‘’ğ‘Ÿğ‘ \nrepresents a continuous variable on a 5-point Likert scale regarding studentsâ€™ agreement with the statement, \"Over-relying on\nLLM AI tools like ChatGPT could negatively impact my ability to get a programming job.\" ğ‘ğ‘ ğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  and ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  represent\ndummy variables of studentsâ€™ majors (reference group: information major). Finally, ğ‘†ğ¸ğ‘  represents a continuous variable of\nstudentsâ€™ self-efficacy score at the end of the course. ğœ–ğ‘  is an error term.\nICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia Padiyath, et al.\nwork. This may explain the increased reported usage of LLMs for\nhomework #5, the RegEx-focused homework.\n[In deciding when to use ChatGPT,] I understood what I\nwas going to do, and how I was going to do it. It was like\nthings that I was probably familiar with already. Or\nmaybe it was something I didnâ€™t think I needed to know\nfor the future, like [Regular Expressions]. I felt like that\nwasnâ€™t a useful package or anything that I would use\nin the field. So those things I just threw to ChatGPT ... -\nP9, CS Major, High Experience\nThis demonstrates that students may use LLMs to bypass learn-\ning material they do not think is relevant to their future careers,\neven if they plan to be a software developer.\n4.1.2 Influence from Perceptions of Peer Use. When students in\nthe survey rated their own usage of LLMs in course assignments,\nalongside how often they believed their peers used LLMs, students\nperceived their peersâ€™ LLM usage as significantly higher than was\nactually reported (ğœ’2(9, N = 148) = 36.44, p < .0001). In a five-point\nLikert scale, with low scores suggesting rare usage and high scores\nsuggesting frequent usage, students, on average, rated their own\nusage as 3.5/5 compared to their perception of their peers usage,\non average, as 4.3/5.\nTo understand why students might overestimate their peersâ€™ LLM\nuse, in interviews we asked whether their use of LLMs may differ\nfrom their peersâ€™ use, and why. We found that most participants\nbelieved there was widespread unauthorized LLM use in their other\nprogramming courses due to a lack of enforcement. Even though\nmany of the interviewees themselves maintained skepticism about\nusing LLMs against course policy.\nThe [CS] classes have, like a huge honor code. Youâ€™re\nnot allowed to like, put in [copied] code or like use code\nor anything. So I was just using it to debug my errors ...\nThereâ€™s not really a way for the college to find out that\nyou used [LLMs], so I am sure that people are still using\nit. - P7, CS Major, High Experience\nI think that itâ€™s cheating, like, if itâ€™s not allowed ... If\nyou make [using LLMs] against the rules, people are\ngonna use it anyway. - P6, Information Major, High\nExperience\nInterestingly, in our context where LLM use was permitted, the\nnormalization of these tools changed some studentsâ€™ attitudes and\nbehaviors, even when initially skeptical. As LLM use became more\nvisible within their peer group, students felt more comfortable\nadopting the tools.\nIn the beginning I was pretty apprehensive towards\nusing ChatGPT ... I was scared Iâ€™d get reliant, but then,\npeople in my class would be like, â€˜Oh, like I use ChatGPT\nfor thisâ€™, like, â€˜Oh, it was really helpful with this!â€™ and\nso that kind of made me like open up to using ChatGPT\nmore, just because, like I saw how normalized it was\nin class and a lot of times the people I was talking to\nseemed to have a very good understanding of Python as\nwell, so that kind of took away that initial sense of fear\nthat I had. - P3, Business + Information Major, Low\nExperience\nIn the beginning, I was just really scared to use it, be-\ncause, like, even if they say â€˜Yes, [use LLMs]â€™ I will use\nit too much, and Iâ€™m gonna get caught ... but then some-\none at my table was like, â€˜Itâ€™s fine, Iâ€™m just gonna use\nit. â€™ So Iâ€™m kind of like, â€˜Oh, yeah, I can use it too. â€™ - P5,\nInformation Major, Low Experience\nThis suggests that the normalization of LLM use by peers can\ninfluence studentsâ€™ decisions to adopt these tools, even if they\ninitially have concerns about negative impacts on their learning.\nMore experienced students, who had taken their initial program-\nming classes without LLMs, expressed concerns that the widespread\nuse of these tools might be undermining their peersâ€™ understanding\nof programming fundamentals.\nThatâ€™s the biggest like issue ... is maybe they donâ€™t really\nunderstand ... how everything works before they just\ncopy and paste. - P10, CS Major, High Experience\nThese concerns suggest the potential risks associated with the\ninfluence of perceptions of peer use on LLM adoption, especially\nfor novice programmers who may not have the same foundational\nskills as their more experienced peers.\n4.2 LLM Usage and Self-Efficacy\nSelf-efficacy emerged as a factor in evaluating the differing effects\nof LLM usage on students. We examined the relationship between\nearly LLM usage and self-efficacy, accounting for the studentsâ€™\nmajors. The analysis included only declared LLM usage in the first\ntwo homework assignments, due to the self-efficacy survey being\ndeployed in the third week. Our regression, as shown in Table 4,\nindicated a significant negative association between LLM citations\non homework and third-week self-efficacy scores regardless of\nmajor: ğ›½= -.18, t(3, 154) = -2.65, p = .009. In conducting a regression\nusing the self-efficacy survey from the end of the course, as shown\nin Table 5, a binary notion of over-reliance (â€˜Yes, I have felt over-\nreliantâ€™ or â€˜No, I have never felt over-reliantâ€™) was significantly\nnegatively associated with self-efficacy (ğ›½ = -.23, t(4, 154) = -2.79, p\n= .006), regardless of their major and their LLM usage. However,\nself-reported LLM usage was not significantly correlated with self-\nefficacy regardless of major, as shown in Table 6. This suggests no\nsignificant relationship, or a more complex relationship between\nself-efficacy and LLM usage at the end of the course.\nOur regressions cannot determine the causality between LLM\nuse and self-efficacy. However, in interviews, when asked about\nthe potential downsides of using LLMs for learning, many students\nwith less programming experience reported a decreased sense of\nself-confidence when they felt over-reliant on LLMs.\nSometimes I just, like, copy-paste it and just work on it\n... I guess, that impacted the way I understand coding ...\nI would say that if you, if you give me like a coding as-\nsessment right now without access to ChatGPT, I would\nfreak out ... [Using ChatGPT negatively affected] my\nconfidence in my own coding abilities, also understand-\ning how to approach coding problems. - P4, Information\nMajor, Low Experience\nThe Appropriation of LLMs in an Undergraduate Programming Course ICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia\nSelf Efficacy (third week) Coefficient Std. err. t P>|t| Std. ğ›½\nLLM Use on Homework Prior to the Third Week -.493 .186 -2.65 .009 -.180\nMajor (Ref. gp.: Computer Science)\nInformation -1.405 .207 -6.79 <.001 -.612\nOther -1.494 .228 -6.56 <.001 -.591\nConstant 6.25 .178 35.08 <.001\nN = 158\nF(3, 154) = 21.41\nProb > F < 0.0001\nğ‘…2 = 0.29\nTable 4: To investigate the relationship between LLM Use and self-efficacy, we conducted the following regression equation:\nğ‘†ğ¸ğ‘  = ğ›½0 +ğ›½1ğ¿ğ¿ğ‘€ğ‘ˆğ‘ ğ‘’ğ‘ƒğ‘Ÿğ‘–ğ‘œğ‘Ÿğ‘‡â„ğ‘–ğ‘Ÿğ‘‘ğ‘Šğ‘’ğ‘’ğ‘˜ ğ‘  +ğ›½2ğ‘–ğ‘›ğ‘“ğ‘œğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğ›½3ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğœ–ğ‘  . ğ‘†ğ¸ğ‘  represents a continuous variable of studentsâ€™\nself-efficacy score at the third week of the course. ğ¿ğ¿ğ‘€ğ‘ˆğ‘ ğ‘’ğ‘ƒğ‘Ÿğ‘–ğ‘œğ‘Ÿğ‘‡â„ğ‘–ğ‘Ÿğ‘‘ğ‘Šğ‘’ğ‘’ğ‘˜ ğ‘  is a dummy variable representing if students cited\nusing LLMs on their homework prior to the third week of class. ğ‘–ğ‘›ğ‘“ğ‘œğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  and ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  represent dummy variables of\nstudentsâ€™ majors (reference group: CS major). ğœ–ğ‘  is an error term.\nSelf Efficacy (End of Course) Coefficient Std. err. t P>|t| Std. ğ›½\nOverreliant? -.403 .144 -2.79 .006 -.233\nReported LLM Usage .133 .065 2.04 .043 .163\nMajor (Ref. gp.: Information)\nComputer Science .444 .172 2.58 .011 .213\nOther -.133 .164 -.81 .417 -.065\nConstant 3.49 .240 14.52 <.001\nN = 153\nF(4, 148) = 6.47\nProb > F = 0.0001\nğ‘…2 = 0.15\nTable 5: To investigate the relationship between studentsâ€™ self-efficacy and their self-perception of over-reliance, we conducted\nthe following regression equation: ğ‘†ğ¸ğ‘  = ğ›½0 +ğ›½1ğ‘‚ğ‘…ğ‘  +ğ›½2ğ¿ğ¿ğ‘€ğ‘ˆğ‘ ğ‘ğ‘”ğ‘’ğ‘  +ğ›½3ğ‘ğ‘ ğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğ›½4ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğœ–ğ‘  . ğ‘†ğ¸ğ‘  represents a continuous\nvariable of studentsâ€™ self-efficacy score at the end of the course. ğ‘‚ğ‘…ğ‘  is a dummy variable representing studentsâ€™ self-perception\nof their over-reliance on LLMs. ğ¿ğ¿ğ‘€ğ‘ˆğ‘ ğ‘ğ‘”ğ‘’ğ‘  is a continuous variable representing the number of homework studentsâ€™ reported\nusing LLM assistance. ğ‘ğ‘ ğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  and ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  represent dummy variables of studentsâ€™ majors (reference group: information\nmajor). ğœ–ğ‘  is an error term.\n4.3 LLM Usage and Learning Outcomes\n4.3.1 Student Perceptions of LLMs Affecting Learning. Through a\nregression analysis as shown in Table 7, we found that there was a\nsignificantly negative correlation between studentsâ€™ concern about\nover-relying on LLMs negatively affecting their programming skills\nand their self-reported usage of LLMs in class, regardless of major\nand self-efficacy (ğ›½ = -.18, t(4, 153) = -2.26, ğ‘ = .03). This suggests\nstudents who were more concerned about the effect of LLMs on\ntheir programming skills reported using LLMs less in class.\nTo understand how students self-reported usage of LLMs corre-\nlate with their feelings of over-reliance, we conducted several logis-\ntic regressions to predict a binary notion of student over-reliance\nbased on studentsâ€™ self-reported usage of LLMs, regardless of self-\nefficacy and major. Due to the multiple comparisons problem of\nconducting repeated regressions, we employ the Bonferroni correc-\ntion [87] to adjust our ğ‘-value threshold to ğ›¼ = .05 / 10 = .005. In\nTable 8, we present the odds ratio and statistics behind each sta-\ntistically significant regression. Four behaviors were significantly\nassociated with self-reported over-reliance: generating solutions\n(e.g. suggesting entire solutions for a coding problem), generating\nusable code (e.g. suggesting fixes in code for bugs), avoiding asking\nfor help (e.g. asking an LLM instead of asking peers or instructors),\nand improving programming skills (e.g. using LLMs for generating\nmore efficient code). Six attributes were not significant, suggesting\nICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia Padiyath, et al.\nSelf Efficacy (End of Course) Coefficient Std. err. t P>|t| Std. ğ›½\nReported LLM Usage .035 .060 .59 .556 .046\nMajor (Ref. gp.: Information)\nComputer Science .600 .164 3.66 <.001 .289\nOther -.101 .163 -.62 .535 -.049\nConstant 3.70 .229 16.13 <.001\nN = 158\nF(3, 154) = 5.52\nProb > F = 0.0013\nğ‘…2 = 0.10\nTable 6: To investigate the relationship between self-efficacy at the end of the course and students reported LLM usage, we\nconducted the following regression equation: ğ‘†ğ¸ğ‘  = ğ›½0 +ğ›½1ğ¿ğ¿ğ‘€ğ‘ˆğ‘ ğ‘ğ‘”ğ‘’ğ‘  +ğ›½2ğ‘ğ‘ ğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğ›½3ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğœ–ğ‘  . ğ‘†ğ¸ğ‘  represents a continuous\nvariable of studentsâ€™ self-efficacy score at the end of the course. ğ¿ğ¿ğ‘€ğ‘ˆğ‘ ğ‘ğ‘”ğ‘’ğ‘  is a continuous variable representing the number of\nhomework studentsâ€™ reported using LLM assistance. ğ‘ğ‘ ğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  and ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  represent dummy variables of studentsâ€™ majors\n(reference group: information major). ğœ–ğ‘  is an error term.\n\"Over-relying on ChatGPT could negatively impact my abil-\nity to learn programming concepts and skills. \"\nCoefficient Std. err. t P>|t| Std. ğ›½\nReported LLM Usage -.363 .161 -2.26 0.025 -.177\nMajor (Ref. gp.: Information)\nComputer Science .151 .213 .71 .481 .059\nOther .299 .204 1.47 .144 .119\nSelf Efficacy (End of Course) .203 .100 2.03 .045 .165\nConstant 3.12 .412 7.59 <.001\nN = 158\nF(4, 153) = 3.39\nProb > F = 0.011\nğ‘…2 = 0.08\nTable 7: To investigate the relationship between perceptions of LLMsâ€™ impacts on studentsâ€™ learning and reported usage of\nLLMs, we conducted the following regression equation: ğ‘‚ğ‘…ğ¿ğ‘’ğ‘ğ‘Ÿğ‘›ğ‘–ğ‘›ğ‘”ğ‘  = ğ›½0 +ğ›½1ğ¿ğ¿ğ‘€ğ‘ˆğ‘ ğ‘ğ‘”ğ‘’ğ‘  +ğ›½2ğ‘ğ‘ ğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğ›½3ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğ›½3ğ‘†ğ¸ğ‘  +ğœ–ğ‘  .\nğ‘‚ğ‘…ğ¿ğ‘’ğ‘ğ‘Ÿğ‘›ğ‘–ğ‘›ğ‘”ğ‘  represents a continuous variable on a 5-point Likert scale regarding studentsâ€™ agreement with the statement,\n\"Over-relying on ChatGPT could negatively impact my ability to learn programming concepts and skills.\" ğ¿ğ¿ğ‘€ğ‘ˆğ‘ ğ‘ğ‘”ğ‘’ğ‘  is a\ncontinuous variable representing the number of homework studentsâ€™ reported using LLM assistance. ğ‘ğ‘ ğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  and ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘ \nrepresent dummy variables of studentsâ€™ majors (reference group: information major). ğ‘†ğ¸ğ‘  represents a continuous variable of\nstudentsâ€™ self-efficacy score at the end of the course. ğœ–ğ‘  is an error term.\nno, a weak, or a more complex relationship: debugging, explaining\nprogramming concepts, ideating, resource finding, and reducing\nstress.\nIn interviews we asked students for the advantages and disadvan-\ntages of using LLMs. The interviewees readily identified their pros\nand cons based on personal experiences. Some students described\nusing LLMs as a tool for explaining code, helping them understand\nconcepts and error messages. This aligns with the survey finding\nof explaining programming concepts not being significantly associ-\nated with over-reliance.\nItâ€™s a teaching tool, right? Or I used it that way. So it\nsort of taught me how to do it, and walked through the\nsteps for me. It was sort of like seeing a worked problem\nin a math textbook. So I was able to get a better grip on\nwhat RegEx (regular expression) was. - P6, Information\nMajor, High Experience\nMost interviewees expressed a concern that relying on LLMs\nfor generating code, as well as using LLMs to avoid needing office\nhours, negatively affected their learning experience which also\naligned with the survey correlations.\nThe Appropriation of LLMs in an Undergraduate Programming Course ICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia\nReasons for Using LLMs LR ğœ’2(4, N=153) Psuedo- ğ‘…2 Odds Ratio ğ‘-value 95% Confidence Interval\nTo Generate Solutions 31.35 .16 2.2 .005 [.98 4.99]\nTo Generate Usable Code 32.75 .17 3.47 .002 [1.55 7.75]\nTo Avoid Asking for Help 33.55 .17 3.7 .002 [1.62 8.44]\nTo Improve Programming Skills 37.94 .19 4.73 < .001 [2.03 11.02]\nTable 8: To investigate the relationship between studentsâ€™ self-reported over-reliance and motivations for LLM usage, we\nconducted the following logistic regression equation: ğ‘‚ğ‘…ğ¿ğ‘–ğ‘˜ğ‘’ğ‘™ğ‘–â„ğ‘œğ‘œğ‘‘ğ‘  = ğ›½0 +ğ›½1ğ‘šğ‘œğ‘¡ğ‘–ğ‘£ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘  +ğ›½2ğ‘ğ‘ ğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğ›½3ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğ›½3ğ‘†ğ¸ğ‘  +ğœ–ğ‘  .\nğ‘‚ğ‘…ğ¿ğ‘–ğ‘˜ğ‘’ğ‘™ğ‘–â„ğ‘œğ‘œğ‘‘ğ‘  represents the log likelihood of a studentsâ€™ self-perception of over-reliance. ğ‘šğ‘œğ‘¡ğ‘–ğ‘£ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘  is a dummy variable\nrepresenting studentsâ€™ different motivations for using LLMs. ğ‘ğ‘ ğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  and ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  represent dummy variables of studentsâ€™\nmajors (reference group: information major). ğ‘†ğ¸ğ‘  represents a continuous variable of studentsâ€™ self-efficacy score at the end of\nthe course. ğœ–ğ‘  is an error term.\nTo an extent, I think I learned a little less [from using\nLLMs to generate code.] Not in the beginning, because I\nknew, like all the concepts in general ... I think I was a\nlittle too reliant on SQL stuff ... it doesnâ€™t feel as intuitive\nas I feel it should. - P7, CS Major, High Experience\nPersonally, I feel like I didnâ€™t learn that well in my\nclasses, because I didnâ€™t like actively think about the\nproblems for my for my own ... I tend to like just follow\nthe steps that they that [ChatGPT] give me. So in a way,\nI was put in like a passive role. - P4, Information Major,\nLow Experience\nI think like the beginning, I used it a lot more ... But then,\nlater, I kind of figured out something is just wrong. So I\njust I kind of use office hours more. - P5, Information\nMajor, Low Experience\nStudents had positive perceptions of their experiences with LLMs\nwhen using them to explain concepts or error messages, however,\nwhen using it for learning new concepts and generating code, many\nstudents noted these as perhaps being less \"intuitive\" as they expect\nit should be. Students who had strong foundations in programming\nfrom previous classes without LLMs were self-aware of this nar-\nrative, as they reported that their foundations were helpful when\nthey later used LLMs for their work.\nSince I had established my foundations in program-\nming, [Copilot] was extremely helpful ... but Iâ€™m seeing\nmy friends and my peers, and itâ€™s an absolute strug-\ngle. Because think of it as learning math, right? If you\ndonâ€™t know how to multiply and divide, and you have\na program that does that for you way before you learn\nhow to do algebra, youâ€™re not gonna be good at algebra.\nThe same way with computer science. If you start using\nthat in your beginner classes, if your foundations are\na generative AI program, you are not gonna be able to\nmake it as a software engineer. Youâ€™re not even gonna be\nable to make it to like the harder classes in your major.\n- P8, CS Major, High Experience\n4.3.2 LLM Use and Midterm Performance. We investigated how\nLLM use, alongside self-efficacy from the third week of the course\nand academic major (reference group: CS Major), correlated with\nstudentsâ€™ midterm exam performance. The LLM use factor for re-\ngressions regarding the first midterm was based on students citing\nLLM use for homework assignments #1-4 â€“ the assignments sub-\nmitted prior to Midterm #1. The LLM use factor for the second\nmidterm was was based on students citing LLM use for homework\nassignments #1-5 and Project #1 â€“ the assignments/project sub-\nmitted prior to Midterm #2. The results are summarized in Table\n9. Results indicate a small negative association of LLM use with\nMidterm #1 scores and a significant positive association with self-\nefficacy measured in the third week for both midterms. Meaning,\nif students used LLMs prior to Midterm #1, they correlated with\nscoring slightly less on Midterm #1, regardless of self-efficacy and\nmajor.\nIn investigating the influence of studentsâ€™ first midterm per-\nformance on studentsâ€™ decision to use LLMs prior to the second\nmidterm, we conducted a paired t-test focused on students who per-\nformed poorly (scoring below average, N=77) on the first midterm.\nThe results of the paired t-test were significant, as students who\nperformed poorly on midterm #1 and used LLMs prior to that exam\nwere significantly less likely to reporting using LLMs prior to the\nsecond midterm (t(76) = 2.137, p = .036).\nThis correlation was also found in discussions with interviewees\non the possible influence and impact of LLM use on their midterm\nperformance. Several novice programmer interviewees reported re-\nsorting to cramming after under-performing on practice midterms,\nleading them to recognize their over-reliance on LLMs and start\npracticing programming more on their own.\nI was studying using ChatGPT, I was doing the practice\nexam and then putting in the ones I got wrong into\nChatGPT and being like, â€˜Why did I get this wrong?â€™ etc.\nBut then I realized, like, Iâ€™ve been using this platform\ntoo much to the point where, like, I donâ€™t know a lot\nof the answers ... I was like. Okay, I need to like, you\nknow, learn on my own a little more. - P2, Business +\nPsychology Major, Low Experience\n5 DISCUSSION\nOur findings suggest that studentsâ€™ decisions to appropriate LLMs\nare not solely driven by LLMsâ€™ affordances and capabilities, but\nare also significantly associated with social factors such as percep-\ntions of peer use, and of the use of LLMs in their future careers.\nFurther, our findings suggest that LLM use might influence usersâ€™\nperceptions of self-efficacy and their learning outcomes.\nICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia Padiyath, et al.\nMidterm 1 Performance Midterm 2 Performance\nStd. ğ›½ t(4, 153) ğ‘-value Std. ğ›½ t(4, 153) ğ‘-value\nLLM Use on Homework\nPrior to the Midterms -.13 -2.01 .046 -.032 -.43 .67\nThird Week Self-efficacy .37 4.51 < .001 .23 2.71 .007\nInformation Major -.30 -2.96 .004 -.30 -2.69 .008\nOther Major -.15 -1.51 .134 -.18 -1.60 .112\nN 158 158\nğ‘…2 .31 .16\np-value < .0001 < .0001\nTable 9: To investigate the relationship between studentsâ€™ midterm performances and reported LLM usage, we conducted\nthe following regression equation: ğ‘€ğ‘–ğ‘‘ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘  = ğ›½0 +ğ›½1ğ¿ğ¿ğ‘€ğ‘ˆğ‘ ğ‘ğ‘”ğ‘’ğ‘  +ğ›½2ğ‘–ğ‘›ğ‘“ğ‘œğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğ›½3ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  +ğ›½3ğ‘†ğ¸ğ‘  +ğœ–ğ‘  . ğ‘€ğ‘–ğ‘‘ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘  is a\ncontinuous variable representing studentsâ€™ midterm scores. ğ¿ğ¿ğ‘€ğ‘ˆğ‘ ğ‘ğ‘”ğ‘’ğ‘  represents whether students used LLM assistance prior\nto each midterm. ğ‘–ğ‘›ğ‘“ğ‘œğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  and ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘€ğ‘ğ‘—ğ‘œğ‘Ÿ ğ‘  represent dummy variables of studentsâ€™ majors (reference group: CS major). ğ‘†ğ¸ğ‘ \nrepresents a continuous variable of studentsâ€™ self-efficacy score at the third week of the course. ğœ–ğ‘  is an error term.\nOur results encourage us to move beyond a deterministic view\nof LLMs. We see LLMs as tools whose appropriation is shaped by\nthe social contexts in which they are used. We interpret our key\nfindings in relation to each research question and previous research,\nas informed by social shaping of technology theory [ 89] and the\ntechnology appropriation model [17]. A summary of our findings is\ndisplayed in Figure 3. Carroll et al. suggest attractors and repellents\nare symmetrical: each attractor is paired with an opposite repellent\n[17]. Thus, we display suggested symmetrical factors, however our\ndata provide no clear examples of factors shown in italicized font.\n5.1 RQ1: How do social perceptions influence\nthe usage of Large Language Models in an\nundergraduate intermediate-level\nprogramming course?\nOur findings suggest student engagement with LLMs is signifi-\ncantly associated with both their perceptions of their career goals,\nas well as their perception of peersâ€™ usage. Students who were con-\ncerned that over-reliance on LLMs could affect their programming\ncareers told us on the survey that they preferred writing code inde-\npendently, rather than through LLMs. Their concern aligns with\nthe concept of â€œrepellentsâ€ in the technology appropriation model,\nwhich suggests negative perceptions of a technology can discour-\nage users from adopting it. During interviews, almost all students\nbelieved LLMs will play a large role in their future careers, or sug-\ngested using them to bypass material they anticipate as not having\nprofessional value. This selective use of LLMs based on perceived\ncareer attributes can be understood through the technology ap-\npropriation modelâ€™s â€œappropriation criteria, â€ which suggests users\nassess a technology based on their specific needs and goals when\ndeciding whether and how to adopt it [16]. Additionally, the ten-\nsion experienced by students - who are both wary of over-reliance\npotentially hindering their ability to obtain a programming job,\nyet anticipate the need for LLMs in their future careers - may be\ninterpreted as a â€œhigher-order reinforcerâ€ [16, 17] â€“ meaning, the\ncontinued use of LLMs is reinforced by students identifying with\nprogramming careers, helping them balance their appropriation\nand disappropriation of LLMs.\nOur findings add nuance to Prather et al. [67]â€™s survey and in-\nterview findings which suggest students anticipate LLMs playing a\nlarge role in their future career. Our study, through the lens of the\ntechnology appropriation model, shows that students experience\na tension between their career expectations and their perceived\nnecessity of learning to program. This continuously reinforces\ntheir decision to either appropriate or disappropriate the tool. This\ncareer-based reinforcement may be partly attributed to the broader\ntrend among students to view higher education as a path towards\nlucrative careers rather than an education towards a greater under-\nstanding of the world [11].\nIn using LLMs, interviews suggested students exercised agency\nin determining what they considered essential for learning. Al-\nthough, as students often do not have authentic industry experi-\nence, they can hold misconceptions about their future professional\nroles and the nature of software engineering [83]. For example, in-\nterviewees imagined LLMs as a tool freely available to them at their\nfuture workplace. However, our participants might be surprised to\nlearn that several companies have imposed bans or restrictions on\nLLM use (including Apple, Verizon, Amazon, Spotify, Samsung, and\nDeutsche Bank) [25, 28]. Further, the contested legality of LLMsâ€™\ndata collection practices may force companies to destroy LLM prod-\nucts due to copyright infringement [ 37]. Alternatively, students\nmay underestimate the role of programming in their future careers,\nleading them to use LLMs as a shortcut to avoid deeper engage-\nment with programming concepts. As programming becomes an\nincreasingly fundamental skill across career fields [34, 35], a solid\ngrasp of programming concepts â€“ even if not at an expert level â€“\nmay be beneficial for studentsâ€™ professional development [84].\nOur findings highlight the role of peer perceptions in shaping\nstudentsâ€™ appropriation of LLMs. Survey data showed students may\nhave overestimated their peersâ€™ use of LLMs, suggesting a potential\nmismatch between studentsâ€™ actual usage and their perception of\nhow widely LLMs are used among their classmates. Through the\nlens of the technology appropriation model, studentsâ€™ perceptions\nThe Appropriation of LLMs in an Undergraduate Programming Course ICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia\nFigure 3: Factors of the Technology Appropriation Model (adapted from [17]).\nof their peersâ€™ LLM usage can be seen as an â€œattractor, â€ encouraging\nthem to engage with these tools to conform to perceived social\nnorms [17]. However, the mismatch may create a sense of social\npressure to conform to what is seen as a norm, or otherwise risk a\nreduced sense of belonging [49]. Interview findings support this in-\nterpretation, with several participants reporting increased comfort\nwith adopting LLMs after observing their classmates using them,\neven if they initially had concerns about potential negative impacts\non their learning.\nInterviewees tended to perceive widespread misuse of LLMs due\nto a lack of enforceability, even though participants were personally\nhesitant to use LLMs in violation of class policies. Around the same\ntime we solicited answers for the survey, our university newspaper\nconducted a similar survey among CS students and found similar\nresults: Most (75%) of the CS respondents (N=690) reported avoiding\nusing LLM tools on their homework assignments when it was not\nauthorized [80]. The difference in student LLM usage between these\ncontexts suggests that social acceptance may serve as a higher-order\nreinforcer for the continued appropriation of LLMs [16]. As students\nobserve their peers using LLMs, they may prioritize fitting in with\ntheir classmatesâ€™ behavior over their concerns about the potential\nimpact of these tools on their learning. This peer influence may\nbe particularly problematic in a class with such a diverse range of\nprior programming experience. When less experienced students\nsee their more knowledgeable peers frequently using LLMs, they\nmay assume that adopting these tools will not negatively affect\ntheir own learning, even if they lack the same foundational skills\nas their classmates.\nThis might demonstrate a limitation of the technology adoption\nframework, Diffusion of Innovations theory [73]. As a component of\nthe framework, observability - the extent to which the innovationâ€™s\nbenefits are visible to others - does not quite capture this finding. In\nour study, interviewees attributed adopting LLMs due to their peersâ€™\nuse, rather than adopting due to the benefits, even after considering\nthe possible harmful impact on their learning.\n5.2 RQ2: How does LLM usage relate to\nprogramming self-efficacy and midterm\nscores among undergraduate students in an\nintermediate-level programming course?\nSocial shaping theory posits that technology is not a neutral tool\nfor completing tasks but it can also significantly influence user\nbehavior and beliefs [89]. Our findings provide evidence for this,\nas interviewees experienced mixed impact on their programming\nself-efficacy and self-perception of their learning outcomes when\nusing LLMs. Data from our surveys, interviews, and analysis of\nmidterm performance indicate that reported use of LLMs on course\nassignments prior to midterm #1 correlated with decreased self-\nefficacy and midterm scores. While later use correlated decreased\nself-efficacy with perceived over-reliance.\nOne of our more interesting findings is the correlation between\nearly LLM use and decreased self-efficacy, as well as the link be-\ntween perceived over-reliance on LLMs and lower self-efficacy. In\nthe technology appropriation model, negative perceptions of tech-\nnology are categorized as â€œdisappropriation criteria, â€ as they may\nlead users to reject a technology [ 17]. For some students, espe-\ncially those with less programming experience, the realization of\ntheir over-reliance on LLMs and associated decrease in self-efficacy\ncould contribute to disappropriation, prompting them to reduce\ntheir usage. However, due to the correlational nature of the survey\nfindings, the directionality of these relationships is still unknown.\nIt is possible that reduced self-efficacy led students to appropriate\nLLMs. Additionally, interviews with students suggest over-reliance\nwas the factor contributing to their reduced self-efficacy. Larger\nstudies should investigate this potential relationship further.\nGiven the strong link between self-efficacy and persistence in\ncomputing education [12, 50, 85], decreases in self-confidence are\nconcerning. Over time, this might turn into a belief that they are in-\ncapable of understanding the programming concepts without LLM\nassistance. This relationship is particularly troubling for broadening\nparticipation in computing, as perceptions of oneâ€™s ability to pro-\ngram may be crucial to persistence in computing [78]. The possible\nreduction in self-efficacy likely results from the understanding that\nmore experience with the process of programming fosters greater\nconfidence and persistence in the field [2, 61].\nICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia Padiyath, et al.\nThe technology appropriation model recognizes that users can\nadapt and modify their use of a technology to better suit their\nneeds [16, 17]. This aligns with the mixed perceptions of LLMsâ€™\neffects on learning outcomes, with some students reporting pos-\nitive experiences when using LLMs for explanations and others\nnoting a lack of intuition when relying on them for generating code.\nSurvey data revealed that students concerned about becoming over-\nreliant on LLMs to learn programming correlated with relying less\non LLMs in class. This potentially highlights a â€œhigher-order rein-\nforcerâ€ of the need for a perception of learning. Students worried\nabout over-relying on LLMs may disappropriate LLMs to increase\ntheir perception of learning. However, this reinforcer may also be\nproblematic, as students who reported using LLMs to improve their\nprogramming skills and avoid help-seeking were more likely to feel\nover-reliant on LLMs.\nStudentsâ€™ use of LLMs to generate full solutions to coding prob-\nlems correlating with over-reliance provides further validation of\nrecent research by Kazemitabaar et al., in which surface-level en-\ngagement with the process of programming when fully generating\nsolutions may lead to over-reliance on LLMs [ 44]. However, in\nour context, generating code for debugging may also be related\nto over-reliance. This may be in contrast to Kazemitabaar et al.â€™s\nfinding that a hybrid approach to using LLM tools â€“ such as us-\ning LLMs for debugging syntax errors â€“ has a positive effect on\nstudentsâ€™ learning. This difference is especially notable as, regard-\nless of major and third-week self-efficacy, reported use of LLMs for\nhomework was negatively correlated with Midterm #1 performance.\nHowever, LLM use was not significantly correlated with Midterm\n#2 performance. Through the lens of the technology appropriation\nmodel, this difference may be attributed to students realizing that\ntheir over-reliance on LLMs was negatively affecting their midterm\nperformance, leading them to disappropriate or modify their use of\nLLMs. Interviews with students supports this interpretation, as they\nreported recognizing their over-reliance on LLMs after performing\npoorly on practice midterms, which prompted some to change their\napproach.\n5.3 Implications\nA key principle of social shaping theory is that it posits an interac-\ntive, cyclical relationship between society and technology, where\neach continuously influences and reshapes the other [6, 17, 89]. In\nthe context of LLM use in our undergraduate programming class,\nwe begin to see evidence of this interaction. The technology appro-\npriation model helps illustrate this dynamic cycle, emphasizing the\nrole of student agency in the appropriation process.\nHowever, our findings also suggest that studentsâ€™ use of LLMs\ncan have unintended consequences. Some students in our study\nreported learning setbacks and over-reliance as well as received\nlower exam scores, potentially leading them to reconsider their\ndependence on LLMs. This realization may prompt students to\nmodify their engagement with LLMs, initiating another cycle of\nappropriation based on their updated perceptions and experiences.\nAdditionally, our results indicate that students may not fully grasp\nthe impact of these consequences due to potential misconceptions\nabout their future careers and the nature of programming. Ulti-\nmately, the long-term effects of this cyclical relationship remains\nuncertain and warrants further investigation. As students progress\nthrough their education and enter the workforce, early experi-\nences with LLMs may continue to shape their attitudes, skills, and\ndecision-making in complex ways. The ongoing interaction be-\ntween students and LLMs underscores the importance of providing\nguidance and support to help students navigate their relationships\nwith LLMs. Longitudinal studies may be necessary to investigate the\nevolving nature of studentsâ€™ LLM appropriation on their academic,\nprofessional, and personal trajectories.\nWhile prior research has found similar concerns among students\n[33, 91], discussions focused on technological interpretations and\nsolutions. For example, in response to finding 45% of their sample\nof students being neutral or disagreeing that they understood how\nto use ChatGPT for academic tasks, the authors advised further\neducation on how best to use ChatGPT [33]. When finding students\nexpressing concerns about ChatGPT sometimes providing incorrect\nanswers or finding themselves becoming lazy, the authors recom-\nmended providing students with â€œprompt literacyâ€ skills [91]. Or\nin interpreting widespread use of an LLM-based tool, the authors\nassumed this meant that students found the tool beneficial [51, 55].\nThese interpretations and implications fail to account for the social\nfactors influencing studentsâ€™ adoption and use of LLMs. Students\nlack of understanding in how to use ChatGPT for learning may stem\nfrom their individual learning needs, goals, and contexts, rather\nthan simply lacking technical knowledge. Or, students concerns\nover incorrect responses and laziness may suggest students would\nrather disappropriate LLMs than learn how to appropriate it differ-\nently. Additionally, widespread use may be driven by social factors\nsuch as peer pressure/norms, career expectations, or AI hype and\nmarketing, rather than because the tool itself is beneficial.\nThis emphasis on technological interpretations and solutions\ncomes from a technological determinism perspective, which im-\nplicitly or explicitly presupposes that the adoption and impact of\nLLMs in programming education are inevitable and desirable. This\npresumption often fails to account for the agency of students in\nshaping their own learning experiences and the complex social\ndynamics that influence the adoption and use of technologies. This\nperspective assumes that students will passively accept and adapt to\nLLMs, rather than recognizing students as active participants in the\nlearning process, as they actively negotiate their relationship with\nLLMs based on their individual needs, goals, and contexts. For ex-\nample, a perspective coming from technological determinism may\nargue that \"there is little doubt that LLMs ... will have a profound\nimpact on computing education over the coming years\" [ 67, 92],\nand that \"LLMs are here to stay\" [68], urging educators to \"embrace\nthese changes or face being left behind\" [24]. However, our study,\nthrough the lens of social shaping theory, finds that the impacts of\nLLMs are not always desirable, as some students may exercise their\nagency to reject, negotiate with, or disappropriate LLMs if they do\nnot align with their needs and goals, rather than accepting them\nas an inevitable part of their learning experience. By acknowledg-\ning studentsâ€™ agency and the complex social dynamics that shape\nthe adoption and use of educational technologies, educators and\nresearchers can develop more nuanced and student-centered strate-\ngies when discussing LLMs in programming curricula, rather than\nassuming a one-size-fits-all approach based on technological deter-\nminism. Paralleling previous educational technologies that failed\nThe Appropriation of LLMs in an Undergraduate Programming Course ICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia\nto live up to their hype, LLMsâ€™ success in education may depend\non how well they can be adapted and shaped to fit the social reali-\nties and needs of students and classrooms, rather than relying on\ntheir capabilities alone. By recognizing this crucial role of social\nfactors in shaping the adoption and impact of LLMs, educators and\nresearchers can develop more realistic strategies for addressing the\ninfluence of LLMs in programming curricula.\nFinally, this study primarily focused on social influences, while\ncultural influences could be significant as well. For instance, biases\nembedded in AI systems could discourage participation from groups\nwho feel alienated or harmed by discriminatory algorithms [10, 70].\nAdditionally, the environmental costs of training and running large\nmodels may deter engagement from those concerned about climate\nimpacts, which also often fall disproportionately on minoritized\ncommunities [9, 15]. Or, people may reject use of LLMs due to\nthe controversial training methods and questionable legality with\nrespect to copyright laws [9, 67]. Itâ€™s imperative that future research\nexplores cultural dimensions to understand the nuances influencing\nLLM engagement.\n5.4 Limitations\nThere are some key limitations of this research. First, the context of\nthis study impacts the generalizability of these findings. This study\nwas conducted with a specific demographic makeup of participants,\nat a single institution, and within one country. While consistent\ntrends emerged from both the interviews and survey responses,\nthese findings may not be universally applicable. Future research\nshould aim to validate our results in different educational settings.\nSecond, despite a relatively high survey response rates, our re-\nsults may be subject to selection bias. There is a possibility that\nthose who chose to participate, especially in interviews, had rel-\natively strong opinions about the use or rejection of LLMs. We\nattempted to mitigate this bias by offering different incentives for\nparticipation, but the potential influence of self-selection cannot be\nentirely ruled out. Additionally, our reliance on self-reported data\nmay introduce response bias. Students may have been reluctant to\nfully disclose their LLM usage due to perceived shame or stigma\nassociated with these tools.\nThird, it is important to note that the regression analyses in\nthis study are correlational, not causal. While we have identified\nsignificant associations between various factors like LLM usage, self-\nefficacy, and learning outcomes, we cannot definitively establish\nthe directionality of these relationships. There may be omitted\nvariables or endogeneity issues that limit the interpretability of our\nregression results.\nFourth, the non-anonymous self-efficacy survey was conducted\nin the third week of the semester, which due to the ephemeral\nnature of self-efficacy, may be noisy or wholly change throughout\nthe course of the semester [ 52, 53]. This limitation may explain\nwhy self-efficacy was not as significant predictor of performance\non Midterm #2 compared to Midterm #1. However, we stress that\nthis early measurement is crucial for understanding studentsâ€™ initial\ndecisions to use LLMs.\nLastly, our literature review was limited to peer-reviewed re-\nsearch. We recognize the machine learning and LLM research com-\nmunities frequently utilize non-peer-reviewed repositories such\nas arXiv.org to publish research. However, we focused solely on\ntraditionally published research due to its increased credibility, as\na recent review has raised concerns about the quality of some non-\npeer-reviewed LLM papers [67]. This decision may have led to the\nomission of relevant contributions or to the replication of existing\nwork.\n6 CONCLUSION\nThis study contributes to the understanding of the social dynamics\nsurrounding the appropriation of large language models (LLMs)\nin undergraduate programming education by triangulating mul-\ntiple sources of data within the framing of the technology appro-\npriation model. Our research investigated how social perceptions\ninfluenced studentsâ€™ decisions to use LLMs and the perceived and\nactual impacts of LLM usage on studentsâ€™ programming self-efficacy\nand midterm performance in an intermediate-level programming\ncourse.\nOur findings revealed that studentsâ€™ engagement with LLMs\nwas significantly influenced by their perception of future career\nnorms as well as their perception of peer usage. Additionally, the\nuse of LLMs had mixed impacts on studentsâ€™ self-efficacy and per-\nceived learning outcomes. There was a notable negative correlation\nbetween LLM usage and self-efficacy regardless of major and a\nnegative correlation between LLM usage and performance on the\nfirst midterm. Our results highlight the complex dynamic between\ntechnology and social factors, challenging the notion of technolog-\nical determinism. By examining the social perceptions and impacts\nsurrounding LLM usage, we gain a better understanding of how\nLLMs are appropriated and how they influence studentsâ€™ learning\nexperiences and outcomes. As LLMs and other AI technologies con-\ntinue to evolve, it is crucial that we consider the social dynamics\nthat shape their appropriation.\nACKNOWLEDGMENTS\nOur thanks to the University of Michigan Undergraduate Research\nOpportunity Program for supporting this project. We are grateful\nto our reviewers for helpful feedback. We also thank University of\nMichigan CSCAR service for their invaluable assistance.\nREFERENCES\n[1] Morgan G Ames. 2019. The charisma machine: The life, death, and legacy of One\nLaptop per Child . Mit Press.\n[2] Petek Askar and David Davenport. 2009. An investigation of factors related to self-\nefficacy for java programming among engineering students. Online Submission 8,\n1 (2009).\n[3] Albert Bandura. 1977. Self-efficacy: toward a unifying theory of behavioral\nchange. Psychological review 84, 2 (1977), 191.\n[4] Albert Bandura and Richard H Walters. 1977. Social learning theory . Vol. 1.\nEnglewood cliffs Prentice Hall.\n[5] Shraddha Barke, Michael B. James, and Nadia Polikarpova. 2023. Grounded\nCopilot: How Programmers Interact with Code-Generating Models. Proc. ACM\nProgram. Lang. 7, OOPSLA1, Article 78 (apr 2023), 27 pages. https://doi.org/10.\n1145/3586030\n[6] Nancy K Baym. 2015. Personal connections in the digital age . John Wiley & Sons.\n[7] Brett A Becker, Paul Denny, James Finnie-Ansley, Andrew Luxton-Reilly, James\nPrather, and Eddie Antonio Santos. 2023. Programming is hard-or at least it\nused to be: Educational opportunities and challenges of ai code generation. In\nProceedings of the 54th ACM Technical Symposium on Computer Science Education\nV. 1. 500â€“506.\n[8] Brett A Becker and Thomas Fitzpatrick. 2019. What do cs1 syllabi reveal about\nour expectations of introductory programming students?. In Proceedings of the\n50th ACM technical symposium on computer science education . 1011â€“1017.\nICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia Padiyath, et al.\n[9] Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret\nShmitchell. 2021. On the dangers of stochastic parrots: Can language models\nbe too big?. In Proceedings of the 2021 ACM conference on fairness, accountability,\nand transparency . 610â€“623.\n[10] Ruha Benjamin. 2019. Race after technology: Abolitionist tools for the new jim\ncode. Social forces (2019).\n[11] Dan Berrett. 2022. The day the purpose of college changed. https://www.\nchronicle.com/article/the-day-the-purpose-of-college-changed/\n[12] Sylvia Beyer. 2014. Why are women underrepresented in Computer Science?\nGender differences in stereotypes, self-efficacy, values, and interests and predic-\ntors of future CS course-taking and grades. Computer Science Education 24, 2-3\n(2014), 153â€“192.\n[13] Wiebe E Bijker. 1997. Of bicycles, bakelites, and bulbs: Toward a theory of so-\nciotechnical change . MIT press.\n[14] Bo Brinkman and Amanda Diekman. 2016. Applying the communal goal con-\ngruity perspective to enhance diversity and inclusion in undergraduate comput-\ning degrees. In Proceedings of the 47th ACM technical symposium on computing\nscience education . 102â€“107.\n[15] Robert D Bullard. 1993. Confronting environmental racism: Voices from the grass-\nroots. South End Press.\n[16] Jennie Carroll, Steve Howard, Frank Vetere, Jane Peck, and John Murphy. 2001.\nIdentity, power and fragmentation in cyberspace: technology appropriation by\nyoung people. (2001).\n[17] Jennie Carroll, Steve Howard, Frank Vetere, Jane Peck, and John Murphy. 2002.\nJust what do the youth of today want? Technology appropriation by young\npeople. In Proceedings of the 35th Annual Hawaii International Conference on\nSystem Sciences . IEEE, 1777â€“1785.\n[18] Yuk Fai Cheong, Frank Pajares, and Paul S Oberman. 2004. Motivation and aca-\ndemic help-seeking in high school computer science. Computer Science Education\n14, 1 (2004), 3â€“19.\n[19] Randy W. Connolly. 2011. Beyond good and evil impacts: rethinking the social\nissues components in our computing curricula. In Proceedings of the 16th Annual\nJoint Conference on Innovation and Technology in Computer Science Education\n(Darmstadt, Germany) (ITiCSE â€™11) . Association for Computing Machinery, New\nYork, NY, USA, 228â€“232. https://doi.org/10.1145/1999747.1999812\n[20] Kathryn Cunningham, Yike Qiao, Alex Feng, and Eleanor Oâ€™Rourke. 2022. Bring-\ning\" High-Level\" Down to Earth: Gaining Clarity in Conversational Programmer\nLearning Goals. InProceedings of the 53rd ACM Technical Symposium on Computer\nScience Education-Volume 1 . 551â€“557.\n[21] Fred D Davis. 1989. Perceived usefulness, perceived ease of use, and user accep-\ntance of information technology. MIS quarterly (1989), 319â€“340.\n[22] Debra L Dawson, Ken N Meadows, and Tom Haffie. 2010. The effect of perfor-\nmance feedback on student help-seeking and learning strategy use: Do clickers\nmake a difference? The Canadian journal for the scholarship of teaching and\nlearning 1, 1 (2010).\n[23] Paul Denny, Brett A. Becker, Juho Leinonen, and James Prather. 2023. Chat\nOverflow: Artificially Intelligent Models for Computing Education - renAIs-\nsance or apocAIypse?. In Proceedings of the 2023 Conference on Innovation\nand Technology in Computer Science Education V. 1 (Turku, Finland) (ITiCSE\n2023). Association for Computing Machinery, New York, NY, USA, 3â€“4. https:\n//doi.org/10.1145/3587102.3588773\n[24] Paul Denny, James Prather, Brett A Becker, James Finnie-Ansley, Arto Hellas,\nJuho Leinonen, Andrew Luxton-Reilly, Brent N Reeves, Eddie Antonio Santos,\nand Sami Sarsa. 2024. Computing education in the era of generative AI.Commun.\nACM 67, 2 (2024), 56â€“67.\n[25] Adam DeRose. 2023. These companies have banned or limited CHATGPT at\nwork. https://www.hr-brew.com/stories/2023/05/11/these-companies-have-\nbanned-chatgpt-in-the-office\n[26] Amanda B Diekman, Elizabeth R Brown, Amanda M Johnston, and Emily K Clark.\n2010. Seeking congruity between goals and roles: A new look at why women opt\nout of science, technology, engineering, and mathematics careers. Psychological\nscience 21, 8 (2010), 1051â€“1057.\n[27] Norman R Draper and Harry Smith. 1998. Applied regression analysis . Vol. 326.\nJohn Wiley & Sons.\n[28] Urvi Dugar. 2023. Apple restricts use of OpenAIâ€™s chatgpt for employees, wall\nstreet ... https://www.reuters.com/technology/apple-restricts-use-chatgpt-wsj-\n2023-05-18/\n[29] Barbara J Ericson and Bradley N Miller. 2020. Runestone: A platform for free, on-\nline, and interactive ebooks. In Proceedings of the 51st ACM Technical Symposium\non Computer Science Education . 1012â€“1018.\n[30] Barbara J Ericson, Janice L Pearce, Susan H Rodger, Andrew Csizmadia, Rita Gar-\ncia, Francisco J Gutierrez, Konstantinos Liaskos, Aadarsh Padiyath, Michael James\nScott, David H Smith IV, et al. 2023. Multi-Institutional Multi-National Studies of\nParsons Problems. In Proceedings of the 2023 Working Group Reports on Innovation\nand Technology in Computer Science Education . 57â€“107.\n[31] Mohammadreza Farrokhnia, Seyyed Kazem Banihashem, Omid Noroozi, and\nArjen Wals. 2023. A SWOT analysis of ChatGPT: Implications for educational\npractice and research. Innovations in Education and Teaching International (2023),\n1â€“15.\n[32] James Finnie-Ansley, Paul Denny, Brett A Becker, Andrew Luxton-Reilly, and\nJames Prather. 2022. The robots are coming: Exploring the implications of openai\ncodex on introductory programming. In Proceedings of the 24th Australasian\nComputing Education Conference . 10â€“19.\n[33] Norbert Forman, JÃ³zsef Udvaros, and MihÃ¡ly SzilÃ¡rd Avornicului. 2023. ChatGPT:\nA new study tool shaping the future for high school students. International\nJournal of Advanced Natural Sciences and Engineering Researches 7, 4 (2023),\n95â€“102.\n[34] Mark Guzdial. 2023. A scaffolded approach into programming for\nArts and Humanities Majors: ITICSE 2023 tips and techniques papers.\nhttps://computinged.wordpress.com/2023/07/10/a-scaffolded-approach-\ninto-programming-for-arts-and-humanities-majors-iticse-2023-tips-and-\ntechniques-papers/\n[35] Mark Guzdial, Emma Dodoo, Bahare Naimpour, Tamara Nelson-Fromm, and\nAadarsh Padiyath. 2023. Putting a Teaspoon of Programming into Other Subjects.\nCommun. ACM 66, 5 (2023), 24â€“26.\n[36] Tracy G Harwood and Tony Garry. 2003. An overview of content analysis. The\nmarketing review 3, 4 (2003), 479â€“498.\n[37] Shawn Helms and Jason Krieser. 2023. Copyright Chaos: Legal Implications\nof Generative AI. https://www.bloomberglaw.com/external/document/\nXDDQ1PNK000000/copyrights-professional-perspective-copyright-chaos-\nlegal-implic\n[38] Toni Honicke and Jaclyn Broadbent. 2016. The influence of academic self-efficacy\non academic performance: A systematic review. Educational research review 17\n(2016), 63â€“84.\n[39] Irene Hou, Sophia Mettille, Owen Man, Zhuo Li, Cynthia Zastudil, and Stephen\nMacNeil. 2024. The Effects of Generative AI on Computing Studentsâ€™ Help-\nSeeking Preferences. In Proceedings of the 26th Australasian Computing Education\nConference. 39â€“48.\n[40] Xinying Hou, Barbara J Ericson, and Xu Wang. 2023. Understanding the Effects of\nUsing Parsons Problems to Scaffold Code Writing for Students with Varying CS\nSelf-Efficacy Levels. InProceedings of the 23rd Koli Calling International Conference\non Computing Education Research (Koli, Finland) (Koli Calling â€™23) . Association\nfor Computing Machinery, New York, NY, USA.\n[41] Xinying Hou, Barbara J. Ericson, and Xu Wang. 2024. Integrating Personalized\nParsons Problems with Multi-Level Textual Explanations to Scaffold Code Writ-\ning. In Proceedings of the 55th ACM Technical Symposium on Computer Science\nEducation V. 2 (SIGCSE 2024) . Association for Computing Machinery, New York,\nNY, USA, 1686â€“1687. https://doi.org/10.1145/3626253.3635606\n[42] Xinying Hou, Zihan Wu, Xu Wang, and Barbara J Ericson. 2024. CodeTailor: LLM-\nPowered Personalized Parsons Puzzles for Engaging Support While Learning\nProgramming. In Proceedings of the Eleventh ACM Conference on Learning @\nScale (L@S â€™24) . Association for Computing Machinery, New York, NY, USA.\nhttps://doi.org/10.1145/3657604.3662032\n[43] Majeed Kazemitabaar, Justin Chow, Carl Ka To Ma, Barbara J Ericson, David\nWeintrop, and Tovi Grossman. 2023. Studying the effect of AI Code Generators\non Supporting Novice Learners in Introductory Programming. In Proceedings of\nthe 2023 CHI Conference on Human Factors in Computing Systems . 1â€“23.\n[44] Majeed Kazemitabaar, Xinying Hou, Austin Henley, Barbara Jane Ericson, David\nWeintrop, and Tovi Grossman. 2023. How novices use LLM-based code generators\nto solve CS1 coding tasks in a self-paced learning environment. In Proceedings of\nthe 23rd Koli Calling International Conference on Computing Education Research .\n1â€“12.\n[45] Majeed Kazemitabaar, Runlong Ye, Xiaoning Wang, Austin Z Henley, Paul Denny,\nMichelle Craig, and Tovi Grossman. 2024. CodeAid: Evaluating a Classroom\nDeployment of an LLM-based Programming Assistant that Balances Student and\nEducator Needs. In Proceedings of the 2024 chi conference on human factors in\ncomputing systems .\n[46] Amy Ko. 2023. Large language models will change programming. . . a lit-\ntle. https://medium.com/bits-and-behavior/large-language-models-will-\nchange-programming-a-little-81445778d957\n[47] Amy Ko. 2024. More than calculators: Why large language models threaten public\neducation. https://medium.com/bits-and-behavior/more-than-calculators-why-\nlarge-language-models-threaten-public-education-480dd5300939\n[48] Sam Lau and Philip J Guo. 2023. From \"Ban It Till We Understand It\" to \"Resistance\nis Futile\": How University Programming Instructors Plan to Adapt as More\nStudents Use AI Code Generation and Explanation Tools such as ChatGPT and\nGitHub Copilot. (2023).\n[49] Colleen M Lewis, Ruth E Anderson, and Ken Yasuhara. 2016. \"I Donâ€™t Code All\nDay\" Fitting in Computer Science When the Stereotypes Donâ€™t Fit. InProceedings\nof the 2016 ACM conference on international computing education research . 23â€“32.\n[50] Colleen M Lewis, Ken Yasuhara, and Ruth E Anderson. 2011. Deciding to major\nin computer science: a grounded theory of studentsâ€™ self-assessment of ability. In\nProceedings of the seventh international workshop on Computing education research .\n3â€“10.\nThe Appropriation of LLMs in an Undergraduate Programming Course ICER â€™24 Vol. 1, August 13â€“15, 2024, Melbourne, VIC, Australia\n[51] Mark Liffiton, Brad E Sheese, Jaromir Savelka, and Paul Denny. 2023. Codehelp:\nUsing large language models with guardrails for scalable support in program-\nming classes. In Proceedings of the 23rd Koli Calling International Conference on\nComputing Education Research . 1â€“11.\n[52] Alex Lishinski, Sarah Narvaiz, and Joshua M Rosenberg. 2022. Self-efficacy,\ninterest, and belongingnessâ€“URM studentsâ€™ momentary experiences in CS1. In\nProceedings of the 2022 ACM Conference on International Computing Education\nResearch-Volume 1. 44â€“60.\n[53] Alex Lishinski and Joshua Rosenberg. 2021. All the pieces matter: The relationship\nof momentary self-efficacy and affective experiences with CS1 achievement and\ninterest in computing. In Proceedings of the 17th ACM Conference on International\nComputing Education Research . 252â€“265.\n[54] Alex Lishinski and Aman Yadav. 2019. 28 Motivation, Attitudes, and Dispositions.\n(2019).\n[55] Rongxin Liu, Carter Zenke, Charlie Liu, Andrew Holmes, Patrick Thornton, and\nDavid J Malan. 2024. Teaching CS50 with AI. (2024).\n[56] Brett Lunceford. 2009. Reconsidering technology adoption and resistance obser-\nvations of a semi-luddite. Explorations in Media Ecology 8, 1 (2009), 29â€“48.\n[57] Hughie Mackay and Gareth Gillespie. 1992. Extending the social shaping of\ntechnology approach: ideology and appropriation. Social studies of science 22, 4\n(1992), 685â€“716.\n[58] Sergi Martin-Arbos, Elena Castarlenas, and Jorge-Manuel Duenas. 2021. Help-\nseeking in an academic context: A systematic review. Sustainability 13, 8 (2021),\n4460.\n[59] Carol Midgley, Martin L Maehr, Ludmila Z Hruda, Eric Anderman, Lynley An-\nderman, Kimberley E Freeman, T Urdan, et al. 2000. Manual for the patterns of\nadaptive learning scales. Ann Arbor: University of Michigan (2000), 734â€“763.\n[60] Glen B Norcliffe. 2001. The ride to modernity: The bicycle in Canada, 1869-1900 .\nUniversity of Toronto Press.\n[61] Vidushi Ojha, Leah West, and Colleen M. Lewis. 2024. Computing Self-Efficacy\nin Undergraduate Students: A Multi-Institutional and Intersectional Analysis. In\nProceedings of the 55th ACM Technical Symposium on Computer Science Education\nV. 1 (Portland, OR, USA) (SIGCSE 2024) . Association for Computing Machinery,\nNew York, NY, USA, 993â€“999. https://doi.org/10.1145/3626252.3630811\n[62] Martin Oliver. 2011. Technological determinism in educational technology re-\nsearch: some alternative ways of thinking about the relationship between learning\nand technology. Journal of Computer Assisted Learning 27, 5 (2011), 373â€“384.\n[63] OpenAI. 2018. OpenAI Charter. https://openai. com/charter/ (2018).\n[64] Aadarsh Padiyath, Kyle Ashburn, and Barbara Ericson. 2024. Undergraduate\nStudent Attitudes towards a Social Justice Context in a Programming Project. In\nProceedings of the 55th ACM Technical Symposium on Computer Science Education\nV. 1. 1000â€“1006.\n[65] Nea Pirttinen, Arto Hellas, Lassi Haaranen, and Rodrigo Duran. 2020. Study major,\ngender, and confidence gap: Effects on experience, performance, and self-efficacy\nin introductory programming. In 2020 IEEE Frontiers in Education Conference\n(FIE). IEEE, 1â€“7.\n[66] James Prather, Brett A Becker, Michelle Craig, Paul Denny, Dastyni Loksa, and\nLauren Margulieux. 2020. What do we think we think we are doing? Metacogni-\ntion and self-regulation in programming. In Proceedings of the 2020 ACM confer-\nence on international computing education research . 2â€“13.\n[67] James Prather, Paul Denny, Juho Leinonen, Brett A Becker, Ibrahim Albluwi,\nMichelle Craig, Hieke Keuning, Natalie Kiesler, Tobias Kohn, Andrew Luxton-\nReilly, et al. 2023. The robots are here: Navigating the generative ai revolution\nin computing education. In Proceedings of the 2023 Working Group Reports on\nInnovation and Technology in Computer Science Education . 108â€“159.\n[68] James Prather, Paul Denny, Juho Leinonen, David H Smith IV, Brent N Reeves,\nStephen MacNeil, Brett A Becker, Andrew Luxton-Reilly, Thezyrie Amarouche,\nand Bailey Kimmel. 2024. Interactions with Prompt Problems: A New Way to\nTeach Programming with Large Language Models.arXiv preprint arXiv:2401.10759\n(2024).\n[69] James Prather, Brent N. Reeves, Paul Denny, Brett A. Becker, Juho Leinonen,\nAndrew Luxton-Reilly, Garrett Powell, James Finnie-Ansley, and Eddie Antonio\nSantos. 2023. â€œItâ€™s Weird That it Knows What I Wantâ€: Usability and Interactions\nwith Copilot for Novice Programmers. ACM Trans. Comput.-Hum. Interact. 31, 1,\nArticle 4 (nov 2023), 31 pages. https://doi.org/10.1145/3617367\n[70] Yolanda A Rankin and Jakita O Thomas. 2020. The intersectional experiences of\nblack women in computing. In Proceedings of the 51st ACM Technical Symposium\non Computer Science Education . 199â€“205.\n[71] Justin Reich. 2020. Failure to disrupt: Why technology alone canâ€™t transform\neducation. Harvard University Press.\n[72] Maxine Robertson, Jacky Swan, and Sue Newell. 1996. The role of networks in\nthe diffusion of technological innovation. Journal of management studies 33, 3\n(1996), 333â€“359.\n[73] Everett M Rogers, Arvind Singhal, and Margaret M Quinlan. 2014. Diffusion of\ninnovations. In An integrated approach to communication theory and research .\nRoutledge, 432â€“448.\n[74] Michael P. Rogers, Hannah Miller Hillberg, and Christopher L. Groves. 2024.\nAttitudes Towards the Use (and Misuse) of ChatGPT: A Preliminary Study. In\nProceedings of the 55th ACM Technical Symposium on Computer Science Education\nV. 1 (Portland, OR, USA) (SIGCSE 2024) . Association for Computing Machinery,\nNew York, NY, USA, 1147â€“1153. https://doi.org/10.1145/3626252.3630784\n[75] Johnny SaldaÃ±a. 2021. The coding manual for qualitative researchers. The coding\nmanual for qualitative researchers (2021), 1â€“440.\n[76] Juana M Sancho-Gil, Pablo Rivera-Vargas, and Raquel MiÃ±o-PuigcercÃ³s. 2020.\nMoving beyond the predictable failure of Ed-Tech initiatives. Learning, Media\nand Technology 45, 1 (2020), 61â€“75.\n[77] Jaromir Savelka, Arav Agarwal, Marshall An, Chris Bogart, and Majd Sakr. 2023.\nThrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle\nto Pass Assessments in Higher Education Programming Courses. In Proceedings\nof the 2023 ACM Conference on International Computing Education Research -\nVolume 1 (Chicago, IL, USA) (ICER â€™23) . Association for Computing Machinery,\nNew York, NY, USA, 78â€“92. https://doi.org/10.1145/3568813.3600142\n[78] Linda J. Sax, Kaitlin N.S. Newhouse, Joanna Goode, Max Skorodinsky, Tomoko M.\nNakajima, and Michelle Sendowski. 2020. Does AP CS Principles Broaden Par-\nticipation in Computing? An Analysis of APCSA and APCSP Participants. In\nProceedings of the 51st ACM Technical Symposium on Computer Science Education\n(Portland, OR, USA) (SIGCSE â€™20) . Association for Computing Machinery, New\nYork, NY, USA, 542â€“548. https://doi.org/10.1145/3328778.3366826\n[79] Neil Selwyn. 2013. Distrusting educational technology: Critical questions for\nchanging times . Routledge.\n[80] Priya Shah, Anushka Raheja, and Hasika Sridhar. 2024. How do students use\nChatGPT? https://www.michigandaily.com/web/data/how-do-students-use-\nchatgpt/\n[81] Merritt Roe Smith and Leo Marx. 1994. Does technology drive history?: The\ndilemma of technological determinism . Mit Press.\n[82] Phil Steinhorst, Andrew Petersen, and Jan Vahrenhold. 2020. Revisiting self-\nefficacy in introductory programming. In Proceedings of the 2020 ACM Conference\non International Computing Education Research . 158â€“169.\n[83] Leigh Ann Sudol and Ciera Jaspan. 2010. Analyzing the strength of undergrad-\nuate misconceptions about software engineering. In Proceedings of the Sixth\nInternational Workshop on Computing Education Research (Aarhus, Denmark)\n(ICER â€™10) . Association for Computing Machinery, New York, NY, USA, 31â€“40.\nhttps://doi.org/10.1145/1839594.1839601\n[84] Burning Glass Technologies. 2018. Employers increasingly demand computer\nscience skills in Non-Tech Jobs. https://www.prnewswire.com/news-\nreleases/employers-increasingly-demand-computer-science-skills-in-non-\ntech-jobs-300555478.html\n[85] F. Boray Tek, Kristin S. Benli, and Ezgi Deveci. 2017. Implicit Theories and Self-\nEfficacy in an Introductory Programming Course. IEEE Transactions on Education\n61 (2017), 218â€“225. https://api.semanticscholar.org/CorpusID:23255587\n[86] Chun-Yen Tsai. 2019. Improving studentsâ€™ understanding of basic program-\nming concepts through visual programming language: The role of self-efficacy.\nComputers in Human Behavior 95 (2019), 224â€“232.\n[87] Eric W Weisstein. 2004. Bonferroni correction. https://mathworld. wolfram. com/\n(2004).\n[88] Joseph B Wiggins, Joseph F Grafsgaard, Kristy Elizabeth Boyer, Eric N Wiebe, and\nJames C Lester. 2017. Do you think you can? the influence of student self-efficacy\non the effectiveness of tutorial dialogue for computer science. International\nJournal of Artificial Intelligence in Education 27, 1 (2017), 130â€“153.\n[89] Robin Williams and David Edge. 1996. The social shaping of technology.Research\npolicy 25, 6 (1996), 865â€“899.\n[90] Langdon Winner. 2017. Do artifacts have politics? In Computer ethics . Routledge,\n177â€“192.\n[91] Ramazan Yilmaz and Fatma Gizem Karaoglan Yilmaz. 2023. Augmented intelli-\ngence in programming learning: Examining student views on the use of ChatGPT\nfor programming learning. Computers in Human Behavior: Artificial Humans 1, 2\n(2023), 100005.\n[92] Cynthia Zastudil, Magdalena Rogalska, Chris Kapp, Jennifer L. Vaughn, and\nStephen Macneil. 2023. Generative AI in Computing Education: Perspectives of\nStudents and Instructors. 2023 IEEE Frontiers in Education Conference (FIE) (2023),\n1â€“9.\n[93] Daniel Zingaro. 2014. Peer instruction contributes to self-efficacy in CS1. In\nProceedings of the 45th ACM technical symposium on Computer Science Education .\n373â€“378.",
  "topic": "Transformative learning",
  "concepts": [
    {
      "name": "Transformative learning",
      "score": 0.7148292660713196
    },
    {
      "name": "Context (archaeology)",
      "score": 0.6198526620864868
    },
    {
      "name": "Appropriation",
      "score": 0.6084697842597961
    },
    {
      "name": "Perception",
      "score": 0.5189380645751953
    },
    {
      "name": "Self-efficacy",
      "score": 0.47318577766418457
    },
    {
      "name": "Computer science",
      "score": 0.4361932873725891
    },
    {
      "name": "Mathematics education",
      "score": 0.39874547719955444
    },
    {
      "name": "Psychology",
      "score": 0.3803783357143402
    },
    {
      "name": "Medical education",
      "score": 0.3222237229347229
    },
    {
      "name": "Pedagogy",
      "score": 0.2447742521762848
    },
    {
      "name": "Social psychology",
      "score": 0.23840749263763428
    },
    {
      "name": "Medicine",
      "score": 0.09412148594856262
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Linguistics",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ]
}