{
  "title": "Transformer-Based Deep Neural Language Modeling for Construct-Specific Automatic Item Generation",
  "url": "https://openalex.org/W4226163610",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A3217257741",
      "name": "Björn E. Hommel",
      "affiliations": [
        "Leipzig University",
        null
      ]
    },
    {
      "id": "https://openalex.org/A4227446553",
      "name": "Franz-Josef M Wollang",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A4227446554",
      "name": "Veronika Kotova",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A2020981169",
      "name": "Hannes Zacher",
      "affiliations": [
        "Leipzig University"
      ]
    },
    {
      "id": "https://openalex.org/A9125003",
      "name": "Stefan C. Schmukle",
      "affiliations": [
        "Leipzig University"
      ]
    },
    {
      "id": "https://openalex.org/A3217257741",
      "name": "Björn E. Hommel",
      "affiliations": [
        "Leipzig University",
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A4227446553",
      "name": "Franz-Josef M Wollang",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A4227446554",
      "name": "Veronika Kotova",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A2020981169",
      "name": "Hannes Zacher",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A9125003",
      "name": "Stefan C. Schmukle",
      "affiliations": [
        "Leipzig University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3112942189",
    "https://openalex.org/W2136219431",
    "https://openalex.org/W2791246286",
    "https://openalex.org/W6629461549",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2979325830",
    "https://openalex.org/W581956982",
    "https://openalex.org/W1979735780",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W6761551260",
    "https://openalex.org/W1577139234",
    "https://openalex.org/W6730267373",
    "https://openalex.org/W6788194643",
    "https://openalex.org/W2995699592",
    "https://openalex.org/W2107725879",
    "https://openalex.org/W3199412738",
    "https://openalex.org/W3138930489",
    "https://openalex.org/W6735282441",
    "https://openalex.org/W201326660",
    "https://openalex.org/W2810451479",
    "https://openalex.org/W6613547880",
    "https://openalex.org/W2159013703",
    "https://openalex.org/W4283794074",
    "https://openalex.org/W2116323796",
    "https://openalex.org/W2944216216",
    "https://openalex.org/W2110485445",
    "https://openalex.org/W2157703634",
    "https://openalex.org/W2963096510",
    "https://openalex.org/W6772940516",
    "https://openalex.org/W6625268989",
    "https://openalex.org/W2132865567",
    "https://openalex.org/W2153579005",
    "https://openalex.org/W6636915900",
    "https://openalex.org/W6674330103",
    "https://openalex.org/W6713134421",
    "https://openalex.org/W6763240421",
    "https://openalex.org/W6630486850",
    "https://openalex.org/W2047185325",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W1614298861",
    "https://openalex.org/W2040870580",
    "https://openalex.org/W2402452943",
    "https://openalex.org/W2736472496",
    "https://openalex.org/W1964218847",
    "https://openalex.org/W2962965405",
    "https://openalex.org/W2963026768",
    "https://openalex.org/W194249466",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W1968956327",
    "https://openalex.org/W2963850840",
    "https://openalex.org/W2099465598",
    "https://openalex.org/W2107878631",
    "https://openalex.org/W1549812429",
    "https://openalex.org/W1979185006",
    "https://openalex.org/W2882319491",
    "https://openalex.org/W4214671568",
    "https://openalex.org/W4213069590",
    "https://openalex.org/W4238095402"
  ],
  "abstract": "Algorithmic automatic item generation can be used to obtain large quantities of cognitive items in the domains of knowledge and aptitude testing. However, conventional item models used by template-based automatic item generation techniques are not ideal for the creation of items for non-cognitive constructs. Progress in this area has been made recently by employing long short-term memory recurrent neural networks to produce word sequences that syntactically resemble items typically found in personality questionnaires. To date, such items have been produced unconditionally, without the possibility of selectively targeting personality domains. In this article, we offer a brief synopsis on past developments in natural language processing and explain why the automatic generation of construct-specific items has become attainable only due to recent technological progress. We propose that pre-trained causal transformer models can be fine-tuned to achieve this task using implicit parameterization in conjunction with conditional generation. We demonstrate this method in a tutorial-like fashion and finally compare aspects of validity in human- and machine-authored items using empirical data. Our study finds that approximately two-thirds of the automatically generated items show good psychometric properties (factor loadings above .40) and that one-third even have properties equivalent to established and highly curated human-authored items. Our work thus demonstrates the practical use of deep neural networks for non-cognitive automatic item generation.",
  "full_text": "psychometrika— vol. 87, no. 2, 749–772\nJune 2022\nhttps://doi.org/10.1007/s11336-021-09823-9\nTRANSFORMER-BASED DEEP NEURAL LANGUAGE MODELING FOR\nCONSTRUCT-SPECIFIC AUTOMATIC ITEM GENERATION\nBjörn E. Hommel\nLEIPZIG UNIVERSITY\nMAGNOLIA PSYCHOMETRICS GMBH\nFranz- Josef M. Wollang\nMAGNOLIA PSYCHOMETRICS GMBH\nVeronika Kotova\nTECHNICAL UNIVERSITY OF MUNICH\nHannes Zacher and Stefan C. Schmukle\nLEIPZIG UNIVERSITY\nAlgorithmic automatic item generation can be used to obtain large quantities of cognitive items in the\ndomains of knowledge and aptitude testing. However, conventional item models used by template-based\nautomatic item generation techniques are not ideal for the creation of items for non-cognitive constructs.\nProgress in this area has been made recently by employing long short-term memory recurrent neural\nnetworks to produce word sequences that syntactically resemble items typically found in personality ques-\ntionnaires. To date, such items have been produced unconditionally, without the possibility of selectively\ntargeting personality domains. In this article, we offer a brief synopsis on past developments in natural\nlanguage processing and explain why the automatic generation of construct-speciﬁc items has become\nattainable only due to recent technological progress. We propose that pre-trained causal transformer mod-\nels can be ﬁne-tuned to achieve this task using implicit parameterization in conjunction with conditional\ngeneration. We demonstrate this method in a tutorial-like fashion and ﬁnally compare aspects of validity in\nhuman- and machine-authored items using empirical data. Our study ﬁnds that approximately two-thirds\nof the automatically generated items show good psychometric properties (factor loadings above .40) and\nthat one-third even have properties equivalent to established and highly curated human-authored items.\nOur work thus demonstrates the practical use of deep neural networks for non-cognitive automatic item\ngeneration.\nKey words: automatic item generation, natural language processing, deep learning, neural networks, lan-\nguage modeling.\nResearch on automatic item generation (AIG) represents a promising endeavor as it allows\nobtaining vast numbers of items by utilizing computer technology. Although progress in this ﬁeld\nhas yielded numerous notable contributions such as generative algorithms for creating Raven’s\nProgressive Matrices (Wang & Su, 2015), software for the generation of multiple-choice items\n(Gierl et al., 2008), and the theoretical foundations of AIG (Drasgow et al., 2006), there is a\ndearth of methods that can be utilized for the generation of item formats typically used to assess\nSupplementary Information The online version contains supplementary material available at https://doi.org/10.\n1007/s11336-021-09823-9 .\nCorrespondence should be made to Björn E. Hommel, Department of Work and Organizational Psychol-\nogy, Institute of Psychology – Wilhelm Wundt, Leipzig University, Neumarkt 9-19, Leipzig04109, Germany.\nEmail: bjoern.hommel@uni-leipzig.de\n749© 2021 The Author(s)\n750 PSYCHOMETRIKA\nnon-cognitive constructs such as personality traits. We believe that this gap in the literature can be\nattributed to the special linguistic challenges posed by items used to measure non-cognitive con-\nstructs. Recently, advances in the ﬁeld of deep learning and natural language processing (NLP)\nhave made it possible to address these challenges. In his pioneering work, von Davier ( 2018)\nsuccessfully demonstrated that personality items can be generated by training a type of recurrent\nneural network known as long short-term memory (LSTM) network on a set of established per-\nsonality statements. Although von Davier’s model produces syntactically correct statements that\nresemble those typically found in questionnaires, its utility is limited as it does not permit the\ngeneration of items that are speciﬁc to a given construct. Test development, however, is always\ngoal-oriented and intends to measure explicit knowledge, skills, abilities, or other characteristics.\nAs stated by Gorin and Embretson ( 2013), “Principled item design, whether automated or not,\nshould begin with a clear deﬁnition of the measurement target” (p. 137). Since the publication\nof von Davier’s article, fast-paced developments in computer science have continued to push the\nboundaries of what can be achieved by language modeling.\nIn this article, we focus on the issue of construct-speciﬁcity for non-cognitive item gener-\nation, that is, the creation of items for a predeﬁned measurement target. We ﬁrst outline and\nformalize the linguistic problem that requires a solution, so that construct-speciﬁc AIG can be\nachieved. We then offer a brief synopsis of previous language modeling techniques to illustrate\nthe challenging problem of synthesizing semantically and syntactically valid statements that can\nbe used to measure psychological states and traits. We highlight a relatively new group of neural\nnetworks known as Transformers (Vaswani et al., 2017) and explain why these models are suit-\nable for construct-speciﬁc AIG and subsequently propose a method for ﬁne-tuning such models\nto this task. Finally, we provide evidence for the validity of this method by comparing human-\nand machine-authored items with regard to their psychometric properties.\n0.1. Challenges with the Automatic Generation of Personality Items\nModern approaches to AIG for cognitive items typically rely on a three-step process (Gierl\n&L a i , 2015). A target knowledge, skill, or ability is ﬁrst organized into a conceptual model that\nstructures the cognitive and content-speciﬁc information required by test takers to solve problems\nin the desired domain. This cognitive model is subsequently used to deﬁne a formative item model,\nincorporating components such as item stem, response options, and placeholder elements. Items\nare ﬁnally assembled by combining all possible variations of options and element inputs. While\nthese template-based AIG techniques have indisputable advantages in comparison to manual\nitem authoring, the generation of non-cognitive item inventories (e.g., personality questionnaires)\ndemands somewhat different approaches (Bejar, 2013).\nRating scales are frequently used for measuring non-cognitive constructs in the social and\nbehavioral sciences, and they can be used to illustrate the difﬁculty of employing template-based\nAIG. Consider the statement “ I am the life of the party ” used in the International Personality\nItem Pool (IPIP; Goldberg et al., 2006) to assess individual differences in extraversion, one\nof the Big Five personality traits (Digman, 1990). At least two problems immediately become\napparent if we would attempt to craft an item-template based on this statement. First, when\nexamined independently, not a single word in this sentence is explicitly descriptive of extraverted\nbehavior. Second, if “party” were regarded as an interchangeable word, the universe of meaningful\nalternative nouns that could replace it is quite limited. Replacing it with synonyms or closely\nrelated words would most likely render the item trivial and restrict the scale’s ability to capture\nvariance. This example illustrates that other non-template based generation techniques may be\nmore adequate in the case of personality items.\nBefore examining possible alternatives to template-based AIG techniques, we ﬁrst describe\nrequirements that must be met by such a method. We propose four criteria that a sequence of\nHOMMEL ET AL. 751\nwords generated by a language model must satisfy to qualify as a rating scale component. First, the\nlatent variable of interest must be linguistically encoded in the word sequence; this is synonymous\nwith the concept of content validity (Cronbach & Meehl, 1955). Second, the sequence must be\nsyntactically arranged such that it reassembles the grammar of a target natural language. Third, the\nsequence must have certain characteristics that elicit reliable and valid responses from test takers\n(see Angleitner et al., 1986 for a systematic taxonomy of typical item–construct relations). Finally,\ngenerated sequences must be segmented into meaningful units of adequate length; preferably, the\ntext of a rating scale item should be limited to a single short sentence.\nAlthough psychometric item and scale properties are dependent on a variety of additional\nformal aspects, such as avoiding double negations and ambiguity (see Krosnick & Presser, 2010,\nfor a comprehensive overview), the mentioned characteristics represent a minimum standard for\npersonality items created with AIG techniques. The difﬁculty of meeting this standard consistently\nwith AIG becomes obvious when revisiting the previously mentioned IPIP item (“ I am the life of\nthe party”)—a statement that requires a considerable inferential leap to identify its relationship to\ntrait-level extraversion. Three approaches to non-template-based AIG are typically distinguished.\nWhile syntax- and semantics-based techniques employ linguistic rule-based systems (e.g., syntax\ntrees, grammatical tagging) to generate items, sequence-based procedures attempt to predict new\ncontent by using linguistic units in existing data (Xinxin, 2019). Hereafter, we examine language\nmodeling as a sequence-based non-template approach to the automatic generation of personality\nitems.\n0.2. Language Modeling Approaches to Construct-Speciﬁc Automatic Item Generation\nIn principle, the problem of AIG of personality items can be posed as a language modeling\nproblem. A language model is a function, or an algorithm for learning such a function, that captures\nthe salient statistical characteristics of the distribution of sequences of words in a natural language,\ntypically allowing one to make probabilistic predictions of the next word given preceding ones\n(Bengio, 2008). Such models are frequently employed to solve a variety of NLP tasks, such as\nmachine translation, speech recognition, dialogue systems, and text summarization.\nThroughout this paper, we consider the problem of construct-speciﬁc AIG to be the inverse\nproblem of text summarization (Rush et al., 2015). Instead of capturing the semantic essence of\na text and producing a shorter, more concise version of it, we wish to do the inverse and expand\na concept expressed by a short sequence of words or even a single word (e.g., “extraversion”)\ninto a longer text sequence that is strongly representative. This task may be regarded as concept\nelaboration, which in language modeling terms can be described as the conditional probability of\nﬁnding the item stem (ι)—deﬁned as a sequence of words (w\n1,w 2,...,w n)—for the linguistic\nmanifestation of a given construct (ψ) as\nP (ι) = P (w1,w 2,...,w n | ψ) (1)\nHowever, in practice generic generative language models base their word predictions not on a\nglobal latent factor corresponding to a speciﬁc abstract concept but on previously generated words,\neither directly or in the form of hidden state encoding contextual information (e.g., Bengio, 2008;\nZellers et al., 2019). Consequently, the conditional probability of any given word (wk ) is given by\nthe following recurrence relation, relating it to the conditional probabilities of all previous words:\n752 PSYCHOMETRIKA\nP\n(\nw[1,n]\n)\n= P (w1) P (w2 | w1) P\n(\nw3 | w[1,2]\n)\n... P\n(\nwn | w[1,n−1]\n)\n=\nn∏\nk=1\nP\n(\nwk | w[1,k−1]\n)\n(2)\nTo achieve concept elaboration for construct-speciﬁc AIG, one must seek to ﬁnd solutions\nthat allow Eq. 2 to approach Eq. 1 asymptotically. For the remainder of this section, we recapitulate\nhistorical developments in NLP that have led to ever more sophisticated approaches to language\nmodeling and that eventually allowed for construct-speciﬁc AIG as presented in this paper.\n0.2.1. Markov Chains and n-gram Models When estimating conditional word probabilities,\nmerely counting the co-occurrence of words in a given corpus does not sufﬁce. Alone, it fails to\ncalculate probabilities for word sequences that have not occurred previously in the corpus. Early\nsolutions to this problem involved the use of n-gram models relying on the Markovian assumption\nthat the probability of a word can be approximated by calculating the conditional probability of\nthe n words preceding it (Jurafsky & Martin, 2020). While n-gram models remain in frequent use\nfor various NLP tasks due to their simplicity, they introduce a dilemma that becomes increasingly\ncritical for more complex chunks of text: smaller context windows (e.g., bigram models) result in\nless accurate predictions while larger n-models decrease the probability of ﬁnding any particular\nsequence of words in a given text, yielding missing data. Another disadvantage of n-gram models\nis their tendency to neglect any information that is not contained in the immediate neighborhood\nof a target word, largely disregarding some types of syntactic structures and failing to maintain\nsemantic continuity over larger sequences. Overall, n-grams are insufﬁcient for the purpose of\nconcept elaboration because the task demands the consideration of broader contextual information\nand AIG in the domain of personality items particular requires the creation of novel statements.\n0.2.2. Distributed Semantics and Word Embeddings The notion that semantic meaning is\nderived from context is the central assumption of the distributional hypothesis (Harris, 1954); as\nfamously summarized by John R. Firth: “You shall know a word by the company it keeps” (Firth,\n1962, p. 11). A notable shift toward distributional semantics in the practice of language mod-\nelling took place with the advance of word embeddings as produced by models such as word2vec\n(Mikolov, Chen, et al., 2013a; Mikolov, Sutskever, et al., 2013b). Word embeddings represent the\nmeaning of words by mapping them into a high-dimensional semantic space, which is achieved by\nevaluating neighboring context words. Originally, this was accomplished by training a binary clas-\nsiﬁer to either predict a target word based on its context words (Continuous Bag-of-Words Model)\nor vice versa (Continuous Skip-gram Model). For each iteration, logistic regression weights are\nupdated to maximize the prediction. These eventually yield an n-dimensional embedding matrix\nin which each word in a vocabulary is represented as an embedding vector. The embedding thereby\ncontains semantic information and one can perform mathematical operations on the word vectors\nto identify relationships.\nFor example, if the task is to ﬁnd words related to “extraversion,” a model trained on an\nappropriate corpus can be prompted to return the k number of words showing the highest similarity\nto it. The similarity may be evaluated by the value of the cosine between embedding vector pairs.\n“Party” might show a higher relatedness to “extraversion” than to “agreeableness,” representing\nthe higher likelihood of “party” co-occurring with “extraversion” in a corpus or other words\nthat co-occur with “extraversion” and thus transitively increase the similarity. A major beneﬁt of\nthese models is the fact that they can achieve distributed semantic representations through semi-\nsupervised learning, meaning that they require no labeled input data and rely solely on raw text.\nHOMMEL ET AL. 753\nHowever, since each word is represented by a single point in a semantic space, word embeddings\nperform poorly on words that entail multiple meanings or in the case of word sequences (Camacho-\nCollados & Pilehvar, 2018). Similar to n-gram models, basic word embeddings do not incorporate\nenough contextual information to pose a viable option for the automatic generation of personality\nitems. Embeddings have nevertheless remained central in NLP and is an integral part of many\nmodern architectures (e.g., the transformer model, as explained in Sect. 1).\n0.2.3. Recurrent Neural Networks and Long Short-Term Memory Networks To remedy the\nproblem of limited contextual encoding, word embeddings have successfully been used in con-\njunction with a variety of deep neural networks. Deep neural networks are layered architectures\nthat extract high-level features from input data by passing information through multiple compu-\ntational stages. These stages or layers consist of multiple smaller, interconnected computational\nunits called neurons, which behave in a manner loosely analogous to their human counterparts by\naltering their state through a non-linear activation (Rosenblatt, 1958; Lapedes & Farber, 1988).\nThe outputs of the neurons of each layer are variously connected to the inputs of the subsequent\nlayer. Similar to linear regression analysis, the initial output of a single neuron is a linear function\nof its inputs, a weight, and an associated intercept referred to as the bias term; however, the initial\noutput is then always fed through a so-called activation function to get the ﬁnal output—often a\nsigmoid, making it in some ways also similar to logistic regression. The activation signal output\nfrom one neuron represents a statistical identiﬁcation or recognition of an intermediate pattern in\nthe space formed using the previous layer’s outputs as a basis. The outputs of all neurons in a layer\nthen together become the basis of the space in which the patterns identiﬁed by the activations of\neach neuron in the subsequent layer reside (Montavon et al., 2011). The accuracy of the network\nin achieving its task is evaluated by a predeﬁned loss function; an iterative procedure is then\nfollowed that identiﬁes the neurons in the network responsible for the largest losses and shifts\ntheir weights some small step in the direction of the negative gradient of the loss. This stochastic\ngradient-descent algorithm is known as backpropagation. Finally, various classical information-\ntheoretical measures are used to determine when to terminate the training of the model. The use of\nmany layers helps the model create increasingly abstract and, usually, meaningful representations\nof the original data that then improve its overall robustness and accuracy. Since a more thorough\nreview of deep neural networks is beyond the scope of this article, the interested reader is referred\nto Lapedes and Farber ( 1988), Nielsen ( 2015), and Goodfellow et al. ( 2016) for introductory\nmaterial.\nAmong deep neural network architectures, recurrent neural networks (RNNs, Elman, 1990)\nhave been particularly convenient for language modeling. Recurrent neural networks are inherently\ndesigned to perform well on sequential data, since information about previous inputs is preserved\nby feeding the output of the network back into itself along with new inputs. This mnemonic\nquality is of crucial importance for sentence generation tasks, as the probability of a given word\noccurring is linked to the sequence of words preceding it. Models with this property are termed\nautoregressive. In practice, however, simple recurrent neural networks struggle to maintain this\nstate persistence or coherence throughout longer input sequences and tend to “forget” previous\nwords. This phenomenon, commonly referred to as the vanishing gradient problem (Hochreiter,\n1991), is discussed in detail in Bengio et al. ( 1994).\nLong short-term memory models (LSTM; Hochreiter & Schmidhuber, 1997; Jozefowicz et\nal., 2015) expand on the recurrent neural network architecture and solve the problem of long-\ndistance dependencies , namely learning the relationships between words even if they are not in\nclose proximity. LSTMs work by passing state vectors (the output of the network from the previous\nstep) through a specialized structure that helps the model learn what information to remember or\nto forget. This structure uses gates to determine what information to add or to remove from the\nstate. By actively forgetting information when it becomes irrelevant and, likewise, selecting and\n754 PSYCHOMETRIKA\ncarrying important parts of the input data through to the next step, LSTMs have shown exceptional\nperformance in a wide variety of NLP tasks. We refer to Olah ( 2015) for a thorough introduction\nto LSTMs.\nWith these developments in language modeling in mind, it is reasonable that von Davier\n(2018) chose LSTM models for AIG and it is apparent why there could not have been fruitful\nattempts prior to these advances. Since von Davier’s seminal contribution, however, research\nin NLP has progressed substantially. Although LSTMs show better performance than traditional\nrecurrent neural networks in long-distance dependencies, they too suffer from vanishing gradients\nwhen given particularly long sequences and tend to require large amounts of hardware resources,\npreventing most researchers from being able to afford training larger models.\n0.2.4. Transformer Models and the Attention Mechanism One of the most recent and arguably\nsubstantial paradigm shifts since the initial advance of distributional semantics was sparked by\nthe introduction of the transformer model by Vaswani et al. ( 2017). Its model architecture holds\nnumerous advantages when applied to sequential data such as natural language. First, sequential\ndata can be processed in parallel by transformer models, reducing the resources required to train\nsuch a model. Sequential information (i.e., the order of words) is preserved by a process termed\npositional encoding, which engrains each word in a sentence with its intended sequential position.\nAs a consequence, larger and more competent language models can be trained. Second, and of\ncentral importance to the design, transformer models learn through a mechanism referred to as\nself-attention. In essence, self-attention refers to the concept of determining the relevance of a\nword in relation to the relevance of other words in the input sequence. We provide more details\non how attention is computed in the next section of this article. In particular, these two features\nallow the transformer model to learn long-range dependencies better than LSTMs.\nSince the publication of Vaswani et al.’s ( 2017) paper, a plethora of transformer imple-\nmentations have been released with various modiﬁcations. One typically distinguishes between\nbidirectional and unidirectional transformer models. Bidirectional models attempt to predict each\ntoken in a sequence by using tokens that both precede and succeed the current target. Tokens are\nsequences of characters in a particular vocabulary that are grouped together as a useful semantic\nunit (e.g. words, syllables, preﬁxes, punctuations, etc.; Manning et al., 2008). This makes such\nmodels suitable for tasks like binary text classiﬁcation or machine translation (Camacho-Collados\n& Pilehvar, 2018; González-Carvajal & Garrido-Merchán, 2021). Unidirectional models, how-\never, based their predictions of tokens in a sequence only on the set of preceding words, making\nthem autoregressive. They are therefore sometimes referred to as causal transformer models and\nhave proven themselves to be exceptionally useful in various applications in the domain of text\ngeneration.\nAs noted by Vaswani et al. (2017), self-attention shows better computational performance than\nrecurrent techniques (i.e., LSTMs) when the input sequence is smaller than the dimensionality of\nthe word representation. It has become common practice for research teams to release transformer\nmodel implementations that have been pretrained on exceedingly large general language datasets.\nIf such a model is obtained, one can easily perform additional training on a more task-speciﬁc\ndataset in a process known as ﬁne-tuning (Howard & Ruder, 2018). During ﬁne-tuning, the weights\nof the pretrained model will shift and bias the latent features toward a better representation of the\ntask-speciﬁc corpus. Notable releases of bi- and unidirectional transformer models include the\nBidirectional Encoder Representations from Transformers (BERT; Devlin et al., 2018) and the\nGenerative Pretrained Transformer (GPT; Radford et al., 2018). In early 2019, OpenAI released\nthe GPT-2 model (Radford et al., 2019) as the largest pretrained causal language model to that\ndate.\nGPT-2 received much attention due to its unparalleled ability to perform well across several\ndifferent NLP tasks, such as reading comprehension, translation, text summarization, and question\nHOMMEL ET AL. 755\nanswering. Furthermore, numerous examples have demonstrated GPT-2’s ability to generate long\nparagraphs of text that have a startling level of syntactic and semantic coherence. It is important\nto note that the effectiveness of GPT-2 is not due to any major modiﬁcations to the original\ntransformer architecture, but can largely be attributed to increased processing power and the data-\nset used to train the model. Speciﬁcally, the model was trained on a 40-gigabyte corpus obtained\nby systematically scraping 8 million web documents. In total, OpenAI has released four versions\nof GPT-2, with the largest model possessing a 48-layer decoder block consisting of 1.5 billion\nparameters, embedding words in a 1600-dimensional ambient space (Radford et al., 2019).\n1. Proposed Method\nAlthough pre-trained transformer models are capable of generating fairly coherent bodies\nof text, it is oftentimes desirable to specialize their linguistic capabilities for speciﬁc application\ndomains. The process of applying previously attained knowledge to solve a related family of\ntasks is referred to as transfer learning, and is especially powerful for applications with scarce\ntraining data (Zhuang et al., 2020). The underlying assumption is that neural networks learn\nrelatively universal representations in the early layers that are good low-level features for a large\nfamily of related tasks. The general nature of these low-level features suggests that it should be\npossible to reuse them for related tasks, reducing the amount of training time or data required\nto derive specialized models from a general one. Utilizing pre-trained transformer models for\nconstruct-speciﬁc AIG therefore requires ﬁne-tuning them for the task of concept elaboration.\nTransformer models learn by taking the positionally encoded embeddings x\ni (as explained in\nSect. 0.2.2) for each token i of a sequence of length n. The length of the embedding vectors xi ,t h e\nmodel dimensionality, is dependent on the language model used with typical values ranging from\nd = 768 to 1,600 in the case of GPT-2. These vectors are then multiplied with weights matrices\nto calculate the attention vectors zi for each token i. Each element in zi is an attention weight that\nreﬂects the relevance of each other token in the sequence in relation to the current token i.\nSpeciﬁcally, the attention vector zi = zi,1,..., zi,n for token i is calculated on the basis\nof the vectors qi = qi,1,..., qi,n, ki = ki,1,..., ki,n and vi = vi,1,...,v i,n. These vectors are\nobtained by xi · Wq|k|v where W are weight matrices that are randomly initialized or learned and\npropagated by previous layers. While qi can be understood as an abstraction of the input values,\nki are respective abstractions of all other embeddings in the context with vi as associated values.\nThese vectors are obtained for each token in a given sequence and the attention matrix Z is then\nbased on the aggregate matrices Q, K , V :\nZ = σ\n( QK T\n√n\n)\n· V (3)\nwhere σ is a softmax transformation for each vector of the input matrix, with length of n.\nWhile typically τ = 1 is for regular softmax, it is sometimes used as a parameter to transform\nthe probability distribution for multinomial sampling:\nσ (a) = e\na\nτ\n∑ n\ni=1 e\nai\nτ\n(4)\nThe resulting attention matrix Z is a square n×n matrix containing attention weights between\nall the input tokens in the sequence.\n756 PSYCHOMETRIKA\nFigure 1.\nSchematic Diagram of the Attention-Mechanism and Components of the Transformer Architecture. Note. The process\nillustrates the encoding and transformation of the sequence “ walks by river bank ” by components of the transformer\narchitecture (Vaswani et al., 2017). Weight matrices ( W h\nm, K |Q|V and Wm ) are randomly initialized and then learned\nduring the training process. In case of causal language models, masking (see Eq. 5) is applied to Zhm .( a ) = Matrix product\nof K hT\nm and Qhm ; (b) Scaling and softmax is applied; n = Input sequence length; d = Model dimensionality, i.e., length of\nembedding vectors; h = Current attention head; nh = Number of attention heads; m = Current layer; Xm = Embedding\nmatrix ( dimensionality : n × d); Xhm = Embedding matrix subset ( n × d\nnh ); W h\nm, K |Q|V = Key, query, and value\nweight matrices ( n × d\nnh ); K hT\nm = Transposed key matrix ( n × d\nnh ); Qhm = Query matrix ( n × d\nnh ); V hm = Value matrix\n(n × d\nnh ); Zm = Attention matrix ( n ×d); Wm = Weight matrix (n ×d); Lm = Layer output matrix ( n ×d);–. = Matrix\nsubdivision; +. = Matrix concatenation.\nIn most architectures, including GPT-2, the vectors qi , ki , and vi are subdivided into multiple\nheads (h) before calculation of Z to allow the entire attention process described above to attend to\nmultiple parts of the sequence at the same time; the calculation of such attention heads is repeated\nmultiple times in parallel by concatenating the heads together into a single larger matrix. When\nusing multiple attention heads, it becomes necessary to multiply the concatenated multi-head\nattention matrix by an additional ﬁnal weight matrix in order to let the model learn through the\ntraining process how to map the multiple attention heads into a single homogenous attention\nrepresentation. In the ﬁnal step, this multi-headed self-attention matrix is subsequently normed\nand passed as a hidden state through a fully-connected neural network (Radford et al., 2019),\nbefore being output to the subsequent transformer layer. In this fashion, the above process repeats\niteratively as embeddings are passed on through the M layers of the transformer (i.e., 12 to 48\nlayers in the case of GPT-2). Figure 1 shows a schematic depiction of the central aspects of the\ntransformer architecture. Note that the model architecture depends on additional components,\n(e.g., positional encoding), which are, however, not central to this paper.\nAs described above, however, the attention for each token could include all other tokens in the\nsequence, resulting in bidirectional predictions. As previously explained, causal language models\naim to predict tokens by only evaluating preceding tokens. Therefore, the self-attention must be\nHOMMEL ET AL. 757\nmasked to form a lower triangular matrix:\n∀zi, j ∈ Z : j ≤ i ⇒ zi, j =− ∞ (5)\nWhere i is the position of a token in the sequence, j is the iteration for j ≤ i, and −∞ is used\nrather than zeroing so that after the softmax operation the corresponding entries in the output\nattention vector will be zeroed.\nOnce training is completed, tokens can be predicted by multiplying the output vectors of the\nﬁnal transformer layer with the matrix of all embedding vectors x for the entire vocabulary and\nthen a ﬁnal softmax operation is performed to ensure that the output is a probability distribution.\nA sequence of words can then easily be generated either by deterministic querying or sampling by\nusing various hyperparameters. One typically distinguishes between two generative modalities\nwhen using transformers for causal language modeling. In unconditional sampling, the model\ngenerates a sequence of tokens based merely on a decoding method that governs how tokens are\ndrawn from a probability distribution. In conditional sampling, the output is additionally based on\na ﬁxed, predeﬁned token or token sequence. Loosely speaking, conditional generation works by\ntriggering the transformer models’ associations to a given input. While decoding methods permit a\ncoarse way of controlling from what part of the probability distribution tokens are sampled, they do\nnot grant explicit semantic output manipulation. We therefore subsequently propose a technique\nfor the indirect parameterization of causal language models that allows for construct-speciﬁc AIG.\nTo leverage the capacity of pretrained language models such as GPT-2, it is conventional\nto perform additional training on data that is close to the target domain. In the case of AIG for\npersonality items, the training data must naturally consist of items from validated personality test\nbatteries. One possibility is ﬁne-tuning models to only be capable of generating a narrow selection\nof items that represent a single ﬁxed construct. Since this is an undesirable prospect, the goal must\nbe to ﬁne-tune a model to more generally traverse the manifold of possible item-like sequences\nwhile being guided toward speciﬁc construct-clusters. Conversely, if tokens in the beginning of\na sequence are representative of a latent construct, they may be used to prompt the completion\nof a sentence which may also be indicative of the construct. Transformer models may then be\ntrained to pay privileged attention to such indicative tokens. Sampling from a transformer model\ntrained in this way would yield a closer approximation of Eq. 1. It is common practice to achieve\nthis goal indirectly by combining special input formatting during ﬁne-tuning with conditional text\ngeneration (e.g., Rosset et al., 2020). The special input formatting teaches the model to conform\nto a segmented pattern concatenated by delimiter tokens. This pattern is then partially prompted in\nconditional generation and extrapolated by the model output. In the context of construct-speciﬁc\nAIG, we propose a training pattern where φ is the function encoding the construct ψ and the item\nstem ι by a concatenation ( ◦) of strings:\nφ(ψ, ι) = u\nA\n1 ◦ c1 ◦···◦ u A\nm ◦ cm ◦ uB ◦ w1 ··· wn (6)\nIn this pattern, the single character delimiter tokens u A separate m construct labels and uB separates\nthe concatenated construct labels from a sequence of n words (w) that constitute the item stem. The\nresult is a string, consisting of one or multiple short descriptive labels of psychological constructs\nseparated by delimiter tokens, followed by a statement that is indicative of those constructs (e.g.,\nsuch a string might look like: “#Anxiety#Neuroticism@I worry about things”). Fine-tuning a\npre-trained causal transformer model with data in this format permits later querying φ(ψ) in\nconditional generation to return a sequence ι that is heuristically related to the construct labels.\nFine-tuning the transformer to this pattern results in changes to its model weights. These\nshifted weights tend to represent transformations that best capture the context of the tokens before\n758 PSYCHOMETRIKA\nthe delimiter token. How well it can do this is measured by forcing the transformer to attempt\nto generate the expected set of training items from the associated construct labels. The general\nconcept of the uncertainty with regard to these attempts is termed perplexity, and in transformers\nis measured by the cross-entropy loss. The classiﬁcation error is calculated for each token for its\ndeviation from the predicted token and combined for the overall expected sequence. The loss is\nthen back-propagated and the learning algorithm makes small changes to the model weights. This\nresults in slight changes to the family of transformations it represents that grow over time into\nlarger changes, biasing the family increasingly toward those that best encode the transformation\nequivalent to a very approximate form of concept elaboration. However, in practice, it works well\nenough to provide a practical tool for AIG.\n2. Workﬂow and Illustration\nWe demonstrate implicit parameterization by illustrating how training data is encoded and\nGPT-2 ﬁne-tuned to the downstream task of construct-speciﬁc AIG. In doing so, we hope to\nguide researchers and practitioners in a tutorial-like fashion and to motivate them to explore the\npromising interdisciplinary domain of NLP applied to a psychometric context. Note that this\nprocedure is expected to work similarly for any causal transformer model or more generally any\nautoregressive model. We recommend the use of the transformers Python package (Wolf et al.,\n2020) for ﬁne-tuning or text generation using a wide variety of transformer models. Pretrained\nGPT-2 models in various sizes can be obtained via the package. At the Open Science Framework\n(OSF) at https://osf.io/3bh7d/, we provide an online repository with an example training data set,\nas well as Python code accompanying this section. Readers who wish to replicate our method will\nﬁnd references to source lines of code (SLOC) for ﬁne-tuning the model (example_ﬁnetuning.py)\nand item generation (example_generation.py) in the remainder of this section.\nIf one wishes to ﬁne-tune GPT-2 for the generation of construct-speciﬁc personality items, a\npossible large dataset of validated items must be acquired (see SLOC #27). This dataset must then\nbe encoded according to the segmented training pattern previously described (see Eq. 6;S L O C\n#33). Figure 2 shows how the encoding scheme for the previously referenced exemplary items\n“I am the life of the party ,” intended to assess extraversion, and “I worry about things,” intended\nto assess neuroticism and anxiety. As delimiter tokens we chose single ASCII characters that are\ninfrequently used in writing.\nBefore commencing ﬁne-tuning, a tokenizer is used to disassemble the encoded training\ndata for smaller units corresponding to tokens in the models’ vocabulary (see SLOC #42). This\nresults in a vector of integers, where each integer represents a token in the vocabulary. It may\nbe meaningful to add all construct labels to the vocabulary in advance, so that these are learned\nas a single unit during ﬁne-tuning (see SLOC #46). Considerations with regard to additional\nﬁne-tuning modalities must be made, such as determining learning rates, choosing optimization\nalgorithms, or termination criteria but are not exclusively pertinent to language modeling and will\ntherefore not be further discussed in this article (see SLOC #54).\nOnce ﬁne-tuning is performed, the partial pattern ( φ[ψ], see Figure 2, SLOC #13) can be\nused as a prompt in conditional generation. Generation will consequently yield item stems that are\nheuristically in the semantic vicinity of the requested construct labels, even if a requested construct\nlabel was not in the ﬁne-tuning dataset. When using language models for text generation, multiple\nsearch heuristics can be applied that directly inﬂuence next word inference. Although a multitude\nof such techniques are conceivable, we will in the following discuss three frequently applied\nmethods, namely greedy search , beam search , and multinomial sampling . The arguably most\nstraightforward approach to text generation is to use a greedy search strategy (SLOC #17), in\nwhich inference is based on nothing but the highest probability token for each prediction step.\nHOMMEL ET AL. 759\nFigure 2.\nIllustration of the Workﬂow of the Proposed Method for Construct-Speciﬁc Automatic Item Generation. Note. Workﬂow\nfor (a) ﬁne-tuning a causal transformer model using the proposed segmented training pattern, and (b) applying the partial\npattern to prompt a causal transformer for the generation of construct-speciﬁc item stems. The depicted transformer shows\nthe 12-layer decoder architecture of the Generative Pretrained Transformer adopted from Radford et al. ( 2018), although\nthe workﬂow in principle is agnostic to what causal transformer architecture is chosen.\nFor construct-speciﬁc AIG, this is the conditional probability of a word at prediction step k\ngiven a history of words that contains the linguistic manifestation of a given latent variable. Text\ngenerated using greedy search may suffer from repeating sub-sequences (Suzuki & Nagata, 2017)\nand may produce sentences that either lack ingenuity or exhibit an overall low joint probability.\nIn contrast, beam search may reduce the risk of generating improbable sequences by comparing\nthe joint probability of n alternative sequences (i.e., beams; SLOC #32) and selecting the overall\nmost probable sentence (Vijayakumar et al., 2018). Figure 3 illustrates the differences in the case\nof construct-speciﬁc AIG for these two search heuristics.\nWhereas greedy and beam search result in deterministic output and arguably fairly prototyp-\nical items, multinomial sampling (SLOC #49) comprises a variety of methods that accomplish\ntext generation by sampling from the probability distribution of words, which oftentimes is trans-\nformed beforehand. In practice, this not only results in a larger pool of potential items but also\nmirrors human language more accurately, as argued by Holtzman et al. ( 2019). Multinomial\nsampling should be used if the goal is to generate a larger set of items.\nThree common schemes are frequently used to transform the probability mass of the dis-\ntribution when applying multinomial sampling. In top-k sampling, the probability mass for next\nword prediction is redistributed from the entire vocabulary to the k words with the highest prob-\nability (Fan et al., 2018). This effectively eliminates the risk of sampling words at the tail of the\ndistribution while arguably permitting variations that are somewhat plausible. Nucleus sampling,\nalso known as top-p sampling, may be used to improve the performance of top-k by allowing the\ncut-off to adjust dynamically to the distribution. Nucleus sampling also truncates the probabil-\nity distribution, but instead of redistributing probabilities to the top k words, it prunes based on\nthe cumulative probabilities of words before reaching a threshold (Holtzman et al., 2019). For\n760 PSYCHOMETRIKA\nFigure 3.\nDifferences in Search Heuristics for Generated Items and Tokens. Note. Item generation after ﬁne-tuning when prompted\nfor the construct label Pessimism, using various search heuristics. (a) greedy search; (b) beam search with n = 3 search\nbeams, dashed lines indicate lower total sequence probabilities; (c) to (g) show next-token probabilities for the premise\n“#Pessimism@I am ” on the y-axis; (c) multinomial sampling with no transformation; (d) multinomial sampling with\ntop-k = 10; (e) multinomial sampling with nucleus sampling at top-p = .7; (f) multinomial sampling with temperature\n= 0.5; and (g) multinomial sampling with temperature = 1.5.\ninstance, the example “e)” in Figure 3 shows a truncated probability distribution of 17 possible\nnext-token predictions for the given preﬁx “ #Pessimism@I am.” The cumulative probability of\nthese tokens amounts to ≤ 70%, thereby prohibiting that improbable will be sampled. The top-k\nand top-p sampling schemes, however, maintain the shape of the distribution which either may\nbe heavily skewed and thereby too predictable, or too uniform to produce a coherent sentence\nor item. This can be rectiﬁed, independently from top-k or top-p sampling, by a modiﬁcation\nto the softmax transformation (see Eq. 4) which magniﬁes or suppresses the modalities of the\ndistribution by manipulating the τ coefﬁcient. This parameter is referred to as temperature (e.g.,\nWang et al., 2020) and is a useful utility for controlling the “creativity” of the generated output\n(see Figure 3). Higher values for τ will yield a more uniform probability distribution of next-word\npredictions and thus favor variety.\n3. Empirical Study\nTo test the proposed method, we compared human- and machine-authored items within a\nquestionnaire in an online survey, similar to von Davier ( 2018). However, the generation of\nconstruct-speciﬁc items requires additional considerations with regard to structural validity. Data,\ncode, and generated items accompanying this study are available from https://osf.io/3bh7d/.N o t e\nthat this repository also contains Python code to replicate the methods proposed in this paper. In\naddition, we provide a web application demonstrating construct-speciﬁc automatic item generation\non https://cs-aig-server-2uogsylmbq-ey.a.run.app/\n1.\n1 An up-to-date link is provided in the online repository.\nHOMMEL ET AL. 761\n3.1. Model Fine-Tuning and Item Generation\nWe obtained a pretrained 355 million parameter GPT-2 model with the goal of ﬁne-tuning it to\nconstruct-speciﬁc AIG 2. Out of the 4452 item stems and 246 construct labels in the International\nPersonality Item Pool 3 (Goldberg, 1999; Goldberg et al., 2006), we selected 1715 unique item\nstems grouped by associated construct labels with a mean of 2.40 ( SD = 1.84) labels for each\nstem. This dataset served as training data to subsequently ﬁne-tune the 335M to the AIG task\nand was fed as delimited concatenated strings of construct labels and item stems as previously\ndescribed in Eq. 6. Training was performed on a Nvidia GeForce RTX 2070 Super using the\nCUDA 9.1.85 and cuDNN 7.6.3 toolkits with TensorFlow 1.14.0 (Abadi et al., 2016) and Python\n3.6.9 by an adaptation of GPT-2-Simple (Woolf, 2020) on Linux Ubuntu 18.04.4. Fine-tuning\nwas terminated after 400 training steps with a learning rate of 5e-04 at ﬁnal cross-entropy loss\nof 0.83. A full list of example items generated during the ﬁne-tuning process can be found in the\nOSF repository.\nWe then prompted the model to generate item stems for two sets of construct labels in condi-\ntional generation. The ﬁrst set consisted of ﬁve trained construct labels ( openness to experience ,\nconscientiousness, extraversion, agreeableness, and neuroticism) which were introduced to the\nmodel in the training dataset during ﬁne-tuning. The second set in turn consisted of ﬁve untrained\nconstruct labels (i.e., benevolence, egalitarianism, egoism, joviality, and pessimism) that were not\nintroduced during ﬁne-tuning. In total, we generated 1,360 item stems associated with one of these\nconstruct labels. All items were generated using multinomial sampling with varying temperatures\n(0.7, 0.9; and 1.1) to increase the variability of the item pool. We refrained from using top-k or\ntop-p sampling to sample from the full probability distribution of tokens.\n3.2. Overﬁt\nOverﬁtting is a major obstacle and common phenomenon in training deep neural networks\n(Srivastava et al., 2014). Instead of learning abstract features, an overﬁtted model will tend to\nreproduce the original training data. We assessed an index of string similarity between the data\nused for model ﬁne-tuning and the model‘s generated output as a proxy measure for model overﬁt.\nCoefﬁcients were calculated by inverting and normalizing the Levenshtein distance (Levenshtein,\n1966) between two item stems, which theoretically may range from 0 to 1, whereas the latter\nindicates an exact match between item stems. In essence, this metric reﬂects the number of single\ncharacter insertions, deletions, or substitutions one must make for two strings to become identical.\nWe regarded item stems with a similarity index ≥ .90 as being largely identical to the training\ndata and thus symptomatic of overﬁt. As most statistical thresholds are picked rather arbitrarily,\nwe carefully chose a cut-off value based on qualitative judgment. For example, the similarity\ncoefﬁcient between the generated item, “I like to be the center of attention,” and the IPIP item,\n“I love to be the center of attention,” amounts to .95 and thus the item was discarded, whereas\nthe similarity between “I am easily angered” and “I am easily annoyed” was below the threshold\nat .85. A full list of similarity indices for each generated item stem can be found in the OSF\nrepository, including a reference to the most similar item in the training data. The mean similarity\nbetween the generated items and the most similar items in the training data was .68 ( SD = .16),\nwith 164 items (12.0%) exceeding the similarity threshold of .90 and, thus, were omitted from\nthe dataset.\n2 Retrieved April 28, 2020, from https://storage.googleapis.com/gpt-2/models/335M/via https://github.com/openai/\ngpt-2/blob/master/download_model.py\n3 Retrieved on the April 22, 2020, from https://ipip.ori.org/\n762 PSYCHOMETRIKA\n3.3. Content V alidity\nWe further omitted duplicate items and items that were labeled with more than one construct\ndown to a selection of 283 items. Items were subsequently rated for content validity by two\nindependent expert judges who were carefully instructed to only rate items as valid if they (a)\nconsidered the item stem to be syntactically and linguistically correct and (b) regarded the item\nstem to be either clearly symptomatic or clearly asymptomatic (in case of reversed items) of the\nlatent variable described by the construct label. The items were rated with an agreement of .72\n(95% CI [.64, .80]) as indicated by Cohen’s kappa. A total of 151 (53.4%) items were endorsed\nby both raters for content validity. While Table S1 in the online supplemental section provides\nsome examples of content valid and rejected items, a data ﬁle with the full list of accepted and\nrejected generated item stems can be found in the OSF repository.\n3.4. Questionnaire\nTo properly assess the psychometric properties of the generated items, we derived a Likert-\nstyle questionnaire consisting of both human- and machine-authored items. From the remaining set\nof 151 machine-authored items unanimously endorsed for content validity, we randomly selected\n5 items for each construct label. This resulted in 25 CLIS-tuples for the ﬁve trained construct labels\nand 25 CLIS-tuples for the ﬁve untrained construct labels. We decided to include only a random\nselection of 50 items into the questionnaire to prevent fatigue in respondents and to safeguard\ndata quality. As for the set of human-authored items, we used the 25 items from the BFI dataset in\nthe R psych-package (version 2.0.9; Revelle, 2020, based on Goldberg, 1999; not to be confused\nwith the Big Five Inventory by John et al., 2012). The BFI is composed of established items taken\nfrom the IPIP and reﬂects the Big Five factors (i.e., openness to experience , conscientiousness,\nextraversion, agreeableness, and neuroticism).\n3.5. Participants and Procedure\nThe ﬁnal questionnaire consisted of 75 human- and machine-authored items using a 5-point\nLikert scale and was converted into an online survey. We recruited 273 participants through\nAmazon Mechanical Turk in exchange for $0.50 upon completion. Items were presented in a\nrandomized order. We used two measures to identify and exclude potential careless responders.\nFirst, we included 3 bogus items in accordance with the recommendations by Meade and Craig\n(2012), which instructed participants to pick a certain response option on the presented scale.\nSecond, we excluded participants with unreasonable response speed based on a relative-speed\nindex ≥ 2.0 (Leiner, 2019). This resulted in a ﬁnal sample of 220 respondents.\n3.6. Results\nWe ﬁrst tested the equivalence between human- and machine-authored items for trained\nconstruct labels at the scale level. Models were computed using conﬁrmatory factor analysis\n(CFA) with polychoric correlations and robust weighted least square mean and variance adjusted\n(WLSMV) estimators, which have been shown to produce accurate estimates for ordered cate-\ngorical items with even small samples (Flora & Curran, 2004). The ﬁt statistics are reported in\nTable 1. CFA model ﬁt was overall similar for machine-authored and human-authored scales,\nwith better ﬁt for machine-authored conscientiousness and extraversion items and better ﬁt for\nhuman-authored agreeableness and neuroticism items. Especially the ﬁt for the machine-authored\nagreeableness scale was strikingly poor (CFI = .80, RMSEA = .27). Here we found the low ﬁt\nto be due to correlated residuals between the item pairs “I care a lot about others” and “I am not a\nnice person” on one hand, and “I am easily angered” and “I am not easily offended” on the other.\nHOMMEL ET AL. 763\nTable 1.\nComparison of Conﬁrmatory Factor Analyses of Human- and Machine-authored Scales for Trained Construct Labels\nHuman-authored Machine-authored\nScale CFI RMSEA λmean λrange ωω CI CFI RMSEA λmean λrange ωω CI p\nOpenness to experience .95 .14 .62 [.82, .72] .72 [.65, .78] .95 .10 .54 [.44, .75] .66 [.66, .58] .097\nConscientiousness .93 .23 .72 [.74, .81] .81 [.76, .85] 1.00 .00 .44 [.15, .69] .46 [.46, .36] <. 001\nExtraversion .98 .15 .77 [.89, .86] .86 [.82, .89] 1.00 .05 .67 [.34, .90] .75 [.75, .68] <. 001\nAgreeableness .96 .17 .73 [.86, .80] .80 [.75, .85] .80 .27 .58 [.35, .87] .63 [.63, .49] <. 001\nNeuroticism .99 .13 .80 [.91, .87] .87 [.84, .90] .98 .17 .56 [.02, .92] .70 [.70, .61] <. 001\nNote. N = 220 respondents. λmean = Mean of standardized factor loadings; λrange = Range of standardized factor loadings; ω = Omega coefﬁcient of internal\nconsistency; ωCI = percentile bootstrapped 95% conﬁdence interval for omega coefﬁcient. p = bootstrapped probability of models’ differences in omega coefﬁcients\n(K = 5, 000 bootstrapped resamples; data from k = 446 iterations were omitted due to failed model convergence).\n764 PSYCHOMETRIKA\nThese correlated residuals can be explained by the comparatively high semantic similarity of the\nrespective items.\nWe used McDonalds’s omega coefﬁcient of internal consistency to assess reliability, which\nranged between .72 ( openness to experience, 95% CI [.65, .78]) and .87 ( neuroticism, 95% CI [.84,\n.90]) for human-authored, and .46 ( conscientiousness, 95% CI [.36, .57]) and .75 ( extraversion,\n95% CI [.68, .81]) for machine-authored items. We bootstrapped omega coefﬁcients and corre-\nsponding conﬁdence intervals in 5,000 iterations for each scale to compare human- and machine-\nauthored items and found signiﬁcantly smaller reliabilities for machine-authored items for all Big\nFive dimensions with the exception of openness to experience ( ω\nhuman = .72, ωmachine = .66,\np = .097).\nFor a better understanding of the validity of speciﬁc machine-authored items, we next com-\npared factor loadings of each individual machine-authored item when added to a model with ﬁve\nhuman-authored items of their respective scale. As depicted in Table 2, a total of 8 machine-\nauthored items (32%) exhibited factor loadings greater or equal to those of their human-authored\ncounterparts. Moreover, 16 items (64%) exceeded the commonly referenced cut-off value of\n.40 (e.g., Hinkin, 1995). In summary, we found evidence that a substantial part of the machine-\nauthored items was as valid as human-authored items, but that other machine-authored items were\nnot suitable at all.\nFinally, we examined machine-authored items generated for untrained construct labels. As\nshown in Table 3, omega coefﬁcients indicated satisfactory to good reliability for three scales\n(benevolence; egalitarianism; pessimism), particularly when considering the small number of\nitems per scale, and ﬁt statistics also indicated satisfactory to good model ﬁt. In contrast, model\nﬁt statistics and reliability estimates for egoism and joviality were not satisfactory. As shown in\nTable 4, at the item level a total of 19 items (76%) exceeded factor loadings of .40 in conﬁrmatory\nfactor analyses.\nNext, we sought to discern the latent structure of the untrained item set using exploratory factor\nanalysis (EFA) with polychoric correlations and oblique rotation. We expected that this structure\nwould reﬂect a ﬁve-factor solution, corresponding to the ﬁve untrained construct labels that we\nhad requested from the ﬁne-tuned GPT-2 model. In line with this expectation, parallel analysis\nsuggested a 5-factor solution. The loadings matrix of the subsequent EFA showed generally\ndistinct loadings for conceptual items for benevolence, egalitarianism and pessimism (see results\nprovided in Table S2 in the online supplemental material). The ﬁfth factor appeared to be rather\nspeciﬁc and absorbed items that poorly ﬁtted to the respective conceptual scales, as indicated by\nrelatively low proportional variance and heterogenous loading patterns.\n4. Discussion\nThis paper offers a comprehensive examination of how deep learning language modeling\ncan be used to automatically generate valid personality items that measure speciﬁc constructs.\nTo achieve this, we utilized a popular pretrained transformer model, GPT-2, by ﬁne-tuning it\nusing the International Personality Item Pool (Goldberg et al., 2006). In doing so, we expand on\nwork by von Davier ( 2018) in which Long Short-Term Memory Models were trained to create\nsyntactically correct items.\nOur primary contribution emphasizes construct-speciﬁc automated item generation, show-\ning that it is possible to align item stems to speciﬁc constructs and to classify unconditionally\ngenerated item stems with correct construct labels. To achieve this, we taught GPT-2 a pattern by\nconcatenating strings of personality statements with labels corresponding to constructs for which\nthe items were conceptualized. By learning this pattern, we anticipated that the model would\nrespond by generating valid item stems when prompted by a given construct label. We considered\nHOMMEL ET AL. 765\nTable 2.\nDescriptive Statistics and Factor Loadings of Machine-authored Items for Trained Construct Labels\nItem MS D Frequencies Skewness Kurtosis λ ∈ λhuman\n1234 5\nI can enjoy a wide variety of musical styles.\n(OPE+)\n4.10 1.05 7 13 30 71 99 −1.16 0.76 .62 1\nI like to be surprised. (OPE +) 3.13 1.32 32 39 61 45 43 −0.10 −1.08 .36 0\nI love to contemplate the universe and its\nbeauty. (OPE+)\n3.94 1.12 9 15 46 60 90 −0.87 −0.04 .65 1\nI like to be with people who are different\nfrom myself. (OPE +)\n3.50 1.06 9 25 75 68 43 −0.32 −0.43 .35 0\nI am not a fan of change. (OPE-) 3.11 1.32 29 47 61 36 47 0.00 −1.13 .35 0\nI am not always on time for work. (CON-) 4.01 1.28 12 28 21 43 116 −1.02 −0.29 .53 0\nI know that I make many mistakes. (CON-) 2.53 1.20 53 61 57 35 14 0.35 −0.84 .20 0\nI work too hard. (CON +) 3.17 1.28 25 45 62 44 44 −0.07 −1.05 .55 0\nI do not like to read or study. (CON-) 4.23 1.04 8 8 27 59 118 −1.44 1.55 .54 0\nI am not concerned with details. (CON-) 4.27 0.95 4 10 23 68 115 −1.39 1.57 .65 0\nI am able to speak conﬁdently. (EXT +) 3.96 1.11 8 18 37 69 88 −0.92 0.06 .84 1\nI avoid public places. (EXT-) 3.50 1.28 21 31 44 66 58 −0.50 −0.85 .46 0\nI am able to handle myself in a crowd.\n(EXT+)\n3.98 1.07 8 15 34 79 84 −1.02 0.44 .73 1\nI do not like to talk about myself. (EXT-) 2.59 1.25 50 65 52 32 21 0.41 −0.84 .45 0\nI am able to hold my own in a discussion.\n(EXT+)\n4.16 0.97 6 11 19 90 94 −1.37 1.74 .60 1\nI care a lot about others. (AGR +) 4.25 0.92 4 5 34 67 110 −1.23 1.30 .87 1\nI am easily angered. (AGR-) 3.96 1.17 11 19 31 65 94 −1.00 0.07 .39 0\nI don’t like to argue. (AGR +) 3.95 1.14 10 17 38 65 90 −0.94 0.05 .23 0\nI am not easily offended. (AGR +) 3.43 1.25 16 45 38 71 50 −0.36 −1.00 .24 0\nI am not a nice person. (AGR-) 4.51 0.84 3 5 17 47 148 −1.95 3.83 .79 1\nI am generally happy and content. (NEU-) 2.15 1.19 82 70 36 18 14 0.91 −0.07 .72 0\nI am often upset by minor things. (NEU +) 2.30 1.23 72 69 33 34 12 0.64 −0.71 .89 1\nI am a person who is easily moved by\nthe good moods and bad moods of others.\n(NEU+)\n3.47 1.23 22 24 52 73 49 −0.55 −0.63 .28 0\nI am generally cheerful and optimistic.\n(NEU-)\n2.30 1.26 72 67 43 18 20 0.76 −0.42 .69 0\nI seldom feel scared. (NEU-) 3.01 1.28 30 57 45 56 32 0.00 −1.15 .38 0\nNote. Based on data from N = 220 respondents. λ = Standardized factor loading in a CFA model with\nthe ﬁve human-authored items and the respective machine-authored item; ∈ λhuman = Factor loading of\nrespective machine-authored item within the range of factor loadings for human-authored scales (1 = within\nthe range); OPE = Openness to experience; CON = Conscientiousness; EXT = Extraversion; AGR =\nAgreeableness; NEU = Neuroticism; +/- indicates positive or negative keying.\nthis task to be the inverse problem of text summarization since it requires a model to elaborate on\na concept. As we outlined in the introductory section of this paper, this can only be achieved by\nlanguage models which are able to learn the relationship between words beyond close proximity.\nTransformer models excel at long-distance dependencies and it is conceivable that GPT-2 is the\nﬁrst model that is capable of the construct-speciﬁc generation of personality items. The ability\nto adapt to patterns such as the segmented training pattern used in this paper is an important\nprerequisite for AIG because it permits an agent to exert control over the generated output after\n766 PSYCHOMETRIKA\nTable 3.\nGoodness of Fit Statistics, Factor Loadings and Reliability Estimates of Conﬁrmatory Factor Analyses of Machine-\nauthored Scales for Untrained Construct Labels\nScale CFI RMSEA λmean λrange ωω CI\nBenevolence 1.00 .05 .69 [.49, .94] .74 [.67, .79]\nEgalitarianism .99 .09 .76 [.67, .87] .78 [.69, .85]\nEgoism .90 .12 .44 [.08, .85] .58 [.47, .67]\nJoviality .83 .16 .44 [.17, .92] .54 [.42, .62]\nPessimism .99 .11 .70 [.45, .93] .82 [.77, .86]\nNote. N = 220 respondents. λmean = Mean of standardized factor loadings; λrange = Range of standardized\nfactor loadings; ω = Omega total coefﬁcient of internal consistency; ωCI = bootstrapped 95% conﬁdence\ninterval for omega coefﬁcient, based on K = 5, 000 bootstrap iterations.\nﬁne-tuning is completed. The successful adaptation of GPT-2 to the segmented training pattern\ntherefore not only fulﬁlls the basic requirements for meaningful AIG applications, but also implies\nthat additional perhaps more complex patterns could be learned.\nIn addition to this conceptual contribution, we conducted an empirical study to examine how\nautomatically generated items fared when assembled into a personality questionnaire. We studied\ntwo groups of items to test the structural validity of machine-authored items. One set consisted of\nitems generated for construct labels which GPT-2 had learned during ﬁne-tuning, while the other\nset comprised items authored for construct labels that were not introduced earlier. Our results\nshowed that neither set of items is comparable in structural validity to what should be expected\nfrom a psychometrically sound personality questionnaire. Yet approximately one third of the\nmachine-authored items for untrained construct labels showed sizable factor loadings in the same\nrange as those of human-authored items of the same scale. More than half of these items even met\nor exceeded cut-off values commonly used by scale developers. Additionally, several items of\nthe set of items generated for untrained construct labels exhibited satisfactory scale statistics. For\nexample, 76% showed factor loadings above .40 and in three out of ﬁve scales, internal consistency\nexceeded coefﬁcients of .70. Considering that generated items were in competition with items\ndeveloped through years of research, we deem these results highly encouraging.\n4.1. Limitations\nAlthough the capabilities of modern pretrained causal transformers are quite formidable, some\nrestrictions remain that limit their applicability to AIG. Most notably, the quality of items generated\nwith our method is currently difﬁcult to predict. As some items generated by our model were\nqualitatively and psychometrically inferior to human-authored items, any practical application\nwould currently require expert oversight. This is also necessary to avoid that semantically very\nsimilar items are selected, a problem that we observed in our study for the agreeableness scale,\nand which resulted in poor model ﬁt due to correlated residuals. Human-in-the-loop systems are\nquite common in machine learning (Chai & Li, 2020) and may be a tolerable transitional solution.\nThis problem could perhaps be remedied by automatically evaluating semantic similarity in post-\nprocessing. Next, generated items tend to contravene item writing guidelines and psychometric\nprinciples. As such, we have frequently seen ﬁne-tuned models phrase double-barreled items, use\nnegations, or conﬂate multiple constructs within one item, violating unidimensionality (Nunnally\n& Bernstein, 1994). Perhaps this could be remedied by training a bidirectional classiﬁer model\n(e.g., a BERT-network; Devlin et al., 2018) to detect such violations. Such a penalty could be\nintegrated in the loss-function when ﬁne-tuning a language model to AIG. Moreover, we identiﬁed\ninadequate item difﬁculty as a dominant reason for poor item and scale statistics in machine-\nHOMMEL ET AL. 767\nTable 4.\nDescriptive Statistics and Factor Loadings of Machine-authored Items for Untrained Construct Labels\nItem MS D Frequencies Skewness Kurtosis λ\n1 234 5\nI care about others’ well-being. (BEN +) 4.41 0.76 2 1 21 77 119 −1.40 2.61 .78\nI forgive others. (BEN +) 3.85 1.09 9 19 39 82 71 −0.85 0.05 .55\nI am not a person who would do anything\nnice for anyone. (BEN-)\n4.57 0.79 2 6 12 44 156 −2.15 4.71 .66\nI have little sympathy for poor people.\n(BEN-)\n4.17 1.23 14 17 16 44 129 −1.38 0.70 .49\nI am not interested in others feelings. (BEN-\n)\n4.30 0.98 4 11 25 55 125 −1.41 1.36 .94\nI believe that the rights of others should be\ntreated equally. (EGA +)\n4.72 0.59 1 2 4 43 170 −2.78 10.18 .87\nI believe that all races are created equal.\n(EGA+)\n4.60 0.89 6 4 13 27 170 −2.52 6.09 .71\nI believe that it is wrong to exploit others for\nyour own gain. (EGA +)\n4.52 0.92 7 5 9 44 155 −2.35 5.37 .67\nI believe in the equality of all peoples.\n(EGA+)\n4.65 0.72 2 3 11 38 166 −2.49 6.95 .81\nI believe that the rights of others should be\nrespected without question. (EGA +)\n4.35 0.84 2 6 22 72 118 −1.38 1.88 .77\nI believe that I have the right to my own way\nof life. (EGO +)\n4.45 0.72 2 1 15 79 123 −1.57 3.69 .08\nI often exaggerate my achievements.\n(EGO+)\n1.94 1.11 97 74 25 13 11 1.24 0.84 .26\nI believe that I am the best. (EGO +) 2.57 1.35 67 44 50 35 24 0.34 −1.11 .85\nI believe that I have more power than others.\n(EGO+)\n2.20 1.17 78 63 46 22 11 0.71 −0.41 .60\nI am not overly proud of my achievements.\n(EGO-)\n3.28 1.32 26 41 49 54 50 −0.23 −1.11 .39\nI am very jovial. (JOV +) 3.37 1.18 15 37 65 57 46 −0.24 −0.83 .92\nI do things that are not fun. (JOV-) 3.34 1.23 16 41 69 41 53 −0.12 −\n0.99 .17\nI sometimes laugh out loud. (JOV +) 4.33 0.93 4 11 13 73 119 −1.61 2.39 .18\nIa mn e v e rs a d .( J O V+) 1.92 1.14 106 61 26 18 9 1.15 0.40 .39\nI am easily entertained. (JOV +) 3.62 1.06 12 17 58 88 45 −0.68 0.05 .55\nI am not likely to succeed in my goals.\n(PES+)\n1.90 1.13 110 54 33 14 9 1.15 0.46 .71\nI can see that things are never going to be\nthe way I want them to be. (PES +)\n2.72 1.33 51 50 57 33 29 0.26 −1.05 .52\nI am not optimistic. (PES +) 2.09 1.28 103 49 26 29 13 0.88 −0.51 .93\nI am always on the lookout for a better way.\n(PES-)\n1.99 0.97 79 83 44 9 5 0.90 0.55 .45\nI look at the bright side. (PES-) 2.23 1.25 79 69 32 23 17 0.83 −0.39 0.90\nNote. Based on data from N = 220 respondents. λ = Standardized factor loadings in a CFA model including\nthe ﬁve machine-authored items of the respective dimension; BEN = Benevolence; EGA = Egalitarianism;\nEGO = Egoism; JOV = Joviality; PES = Pessimism; +/- indicates positive or negative keying.\n768 PSYCHOMETRIKA\nauthored items. For example, all items generated for the egalitarianism construct label were\noverwhelmingly endorsed by respondents. Extreme difﬁculty is a likely symptom of a variety\nof potential causes, such as statements that are socially undesirable to endorse or reject (e.g., “ I\nbelieve that all races are created equal ”). It is important to ﬁnd ways to gain control over these\naspects to advance this line of research and to make practical applications of AIG feasible.\nWhile our proposed method solves concept elaboration in the case of AIG in the domain\nof personality, we have not offered any tangible advice on how the process of ﬁne-tuning causal\ntransformers can be optimized to improve our results. Here, a variety of enhancement measures are\nconceivable. In light of the dearth of openly accessible training data in the domain of personality\ntesting, perhaps data augmentation techniques similar to those conventionally applied in image\nrecognition can be applied (Perez & Wang, 2017). Moreover, researchers could attempt to optimize\nthe ﬁne-tuning process more directly, perhaps by modifying the objective function of the neural\nnetwork or by freezing the lower layers of the transformer (Lee et al., 2019; Lu et al., 2021).\nOn a more fundamental level, another obstacle is that we remain oblivious to the true size of\nthe problem space. As such, it is currently not possible to estimate the limits of GPT-2—or any\nother causal transformer model—with regard to our notion of concept elaboration. One simply\ncannot know in advance what level of precision or proportion of validity that can be achieved by\ncurrent technology given better training strategies or better training data. In addition, although we\nadvocated the use of multinomial sampling for the generation of larger item pools, techniques must\nbe derived to estimate the size of the universe of possible meaningful items that can be obtained\nfrom a model. In essence, since there is no theoretical reason to assume that probabilistic language\nmodels per se should be inferior to human test developers, deﬁciencies in item generation can\nonly be attributed to model architecture, pretrained model parameters, and ﬁne-tuning. Since the\nproportion of each of these components is likely to remain unknown, it is difﬁcult to judge how\nclose our results come to a model-speciﬁc optimum. This is problematic since it leaves future\nresearchers without means to determine if stagnation is due to inadequate methodology with\nregard to model ﬁne-tuning or because a language models’ potential has been exhausted.\n4.2. Future Directions for the Automatic Generation of Non-cognitive Items\nFuture developments in deep language modeling will likely continue to beneﬁt research and\nassessment technology for sequence-based AIG for personality items. As noted by a reviewer,\none might wonder in what use case it is desirable to obtain large quantities of personality items.\nThe primarily current practical utility of our proposed method is limited to a decision support\nsystem (Rosenbusch et al., 2020) for item authors, which in some cases may lessen the dependence\non content specialists. When constructing a scale, authors require a large item pool from which\nthey can select items with the best psychometric properties to cover the full breadth of a target\nconstruct. Even larger quantities of items are required in computerized adaptive testing (CAT),\nwhere test developers may use our approach with multinominal sampling, to obtain a large variety\nof potential items. Language models for non-cognitive AIG may be a valuable tool to expand the\noriginal item pool, improving the quality of scales. We demonstrate this use case by offering an\neasy-to-use internet tool at https://cs-aig-server-2uogsylmbq-ey.a.run.app/ for creating items for\na given construct, which can be used by scale authors without knowledge of computer science or\nAIG.\nFurthermore, it is important to note that deep language models not merely generate text, but\nalso derive embeddings that encode a richness of abstract information about the generated item.\nOperations on such vectors could lead to a host of potential improvements in scale development.\nFor example, measures of semantic similarity (Kjell et al., 2019; Rosenbusch et al., 2020) could\nbe integrated in the loss-function of a transformer model or perhaps even explicitly prompted\nHOMMEL ET AL. 769\nto enable test developers to specify a desirable distance to a target construct. This could permit\npsychometricians to control content coverage a priori to item development.\nWhile our research demonstrates that implicit parameterization can be used for item gener-\nation at the construct level, future work should attempt to expand on such parameterization to\ninclude psychometric properties. The highly promising prospect of using CAT in conjunction\nwith AIG has previously been discussed in the literature (Glas & van der Linden, 2003; Simms et\nal., 2011; Luecht, 2013). Sentence embeddings offer a potential extension of CAT to the domain\nof personality item generation, if difﬁculty estimates could be extracted from such embeddings.\nWhen this is achieved, it is conceivable that personality questionnaires could be assembled “just-\nin-time,” tailored to the individual test-taker, instead of maintaining large, static item banks, as\nusually required for CAT. This goal, distant as it currently may seem, may help guide the future\nresearch agenda in the ﬁeld of non-cognitive AIG. Such an agenda should primarily focus on two\naspects:\nFirst, language models must reliably produce valid items. In contrast to template-based AIG\ntechniques, this is more difﬁcult to attain when using probabilistic language models. Indeed, Bejar\n(2013) noted that “item generation and construct representation go hand in hand” (p. 43). This is\nmuch closer to the truth when using strictly algorithmic approaches to AIG, rooted in conventional\nitem modeling (Gierl et al., 2008). The heuristic nature of pretrained language models, however,\nobscures the relationship between output and construct, rendering such methods exceedingly\nunpredictable. In order to use just-in-time AIG in conjunction with CAT, it is imperative that the\nitem generating method—in our case language models —reliably produce items that represent a\nrequested construct, i.e., hold validity, without exceptions. This may be achieved by modiﬁcations\nto the model architecture, larger pretrained models, or better and larger quantities of training data.\nSecond, future AIG techniques must permit control over latent parameters such as item dif-\nﬁculty, measurement invariance, or even face validity. As illustrated by some items generated\nwithin the scope of our empirical study, the proportion of socially desirable items was tremen-\ndously high. Such levels of item difﬁculty are rarely desirable in psychometric testing. Naturally,\nin contrast to static item banks used for CAT which contain information about item difﬁculty, a\njust-in-time generated item used for the same purposes must be precalibrated to speciﬁc difﬁculty\nlevels prior to its creation.\nBesides such general improvements, we would welcome the application of language mod-\nelling to other test formats that have not been addressed by conventional AIG techniques to date.\nCertainly, situational judgment tests (Lievens et al., 2008), forced-choice response formats (Cao\n&D r a s g o w ,2019), and conditional reasoning tests (James, 1998) could also beneﬁt from the\npotential that lies within modern approaches to language modeling.\nFunding Open Access funding enabled and organized by Projekt DEAL.\nDeclarations\nConﬂicts of interest We have no known conﬂicts of interest to disclose.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which\npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give\nappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence,\nand indicate if changes were made. The images or other third party material in this article are included in the\narticle’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is\nnot included in the article’s Creative Commons licence and your intended use is not permitted by statutory\n770 PSYCHOMETRIKA\nregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright\nholder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/ .\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in pub-\nlished maps and institutional afﬁliations.\nReferences\nAbadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghemawat, S., Irving, G., Isard, M., Kudlur, M.,\nLevenberg, J., Monga, R., Moore, S., Murray, D. G., Steiner, B., Tucker, P., Vasudevan, V ., Warden, P., ...Zheng, X.\n(2016). TensorFlow: A system for large-scale machine learning. 12th USENIX symposium on operating systems design\nand implementation (OSDI 16) , 265–283. https://www.usenix.org/system/ﬁles/conference/osdi16/osdi16-abadi.pdf\nAngleitner, A., John, O. P., & Löhr, F.-J. (1986). It’s what you ask and how you ask it: An itemmetric analysis of\npersonality questionnaires. In A. Angleitner & J. S. Wiggins (Eds.), Personality assessment via questionnaires (pp.\n61–108). Springer. https://doi.org/10.1007/978-3-642-70751-3_5\nBejar, I. (2013). Item generation: Implications for a validity argument. In M. J. Gierl & T. M. Haladyna (Eds.), Automatic\nitem generation: Theory and practice (pp. 40–55). Routledge.\nBengio, Y . (2008). Neural net language models. Scholarpedia, 3 (1), 3881. https://doi.org/10.4249/scholarpedia.3881\nBengio, Y ., Simard, P., & Frasconi, P. (1994). Learning long-term dependencies with gradient descent is difﬁcult. IEEE\nTransactions on Neural Networks, 5 (2), 157–166.\nCamacho-Collados, J., & Pilehvar, M. T. (2018). From word to sense embeddings: A survey on vector representations of\nmeaning. Journal of Artiﬁcial Intelligence Research, 63 , 743–788. https://doi.org/10.1613/jair.1.11259\nCao, M., & Drasgow, F. (2019). Does forcing reduce faking? A meta-analytic review of forced-choice personality measures\nin high-stakes situations. Journal of Applied Psychology, 104 (11), 1347–1368. https://doi.org/10.1037/apl0000414\nChai, C., & Li, G. (2020). Human-in-the-loop techniques in machine learning. Data Engineering, 37 , 16.\nCronbach, L. J., & Meehl, P. E. (1955). Construct validity in psychological tests. Psychological Bulletin, 52 (4), 281.\nDevlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for\nlanguage understanding. ArXiv Preprint arXiv:1810.04805.\nDigman, J. M. (1990). Personality structure: Emergence of the ﬁve-factor model. Annual Review of Psychology, 41 (1),\n417–440. https://doi.org/10.1146/annurev.ps.41.020190.002221\nDrasgow, F., Luecht, R. M., & Bennett, R. E. (2006). Technology and testing. In R. L. Brennan, National Council on\nMeasurement in Education, & American Council on Education (Eds.), Educational measurement (4th ed., pp. 471–\n515). Praeger Publishing.\nElman, J. L. (1990). Finding structure in time. Cognitive Science, 14 (2), 179–211. https://doi.org/10.1207/\ns15516709cog1402_1\nFan, A., Lewis, M., & Dauphin, Y . (2018). Hierarchical neural story generation. arXiv:1805.04833\nFirth, J. R. (1962). Studies in linguistic analysis . Blackwell.\nFlora, D. B., & Curran, P. J. (2004). An empirical evaluation of alternative methods of estimation for conﬁrmatory factor\nanalysis with ordinal data. Psychological Methods, 9 (4), 466–491. https://doi.org/10.1037/1082-989X.9.4.466\nGierl, M. J., & Lai, H. (2015). Automatic item generation. In S. Lane, M. R. Raymond, & T. M. Haladyna (Eds.), Handbook\nof test development (2nd ed.). Routledge.\nGierl, M. J., Zhou, J., & Alves, C. (2008). Developing a taxonomy of item model types to promote assessment engineering.\nJournal of Technology, Learning, and Assessment, 7 (2), 1–50.\nGlas, C. A. W., & van der Linden, W. J. (2003). Computerized adaptive testing with item cloning. Applied Psychological\nMeasurement, 27 (4), 247–261. https://doi.org/10.1177/0146621603027004001\nGoldberg, L. R. (1999). A broad-bandwidth, public domain, personality inventory measuring the lower-level facets of\nseveral ﬁve-factor models. Personality Psychology in Europe, 7 (1), 7–28.\nGoldberg, L. R., Johnson, J. A., Eber, H. W., Hogan, R., Ashton, M. C., Cloninger, C. R., & Gough, H. G. (2006). The\ninternational personality item pool and the future of public-domain personality measures. Journal of Research in\nPersonality, 40(1), 84–96.\nGonzález-Carvajal, S., & Garrido-Merchán, E. C. (2021). Comparing BERT against traditional machine learning text\nclassiﬁcation. arXiv:2005.13012.\nGoodfellow, I., Bengio, Y ., & Courville, A. (2016). Deep learning . MIT press. http://www.deeplearningbook.org\nGorin, J. S., & Embretson, S. E. (2013). Using cognitive psychology to generate items and predict item characteristics.\nIn M. J. Gierl & T. M. Haladyna (Eds.), Automatic item generation: Theory and practice (pp. 136–156). Routledge.\nHarris, Z. S. (1954). Distributional structure. Word, 10(2–3), 146–162. https://doi.org/10.1080/00437956.1954.11659520\nHinkin, T. R. (1995). A review of scale development practices in the study of organizations. Journal of Management,\n21(5), 967–988. https://doi.org/10.1177/014920639502100509\nHochreiter, S. (1991). Untersuchungen zu dynamischen neuronalen Netzen . Diploma Technische Universität München.\nHochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation, 9 (8), 1735–1780. https://doi.\norg/10.1162/neco.1997.9.8.1735\nHoltzman, A., Buys, J., Du, L., Forbes, M., & Choi, Y . (2019). The curious case of neural text degeneration. ArXiv Preprint\narXiv:1904.09751.\nHoward, J., & Ruder, S. (2018). Universal language model ﬁne-tuning for text classiﬁcation. arXiv:1801.06146.\nJames, L. R. (1998). Measurement of personality via conditional reasoning. Organizational Research Methods, 1 (2),\n131–163. https://doi.org/10.1177/109442819812001\nHOMMEL ET AL. 771\nJohn, O. P., Donahue, E. M., & Kentle, R. L. (2012). Big ﬁve inventory [Data set]. American Psychological Association .\nhttps://doi.org/10.1037/t07550-000\nJozefowicz, R., Zaremba, W., & Sutskever, I. (2015). An empirical exploration of recurrent network architectures. Inter-\nnational Conference on Machine Learning , 2342–2350. http://proceedings.mlr.press/v37/jozefowicz15.pdf\nJurafsky, D., & Martin, J. H. (2020). N-gram language models. In Speech and Language Processing. Unpublished pre-print.\nhttps://web.stanford.edu/~jurafsky/slp3/\nKjell, O. N. E., Kjell, K., Garcia, D., & Sikström, S. (2019). Semantic measures: Using natural language processing to\nmeasure, differentiate, and describe psychological constructs. Psychological Methods, 24 (1), 92–115. https://doi.org/\n10.1037/met0000191\nKrosnick, J. A., & Presser, S. (2010). Question and Questionnaire Design. In P. V . Marsden & J. D. Wright (Eds.),\nHandbook of survey research (2nd ed., pp. 263–314). Emerald.\nLapedes, A., & Farber, R. (1988). How neural nets work. In Evolution, learning and cognition (pp. 331–346). World\nScientiﬁc.\nLee, J., Tang, R., & Lin, J. (2019). What Would Elsa Do? Freezing Layers During Transformer Fine-Tuning.\narXiv:1911.03090.\nLeiner, D. J. (2019). Too fast, too straight, too weird: Non-reactive indicators for meaningless data in internet surveys.\nSurvey Research Methods, 13 (3), 229–248.\nLevenshtein, V . I. (1966). Binary codes capable of correcting deletions, insertions, and reversals. Soviet Physics Doklady,\n10(8), 707–710.\nLievens, F., Peeters, H., & Schollaert, E. (2008). Situational judgment tests: A review of recent research. Personnel Review,\n37(4), 426–441. https://doi.org/10.1108/00483480810877598\nLu, K., Grover, A., Abbeel, P., & Mordatch, I. (2021). Pretrained transformers as universal computation engines.\narXiv:2103.05247 [Cs].\nLuecht, R. M. (2013). Automatic item generation for computerized adaptive testing. In M. J. Gierl & T. M. Haladyna\n(Eds.), Automatic item generation: Theory and practice (pp. 40–55). Routledge.\nManning, C. D., Raghavan, P., & Schütze, H. (2008). The term vocabulary and postings lists. In Introduction to information\nretrieval (pp. 44–78). Cambridge University Press.\nMeade, A. W., & Craig, S. B. (2012). Identifying careless responses in survey data. Psychological Methods, 17 (3),\n437–455. https://doi.org/10.1037/a0028085\nMikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efﬁcient estimation of word representations in vector space. ArXiv.\narXiv:1301.3781.\nMikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of words and phrases\nand their compositionality. In Advances in neural information processing systems, (pp. 3111–3119). arXiv:1310.4546.\nMontavon, G., Braun, M. L., & Müller, K.-R. (2011). Kernel analysis of deep networks. Journal of Machine Learning\nResearch, 12(9)\nNielsen, M. A. (2015). Neural networks and deep learning (V ol. 2018). Determination press. http://\nneuralnetworksanddeeplearning.com/about.html\nNunnally, J. C., & Bernstein, I. H. (1994). Psychometric theory (3rd ed.). McGraw-Hill.\nOlah, C. (2015). Understanding lstm networks . https://colah.github.io/posts/2015-08-Understanding-LSTMs/\nPerez, L., & Wang, J. (2017). The effectiveness of data augmentation in image classiﬁcation using deep learning.\narXiv:1712.04621\nRadford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language understanding by gen-\nerative pre-training. https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/\nlanguage_understanding_paper.pdf.\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language models are unsupervised multitask\nlearners. OpenAI Blog, 1 (8), 9.\nRevelle, W. (2020). psych: Procedures for psychological, psychometric, and personality research . Northwestern Univer-\nsity. https://CRAN.R-project.org/package=psych\nRosenblatt, F. (1958). The perceptron: A probabilistic model for information storage and organization in the brain.\nPsychological Review, 65 (6), 386.\nRosenbusch, H., Wanders, F., & Pit, I. L. (2020). The Semantic Scale Network: An online tool to detect semantic overlap\nof psychological scales and prevent scale redundancies. Psychological Methods, 25 (3), 380–392. https://doi.org/10.\n1037/met0000244\nRosset, C., Xiong, C., Song, X., Campos, D., Craswell, N., Tiwary, S., & Bennett, P. (2020). Leading conversational\nsearch by suggesting useful questions. Proceedings of The Web Conference, 2020 , 1160–1170.\nRush, A. M., Chopra, S., & Weston, J. (2015). A neural attention model for abstractive sentence summarization.\narXiv:1509.00685.\nSimms, L. J., Goldberg, L. R., Roberts, J. E., Watson, D., Welte, J., & Rotterman, J. H. (2011). Computerized adaptive\nassessment of personality disorder: Introducing the CAT-PD project. Journal of Personality Assessment, 93 (4), 380–\n389. https://doi.org/10.1080/00223891.2011.577475\nSrivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: A simple way to prevent\nneural networks from overﬁtting. The Journal of Machine Learning Research, 15 (1), 1929–1958.\nSuzuki, J., & Nagata, M. (2017). Cutting-off redundant repeating generations for neural abstractive summarization.\narXiv:1701.00138.\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, \\Lukasz, & Polosukhin, I. (2017).\nAttention is all you need. In Advances in Neural Information Processing Systems (pp. 5998–6008). arXiv:1706.03762\n772 PSYCHOMETRIKA\nVijayakumar, A. K., Cogswell, M., Selvaraju, R. R., Sun, Q., Lee, S., Crandall, D., & Batra, D. (2018). Diverse beam\nsearch: Decoding diverse solutions from neural sequence models. arXiv:1610.02424.\nvon Davier, M. (2018). Automated Item Generation with Recurrent Neural Networks. Psychometrika, 83 (4), 847–857.\nhttps://doi.org/10.1007/s11336-018-9608-y\nWang, K., & Su, Z. (2015). Automatic generation of raven’s progressive matrices. Twenty-fourth international joint\nconference on artiﬁcial intelligence . https://www.ijcai.org/Proceedings/15/Papers/132.pdf\nWang, P.-H., Hsieh, S.-I., Chang, S.-C., Chen, Y .-T., Pan, J.-Y ., Wei, W., & Juan, D.-C. (2020). Contextual temperature\nfor language modeling. arXiv:2012.13575.\nWolf, T., Debut, L., Sanh, V ., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M.,\nDavison, J., Shleifer, S., von Platen, P., Ma, C., Jernite, Y ., Plu, J., Xu, C., Le Scao, T., Gugger, S., ...Rush, A. (2020).\nTransformers: State-of-the-art natural language processing. Proceedings of the 2020 conference on empirical methods\nin natural language processing: system demonstrations (pp. 38–45). https://doi.org/10.18653/v1/2020.emnlp-demos.\n6\nWoolf, M. (2020). Gpt-2-simple (Version 92d3596) [Computer software]. https://github.com/minimaxir/gpt-2-simple\nXinxin, Z. (2019). Using automatic item generation to create content for computerized formative assessment .\nZellers, R., Holtzman, A., Rashkin, H., Bisk, Y ., Farhadi, A., Roesner, F., & Choi, Y . (2019). Defending against neural\nfake news. ArXiv Preprint arXiv:1905.12616.\nZhuang, F., Qi, Z., Duan, K., Xi, D., Zhu, Y ., Zhu, H., Xiong, H., & He, Q. (2020). A comprehensive survey on transfer\nlearning. arXiv:1911.02685.\nManuscript Received: 10 MAY 2021\nFinal V ersion Received: 28 OCT 2021\nPublished Online Date: 14 DEC 2021",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7720175981521606
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6472381353378296
    },
    {
      "name": "Construct (python library)",
      "score": 0.6028274297714233
    },
    {
      "name": "Cognition",
      "score": 0.5188566446304321
    },
    {
      "name": "Natural language processing",
      "score": 0.5082992911338806
    },
    {
      "name": "Transformer",
      "score": 0.5073544383049011
    },
    {
      "name": "Machine learning",
      "score": 0.5034891963005066
    },
    {
      "name": "Artificial neural network",
      "score": 0.49820375442504883
    },
    {
      "name": "Psychology",
      "score": 0.15757310390472412
    },
    {
      "name": "Programming language",
      "score": 0.15548789501190186
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I926574661",
      "name": "Leipzig University",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I62916508",
      "name": "Technical University of Munich",
      "country": "DE"
    }
  ]
}