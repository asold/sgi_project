{
  "title": "Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy of Transformer Faults",
  "url": "https://openalex.org/W3164885417",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A1999641301",
      "name": "Sherif S. M. Ghoneim",
      "affiliations": [
        "Taif University"
      ]
    },
    {
      "id": "https://openalex.org/A2037166447",
      "name": "Tamer Ahmed Farrag",
      "affiliations": [
        "Scientific Research Group in Egypt"
      ]
    },
    {
      "id": "https://openalex.org/A3165759443",
      "name": "A. Ali Rashed",
      "affiliations": [
        "Taif University"
      ]
    },
    {
      "id": "https://openalex.org/A4207715693",
      "name": "El-Sayed M. El-kenawy",
      "affiliations": [
        "Higher Institute of Engineering"
      ]
    },
    {
      "id": "https://openalex.org/A2238572349",
      "name": "Abdelhameed Ibrahim",
      "affiliations": [
        "Mansoura University"
      ]
    },
    {
      "id": "https://openalex.org/A1999641301",
      "name": "Sherif S. M. Ghoneim",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2037166447",
      "name": "Tamer Ahmed Farrag",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3165759443",
      "name": "A. Ali Rashed",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4207715693",
      "name": "El-Sayed M. El-kenawy",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2238572349",
      "name": "Abdelhameed Ibrahim",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2885617665",
    "https://openalex.org/W2909846570",
    "https://openalex.org/W3008024556",
    "https://openalex.org/W2913460559",
    "https://openalex.org/W3045707326",
    "https://openalex.org/W2985148234",
    "https://openalex.org/W2949622016",
    "https://openalex.org/W2346912247",
    "https://openalex.org/W2792332970",
    "https://openalex.org/W2548394137",
    "https://openalex.org/W2295580010",
    "https://openalex.org/W2910145865",
    "https://openalex.org/W2124273711",
    "https://openalex.org/W2727024523",
    "https://openalex.org/W2003722534",
    "https://openalex.org/W1957118915",
    "https://openalex.org/W2160554740",
    "https://openalex.org/W2188681465",
    "https://openalex.org/W2155409467",
    "https://openalex.org/W2415033110",
    "https://openalex.org/W3129440340",
    "https://openalex.org/W1840715785",
    "https://openalex.org/W3035533770",
    "https://openalex.org/W3089460656",
    "https://openalex.org/W2770595689",
    "https://openalex.org/W3091784365",
    "https://openalex.org/W3005155019",
    "https://openalex.org/W6696091093",
    "https://openalex.org/W2792282766",
    "https://openalex.org/W2084575229",
    "https://openalex.org/W2893368981",
    "https://openalex.org/W1972404441",
    "https://openalex.org/W2163214087",
    "https://openalex.org/W4240726130",
    "https://openalex.org/W2031183907",
    "https://openalex.org/W2168081761",
    "https://openalex.org/W2111185414",
    "https://openalex.org/W1564945538",
    "https://openalex.org/W2086777172",
    "https://openalex.org/W2152526563",
    "https://openalex.org/W2020998925",
    "https://openalex.org/W2002979815",
    "https://openalex.org/W6633913540",
    "https://openalex.org/W2015025818",
    "https://openalex.org/W2548153325",
    "https://openalex.org/W3133138473",
    "https://openalex.org/W2754360368",
    "https://openalex.org/W2535500033",
    "https://openalex.org/W2786257166",
    "https://openalex.org/W2921063114",
    "https://openalex.org/W2913215546",
    "https://openalex.org/W2610069517",
    "https://openalex.org/W1968576846",
    "https://openalex.org/W6756474200",
    "https://openalex.org/W2516429987",
    "https://openalex.org/W2803915465",
    "https://openalex.org/W2084277209",
    "https://openalex.org/W2148714802",
    "https://openalex.org/W2571820952",
    "https://openalex.org/W2549813608",
    "https://openalex.org/W2924610876",
    "https://openalex.org/W3009196730",
    "https://openalex.org/W2922396237",
    "https://openalex.org/W2290883490",
    "https://openalex.org/W3094630153",
    "https://openalex.org/W3021773213",
    "https://openalex.org/W2100231112",
    "https://openalex.org/W1566557213",
    "https://openalex.org/W2288088765",
    "https://openalex.org/W2131850647",
    "https://openalex.org/W2955501343",
    "https://openalex.org/W2926390335",
    "https://openalex.org/W2901758099"
  ],
  "abstract": "Detection of transformer faults avoids the transformer&#x2019;s undesirable loss from service and ensures utility service continuity. Diagnosis of transformer faults is determined using dissolved gas analysis (DGA). Several traditional DGA techniques, such as IEC code 60599, Rogers&#x2019; ratio method, Dornenburg method, Key gas method, and Duval triangle method, but these DGA techniques suffer from poor diagnosis transformer faults. Therefore, more research was used to diagnose transformer fault and diagnostic accuracy by combining traditional DGA techniques with artificial intelligence and optimization techniques. In this paper, a proposed Adaptive Dynamic Polar Rose Guided Whale Optimization algorithm (AD-PRS-Guided WOA) improves the classification techniques&#x2019; parameters that were used to enhance the transformer diagnostic accuracy. The results showed that the proposed AD-PRS-Guided WOA provides high diagnostic accuracy of transformer faults as 97.1&#x0025;, which is higher than other DGA techniques in the literature. The statistical analysis based on different tests, including ANOVA and Wilcoxon&#x2019;s rank-sum, confirms the algorithm&#x2019;s accuracy.",
  "full_text": "Received May 16, 2021, accepted May 22, 2021, date of publication May 25, 2021, date of current version June 3, 2021.\nDigital Object Identifier 10.1 109/ACCESS.2021.3083593\nAdaptive Dynamic Meta-Heuristics for Feature\nSelection and Classification in Diagnostic\nAccuracy of Transformer Faults\nSHERIF S. M. GHONEIM\n1, (Senior Member, IEEE), TAMER AHMED FARRAG\n2,\nA. ALI RASHED1, EL-SAYED M. EL-KENAWY\n3, (Member, IEEE),\nAND ABDELHAMEED IBRAHIM\n 4, (Member, IEEE)\n1Department of Electrical Engineering, College of Engineering, Taif University, Taif 21944, Saudi Arabia\n2Department of Computer Engineering, MISR Higher Institute for Engineering and Technology, Mansoura 35511, Egypt\n3Department of Communications and Electronics, Delta Higher Institute of Engineering & Technology (DHIET), Mansoura 35111, Egypt\n4Department of Computer Engineering and Control Systems, Faculty of Engineering, Mansoura University, Mansoura 35516, Egypt\nCorresponding authors: Abdelhameed Ibrahim (afai79@mans.edu.eg) and El-Sayed M. El-Kenawy (skenawy@ieee.org)\nThis work was supported by Taif University, Taif, Saudi Arabia, through the Taif University Researchers Supporting Project under\nGrant TURSP-2020/34.\nABSTRACT Detection of transformer faults avoids the transformer’s undesirable loss from service and\nensures utility service continuity. Diagnosis of transformer faults is determined using dissolved gas analysis\n(DGA). Several traditional DGA techniques, such as IEC code 60599, Rogers’ ratio method, Dornenburg\nmethod, Key gas method, and Duval triangle method, but these DGA techniques suffer from poor diagnosis\ntransformer faults. Therefore, more research was used to diagnose transformer fault and diagnostic accuracy\nby combining traditional DGA techniques with artiﬁcial intelligence and optimization techniques. In this\npaper, a proposed Adaptive Dynamic Polar Rose Guided Whale Optimization algorithm (AD-PRS-Guided\nWOA) improves the classiﬁcation techniques’ parameters that were used to enhance the transformer\ndiagnostic accuracy. The results showed that the proposed AD-PRS-Guided WOA provides high diagnostic\naccuracy of transformer faults as 97.1%, which is higher than other DGA techniques in the literature.\nThe statistical analysis based on different tests, including ANOV A and Wilcoxon’s rank-sum, conﬁrms the\nalgorithm’s accuracy.\nINDEX TERMS Diagnostic accuracy, dissolved gas analysis, polar rose, artiﬁcial intelligence, data\nclassiﬁcation.\nI. INTRODUCTION\nThe power transformers are very crucial in the electrical\npower system, and the electricity utilities are keen to carry out\ninspections to monitor their status regularly. The malfunction\nin their operation will lead to disconnection of the system\nand consequently to revenue loss [1], [2]. The detection of\nthe transformer faults is essential to avoid an unexpected\nand undesired outage from the system [3]. Dissolved gas\nanalysis (DGA) is a method that interprets the cause of\ntransformer faults and identiﬁes the fault types [4]. Several\nDGA methods have been developed to address the rules used\nto diagnose the transformer faults, such as the Dornenburg,\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Szidónia Lefkovits\n.\nRogers’ ratios, IEC code 60599, and Duval triangle methods,\nas the traditional DGA methods [5]–[9]. Some graphical\nrepresentations are designed to identify the transformer faults\nsuch as Duval Triangle [7], [8], pentagon [10], [11], and\nheptagon [12]. The poor accuracy of the traditional DGA\nmethods is observed, and decreasing the errors between the\nestimated and actual diagnostic faults requires other tools to\nsolve this shortcoming; then, the intelligent techniques are\nutilized.\nSeveral attempts were carried out to increase the tra-\nditional DGA method’s diagnostic accuracy to provide a\ncorrect diagnosis of transformer fault type using artiﬁ-\ncial intelligence techniques. Several intelligent techniques\nwere addressed combining with traditional DGA methods to\nimprove the accuracy of diagnosing the transformer faults\n78324 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/VOLUME 9, 2021\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\nsuch as artiﬁcial neural networks (ANN) [13]–[15], Fuzzy\nlogic system [FLS] [10], [16]–[18], Neuro-fuzzy [19], [20],\nsupport vector machine (SVM) [21], [22], Dempster–Shafer\nTheory [23], and k-NN [24]. Despite the combination of\nartiﬁcial intelligence methods with traditional DGA methods,\nthe accuracy of diagnosing transformer faults is still less than\nresearchers’ aspiration. Therefore many of them resorted to\ntrying to improve the accuracy of diagnosis through optimiza-\ntion techniques.\nSome of the researchers’ contributions using the opti-\nmization techniques were reported to improve the artiﬁcial\nintelligence methods’ parameters to enhance the accuracy of\nthe diagnosis of transformer faults. In [25], the genetic algo-\nrithm (GA) is used to adapt the wavelet networks (GAWNs)\nparameters such as the nodes’ weighting values and wavelet\nnodes translation and dilation. The GAWNs, ANN, and con-\nventional DGA accuracy results were compared. The boot-\nstrap is used with genetic programming (GP) to enhance\nthe extraction of classiﬁcation features of each transformer\nfault type [26]. The features supplied the ANN, SVM, and\nK-nearest neighbor (KNN) classiﬁers as the inputs to identify\neach fault classiﬁcation. The results revealed that the sug-\ngested algorithm improved the accuracy of the transformer\nfaults diagnosis. A Genetic Neural Computing (GNC) is used\nin [27] to interpret and diagnose the transformer faults based\non DGA data. According to IEEE C57.104, the faults are\ncategorized into four subsets using GA. The clustered data\nare used as inputs to ANN to predict the transformer fault\ntypes. The suggested algorithm developed the required deci-\nsion rules to identify the correct diagnoses of the transformer\nfaults.\nIn [28], the Particle swarm optimizer (PSO) optimized the\nParzan windows (PW) parameters to improve its ability for\ntransformer fault classiﬁcation. An intuitive interpretation of\ntransformer faults and correct decision-making are the main\nadvantages of this algorithm. Furthermore, the diagnostic\naccuracy is enhanced according to the other DGA methods.\nThe ANN and PSO are merged to increase the accuracy of\nthe transformer faults diagnosis based on DGA datasets [29].\nIt revealed that the accuracy is improved using the suggested\nalgorithm. A hybrid modiﬁed evolutionary particle swarm\noptimization-time varying acceleration coefﬁcient (MEPSO-\nTV AC) with artiﬁcial neural network (ANN) was suggested\nas a combined optimizer to identify the transformer faults\nbased on DGA records [30].\nThe transformer faults can be diagnosed using an opti-\nmized regression ANN (GRNN), Cuckoo search algorithm\n(CSA), and rough set theory (RS) in [31]. The RS reduced\nand simpliﬁed the high dimensioned data to develop the better\nfeatures of GRNN input. The CSA with Levy ﬂight helps the\nGRNN to get a good global convergence. Real fault cases\nare used to validate the proposed algorithm, and the results\nexplained that the algorithm could provide good accuracy for\ndiagnosing the fault types based on the DGA dataset. The\nIEC 60599 code and Rogers’ ratio method were utilized to\nidentify the transformer faults, but they have poor diagnostic\naccuracy; then, the PSO-FS optimizer is used to determine\nthe optimal limit of the two methods ratios to enhance the\ndiagnostic accuracy [1]. The Fuzzy system (FS) identiﬁes the\ntransformer faults by the modiﬁed ratio limits developed by\nPSO. The proposed algorithm enhanced the diagnostic accu-\nracy compared with the other DGA methods in the literature.\nA hybrid grey wolf optimizer (GWO) with differential\nevaluation (DE) is presented for enhancing the diagnostic\naccuracy of DGA methods by avoiding the local optima,\nimproving the diversity of the population, then ﬁtting the\nrelation between the exploration and exploitation [32]. A fault\ndiagnosis model of GWO optimized least square support\nvector machine (HGWO-LSSVM) is suggested and applied\nto transformer fault diagnosis with the optimal hybrid DGA\nfeature set selected as the model’s input. The kernel prin-\ncipal component analysis (KPCA) is utilized to extract the\nfeatures decreasing the model training time. A fuzzy system\nproduced the rules to limit the gas ratio for transformer fault\ntypes considering three memberships for three regions of\neach gas percentage range [33]. The membership limits can\nbe optimized using GWO, which developed the diagnostic\ncode matrix. The proposed algorithm enhanced the diagnostic\naccuracy of the transformer faults (95.45 %) for the random\ntesting data.\nThe traditional DGA techniques in IEC standard 60599 [5]\nand IEEE Standards C 57.104 [6] fail to interpret the trans-\nformer faults in most cases, then the diagnostic accuracy of\nthese methods is lacking. Moreover, combining the DGA\nmethods and artiﬁcial intelligence methods to enhance the\ndiagnostic accuracy of traditional DGA techniques requires\nmuch work, and diagnostic accuracy is still low. Therefore,\nthe researchers attempted to use the optimization techniques\nto optimize the DGA method parameters or to optimize\nthe classiﬁcation parameters for the classiﬁcation techniques\n[1], [21], [22], [28]–[33]. The optimization techniques max-\nimize the agreement of predicting and the actual faults to\ndevelop the highest diagnostic accuracy of the transformer\nfaults. Table 1 illustrates the recent research diagnosing the\ntransformer fault based on several artiﬁcial intelligence and\noptimization methods. The accuracy differs from the DGA\nmethod to another based on the used technique and the\nnumber of data samples. It is seen that only one approach\ndevelops high diagnostic accuracy, as in [34]. Still, the num-\nber of data samples is deﬁcient, which cannot indicate the\nrobustness of the BA-PNN based DGA technique. The other\nrecent DGA techniques develop diagnostic accuracy of about\n90%, which is higher in most cases than traditional DGA\nmethods.\nIn this work, 475 dataset samples were collected\nfrom the central chemical laboratory of the Electricity\nAuthority of Egypt and literature. The proposed Adaptive\nDynamic Polar Rose Guided Whale Optimization algorithm\n(AD-PRS-Guided WOA) enhances several classiﬁcation\nmethods’ parameters, such as k-NN, ensemble classiﬁer, and\nvoting classiﬁer, to improve their performance in classifying\npurposes. The proposed classiﬁcation method developed an\nVOLUME 9, 2021 78325\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\nTABLE 1. Recent research for classification in diagnostic accuracy of transformer faults.\nexcellent diagnostic accuracy of the transformer faults. First,\na binary version of the proposed (AD-PRS-Guided WOA)\nalgorithm is used for feature selection from the tested dataset.\nThe binary AD-PRS-Guided WOA algorithm is evaluated\nin compared with the Grey Wolf Optimizer (GWO) [42],\nPSO [43], [44], Bat Algorithm (BA) [45], [46], WOA\n[47], [48], Bowerbird Optimizer (SBO) [49], Multiverse\nOptimization (MVO) [50], Biogeography-Based Optimizer\n(BBO) [51], Fireﬂy Algorithm (FA) [52], and Genetic\nAlgorithm (GA) [53]. Second, a voting classiﬁer based on\nthe proposed algorithm (voting AD-PRS-Guided WOA) is\napplied to the experiments’ dataset. The output results are\ncompared with voting WOA, voting GWO, voting GA, and\nV oting PSO. Finally, the diagnostic accuracy of the proposed\nclassiﬁcation algorithm of the randomly selected samples\nextracted by the optimizer from the total of 475 samples is\ninvestigated. The comparison of the proposed classiﬁcation\nalgorithm and the other DGA techniques in literature, such\nas Conditional probability [13] and NPR [41] and other DGA\ntechniques, is illustrated in the experiments.\nThe main contributions of this work can be formed as\nfollows.\n• A novel Adaptive Dynamic Polar Rose Guided Whale\nOptimization algorithm (AD-PRS-Guided WOA) is\nproposed.\n• A binary version of the proposed algorithm (binary AD-\nPRS-Guided WOA) is used for feature selection from\nthe tested dataset.\n• To test the statistical difference of the proposed binary\nAD-PRS-Guided WOA, a one-way analysis of vari-\nance ANOV A) and a one-sample t-test tests are applied\nin this experiment.\n• A voting classiﬁer based on the proposed algorithm\n(voting AD-PRS-Guided WOA) is developed to improve\nthe tested dataset classiﬁcation accuracy.\n• The ANOV A and Wilcoxon’s rank-sum tests are inves-\ntigated to test the statistical difference of the proposed\nvoting (AD-PRS-Guided WOA) algorithm.\n• The importance of the current work is applying a\nnew optimization Polar Rose Guided Whale Optimiza-\ntion algorithm (ADPRS-GuidedWOA) to enhance sev-\neral classiﬁcation methods’ parameters, such as k-NN,\nensemble classiﬁer, and voting classiﬁer.\n• The AD-PRS-Guided WOA algorithm is used to\nimprove the classiﬁcation method performance in classi-\nfying purposes and apply it in a new application of high\nvoltage engineering to diagnose the transformer faults\nachieving high diagnostic accuracy of the transformer\nfaults.\n• The proposed binary and voting algorithms can be gen-\neralized and applied to different types of datasets.\nII. MATERIALS AND METHODS\nThis section will discuss the dataset samples tested in this\nwork and introduce the essential machine learning algo-\nrithms, including mathematical discussion of the traditional\nclassiﬁers and ensemble methods. The original whale opti-\nmization algorithm will also be introduced in this section.\nA. DATASET\nIn this study, 475 dataset samples were collected from\nthe central chemical laboratory, Egyptian electricity hold-\ning company, and the literature. The distribution of the\n475 samples is based on the transformer fault types, and\ntheir references are illustrated in Table 2. Table 2 shows\nthat 242 data samples for real cases from the central chem-\nical laboratory and Egyptian electricity holding company are\nincluded [54].\nTABLE 2. Distribution of the data samples according to transformer fault\ntypes and literature.\n78326 VOLUME 9, 2021\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\nB. MACHINE LEARNING ALGORITHMS\nIn this section, traditional classiﬁers and ensemble methods\nare considered as they are employed in the experiments for\nthe dataset illustrated in Table 2. The traditional classiﬁers\nare Multilayer Perceptron (MLP) and k-Nearest Neighbors\n(k-NN). Ensemble methods cover two main types of ensem-\nble methods: bagging classiﬁer and random forest as a type\nof averaging technique, and Adaboost and voting as a type of\nboosting technique.\n1) TRADITIONAL CLASSIFIERS\nArtiﬁcial neural networks (ANN) are excellent classiﬁcation\nalgorithms due to their ability to learn a non-linear decision\nboundary, like MLP, containing two or more layers. Thus,\nit is very ﬂexible in solving real-world tasks. It consists\nof many processing elements (PEs) that are called artiﬁcial\nneurons and connections. These PEs try to emulate our human\nnervous system’s operation using special training algorithms\n(i.e., ADAM, SGD, and L-BFGS-B) [66]. The MLP neural\nnetwork can include input and output layers and one layer\nbetween them named hidden layer. For the node output value\ncalculations, the weighted sum is computed as\nSj =\nn∑\ni=1\nwijIi +βj (1)\nwhere Ii indicates input variable i and wij is connection weight\nbetween Ii and neuron j in the hidden layer. βj is a bias value.\nThe node j output can be deﬁned using the sigmoid activation\nfunction as\nfj(Sj) = 1\n1 +exp−Sj\n(2)\nThe network output is then deﬁned using the value of fj(Sj)\nfor all hidden layer neurons as\nyk =\nm∑\nj=1\nwjk fj(Sj) +βk (3)\nwhere wjk is the weights between neuron j in the hidden layer\nand output node k and βk is the bias value for the output layer.\nThe k-NN algorithm classiﬁes samples or cases based on\ntheir similarity measure after storing all variable samples.\nIn this algorithm, data is used directly for classiﬁcation, and\nthe classiﬁcation process is done based on the nearest points\nor samples. The value of the nearest neighbors (k) is an\nadjustable parameter that can change to make the model more\n(i.e., small values of k) or less ﬂexible (i.e., large values\nof k). Besides, the value of the nearest neighbors is one by\ndefault [67]. k-NN is employed to predict the output variables\nbased on classiﬁcation approaches. The dataset is divided\ninto training and testing data in this approach. A similarity\nmeasure is used by the k-NN model to compare the given\ntesting to training data. The Euclidean distance is commonly\nused between training data (x train) and data testing (x test ), and\nit can be as follows.\nD\n(\nxtrain,i,xtest,i\n)\n=\n√\nk∑\ni=1\n(xtrain,i −xtest,i)2 (4)\nIn predicting output variables, the k-NN model chooses k\ntraining data that can be close to the testing data. To predict\nthe output value of the unknown testing data, the output value\nof k training data is selected to be the nearest neighbors.\nTo predict a value, the following formula is used by k-NN\nregression.\nˆy =1\nk\nk∑\nj=1\nyj (5)\nwhere k represents number of nearest neighbors of yj. In case\nof time series data, Eq. 5 is less efﬁcient because the correla-\ntion between observations (time) is not considered. To predict\nthe data testing, the following general formulation is applied.\nˆy =\nk∑\nj=1\nwjyj (6)\nwhere wj is weighted for the jth neighbor. This weighting is\nadjusted based on the observed data, as wj = j/n, with n\nrepresents number of training data. This model is considered\nas a time series model of k-NN.\n2) AVERAGING ENSEMBLE CLASSIFIERS\nThe ensemble methods seek to merge ML classiﬁers’ predic-\ntions to improve performance over a single classiﬁer because\nof the variance reduction. Bagging or averaging methods\nare based on building several classiﬁers independently and\nthen averaging their predictions (e.g., bagging classiﬁer, ran-\ndomized trees (random forest), and voting methods (soft and\nhard). These algorithms are less affected by the overﬁtting\nproblem. Random decision forests (RF) is one of the most\npopular and successful ensemble algorithms used for classi-\nﬁcation, regression. RF has gained massive interest due to its\naccuracy and immunity to noise than single classiﬁers did.\nThis means that small changes in training data do not make\nany reasonable change in the tree. This is because of the\nhierarchical architecture of the tree classiﬁers. High variance\nis a drawback for this algorithm. Generally, RF performance\nis lower than gradient boosted trees (GBT) and higher than\ndecision trees (DT). This technique is a very effective tech-\nnique for high-dimensional classiﬁcation tasks [68].\nFor the RF training algorithm, set X =x1,..., xn with\nresponses set as Y =y1,..., yn. With B times, the bagging\nselects a sample randomly with the training set replacement\nand ﬁts trees to these samples. Let b =1,..., B, a sample,\nwith replacement, for n training examples from X and Y ;\nnamed Xb and Yb. Then, train the classiﬁcation/regression\ntree fb on Xb and Yb. After the training process, the predic-\ntions for unseen samples x′ can be made by averaging the\npredictions from all the individual regression trees on x′as\nVOLUME 9, 2021 78327\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\nfollows.\nˆf =1\nB\nB∑\nb=1\nfb(x′) (7)\nIn the classiﬁcation trees case, the majority vote is applied.\n3) BOOSTING ENSEMBLE CLASSIFIERS\nAdaboost is a type of ensemble boosting method that can\nimprove accuracy by combining multiple classiﬁers. It builds\na high-performance classiﬁer by merging a set weak classi-\nﬁer (low accurate). This algorithm’s philosophy is to set the\nweights of classiﬁers and to train the data case in each itera-\ntion to ensure the exact predictions of unusual observations.\nAny ML technique can be used as a base estimator if it accepts\nweights on the training set. Bagging classiﬁer is an acronym\nfrom Bootstrap aggregating. It gets its name because it merges\ntwo techniques (i.e., Bootstrapping and Aggregation) into\none model. It is a type of ensemble averaging method with\nsimple implementation and improves the performance of ML\nalgorithms [69]. It works by learning different classiﬁers on\nrandomly generated training sets to get a ﬁnal prediction.\nAll classiﬁers in the ensemble are used to classify the test\nsample by merging all models’ predictions using uniform\naveraging or voting methods over class labels. This technique\ncan be used as a variance reduction method because of the\nrandomization into its structure procedure, and then we can\ncreate an ensemble out of it. The concept behind this method\nis to merge a set of ML estimators and use a majority vote\n(i.e., the output of each estimator) called hard voting. On the\nopposite side, soft voting or average predicted probabilities\nreturns the class label as argmax of the sum of predicted\nprobabilities. The expected class probabilities are collected\nfor each classiﬁer. It is then multiplied by a speciﬁc weight for\neach classiﬁer and is then averaged. The ﬁnal class label (i.e.,\nthe highest average probability) is then derived from the class\nlabel. This technique is suitable for equally well-performing\nML classiﬁers to balance their weaknesses [68].\nC. WHALE OPTIMIZATION ALGORITHM\nWOA has shown its advantages in the optimization area,\nand it is considered one of the most effective algorithms\nin the literature. However, it suffers from a low exploration\ncapability of the search space in some applications [68]. The\ninspiration in the WOA algorithm is from the behaviour of\nwhales in ﬁnding food [47], [70]. There is an n-dimensional\nsearch space in which whales swim. n represents the num-\nber of variables. The global solution can be found if each\nsolution’s position in the space search is updated. The main\nmechanism of this algorithm uses this equation to update\nsolution’ positions.\nX(t +1) =X∗(t) −A.D,D =|C .X∗(t) −X(t)| (8)\nwhere X(t) indicates a solution at iteration t and X∗(t) indi-\ncates the prey’ position (best solution). The ‘‘.’’ is pairwise\nmultiplication and X(t +1) indicates the updated solution’s\nposition [71], [72]. The A and C vectors are updated in each\niteration by A =2a.r1 −a and C =2.r2. a is changing from\n2 to 0 linearly. r1 and r2 are random values in [0, 1].\nIII. PROPOSED AD-PRS-GUIDED WOA ALGORITHM\nThe proposed Adaptive Dynamic Polar Rose Guided Whale\nOptimization Algorithm (AD-PRS-Guided WOA) has the\nfollowing main parts that are different from the original WOA\nalgorithm. These changes are used to explore the search\nspace while being affected by the leader’s position to enhance\nexploration performance. The AD-PRS-Guided WOA algo-\nrithm is shown in Algorithm (1).\n• The algorithm follows three random solutions instead of\none solution.\n• It uses exponentially change instead of linearly one to\nchange between exploration and exploitation processes\nsmoothly.\n• It calculates a list of generated walks in a diffusion\nprocess, according to the best solution, as a polar rose\nfunction.\nEach of these changes, the Guided WOA Algorithm, Adap-\ntive Dynamic Technique, and Polar Rose Function, then the\nproposed algorithm, will be explained in detail in the follow-\ning subsections.\nA. GUIDED WOA ALGORITHM\nIn the AD-PRS-Guided WOA algorithm, the updating posi-\ntions mechanism of the WOA algorithm is modiﬁed to fol-\nlow three random solutions instead of one solution. The\nthree random solutions are named Xo1, Xo2, and Xo3. These\nsolutions are updated each iteration to enhance the algo-\nrithm performance and reach the best solution at minimum\ntime.\nX(t +1) =w1 ∗Xo1\n+z ∗w2 ∗(Xo2 −Xo3)\n+(1 −z) ∗w3 ∗(Q −X(t)) (9)\nwhere X(t) represents the solution at iteration t and X(t +1)\nrepresents the updated solution position. Q indicates the best\nsolution (prey’ position). w1, w2, and w3 are random values in\n[0,0.5], [0 ,1], and [0, 1], respectively. z is updated between\nexploitation and exploration smoothly and is calculated as\nfollows\nz =1 −\n( t\nitersmax\n)2\n(10)\nwhere itersmax is maximum iterations and t is an iteration.\nB. ADAPTIVE DYNAMIC TECHNIQUE\nA ﬁtness value is determined for each solution in the popula-\ntion after initialization. The algorithm then ﬁnds the best solu-\ntion with the best ﬁtness value. After that, the algorithm splits\nindividuals from the population into two groups as shown\nin Fig. 1: the exploration and exploitation groups. Some\nindividuals in the exploitation group are going toward the\n78328 VOLUME 9, 2021\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\nFIGURE 1. Groups balance in the proposed AD-PRS-Guided WOA\nalgorithm.\nbest ‘‘leaders’’ option, and other individuals search in the area\naround the leaders. Most individuals in any of the sub-groups\nof the population dynamically change. To guarantee a balance\nbetween exploration and exploitation, the algorithm starts\nwith a (50/50) population.\nC. POLAR ROSE FUNCTION\nThe polar rose function is employed in the proposed algo-\nrithm to search around the best solution to ﬁnd another good\nsolution. It can be applied as follows.\nX(t +1) =k sin\n(a\nbθ\n)\n(11)\nwhere a and b are within [−10, 10] and 0 ≤ θ ≤ 12π.\nThe k value decreases exponentially and is calculated as\n2 − 2×t2\n(itersmax )2 for iteration t and maximum iterations itersmax .\nTo show how this function helps search about the best\nsolution and how it can cover an enormous range of areas\naround the selected solution, Fig. 2 shows the output of the\npolar rose function based on different values of a and b.\nD. COMPUTATIONAL COMPLEXITY\nThe proposed AD-PRS-Guided WOA algorithm’ computa-\ntional complexity, as shown in Algorithm 1, can be expressed\nas follow for a number of population n =n1 +n2 and number\nof iterations itersmax .\n• Population settings: O (1).\n• Parameters settings w1, w2, w3: O (1).\n• Collection of conﬁguration parameters: O (1).\nFIGURE 2. Polar rose function based on different values ofa and b.\nVOLUME 9, 2021 78329\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\nAlgorithm 1: Proposed AD-PRS-Guided WOA Algorithm\n1: Set population Xi(i =1,2,..., n), objective function Fn, size n, maximum iterations itersmax .\n2: Set parameters w1, w2, w3\n3: Collection AD-PRS-Guided WOA conﬁguration parameters\n4: Calculate objective function Fn for all solutions Xi\n5: Set Q = best agent position\n6: while t ≤itersmax do\n7: for (i =1 :i ≤n) do\n8: Select three random solutions Xo1, Xo2, and Xo3\n9: Set z =1 −\n(\nt\nitersmax\n)2\n10: Update position of current search agent as\nX(t +1) =w1 ∗Xo1 +z ∗w2 ∗(Xo2 −Xo3) +(1 −z) ∗w3 ∗(Q −X(t))\n11: end for\n12: Update Solutions in exploration group (n 1) and exploitation group (n 2)\n13: if (Best Fn is same for three iterations) then\n14: Increase solutions of exploration group (n 1)\n15: Decrease solutions of exploitation group (n 2)\n16: end if\n17: for (i =1 :i ≤n1) do\n(exploration group update)\n18: update three random solutions Xo1, Xo2, Xo3, and Q (The best solutions were elitism)\n19: if (Q <Any of the best solutions) then\n20: Mutate the solution by\nX(t +1) =k +\n(∑Xo1+Xo2+Xo3\nezk\n)\n, k =2 − 2×t2\n(itersmax )2\n21: else\n22: Update agent position by\nX(t +1) =w1 ∗Xo1 +z ∗w2 ∗(Xo2 −Xo3) +(1 −z) ∗w3 ∗(Q −X(t))\n23: end if\n24: end for\n25: for (i =1 :i ≤n2) do\n(exploitation group update)\n26: update three random solutions Xo1, Xo2, Xo3, and Q (The best solutions were elitism)\n27: if (Q <Any of the best solutions) then\n28: Move towards the best solution by\nX(t +1) =w1 ∗Xo1 +z ∗w2 ∗(Xo2 −Xo3) +(1 −z) ∗w3 ∗(Q −X(t))\n29: else\n30: Search around the best solution\nX(t +1) =k sin\n(a\nb θ\n)\n31: end if\n32: end for\n33: Amend solutions\n34: Update ﬁtness\n35: end while\n36: Return best agent Q\n• Calculate objective function for n solutions: O (n).\n• Finding best solution Q: O (n).\n• Selecting three random solutions Xo1, Xo2, and Xo3: O\n(itersmax ×n).\n• setting z value: O (itersmax ×n).\n• Positions’ updating for each solution: O (itersmax ×n).\n• Positions’ updating for each solution in exploration\ngroup: O (itersmax ×n1).\n• Positions’ updating for each solution in exploitation\ngroup: O (itersmax ×n2).\n• Increasing solutions in exploration group: O\n(itersmax ×n1).\n• Decreasing solutions in exploitation group: O\n(itersmax ×n2).\n• Updating random solutions in exploration group Xo1,\nXo2, Xo3, and Q: O (itersmax ×n1).\n78330 VOLUME 9, 2021\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\n• Mutate solutions in exploration group: O (itersmax ×n1).\n• Positions’ updating for each solution: O (itersmax ×n1).\n• Updating random solutions in exploitation group Xo1,\nXo2, Xo3, and Q: O (itersmax ×n2).\n• Move solutions in exploitation group: O (itersmax ×n2).\n• Searching around best solution in exploitation group: O\n(itersmax ×n2).\n• Amend solutions: O (n).\n• Update ﬁtness: O (n).\n• Returning the best solution Q: O (1).\nThis analysis shows that the proposed AD-PRS-Guided WOA\nalgorithm’ complexity of computations is O (itersmax ×n),\nsince n ≥n1 and n ≥n2. In case of a d dimension’ problem,\nthe algorithm’ complexity will be O (itersmax ×n ×d).\nE. BINARY OPTIMIZER\nFor the problems of feature selection, the solutions are only\nbinary with values of 0 or 1. Thus, the proposed AD-PRS-\nGuided WOA algorithm’s continuous values can be converted\ninto binary [0,1] to achieve the feature selection process. The\nfollowing equation based on the Sigmoid function is applied\nin this work.\nX(t +1) =\n{\n1 if Sigmoid(x) ≥0.5\n0 otherwise ,\nSigmoid(x) = 1\n1 +exp−10(x−0.5) , (12)\nwhere X(t +1) indicates the binary solution at itera-\ntion t. Sigmoid can scale the output values to be binary.\nSigmoid(x) ≥0.5 converts the value to be 1. x represents\nthe best solution of the proposed algorithm. The binary\nAD-PRS-Guided WOA Algorithm in explained step by step\nin Algorithm 2.\nAlgorithm 2 : Proposed Binary AD-PRS-Guided WOA\nAlgorithm\n1: Set AD-PRS-Guided WOA population, parameters, con-\nﬁguration.\n2: Convert solutions to binary [0,1]\n3: Calculate objective function and select best solutions\n4: Train k-NN and calculate error\n5: while t ≤itersmax do\n6: Apply AD-PRS-Guided WOA algorithm\n7: Convert updated solution to binary by Eq. 12\n8: Calculate ﬁtness\n9: Update parameters\n10: end while\n11: Return best solution\nF. OBJECTIVE FUNCTION\nThe objective function is applied to get the optimizer\nsolutions’ quality. To evaluate the quality of a solution,\nthe following equation is used.\nFn =αER(D) +β|s|\n|f | (13)\nwhere ER(D) gives classier’ error rate, s indicates number of\nselected features, f represents the hole number of features.\nα ∈[0,1],β =1 −α shows the number of the selected\nfeature importance for population. The solution is a good\nsolution if it can get a subset of features that can give low clas-\nsiﬁcation error rate with lower number of selected features.\nIV. DIAGNOSTIC ACCURACY OF TRANSFORMER\nFAULTS FRAMEWORK\nThe proposed step-by-step framework for the diagnostic\naccuracy of transformer faults is shown in Fig. 3. The\nframework consists of three main steps: First step of data\nprocessing, Second step of training base model, and Third\nstep of training voting ensemble model. In the ﬁrst step of\nthe framework, the processes of removing null values, feature\nscaling, and correlation analysis are applied to the input data\nsamples as a data processing stage. The binary AD-PRS-\nGuided WOA algorithm, shown in Algorithm 2, is applied\nhere for the feature selection from the processed data in the\ninput dataset. The data is then divided randomly into 80%\nfor training purposes, and the remaining samples are used for\ntesting the models. The base models of NN, k-NN, and Ran-\ndom forest are trained on the second step of the framework\nusing the processed data in the ﬁrst step. The NN model is\nbased on Eq. 1, Eq. 2, and Eq. 3. The k-NN model is based\non Eq. 4, Eq. 5, and Eq. 6, while the Random Forest model\nuses Eq. 7.\nThe last step of the proposed framework as shown in Fig. 3\nis the training voting ensemble model. In this step, a voting\nclassiﬁer is presented using the proposed AD-PRS-Guided\nWOA algorithm illustrated in Algorithm 1 based on the\nGuided WOA Algorithm, Adaptive Dynamic Technique, and\nPolar Rose Function. The voting algorithm improves the\nensemble’s accuracy by aggregating the NN, k-NN, and Ran-\ndom Forest classiﬁers. V oting is based on merging a set of ML\nalgorithms and returns the class label as argmax of the sum\nof predicted probabilities. The predicted class probabilities\nare collected for each classiﬁer. Then, it is multiplied by\na speciﬁc weight for each classiﬁer and is then averaged.\nThe ﬁnal class label (i.e., the highest average probability)\nis then derived from the class label. In addition, weights\nare optimized using the AD-PRS-GUIDE WOA algorithm.\nThis process will guarantee the best model performance. The\nensemble of the classiﬁer is based on weighted voting. The\ndata is then classiﬁed, and the output is predicted.\nV. EXPERIMENTAL RESULTS\nThere are two main parts of the experiments. The ﬁrst\npart considers the feature selection ability of the proposed\nbinary AD-PRS-Guided WOA algorithm. The second part is\ndesigned for the classiﬁcation problem of the tested dataset\nbased on the algorithm. The 475 dataset samples are divided\nVOLUME 9, 2021 78331\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\nFIGURE 3. Proposed framework based on AD-PRS-Guided WOA algorithm.\ninto 80% training and 20% testing. The training samples are\nused to train the proposed optimizer, and the testing samples\nare used for the evaluation.\nA. FEATURE SELECTION SCENARIO\nThe proposed binary algorithm is used in this scenario for\nfeature selection from the tested dataset. The binary AD-PRS-\nGuided WOA algorithm is evaluated in compared with the\nGrey Wolf Optimizer (GWO), PSO [43], Bat Algorithm (BA)\n[45], [46], WOA [47], Bowerbird Optimizer (SBO) [49],\nMultiverse Optimization (MVO) [50], Biogeography-Based\nOptimizer (BBO) [51], Fireﬂy Algorithm (FA) [52], and\nGenetic Algorithm (GA) [53]. Table 3 shows the perfor-\nmance metrics for feature selection tested in this experiment.\nThe conﬁguration of the proposed algorithm is presented\nin Table 4. The parameters of the objective function α and\nβare set to 0.99 and 0.01. The conﬁguration of the compared\nalgorithms is shown in Table 5. The average error of (0.4515)\nachieved by the proposed binary AD-PRS-Guided WOA,\nshown in Table 6 is the minimum error among the compared\nalgorithms. Other metrics, including the standard deviation of\n(0.0337), approve the algorithm’s superiority in this kind of\nTABLE 3. Performance metrics for feature selection.\nproblem. Figure 4 shows the fast convergence of the proposed\nAD-PRS-Guided WOA algorithm to ﬁnd the optimal solution\ncompared to other techniques.\nTo test the statistical difference of the proposed (AD-PRS-\nGuided WOA), a one-way analysis of variance (ANOV A) test\nis applied in this experiment. A null hypothesis is set as (H 0:\nµAD−PRS−Guided WOA =µGWO =µPSO =µBA =µWOA =\nµBBO =µMVO =µSBO =µFA =µGA) and an alternate\nhypothesis is conﬁrmed as (H 1: No equal means). Table 7\nshows the ANOV A test results. Figure5 presents the proposed\nand compared algorithms ANOV A test results considering the\n78332 VOLUME 9, 2021\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\nTABLE 4. AD-PRS-Guided WOA algorithm configuration.\nTABLE 5. Compared algorithms configuration.\nFIGURE 4. Convergence curves of the proposed and compared algorithms.\nfunction Fn. It is noted that the alternate hypothesis H1 can\nbe accepted for this test.\nAnother test, named one sample t-test, is conducted for the\nevaluation at a signiﬁcance level of 0.05. In this test, a null\nhypothesis is set as (H 0: µA =µGWO, µA =µPSO, µA =\nµBA, µA =µWOA, µA =µBBO, µA =µMVO, µA =µSBO,\nµA =µFA, µA =µGA), for A =AD −PRS −Guided WOA,\nand an alternate hypothesis is formed as (H 1: No equal\nmeans). Table 8 show the test results of 20 runs (Repetitions)\nas indicated in Table 4. This conﬁrm that the p-values are less\nthan 0.05 which shows the statistical signiﬁcant difference\nbetween groups. Thus, the hypothesis H1 can be accepted\naccepted.\nThe residual values and plots can observe the possible\nproblems better than the plot of the original dataset. Some\ndatasets cannot be good candidates for the feature selec-\ntion process. Figure 5 shows the residual, heteroscedastic-\nity, quantile-quantile (QQ) plots, and the heatmap. These\nplots provide a visual view between the prediction errors\nand the predicted dependent variable scores. Any violation\ncan be quickly determined to improve the accuracy of the\nresearch ﬁndings. Note that the QQ plot points’ distributions\nare approximately near to the line. These plots indicate that\nthe actual and the predicted residuals are linearly related,\nconﬁrming the proposed algorithm performance.\nB. CLASSIFICATION SCENARIO\nThe second part of the experiment is based on the proposed\nvoting classiﬁer (voting AD-PRS-Guided WOA) algorithm.\nThe algorithm results are compared with voting WOA, voting\nGWO, voting GA, and V oting PSO against the Area Under\nThe Curve (AUC) and the Mean Square Error (MSE). The\nAUC or balanced accuracy is calculated using an average of\nsensitivity and speciﬁcity in the following equation.\nAUC =(Sensitivity +Speciﬁcity)/2 (14)\nThe MSE value is evaluated by calculating the difference\nbetween the required and the actual output of the classiﬁers\naccording to this equation:\nMSE =\nn∑\nx=1\n(oh\nx dh\nx )2 (15)\nwhere for n number of outputs, dh\nx is the xth input neuron\noptimal value when applying hth training instance. When the\nhth training instance appears in the input, oh\nx is the optimal\noutput actual value of the xth input neuron.\nClassiﬁcation models parameters settings are presented\nin Table 9. The table includes the values of the parameters\nof NN, k-NN, Random Forest, and V oting classiﬁers.\nSingle classiﬁcation models’ results for the tested dataset\nbased on the NN, k-NN, Random forest techniques are shown\nin Table 10. The Random forest classiﬁer achieved an AUC\nof (0.797) and an MSE of (0.04887), which are better than the\nNN and k-NN classiﬁers for the current problem. However,\nthe results can be improved. The results of the proposed\n(voting AD-PRS-Guided WOA) algorithm compared to Bag-\nging, AdaBoost, and Majority, voting ensemble techniques,\nare presented in Table 11.\nThe voting AD-PRS-Guided WOA algorithm reached an\nAUC value of (0.971) and an MSE value of (4.77E-04).\nThese results show the algorithm’s performance compared\nto single classiﬁer models, including Random forest and\nensemble-based techniques. The algorithm is compared to\nvoting WOA, voting GWO, voting GA, and voting PSO\nalgorithms to conﬁrm the proposed voting algorithm’s clas-\nsiﬁcation accuracy. Table 12 presents the voting-based\nVOLUME 9, 2021 78333\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\nTABLE 6. Feature selection results of the proposed and compared algorithms.\nTABLE 7. ANOVA test results of the proposed algorithm.\nTABLE 8. One sample t-test results of the proposed and compared algorithms.\nTABLE 9. Classification models parameters.\nTABLE 10. Single classification models’ results.\nalgorithms results. This table conﬁrms that the AUC value\nof (0.971) and the MSE value of (4.77E-04) are the optimal\nresults that can be achieved based on the tested dataset. The\ndescriptive statistics of voting AD-PRS-Guided WOA, voting\nWOA, voting GWO, voting GA, and voting PSO algorithms\nare shown in Table 13 which conﬁrms the superiority of the\nproposed voting algorithm.\nThe ANOV A test is also applied in this experiment to test\nthe statistical difference of the proposed voting (AD-PRS-\nGuided WOA). A null hypothesis is set as (H 0: µA1 =µB1 =\nµC1 =µD1 =µE1), where A1: V oting (AD-PRS-Guided\nWOA), B1: V oting WOA, C1: V oting GWO, D1: V oting\nGA, and E1: V oting PSO, and an alternate hypothesis is\nformed as (H1: No equal means). Table 14 shows the ANOV A\ntest results. Figure 6 presents the proposed and compared\nalgorithms ANOV A test results considering the function Fn.\nIt is noted that the alternate hypothesis H1 can be accepted\nfor this test.\nOne more test, named Wilcoxon’s rank-sum test,\nis employed in this part. This test can discover whether\nthe proposed algorithm results have a signiﬁcant difference\ncompared to other algorithms. If the p-value < 0.05, it will\nindicate that algorithm has signiﬁcant superiority. A null\nhypothesis is set as (H 0: µA1 =µB1,µA1 =µC1,µA1 =\nµD1,µA1 = µE1), and an alternate hypothesis is formed\nas (H 1: No equal means). Table 15 show the test results\nof 20 runs (Repetitions) as indicated in Table 4. This con-\nﬁrms that the p-values are less than 0.05, which shows\nthe statistically signiﬁcant difference between groups. Thus,\nthe hypothesis H1 can be accepted.\nThe residual values and plots can observe the possible\nproblems better than the plot of the original dataset. Some\ndatasets can be not also good candidates for the classiﬁcation\nprocess. Figure 6 shows the residual, heteroscedasticity, and\nquantile-quantile (QQ) plots and the heatmap for the tested\ndataset classiﬁcation process. These plots indicate that the\n78334 VOLUME 9, 2021\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\nFIGURE 5. Different curves for the feature selection techniques.\nTABLE 11. Proposed optimization ensemble (AD-PRS-Guided WOA) compared to other algorithms.\nactual and the predicted residuals are linearly related, con-\nﬁrming the proposed voting (AD-PRS-Guided WOA) algo-\nrithm performance. Figure 6 also includes the ROC curves\nof the proposed voting (AD-PRS-Guided WOA) algorithm\nmapped to the compared voting algorithms. The ROC curves\nindicate that the proposed voting algorithm can distinguish\ndifferent cases with a high AUC value near 1.0.\nVI. VALIDATION AND DISCUSSION\nThe proposed classiﬁcation algorithm is validated by compar-\ning its results with the other DGA techniques in the literature.\nA total of 74 samples were extracted from the 475 data\nsamples as testing samples. A total of the 74 samples was\nrandomly selected by the optimization method. The distribu-\ntion of the testing samples is illustrated in Table 16. In this\ntable, the samples were categorized as 6 labels for PD, 13 for\nD1, 24 for D2, 16 for T1, 4 for T2, and 10 for T3 fault. It also\nshows the number of samples that were collected from the\npractical cases (39 real samples from [54]) and the credited\npublished articles as 17 samples from [8]. The results of the\ndiagnostic accuracy of the proposed classiﬁcation algorithm\nare illustrated in Table 17 comparing with the diagnostic\naccuracy of other DGA techniques in the literature. It showed\nfrom Table 17 that the overall diagnostic accuracy of the\nproposed classiﬁcation algorithm is 94.6%, which is greater\nthan that of the other DGA techniques where the highest\ndiagnostic accuracy that close to the proposed algorithm is\nConditional probability [13] and NPR [41] providing 90.54%.\nOn the other hand, the other traditional DGA techniques\nhave poor overall diagnostic accuracies such as IEC 60599\n(50%), Rogers Ratio method (45.95%), and Duval triangle\nmethod (66.27%). The proposed classiﬁcation algorithm’s\ndiagnostic accuracy results revealed that the proposed clas-\nsiﬁcation algorithm’s a high ability for correct diagnoses of\nthe transformer faults.\nThe proposed binary AD-PRS-Guided WOA algorithm\nin the feature selection process achieved an average error\nVOLUME 9, 2021 78335\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\nTABLE 12. Proposed optimization ensemble voting (AD-PRS-Guided WOA) compared to other voting based algorithms.\nTABLE 13. Descriptive statistics of the proposed optimization ensemble (AD-PRS-Guided WOA) compared to other algorithms.\nTABLE 14. ANOVA test results of the proposed optimization ensemble (AD-PRS-Guided WOA) algorithm.\nTABLE 15. Wilcoxon signed rank test results of the proposed and compared voting-based algorithms.\nTABLE 16. Distribution of the 74 testing samples according to the fault\ntype and references.\nof (0.4515) which is the minimum error among the com-\npared algorithms, and other metrics, including the standard\ndeviation of (0.0337), approve the algorithm’s superiority\nin this kind of problem. The algorithm also shows a fast\nconvergence in ﬁnding ﬁnd the optimal solution compared\nto other techniques. The proposed voting AD-PRS-Guided\nWOA algorithm achieved an AUC (balanced accuracy) value\nof (0.971) and a MSE value of (4.77E-04) which are the\nbest results that can be achieved based on the tested dataset\ncompared to other techniques.\nFor the feature selection scenario, the ANOV A test was\napplied to test the statistical difference of the proposed\n(AD-PRS-Guided WOA) algorithm. Another test, named the\none-sample t-test, was also conducted for the evaluation\nat a signiﬁcance level of 0.05. For the classiﬁcation sce-\nnario, the ANOV A test was applied in the experiment\nto test the statistical difference of the proposed voting\n(AD-PRS-Guided WOA) algorithm. One more test, named\nWilcoxon’s rank-sum test, was also employed in this part.\n78336 VOLUME 9, 2021\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\nFIGURE 6. Different curves for the classification techniques.\nTABLE 17. Diagnostic accuracy of the 74 testing samples of the suggested DGA algorithm and the other DGA techniques in literature.\nThis test can discover whether the proposed algorithm results\nhave a signiﬁcant difference compared to other algorithms.\nThe statistical analysis based on different tests conﬁrmed\nthat the proposed algorithm is a statistically signiﬁcant\ndifference.\nVII. CONCLUSION\nSeveral traditional dissolved gas analysis (DGA) techniques,\nsuch as IEC code 60599 and the Duval triangle method,\nwere used to diagnose the transformer faults. This paper\nproposed a novel Adaptive Dynamic Polar Rose Guided\nVOLUME 9, 2021 78337\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\nWhale Optimization algorithm (AD-PRS-Guided WOA) to\nimprove classiﬁcation techniques’ parameters of several clas-\nsiﬁcation techniques. A binary version of the proposed algo-\nrithm (binary AD-PRS-Guided WOA) was used for feature\nselection from the tested dataset. ANOV A and one-sample\nt-test tests were applied in this experiment to test the sta-\ntistical difference of the proposed binary AD-PRS-Guided\nWOA. A voting classiﬁer based on the proposed algorithm\n(voting AD-PRS-Guided WOA) was developed to improve\nthe tested dataset classiﬁcation accuracy. The ANOV A and\nWilcoxon’s rank-sum tests were investigated to show the pro-\nposed voting’s statistical difference (AD-PRS-Guided WOA)\nalgorithm. The proposed AD-PRS-Guided WOA algorithm\nprovided high diagnostic accuracy of transformer faults,\nhigher than other DGA techniques in the literature. The pro-\nposed algorithm’s diagnostic accuracy results have a high\nability for correct diagnoses of the transformer faults. The\nproposed algorithm’s diagnostic accuracy based on randomly\nselected samples from the tested dataset approved the algo-\nrithm’s performance compared to other DGA techniques. The\nproposed binary and voting algorithms can be generalized and\napplied to different datasets in the future.\nACKNOWLEDGMENT\nThis work was supported by Taif University, Taif, Saudi\nArabia, through Taif University Researchers Supporting\nProject, under Grant TURSP-2020/34.\nREFERENCES\n[1] I. B. M. Taha, A. Hoballah, and S. S. M. Ghoneim, ‘‘Optimal ratio limits\nof rogers’ four-ratios and IEC 60599 code methods using particle swarm\noptimization fuzzy-logic approach,’’ IEEE Trans. Dielectr. Electr. Insul.,\nvol. 27, no. 1, pp. 222–230, Feb. 2020, doi: 10.1109/tdei.2019.008395.\n[2] S. S. M. Ghoneim and I. B. M. Taha, ‘‘Comparative study of full\nand reduced feature scenarios for health index computation of power\ntransformers,’’ IEEE Access, vol. 8, pp. 181326–181339, 2020, doi:\n10.1109/access.2020.3028689.\n[3] O. E. Gouda, S. H. El-Hoshy, and H. H. E. L. Tamaly, ‘‘Proposed three\nratios technique for the interpretation of mineral oil transformers based\ndissolved gas analysis,’’ IET Gener., Transmiss. Distrib. , vol. 12, no. 11,\npp. 2650–2661, Apr. 2018, doi: 10.1049/iet-gtd.2017.1927.\n[4] S. S. M. Ghoneim, I. B. M. Taha, and N. I. Elkalashy, ‘‘Integrated ANN-\nbased proactive fault diagnostic scheme for power transformers using\ndissolved gas analysis,’’ IEEE Trans. Dielectr. Electr. Insul., vol. 23, no. 3,\npp. 1838–1845, Jun. 2016, doi: 10.1109/tdei.2016.005301.\n[5] Mineral Oil-Filled Electrical Equipment in Service—Guidance on the\nInterpretation of Dissolved and Free Gases Analysis, document IEC 60599,\nIEC, Geneva, Switzerland, Edition 2.1, 2007.\n[6] IEEE Guide for the Interpretation of Gases Generated in Oil-Immersed\nTransformers, IEEE Standard C57.104-2008 (Revision IEEE Std C57.104-\n1991), 2009, pp. 1–36.\n[7] M. Duval, ‘‘A review of faults detectable by gas-in-oil analysis in trans-\nformers,’’ IEEE Elect. Insul. Mag., vol. 18, no. 3, pp. 8–17, May 2002,\ndoi: 10.1109/mei.2002.1014963.\n[8] M. Duval and A. dePabla, ‘‘Interpretation of gas-in-oil analysis using new\nIEC publication 60599 and IEC TC 10 databases,’’ IEEE Elect. Insul. Mag.,\nvol. 17, no. 2, pp. 31–41, Mar. 2001, doi: 10.1109/57.917529.\n[9] N. A. Bakar and A. Abu-Siada, ‘‘Fuzzy logic approach for transformer\nremnant life prediction and asset management decision,’’ IEEE Trans.\nDielectr. Electr. Insul., vol. 23, no. 5, pp. 3199–3208, Oct. 2016, doi:\n10.1109/tdei.2016.7736886.\n[10] D.-E.-A. Mansour, ‘‘Development of a new graphical technique for dis-\nsolved gas analysis in power transformers based on the ﬁve combustible\ngases,’’IEEE Trans. Dielectr. Electr. Insul., vol. 22, no. 5, pp. 2507–2512,\nOct. 2015, doi: 10.1109/tdei.2015.004999.\n[11] M. Duval and L. Lamarre, ‘‘The duval pentagon—A new complemen-\ntary tool for the interpretation of dissolved gas analysis in transform-\ners,’’ IEEE Elect. Insul. Mag., vol. 30, no. 6, pp. 9–12, Nov. 2014, doi:\n10.1109/mei.2014.6943428.\n[12] O. E. Gouda, S. H. El-Hoshy, and H. H. El-Tamaly, ‘‘Proposed heptagon\ngraph for DGA interpretation of oil transformers,’’ IET Gener., Trans-\nmiss. Distrib., vol. 12, no. 2, pp. 490–498, Jan. 2018, doi: 10.1049/iet-\ngtd.2017.0826.\n[13] I. B. M. Taha, D.-E.-A. Mansour, S. S. M. Ghoneim, and N. I. Elkalashy,\n‘‘Conditional probability-based interpretation of dissolved gas analysis\nfor transformer incipient faults,’’ IET Gener., Transmiss. Distrib., vol. 11,\nno. 4, pp. 943–951, Mar. 2017, doi: 10.1049/iet-gtd.2016.0886.\n[14] M. D. Equbal, S. A. Khan, and T. Islam, ‘‘Transformer incipient fault\ndiagnosis on the basis of energy-weighted DGA using an artiﬁcial neu-\nral network,’’ Turkish J. Electr. Eng. Comput. Sci., vol. 26, pp. 77–88,\nJan. 2018.\n[15] M. Ou, H. Wei, Y . Zhang, and J. Tan, ‘‘A dynamic adam based deep\nneural network for fault diagnosis of oil-immersed power transformers,’’\nEnergies, vol. 12, no. 6, p. 995, Mar. 2019, doi: 10.3390/en12060995.\n[16] E. T. Mharakurwa, G. N. Nyakoe, and A. O. Akumu, ‘‘Power transformer\nfault severity estimation based on dissolved gas analysis and energy of\nfault formation technique,’’ J. Electr. Comput. Eng., vol. 2019, pp. 1–10,\nFeb. 2019, doi: 10.1155/2019/9674054.\n[17] M. Noori, R. Effatnejad, and P. Hajihosseini, ‘‘Using dissolved gas analysis\nresults to detect and isolate the internal faults of power transformers by\napplying a fuzzy logic method,’’ IET Gener., Transmiss. Distrib., vol. 11,\nno. 10, pp. 2721–2729, Jul. 2017, doi: 10.1049/iet-gtd.2017.0028.\n[18] J. Aghaei, A. Gholami, H. A. Shayanfar, and A. Dezhamkhooy, ‘‘Dissolved\ngas analysis of transformers using fuzzy logic approach,’’ Eur. Trans.\nElectr. Power, vol. 20, pp. 630–638, Jul. 2009, doi: 10.1002/etep.343.\n[19] K. U. Mulyodinoto, Suwarno, R. Prasojo, and A. Abu-Siada, ‘‘Applications\nof anﬁs to estimate the degree of polymerization using transformer dissolve\ngas analysis and oil characteristics,’’ Polym. Sci., vol. 14, no. 2, pp. 1–9,\n2018.\n[20] M. Allahbakhshi and A. Akbari, ‘‘Novel fusion approaches for the dis-\nsolved gas analysis of insulating oil,’’ IJST, Trans. Electr. Eng., vol. 35,\nno. E1, pp. 13–24, 2011.\n[21] K. Bacha, S. Souahlia, and M. Gossa, ‘‘Power transformer fault diag-\nnosis based on dissolved gas analysis by support vector machine,’’\nElectr. Power Syst. Res., vol. 83, no. 1, pp. 73–79, Feb. 2012, doi:\n10.1016/j.epsr.2011.09.012.\n[22] Y . Benmahamed, M. Teguar, and A. Boubakeur, ‘‘Application of SVM and\nKNN to duval pentagon 1 for transformer oil diagnosis,’’ IEEE Trans.\nDielectr. Electr. Insul., vol. 24, no. 6, pp. 3443–3451, Dec. 2017, doi:\n10.1109/tdei.2017.006841.\n[23] D. Bhalla, R. K. Bansal, and H. O. Gupta, ‘‘Integrating AI based DGA\nfault diagnosis using Dempster–Shafer theory,’’ Int. J. Electr. Power\nEnergy Syst. , vol. 48, pp. 31–38, Jun. 2013, doi: 10.1016/j.ijepes.2012.\n11.018.\n[24] Y . Benmahamed, Y . Kemari, M. Teguar, and A. Boubakeur, ‘‘Diagno-\nsis of power transformer oil using KNN and nave bayes classiﬁers,’’\nin Proc. IEEE 2nd Int. Conf. Dielectr. (ICD), Jul. 2018, pp. 1–4, doi:\n10.1109/icd.2018.8514789.\n[25] Y .-C. Huang, ‘‘A new data mining approach to dissolved gas anal-\nysis of oil-insulated power apparatus,’’ IEEE Trans. Power Del.,\nvol. 18, no. 4, pp. 1257–1261, Oct. 2003, doi: 10.1109/tpwrd.2003.\n817736.\n[26] A. Shintemirov, W. Tang, and Q. H. Wu, ‘‘Power transformer fault clas-\nsiﬁcation based on dissolved gas analysis by implementing bootstrap\nand genetic programming,’’ IEEE Trans. Syst., Man, Cybern. C, Appl.\nRev., vol. 39, no. 1, pp. 69–79, Jan. 2009, doi: 10.1109/tsmcc.2008.\n2007253.\n[27] S. Al-Janabi, S. Rawat, A. Patel, and I. Al-Shourbaji, ‘‘Design and evalu-\nation of a hybrid system for detection and prediction of faults in electrical\ntransformers,’’ Int. J. Electr. Power Energy Syst., vol. 67, pp. 324–335,\nMay 2015, doi: 10.1016/j.ijepes.2014.12.005.\n[28] Z. J. Richardson, J. Fitch, W. H. Tang, J. Y . Goulermas, and Q. H. Wu,\n‘‘A probabilistic classiﬁer for transformer dissolved gas analysis with\na particle swarm optimizer,’’ IEEE Trans. Power Del., vol. 23, no. 2,\npp. 751–759, Apr. 2008, doi: 10.1109/tpwrd.2008.915812.\n[29] H. A. Illias, X. R. Chai, A. H. A. Bakar, and H. Mokhlis, ‘‘Trans-\nformer incipient fault prediction using combined artiﬁcial neural net-\nwork and various particle swarm optimisation techniques,’’ PLoS ONE,\nvol. 10, no. 6, Jun. 2015, Art. no. e0129363, doi: 10.1371/journal.pone.\n0129363.\n78338 VOLUME 9, 2021\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\n[30] H. A. Illias, X. R. Chai, and A. H. A. Bakar, ‘‘Hybrid modiﬁed evolutionary\nparticle swarm optimisation-time varying acceleration coefﬁcient-artiﬁcial\nneural network for power transformer fault diagnosis,’’ Measurement,\nvol. 90, pp. 94–102, Aug. 2016, doi: 10.1016/j.measurement.2016.\n04.052.\n[31] A. Li, X. Yang, Z. Xie, and C. Yang, ‘‘An optimized GRNN-enabled\napproach for power transformer fault diagnosis,’’ IEEJ Trans. Electr.\nElectron. Eng., vol. 14, no. 8, pp. 1181–1188, Jun. 2019, doi: 10.1002/\ntee.22916.\n[32] B. Zeng, J. Guo, W. Zhu, Z. Xiao, F. Yuan, and S. Huang, ‘‘A transformer\nfault diagnosis model based on hybrid grey wolf optimizer and LS-SVM,’’\nEnergies, vol. 12, no. 21, p. 4170, Nov. 2019, doi: 10.3390/en12214170.\n[33] A. Hoballah, D.-E.-A. Mansour, and I. B. M. Taha, ‘‘Hybrid grey wolf\noptimizer for transformer fault diagnosis using dissolved gases considering\nuncertainty in measurements,’’ IEEE Access, vol. 8, pp. 139176–139187,\n2020, doi: 10.1109/access.2020.3012633.\n[34] X. Yang, W. Chen, A. Li, C. Yang, Z. Xie, and H. Dong, ‘‘BA-PNN-\nbased methods for power transformer fault diagnosis,’’ Adv. Eng. Informat.,\nvol. 39, pp. 178–185, Jan. 2019, doi: 10.1016/j.aei.2019.01.001.\n[35] S. S. M. Ghoneim and I. B. M. Taha, ‘‘A new approach of DGA interpreta-\ntion technique for transformer fault diagnosis,’’ Int. J. Electr. Power Energy\nSyst., vol. 81, pp. 265–274, Oct. 2016, doi: 10.1016/j.ijepes.2016.02.018.\n[36] S. Koroglu and A. Demircali, ‘‘Diagnosis of power transformer faults\nbased on multi-layer support vector machine hybridized with optimization\nmethods,’’ Electr. Power Compon. Syst., vol. 44, no. 19, pp. 2172–2184,\nNov. 2016, doi: 10.1080/15325008.2016.1219427.\n[37] T. Kari, W. Gao, D. Zhao, Z. Zhang, W. Mo, Y . Wang, and L. Luan,\n‘‘An integrated method of ANFIS and dempster-shafer theory for\nfault diagnosis of power transformer,’’ IEEE Trans. Dielectr. Electr.\nInsul., vol. 25, no. 1, pp. 360–371, Feb. 2018, doi: 10.1109/tdei.2018.\n006746.\n[38] Y . Kim, T. Park, S. Kim, N. Kwak, and D. Kweon, ‘‘Artiﬁcial intelligent\nfault diagnostic method for power transformers using a new classiﬁcation\nsystem of faults,’’ J. Electr. Eng. Technol., vol. 14, no. 2, pp. 825–831,\nFeb. 2019, doi: 10.1007/s42835-019-00105-0.\n[39] X. Wu, Y . He, and J. Duan, ‘‘A deep parallel diagnostic method for\ntransformer dissolved gas analysis,’’ Appl. Sci., vol. 10, no. 4, p. 1329,\nFeb. 2020, doi: 10.3390/app10041329.\n[40] S. S. M. Ghoneim, K. Mahmoud, M. Lehtonen, and M. M. F. Darwish,\n‘‘Enhancing diagnostic accuracy of transformer faults using teaching-\nlearning-based optimization,’’ IEEE Access, vol. 9, pp. 30817–30832,\n2021, doi: 10.1109/access.2021.3060288.\n[41] I. B. M. Taha, S. S. Dessouky, and S. S. M. Ghoneim, ‘‘Transformer fault\ntypes and severity class prediction based on neural pattern-recognition\ntechniques,’’Electr. Power Syst. Res., vol. 191, Feb. 2021, Art. no. 106899,\ndoi: 10.1016/j.epsr.2020.106899.\n[42] E.-S. M. El-Kenawy and M. Eid, ‘‘Hybrid gray wolf and particle swarm\noptimization for feature selection,’’ Int. J. Innov. Comput. Inf. Control,\nvol. 16, no. 3, pp. 831–844, 2020.\n[43] R. Bello, Y . Gomez, A. Nowe, and M. M. Garcia, ‘‘Two-step particle swarm\noptimization to solve the feature selection problem,’’ in Proc. 7th Int. Conf.\nIntell. Syst. Design Appl. (ISDA), Oct. 2007, pp. 691–696.\n[44] A. Ibrahim, M. Noshy, H. A. Ali, and M. Badawy, ‘‘PAPSO:\nA power-aware VM placement technique based on particle swarm\noptimization,’’ IEEE Access, vol. 8, pp. 81747–81764, 2020, doi:\n10.1109/access.2020.2990828.\n[45] I. Karakonstantis and A. Vlachos, ‘‘Bat algorithm applied to continuous\nconstrained optimization problems,’’ J. Inf. Optim. Sci., vol. 42, no. 1,\npp. 1–19, Mar. 2020, doi: 10.1080/02522667.2019.1694740.\n[46] Q. Al-Tashi, S. J. A. Kadir, H. M. Rais, S. Mirjalili, and H. Alhussian,\n‘‘Binary optimization using hybrid grey wolf optimization for feature\nselection,’’IEEE Access, vol. 7, pp. 39496–39508, 2019.\n[47] S. Mirjalili and A. Lewis, ‘‘The whale optimization algorithm,’’ Adv. Eng.\nSoftw., vol. 95, pp. 51–67, May 2016. [Online]. Available: http://www.\nsciencedirect.com/science/article/pii/S0965997816300163\n[48] E. M. Hassib, A. I. El-Desouky, L. M. Labib, and E.-S.-M. El-kenawy,\n‘‘WOA +BRNN: An imbalanced big data classiﬁcation framework\nusing whale optimization and deep neural network,’’ Soft Comput. ,\nvol. 24, no. 8, pp. 5573–5592, Mar. 2019, doi: 10.1007/s00500-019-\n03901-y.\n[49] S. H. S. Moosavi and V . K. Bardsiri, ‘‘Satin bowerbird optimizer: A new\noptimization algorithm to optimize ANFIS for software development effort\nestimation,’’ Eng. Appl. Artif. Intell., vol. 60, pp. 1–15, Apr. 2017, doi:\n10.1016/j.engappai.2017.01.006.\n[50] S. Mirjalili, S. M. Mirjalili, and A. Hatamlou, ‘‘Multi-verse optimizer:\nA nature-inspired algorithm for global optimization,’’ Neural Comput.\nAppl., vol. 27, no. 2, pp. 495–513, Feb. 2016, doi: 10.1007/s00521-015-\n1870-7.\n[51] D. Simon, ‘‘Biogeography-based optimization,’’ IEEE Trans. Evol.\nComput., vol. 12, no. 6, pp. 702–713, Dec. 2008, doi: 10.1109/\ntevc.2008.919004.\n[52] I. Fister, Jr., X.-S. Yang, I. Fister, and J. Brest, ‘‘Memetic ﬁreﬂy algorithm\nfor combinatorial optimization,’’ in Bioinspired Optimization Methods\nand Their Applications—BIOMA. Jozef Stefan Institute, 2012, pp. 75–86.\n[Online]. Available: https://cds.cern.ch/record/1443422\n[53] M. M. Kabir, M. Shahjahan, and K. Murase, ‘‘A new local search\nbased hybrid genetic algorithm for feature selection,’’ Neurocomput-\ning, vol. 74, no. 17, pp. 2914–2928, Oct. 2011. [Online]. Available:\nhttp://www.sciencedirect.com/science/article/pii/S0925231211002748\n[54] Egyptian Electricity Holding Company (EEHC) Reports.\nAccessed: Mar. 6, 2021. [Online]. Available: http://www.moee.\ngov.eg/english_new/report.aspx\n[55] S. Agrawal and A. K. Chandel, ‘‘Transformer incipient fault diagnosis\nbased on probabilistic neural network,’’ in Proc. Students Conf. Eng. Syst.,\nMar. 2012, pp. 1–5, doi: 10.1109/sces.2012.6199110.\n[56] M.-H. Wang, ‘‘A novel extension method for transformer fault diagnosis,’’\nIEEE Trans. Power Del., vol. 18, no. 1, pp. 164–169, Jan. 2003, doi:\n10.1109/tpwrd.2002.803838.\n[57] Z. Yong-Li, W. Fang, and G. Lan-Qin, ‘‘Transformer fault diagnosis based\non naive Bayesian classiﬁer and SVR,’’ in Proc. IEEE Region Conf.\n(TENCON), Nov. 2006, pp. 1–4, doi: 10.1109/tencon.2006.343895.\n[58] D. S. Sarma and G. N. S. Kalyani, ‘‘Ann approach for condition moni-\ntoring of power transformers using DGA,’’ in Proc. IEEE Region Conf.\n(TENCON), vol. 3, Nov. 2004, pp. 444–447.\n[59] J.-T. Hu, L.-X. Zhou, and M.-L. Song, ‘‘Transformer fault diagnosis\nmethod of gas hromatographic analysis using computer image analy-\nsis,’’ in Proc. 2nd Int. Conf. Intell. Syst. Design Eng. Appl., Jan. 2012,\npp. 1169–1172.\n[60] S. Seifeddine, B. Khmais, and C. Abdelkader, ‘‘Power transformer fault\ndiagnosis based on dissolved gas analysis by artiﬁcial neural network,’’\nin Proc. 1st Int. Conf. Renew. Energies Veh. Technol., Mar. 2012,\npp. 230–236.\n[61] M. Rajabimendi and E. P. Dadios, ‘‘A hybrid algorithm based on neural-\nfuzzy system for interpretation of dissolved gas analysis in power trans-\nformers,’’ in Proc. IEEE Region Conf. (TENCON), Nov. 2012, pp. 1–6.\n[62] R. Soni and K. Chaudhari, ‘‘An approach to diagnose incipient faults of\npower transformer using dissolved gas analysis of mineral oil by ratio\nmethods using fuzzy logic,’’ in Proc. Int. Conf. Signal Process., Commun.,\nPower Embedded Syst. (SCOPES), Oct. 2016, pp. 1894–1899.\n[63] G. Zhang, K. Yasuoka, S. Ishii, L. Yang, and Z. Yan, ‘‘Application of fuzzy\nequivalent matrix for fault diagnosis of oil-immersed insulation,’’ in Proc.\nIEEE 13th Int. Conf. Dielectric Liquids (ICDL), Jul. 1999, pp. 400–403.\n[64] O. E. Gouda, S. M. Saleh, and S. H. El-hoshy, ‘‘Power transformer\nincipient faults diagnosis based on dissolved gas analysis,’’ Indonesian\nJ. Electr. Eng. Comput. Sci., vol. 1, no. 1, pp. 10–16, Jan. 2016, doi:\n10.11591/ijeecs.v1.i1.pp10-16.\n[65] J. Li, Q. Zhang, K. Wang, J. Wang, T. Zhou, and Y . Zhang, ‘‘Opti-\nmal dissolved gas ratios selected by genetic algorithm for power trans-\nformer fault diagnosis based on support vector machine,’’ IEEE Trans.\nDielectr. Electr. Insul., vol. 23, no. 2, pp. 1198–1206, Apr. 2016, doi:\n10.1109/tdei.2015.005277.\n[66] E.-S. M. El-kenawy, S. Mirjalili, A. Ibrahim, M. Alrahmawy, M. El-Said,\nR. M. Zaki, and M. M. Eid, ‘‘Advanced meta-heuristics, convolutional\nneural networks, and feature selectors for efﬁcient COVID-19 X-ray chest\nimage classiﬁcation,’’ IEEE Access, vol. 9, pp. 36019–36037, 2021, doi:\n10.1109/access.2021.3061058.\n[67] E.-S.-M. El-Kenawy, M. M. Eid, M. Saber, and A. Ibrahim, ‘‘MbGWO-\nSFS: Modiﬁed binary grey wolf optimizer based on stochastic fractal\nsearch for feature selection,’’ IEEE Access, vol. 8, pp. 107635–107649,\n2020, doi: 10.1109/access.2020.3001151.\n[68] E.-S. M. El-kenawy, A. Ibrahim, S. Mirjalili, M. M. Eid, and S. E. Hussein,\n‘‘Novel feature selection and voting classiﬁer algorithms for COVID-19\nclassiﬁcation in CT images,’’ IEEE Access , vol. 8, pp. 179317–179335,\n2020, doi: 10.1109/access.2020.3028012.\n[69] A. Ibrahim, A. Tharwat, T. Gaber, and A. E. Hassanien, ‘‘Optimized\nsuperpixel and AdaBoost classiﬁer for human thermal face recognition,’’\nSignal, Image Video Process., vol. 12, no. 4, pp. 711–719, May 2018, doi:\n10.1007/s11760-017-1212-6.\nVOLUME 9, 2021 78339\nS. S. M. Ghoneimet al.: Adaptive Dynamic Meta-Heuristics for Feature Selection and Classification in Diagnostic Accuracy\n[70] S. Mirjalili, S. M. Mirjalili, S. Saremi, and S. Mirjalili, Whale Optimiza-\ntion Algorithm: Theory, Literature Review, and Application in Designing\nPhotonic Crystal Filters. Cham, Switzerland: Springer, 2020, pp. 219–238,\ndoi: 10.1007/978-3-030-12127-3_13.\n[71] E. Cuevas, F. Fausto, and A. González, Metaheuristics and Swarm\nMethods: A Discussion on Their Performance and Applications. Cham,\nSwitzerland: Springer, 2020, pp. 43–67, doi: 10.1007/978-3-030-16339-\n6_2.\n[72] F. Fausto, A. Reyna-Orta, E. Cuevas, Á. G. Andrade, and\nM. Perez-Cisneros, ‘‘From ants to whales: Metaheuristics for all tastes,’’\nArtif. Intell. Rev., vol. 53, no. 1, pp. 753–810, Jan. 2020.\n[73] S. I. Ibrahim, S. S. M. Ghoneim, and I. B. M. Taha, ‘‘DGALab: An exten-\nsible software implementation for DGA,’’ IET Gener., Transmiss. Distrib.,\nvol. 12, no. 18, pp. 4117–4124, Sep. 2018, doi: 10.1049/iet-gtd.2018.5564.\nSHERIF S. M. GHONEIM (Senior Member,\nIEEE) received the B.Sc. and M.Sc. degrees from\nthe Faculty of Engineering at Shoubra, Zagazig\nUniversity, Egypt, in 1994 and 2000, respectively,\nand the Ph.D. degree in electrical power and\nmachines from the Faculty of Engineering, Cairo\nUniversity, in 2008. Since 1996, he has been\nteaching with the Faculty of Industrial Educa-\ntion, Suez Canal University, Egypt. From 2005 to\n2007, he was a Guest Researcher with the Institute\nof Energy Transport and Storage (ETS), University of Duisburg–Essen,\nGermany. He joined Taif University as an Associate Professor with the\nElectrical Engineering Department, Faculty of Engineering. His research\ninterests include grounding systems, dissolved gas analysis, breakdown in\nSF6 gas, and AI technique applications.\nTAMER AHMED FARRAG was born, in 1981.\nHe received the B.Sc., M.Sc., and Ph.D. degrees\nfrom the Department of Computers and Sys-\ntems Engineering, Mansoura University, Egypt,\nin 2002, 2006, and 2012, respectively. In Egypt,\nhe worked as an Assistant Professor with the\nDepartment of Computer Engineering, MISR\nHigher Institute for Engineering and Technology.\nHis research interests include artiﬁcial intelli-\ngence, optimization, programming languages, and\ncomputing systems.\nA. ALI RASHEDis currently a Staff Member with Taif University, Taif, Saudi\nArabia. He has authored or coauthored in more than six technical articles. His\nresearch interests include electrical power systems and machine learning.\nEL-SAYED M. EL-KENAWY(Member, IEEE) is\ncurrently an Assistant Professor with the Delta\nHigher Institute for Engineering & Technology\n(DHIET), Mansoura, Egypt. Inspiring and moti-\nvating students by providing a thorough under-\nstanding of a variety of computer concepts.\nHe has published over 30 publications with over\n650 citations and an H-index of 18. He has pio-\nneered and launched independent research pro-\ngrams. Adept at sometimes explaining complex\nconcepts in an easy-to-understand manner. He also serves as a Reviewer\nfor journal IEEE ACCESS. His research interests include optimization, arti-\nﬁcial intelligence, machine learning, deep learning, data science, and digital\nmarketing.\nABDELHAMEED IBRAHIM (Member, IEEE)\nreceived the bachelor’s and master’s degrees in\nengineering from the Department of Computer\nEngineering and Systems, in 2001 and 2005,\nrespectively, and the Ph.D. degree in engineering\nfrom the Faculty of Engineering, Chiba Univer-\nsity, Japan, in 2011. He was with the Faculty of\nEngineering, Mansoura University, Egypt, from\n2001 to 2007, where he is currently an Asso-\nciate Professor of Computer Engineering with the\nFaculty of Engineering. He has published over 50 publications with over\n900 citations and an H-index of 18. He also serves as a Reviewer for the\nJournal of Electronic Imaging, Optical Engineering, the IEEE JOURNAL OF\nBIOMEDICAL AND HEALTH INFORMATICS, IEEE ACCESS, Computer Standards and\nInterfaces, Journal of Healthcare Engineering, IET Image Processing, Mul-\ntimedia Tools and Applications, and other respected journals. His research\ninterests include pattern recognition, optimization, machine learning, virtu-\nalization, and live virtual machine migration.\n78340 VOLUME 9, 2021",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6273157596588135
    },
    {
      "name": "Transformer",
      "score": 0.594226598739624
    },
    {
      "name": "Dissolved gas analysis",
      "score": 0.5083343386650085
    },
    {
      "name": "Diagnostic accuracy",
      "score": 0.4353031814098358
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4285552203655243
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.36613327264785767
    },
    {
      "name": "Transformer oil",
      "score": 0.28793418407440186
    },
    {
      "name": "Engineering",
      "score": 0.24832141399383545
    },
    {
      "name": "Voltage",
      "score": 0.13846653699874878
    },
    {
      "name": "Radiology",
      "score": 0.0
    },
    {
      "name": "Medicine",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I179331831",
      "name": "Taif University",
      "country": "SA"
    },
    {
      "id": "https://openalex.org/I4210134598",
      "name": "Scientific Research Group in Egypt",
      "country": "EG"
    },
    {
      "id": "https://openalex.org/I4210120363",
      "name": "Higher Institute of Engineering",
      "country": "EG"
    },
    {
      "id": "https://openalex.org/I159247623",
      "name": "Mansoura University",
      "country": "EG"
    }
  ]
}