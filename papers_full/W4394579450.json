{
    "title": "Extending Context Window in Large Language Models with Segmented Base Adjustment for Rotary Position Embeddings",
    "url": "https://openalex.org/W4394579450",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2097098582",
            "name": "Rongsheng Li",
            "affiliations": [
                "University Town of Shenzhen",
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A2008268640",
            "name": "Jin Xu",
            "affiliations": [
                "Tsinghua University",
                "University Town of Shenzhen"
            ]
        },
        {
            "id": "https://openalex.org/A2768177078",
            "name": "Zhixiong Cao",
            "affiliations": [
                "University Town of Shenzhen",
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A2508172955",
            "name": "Hai-Tao Zheng",
            "affiliations": [
                "University Town of Shenzhen",
                "Tsinghua University",
                "Peng Cheng Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A2641490281",
            "name": "Hong-Gee Kim",
            "affiliations": [
                "Seoul National University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2064675550",
        "https://openalex.org/W2963925437",
        "https://openalex.org/W3196318247",
        "https://openalex.org/W4385570645",
        "https://openalex.org/W4285225959",
        "https://openalex.org/W4362655426",
        "https://openalex.org/W2970971581",
        "https://openalex.org/W2132083787",
        "https://openalex.org/W3081168214",
        "https://openalex.org/W2986922898",
        "https://openalex.org/W3152388841"
    ],
    "abstract": "In the realm of large language models (LLMs), extending the context window for long text processing is crucial for enhancing performance. This paper introduces SBA-RoPE (Segmented Base Adjustment for Rotary Position Embeddings), a novel approach designed to efficiently extend the context window by segmentally adjusting the base of rotary position embeddings (RoPE). Unlike existing methods, such as Position Interpolation (PI), NTK, and YaRN, SBA-RoPE modifies the base of RoPE across different dimensions, optimizing the encoding of positional information for extended sequences. Through experiments on the Pythia model, we demonstrate the effectiveness of SBA-RoPE in extending context windows, particularly for texts exceeding the original training lengths. We fine-tuned the Pythia-2.8B model on the PG-19 dataset and conducted passkey retrieval and perplexity (PPL) experiments on the Proof-pile dataset to evaluate model performance. Results show that SBA-RoPE maintains or improves model performance when extending the context window, especially on longer text sequences. Compared to other methods, SBA-RoPE exhibits superior or comparable performance across various lengths and tasks, highlighting its potential as an effective technique for context window extension in LLMs.",
    "full_text": null
}