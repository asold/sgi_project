{
  "title": "Multilingual LLMs are Better Cross-lingual In-context Learners with Alignment",
  "url": "https://openalex.org/W4385572198",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4365818928",
      "name": "Eshaan Tanwar",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2290175416",
      "name": "Subhabrata Dutta",
      "affiliations": [
        "Indian Institute of Technology Delhi"
      ]
    },
    {
      "id": "https://openalex.org/A5108299140",
      "name": "Manish Borthakur",
      "affiliations": [
        "Indian Institute of Technology Delhi"
      ]
    },
    {
      "id": "https://openalex.org/A2128156271",
      "name": "Tanmoy Chakraborty",
      "affiliations": [
        "Indian Institute of Technology Delhi"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3093517588",
    "https://openalex.org/W3198599617",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W3172943453",
    "https://openalex.org/W4311726128",
    "https://openalex.org/W4287888325",
    "https://openalex.org/W3122241445",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3100880133",
    "https://openalex.org/W3107826490",
    "https://openalex.org/W4286769130",
    "https://openalex.org/W3196642073",
    "https://openalex.org/W3100806282",
    "https://openalex.org/W4226155321",
    "https://openalex.org/W4385573436",
    "https://openalex.org/W4317466024",
    "https://openalex.org/W2954226438",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4205523161",
    "https://openalex.org/W2171068337",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W3169483174",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3083410900",
    "https://openalex.org/W3104820280",
    "https://openalex.org/W4385573402"
  ],
  "abstract": "In-context learning (ICL) unfolds as large language models become capable of inferring test labels conditioned on a few labeled samples without any gradient update. ICL-enabled large language models provide a promising step forward toward bypassing recurrent annotation costs in a low-resource setting. Yet, only a handful of past studies have explored ICL in a cross-lingual setting, in which the need for transferring label-knowledge from a high-resource language to a low-resource one is immensely crucial. To bridge the gap, we provide the first in-depth analysis of ICL for cross-lingual text classification. We find that the prevalent mode of selecting random input-label pairs to construct the prompt-context is severely limited in the case of cross-lingual ICL, primarily due to the lack of alignment in the input as well as the output spaces. To mitigate this, we propose a novel prompt construction strategy — Cross-lingual In-context Source Target Alignment (X-InSTA). With an injected coherence in the semantics of the input examples and a task-based alignment across the source and target languages, X-InSTA is able to outperform random prompt selection by a large margin across three different tasks using 44 different cross-lingual pairs.",
  "full_text": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\nVolume 1: Long Papers, pages 6292–6307\nJuly 9-14, 2023 ©2023 Association for Computational Linguistics\nMultilingual LLMs are Better Cross-lingual\nIn-context Learners with Alignment\nEshaan Tanwar\nDTU, India\neshaantanwar2000@gmail.com\nSubhabrata Dutta\nIIT Delhi, India\nsubha0009@gmail.com\nManish Borthakur\nIIT Delhi, India\nmt6190493@iitd.ac.in\nTanmoy Chakraborty\nIIT Delhi, India\ntanchak@iitd.ac.in\nAbstract\nIn-context learning (ICL) unfolds as large lan-\nguage models become capable of inferring test\nlabels conditioned on a few labeled samples\nwithout any gradient update. ICL-enabled\nlarge language models provide a promising\nstep forward toward bypassing recurrent an-\nnotation costs in a low-resource setting. Yet,\nonly a handful of past studies have explored\nICL in a cross-lingual setting, in which the\nneed for transferring label-knowledge from a\nhigh-resource language to a low-resource one\nis immensely crucial. To bridge the gap, we\nprovide the first in-depth analysis of ICL for\ncross-lingual text classification. We find that\nthe prevalent mode of selecting random input-\nlabel pairs to construct the prompt-context is\nseverely limited in the case of cross-lingual\nICL, primarily due to the lack of alignment\nin the input as well as the output spaces. To\nmitigate this, we propose a novel prompt con-\nstruction strategy – Cross-lingual In-context\nSource-Target Alignment (X-InSTA). With an\ninjected coherence in the semantics of the input\nexamples and a task-based alignment across the\nsource and target languages, X-InSTA is able\nto outperform random prompt selection by a\nlarge margin across three different tasks using\n44 different cross-lingual pairs.\n1 Introduction\nThe emergence of large-scale, pretrained,\nTransformer-based language models (LLMs) has\nmarked the commencement of an avant-garde era\nin NLP. Departing from the traditional methods\nof neural language learning with temporally\nseparated training-testing phases for downstream\ntasks, pretrained LLMs have shown the ability to\ninfer labels from test inputs conditioned on the\ntraining data within a single pass. This is known\nas In-context learning – an LLM is prompted\nET and SD contributed equally. ET and SD designed the\nexperiments. ET and MB ran the experiments. SD and TC\nwrote the paper. TC mentored the project.\nwith a few input-output pairs from the training\ndata (commonly referred to as demonstrations)\nfollowed by the test input; for generative tasks\n(summarization, text-to-code, chain-of-thought\nreasoning, etc.) the LLM is then required to\nproduce an output; for classification tasks, the\nprobabilities of the next tokens predicted by the\nLLM are mapped to the label space. All of this is\ndone without updating the parameters of the LLM.\nIn-context learning is particularly promising for\ntwo different aspects. Firstly, it reduces the need\nfor task-specific training data, and thus, the cost\nof human annotation. Secondly, while the LLM\nwas trained in a compute-intensive environment,\nthe removal of the need for task-specific gradient-\nbased weight updates can significantly reduce\nthe carbon footprint of automated NLP/NLU\nsince the inference-time compute-necessity is\norders of magnitude smaller than that of the\ntraining/finetuning phases. Multiple recent\nadvancements have been proposed to optimize\nthe ICL ability of the LLMs (Lin et al., 2021;\nChowdhery et al., 2022; Liu et al., 2022; Zhang\net al., 2021).\nChallenges in cross-lingual ICL: Given that\nthere is an order-of-magnitude discrepancy in the\navailability of annotated data in a high-resource lan-\nguage vs. a low-resource one, the ability to learn\nfrom the high-resource source context to solve\ntasks in low-resource targets sounds enticing. Yet,\nthe application of ICL in a cross-lingual setting\nremains largely unexplored. Previous attempts at\nmultilingual ICL (Zhang et al., 2021; Winata et al.,\n2021) use randomly selected input-label pairs to\nconstruct the prompt-context. This limits the abil-\nity of an LLM to infer from the context. As Xie\net al. (2022) suggested, ICL emerges as the ability\nto infer target labels from the pretraining distribu-\ntion conditioned upon the context; each input-label\npair in the prompt-context are, in turn, sampled\nfrom the prompt token distribution. Theoretically,\n6292\nReview: cannot operate this without using 2 hands. doesnt that\ndefeat the point of using it in the .. \n... \nReview: they were nice but too big. Rating:\nReview: So unhappy with these! Hold no charge and \nstopped working after a few,Probably ... \n... \nReview: Failed on first day of use. It worked fine for a while,\nmaybe 30 minutes of intermittent us\nExamen: Bonjour, En fait, j’ai un probleme avec cette\ncommande. Certaines pieces manquent. Je vous joins la photo\ndu système après montage. Les 2 pieces bleues en plastique a\nfixer aux extrémités des bras tournants n’ont pas été livrees\ndans le colis. Pourriez vous me les faire parvenir. Salutations.\nLoic Menez Évaluation:\nReview: Piece of junk! It comes in a million little pieces with no\ninstructions on how to put together. T... \n... \nReview: I don’t know... I received had a cracked plastic piece\nReview: cannot operate this without using 2 hands. doesnt that\ndefeat the point of using it in the... \n... \nReview: they were nice but too big. Rating:.. \nIn French bad means mal and good means bien.\nExamen: j ai commencé a écrire correctement puis au bout de 10\nlignes l'encre commence a sortir difficilement je suis très déçu de la\nqualité de ces recharges je ne pense pas que ce soit des\nrecharges mont banc malgré l'emballage.....je vais faire une\nréclamation  Évaluation:\nReview: cannot operate this without using 2 hands. doesnt  \nthat defeat the point of using it in the... \n... \nReview: they were nice but too big. Rating:.. \nIn French bad means mal and good means bien.\nReview: Great pen set. I love the colors and the writing is very\nsmooth. A few of the pens I received were broken upon... \n... \n..arrived cracked and broken. a very bad experience..... \nIn French bad means mal and good means bien.\nInput\nRandom:\nSemantic aligned: Task aligned:\nSemantic aligned:\nInput\nTask aligned:\nInput\nExamen: Après seulement une petite semaine d'utilisation ou une\nvingtaine d'heure, en plus utilisation peu intensive la carte a\nsubitement décider de ne plus fonctionner. Ayant retrouver\nplusieurs commentaires présentant le même problème le défaut\ndoit donc être récurrent je déconseille vivement d'acheter cette\ncarte sur amazon. Évaluation:\n1). 2). 3).\nTask and Semanticaligned:\nFigure 1: Working example of different ICL prompts explored in this work. In example #1, randomly selecting the\nprompt examples fails as it prompts irrelevant contradictions, whereas semantic alignment succeeds as it makes the\ncontext with similar reviews. In example #2, semantic alignment fails; it extracts demonstrations about ‘multiple\npieces’, but these are not helpful for the LLM, whereas a simple task aligner works. In the last example, it is a\ncombination of semantic and task alignments that works.\nthe expected prediction error decreases as the num-\nber of examples in the prompt increases. However,\nsuch infinitely long prompts are practically infea-\nsible to attain. Xie et al. (2022) imposed that a\ndistinguishability of the prompt-concept, shared\nacross the prompt-examples, from all other possi-\nble concepts is essential for an optimal predictor. A\nrandom sampling of prompt examples is unlikely\nto construct a prompt with distinguishable con-\ncepts. Furthermore, given (xi, yi) and (xi+1, yi+1)\nas two consecutive input-label pairs in the prompt-\ncontext, the transition probability from yi to xi+1\nis a low-probability one under the pretraining dis-\ntribution (Xie et al., 2022). The transition becomes\neven more improbable if we are to simply append\na test example to the prompt-context of a different\nlanguage. Consider the following example of ICL\nprompting for cross-lingual sentiment classifica-\ntion:\n1. That movie was good. Positive\n2. Depression is the new pandemic. Negative\n3. Ella lo está haciendo bien ?\nThe text segments are concatenated from left-to-\nright and top-to-bottom; therefore, two English\ninput-label pairs are followed by a Spanish test\ninput. There are irremovable, token-level low-\nprobability transitions from the labels to the next\ninput sentences. On top of this, we have three\ncompletely unrelated sentences juxtaposed together\nwith an abrupt change in language. Intuitively, it is\nless likely for an LLM to be able to map the third\ninput to its correct label, positiva (positive in Span-\nish) following the very much convoluted patterns\npresented in English.\nProposed approach: We seek to develop\nprompt-design strategies for ICL in a cross-lingual\nsetting that can overcome the foregoing challenges.\nA two-way alignment of the source and target ex-\namples is proposed. We start with injecting seman-\ntic coherence into the prompt-context by selecting\nsimilar examples; this aligns the labeled demon-\nstrations as well as the test inputs to share a set of\ncommon concepts. Next, we seek to enforce an\nalignment of task-level signals across languages.\nWe introduce manually-designed task-specific map-\npings from the source language to the target lan-\nguage, thereby providing the LLM with a ‘natu-\nral’ transition from the former to the latter. To-\ngether, these two approaches constitute our pro-\nposed prompts-selection strategy, X-InSTA (Cross-\nlingual In-context Source-Target Alignment, see\nFigure 1 for working examples). X-InSTA shows a\nstaggering 18% relative improvement over random\nprompt selection averaged across three different\ntext classification tasks in multiple different lan-\nguages with English being the source language.\nCareful perturbations to these alignment methods\ndisclose the importance of label space structure\ninduced by LLMs for cross-lingual ICL.\nOur contributions are summarized below1:\n1. We propose X-InSTA, a novel method of align-\ning prompt examples in a cross-lingual scenario.\nTo the best of our knowledge, this is the first at-\n1Code available at https://github.com/EshaanT/\nX-InSTA\n6293\ntempt to push prompt design techniques for ICL in\ncross-lingual settings beyond the trivial strategy of\nrandom example selection.\n2. We present the first, in-depth analysis of the role\nof semantic similarity between prompt examples\nfor cross-lingual ICL.\n3. A novel concept of task-based prompt alignment\nis presented. We show its efficacy with 44 different\nsource-target language pairs and empirically relate\nthis to the underlying structures of multilingual\nrepresentations of the LLM.\n2 Prompting Techniques\nIn this section, we lay out a step-by-step ap-\nproach to aligning semantic coherence and task-\nbased signals across source-target examples for\nICL prompts.\n2.1 Prelimineries\nLet Ds = {(xi\ns, yi\ns)}i be a monolingual labeled\ndataset in language s, realized as a collection of\ninput examples and their labels, xi\ns ∈ Xs and\nyi\ns ∈Ys, respectively. Here Ys is the natural lan-\nguage label space in language s. We have another\ncollection of input examples, Dt = {xi\nt}i, with\nexamples in language t. One can define a cross-\nlingual text classification task with source and tar-\nget languages being s and t in the following man-\nner. First, we select k input-label pairs from Ds to\nconstruct the prompt-context, C:\nC = x1\ns ⊕y1\ns ⊕[sep] ⊕··· xk\ns ⊕yk\ns (1)\nwhere [sep] denotes a separator token (e.g., new-\nlines), and ⊕denotes the concatenation operator.\nThe problem of in-context prediction then trans-\nlates to inferring the label yt ∈Yt, where Yt is the\nnatural language label space in language t corre-\nsponding to the test input xt ∈Dt conditioned on\nthe prompt-context C, as follows:\nyt = argmax\ny∈Yt\np(y|C ⊕xt)\ni.e., we select the maximum probability label in\nthe target label space generated by the model as\nthe token next to the test input xt appended to the\ncontext C. The source and target label spaces, Ys\nand Yt, share a one-to-one mapping among each\nother in terms of translation from s to t.\nOne of the most widely-used methods of con-\nstructing the context C, which we will henceforth\ncall random prompting , is to randomly select\n(xi\ns, yi\ns) from Ds and concatenate together. We\nexplore this method in our analysis, and it serves\nas a baseline for our experiments.\n2.2 Semantic Alignment\nChang et al. (2022) showed that multilingual mod-\nels encode these languages in a shared embed-\nding space, while still preserving several language-\nsensitive semantic information. Despite the lan-\nguage difference between source and target inputs,\nxs and xt, it is then likely that their semantic simi-\nlarities will be reflected in their hidden representa-\ntions constructed by LLM. Therefore, we hypothe-\nsize that choosing semantically similar examples to\nconstruct the prompt-context would help the model\ndo in-context inference. That is, if et is the em-\nbedding of the target and es that of the source, the\nhigher the similarity score between them, the better\nsentence xs will serve as a demonstration for the\ntarget sentence xt.\nInspired by Liu et al. (2022), we extract prompt\nexamples directly dependent on the test input dis-\ntribution. Here we utilize multilingual sentence-\ntransformers (Reimers and Gurevych, 2020) to\nextract the sentence embedding of the test input\nxt ∈Dt and the source inputs Xs. Based on the\ncosine similarity between the target input xj\nt and\nsource inputs xj\ns ∈Xs, we then extract the top k\ndemonstrations (see Algorithm 1). While the tar-\nget input and the demonstration differ in language,\nwe hypothesize that by pairing semantically simi-\nlar context demonstration and input sentence, the\nLLM would be able to improve its reasoning abil-\nity and subsequently, the final task performance\n(see Table 11 in Appendix D for examples of such\naligned demonstrations).\nAlgorithm 1: Semantic Alignment\nInput: An unlabeled target sentence xt, source data\nDs, multilingual sentence encoder, θ, and number of\nsamples to extract k.\nProcedure: et ←θ(xt)\nfor xs ∈Ds do\nei\ns ←θ(xi\ns)\nsi ←\net.ei\ns\n||et||2||eis||2\nend\nSelect top ksentences based on si\nC ←x1\ns ⊕y1\ns ⊕[sep] ⊕··· xk\ns ⊕yk\ns\nyt = argmaxy∈Yt p(y|C⊕xt)\n2.3 Task-based Alignment\nDespite the semantic coherence enforced within\nthe prompt-context via the previously mentioned\n6294\nmethod, the source and target label spaces,\nYs and Yt, remain superficially disconnected.\nFor fine-tuning, techniques like meta-learning\n(Nooralahzadeh et al., 2020), and adapters (Parovi´c\net al., 2022) have been used to bridge this gap. For\nin-context prompting in which context matters the\nmost, we propose to do so by adding a manually de-\nsigned statement that gives the LLM task-specific\ninformation like target language and target label\nspace.\nTask-based alignment is done by appending a\nmanually-designed statement, called task aligner\nto context. This aligner is supposed to inform\nthe LLM about the mapping from the source label\nspace Ys to the target label space Yt. We do task\nalignment by first manually creating Dl = {Ls,t}\nfor a given task and source-target language pairs\ns and t as a collection of statements in the source\nlanguage that emphasizes what the target label and\nlanguage are. For example, when the source is En-\nglish and the target is Spanish, “In Española bad\nmeans malo and good means bueno” will be the\nsaid task aligner that gives the information that the\ntarget language is Española (Spanish) and the target\nlabels are malo and bueno (bad and good, respec-\ntively). Next, we construct the prompt-context by\nrandomly selecting k source language examples,\nfollowed by the task aligner from this source-target\npair from Dl (see Algorithm 2). For more exam-\nples of task-aligned prompt design, please refer to\nTables 11 and 12 in Appendix D.\nAlgorithm 2: Task Alignment\nInput: An unlabeled target sentence xt, source\ndataset Ds, aligner Ls,t and number of samples to\nextract k.\nProcedure: Randomly select ksentences from Ds\nC ←x1\ns ⊕y1\ns ⊕[sep] ⊕··· xk\ns ⊕yk\ns\nC ←C⊕Ls,t\nyt = argmaxy∈Yt p(y|C⊕xt)\n2.4 X-InSTA\nWe finally move on to our proposed method\nX-InSTA that combines semantic alignment with\nthe task-based one. It first selects source exam-\nples from Ds with top-k similarity scores as men-\ntioned in Section 2.2. Additionally, we select task-\naligners from Dl depending on the source and tar-\nget languages and the task. Finally, we construct\nthe prompt context by concatenating the selected\nexamples followed by the task-aligner. The final\nSRC\nTAR de en es fr ja zh\nRandom Prompting\nde − 0.446 0 .517 0 .547 0 .454 0 .413\nen 0.380 − 0.761 0.663 0.526 0.362\nes 0.339 0 .696 − 0.563 0 .519 0 .445\nfr 0.340 0 .692 0.864 − 0.479 0 .410\nja 0.333 0.701 0.678 0 .612 − 0.678\nzh 0.333 0 .632 0 .836 0 .402 0 .521 −\nA VG 0.345 0 .633 0 .731 0 .557 0 .499 0 .462\nSemantic Alignment\nde − 0.6 0 .552 0 .679 0 .559 0 .483\nen 0.458 − 0.783 0.762 0.608 0 .450\nes 0.377 0.771 − 0.740 0 .643 0 .568\nfr 0.376 0 .752 0.879 − 0.565 0 .589\nja 0.333 0 .754 0 .733 0 .690 − 0.697\nzh 0.333 0 .682 0 .839 0 .536 0.675 −\nA VG 0.375 0 .713 0 .757 0 .681 0 .610 0 .557\nTask-based Alignment\nde − 0.567 0 .701 0 .768 0 .645 0 .333\nen 0.355 − 0.888 0.826 0 .727 0 .333\nes 0.334 0 .784 − 0.806 0.779 0.333\nfr 0.336 0 .783 0 .827 − 0.766 0 .333\nja 0.333 0.796 0.864 0.847 − 0.345\nzh 0.333 0 .682 0 .872 0 .543 0 .734 −\nA VG 0.338 0 .722 0 .830 0 .758 0 .730 0 .335\nX-InSTA\nde − 0.721 0 .756 0 .847 0 .760 0 .333\nen 0.382 − 0.891 0 .858 0 .783 0 .335\nes 0.348 0.857 − 0.875 0.851 0.334\nfr 0.356 0 .849 0.906 − 0.825 0 .336\nja 0.333 0 .832 0 .890 0 .845 − 0.348\nzh 0.333 0 .717 0 .883 0 .684 0 .809 −\nA VG 0.350 0 .795 0 .865 0 .822 0 .805 0 .337\nTable 1: Macro-F1 scores for different prompting tech-\nniques on the MARC dataset (source and target lan-\nguages are abbreviated as SRC and TAR, respectively).\nImprovement across all six languages can be observed\nonce we introduce semantic alignment. X-InSTA out-\nperforms rest of the methods on 4 out of 6 languages.\nlabel inference can be described as\nyt = argmax\ny∈Yt\np(y|x1\ns ⊕y1\ns ···xk\ns ⊕yk\ns ⊕Ls,t ⊕xt)\nwhere sim(xi\ns, xt) ≥sim(xi+1\ns , xt), and Ls,t ∈Dl\nis the task aligner for source and target languages\ns and t, respectively for the given task.\n3 Results and Analysis\nWe experiment on three datasets – Multilingual\nAmazon Reviews Corpus (MARC) (Keung et al.,\n2020), Cross-language sentiment classification\n(CLS) (Prettenhofer and Stein, 2010), and Hat-\nEval (Basile et al., 2019), spanning over twelve\nlanguage-task pairs and totalling 44 cross-lingual\nsetups (refer to Appendix A for further description\nof the datasets). The results on MARC, CLS and\nHatEval are shown in Tables 1, 2, and 3, respec-\ntively. For our main experiments, we make use of\n6295\nSource\nTarget de en fr ja\nRandom Prompting\nde − 0.517 0.597 0.618\nen 0.682 − 0.412 0 .609\nfr 0.545 0.694 − 0.666\nja 0.344 0 .595 0 .475 −\nA VG 0.524 0 .602 0 .495 0 .631\nSemantic Alignment\nde − 0.502 0.643 0.657\nen 0.677 − 0.505 0 .691\nfr 0.572 0.746 − 0.743\nja 0.344 0 .617 0 .481 −\nA VG 0.531 0 .621 0 .543 0 .697\nTask Alignment\nde − 0.618 0.741 0.753\nen 0.620 − 0.696 0 .752\nfr 0.511 0.782 − 0.824\nja 0.339 0 .658 0 .697 −\nA VG 0.490 0 .686 0 .711 0 .776\nX-InSTA\nde − 0.622 0.788 0.779\nen 0.588 − 0.778 0 .794\nfr 0.524 0.821 − 0.834\nja 0.339 0 .701 0 .705 −\nA VG 0.483 0 .715 0 .757 0 .803\nTable 2: Macro F1 scores on the CLS dataset.\nXGLM (Lin et al., 2021) 7.5 billion variant. We ex-\nperiment with various models with random prompt-\ning and select XGLM 7.5B for its performance\nsuperiority on various tasks (refer to Table 8 in Ap-\npendix B). For further details on the experimental\nsetup, please refer to Appendix C and Table 10 for\nthe language abbreviations used.\n3.1 Comparing Alignment Techniques\nSemantic Alignment: The improvement intro-\nduced by semantic alignment of the prompt-context\nover randomly-selected source examples is eminent\nin Tables 1, 2, and 3. On the MARC dataset, we\nobserve a 14% improvement in macro F1 scores\naveraged across different languages. This observa-\ntion is consistent across all target-source pairs on\nother datasets as well — a gain of 10% on Hateval,\nand 6% on CLS. This improvement over random\nexample selection is consistent across all language\npairs (except English-to-German in CLS) consid-\nered in this experiment. This is particularly note-\nworthy and one might lead to the conclusion that\ndynamically selecting prompt examples based on\nsemantic similarity aligns the LLM to become a\nbetter in-context learner irrespective of the task and\nthe languages.\nTask-based Alignment: Just by adding a task\naligner, we not only outperform random prompts\nbut also bring substantial improvements for simi-\nSource\nTarget es en\nRandom Prompting\nes − 0.274\nen 0.435 −\nA VG 0.435 0 .274\nSemantic Alignment\nes − 0.284\nen 0.493 −\nA VG 0.493 0 .284\nTask Alignment\nes − 0.269\nen 0.499 −\nA VG 0.499 0 .269\nX-InSTA\nes − 0.269\nen 0.542 −\nA VG 0.542 0 .269\nTable 3: Macro F1 scores on the HatEval dataset.\nlarity prompting, even though it is not dynamically\nvarying with input sentences. The improvement is\n18% in CLS, 8% in HatEval, and 15% in MARC,\nin terms of macro F1 scores averaged over different\nlanguage pairs.\nHowever, some languages like German in\nMARC and English in HatEval produce near-\nrandom predictions in all the set-ups we experi-\nmented with. This might be due to the model’s\ninability to perform ICL on these tasks in a cross-\nlingual manner for these languages. Previous stud-\nies observed such phenomena in monolingual ICL\n(Webson and Pavlick, 2022; Lin et al., 2021); cross-\nlingual ICL has its added nuances that make it even\nmore difficult.\nWe also see a performance drop in the case of\nMandarin in MARC (Table 1) while adding a task\naligner. We investigate the performance drop and\nnear-random results of German further.\nX-InSTA: This prompting mechanism inher-\nits both the benefits of semantic and task-based\nprompting, hence giving the best results in most\nlanguage pairs. But similar to task-based align-\nment, X-InSTA also performs badly on some target\nlanguages. The improvement is 23% on MARC,\n22% on CLS, and 14% on HatEval. We also note\nthat no specific language can be used as the best\nsource language.\n3.2 Why does Task Alignment Work?\nNext, we seek to validate the performance boost\nachieved via task-based aligners along with an at-\ntempt to explain the drop in performance with Man-\ndarin and German. We vary the task aligner and\n6296\nSetup\nTarget language de en es fr ja zh\nRandom prompt 0.345 0.633 0.731 0.557 0.499 0.462\nUniform label space 0.441 0.570 0.493 0.414 0.483 0.594\nTask alignment by language information only 0.346 0.645 0.733 0.575 0.543 0.508\nTask alignment via third language 0.345 0.687 0.755 0.673 0.601 0.423\nIncorrect task alignment 0.338 0.665 0.787 0.647 0.544 0.339\nTask Alignment 0.338 0.722 0.830 0.758 0.730 0.335\nTable 4: Understanding how task alignment works. Average F1-Macro across all source-target pairs on MARC.\nSetup\nTarget de en fr ja\nRandom 0.524 0.602 0.495 0.631\nNon-Semantic 0.531 0.561 0.453 0.515\nSemantic 0.531 0.621 0.543 0.697\nTable 5: Dissecting the role of semantic alignment;\nwe present macro-F1 scores corresponding to differ-\nent prompting techniques on the CLS dataset for each\nsource language averaged over all target languages.\nnote its effect on the output. We do so in five differ-\nent variations along with the original method (see\nTable 12 in Appendix D for detailed examples of\neach scenario):\n1. No aligner prompt added: Same as random\nprompting.\n2. Making the label space uniform: Across all\nsource-target setups, we set the source-label\ndistribution as output for the target too, reduc-\ning the need for task alignment.\n3. Only language information: Only giving\nthe language information to LLM, without\nproviding any further label information. An\nexample of such an aligner would be ‘The\nfollowing post is in French language’, in a\ncase when the source is English, and the target\nis French.\n4. Providing aligner but of a third unrelated\nlanguage: We set the aligner of a third lan-\nguage. For example ‘In Spanish bad means\nmalo and good means bueno.’, in a case when\nthe source is English and the target is French.\n5. Incorrect aligner: Making the aligner in-\ncorrect corresponding to the label space. For\nexample ‘In French bad means bien and good\nmeans mal.’, in a case when the source is En-\nglish and the target is French.\nIt’s all about the label information: In Table\n4, we note the importance of label space informa-\ntion. Providing the model with language infor-\nmation does improve the performance; however,\nthe improvement is minuscule compared to the im-\nprovement achieved via task aligners. This label\ninformation, even when of an unrelated third lan-\nguage, still helps the model predict better. This\nmight be due to the fact that the model looks more\nrigorously at label space for inference. Therefore,\nthis showcases the importance of labelling informa-\ntion while going cross-lingual.\nWhy drop in some languages? It is noteworthy\nthat in Table 4, the task aligner works best for all\ntarget languages except for German and Mandarin.\nBoth of these languages give the best results in\nuniform label space, i.e., when yt is made the same\nas ys. This points to the inability of the LLM to\nalign the label space of different source languages\nto these target languages. In making the label space\nuniform, we lose certain language-specific signals,\nbut this may also be seen as a way of reducing task\nalignment. Only for German and Mandarin do we\nsee this trade-off as beneficial; in all other cases,\nthe loss of language-specific features of yt leads to\na drop in performance.\n3.3 Role of semantic alignment\nTo understand the role of semantic alignment, we\nran an experiment in which instead of choosing k\nnearest neighbor of xt, we chose the most dissimi-\nlar sentences. Table 5 shows that there is a sharp\ndecrease in performance as compared to random\nprompting for all languages, with German as an\nexception. The average fall is 8% whereas using se-\nmantic alignment gives a gain of 10% w.r.t. random\nprompting.\n3.4 Automated aligner generation\nWe also expand our analyses to automatically gen-\nerate the aligner using mT5 (Xue et al., 2021). It\nis trained using a span generation task using sen-\ntences like ‘Paris <MASK> France’. The mT5\nmodel is trained to fill the mask token by generat-\ning spans like ‘is capital of’. In our usage, mT5\nwill fill the <MASK> between the input target test\nxt, and prompt context C in the source language\nto align the semantics of both. We summarize our\n6297\nSetup\nTarget MARC CLS HatEval\nde es fr ja zh de fr ja es\nRandom prompting 0.380 0.761 0.663 0.526 0.362 0.682 0.412 0.609 0.435\nSemantic alignment 0.458 0.783 0.762 0.608 0.450 0.677 0.505 0.691 0.493\nTask-based alignment 0.355 0.888 0.826 0.727 0.333 0.620 0.696 0.752 0.499\nAutomated aligner 0.531 0.792 0.699 0.599 0.350 0.721 0.430 0.610 0.438\nTable 6: Comparing the performance of automated aligners generated by mT5 with the rest of the methods in terms\nof macro-F1. We use English as the source language for all three tasks in this experiment.\nprocedure for automatic alignment generation in\nAlgorithm 3.\nAlgorithm 3: Task Alignment\nInput: An unlabeled target sentence xt, source data\nset Ds, multilingual-T5, mT5, multilingual LLM,\nM and number of samples to extract k.\nProcedure: Randomly select ksentences from Ds\nC ←x1\ns ⊕y1\ns ⊕[sep] ⊕··· xk\ns ⊕yk\ns\nL←mT5(C⊕[MASK] ⊕xt), where L is the\ngenerated span\nC ←C⊕L\nyt = argmaxy∈Yt p(y|C⊕xt)\nDue to the computational cost of generating the\nintermediate prompt for each source-target input\npair, we experiment with English as the only source\nlanguage in all three datasets. Table 6 summarizes\nthe results of using an automated aligner. We note\nthat the automated aligner leads to better results\nthan random prompting, and delivers results com-\npetitive to semantic prompting in some languages.\nHowever, it fails to incorporate any task-specific\nsignals, therefore failing to beat task-based align-\nment. One can note the limitations of this approach\nin terms of the different pretraining distributions\nof the in-context learner and the aligner generator\n(XGLM and mT5, respectively, in this scenario).\nThe hypothesized role of the aligner was to con-\nstruct a ‘natural’ transition from the source context\nto the target input for a particular task. Since mT5\ngenerates these aligners independently without any\naccess to the pretraining distribution of XGLM, the\ndisparity manifests with sub-optimal results.\n3.5 Error Analysis\nWe present four examples in Table 7, highlight-\ning the four major errors we notice while using\nX-InSTA, stemming from the following factors:\n1. Static task-aligner: In example #1, slurs are\nused by all the posts. In the context examples,\nthey are being used as hate speech; whereas in\nthe target, it is not directed at any individual and\nthereby, should not be identified as hate speech.\nHowever, the model labels it otherwise. Here, the\napparent semantic similarity is misdirecting the\nmodel, and the static nature of the task aligners is\nnot able to guide it to understand the nuances of\nthe task.\n2. Cultural differences: None of the alignment\nmethods introduces common knowledge or cultural\nknowledge in the prompt. To classify the tweet in\nexample #2, one must have a grasp of hate focused\non migration.\n3. Input length : Both the context prompt and the\ninput sentence are just too long in example #3.\nIn this case, no matter how better we design the\naligner, we cannot fit it within the maximum input\nlength of 1024 tokens. One cannot keep on increas-\ning the max-length to accommodate this pitfall, as\nthat might lead to higher computation costs. A\npossible solution can be found in the direction of\nTransformer architectures suitable for longer input\nsequences.\n4. Lack of human-like commonsense: In exam-\nple #4, alignment of the semantics and the task con-\nstructed a good prompt, but the model predicted\nit wrongly by getting confused by the sarcasm in\nthe first demonstration. To bridge this pitfall, we\nneed to bring more knowledge of humor or com-\nmonsense to make the model understand what is\nobvious to us.\nIt should be noted that the majority of these er-\nrors are stemming from the incapability of the LLM\nitself. Advancements in language model designs\nmay lead to betterment in future models.\n4 Related Works\nIn-context learning (ICL): Brown et al. (2020)\nintroduced a new approach, called in-context few-\nshot learning using the GPT-3 model. Subsequent\nefforts have been made to enhance the effective-\nness of ICL. Hendrycks et al. (2020) evaluated the\nbreadth and depth of model understanding to de-\ntermine its weaknesses and strengths. Techniques\nsuch as selecting semantically-similar examples,\nusing differentiable soft prompts for backpropaga-\ntion, and adjusting prompts to eliminate bias in\n6298\n# Prompt Input Output\n1.\nPost: @anne_theriault @hels Shut up cunt bitch whore Is hatefull? yes\nPost: @okaayythen bitch ass whore ass motherfucker Is hatefull? yes\nPost: @KoiyaThePerv bitch ass hoe Is hatefull? yes\nPost: @nonracialnigger Wow shut up you whore Is hatefull? yes\nIn Spanish no hate means no odio and yes means si odio\ncorreo: @Viplajo @blondeputicorn cál-\nlate era una historia de amor hijo de puta\nEs odioso?\nyes\n2.\ncorreo: @diegovftbau REENCUENTRO LA PUTA MADRE, DISFRUTALO\nMUCHO, LO RE MERECES AMIGA Es odioso? no\ncorreo: @AlejoIgoa @igoaftbau BIAN LA PUTA MADRE TE LO MERECES\nMAS QUE A NADIE Es odioso? no\ncorreo: @ansecas CÁLLATE LESBIANA HIJA DE PUTA QUE ESTÁ AHÍ TÚ\nHIJO BORT Es odioso? si\ncorreo: @Isranutrof CALLATE PUTA! MIS JOJOS VUELVEEEEN Es odioso?\nsi\nEn English no odio significa no hate y si odio significa yes hate\nPost: Arrest them and DEPORT THEM\nALL!!!!#BuildThatWall Is hateful? no\n3.\n</s> Examen: Bravo à Nicolas Jacquette pour avoir réussi à quitter l’enfer\nd’une secte qui met au pinacle le sacrifice de la vie des siens...TO LONG\nCONTEXT....bon signifie good\nReview: In the end, it appears ......THE\nPOST IS TOO LONG..... the problem\nthan for the individual transgressions of\ncertain priests Rating:\ngood\n4.\n</s> Review: The mice loved them & are holes in the bags to get to the inside\nproduct. Rating: bad\nReview: Product bag was smashed and bag was spilled out in box. Rating: bad\nReview: The product came in and the spoons are already cracked and broken.\nRating: bad\nReview: Item received was broken, with product leaking out and all over the jar.\nRating: bad\n</s> In French bad means mal and good means bien.</s>\nExamen: Produit bien reçu mais\npastilles a l’intérieur des sachets en mi-\nettes et un sachet craqué. Évaluation:\nbien\nTable 7: Error analysis ofX-InSTA. Four examples represent the major error characteristics (discussed in Section 3.5).\nWe omit most of the text in the test input of the 3rd example as it was too long.\npredictions have been implemented to optimize the\ninput prompt (Liu et al., 2022; Zhang et al., 2021;\nZhao et al., 2021). These efforts have primarily\nbeen directed toward improving the performance\nof ICL in a monolingual setting.\nMultiple recent studies have sought to explain\nthe emergence of ICL by assigning different roles\nto the LLM. Xie et al. (2022) provided the notion of\nLLMs doing Bayesian inference conditioned upon\nthe prompt context to predict the test label. Our\nwork is much in line with this hypothetical model\nsince alignment over the semantics and the task-\nbased signals across languages are motivated by\nthe quest for better alignment between the prompt\nand the pretraining distribution and warranting a\nshared, distinguishable concept as Xie et al. (2022)\nargued. Additionally, von Oswald et al. (2022)\nsought to identify LLMs doing gradient-descent as\nmeta-optimizers while learning in context. Li et al.\n(2023) described ICL as implicit model selection.\nMultilingual models: Recent studies on mul-\ntilingual tasks have focused on creating multilin-\ngual versions of popular pre-trained language mod-\nels. These include mBERT (Devlin et al., 2018),\nmBART (Liu et al., 2020), XLM-R (Conneau et al.,\n2020), and mT5 (Xue et al., 2020), which are de-\nrived from models like BERT (Devlin et al., 2018),\nBART (Lewis et al., 2020), RoBERTa (Liu et al.,\n2019), and T5 (Raffel et al., 2019), respectively.\nHowever, fine-tuning these large models for each\ntask is infeasible due to computational limitations.\nWhile ICL has been attempted for cross-lingual\ndownstream tasks, these methods only involve ran-\ndom sampling of demonstrations for prompt con-\nstruction (Zhang et al., 2021; Winata et al., 2021).\nShi et al. (2022) addressed the problem of cross-\nlingual text-to-sql conversion using ICL. However,\ntheir method relies on translating the input text in\nthe source language to the target language before\ngenerating the corresponding SQL code. Agrawal\net al. (2022) demonstrated the effects of similar\nexample selection in a few-shot machine transla-\ntion setting which is much similar to our proposed\nsemantic alignment. To the best of our knowledge,\nthere is no study on optimizing prompts for cross-\nlingual NLP tasks using ICL.\n5 Conclusion\nIn this work, we described the first-ever attempt\nin the direction of cross-lingual prompt design for\nin-context learning. We found that a random se-\nlection of labeled training examples to construct\nthe prompt-context limits the capability of a multi-\nlingual LLM to infer target labels. Instead, align-\ning the semantics as well as the task-specific tex-\ntual signals across the source and the target lan-\nguage inputs in the prompt demonstrates supe-\nrior performance in cross-lingual text classification.\n6299\nBased on these findings, we introduced X-InSTA,\na novel method of in-context prompt design for\ncross-lingual text classification. X-InSTA improves\nupon random prompt selection substantially across\nmultiple different cross-lingual tasks.\nWe found that the dynamicity of similarity-based\nexample selection is able to guide the LLM to learn\nbetter in-context predictors irrespective of the lan-\nguage pair under consideration. On the other hand,\nlanguage pairs with proper alignment in the label\nspace get more out of the task-based alignment.\nThese findings may serve as paving stones toward\nbetter cross-lingual ICL methods that incorporate\nan automated, dynamic transition from the source\nto target distributions.\nLimitations\nSince this work relies on the in-context learning\nability of large language models, the challenges\nassociated with computational resources to load an\nLLM ensue. Due to resource constraints, we could\nnot use larger or commercially available LLMs to\nvalidate if the advantages of X-InSTA translate to\nthose models as well.\nAs we observed in Section 3.5, the static na-\nture of the aligners poses a limitation on X-InSTA.\nMoreover, these aligners are manually designed.\nTherefore, task-specific, trial-and-error style man-\nual intervention is needed. We believe a better\nunderstanding of the pretraining distribution of the\nmultilingual LLMs can pave the way toward better\nautomated alignment methods.\nThere are multiple shortcomings of monolingual\nICL that entail its cross-lingual counterpart and\nX-InSTA does not address them; issues like knowl-\nedge hallucination, limited common-sense reason-\ning, inconsistency in retrieving factual associations,\netc.\nEthics statement\nOur proposed method, X-InSTA, delivers improve-\nments in cross-lingual in-context learning. Since\nin-context learning ability is emergent in language\nmodels over billion parameters in size, this can\ncause potential discrimination in the usage of these\nmethods based on the availability of access to com-\nputational resources. Research groups with limited\naccess to computational resources will be handi-\ncapped while resourceful groups will be able to\ninvestigate and advance the future directions of this\nresearch.\nWe did not use any private or sensitive infor-\nmation throughout this research. However, if any\nprivate information was leaked to an LLM during\nthe pretraining stage, X-InSTA does not provide\nany privacy filtration. Therefore, privacy concerns\nof the underlying model can potentially manifest\nwith the outputs provided by X-InSTA.\nAs we dissected the erroneous predictions in\nSection 3.5, the lack of knowledge of cultural dif-\nferences among different languages is a serious\nchallenge within the LLM and this limits the per-\nformance of X-InSTA. Therefore, any potential de-\nployment of our proposed method should be done\nunder the lens of such considerations. This is even\nmore delicate in case tasks like hate-speech clas-\nsification which was one of the tasks that we ex-\nplored in this work. Wrongfully identifying a hate\nspeech as non-hate or vice versa in a low-resource\ntarget language based on culturally different lan-\nguage usage cues present in the prompt-context in\na high-resource languages is a possibility; this may\nlead to unwarranted cultural appropriation and/or\nundemocratic gatekeeping.\nReferences\nSweta Agrawal, Chunting Zhou, Mike Lewis, Luke\nZettlemoyer, and Marjan Ghazvininejad. 2022. In-\ncontext examples selection for machine translation.\nValerio Basile, Cristina Bosco, Elisabetta Fersini,\nDebora Nozza, Viviana Patti, Francisco Manuel\nRangel Pardo, Paolo Rosso, and Manuela Sanguinetti.\n2019. SemEval-2019 task 5: Multilingual detection\nof hate speech against immigrants and women in\nTwitter. In Proceedings of the 13th International\nWorkshop on Semantic Evaluation, pages 54–63, Min-\nneapolis, Minnesota, USA. Association for Compu-\ntational Linguistics.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nTyler A Chang, Zhuowen Tu, and Benjamin K Bergen.\n2022. The geometry of multilingual language model\nrepresentations. arXiv preprint arXiv:2205.10964.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, et al. 2022. Palm: Scaling\nlanguage modeling with pathways. arXiv preprint\narXiv:2204.02311.\n6300\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 8440–\n8451, Online. Association for Computational Lin-\nguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning.\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou,\nMantas Mazeika, Dawn Song, and Jacob Steinhardt.\n2020. Measuring massive multitask language under-\nstanding.\nPhillip Keung, Yichao Lu, György Szarvas, and Noah A.\nSmith. 2020. The multilingual Amazon reviews cor-\npus. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 4563–4568, Online. Association for\nComputational Linguistics.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020.\nBART: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and com-\nprehension. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 7871–7880, Online. Association for Computa-\ntional Linguistics.\nYingcong Li, M Emrullah Ildiz, Dimitris Papailiopou-\nlos, and Samet Oymak. 2023. Transformers as\nalgorithms: Generalization and implicit model se-\nlection in in-context learning. arXiv preprint\narXiv:2301.07067.\nXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu\nWang, Shuohui Chen, Daniel Simig, Myle Ott, Na-\nman Goyal, Shruti Bhosale, Jingfei Du, et al. 2021.\nFew-shot learning with multilingual language models.\narXiv preprint arXiv:2112.10668.\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,\nLawrence Carin, and Weizhu Chen. 2022. What\nmakes good in-context examples for GPT-3? In\nProceedings of Deep Learning Inside Out (DeeLIO\n2022): The 3rd Workshop on Knowledge Extrac-\ntion and Integration for Deep Learning Architectures,\npages 100–114, Dublin, Ireland and Online. Associa-\ntion for Computational Linguistics.\nYinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey\nEdunov, Marjan Ghazvininejad, Mike Lewis, and\nLuke Zettlemoyer. 2020. Multilingual denoising pre-\ntraining for neural machine translation.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach.\nFarhad Nooralahzadeh, Giannis Bekoulis, Johannes\nBjerva, and Isabelle Augenstein. 2020. Zero-shot\ncross-lingual transfer with meta learning. arXiv\npreprint arXiv:2003.02739.\nMarinela Parovi´c, Goran Glavaš, Ivan Vuli´c, and Anna\nKorhonen. 2022. BAD-X: Bilingual adapters im-\nprove zero-shot cross-lingual transfer. In Proceed-\nings of the 2022 Conference of the North Ameri-\ncan Chapter of the Association for Computational\nLinguistics: Human Language Technologies, pages\n1791–1799, Seattle, United States. Association for\nComputational Linguistics.\nPeter Prettenhofer and Benno Stein. 2010. Cross-\nlanguage text classification using structural corre-\nspondence learning. In Proceedings of the 48th An-\nnual Meeting of the Association for Computational\nLinguistics, pages 1118–1127, Uppsala, Sweden. As-\nsociation for Computational Linguistics.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2019. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer.\nNils Reimers and Iryna Gurevych. 2020. Mak-\ning monolingual sentence embeddings multilin-\ngual using knowledge distillation. arXiv preprint\narXiv:2004.09813.\nPeng Shi, Rui Zhang, He Bai, and Jimmy Lin. 2022.\nXricl: Cross-lingual retrieval-augmented in-context\nlearning for cross-lingual text-to-sql semantic pars-\ning. arXiv preprint arXiv:2210.13693.\nJohannes von Oswald, Eyvind Niklasson, Ettore Ran-\ndazzo, João Sacramento, Alexander Mordvintsev, An-\ndrey Zhmoginov, and Max Vladymyrov. 2022. Trans-\nformers learn in-context by gradient descent. arXiv\npreprint arXiv:2212.07677.\nAlbert Webson and Ellie Pavlick. 2022. Do prompt-\nbased models really understand the meaning of their\nprompts? In Proceedings of the 2022 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, pages 2300–2344, Seattle, United States.\nAssociation for Computational Linguistics.\nGenta Indra Winata, Andrea Madotto, Zhaojiang Lin,\nRosanne Liu, Jason Yosinski, and Pascale Fung. 2021.\nLanguage models are few-shot multilingual learners.\nIn Proceedings of the 1st Workshop on Multilingual\nRepresentation Learning, pages 1–15, Punta Cana,\nDominican Republic. Association for Computational\nLinguistics.\nSang Michael Xie, Aditi Raghunathan, Percy Liang,\nand Tengyu Ma. 2022. An explanation of in-context\nlearning as implicit bayesian inference. In The Tenth\n6301\nInternational Conference on Learning Representa-\ntions, ICLR 2022, Virtual Event, April 25-29, 2022.\nOpenReview.net.\nLinting Xue, Noah Constant, Adam Roberts, Mihir Kale,\nRami Al-Rfou, Aditya Siddhant, Aditya Barua, and\nColin Raffel. 2020. mt5: A massively multilingual\npre-trained text-to-text transformer.\nLinting Xue, Noah Constant, Adam Roberts, Mihir Kale,\nRami Al-Rfou, Aditya Siddhant, Aditya Barua, and\nColin Raffel. 2021. mT5: A massively multilingual\npre-trained text-to-text transformer. In Proceedings\nof the 2021 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 483–498, On-\nline. Association for Computational Linguistics.\nNingyu Zhang, Luoqiu Li, Xiang Chen, Shumin Deng,\nZhen Bi, Chuanqi Tan, Fei Huang, and Huajun\nChen. 2021. Differentiable prompt makes pre-trained\nlanguage models better few-shot learners. arXiv\npreprint arXiv:2108.13161.\nTony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and\nSameer Singh. 2021. Calibrate before use: Improv-\ning few-shot performance of language models.\nA Dataset Details\nMultilingual Amazon Reviews Corpus: MARC\n(Keung et al., 2020) is a large-scale multilingual\ncorpus of Amazon reviews of customers. The cor-\npus consists of six distinct languages – German,\nEnglish, Spanish, French, Japanese, and Mandarin.\nEach language has a training set of size 200K that\nwe use for selecting our demonstrations and a test\nset of 40, 000 reviews classified as positive or neg-\native.\nCross-language sentiment classification:\nCLS (Prettenhofer and Stein, 2010) is a multilin-\ngual corpus of four languages – German, English,\nFrench, and Japanese. It consists of reviews on\nDVD, music, and books, with a training set and\na test set of 2, 000 sentences for each language\nclassified into negative and positive.\nHateval: HatEval (Basile et al., 2019) consists\nof two languages – English and Spanish, classi-\nfied into hate or non-hate. The test set contains\n3, 000 posts for English and 1, 600 for Spanish,\nwith the training set size being 5, 000 for Spanish\nand 10, 000 for English.\nB Model Variants\nWe experiment with multiple different LMs in their\nbase versions (i.e., random prompting) to gauge\ntheir ability, namely XGLM 7.5B, XGLM 1.7B,\nand Bloom 7.1B. Table 8 contains the performance\nof these models on a subset of the test data used\n(namely, CLS and HatEval with English as the\nsource language). As we can see, XGLM 7.5B\nappears to outperform other models by a significant\nmargin on multiple different tasks, and therefore,\nis used for the rest of the experiments.\nModel\nTarget CLS HatEval\nde fr ja es\nxglm-1.7B 0.711 0.382 0.395 0.370\nxglm-7.5B 0.682 0.412 0.609 0.435\nbloom-7.1B 0.33 0.355 0.508 0.373\nTable 8: Comparing the performance of different vari-\nants of multilingual generative models on random\nprompting. We use English as the source language in\nall the experiments.\nC Hyperparameters\nAll codes were written using PyTorch. We used\nthe Huggingface repository for loading the LLM\nand sentence transformer for extracting semantic\nsimilarity. Sklearn was used for calculating the\nF1 score. Table 9 describes values of different\nhyperparameters and compute resources used.\nD Miscellaneous\nD.1 Language Code\nRefer to Table 10 for this information.\nD.2 Prompt Examples\nWe show a few example prompts (demonstrations\nand test input) in Table 11. Additionally, in Ta-\nble 12, we demonstrate a few examples of different\ntask-aligners used for the analysis in Section 3.2.\n6302\nHyperparameter Value\nModel XGLM-7.5B\nGPU NVIDIA A100\nBatch Size 4\nMax length 1024\nSeeds 32,5,232,100,42\nk 4\nTable 9: List of hyperparameters used for experiments.\nLanguage ISO 639-1 code Family\nGERMAN DE IE: GERMANIC\nENGLISH EN IE: GERMANIC\nFRENCH FR IE: ITALIC\nSPANISH ES IE: ITALIC\nMANDARIN ZH SINO-TIBETAN\nJAPANESE JA JAPANIC\nTable 10: List of languages and their ISO codes used in\nour experiments.\n6303\nPrompting\nMethod Prompt Input Output\nRandom\nPrompting\n</s> Review: cannot operate this\nwithout using 2 hands. doesnt\nthat defeat the point of using it in\nthe car? I didnt realize how diffi-\ncult it would be to mount it with\na pop socket on the back, too Rat-\ning: bad </s> Review: Was skep-\ntical because these headphones\nare cheap and all the reviews are\nfive stars, well, here goes another\n5 stars one! For the price, you\nwon’t find anything better right\nnow. Rating: good</s> Review:\nthey were nice but too big. Rat-\ning: good</s>\nRevisar: no me llego el articulo\nme lo mando por correos normal\nsin seguimiento y nunca me llego\ntota un desastre Clasificación:\nmalo/bueno\nSemantic\nAlignment\n</s> Review: It never came in\nthe mail I never got it and they\ncharge me Rating: bad</s> Re-\nview: I never recieved this prod-\nuct and it never came in the mail.\nIt was never delivered to my ad-\ndress Rating: bad</s>\nRevisar: no me llego el articulo\nme lo mando por correos normal\nsin seguimiento y nunca me llego\ntota un desastre Clasificación:\nmalo/bueno\nTask Align-\nment\n</s> Review: cannot operate this\nwithout using 2 hands. doesnt\nthat defeat the point of using it in\nthe car? I didnt realize how diffi-\ncult it would be to mount it with\na pop socket on the back, too Rat-\ning: bad </s> Review: Was skep-\ntical because these headphones\nare cheap and all the reviews are\nfive stars, well, here goes an-\nother 5 stars one! For the price,\nyou won’t find anything better\nright now. Rating: good</s> Re-\nview: they were nice but too big.\nRating: good </s> In Española\nbad means malo and good means\nbueno.</s>\nRevisar: no me llego el articulo\nme lo mando por correos normal\nsin seguimiento y nunca me llego\ntota un desastre Clasificación:\nmalo/bueno\nX-InSTA\n</s> Review: It never came in\nthe mail I never got it and they\ncharge me Rating: bad</s> Re-\nview: I never received this prod-\nuct and it never came in the mail.\nIt was never delivered to my ad-\ndress Rating: bad</s> In Es-\npañola bad means malo and good\nmeans bueno.</s>\nRevisar: no me llego el articulo\nme lo mando por correos normal\nsin seguimiento y nunca me llego\ntota un desastre Clasificación:\nmalo/bueno\nTable 11: Examples of prompts for MARC. In all examples, the source is English while the target is Spanish. Blue\ntext marks the task aligner. The value of k is 2 in these examples.\n6304\nPrompting Method Prompt Input Output\nRandom Prompt\n</s> Review: cannot operate this with-\nout using 2 hands.... For the price, you\nwon’t find anything better right now.\nRating: good</s> Review: they were\nnice but too big. Rating: good\nRevisar: no me llego el articulo\nme lo mando por correos normal sin\nseguimiento y nunca me llego tota un\ndesastre Clasificación:\nmalo/bueno\nUniform Label Space\n</s> Review: cannot operate this with-\nout using 2 hands....For the price, you\nwon’t find anything better right now.\nRating: good</s> Review: they were\nnice but too big. Rating: good\nRevisar: no me llego el articulo\nme lo mando por correos normal sin\nseguimiento y nunca me llego tota un\ndesastre Clasificación:\nbad/good\nLanguage Information\nOnly\n</s> Review: cannot operate this with-\nout using 2 hands....For the price, you\nwon’t find anything better right now.\nRating: good</s> Review: they were\nnice but too big. Rating: good</s> The\nfollowing post is in Española </s>\nRevisar: no me llego el articulo\nme lo mando por correos normal sin\nseguimiento y nunca me llego tota un\ndesastre Clasificación:\nmalo/bueno\nThird language aligner\n</s> Review: cannot operate this with-\nout using 2 hands....For the price, you\nwon’t find anything better right now.\nRating: good</s> Review: they were\nnice but too big. Rating: good</s> In\nFrench bad means mal and good means\nbien.</s>\nRevisar: no me llego el articulo\nme lo mando por correos normal sin\nseguimiento y nunca me llego tota un\ndesastre Clasificación:\nmalo/bueno\nTask Alignment\n</s> Review: cannot operate this with-\nout using 2 hands....For the price, you\nwon’t find anything better right now.\nRating: good</s> Review: they were\nnice but too big. Rating: good </s> In\nEspañola bad means bueno and good\nmeans malo.</s>\nRevisar: no me llego el articulo\nme lo mando por correos normal sin\nseguimiento y nunca me llego tota un\ndesastre Clasificación:\nmalo/bueno\nTable 12: Examples of different types of task aligners. Blue text marks the task aligner. As there is variation only in\nthe aligner and none in the demonstration of the context prompt, the demonstrations are shortened. In the examples,\nEnglish serves as the source language while Spanish is the target language. Hence, Yt is {malo, bueno} and Ys is\n{bad, good}. In the second row, the labels are colored in red to highlight that we have made Yt the same as Ys, i.e.,\nfor the input example we will label based on the label space {bad, good}, therefore, making the label space uniform.\nIn the fourth row, the aligner of a third unrelated language is given (French in this case).\n6305\nACL 2023 Responsible NLP Checklist\nA For every submission:\n□\u0013 A1. Did you describe the limitations of your work?\nSection 6.\n□\u0013 A2. Did you discuss any potential risks of your work?\nSection 7.\n□\u0013 A3. Do the abstract and introduction summarize the paper’s main claims?\nLeft blank.\n□\u0017 A4. Have you used AI writing assistants when working on this paper?\nLeft blank.\nB □ Did you use or create scientiﬁc artifacts?\nNot applicable. Left blank.\n□ B1. Did you cite the creators of artifacts you used?\nNo response.\n□ B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\nNo response.\n□ B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\nNo response.\n□ B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiﬁes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nNo response.\n□ B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\nNo response.\n□ B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiﬁcant, while on small test sets they may not be.\nNo response.\nC □\u0013 Did you run computational experiments?\nSection 3.\n□\u0013 C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\nAppendix A\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n6306\n□\u0013 C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\nAppendix A\n□\u0013 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\nLeft blank.\n□\u0013 C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\nLeft blank.\nD □\u0017 Did you use human annotators (e.g., crowdworkers) or research with human participants?\nLeft blank.\n□ D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\nNo response.\n□ D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants’ demographic\n(e.g., country of residence)?\nNo response.\n□ D3. Did you discuss whether and how consent was obtained from people whose data you’re\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nNo response.\n□ D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\nNo response.\n□ D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nNo response.\n6307",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7703151702880859
    },
    {
      "name": "Context (archaeology)",
      "score": 0.7468377947807312
    },
    {
      "name": "Coherence (philosophical gambling strategy)",
      "score": 0.5912812352180481
    },
    {
      "name": "Margin (machine learning)",
      "score": 0.5817509889602661
    },
    {
      "name": "Task (project management)",
      "score": 0.5789215564727783
    },
    {
      "name": "Annotation",
      "score": 0.5600806474685669
    },
    {
      "name": "Natural language processing",
      "score": 0.5471977591514587
    },
    {
      "name": "Resource (disambiguation)",
      "score": 0.5153738856315613
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5073444247245789
    },
    {
      "name": "Selection (genetic algorithm)",
      "score": 0.47641265392303467
    },
    {
      "name": "Bridge (graph theory)",
      "score": 0.4550328254699707
    },
    {
      "name": "Machine learning",
      "score": 0.2525860071182251
    },
    {
      "name": "Mathematics",
      "score": 0.0916985273361206
    },
    {
      "name": "Medicine",
      "score": 0.06546950340270996
    },
    {
      "name": "Computer network",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Internal medicine",
      "score": 0.0
    },
    {
      "name": "Statistics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I68891433",
      "name": "Indian Institute of Technology Delhi",
      "country": "IN"
    }
  ]
}