{
    "title": "Block-Sparse Adversarial Attack to Fool Transformer-Based Text Classifiers",
    "url": "https://openalex.org/W4224920313",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2899035194",
            "name": "Sahar Sadrizadeh",
            "affiliations": [
                "École Polytechnique Fédérale de Lausanne"
            ]
        },
        {
            "id": "https://openalex.org/A4883716",
            "name": "Ljiljana Dolamic",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2063844727",
            "name": "Pascal Frossard",
            "affiliations": [
                "École Polytechnique Fédérale de Lausanne"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2799194071",
        "https://openalex.org/W2962818281",
        "https://openalex.org/W2949128310",
        "https://openalex.org/W2988194011",
        "https://openalex.org/W2962718684",
        "https://openalex.org/W2996851481",
        "https://openalex.org/W3101449015",
        "https://openalex.org/W2114595593",
        "https://openalex.org/W2963846996",
        "https://openalex.org/W2243397390",
        "https://openalex.org/W6637162671",
        "https://openalex.org/W2963834268",
        "https://openalex.org/W6739868092",
        "https://openalex.org/W6730161283",
        "https://openalex.org/W2963083752",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W2194775991",
        "https://openalex.org/W6794593925",
        "https://openalex.org/W6685053522",
        "https://openalex.org/W6749879876",
        "https://openalex.org/W3158360872",
        "https://openalex.org/W2794557536",
        "https://openalex.org/W4293846201",
        "https://openalex.org/W2170240176",
        "https://openalex.org/W1673923490",
        "https://openalex.org/W4300996741",
        "https://openalex.org/W3035736465",
        "https://openalex.org/W4385245566"
    ],
    "abstract": "Recently, it has been shown that, in spite of the significant performance of deep neural networks in different fields, those are vulnerable to adversarial examples. In this paper, we propose a gradient-based adversarial attack against transformer-based text classifiers. The adversarial perturbation in our method is imposed to be block-sparse so that the resultant adversarial example differs from the original sentence in only a few words. Due to the discrete nature of textual data, we perform gradient projection to find the minimizer of our proposed optimization problem. Experimental results demonstrate that, while our adversarial attack maintains the semantics of the sentence, it can reduce the accuracy of GPT-2 to less than 5% on different datasets (AG News, MNLI, and Yelp Reviews). Furthermore, the block-sparsity constraint of the proposed optimization problem results in small perturbations in the adversarial example. (1)",
    "full_text": null
}