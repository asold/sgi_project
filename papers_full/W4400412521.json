{
    "title": "Exploring the Prompt Space of Large Language Models through Evolutionary Sampling",
    "url": "https://openalex.org/W4400412521",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A3100218420",
            "name": "Martina Saletta",
            "affiliations": [
                "University of Bergamo"
            ]
        },
        {
            "id": "https://openalex.org/A2122796275",
            "name": "Claudio Ferretti",
            "affiliations": [
                "University of Milano-Bicocca"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6810081322",
        "https://openalex.org/W4386839807",
        "https://openalex.org/W2107726111",
        "https://openalex.org/W2302057568",
        "https://openalex.org/W2296218809",
        "https://openalex.org/W4294811486",
        "https://openalex.org/W3098267758",
        "https://openalex.org/W4285129823",
        "https://openalex.org/W3162108968",
        "https://openalex.org/W4224308101"
    ],
    "abstract": "Large language models (LLMs) are increasingly gaining relevance in every-day life, due to their apparent ability in solving tasks that demand intricate linguistic comprehension. Recent studies state that one of the key points that impact their outcome is the quality of the prompt used to interact with them. This work proposes a grammar-based evolutionary approach for exploring the prompt space of LLMs, driven by a fitness function that aims at optimizing the performance on a given task. We tested our technique by steering two state-of-the-art models through evolved prompts, and by comparing the performance they obtain on 8 benchmark tasks with that obtained when using other baseline prompts on the same tasks, showing that in most cases our prompts yield better results. Further, we defined a constrained mutation operator that limits the changes to specific grammar non-terminals, allowing to study and highlight the elements in the prompt that mostly affect the output of the LLM. Finally, a thorough discussion points out some issues that limit the relevance of the emerging prompt engineering discipline, given the existence of many effective prompt structures and the possible diversity that can be observed in the LLM output given the same input to the model.",
    "full_text": null
}