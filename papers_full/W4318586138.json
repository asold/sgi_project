{
  "title": "Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification Using the Multimodal Fusion Transformer",
  "url": "https://openalex.org/W4318586138",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2146637135",
      "name": "Tae Won Lee",
      "affiliations": [
        "Chung-Ang University"
      ]
    },
    {
      "id": "https://openalex.org/A1879820226",
      "name": "Pawel Teisseyre",
      "affiliations": [
        "Polish Academy of Sciences",
        "Institute of Computer Science"
      ]
    },
    {
      "id": "https://openalex.org/A2100579529",
      "name": "Jae-Sung Lee",
      "affiliations": [
        "Chung-Ang University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3080733778",
    "https://openalex.org/W1933113571",
    "https://openalex.org/W2159878099",
    "https://openalex.org/W3035588244",
    "https://openalex.org/W3177318507",
    "https://openalex.org/W2077654972",
    "https://openalex.org/W3011727199",
    "https://openalex.org/W3126284633",
    "https://openalex.org/W3173539742",
    "https://openalex.org/W2079605058",
    "https://openalex.org/W2171234954",
    "https://openalex.org/W2799635155",
    "https://openalex.org/W1975372198",
    "https://openalex.org/W2000950277",
    "https://openalex.org/W3146366485",
    "https://openalex.org/W1980836123",
    "https://openalex.org/W6631190155",
    "https://openalex.org/W2734777338",
    "https://openalex.org/W3047180632",
    "https://openalex.org/W2790531191",
    "https://openalex.org/W2744043447",
    "https://openalex.org/W6739394593",
    "https://openalex.org/W1565746575",
    "https://openalex.org/W6704825425",
    "https://openalex.org/W2169533279",
    "https://openalex.org/W6637359451",
    "https://openalex.org/W2159345505",
    "https://openalex.org/W6681496859",
    "https://openalex.org/W2012079387",
    "https://openalex.org/W1969852690",
    "https://openalex.org/W2206592226",
    "https://openalex.org/W2890270470",
    "https://openalex.org/W3155398915",
    "https://openalex.org/W2116209939",
    "https://openalex.org/W2780013296",
    "https://openalex.org/W4289639877",
    "https://openalex.org/W6755591634",
    "https://openalex.org/W2992429266",
    "https://openalex.org/W2783987496",
    "https://openalex.org/W3110378470",
    "https://openalex.org/W2166014406",
    "https://openalex.org/W2015174807",
    "https://openalex.org/W3024494371",
    "https://openalex.org/W3105750503",
    "https://openalex.org/W6799370299",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W1979161824",
    "https://openalex.org/W6772412004",
    "https://openalex.org/W2936404407",
    "https://openalex.org/W4285402398",
    "https://openalex.org/W6802558818",
    "https://openalex.org/W3170487013",
    "https://openalex.org/W3212890323",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4300511110",
    "https://openalex.org/W3204866564",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2964413206",
    "https://openalex.org/W2145299490",
    "https://openalex.org/W2624187848",
    "https://openalex.org/W1683511521",
    "https://openalex.org/W3159202476",
    "https://openalex.org/W4287025617"
  ],
  "abstract": "An enormous ripple effect can occur in financial data mining if it accurately predicts stock prices. However, predicting stock prices using only stock price data is difficult because of the random nature of stock price data. This paper attempts to fuse data to solve the stock price prediction problem. The following data affecting the stock price are added to the proposed method as an additional modality: macroeconomic indicators and the months and day of the week. The multimodal early fusion method is used, which learns the intermodality correlation of features. The proposed model in this paper outperformed the comparison models and achieved statistically significant results. Specifically, 27 out of 50 stocks achieved higher classification accuracy than the comparative model. In addition, the in-depth analysis indicates that the early fusion strategy achieved better classification accuracy in 30 of 50 datasets than the late fusion strategy for stock price prediction.",
  "full_text": "Received 6 December 2022, accepted 21 January 2023, date of publication 30 January 2023, date of current version 2 February 2023.\nDigital Object Identifier 10.1 109/ACCESS.2023.3240422\nEffective Exploitation of Macroeconomic\nIndicators for Stock Direction Classification\nUsing the Multimodal Fusion Transformer\nTAE-WON LEE1, PAWEŁ TEISSEYRE2,3, AND JAESUNG LEE\n1,4\n1Department of Artificial Intelligence, Chung-Ang University, Seoul 06974, South Korea\n2Institute of Computer Science, Polish Academy of Sciences, 00-901 Warsaw, Poland\n3Faculty of Mathematics and Information Sciences, Warsaw University of Technology, 00-661 Warsaw, Poland\n4AI/ML Innovation Research Center, Chung-Ang University, Seoul 06974, South Korea\nCorresponding author: Jaesung Lee (curseor@cau.ac.kr)\nThis work was supported by Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the\nKorea government(MSIT) (2021-0-01341,Artificial Intelligence Graduate School Program(Chung-Ang University)).\nABSTRACT An enormous ripple effect can occur in financial data mining if it accurately predicts stock\nprices. However, predicting stock prices using only stock price data is difficult because of the random\nnature of stock price data. This paper attempts to fuse data to solve the stock price prediction problem.\nThe following data affecting the stock price are added to the proposed method as an additional modality:\nmacroeconomic indicators and the months and day of the week. The multimodal early fusion method is used,\nwhich learns the intermodality correlation of features. The proposed model in this paper outperformed the\ncomparison models and achieved statistically significant results. Specifically, 27 out of 50 stocks achieved\nhigher classification accuracy than the comparative model. In addition, the in-depth analysis indicates that\nthe early fusion strategy achieved better classification accuracy in 30 of 50 datasets than the late fusion\nstrategy for stock price prediction.\nINDEX TERMS Stock price prediction, multimodal learning, information fusion, macroeconomic data,\ntechnical indicator.\nI. INTRODUCTION\nAs the world economy expands, equity markets have grown,\nand the number of market participants has increased. Stock\nprice prediction has become one of the most popular subjects\nof financial data mining [1]. Although an accurate stock price\nprediction can help investors to make the right decision, it is\ndifficult to achieve because of randomness, non-linearity, and\nthe high noise level of the stock price data [2], [3]. Thus, using\nonly the stock price data may be unsuitable for stock price\nprediction because the stock market is sensitively affected\nby external factors, such as the world economy, domestic\npolitics, accidental events, and even by the months or day of\nthe week [4].\nResearchers use statistical and machine learning models to\nmodel the stock price. The autoregressive integrated moving\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Tallha Akram\n.\naverage (ARIMA) model, which combines the autoregressive\nmodel, moving average model, and differencing, is one of the\nmost representative statistical models to analyze time-series\ndata [5]. Traditional machine learning models, such as the\nsupport vector machine and hidden Markov model, have also\nbeen applied in this field [6], [7], [8]. Deep neural networks\n(DNNs) have recently demonstrated excellent prediction per-\nformance [9], [10] owing to their information fusion capabil-\nity that helps capture nonlinear relationships between various\nfinancial data sources [11].\nIn addition to the stock price data, another information\nsource, economic indicators, can represent economic situa-\ntions in the market [12]. Thus, by exploiting the economic\nindicators for predicting stock prices, an improvement in\naccuracy can be expected. In addition, because the stock price\ncan be correlated to the months and day of the week, the\naccuracy of the stock price prediction can be enhanced [4].\nIn addition, the internal structure of information fusion\nVOLUME 11, 2023 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 10275\nT.-W. Lee et al.: Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification\nshould be carefully designed to achieve the best prediction\npower [13].\nHowever, conventional studies suffer from performance\ndegradation because of the limited number of considered\ninformation sources and the intrinsically conducted structure\ndesign of the information fusion. The information fusion\nstrategy in DNNs can be roughly divided into two types\naccording to the location where fusion starts in the net-\nwork: early fusion, specializing in capturing the intermodal-\nity correlation, and late fusion, specializing in capturing\nthe intramodality correlation [14]. Because these two fusion\nstrategies have different strengths in information processing,\nit is still unclear which fusion strategy will lead to the best\nprediction power for stock price prediction. This paper pro-\nposes a novel multimodal fusion transformer for stock price\nprediction. Contributions from this study can be summarized\nas follows:\n• A novel multimodal early fusion transformer is proposed\nto achieve accurate stock price prediction. In the pro-\nposed network, the early fusion strategy is used to fuse\nthe information between each modality effectively.\n• Twenty-five information sources are considered in\nthis study from three domains: stock price, months\nand day of the week, and macroeconomic indicator\nmodalities.\n• An in-depth analysis is conducted regarding the fusion\nstrategy. The proposed method indicated that the early\nfusion strategy provides the best prediction perfor-\nmance. However, a group of stocks offers better predic-\ntion performance using the late fusion strategy.\nThe experimental results on 50 stock price datasets indi-\ncated that the proposed multimodal early fusion transformer\nsignificantly outperforms conventional methods.\nII. RELATED WORK\nIn the field of time-series prediction, the ARIMA model was\nfrequently employed for developing the model of power gen-\neration, traffic flow, and sensor data [15], [16], [17]. Another\nresearcher used the ARIMA model to predict financial time\nseries [5]. The statistical time-series model, like ARIMA,\nassumes that the data have linearity [18]. It is challenging\nto apply such assumptions throughout a financial time-series\ndata analysis because the data have traits of nonlinearity and\nrandomness [2], [3].\nDespite the excellent performance of a statistical stock\nprice prediction using, for example, the ARIMA model,\na series of attempts have been made to exploit machine learn-\ning models for stock price prediction. For instance, in [19],\nthe authors used support vector regression to predict stock\nminute prices using technical indicators. In addition to the\nsupport vector regression, the random forest was also used\nto build a stock price prediction model [8]. The continuous\nhidden Markov model, one of the most popular modeling\ntechniques for time-series data analysis, was used in [20].\nIn this work, the emission probabilities are modeled as Gaus-\nsian mixture models.\nThe DNNs can be effective alternatives to conventional\neconometric and statistical models with weaknesses in mod-\neling financial time-series data with nonlinear traits [21].\nFor example, a convolutional neural network (CNN) used\nfor image data analysis can be applied to stock price predic-\ntion [22]. In addition, long short-term memory (LSTM), bidi-\nrectional LSTM, and attention mechanisms model sequential\ndata, such as natural language and time-series data. In detail,\nthe bidirectional attention LSTM model for stock price pre-\ndiction was proposed in [23]. The model combined with\nthe CNN and LSTM is employed to extract the features of\nthe limit order book and stock price data. The CNN mod-\nule extracts the features in the limit order book, and the\nLSTM module extracts the time-series features in stock price\ndata [24].\nThe transformer model was devised to improve the atten-\ntion encoder-decoder LSTM model [25], whose variant is\nwidely used in the field of sequence modeling [26], [27].\nA stock price prediction model combined with the CNN\nand attention bidirectional LSTM was also considered [1].\nRecently, a transformer model for stock market index pre-\ndiction was suggested [28]. The attention mechanism in\nthe transformer can learn the correlation of many stocks\ndynamically with the market index and helps them predict\neach stock [29]. Some authors [30] insisted that conventional\nmachine learning algorithms ignore the stochastic property of\na stock that changes over time. Thus, they proposed adversar-\nial training to learn the stochastic property of the stock price\nusing the attention LSTM.\nRecent financial studies have combined various data with\nstock price data [13]. The information fusion can be enhanced\nby conducting parallel operations that contain inter/intra\ncrossovers and adaptive mutations in the genetic algorithm\n[31]. The proposed information fusion-based genetic algo-\nrithm approach can optimize the parameters of an extended\nshort-term memory stock price prediction model and selects\na set of features. Other authors [32] addressed the problem\nof technical analysis information fusion in improving stock\nmarket index-level prediction. Multiple predictive systems\nbased on various technical analysis metric categories have\nbeen devised. The system has multiple prediction models\nwith various technical analysis metric data categories. Each\nprediction model is based on an ensemble of neural networks\nusing particle swarm optimization. Other authors [33] pro-\nposed multimodal neural networks where the architecture\nlearns the cross-correlation of the United States and Korean\nstock prices.\nWith recent progress in natural language processing tech-\nniques, text data, such as news and Twitter data, were\nused for feeding the overall atmosphere of the market to\nthe prediction model that each stock data is unable to\ndeliver [34]. An event-driven approach was used with stock\nprice data [35]. The event-driven method was elaborated\nby extracting the stock-related event from the news titles.\nMoreover, the method enhancing the joint effects was also\ndevised by calculating the similarity of the two stocks using\n10276 VOLUME 11, 2023\nT.-W. Lee et al.: Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification\ntheir p-change values and Pearson correlation coefficient.\nHistorical stock quantitative data, social media data, and web\nnews data could be used by expressing the information as\na matrix and tensor for stock market prediction [36]. The\nstock quantitative feature matrix and stock correlation matrix\nwere created using the quantitative and social media data for\nthe stock. The stock movement tensor was built using events\nand sentiment extraction from news articles and social media.\nThe stock quantitative feature matrix and stock correlation\nmatrix were factorized, and the stock movement tensor was\ndecomposed for stock price prediction. The bag-of-words\nand named entity approach using a large corpus of freely\navailable financial reports were used to predict the volatil-\nity of the stock returns and stock market prediction using\nsupport vector regression [37], [38], [38]. However, these\napproaches suffer from several issues; the complex nature\nof natural language processing techniques, the subjectivity in\nthe news sentences or social media, and legal problems such\nas copyright issues. As a result, the empirical results cannot\nbe reproduced, making the application of those methods to\npractice extremely difficult. In this paper, we consider a\nsimpler alternative, the macroeconomic indicators, to feed the\ntendency of the overall market.\nIII. MATERIALS AND METHOD\nA. MOTIVATION\nFirst, we discuss the data we used in this study. The macroeco-\nnomic indicator is a representative factor affecting the stock\nmarket [40]. Some fundamental macroeconomic indicators,\nsuch as the exchange rate, interest rate, industrial production,\nand inflation, have associations with the stock price [39].\nIn addition to the macroeconomic indicators, the effect of\nthe months and day of the week can also be considered to\nobtain information affecting the stock market [4]. However,\nstock prices may only partially reflect the macroeconomic\nindicator information and the effects of the months and day of\nthe week. Therefore, the model must have information about\nthe macroeconomic indicators and the months and day of the\nweek to reflect this information instantly. Thus, data fusion\ncan be a valid method for accurate stock price prediction\nbecause the stock markets are affected by many factors [41]\nand randomness [2].\nMultimodal neural networks that fuses various information\nsources internally can be considered to solve the randomness\nproblem in data. The early fusion method extracts the inter-\nmodality correlation more efficiently than the intramodality\ncorrelation [33]. In this paper, the model that learns the corre-\nlation between significant data affecting the stock price well\nis designed to solve randomness problems in the stock price\ndata. The transformer encoder is advantageous for extracting\ninformation from sequential data [25]. The query, key, and\nvalue have the same value in the transformer encoder. The\nscaled dot-product self-attention in the transformer encoder\nlearns the correlation between the query, key, and value. The\nmultimodal early fusion transformer method is used in this\nFIGURE 1. Overview of the proposed method comprising feature\nconcatenation, a transformer encoder, and a classification layer.\npaper to employ the characteristics of the transformer encoder\nthat learn the correlations between model input features.\nIn this study, the problem of the stock direction classifica-\ntion is considered that predicts whether stock prices rise or\nfall in the future because it guides investors to buy a stock\nbefore the price rises or sell it before its value declines [42],\n[43]. Specifically, the proposed method predicts the next\nday’s stock up and down direction using the previous ten\ndays of data as a binary classification task. Thus, the stock\ndirection classification in this study can be formulated as the\nbinary classification problem based on about two weeks of\nstock market history, where the performance can be evaluated\nusing a conventional accuracy metric. As a result, an early\nfusion neural network is designed with feature concatenation,\na transformer encoder, and a classifier layer. Fig. 1 presents\nthe overview of the proposed method.\nB. PROPOSED METHOD\nThe entire experiment was conducted by setting three modal-\nities: stock price modality, months and day-of-the-week\nmodality, and macroeconomic indicator modality. Table 1\nVOLUME 11, 2023 10277\nT.-W. Lee et al.: Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification\nTABLE 1. Stock price modality.\nlists the details of the stock price modality. The KDD17\npublic dataset was used to add to the reliability of this exper-\niment [44]. The features of the KDD17 dataset are open,\nclose, high, low, volume, and adjusted close. Moreover, ten\nTABLE 2. Months and day of the week modality.\nTABLE 3. Macroeconomic indicator modality.\ntechnical indicators were added, and two additional features\nin the stock price modality were extracted through feature\nengineering to extract significant features in stock price\ndata [45]. Table 2 details the months and day-of-the-week\nmodality. In this modality, the months and day-of-the-week\nfeatures were extracted using one-hot encoding because the\nmonth is a categorical variable with 12 classes, and the day\nof the week is also a categorical variable with seven classes.\nThe extracted one-hot encoding vector can be expressed as\n[0, 1, · · ·, 0]. Last, in the macroeconomic indicator modality\ndescribed in Table 3, six features were selected: NASDAQ\n100; the US 2-, 10-, and 30-year bond yields; the US Dol-\nlar Index; and the WTI oil price. Only the close column\nin macroeconomic indicators was used in the data, even if\nthe macroeconomic indicators had several columns, such as\nopen, high, low, close, and volume. Before conducting the\ntraining and testing processes, the min-max normalization\nwas applied to each ten-day sequence because financial data\nvary the scale over a long period.\nFig. 2 depicts the detailed structure of the former half of\nthe proposed method, including the feature concatenation and\nmultihead attention model. Each modality was concatenated\nby a feature dimension to fuse data using the early fusion\nmethod. We let F1, F2 and F3 be the feature sizes of the\nstock price modality, the months and day-of-the-week modal-\nity, and the macroeconomic indicator modality, respectively.\nThen, x1 ∈ Rl×F1 , x2 ∈ Rl×F2 , and x3 ∈ Rl×F3 are the stock\nprice modality, months and day-of-the-week modality, and\nmacroeconomic indicator modality, where l is the sequence\n10278 VOLUME 11, 2023\nT.-W. Lee et al.: Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification\nFIGURE 2. Process of feature concatenation and multihead attention in the proposed method.\nlength, respectively. These multiple information sources can\nbe concatenated alongside the feature dimension to create an\ninput modality matrix M ∈ Rl×(F1+F2+F3), represented as\nfollows:\nM = [x1; x2; x3]. (1)\nIn this paper, the months and day-of-the-week modality\nis represented using a one-hot encoding scheme, resulting\nin twelve months features and five day-of-the-week features.\nThus, F1, F2, and F3 were set to 17, 17, and 6, respectively\nbecause the numbers of features in each modality were 17,\n17, and 6. The day that affects the next day’s stock price\nprediction can be different. The positional encoding module\nwas used to let the model know the position information\nof the data. The sine and cosine functions express different\nfrequencies [25]. In addition, pos denotes the position, and i\nrepresents the dimension. Further, dmodel denotes the feature\ndimension of the modality data concatenated along with the\nfeature dimension, and M concatenates three modalities that\nare added based on the positional encoding:\nPE(pos,2i) = sin(pos/100002i/dmodel ) (2)\nand\nPE(pos,2i+1) = cos(pos/100002i/dmodel ) (3)\nScaled dot-product attention comprises the query, key of\ndimension dk , and value of dimension dv, its dot-product [46].\nThe query, key, and value were calculated by multiplying\neach other’s linear layer of dimension dv by the output of the\npositional encoding. Then, the query and key were multiplied\nusing the dot-product operation. After the dot-product, the\nmultiplied output of the dot-product was divided by √\ndk and\nmultiplied by the value. Scaled dot-product self-attention rep-\nresents the data parts and their relevance to each other. Fig. 3\nFIGURE 3. Scaled dot-product attention.\nillustrates the overview of the scaled dot-product attention,\nrepresented as\nAttention(Q; K; V ) = softmax(QKT\n√dk\n)V . (4)\nUsing only a single attention mechanism can be challeng-\ning to learn various features in three modalities. Multihead\nattention can jointly address different representation sub-\nspaces that express a variety of features in data. It expresses\nthe diverse subspace representation in the modality. We let\nHeadi = Attention(QW q\ni ; KW k\ni ; VW v\ni ) be the ith head of the\nmultihead attention and W q\ni ∈ Rdmodel ×dk , W k\ni ∈ Rdmodel ×dk ,\nand W v\ni ∈ Rdmodel ×dk comprise the linear layer. We let W 0 ∈\nRdmodel ×dk be a weighted matrix multiplied after all heads are\nVOLUME 11, 2023 10279\nT.-W. Lee et al.: Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification\nFIGURE 4. Process of the point-wise feedforward network and classifier in the proposed method.\nFIGURE 5. Blocked time-series cross-validation.\nconcatenated. In addition, h = 8 was the number of heads,\nand dmodel was set todk = dmodel /h = 40. Then the multihead\nin the proposed architecture can be defined as\nMultiHead(Q; K; V ) = [Head1; · · · ;Headh]W 0. (5)\nNext, after the input data were passed through the feature\nconcatenation and multihead attention, feature compression\nfeedforward networks extract the information between fea-\ntures extracted using multihead attention. Fig. 4 depicts the\nlatter half of the proposed method. The point-wise feedfor-\nward networks have a rectified linear unit (ReLU) activation\nfunction that extracts nonlinear features. In addition, W1 and\nb1 and W2 and b2 are the weight and bias, respectively,\nin point-wise feedforward networks. Each point-wise feed-\nforward network was applied to each position separately and\nidentically to the output of the multihead attention:\nFFN(x) = max(0; xW1 + b1)W2 + b2. (6)\nAfter the feature compression feedforward networks, the\nfeature dimension is 1. In addition, time-sequence compres-\nsion feedforward networks extract the information through\nthe time-sequence dimension. We let x be the output of\nthe point-wise feedforward networks. Moreover, Wf ∈ Rdk\nand bf ∈ Rdk are the weight and bias values, respectively,\nof the feature-compressed feedforward networks. Further,\nWs ∈ Rl and bs ∈ R1 are the weight and bias of the\nsequence-compressed feedforward networks:\nFFNf (x) = max(0; xWf + bf ) (7)\nand\nFFNs(x) = max(0; xWs + bs). (8)\nThe output of the sequence-compressed feedforward net-\nworks enters the sigmoid function. The sigmoid function is\nthe nonlinear function that makes the input value range [0, 1].\n10280 VOLUME 11, 2023\nT.-W. Lee et al.: Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification\nTABLE 4. Comparison of the classification accuracy (%) between the proposed method and comparison models.\nThe output value of the sigmoid function was used for the\ninput of the binary cross-entropy loss with the target value.\nThus, trainable parameters were updated based on the binary\ncross-entropy loss.\nIV. EXPERIMENTAL RESULTS\nA. EXPERIMENTAL SETTINGS\nThe KDD17 datasets [44] and macroeconomic indica-\ntors were used for stock direction classification. The\nVOLUME 11, 2023 10281\nT.-W. Lee et al.: Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification\nTABLE 5. Summary of the abbreviated sector names.\nTABLE 6. Summary of the friedman statisticFF (k = 4, N = 50) and critical\nvalue in terms of accuracy measure between the proposed method and\ncomparison models.\nFIGURE 6. Result of the Bonferroni-Dunn Test between the Proposed and\nComparison Models.\nmacroeconomic indicators were collected on Investing.com.\nThe period of the historical price in KDD17 datasets and\nmacroeconomic indicators was 2,518 days from January 1,\n2007, to January 1, 2016. The KDD17 dataset has 50 stocks\nin US markets. This paper’s macroeconomic indicators\ninclude the NASDAQ 100; the US 2-, 10-, and 30-year bond\nyield; the US Dollar Index; and the WTI oil price.\nA blocked time-series cross-validation was used as a data\nsplit strategy to consider the trait of the time-series data [47].\nData leakage can occur if the random split strategy is used\nbecause the random split strategy in a time series can make\nthe model predict the next day by examining a future value.\nIn addition, a ten-fold split was used for the entire data length,\nsetting the training, validation, and testing data ratio to 8:1:1.\nFig. 5 presents the overview of the blocked time-series cross-\nvalidation.\nThe proposed model was compared to three comparison\nmodels via accuracy. The parameter was set for the three com-\nparison models to the value recommended by each research.\nA brief review of the three comparison models follows.\n• CNN-Attention Bi-LSTM [1]: The CNN-attention\nBi-LSTM model combines the CNN and attention\nBi-LSTM to predict stock price prediction. The CNN\nextracts the local perception and improves the efficiency\nof model training by reducing the number of parameters.\nThe attention Bi-LSTM learns the sequential features\nof the stock data. The authors used the stock dataset of\nShanghai Composite Index.\n• Adversarial LSTM [30]: The adversarial training\nmethod is a module that captures the stochastic property\nin stock data. The adversarial training method has been\nused for computer vision tasks at the data level. Still,\nthis paper concatenates feature-level perturbations dur-\ning training to express inherent stochastic properties in\nstock data to overcome the stochastic property in stock\nprice data for stock price prediction.\n• DTML [29]: The DTML model is combined with the\nattention LSTM and transformer model. The authors\nused the attention LSTM model to extract the sequential\nfeature in the stock data and concatenated the model\noutput. Furthermore, the transformer model is used to\nlearn the correlation between the multiple stocks in the\nconcatenated attention LSTM feature.\nIn this paper, the hyperparameters were set as follows. The\nbatch size was set to 32. The learning rate was set to 0.001.\nThe training progression used 100 epochs, and the model\nwith the lowest validation loss between epochs was used for\ntesting. The Adam optimizer was used for training [48]. The\nnumber of transformer model layers was 1. The transformer\nmodel dimensions were 320, and the number of transformer\nheads was set to eight. The loss function was set to binary\ncross-entropy loss, which is defined as follows:\nBCE(x) = −1\nn\nn∑\ni=1\nyilog(h(xi)) + (1 − yi)log(1 − h(xi)) (9)\nwhere n, yi, and h(xi) are the number of data, 0/1 binary target\nvalue for the prediction of the proposed model, and the final\noutput of the model through the sigmoid function, respec-\ntively. In addition, Accuracy is employed as an evaluation\nmeasure:\nAccuracy(%) = TP + TN\nTP + TN + FP + FN × 100 (10)\nwhere TP, TN, FP, and FN refer to true positive, true negative,\nfalse positive, and false negative. For each dataset, ten accu-\nracy values can be obtained each representing the accuracy\nof the corresponding fold among ten splits. These values are\naveraged to represent the performance of the corresponding\nmethod. Based on the average accuracy of ten splits, the\nsuperiority among compared methods for each dataset can\nbe determined and represented as the rank value. Lastly, the\naverage rank can be obtained by averaging the rank value of\neach method over all the datasets.\nStatistical tests were performed to validate the superiority\nof the proposed method for stock direction classification. The\nFriedman test is a statistical test for multiple nonparamet-\nric comparisons of the methods with multiple datasets [49].\nGiven k methods and N datasets, rj\ni denotes the rank of the\njth method on the ith dataset (mean ranks are used in case\nof ties). The Friedman test compares the average ranks of\nthe methods, and Rj = 1\nN\n∑N\ni=1 rj\ni represents the average\n10282 VOLUME 11, 2023\nT.-W. Lee et al.: Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification\nTABLE 7. Comparison of the classification accuracy (%) between the proposed method and transformer model variants.\nrank on the jth method. The null-hypothesis states that all the\nmethods are equivalent and so their ranks Rj should be equal.\nFurthermore, the Friedman test statistic is\nFF = (N − 1)x2\nF\nN(k − 1) − x2\nF\n(11)\nwhere\nx2\nF = 12N\nk(k + 1)\n\n\nk∑\nj=1\nR2\nj − k(k + 1)2\n4\n\n. (12)\nUnder the null hypothesis, the statistic FF is distributed\naccording to the F-distribution with k-1 and (k − 1)(N − 1)\nVOLUME 11, 2023 10283\nT.-W. Lee et al.: Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification\nTABLE 8. Summary of the Friedman statisticFF (k = 4, N = 50) and\nCritical Value in terms of Accuracy measure between the proposed\nmethod and variants of the transformer model.\nFIGURE 7. Result of the Bonferroni-Dunn Test between the Proposed\nmethod and Variants.\ndegrees of freedom [50]. The null hypothesis of the multiple\ncomparisons is rejected when the FF statistic is larger than\nthe critical value under significance level α, or equivalently\nthe corresponding p-value is smaller than α. In this case,\nthe post-hoc test can proceed to make pairwise comparisons\nbetween the methods. The Bonferroni-Dunn test was selected\nas a post-hoc test because it is usually recommended after\nrejecting the Friedman test’s null hypothesis [52 ]. The per-\nformance of the two methods is significantly different if the\ncorresponding average ranks differ by at least the critical\ndifference (CD):\nCD = qα/(k−1)\n√\nk(k + 1)\n12N , (13)\nwhere qα/(k−1) is the upper α/(k − 1)-th percentile point\nof the studentized range distribution with (K , ∞) degrees of\nfreedom [51].\nB. COMPARISON RESULTS\nTable 4 reveals the experimental results for the entire dataset\nin terms of accuracy. The table consists of the ticker, sector,\nand experimental results for the proposed and three compar-\nison models. The ticker represents the name of a specific\nstock. The sector of the stock is a unit consisting of similar\nindustries. The experimental results are expressed as the aver-\nage accuracy and its standard deviation. Table 5 presents the\nabbreviation of each sector.\nThe proposed method, 27 out of 50 stocks, had the best\naccuracy compared to the comparison models. With the\nproposed method, the stock that yielded the best perfor-\nmance was Verizon Communications (VZ), and the differ-\nence in accuracy was 8.85%p compared to the comparison\nmodel, which can be regarded as a significant difference\nin the stock direction classification. The Friedman test with\na 5% significance level was used to verify whether dif-\nferences exist between groups. As shown in Table 6, the\nFriedman test statistic was 24.084, and the p-value was\n2.3981e-05. There were statistically significant differences\nbetween groups under a significance level of 0.05.\nAs a result, the Bonferroni-Dunn test was applied with\na 5% significance level to verify which groups differ. The\nTABLE 9. Comparison of the classification accuracy between the early\nfusion method (proposed) and late fusion method.\nCD value was 0.6181 under a significance level of 0.05 in\nthe Bonferroni-Dunn test. The differences in the average\nrank between the proposed and comparison models were\ngreater than the CD value. Fig. 6 presents the results of the\nBonferroni-Dunn test. In the figure, the three comparison\nmodels are farther to the left than the CD = 0.61812 com-\npared to the proposed model. The proposed method achieved\nthe best average rank and outperformed all comparison meth-\nods. The quantitative analysis confirmed that the proposed\nmethod has a numerical difference compared to the compar-\nison model. The statistical tests indicate that the proposed\nmodel had a statistically significant difference compared to\nthe competitive models.\n10284 VOLUME 11, 2023\nT.-W. Lee et al.: Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification\nFIGURE 8. Sectors in which the early fusion method performs better than\nthe late fusion method and the proportion of how well the sectors\nperform compared to the late fusion method.\nFIGURE 9. Sectors in which the late fusion method performs better than\nthe early fusion method and the proportion of how well the sectors\nperform compared to the early fusion method.\nFIGURE 10. Sectors in which early and late fusion methods perform\nrespectively better than each other, and the proportion of how well the\nsectors perform compared to each other.\nAdditional comparison experiments were conducted on\ntransformer variant models to determine whether the result\nof the proposed model is the effect of the transformer or\nmodality fusion. Table 7 presents the experimental results\nbetween the proposed and transformer variant models in\nterms of accuracy. We included DTML [29] in this exper-\niment again because it is based on the transformer archi-\ntecture. The proposed method gained the best average rank\nof 1.96 compared to the transformer variant models. The\nFriedman and Bonferroni-Dunn tests were performed with a\nsignificance level of 0.05 to determine whether a statistical\ndifference exists. Table 8 lists the results of the Friedman\ntest, and Fig. 7 displays the results of the Bonferroni-Dunn\ntest. The Friedman test statistic was 18.595, and the p-value\nwas 0.00033. There were statistically significant differences\nbetween the proposed model and comparison models. The\nCD value was 0.6181 with a significance level of 0.05 in\nthe Bonferroni-Dunn test. When comparing the difference in\naverage rank between the proposed and comparison models,\namong the comparison models, the mean rank difference\nbetween the proposed model and the informer model was\nsmaller than that of the CD. The statistical tests found that\nFIGURE 11. Attention map for the early fusion method: (1) stock price\nmodality, (2) months and day-of-the-week modality, and\n(3) macroeconomic indicator modality.\nthe proposed model had a statistically significant difference\nfrom the comparison models except for the informer model.\nC. IN-DEPTH ANALYSIS\nIn this study, we devised a multimodal transformer based on\nearly fusion strategy. To verify the effectiveness of our choice,\nthe early and late fusion models were compared in terms\nof accuracy to demonstrate the superiority of early fusion\nstrategy compared to the late fusion model. Table 9 shows the\ncomparison results in terms of accuracy. The proposed early\nfusion model achieved better classification accuracy in 30 out\nof 50 stocks compared to the late fusion model. Although the\nearly fusion method achieved the best performance in 3 out\nof 6 stocks in the financial sector, it acquired the best perfor-\nmance in 6 out of 8 stocks compared to the late fusion method\nin the energy sector in classification accuracy. Fig. 8 presents\nthe sectors where early fusion methods perform better than\nlate fusion methods, the proportion of the number of stocks,\nand how well the stocks in each sector perform.\nFig. 9 lists the sectors where late fusion methods perform\nbetter than early fusion methods, the proportion of the number\nof stocks, and how well the stocks in each sector perform.\nFig. 10 displays the overall results of the sectors in which\nearly and late fusion methods respectively perform better than\neach other, the proportion of the number of stocks, and how\nwell the stocks in each sector perform comparatively. The\nearly fusion method achieved higher classification accuracy\nthan late fusion in five sectors: materials, communication ser-\nvices, energy, information technology, and cyclical consumer\nsectors. The late fusion method achieved higher classification\naccuracy than the early fusion method in three sectors: utility,\nconsumer defensive, and healthcare. The sectors with the\nsame ratio of stocks with high classification accuracy in early\nand late fusion were the industrial and financial sectors.\nThe attention map was also analyzed for scaled dot-product\nattention at the inference level. The corporation for the atten-\ntion map in Figs. 11 and 12 is Apple Inc., which achieved high\nclassification accuracy compared to the comparison models.\nVOLUME 11, 2023 10285\nT.-W. Lee et al.: Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification\nFIGURE 12. Attention map for the late fusion method: (1) stock price\nmodality, (2) months and day-of-the-week modality, and\n(3) macroeconomic indicator modality.\nIf the color in the attention map is white, the corresponding\nfeatures are highly correlated. If the color in the attention\nmap is black, the corresponding features are weakly corre-\nlated. Fig. 11 depicts the attention map for early fusion, and\nFig. 12 depicts the attention map for late fusion. Part ‘‘a’’ in\nFig. 11 represents that the 11 features in stock price modality\nare highly correlated with the months and day-of-the-week\nmodality and the macroeconomic indicator modality. The\nattention map for early fusion indicates that each modality\n(1), (2), and (3) is correlated because the value of each section\nin the attention map is highly activated. Accordingly, in the\nearly fusion method, each modality learns by referring to the\nother. However, in late fusion, the attention map is highly\nactivated apart from each modality. The features in the late\nfusion method are separated and passed through the scaled\ndot-product attention. Consequently, the early fusion method\nlearns the intermodality correlation better than the late fusion\nmethod because all the modalities are processed through\nthe scaled dot-product attention together, which learns the\nrelationship between data in the early fusion method.\nV. CONCLUSION\nThe task of stock price prediction can be challenging if\nthe algorithm depends only on the stock data because the\nstock price can be affected by external factors, such as the\nworld economy and policy. In this study, in addition to the\nstock data, two modalities such as macroeconomic indicators\nand month-and-day-of-the-week provide a global view of\nthe stock market and seasonal/weekly information, respec-\ntively. A multimodal fusion architecture was considered when\ndesigning the proposed method, which learns the intermodal-\nity correlation for features.\nThe proposed model in this paper outperformed the com-\nparison models and displayed a statistically significant dif-\nference. The test results confirmed that the proposed model\nexhibited a statistically significant difference compared to the\ncomparison models. An in-depth analysis of the comparison\nresults was also performed between early and late fusion\nmethods. The analysis indicates that the early fusion method\nachieved high classification accuracy in 30 of 50 datasets.\nOur analysis showed that each strategy demonstrates different\nstrengths for given sectors.\nPotential directions of future work include additional data\nexploratory research in financial data mining. Moreover, the\ndata fusion methodology considering the traits between var-\nious data types is also crucial in multimodal stock direction\nclassification.\nREFERENCES\n[1] W. Lu, J. Li, J. Wang, and L. Qin, ‘‘A CNN-BiLSTM-AM method for stock\nprice prediction,’’ Neural Comput. Appl., vol. 33, no. 10, pp. 4741–4753,\nMay 2021.\n[2] P. H. Cootner, ‘‘Stock prices: Random vs. systematic changes,’’ Ind. Man-\nage. Rev., vol. 3, no. 2, p. 24, 1962.\n[3] S.-W. Chen, ‘‘Non-stationarity and non-linearity in stock prices: Evidence\nfrom the OECD countries,’’ Econ. Bull., vol. 3, no. 11, pp. 1–11, 2008.\n[4] R. J. Rogalski, ‘‘New findings regarding day-of-the-week returns over\ntrading and non-trading periods: A note,’’ J. Finance, vol. 39, no. 5,\npp. 1603–1614, Dec. 1984.\n[5] A. A. Ariyo, A. O. Adewumi, and C. K. Ayo, ‘‘Stock price prediction\nusing the ARIMA model,’’ in Proc. UKSim-AMSS 16th Int. Conf. Comput.\nModeling Simulation, Mar. 2014, pp. 106–112.\n[6] K. J. Kim, ‘‘Financial time series forecasting using support vector\nmachines,’’Neurocomputing, vol. 55, nos. 1–2, pp. 307–319, Sep. 2003.\n[7] M. R. Hassan and B. Nath, ‘‘Stock market forecasting using hidden Markov\nmodel: A new approach,’’ in Proc. 5th Int. Conf. Intell. Syst. Design Appl.\n(ISDA), Sep. 2005, pp. 192–196.\n[8] L. Khaidem, S. Saha, and S. R. Dey, ‘‘Predicting the direction of stock\nmarket prices using random forest,’’ 2016, arXiv:1605.00003.\n[9] F. Agostinelli, M. Hoffman, P. Sadowski, and P. Baldi, ‘‘Learning activa-\ntion functions to improve deep neural networks,’’ 2014, arXiv:1412.6830.\n[10] Z. Hu, Y . Zhao, and M. Khushi, ‘‘A survey of forex and stock price\nprediction using deep learning,’’ Appl. Syst. Innov., vol. 4, no. 1, p. 9,\nFeb. 2021.\n[11] J. Gao, P. Li, Z. Chen, and J. Zhang, ‘‘A survey on deep learning for\nmultimodal data fusion,’’ Neural Comput., vol. 32, no. 5, pp. 829–864,\nMay 2020.\n[12] A. Kyereboah-Coleman and K. F. Agyire-Tettey, ‘‘Impact of macroeco-\nnomic indicators on stock market performance: The case of the Ghana\nstock exchange,’’ J. Risk Finance, vol. 9, no. 4, pp. 365–378, Aug. 2008.\n[13] A. Thakkar and K. Chaudhari, ‘‘Fusion in stock market prediction: A\ndecade survey on the necessity, recent developments, and potential future\ndirections,’’Inf. Fusion, vol. 65, pp. 95–107, Jan. 2021.\n[14] X. Wei, T. Zhang, Y . Li, Y . Zhang, and F. Wu, ‘‘Multi-modality cross atten-\ntion network for image and sentence matching,’’ in Proc. IEEE/CVF Conf.\nComput. Vis. Pattern Recognit. (CVPR), Jun. 2020, pp. 10941–10950.\n[15] P. Chen, T. Pedersen, B. Bak-Jensen, and Z. Chen, ‘‘ARIMA-based time\nseries model of stochastic wind power generation,’’ IEEE Trans. Power\nSyst., vol. 25, no. 2, pp. 667–676, May 2010.\n[16] M. Van Der V oort, M. Dougherty, and S. Watson, ‘‘Combining Kohonen\nmaps with ARIMA time series models to forecast traffic flow,’’ Transp.\nRes. C, Emerg. Technol., vol. 4, no. 5, pp. 307–318, 1996.\n[17] P. Han, P. X. Wang, S. Y . Zhang, and D. H. Zhu, ‘‘Drought forecasting\nbased on the remote sensing data using ARIMA models,’’ Math. Comput.\nModel., vol. 51, nos. 11–12, pp. 1398–1403, 2010.\n[18] B. K. Nelson, ‘‘Time series analysis using autoregressive integrated mov-\ning average (ARIMA) models,’’ Academic Emergency Med., vol. 5, no. 7,\npp. 739–744, Jul. 1998.\n[19] B. M. Henrique, V . A. Sobreiro, and H. Kimura, ‘‘Stock price prediction\nusing support vector regression on daily and up to the minute prices,’’\nJ. Finance Data Sci., vol. 4, no. 3, pp. 183–201, 2018.\n[20] P. Somani, S. Talele, and S. Sawant, ‘‘Stock market prediction using hidden\nMarkov model,’’ in Proc. IEEE 7th Joint Int. Inf. Technol. Artif. Intell.\nConf., Dec. 2014, pp. 89–92.\n10286 VOLUME 11, 2023\nT.-W. Lee et al.: Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification\n[21] P. Yu and X. Yan, ‘‘Stock price prediction based on deep neural networks,’’\nNeural Comput. Appl., vol. 32, no. 6, pp. 1609–1628, Mar. 2020.\n[22] S. Mehtab and J. Sen, ‘‘Stock price prediction using convolutional neural\nnetworks on a multivariate timeseries,’’ 2020, arXiv:2001.09769.\n[23] M. A. I. Sunny, M. M. S. Maswood, and A. G. Alharbi, ‘‘Deep learning-\nbased stock price prediction using LSTM and bi-directional LSTM\nmodel,’’ in Proc. 2nd Novel Intell. Lead. Emerg. Sci. Conf. (NILES),\nOct. 2020, pp. 87–92.\n[24] A. Tsantekidis, N. Passalis, A. Tefas, J. Kanniainen, M. Gabbouj, and\nA. Iosifidis, ‘‘Using deep learning for price prediction by exploiting sta-\ntionary limit order book features,’’ Appl. Soft Comput., vol. 93, Aug. 2020,\nArt. no. 106401.\n[25] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL. Kaiser, and I. Polosukhin, ‘‘Attention is all you need,’’ in Proc. Adv.\nNeural Inf. Process. Syst., vol. 30, 2017, pp. 1–11.\n[26] K. S. Kalyan, A. Rajasekharan, and S. Sangeetha, ‘‘AMMUS : A survey\nof transformer-based pretrained models in natural language processing,’’\n2021, arXiv:2108.05542.\n[27] F. Dama and C. Sinoquet, ‘‘Time series analysis and modeling to forecast:\nA survey,’’ 2021, arXiv:2104.00164.\n[28] C. Wang, Y . Chen, S. Zhang, and Q. Zhang, ‘‘Stock market index prediction\nusing deep transformer model,’’ Expert Syst. Appl., vol. 208, Dec. 2022,\nArt. no. 118128.\n[29] J. Yoo, Y . Soun, Y .-C. Park, and U. Kang, ‘‘Accurate multivariate stock\nmovement prediction via data-axis transformer with multi-level contexts,’’\nin Proc. 27th ACM SIGKDD Conf. Knowl. Discovery Data Mining,\nAug. 2021, pp. 2037–2045.\n[30] F. Feng, H. Chen, X. He, J. Ding, M. Sun, and T.-S. Chua,\n‘‘Enhancing stock movement prediction with adversarial training,’’ 2018,\narXiv:1810.09936.\n[31] A. Thakkar and K. Chaudhari, ‘‘Information fusion-based genetic algo-\nrithm with long short-term memory for stock price and trend prediction,’’\nAppl. Soft Comput., vol. 128, Oct. 2022, Art. no. 109428.\n[32] S. Lahmiri, ‘‘A technical analysis information fusion approach for stock\nprice analysis and modeling,’’ Fluctuation Noise Lett., vol. 17, no. 1,\nMar. 2018, Art. no. 1850007.\n[33] S. I. Lee and S. J. Yoo, ‘‘Multimodal deep learning for finance: Integrating\nand forecasting international stock markets,’’ J. Supercomput., vol. 76,\nno. 10, pp. 8294–8312, Oct. 2020.\n[34] N. Jing, Z. Wu, and H. Wang, ‘‘A hybrid model integrating deep learning\nwith investor sentiment analysis for stock price prediction,’’ Expert Syst.\nAppl., vol. 178, Sep. 2021, Art. no. 115019.\n[35] X. Zhang, Y . Li, S. Wang, B. Fang, and P. S. Yu, ‘‘Enhancing stock\nmarket prediction with extended coupled hidden Markov model over\nmulti-sourced data,’’ Knowl. Inf. Syst., vol. 61, no. 2, pp. 1071–1090,\nNov. 2019.\n[36] X. Zhang, Y . Zhang, S. Wang, Y . Yao, B. Fang, and P. S. Yu, ‘‘Improving\nstock market prediction via heterogeneous information fusion,’’ Knowl.-\nBased Syst., vol. 143, pp. 236–247, Mar. 2018.\n[37] S. Kogan, D. Levin, B. R. Routledge, J. S. Sagi, and N. A. Smith, ‘‘Pre-\ndicting risk from financial reports with regression,’’ in Proc. Hum. Lang.\nTechnolog., Annu. Conf. North Amer. Chapter Assoc. Comput. Linguistics\n(NAACL), 2009, pp. 272–280.\n[38] R. P. Schumaker and H. Chen, ‘‘Textual analysis of stock market prediction\nusing breaking financial news: The AZFin text system,’’ ACM Trans. Inf.\nSyst., vol. 27, no. 2, pp. 1–19, 2009.\n[39] A. M. Adam and G. Tweneboah, ‘‘Macroeconomic factors and stock\nmarket movement: Evidence from Ghana,’’ Social Sci. Res. Netw.,\nvol. 2008, no. 1289842, pp. 1–26, 2008.\n[40] F. J. Cebrian and L. Negrut, ‘‘US stock market and macroeconomic fac-\ntors,’’J. Appl. Bus. Res., vol. 32, no. 1, pp. 325–340, 2016.\n[41] H. Gursida, ‘‘The influence of fundamental and macroeconomic analysis\non stock price,’’ Jurnal Terapan Manajemen dan Bisnis, vol. 3, no. 2,\npp. 222–234, 2017.\n[42] S. Ravikumar and P. Saraf, ‘‘Prediction of stock prices using machine\nlearning (regression, classification) algorithms,’’ in Proc. Int. Conf. Emerg.\nTechnol. (INCET), Jun. 2020, pp. 1–5.\n[43] T. T. Khuat and M. H. Le, ‘‘An application of artificial neural networks and\nfuzzy logic on the stock price prediction problem,’’ JOIV: Int. J. Informat.\nVisualizat., vol. 1, no. 2, pp. 40–49, 2017.\n[44] L. Zhang, C. Aggarwal, and G.-J. Qi, ‘‘Stock price prediction via discov-\nering multi-frequency trading patterns,’’ in Proc. 23rd ACM SIGKDD Int.\nConf. Knowl. Discovery Data Mining, Aug. 2017, pp. 2141–2149.\n[45] Y . Kara, M. A. Boyacioglu, and Ö. K. Baykan, ‘‘Predicting direction of\nstock price index movement using artificial neural networks and support\nvector machines: The sample of the Istanbul stock exchange,’’ Expert Syst.\nAppl., vol. 38, no. 5, pp. 5311–5319, May 2011.\n[46] Z. Niu, G. Zhong, and H. Yu, ‘‘A review on the attention mechanism of\ndeep learning,’’ Neurocomputing, vol. 452, pp. 48–62, Sep. 2021.\n[47] W. Bao, J. Yue, and Y . Rao, ‘‘A deep learning framework for financial time\nseries using stacked autoencoders and long-short term memory,’’ PLoS\nONE, vol. 12, no. 7, Jul. 2017, Art. no. e0180944.\n[48] D. P. Kingma and J. Ba, ‘‘Adam: A method for stochastic optimization,’’\n2014, arXiv:1412.6980.\n[49] J. Demšar, ‘‘Statistical comparisons of classifiers over multiple data sets,’’\nJ. Mach. Learn. Res., vol. 7, pp. 1–30, Dec. 2006.\n[50] R. L. Iman and J. M. Davenport, ‘‘Approximations of the critical region of\nthe Friedman statistic,’’ Commun. Statist.-Theory Methods, vol. 9, no. 6,\npp. 571–595, 1980.\n[51] P. B. Nemenyi, ‘‘Distribution-free multiple comparisons,’’ Ph.D. thesis,\nDept. Math., Princeton Univ., Princeton, NJ, USA, 1963.\n[52] B. Trawiński, M. Sme ¸tek, Z. Telec, and T. Lasota, ‘‘Nonparametric sta-\ntistical analysis for multiple comparison of machine learning regression\nalgorithms,’’Int. J. Appl. Math. Comput. Sci., vol. 22, no. 4, pp. 867–881,\nDec. 2012.\n[53] H. Zhou, S. Zhang, J. Peng, S. Zhang, J. Li, H. Xiong, and W. Zhang,\n‘‘Informer: Beyond efficient transformer for long sequence time-series\nforecasting,’’ in Proc. AAAI Conf. Artif. Intell., vol. 35, no. 12, 2021,\npp. 11106–11115.\n[54] J. Xu, ‘‘Autoformer: Decomposition transformers with auto-correlation\nfor long-term series forecasting,’’ in Proc. Adv. Neural Inf. Process. Syst.,\nvol. 34, 2021, pp. 22419–22430.\nTAE-WON LEEreceived the B.Sc. degree in statis-\ntics from Inje University, in 2021. He is currently\npursuing the M.Sc. degree with the Department\nof Artificial Intelligence, Chung-Ang University.\nHis research interest includes multimodal learning\nmethods for time series data.\nPAWEŁ TEISSEYRE received the Ph.D. degree\nfrom the Institute of Computer Science, Pol-\nish Academy of Sciences, in 2013. He works\nas an Assistant Professor with the Institute of\nComputer Science, Polish Academy of Sciences\nand on the Faculty of Mathematics and Informa-\ntion Sciences, Warsaw University of Technology.\nHis research interests include feature selection\nin high-dimensional supervised problems, multi-\nlabel classification, learning from partially labeled\ndata, and applications of machine learning methods in medicine and genetics.\nJAESUNG LEEreceived the B.S., M.S., and Ph.D.\ndegrees in computer science from Chung-Ang\nUniversity, Seoul, South Korea, in 2007, 2009, and\n2013, respectively. He also studies classification,\nfeature selection, especially multilabel learning\nwith information theory. He is currently the Head\nand an Associate Professor with the Department\nof Artificial Intelligence, Chung-Ang University,\nwhere he is the Chief of the AI/ML Innovation\nResearch Center. His research interests include\nmachine learning, multilabel learning, model selection, and neural architec-\nture search.\nVOLUME 11, 2023 10287",
  "topic": "Stock (firearms)",
  "concepts": [
    {
      "name": "Stock (firearms)",
      "score": 0.6566470861434937
    },
    {
      "name": "Econometrics",
      "score": 0.6099303960800171
    },
    {
      "name": "Computer science",
      "score": 0.5924646854400635
    },
    {
      "name": "Stock price",
      "score": 0.44663918018341064
    },
    {
      "name": "Sensor fusion",
      "score": 0.43273046612739563
    },
    {
      "name": "Fusion",
      "score": 0.4244413375854492
    },
    {
      "name": "Data modeling",
      "score": 0.4220172166824341
    },
    {
      "name": "Data mining",
      "score": 0.3958911597728729
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3820153772830963
    },
    {
      "name": "Economics",
      "score": 0.2510893940925598
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Mechanical engineering",
      "score": 0.0
    },
    {
      "name": "Database",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Linguistics",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Series (stratigraphy)",
      "score": 0.0
    },
    {
      "name": "Engineering",
      "score": 0.0
    }
  ]
}