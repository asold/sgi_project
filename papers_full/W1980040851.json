{
  "title": "Usability of a Patient Education and Motivation Tool Using Heuristic Evaluation",
  "url": "https://openalex.org/W1980040851",
  "year": 2009,
  "authors": [
    {
      "id": "https://openalex.org/A2338201200",
      "name": "Joshi Ashish",
      "affiliations": [
        "University of Maryland, Baltimore County"
      ]
    },
    {
      "id": "https://openalex.org/A4289623478",
      "name": "Arora, Mohit",
      "affiliations": [
        "University of Maryland, Baltimore County"
      ]
    },
    {
      "id": "https://openalex.org/A2356875927",
      "name": "Dai Li-wei",
      "affiliations": [
        "Xerox (United States)"
      ]
    },
    {
      "id": null,
      "name": "Price, Kathleen",
      "affiliations": [
        "University of Maryland, Baltimore County"
      ]
    },
    {
      "id": null,
      "name": "Vizer, Lisa",
      "affiliations": [
        "University of Maryland, Baltimore County"
      ]
    },
    {
      "id": null,
      "name": "Sears, Andrew",
      "affiliations": [
        "University of Maryland, Baltimore County"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2106902595",
    "https://openalex.org/W1803861166",
    "https://openalex.org/W122518437",
    "https://openalex.org/W2037579514",
    "https://openalex.org/W1550991777",
    "https://openalex.org/W2176594967",
    "https://openalex.org/W2160271672",
    "https://openalex.org/W2163058110",
    "https://openalex.org/W2123051583",
    "https://openalex.org/W1817544967",
    "https://openalex.org/W1589029596",
    "https://openalex.org/W2342091124",
    "https://openalex.org/W2109428365",
    "https://openalex.org/W2913758505",
    "https://openalex.org/W2158685692",
    "https://openalex.org/W1958462358",
    "https://openalex.org/W2995575468",
    "https://openalex.org/W4239720002"
  ],
  "abstract": "We describe the heuristic evaluation method employed to assess the usability of PEMT, a method which uncovers heuristic violations in the interface design in a quick and efficient manner. Bringing together usability experts and health professionals to evaluate a computer-mediated patient education program can help to identify problems in a timely manner. This makes this method particularly well suited to the iterative design process when developing other computer-mediated health education programs. Heuristic evaluations provided a means to assess the user interface of PEMT.",
  "full_text": "Tutorial\nUsability of a Patient Education and Motivation Tool Using\nHeuristic Evaluation\nAshish Joshi1, MD, MPH; Mohit Arora1, MS; Liwei Dai2, PhD; Kathleen Price1, MS, RN; Lisa Vizer1, MS; Andrew\nSears1, PhD\n1Department of Information Systems, University of Maryland, Baltimore County, Baltimore, MD, USA\n2Usability Engineering Group, Xerox Corporation, Baltimore, MD, USA\nCorresponding Author:\nAshish Joshi, MD, MPH\nDepartment of Information Systems\nUniversity of Maryland, Baltimore County\n1000 Hilltop Circle, ITE 437\nBaltimore, MD 21250\nUSA\nPhone: +1 410 455 8837\nFax: +1 410 455 1217\nEmail: asjoshi@umbc.edu\nAbstract\nBackground: Computer-mediated educational applications can provide a self-paced, interactive environment to deliver educational\ncontent to individuals about their health condition. These programs have been used to deliver health-related information about a\nvariety of topics, including breast cancer screening, asthma management, and injury prevention. We have designed the Patient\nEducation and Motivation Tool (PEMT), an interactive computer-based educational program based on behavioral, cognitive, and\nhumanistic learning theories. The tool is designed to educate users and has three key components: screening, learning, and\nevaluation.\nObjective: The objective of this tutorial is to illustrate a heuristic evaluation using a computer-based patient education program\n(PEMT) as a case study. The aims were to improve the usability of PEMT through heuristic evaluation of the interface; to report\nthe results of these usability evaluations; to make changes based on the findings of the usability experts; and to describe the\nbenefits and limitations of applying usability evaluations to PEMT.\nMethods: PEMT was evaluated by three usability experts using Nielsen’s usability heuristics while reviewing the interface to\nproduce a list of heuristic violations with severity ratings. The violations were sorted by heuristic and ordered from most to least\nsevere within each heuristic.\nResults: A total of 127 violations were identified with a median severity of 3 (range 0 to 4 with 0 = no problem to 4 = catastrophic\nproblem). Results showed 13 violations for visibility (median severity = 2), 38 violations for match between system and real\nworld (median severity = 2), 6 violations for user control and freedom (median severity = 3), 34 violations for consistency and\nstandards (median severity = 2), 11 violations for error severity (median severity = 3), 1 violation for recognition and control\n(median severity = 3), 7 violations for flexibility and efficiency (median severity = 2), 9 violations for aesthetic and minimalist\ndesign (median severity = 2), 4 violations for help users recognize, diagnose, and recover from errors (median severity = 3), and\n4 violations for help and documentation (median severity = 4).\nConclusion: We describe the heuristic evaluation method employed to assess the usability of PEMT, a method which uncovers\nheuristic violations in the interface design in a quick and efficient manner. Bringing together usability experts and health\nprofessionals to evaluate a computer-mediated patient education program can help to identify problems in a timely manner. This\nmakes this method particularly well suited to the iterative design process when developing other computer-mediated health\neducation programs. Heuristic evaluations provided a means to assess the user interface of PEMT.\n(J Med Internet Res 2009;11(4):e47) doi: 10.2196/jmir.1244\nKEYWORDS\nComputers; health; education; usability; heuristic\nJ Med Internet Res 2009 | vol. 11 | iss. 4 | e47 | p. 1http://www.jmir.org/2009/4/e47/\n(page number not for citation purposes)\nJoshi et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nIntroduction\nComputer technology has been widely used for education of\nboth patients and health care professionals. Patient receptivity\nto computerized education is reported to be high across diverse\nmedical settings and age groups. Computerized patient education\nhas also been shown to increase patient knowledge, but little is\nreported about the results of findings of usability assessments\nof computerized patient education programs.\nThe objective of this case study was to describe the usability of\nthe Patient Education and Motivation Tool (PEMT) through\nheuristic evaluation of the interface. We report the results of\nthe usability evaluation, make changes based on the findings\nof the usability experts, and describe the benefits and limitations\nof applying usability evaluations to PEMT. We used Nielson’s\n10 usability heuristics [6] to identify potential usability\nproblems, describe severity ratings for each heuristic violation,\nand use the results to improve the overall usability of PEMT.\nThis paper presents the results of the heuristic evaluation of\nPEMT, system changes performed based on the evaluation, and\nplanned future research.\nHuman-Computer Interaction Evaluation\nHuman factor or usability engineering is a discipline that\ninvestigates human/machine interface issues, using a wide array\nof methodologies [7]. These methodologies vary in terms of\nresearch design, complexity, cost, duration, and relevance to\noperational programs [7]. The two approaches for evaluating\nthe human-computer interaction (HCI) characteristics of a\nsystem include inspection methods or user evaluations [5,8].\nInspection methods are based on reviews of a system, often by\nexperts, which can be guided by usability heuristics, user tasks,\nor other information [5,8,9]. User evaluations measure user task\nperformance in a lab setting [5,8]. Using these methods in\nsystem development has been recognized as an important way\nto ensure the usability of the end product [5,8,9].\nNielson defines heuristic evaluation as a measurement that\nutilizes heuristics in order to find usability problems [4].\nNielson’s method uses a small set of principles, guidelines, or\nheuristics that are systematically assessed against a target system\nin order to identify problems and their severity, as well\nconsequences for the user [4,7]. Heuristic evaluation is an\neffective usability inspection method for discovering the most\nserious problems with a low investment of resources, while\nrepresenting a high cost-benefit ratio [10]. During the heuristic\nevaluation, a group of usability experts examine the user\ninterface design according to a set of usability guidelines [11].\nA list of heuristic violations found in the interface design and\nan assessment of the severity of these problems is generated\n[11]. The results can be utilized as suggestions for interface\nrefinements. This method requires less time and resources than\nmany other usability engineering methods. Nielsen identified\n10 usability heuristics as the basic characteristics of usable\ninterfaces [4]. Research in the past has shown that usability\ninspection through heuristic evaluation is an effective way to\nuncover user interface design problems in a broad range of\nclinical contexts [12]. In a previous study, heuristic evaluation\ncombined with small-scale expert assessment was examined in\nthe context of the design and development of a Web-based\ntelemedicine system [12]. The study found usage difficulties\nrelated to HCI problems primarily characterized by a mismatch\nof the designer model and the content expert model [12]. The\nheuristic/usage methodology provided an incremental benefit\nin a variety of design activities [12]. They examined a software\nuser interface with heuristic evaluation, software guidelines,\ncognitive walkthrough, and usability testing and found that\nheuristic evaluation by several user interface specialists yielded\nthe highest number of serious problems with the least amount\nof effort [12]. A single general usability expert familiar with\nthe kind of interface being evaluated can identify about 60% of\nthe problems [7,13]. This method was applied to support the\nclinical information system during a standard Call for Tender\nand was found to be an efficient and cost-effective approach to\nchoose an appropriate and useful clinical information system\n[14]. In another study, Zhang and colleagues applied this method\nto evaluate patient safety with regard to the use of medical\ndevices [15]. Heuristic evaluation through the identification of\nusability problems and their severities was found to be a useful,\nefficient, and low-cost method to evaluate patient safety features\nof medical devices [15].\nOverview of the Patient Education and Motivation\nTool (PEMT)\nPEMT is an interactive computer-based program that is being\ndesigned according to three sets of learning theories [16]:\nbehavioral, cognitive, and humanistic. Two key ideas of\nbehavioral theory are that learning is manifested by a change\nin behavior and that technology-based instructional materials\nshould be introduced in increments. Cognitive learning theory\nfocuses on providing structured education to individuals along\nwith reinforcement. Humanistic theory predominantly\nemphasizes the participants’willingness to learn and their ability\nto be evaluated. The outcome of learning depends upon how\nthe information is presented and how the learner processes that\ninformation.\nA computer-based educational program provides individuals\nwith a self-paced learning environment and presents educational\nmodules as a series of short messages. The information is\nprovided in various representations, including audio, images,\ntext, and animation with the resulting program being interactive.\nThe system accounts for a variety of literacy levels and learning\nstyles amongst users. Visual learners prefer seeing what they\nare learning, so pictures and images help them understand ideas\nand information better than text-based explanations [17].\nAuditory learners learn best by hearing things and remember\nverbal instructions well, preferring someone else read the\ndirections to them while they do the physical work or task [18].\nPEMT allows users to toggle the audio on or off based on their\npreferences. The tool provides users with the opportunity and\nflexibility to navigate modules relevant to their condition by\nallowing them to move forward and backward at their own pace.\nPEMT also provides users with access to extensive information\nand empowers patients to obtain pertinent information about\ntheir condition. We employed usability principles when\ndesigning the user interface [19].\nPEMT has three key components [20]:\nJ Med Internet Res 2009 | vol. 11 | iss. 4 | e47 | p. 2http://www.jmir.org/2009/4/e47/\n(page number not for citation purposes)\nJoshi et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\n1. Screening: PEMT allows users to enter information about\ntheir socio-demographics at their own pace, including age,\ngender, education, disease severity, and prior disease\nknowledge through a series of multiple-choice questions.\nNo feedback is given to the individuals during this\ncomponent.\n2. Learning: The learning material is broken down into a\nseries of educational messages with relevant audio, images,\nand animations as appropriate. Individuals can move\nforward and backward through the messages by clicking\nnext and back buttons. The information on each screen\nvaries in terms of the number of paragraphs, sentences,\nwords, bulleted items, highlights, and animations.\n3. Evaluation: The evaluation component is a post-learning\nquestionnaire similar to that used during the screening\ncomponent. Feedback is provided to the users based on\ntheir responses. Users giving correct responses receive\npositive prompts and encouragement while individuals\ngiving incorrect responses are given corrective feedback\nand reinforcement. The goal of the evaluation component\nis to track the progress of individual behavior, knowledge,\nand disease progression over a period of time.\nThese three key components of PEMT make it a multifaceted\ntool that can be utilized to screen individuals’ demographics,\nhealth literacy, prior knowledge, attitudes, behavior, and prior\nuse of technology. The tool has been successfully employed in\ndifferent clinical settings (including emergency departments\nand outpatient clinics), for different conditions, including asthma\n[20] and influenza [21], and across different populations\n(including children, parents, and caregivers). In our prior study,\nwe implemented PEMT on a touch-screen computer in a\npediatric emergency department (ED). Children with asthma\nand their parents used the asthma education program in the ED.\nThe results showed significant improvement in their knowledge\nand found PEMT to be highly acceptable [20]. In another study,\nwe implemented PEMT in an ED and in an inner city outpatient\npediatric ambulatory center (PAC) to assess and describe\nchanges in the knowledge, attitudes, and practice regarding the\ninfluenza vaccine in participants whose children were between\n6 months to 5 years of age [21]. The results of the study showed\nhigh acceptance of PEMT, and users found PEMT easy to use\nwith no difficulties in navigating from one screen to another\n[21]. Users could interact with the tool on a desktop, laptop, or\ntablet PC using a touch screen, keyboard, and/or mouse. The\nsystem is available as a local or Web-based application.\nPEMT Hardware and Software\nPEMT is implemented in an n-tier architecture, using Adobe\nFlash CS3 for the presentation layer, XML for content\nmanagement, Microsoft.Net Framework version 2.0 with Visual\nBasic.Net for program logic and data flow control, and Microsoft\nSQL Server 2005 for data storage. Educational content\nelements—including text, images, thumbnails, animations, and\naudio—and accessibility features—including textual descriptors\nand closed captions—are organized using multiple XML files.\nThe Adobe Flash layer is used to render educational content\nand user interface controls dynamically. User interactions with\nthe Adobe Flash layer—including responses to questions and\nnavigational interactions—are captured by the .Net layer and\nrecorded in a relational structure, linked with timestamps and\na unique session identifier in the MS SQL Server database. For\nheuristic evaluations, the software experts used the software on\ndesktop and laptop computers running Windows XP with a\nminimum configuration of a Pentium 4 processor and 512MB\nRAM.\nMethods\nHeuristic evaluation is better if several people conduct the\nevaluation independent of each other [6]. Jacob Nielsen's\nheuristics are probably the most used usability heuristics for\nuser interface design [6]. The evaluation is structured in terms\nof recognized usability principles.\nThe severity of a usability problem is a combination of three\nfactors:\n• The frequency with which the problem occurs: Is it\ncommon or rare?\n• The impact of the problem if it occurs: Will it be easy or\ndifficult for the users to overcome?\n• The persistence of the problem: Is it a one-time problem\nthat users can overcome once they know about it, or will\nusers repeatedly be bothered by the problem?\nThree usability experts (LD, KP, and LV) used Nielsen’s\nusability heuristics (Table 1) while reviewing the PEMT user\ninterface and generated a list of heuristic violations. One of the\nusability experts was a registered nurse with 15 years of clinical\nand HCI experience and had conducted numerous heuristic\nevaluation studies (KP). One of the other experts had 12 years\nof professional experience in usability design and heuristic\nevaluation (LV), and the third expert was a PhD student in HCI\nwith experience in doing heuristic evaluations for several studies\n(LD). During the evaluation, the usability experts first reviewed\nthe user interface of PEMT independently and generated a list\nof heuristic violations. The usability experts then independently\nrated the severity of each usability violation on the following\nscale [6]:\n0 - I don’t agree that this is a usability problem at all\n1 - Cosmetic problem only: need not be fixed unless extra time\nis available on the project\n2 - Minor usability problem: fixing this should be given low\npriority\n3 - Major usability problem: important to fix, so should be given\nhigh priority\n4 - Usability catastrophe: imperative to fix this before product\ncan be released\nIn rating the problems, persistent issues with major impact on\nmost users received the highest severity rating. The mean\nseverity for each violation was calculated from the individual\nratings. The three independent lists were combined together to\ngenerate a single list of heuristics violations, their severity\nratings, and suggestions for the correction of these violations.\nThe three usability experts (LD, KP, and LV) discussed their\nindividual lists together, and any disagreements in assigning\nthe severity ratings were resolved after mutual discussions. The\nJ Med Internet Res 2009 | vol. 11 | iss. 4 | e47 | p. 3http://www.jmir.org/2009/4/e47/\n(page number not for citation purposes)\nJoshi et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\ncombined list of heuristic violations was then reviewed and changes were made.\nTable 1. Nielsen’s usability heuristics\nDescriptionUsability Heuristic\nThe system should always keep users informed about what is going on, through appropriate feedback\nwithin reasonable time.\n1. Visibility of system status\nThe system should speak the users' language, with words, phrases, and concepts familiar to the user,\nrather than system-oriented terms. Follow real-world conventions, making information appear in a\nnatural and logical order.\n2. Match between system and real world\nUsers often choose system functions by mistake and will need a clearly marked \"emergency exit\"\nto leave the unwanted state without having to go through an extended dialogue. Support undo and\nredo.\n3. User control and freedom\nUsers should not have to wonder whether different words, situations, or actions mean the same\nthing. Follow platform conventions.\n4. Consistency and standards\nEven better than good error messages is a careful design which prevents a problem from occurring\nin the first place. Either eliminate error-prone conditions or check for them and present users with\na confirmation option before they commit to the action.\n5. Error prevention\nMinimize the user's memory load by making objects, actions, and options visible. The user should\nnot have to remember information from one part of the dialogue to another. Instructions for use of\nthe system should be visible or easily retrievable whenever appropriate.\n6. Recognition rather than recall\nAccelerators—unseen by the novice user—may often speed up the interaction for the expert user\nsuch that the system can cater to both inexperienced and experienced users. Allow users to tailor\nfrequent actions.\n7. Flexibility and efficiency of use\nDialogues should not contain information which is irrelevant or rarely needed. Every extra unit of\ninformation in a dialogue competes with the relevant units of information and diminishes their relative\nvisibility.\n8. Aesthetic and minimalist design\nExpress error messages in plain language (no codes), precisely indicate the problem, and construc-\ntively suggest a solution.\n9. Help users recognize, diagnose, and recover\nfrom errors\nEven though it is better if the system can be used without documentation, it may be necessary to\nprovide help and documentation. Any such information should be easy to search, be focused on the\nuser's task, list concrete steps to be carried out, and not be too large.\n10. Help and documentation\nResults\nThe result of the heuristic evaluation was a combined list of\nviolations with severity ratings. The violations were sorted by\nheuristic and ordered from most to least severe within each\nheuristic category. A total of 127 violations were identified with\na mean severity of 3 (range 0 - 4). The usability problems\npertaining to the system function were organized by individual\nscreens. An excerpt of the evaluation results for the user\ninterface prototype has been presented (Table 2). Sample\nheuristic violations included a “lack of feedback to the user if\nthey didn’t answer a question and tried to proceed to the next\nscreen”, and the “inability to exit or obtain help throughout the\nentire program”.\nThe results of the heuristic evaluation were given to the software\ndevelopment team so that the interface could be revised. The\ndomain expert and the software development team discussed\nthese changes and, based on the severity ratings, changes were\nprioritized and implemented (Figure 1, Figure 2, Figure 3). In\nFigure 1, if an option is not selected and the user clicks next to\ngo forward, no feedback is given to the user. No help is provided\nto assist users during their use of the program, and no exit button\nis available to leave the program at any time.\nIn Figure 2, feedback is provided if no option is selected, and\nthe user is able to exit anytime during the use of the program.\nTable 2. Sample heuristic evaluation results\nSeverity RatingProgram SectionProblem DescriptionHeuristic violated\n3Screening sectionIf you don't answer a question and then try to advance,\nthe system will not let you, but it gives you no feedback\non how to proceed.\nVisibility\n3Entire programNo Exit or Quit present.User control and freedom\n4Entire programNo Help present.Help and documentation\nJ Med Internet Res 2009 | vol. 11 | iss. 4 | e47 | p. 4http://www.jmir.org/2009/4/e47/\n(page number not for citation purposes)\nJoshi et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nFigure 1. PEMT Version before heuristic evaluation\nJ Med Internet Res 2009 | vol. 11 | iss. 4 | e47 | p. 5http://www.jmir.org/2009/4/e47/\n(page number not for citation purposes)\nJoshi et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nFigure 2. Revised PEMT version after changes were made based on heuristic evaluations\nJ Med Internet Res 2009 | vol. 11 | iss. 4 | e47 | p. 6http://www.jmir.org/2009/4/e47/\n(page number not for citation purposes)\nJoshi et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nFigure 3. Help section is provided during the use of the program in the modified version of PEMT\nTable 3 shows the average number of violations for visibility,\nthe match between system and real world, user control and\nfreedom, consistency and standards, error prevention,\nrecognition rather than recall, flexibility and efficiency, aesthetic\nand minimalist design, help users recognize, diagnose, and\nrecover from errors, and help and documentation. Results\nshowed that among the 10 usability heuristics, the match\nbetween system and real world (n = 38) and consistency and\nstandards (n = 34) were the two heuristics most frequently\nviolated. These two heuristics accounted for more than half\n(57%) of all the violations. Two examples of heuristic violations\nrelated to the match between system and real world included:\n1) lack of clarity in the presentation of the buttons and their\nfunctions and 2) a mismatch between the audio and written\ncontent. Consistency and standards heuristic violations included:\n1) differences in function performed by similar buttons,\nincluding the “next” button that was used to display additional\ncontent on the same screen instead of to advance screens and\n2) inconsistent typesizes and styles used on the same screen.\nWe found severity ratings predominantly higher for violations\nof the usability heuristics “Help users recognize, diagnose, and\nrecover from errors” (median rating = 3) and “Help and\ndocumentation” (median rating = 4) (Table 3).\nFor four heuristics, more than 50% of the violations were major\nviolations: “User control and freedom” (n = 4/6; 66.67%), “Error\nprevention” (n = 6/10; 54.54%), “Recognition rather than recall”\n(n = 1/1; 100%), and “Help users recognize, diagnose, and\nJ Med Internet Res 2009 | vol. 11 | iss. 4 | e47 | p. 7http://www.jmir.org/2009/4/e47/\n(page number not for citation purposes)\nJoshi et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nrecover from errors” (n = 4/4; 100%) (Table 3). The median\nseverity rating per usability heuristic has also been reported\n(Table 3). This information was used to evaluate the severity\nof the violations in each category of the usability heuristics and\nwas used as a medium to describe not only the average number\nof severe violations in each category but also to prioritize\nchanges that can be made to the violations.\nTable 3. Number of violations, average severity rating, and severity category per usability heuristic\nCatastrophicMajorMinorCosmeticMedian severity\nrating\nUsability heuristic\n672Visibility of system status (n = 13)\n617152Match between system and real world\n(n = 38)\n423User control and freedom (n = 6)\n62442Consistency and standards (n = 34)\n1643Error prevention\n(n = 11)\n13Recognition rather than recall (n = 1)\n342Flexibility and efficiency of use\n(n = 7)\n632Aesthetic and minimalist design\n(n = 9)\n43Help users recognize, diagnose, and\nrecover from errors\n(n = 4)\n314Help and documentation\n(n = 4)\nBased on the feedback from the heuristic evaluations, the user\ninterface of PEMT underwent considerable changes. The\nmajority of the changes that required urgent attention were fixed;\nhowever, certain changes were particular to the environment in\nwhich the system was to be used which, in this case, was an\nemergency department setting. The changes immediately made\nto the system included giving users feedback in the form of a\ntext message when they tried to navigate to the next screen\nwithout making a choice. Some of the changes that were\nrecommended by the usability experts were not completely\nadopted in the revised prototype due to specific user roles and\nthe study protocol. Designers and users are faced with different\nrequirements and tend to focus on different sets of issues. A\nprior study supports the view that it is not surprising to find\nexperts and end users faced with different requirements focusing\non different sets of issues [7]. Heuristic evaluation focuses on\nthe interface characteristics mediating between functionality\nand performance [7].\nDiscussion\nThis tutorial illustrates a heuristic evaluation using a\ncomputer-based patient education program (PEMT) as a case\nstudy. The motivation to conduct this heuristic evaluation was\nto uncover usability violations in the user interface prototypes\nof PEMT in an efficient yet effective manner. Our case study\nillustrates the relevance of the heuristic evaluation for\nidentifying usability problems with computer-based health\neducation programs. We evaluated acceptance of PEMT in the\nemergency department and the pediatric ambulatory clinic using\nan attitudinal survey. The results showed that 95% of the users\nfound the program easy to use, 91% found it easy to navigate\nthe program’s different screens, 94% found the text easy to read,\nand 93% liked the colors used on the screen [21]. Overall, the\nresults of this study suggested high acceptance of PEMT [21].\nOne major weakness in our assessment of heuristic evaluation\nas a method is that we have no baseline against which to\nmeasure our results. Earlier studies suggest that heuristic\nevaluations detect 40 - 60% of the usability problems an\nempirical user test would find, and also claim that the types of\nproblems found are roughly comparable [6].\nA substantial benefit of heuristic evaluation is that it represents\nsignificant savings in time over the duration of a complete\nempirical user test, both in terms of execution and generation\nof interface changes for implementation. It has been reported\nthat heuristic evaluations employing 3 - 5 evaluators can identify\n60 - 70% of the usability problems in an interface, including\nmany of the major problems, even though it requires less time\nthan other evaluation techniques [21]. The current case study\ndemonstrates the significance and relevance of human factors\nin designing computer-mediated health education programs,\nespecially with respect to improving the acceptance of these\nsystems.\nHeuristic evaluation is a usability inspection method and differs\nfrom empirical approaches that rely heavily on user performance\ndata, such as user testing. The study shows the practicality of\nheuristic evaluation. The results suggest that the application of\nJ Med Internet Res 2009 | vol. 11 | iss. 4 | e47 | p. 8http://www.jmir.org/2009/4/e47/\n(page number not for citation purposes)\nJoshi et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nhuman-computer interaction design principles to\ntechnology-based health education programs can be a quick,\nrelatively efficient way to gather feedback and guidance to\nimprove the interface of a system. The heuristic evaluation\nresults were also a guide during the iterative software\ndevelopment process. The results were presented to the\ndevelopment team, and the recommended changes were\nimplemented. The changes made to the interface were prioritized\nbased on the severity ratings, from catastrophic to cosmetic.\nThe immediate changes made to the program included adding\na help mechanism, providing feedback to the users based on\ntheir actions, and allowing users to exit the system. Therefore,\nthe sorted list of heuristic violations with severity ratings was\nvery helpful for prioritizing the revisions to PEMT. The\nrecommended changes were easily understood, not only by the\nsoftware development team, but also by domain experts, since\nthe rationale used to make changes to the system was well\njustified by the heuristics. The benefits of the recommended\nchanges became evident after the revised software demonstrated\nhigher ease of use and greater ease of navigation, while\nminimizing errors. Thus, providing software designers with\npractical feedback in a timely fashion represents a distinct\nadvantage that heuristic evaluation possesses which many other\nusability engineering methods do not.\nOver the long term, perhaps the most lasting result of the\nheuristic evaluation concerns more than the specific system\ntested, since heuristic evaluation also relates to internal\norganizational development. Heuristic evaluation was another\nstep in this educational process. The experimenters and\nevaluators learned to use the method and to incorporate the\nresults into subsequent development. A large number of usability\nproblems were identified with a reasonable expenditure of effort.\nTo ensure the success of education programs, information must\nbe delivered in a way that is accessible to and meaningful to\nusers.\nHowever, there are several limitations of using heuristic\nevaluation compared to other usability engineering methods.\nThis method relies heavily on the expertise of the usability\nprofessionals who conduct the evaluation [5]. These experts\nmay lack domain knowledge and could therefore overlook\ndomain-related usability problems [5]. One way to overcome\nthis obstacle is to employ evaluators, known as double experts,\nwho possess both usability and domain knowledge [5]. In our\ncase study, usability experts, designers, and domain experts\nworked together on the design and evaluation of the PEMT. It\nis highly important to have a combination of these experts while\nevaluating computer-mediated patient education programs in\nthe health care environment, or else there is a risk of producing\na mismatch between the system and the real world. Involving\nprofessionals with expertise in both computer-mediated\neducation and the health care environment allows for the\nadjustment of several variables while evaluating the system.\nThe PEMT user interface was more consistent with Nielsen’s\nusability heuristics after the expert-recommended changes were\ncompleted. In our study, we examined the value of heuristic\nevaluation for improving the usability of PEMT by uncovering\nheuristic violations in the interface design in a quick, efficient,\nand cost-effective manner. The ability to identify problems in\na timely manner makes this method particularly well suited to\nthe iterative design process. In addition, it is very important that\nthe focus is on users when evaluating the interface design\nbecause this can influence the problems identified by the\nusability experts, as well as how these problems are described\nand prioritized. The system should speak the user’s language,\nwith words, phrases, and concepts familiar to the user, rather\nthan system-oriented terms and information, and these words,\nphrases, and concepts should appear in a natural and logical\norder. The “match between system and real world” means that\nthe system should follow real-world conventions as closely as\npossible, in order to allow the user to understand how to operate\nthe program.\nWe are currently conducting multiple studies to evaluate the\nusability of PEMT by combining heuristic evaluation and user\ntesting for other patient education programs.\nConflicts of Interest\nNone declared.\nReferences\n1. Diefenbach MA, Butz BP. A multimedia interactive education system for prostate cancer patients: development and\npreliminary evaluation. J Med Internet Res 2004 Jan 21;6(1):e3 [FREE Full text] [Medline: 15111269] [doi:\n10.2196/jmir.6.1.e3]\n2. Hofstetter FT. Multimedia Literacy with Student CD-ROM. 3rd edition. New York, NY: Irwin/McGraw-Hill; 2000.\n3. O'Grady LA. Consumer e-health education in HIV/AIDS: a pilot study of a web-based video workshop. BMC Med Inform\nDecis Mak 2006;6(1):10 [FREE Full text] [Medline: 16504148] [doi: 10.1186/1472-6947-6-10]\n4. Nielson J. Usability Engineering. San Diego, CA: Academic Press; 1993.\n5. Tang Z, Johnson TR, Tindall RD, Zhang J. Applying heuristic evaluation to improve the usability of a telemedicine system.\nTelemed J E Health 2006 Feb;12(1):24-34. [Medline: 16478410] [doi: 10.1089/tmj.2006.12.24]\n6. Nielsen J. Heuristic evaluation. In: Nielsen J, Mack RL, editors. Usability Inspection Methods. New York, NY: John Wiley\n& Sons; 1994.\n7. Lathan CE, Sebrechts MM, Newman DJ, Doarn CR. Heuristic evaluation of a web-based interface for internet telemedicine.\nTelemed J 1999;5(2):177-185. [Medline: 10908430] [doi: 10.1089/107830299312140]\n8. Kushniruk AW, Patel VL. Cognitive and usability engineering methods for the evaluation of clinical information systems.\nJ Biomed Inform 2004 Feb;37(1):56-76. [Medline: 15016386] [doi: 10.1016/j.jbi.2004.01.003]\nJ Med Internet Res 2009 | vol. 11 | iss. 4 | e47 | p. 9http://www.jmir.org/2009/4/e47/\n(page number not for citation purposes)\nJoshi et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\n9. Jeffries R, Miller JR, Wharton C, Uyeda KM. User interface evaluation in the real world: a comparison of four techniques.\nIn: Robertson S, Oslon GM, Oslon JS, editors. Human Factors in Computing Systems CHI’91 Conference Proceedings.\nNew York, NY: ADM Press; 1991.\n10. Nielson J. Guerilla HCI: using discount usability engineering to penetrate intimidation barrier. In: Bias RG, Mayhew DJ,\neditors. Cost-Justifying Usability. San Diego, CA: Academic Press; 1994.\n11. Jaspers MWM. A comparison of usability methods for testing interactive health technologies: methodological aspects and\nempirical evidence. Int J Med Inform 2009 May;78(5):340-353. [Medline: 19046928] [doi: 10.1016/j.ijmedinf.2008.10.002]\n12. Tang Z, Johnson TR, Tindall RD, Zhang J. Applying heuristic evaluation to improve the usability of a telemedicine system.\nTelemed J E Health 2006 Feb;12(1):24-34. [Medline: 16478410] [doi: 10.1089/tmj.2006.12.24]\n13. Nielson J. Usability evaluation and inspection methods. In: Ashlund S, Mullet K, Henderson A, Hollnagel E, White T,\neditors. Bridges Between Worlds, INTERCHI’93 Tutorial Notes 22. Reading, MA: Addison-Wesley; 1993.\n14. Beuscart-Zéphir MC, Watbled L, Carpentier AM, Degroisse M, Alao O. A rapid usability assessment methodology to\nsupport the choice of clinical information systems: a case study. Proc AMIA Symp 2002:46-50 [FREE Full text] [Medline:\n12463784]\n15. Zhang J, Johnson TR, Patel VL, Paige DL, Kubose T. Using usability heuristics to evaluate patient safety of medical devices.\nJ Biomed Inform 2003;36(1-2):23-30. [Medline: 14552844] [doi: 10.1016/S1532-0464(03)00060-1]\n16. Smith MK. The Encyclopedia of Informal Education. 2003. Learning Theory. URL: http://www.infed.org/biblio/b-learn.\nhtm [accessed 2009 Oct 26] [WebCite Cache ID 5fOKSfZtW]\n17. Jezierski J. Learnativity.com. 2003. Learning Styles. URL: http://www.learnativity.com/learningstyles.html [accessed 2009\nOct 30] [WebCite Cache ID 5kwoTBbNC]\n18. Russell SS. An overview of adult learning processes. Urol Nurs 2006;26(5):349-352, 370. [Medline: 17078322]\n19. Shneiderman B. Designing the User Interface: Strategies for Effective Human-Computer Interaction. Reading, MA:\nAddison-Wesley; 1998.\n20. Joshi A, Lichenstein R, Rafei K, Bakar A, Arora M. A pilot study to evaluate self initiated computer patient education in\nchildren with acute asthma in pediatric emergency department. Technol Health Care 2007;15(6):433-444. [Medline:\n18057566]\n21. Joshi A, Lichenstein R, King J, Arora M, Khan S. Evaluation of a Computer-Based Patient Education and Motivation Tool\non Knowledge, Attitudes, and Practice Towards Influenza Vaccination. IEJHE 2009;12:1-15.\nAbbreviations\nED: emergency department\nHCI: human computer interaction\nPAC: pediatric ambulatory center\nPEMT: Patient Education and Motivation Tool\nEdited by G Eysenbach; submitted 06.04.09; peer-reviewed by M Mackert, H Witteman; comments to author 28.04.09; revised version\nreceived 17.09.09; accepted 09.10.09; published 06.11.09\nPlease cite as:\nJoshi A, Arora M, Dai L, Price K, Vizer L, Sears A\nUsability of a Patient Education and Motivation Tool Using Heuristic Evaluation\nJ Med Internet Res 2009;11(4):e47\nURL: http://www.jmir.org/2009/4/e47/\ndoi: 10.2196/jmir.1244\nPMID: 19897458\n© Ashish Joshi, Mohit Arora, Liwei Dai, Kathleen Price, Lisa Vizer, Andrew Sears. Originally published in the Journal of Medical\nInternet Research (http://www.jmir.org), 06.11.2009.   This is an open-access article distributed under the terms of the Creative\nCommons Attribution License (http://creativecommons.org/licenses/by/2.0/), which permits unrestricted use, distribution, and\nreproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly\ncited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright\nand license information must be included.\nJ Med Internet Res 2009 | vol. 11 | iss. 4 | e47 | p. 10http://www.jmir.org/2009/4/e47/\n(page number not for citation purposes)\nJoshi et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX",
  "topic": "Usability",
  "concepts": [
    {
      "name": "Usability",
      "score": 0.9130677580833435
    },
    {
      "name": "Heuristic evaluation",
      "score": 0.8266324996948242
    },
    {
      "name": "Heuristics",
      "score": 0.6760831475257874
    },
    {
      "name": "Computer science",
      "score": 0.6481271386146545
    },
    {
      "name": "Cognitive walkthrough",
      "score": 0.5561137795448303
    },
    {
      "name": "Heuristic",
      "score": 0.555583119392395
    },
    {
      "name": "Human–computer interaction",
      "score": 0.43630677461624146
    },
    {
      "name": "Artificial intelligence",
      "score": 0.2770903706550598
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ]
}