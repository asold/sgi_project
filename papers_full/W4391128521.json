{
  "title": "Dual-3DM<sup>3</sup>AD: Mixed Transformer Based Semantic Segmentation and Triplet Pre-Processing for Early Multi-Class Alzheimer’s Diagnosis",
  "url": "https://openalex.org/W4391128521",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2730549247",
      "name": "Arfat Ahmad Khan",
      "affiliations": [
        "Khon Kaen University"
      ]
    },
    {
      "id": "https://openalex.org/A3010541911",
      "name": "Rakesh Kumar Mahendran",
      "affiliations": [
        "Rajalakshmi Engineering College"
      ]
    },
    {
      "id": "https://openalex.org/A2723128235",
      "name": "Kumar Perumal",
      "affiliations": [
        "Rajalakshmi Engineering College"
      ]
    },
    {
      "id": "https://openalex.org/A1962309956",
      "name": "Muhammad Faheem",
      "affiliations": [
        "University of Vaasa"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4386352629",
    "https://openalex.org/W4221004276",
    "https://openalex.org/W4366205215",
    "https://openalex.org/W4293424952",
    "https://openalex.org/W3044090667",
    "https://openalex.org/W4382601497",
    "https://openalex.org/W3171367875",
    "https://openalex.org/W4210510666",
    "https://openalex.org/W3091780972",
    "https://openalex.org/W4362553764",
    "https://openalex.org/W4200308765",
    "https://openalex.org/W3148758127",
    "https://openalex.org/W4221041973",
    "https://openalex.org/W4283653860",
    "https://openalex.org/W4386369694",
    "https://openalex.org/W3082697704",
    "https://openalex.org/W4317569231",
    "https://openalex.org/W3120576328",
    "https://openalex.org/W3183625741",
    "https://openalex.org/W3112492401",
    "https://openalex.org/W3011893870",
    "https://openalex.org/W4285130568",
    "https://openalex.org/W3007755486",
    "https://openalex.org/W3173195087",
    "https://openalex.org/W4381715639",
    "https://openalex.org/W4225898646",
    "https://openalex.org/W3137895856",
    "https://openalex.org/W3145812136",
    "https://openalex.org/W3167864582",
    "https://openalex.org/W3157083093",
    "https://openalex.org/W4362466462",
    "https://openalex.org/W4316496302",
    "https://openalex.org/W3082779161",
    "https://openalex.org/W4362590227",
    "https://openalex.org/W2995495466",
    "https://openalex.org/W3197215693",
    "https://openalex.org/W3152593248",
    "https://openalex.org/W4213039815",
    "https://openalex.org/W3018492956",
    "https://openalex.org/W3017328779"
  ],
  "abstract": "Alzheimer's Disease (AD) is a widespread, chronic, irreversible, and degenerative condition, and its early detection during the prodromal stage is of utmost importance. Typically, AD studies rely on single data modalities, such as MRI or PET, for making predictions. Nevertheless, combining metabolic and structural data can offer a comprehensive perspective on AD staging analysis. To address this goal, this paper introduces an innovative multi-modal fusion-based approach named as Dual-3DM3-AD. This model is proposed for an accurate and early Alzheimer's diagnosis by considering both MRI and PET image scans. Initially, we pre-process both images in terms of noise reduction, skull stripping and 3D image conversion using Quaternion Non-local Means Denoising Algorithm (QNLM), Morphology function and Block Divider Model (BDM), respectively, which enhances the image quality. Furthermore, we have adapted Mixed-transformer with Furthered U-Net for performing semantic segmentation and minimizing complexity. Dual-3DM3-AD model is consisted of multi-scale feature extraction module for extracting appropriate features from both segmented images. The extracted features are then aggregated using Densely Connected Feature Aggregator Module (DCFAM) to utilize both features. Finally, a multi-head attention mechanism is adapted for feature dimensionality reduction, and then the softmax layer is applied for multi-class Alzheimer's diagnosis. The proposed Dual-3DM3-AD model is compared with several baseline approaches with the help of several performance metrics. The final results unveil that the proposed work achieves 98% of accuracy, 97.8% of sensitivity, 97.5% of specificity, 98.2% of f-measure, and better ROC curves, which outperforms other existing models in multi-class Alzheimer's diagnosis.",
  "full_text": "D\nual\n-\n3DM\n3\n-\nAD: \nMixed \nTransformer based Semantic \nSegmentation and Triplet Pre\n-\nprocessing for Early \nMulti\n-\nClass Alzheimer's Diagnosis\n \nArfat Ahmad Khan, \nRakesh Kumar Mahendran, Kumar Perumal, \nMember, IEEE\n,\n \nMuhammad Faheem \n \n \n \nAbstract\n \n–\n \nAlzheimer's Disease (AD) is a widespread,\n \nchronic,\n \nirreversible,\n \nand\n \ndegenerative condition,\n \nand its early \nd\netection\n \nduring the prodromal stage is of utmost importance. \nTypically, AD studies rely on single data modalities, such as MRI \nor PET, for making predictions. Nevertheless, combining \nmetabolic and structural data can offer a comprehensive \nperspective on AD staging\n \nanalysis. To address this goal, this \npaper introduces an innovative multi\n-\nmodal fusion\n-\nbased \napproach\n \nnamed as\n \nDual\n-\n3DM\n3\n-\nAD\n. This model\n \nis proposed for\n \nan\n \naccurate and early Alzheimer’s diagnosis by considering \nboth MRI and PET image scans. Initially, we \npre\n-\nprocess\n \nboth \nimages in terms of noise reduction, skull stripping and 3D image \nconversion using Quaternion Non\n-\nlocal Means Denoising \nAlgorithm (QNLM), Morphology function and \nBlock Divider \nModel (BDM)\n,\n \nrespectively\n,\n \nwhich enhances the image quality. \nFurthermore\n, we have adapted Mixed\n-\ntransformer with \nFurthered U\n-\nNet for performing semantic segmentation\n \nand\n \nminimizing complexity. \nDual\n-\n3DM\n3\n-\nAD model \nis\n \nconsist\ned\n \nof \nmulti\n-\nscale\n \nfeature extraction module for extracting appropriate \nfeatures from both segmented images. \nT\nhe extracted features \nare \nthen \naggregat\ned\n \nusing Densely \nC\nonnected \nF\neature \nA\nggregator \nM\nodule (DCFAM) to utilize both features. Finally, \na\n \nmulti\n-\nhead\n \nattention mechanism is adapted for feature \ndimensionality reduction\n,\n \nand then\n \nthe\n \nsoftmax layer is applied \nfor multi\n-\nclass Alzheimer’s diagnosis.\n \nThe proposed Dual\n-\n3DM\n3\n-\nAD model is compared with several baseline approaches \nwith \nthe help of\n \nseveral performance metrics\n.\n \nThe final results unveil \nthat the\n \nproposed work achieve\ns\n \n98\n% of accuracy, 97.8% of \nsensitivity, 97.5% of specificity\n,\n \n98.2% of f\n-\nmeasure\n,\n \nand better \nROC curve\ns, which\n \noutperforms other existing models in multi\n-\nclass \nAlzheimer’s diagnosis\n.\n \n \nIndex Terms \n–\n \nAlzheimer’s diagnosis, Multi\n-\nmodalities, MRI, \nPET, Semantic segmentation, Mixed transformer, \nmulti\n-\nscale\n \nfeature extraction\n.\n \nI.\n \nI\nNTRODUCTION\n \nA\nlzheimer's disease, an inexorable and \nseries\n \nneurological \nproblem\n, \ncauses\n \nbrain shrinkage and ranks \namong the most prevalent \ncauses of mortality in the elderly population [1]\n-\n[3]. \nIt progressively \nerodes memory and cognitive faculties, eventually rendering even \nthe simplest tasks insurmountable, disrupting daily life [4]. The \nprimary culprit behind the disease is the accumulation of abnormal \nproteins in and around brain cells [5]. A\nmyloid protein aggregates \nto form plaques around the brain, while tau protein forms\n \n \nArfat Ahmad Khan is with Department of Computer Science, College of Computing, Khon \nKaen \nUniversity,\n \nKhon Kaen 40002, Thailand,\n \n(email:\narfatkhan@kku.ac.th\n)\n \nRakesh Kumar Mahendran is with Department of Computer Science and Engineering, \nRajalakshmi Engineering College, Chennai 602 105, India, \n(email:\nrakeshkumarmahendran@gmail.com\n)\n \nKumar Perumal is with Department of Computer Science and Engineering, Rajalakshmi \nEngineering College, Chennai 602 105, India. (email:\n \nkumar@rajalakshmi.edu.in\n)\n \nMuhammad Faheem is with Department of Computing Technology and Innovations, University \nof Vaasa,\n \nVaasa 65200, Finland, (email: \nmuhammad.faheem@uwasa.fi\n)\n \nCorresponding Author: Muhammad Faheem\n \ntangles within. Diagnosing Alzheimer's disease can be challenging, \nespecially in older individuals\n \n[6][7]\n. Consequently, \nM\nagnetic \nR\nesonance \nI\nmaging (MRI) \nhelps\n \nmedical professionals in the \ndetection of this illness. Image analysis stands out as a prominent \nmethod for diagnosing Alzheimer's disease, as modern medical \nimaging equipment yields a plethora of data about the\n \nunder\n-\nexamination\n \npatient. T1\n-\nweighted structural MRI scans and 18F 2\n-\nF\nluoro\n-\n2\n-\ndeoxy\n-\nD\n-\nG\nlucose \nP\nositron \nE\nmission \nT\nomography (FDG\n-\nPET) offer \nspatial insights into\n \natrophy and\n \nhypometabolism, \nrespectively\n \n[8]\n-\n[11]\n.\n \nThe pathophysiological processes \nbehind\n \nAlzheimer's disease \ninflict damage upon brain tissues and disrupt their normal metabolic \nfunctions\n \n[12]\n. FDG\n-\nPET can pinpoint areas with impaired function\ns\n \nby visualizing metabolic irregularities. \nThe r\negional \nhypoperfusion/hypometabolism, particularly in biparietal and \nbitemporal distributions, strongly correlates with the clinical \nd\netection\n \nof \nthe\n \ndisease\n \n[13][14]\n. PET scans are capable of \nidentifying diseases even before the emergence of discernible \nsymptoms or war\nning signals by scrutinizing \nbiological functions \nthrough metabolic processes\n \n[15]\n. Similarly, MRI scans can gauge \nvariations\n \nin the volume of recognizable brain regions, allowing the \nobservation of the gradual brain atrophy caused by AD\n-\nrelated \nneurodegeneration\n \n[16]\n. This atrophy is attributed to losses in \ndendrites and neurons. \nThe a\ntrophy measurements from MRIs can \nbe employed to estimate cumulative neuronal damage, as there exist \na robust correlation between atrophy and cognitive decline\n \n[17]\n-\n[19]\n.\n \n \nDetecting Alzheimer's disease \nwith the help of\n \nMRI images \ni\nnvolves\n \nmany\n \nkey \nstages\n, \nsuch as\n \npre\n-\nprocessing,\n \nextraction of \nfeatures,\n \nsegmentation, and classification. In the initial stage of pre\n-\nprocessing, MRI images undergo essential adjustments to address \ntheir susceptibility to noise a\ns well as non\n-\nbrain tissue existences\n \n(such as the\n \nskin, scalp, dura, muscles, fat, eye,\n \netc.)\n \n[20][\n3\n1][\n3\n2]\n. It\n \ni\ns worth noti\nci\nng that some previous studies omit skull stripping and \noverlook noise reduction (including\n \nsalt and pepper noise, Gaussian \nnoise, and Rician\n \nnoise, etc.), ultimately compromising their \nclassification accurac\nies\n. To enhance\n \nthe\n \nclassification accuracy and \ncomputational efficiency, segmentation follows pre\n-\nprocessing. \nSegmentation is a crucial process that involves distinguishing the \ncerebrospinal fluid, white matter, and gray matter, yielding essential \ninformation for subsequent\n \ncategorization\n \n[33]\n. Interestingly, some \nprior research neglects segmentation altogether, while many rely on \nautomated \nimage analysis tools like \nS\ntatistical \nP\narametric \nM\napping \n(SPM), FreeSurfer, and FSL\n-\nFAST4\n \n[34]\n. However, the use of such\n \nautomated tools can substantially increase\n \nthe\n \ncomputation time, \npotentially impacting the efficiency of the segmentation process\n \n[3\n5\n]\n. It\n \ni\ns important to highlight that \nthe\n \nautomated methods for \nestimating volume yield inaccurate results\n \nwithout the proper \nvalidation\n. Automated tools often rely on intensity comparisons with \nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2024.3357723\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\natlases to guide the segmentation process, which can introduce \npotential errors and complexities in the analysis\n \n[3\n6\n]\n.\n \n \nThe prevailing approach in current research involves employing \ndeep learning\n-\nbased\n \nmethods\n \nwith the aim of classification and \nextraction of useful\n \nfeature\ns\n. However, these algorithms typically \nextract only individual features or small datasets, which prove\ns to be\n \ninsufficient \nin terms of\n \nclassification\n \nin an accurate way\n. \nThe \ne\nxisting studies draw upon a repertoire of techniques, \ncontaining\n \nM\nachine \nL\nearning (ML), neural networks, and \nD\neep \nL\nearning (DL)\n \n[37]\n. ML \nmethod\ns \nincluding K\n-\nnearest \nneighbours\n, decision trees, \nSVM\n \nand random forests are frequently utilized. \nHowever\n, their \ntraining complexity tends to increase due to the generation of \nmany\n \ntrees during\n \nthe extraction of\n \nfeature\ns\n, and\n \nthese methods do not \nperform well in terms of \nhandling extensive datasets. On the other \nhand, deep learning, which relies on neural networks for\n \nclassification and the extraction of\n \nfeature\ns\n, encompasses various \nmodel\ns like convolutional neural networks, multilayer perceptrons, \nand radial basis functions. Deep learning surpasses the \nshortcomings\n \nof \nconventional \nML methods. However, this approach often \ninvolves numerous hidden layers, substantial convergence weights, \nand extended computation times, leading to\n \nthe\n \nheightened \ncomplexity and a potential reduction in classification accurac\nies\n \n[38]\n-\n[40]\n. To address these challenges, researchers have turned to \nMixed\n \ntransformer\n-\nbased semantic segmentation to overcome the \nhurdl\nes faced by automated tools during the segmentation process. \nAdditionally,\n \na\n \nmulti\n-\nscale feature extraction with an effective\n \nDual\n-\n3DM\n3\n-\nAD\n \narchitecture has been employed to mitigate the issues \narising from high complexity and elevated false positive rates \nencountered during\n \nthe\n \nfeature extraction.\n \nResearch Contribution\n \n \nThe diagnosis of Alzheimer's disease \nfaces\n \nseveral notable \ndrawbacks, particularly in the context of neuroimaging and image \nanalysis. Alzheimer's, a relentless and debilitating neurological \ncondition, is marked by significant challenges in its diagnosis. MRI \nand PET scans have become integral tool\ns for identifying the \ndisease,\n \nand\n \nthey are not without limitations. One significant \ndrawback is the high cost and resource\n-\nintensive nature of these \nimaging techniques, making them less accessible for many patients \nand healthcare facilities. Furthermore, \nthese methods primarily \nprovide structural or metabolic insights into the brain, often lacking \nthe ability to diagnose the disease in its early stages when structural \nchanges may not yet\n \nto\n \nbe apparent. Additionally, the process of \nimage analysis\n,\n \ninvolv\nes\n \npre\n-\nprocessing, segmentation, and \nclassification, is susceptible to errors and variations. \nAlthough \na\nutomated tools\n \nare\n \nconvenient,\n \nthey\n \ncan compromise accuracy and \nintroduce complexities. The prevailing use of neural networks, \nmachine learning, and deep \nlearning methods\n \nexhibits good \nperformances. However, they\n \noften demand substantial \ncomputational resources, resulting in\n \nthe\n \nincreased complexity and \npotentially reduced diagnostic accuracy. These challenges highlight \nthe need for ongoing research and the development of more \naccessible and precise diagnostic methods for Alzheimer's disease. \nHenceforth, we focus\n \non an\n \naccurate and earlier Alzheimer diagnosis \nusing multi\n-\nmodalities. To achieve th\nis\n, we have contribute\nd several \nnovelties explained as follows:\n \n\n \nThis paper introduces a novel approach that combines multiple \ndata modalities, specifically MRI and PET scans, to enhance \nAlzheimer's Disease (AD) diagnosis. This fusion\n-\nbased \napproach offers a holistic perspective on AD staging analysis.\n \n\n \nThe research incorporates advanced preprocessing techniques, \nincluding noise reduction, skull stripping, and 3D image \nconversion, achieved through the QNLM, Morphology \nfunction, and BDM. These processes significantly enhance the \nquality of the image data, \nensuring more reliable analysis.\n \n\n \nTo reduce complexity and improve the accuracy of the \nanalysis, the study employs \na\n \nMixed\n-\ntransformer with \nFurthered U\n-\nNet architecture for semantic segmentation. This \nstep aids in identifying and isolating relevant regions within the \nimages.\n \n\n \nDual\n-\n3DM3\n-\nAD model includes a \nmulti\n-\nscale\n \nfeature \nextraction module, which extracts pertinent features from both \nsegmented images. This module ensures that\n \nthe\n \ncritical \ninformation from images is\n \neffectively\n \ncaptured. \nThe e\nxtracted \nfeatures are\n \nthen\n \naggregated using the DCFAM. This \naggregation process maximizes the utilization of information \nfrom both MRI and PET scans, further enhancing the accuracy \nof the diagnosis.\n \nThe\n \nm\nulti\n-\nhead attention mechanism\n \nhelps\n \nto \nreduce\n \nthe\n \nfeature dimensionality. This step \nactually aids to\n \nstreamline the data\n,\n \nwhil\ne retaining essential information.\n \nII.\n \nL\nITERATURE \nS\nURVEY\n \nThe prevalence of big data analytics and the enhanced \ncomputational power offered by GPU clusters have firmly \nestablished \nD\neep \nL\nearning (DL) as a prevalent and influential \ntechnique, extending its reach into numerous domains. Presently, it \nhas become common to leverage DL models for various recognition \napplications in the realm of medical image analysis. In recent times, \nresearcher\ns have increasingly turned to MRI and PET modalities to \nembrace DL for the development of Alzheimer's \nD\nisease (AD) \ndiagnosis mod\nels. Remarkably, a high\n-\nresolution T1\n-\nweighted MRI \nscan possesses the capability to identify atrophies in distinct brain \nregions by providing critical structural insights into the brain. Wei \net al. [21] explore the application of Bi\n-\ndirectional Empirical M\nodel \nDecomposition (BEMD) for the automated detection of Alzheimer's \ndisease. BEMD, a signal processing technique, is employed for \nfeature extraction from medical data. This approach leverages \nBEMD's potential in revealing hidden patterns in multi\n-\nmodal da\nta \nsources to enhance the early diagnosis of Alzheimer's disease. The \nnovelty of this work lies in its innovative application of BEMD for\n \nthe\n \nautomated Alzheimer's disease detection, potentially improving \ndiagnostic accuracy. Zaina et al. [22] introduce a novel feature \nextraction method called Exemplar Pyramid for Alzheimer's disease \nclassification. The study focuses on extracting discriminativ\ne \nfeatures from neuroimaging data, particularly MRI scans, to aid in \nthe accurate detection of Alzheimer's disease.\n \nThe innovation lies in \nits novel approach of utilizing exemplar pyramid feature extraction, \nwhich enhances the accuracy and effectiveness of Alzheimer's \ndisease classification. Basheera et al. [23] present a classification \nmethod for Alzheimer's disease b\nased on \nC\nonvolutional \nN\neural \nN\networks (CNNs)\n,\n \nand\n \nthe\n \nenhanced \nI\nndependent \nC\nomponent \nA\nnalysis (ICA)\n \nis\n \napplied to segmented gray matter in MRI images. \nBy combining deep learning and feature extraction from MRI scans, \nthis study aims to advance the accuracy\n \nand efficiency of \nAlzheimer's disease detection. The paper's contribution lies in \nintroducing a novel Alzheimer's disease classification method that \ncombines CNN and hybrid enhanced ICA segmentation, improving \nthe accuracy of diagnosis using MRI data. Mur\nugan et al. [24] \npropose a deep learning model for the early diagnosis of Alzheimer's \ndisease and dementia using MR images. This research leverages the \nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2024.3357723\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\npower of deep neural networks to automatically extract relevant \nfeatures and classify patients based on neuroimaging data. The \naim\n \nof this work is the development of a deep learning model for early \nand accurate diagnosis of Alzheimer's disease and dementia, \npotentially advancing early intervention and treatment. Febietti et al. \n[25] delve into early detection by utilizing cortical an\nd hippocampal \nL\nocal \nF\nield \nP\notentials (LFPs) and \nensemble\n \nmachine learning \nmodels. By incorporating electrophysiological data, this study \nexplores an alternative approach to Alzheimer's disease detection. \nThe contribution of this work is the development of an ensemble \nmachine learning approach for early Alzheime\nr's disease detection \nusing neural signals, potentially advancing early diagnosis and \nintervention.\n \nDwivedi et al. [26] focuse on the development of a multi\n-\nmodal \nfusion\n-\nbased deep learning network for the effective diagnosis of \nAlzheimer's disease. It addresses the importance of integrating data \nfrom various sources, such as neuroimaging, genomics, and \nclinical \nassessments, to enhance diagnostic accuracy. Yu et al. [27] explore \nthe application of high\n-\norder pooling and \nG\nenerative \nA\ndversarial \nN\networks (GANs) for assessing Alzheimer's disease. The research \nintroduces innovative techniques for feature extra\nction and data \nrepresentation by tensorizing GANs. The approach aims to improve \nthe accuracy and efficiency of Alzheimer's disease assessment using \nadvanced data manipulation. The effectiveness of this paper is the \ninnovative integration of high\n-\norder pool\ning and GAN techniques to \nenhance the assessment of Alzheimer's disease, potentially \nimproving diagnostic accuracy and early detection. Song et al. [28] \ndelve into the application of the Random Forest algorithm for \ndiagnostic classification and biomarker i\ndentification in Alzheimer's \ndisease. It emphasizes the importance of interpretable machine \nlearning methods in uncovering relevant biomarkers for diagnosis. \nBron et al. [29] investigate the generalizability of machine learning \nmodels for Alzheimer's disea\nse diagnosis across different cohorts. It \naddresses the challenge of model transferability by examining the \nperformance of deep learning and conventional machine learning \nmodels on diverse datasets.  The effectiveness of this research is \ndemonstrated throu\ngh its robust ability to generalize and accurately \ndiagnose Alzheimer's disease across multiple cohorts, showcasing \nits potential for broad clinical application. Etmanani et al. [30] \nintroduce a 3D deep learning model for predicting the diagnosis of \nvariou\ns neurodegenerative disorders, including dementia with Lewy \nbodies, Alzheimer's disease, and mild cognitive impairment. The use \nof brain 18F\n-\nFDG PET scans and deep learning techniques \nunderscores the potential of non\n-\ninvasive imaging in early diagnosis \nand\n \ndifferentiation of these conditions. The effectiveness of this \nwork is evidenced by its accurate prediction of various \nneurodegenerative conditions through the analysis of 3D PET scans, \nproviding valuable diagnostic support. \n \nIII.\n \nD\nUAL\n-\n3DM\n3\n-\nAD\n \nF\nRAMEWORK\n \nIn this study, we primarily concentrate on the\n \ndetection of \nAlzheimer’s disease with the help of mathematical\n \nmodelling. \nWith \nthe help of\n \npre\n-\nprocessing,\n \nextracting features, \nand segmenting\n, the \nsuggested approach increases\n \nthe\n \nclassification accuracy. We use the \nAlzheimer's Disease Neuroimaging Initiative (ADNI) database's T1\n-\nweighted MRI and PET images. The three phases of the proposed \nwork are as follows: \n \nA.\n \nData Acquisition\n \n \n \nIn this research, we have utilized neuroimaging data acquired \nfrom Alzheimer's Disease Neuroimaging Initiative (ADNI) \ndataset \n(\nhttps://www.kaggle.com/datasets/madhucharan/alzheimersdisease\n5classdatasetadni\n). \nThe main intention of ADNI \nteam\n \nis\n \nthe\n \nneuropsychological calculation for evaluating the improvement of \nMCI to initial AD and for AD supplemented via research of resultant \nof combined several biomarkers, \nutilizing \nCerebos S\npinal \nF\nluid \n(CSF) data, MRI and PET.\n \nThe\n \nc\nases are chosen from ADNI dataset \ncohort to our experiment prerequisite, \nhaving the visit of both \nconsequent and screening. \nThe cases age range\ns\n \nfrom 55 to 89\n \nyears \nold\n, containing both female and male. \nW\ne chose 100 normal, 100 \nMCI and AD cases. For every \ncase\n, the 18\n-\nFDG\n-\nPET images and \nT1\n-\nweighted MRI are adapted in this research. \nHere\n, the\n \nPET images \nare\n \nobtained \nby \nthe \nconstructor\n \nmodel of SIEMENS \nalong with \n2.4mm slice thickness. \nFor that, the radiopharmaceutical 18F\n-\nFDG \nis utilized\n \nwhich consists of 63\n \nslices. \nBesides, MRI images are \nacquired by 1.5 T scanners\n. The\n \nslice\n \nthickness is\n \n1.2mm\n \nwith\n \n160 \nslices\n, where the \nsize\n \nof each slice is\n \n192x192\n \nof 3D images\n. \n \nB.\n \nData Pre\n-\nprocessing\n \n \nThe pre\n-\nprocessing approach is optimally prejudiced by \nthe \nconsequent processing algorithm with image format defined as\n:\n \n(i)\n \nNoise Reduction:\n \n \nInitially, the noise present in both MRI and PET scans \nis\n \nremoved for enhancing image quality. \nTo do\n, we have utilized \nQuaternion Non\n-\nlocal Means Denoising Algorithm (QNLM). \nAs\n \nthe \nQNLM denoising technique leverages the inherent high\n-\ndegree self\n-\nsimilarities within images for noise suppression, the choice of a \nsimilarity metric among image patches plays a pivotal role in the \nalgorithm's noise reduction effectiveness. We have int\nroduced a \nnovel approach by replacing the traditional Euclidean distance with \nthe QNLM technique as \na\n \nmetric for evaluating similarit\nies\n \nbetween \nimage patches. \nMeanwhile\n,\n \nthe image \ninformation constantly\n \ncontains\n \ncertain repeatability\n,\n \nas self\n-\nresemblance forms during the \ndistribution of noise is arbitrary. Hence, the target of QNLM is to \nmake utilize of self\n-\nresemblance forms to overwhelm the noise. \nHenceforth, the QNLM improve\ns the\n \ndenoising process from the \nlevel of pixel to patch. The noisy MRI image is modeled as \n\u0000\n=\n\u0000\n+\n\u0000\n,\n \nand then\n \nthe\n \ndenoised image \n\u0000\n\u0000\n \nby QNLM is mathematically \nexpressed as\n:\n \n                     \n\u0000\n\u0000\n(\n\u0000\n)\n=\n∑\n\u0000\n(\n\u0000\n,\n\u0000\n)\n×\n\u0000\n(\n\u0000\n)\n\u0000\n\u0000\n\u0000\n\u0000\n∑\n\u0000\n(\n\u0000\n,\n\u0000\n)\n\u0000\n\u0000\n\u0000\n\u0000\n                              \n(1)\n \n \nWhere \nδ\n\u0000\n \nis denoted as\n \nthe\n \nsearch window along with center \nρ\n,\n \nand\n \nthe weight \nϖ\n(\nρ\n,\nq\n)\n \nis defined as\n:\n \n                  \nϖ\n(\nρ\n,\nq\n)\n=\nexp\n\u0000\n−\n\u0000\n(\n\u0000\n,\n\u0000\n)\n/\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n                    \n(2) \n \n \nHere, \n\u0000\n(\nρ\n,\nq\n)\n \nindicates the Euclidean distance among two image \npatches along with center \nρ\n \nand \nq\n \nin \nδ\n\u0000\n. Likewise, the PET image \nscans are denoised for image betterment.\n \n(ii)\n \nSkull Stripping\n \n \nFollowing\n \ndenoising\n, the\n \nskull stripping is performed by \nutilizing morphology. \nThe s\nkull stripping is a preprocessing step \nperformed in Alzheimer's disease diagnosis using brain imaging \ntechniques, such as MRI and PET scans. It involves the removal of \nnon\n-\nbrain tissues, including the skull, scalp, and other extraneous \nstructures, from the\n \nacquired images. This step is crucial because it \nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2024.3357723\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nhelps isolate the brain region of interest, reducing noise and \ninterference caused by surrounding tissues. By effectively stripping \naway non\n-\nbrain elements, the\n \nprocesses of\n \nsubsequent image \nanalysis and feature extraction become more accurate, allowing for \na clearer focus on the brain's structural and metabolic changes \nassociated with Alzheimer's disease.\n \nThe\n \ns\nkull stripping enhances \nthe overall quality of the images and aids in the reliable and precise \ndetection of Alzheimer's\n-\nrelated abnormalities. For t\nh\nis\n \npurpose, \nthe\n \nproposed technique is mathematically integrated\n \nwith\n \nErosion and \nDilation operators. \nFurthermore, the proposed technique utilized \nglobal thresholding continued by morphological functions. \nT\nhe \nt\nhresholding value is evaluated as per intensity distribution \nknowledge of brain scans. \nInitially, the \nimage \n(\nℑ\n)\n \nis read\n,\n \nand RGB \nis \nconverted as grayscale profile \n(\nℑ\n\u0000\n)\n. Here\n,\n \nthe grayscale scan is \neroded \n(\nℑ\n\u0000\n)\n \nby structuring element of disk\n-\nhanded \n(\nx\n)\n \nin size 4 that \nis continued by Dilation \n(\nℑ\n\u0000\n)\n \nof \noutcome image utilizing \nsame\n \nstructuring element \n(\nx\n)\n. \nBy\n \nadapting thresholding scheme, the\n \nacquired\n \nimage is\n \nthen\n \nbinarized \n(\nℑ\n\u0000\n)\n. \nThe\n \nacquired\n \nbinary image is \ntransmuted to unit of 8 format \n(\nℑ\n\u0000\n)\n \nand that is subtracted \n(\nℑ\n\u0000\n)\n \nfrom \nthe grayscale profile comprising skull portion alone. \nBy subtracting\n \nthe image of\n \n(\nℑ\n\u0000\n)\n \nfrom grayscale, the skull portion is removed and \nthen, the region of brain is acquired\n,\n \nwhich is \nwritten\n \nas\n:\n \nℰ\n(\nf\n)\n=\nf\n⨁\nx\n=\n{\nγ\n|\n(\nx\n)\n\u0000\n∩\nf\n∁\n=\n∅\n}\n              \n      \n        \n(3)\n \n\u0000\n(\nf\n)\n=\nf\n⨁\nx\n=\n{\nγ\n|\n(\nx\n)\n\u0000\n∩\nf\n=\n∅\n}\n               \n        \n      \n(4)\n \n(iii)\n \n3D Image Conversion\n \nAs 3D image \nfacilities\n \na better navigation in terms of multiple \nperspectives, we transfigured the images to 3D with the skull \nstripping.\n \nAs \n3D images allow us to navigate from multiple \nperspectives \nin\n \nthe quest for skull stripping, the transformation of \ntwo\n-\ndimensional (2D) MRI scans into three\n-\ndimensional (3D) \nimages is undertaken. This transformation is driven by the inherent \nlimitation of 2D images, which provide\ns\n \na flat and single\n-\nperspective view, while 3D images enable navigation from multiple \nangles, offering richer and m\nore diverse viewpoints. To achieve \nthese enhanced 3D images, a Block Divider Model (BDM) is \nemployed, significantly reducing the time required to obtain precise \ndepth details by segmenting the 2D images into blocks.\n \nThe process \nbegins with the creation of a depth map through node and link \nformation. During the conversion from 2D to 3D images, the depth \n \ngradient hypothesis assigns depth values to individual blocks. This \nhypothesis encompasses depth gradients, validating accuracy within \nthe detected area, culminating in the generation of depth maps. \nFurthermore, the identification of shifts in the scene al\nlows the \nexamination of linear scene perception, facilitated by the Hough \nTransform Line Detection Algorithm (HTLDA). The mathematical \nformulation of the depth gradient hypothesis is as follows:\n \nDep\n(\n\u0000\n)\n=\n128\n+\n255\n\u0000\n∑\nW\n\u0000\u0000\n\u0000\u0000\u0000\u0000\u0000\n(\n\u0000\n,\n\u0000\n)\n+\n \nW\n\u0000\u0000\n\u0000\n\u0000\n\u0000\u0000\u0000\u0000\u0000\u0000\n\u0000\n\u0000\u0000\u0000\u0000\u0000\n\u0000\n/\npixe\nl\n\u0000\u0000\u0000\n(\n\u0000\n)\n                   \n                                                          \n(5)\n                                                       \n \nWhere \n|\nw\n\u0000\u0000\n|\n+\n|\nw\n\u0000\u0000\n|\n=\n1\n \nDep\n(\n\u0000\n\u0000\n)\n=\n\u0000\n\u0000\n(\n\u0000\n\u0000\n)\n∑\ne\n\u0000\n\u0000\n.\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n∈\n\u0000\n(\n\u0000\n\u0000\n)\nDep\n\u0000\na\n\u0000\n\u0000\n \n(6)\n            \n \n    \nP\n(\na\n\u0000\n)\n=\n∑\ne\n\u0000\n\u0000\n.\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n(\n\u0000\n\u0000\n)\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n∈\n\u0000\n(\n\u0000\n\u0000\n)\n   \n(7)\n \nA higher depth value indicates that the pixel is closer to the \nobserver. Here,\n \nthe\n \nintensity values are scaled from 0 (black) to 255 \n(white), with intermediate shades of gray\n \nare\n \nrepresenting different \nsignal strengths in the image. \nThe following equation illustrates that \nthe\n \ncenter of gravity is represented by the depth value\n \nwithin a block \ngroup, where\n \nthe \npixels belong to the same group share the\n \nsame \ndepth value. The |\nw\n\u0000\u0000\n \n| and |\nw\n\u0000\u0000\n \n| values \nare controlled\n \nto control the \ndepth gradient \nhorizontally as well as vertically\n. Once the depth map \nis generated by grouping regions into blocks, it may exhibit blocky \nartifacts. To address this issue, the cross\n-\nbilateral filter is employed \nto smoothly refine the depth map while preserving object \nboundaries. Afterward, the depth map \nis further improved through \npixel value adjustments and hole filling using the \nQNLM \nfilter, \nresulting in the creation of 3D representations. The preprocessing of \nthe d\nepth image primarily involves applying a smoothing filter. \nHowever\n,\n \nthis filter, combined with the transition of sharp horizontal \nfeatures, can create significant holes. To mitigate this problem, the \nQNLM \nfilter is utilized to reduce the occurrence of large holes.\n \nW\ne\n \nthen\n \nexecute 3D image warping,\n \nand\n \nthe 3D image warping \nscheme repositions pixels according to their depth values. The \nformulation of 3D image warping is as follows\n:\n \n                            \ne\n\u0000\n=\ne\n\u0000\n+\n\u0000\n\u0000\n\u0000\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n    \n                \n            \n    \n(8)\n                         \n                            \ne\n\u0000\n=\ne\n\u0000\n−\n\u0000\n\u0000\n\u0000\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n         \n          \n             \n     \n(9)\n                    \nWhere\n,\n \nthe horizontal positions are expressed as\n \ne\n\u0000\n,\ne\n\u0000\n \nand \ne\n\u0000\n \n \nwith respect to the left, right and interposed positions, respectively. \nThe value of depth in the current pixel is represented by\n \nZ\n. The \ndistance of eye and the focal length is represented as  \nd\n\u0000\u0000\n \nand\n \nf\n, \nrespectively\n.\n \nMoreover\n,\n \nwe use QNLM with the aim of filtering \nholes to generate a \n3D image.\n \nC.\n \nTransformer based Semantic Segmentation\n \nFollowing the\n \npre\n-\nprocessing\n,\n \nboth pre\n-\nprocessed images are \nutilized for segmentation. Here, transformer based semantic \nsegmentation is executed for acquiring pixel\n-\nlevel information \neffectively. For that, \nMixed\n-\ntransformer is \nused for getting\n \nfeatures\n,\n \n \nincluding\n \ncortical thickness, \ncolour\n, texture and boundary \ndetails\n \nfrom images. \nT\nhe densely connected feature aggregator model is\n \nthen\n \nemployed for collecting the features from multi\n-\nmodalities and \nsegment the ROI\n,\n \nwhich \nis\n \ndetailly described below as follows\n:\n \n(i)\n \nMixed Transformer \n \n \nThe core architecture of the network is based on an encoder\n-\ndecoder framework, with the incorporation of skip connections \nduring the decoding phase to retain essential low\n-\nlevel features. \nNotably, in an effort to optimize computational resources, we \nselect\nively apply Multi\n-\nHead Transformer Modules (MTMs) \nexclusively to the deeper layers with reduced spatial dimensions. For \nthe upper layers, we maintain the use of conventional convolutional \noperations. This distinction is deliberate, as the initial layers c\nontain \nhigher\n-\nresolution features, and our focus is on capturing local \nrelationships within them. Furthermore, the utilization of \nconvolutional operations in the upper layers enables us to introduce \nstructural priors into the model, a valuable feature part\nicularly when \nworking with relatively small medical image datasets. It is worth \nnoting that a 2\n-\nstride convolutional/deconvolutional kernel is \nuniformly employed across all Transformer modules to facilitate \nchannel expansion, compression, and down/up sampl\ning. MT \nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2024.3357723\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\ncomprise\ns\n \nof \nL\nocal \nG\nlobal \nG\naussian\n-\nS\nelf \nA\nttention (LGG\n-\nSA) and \nDense Allied Feature Accumulation (DAFA). LGG\n-\nSA is \nconstructed to model long\n-\nrange and short\n-\nrange dependencies \nalong with diverse granularity. This technique is designed to \nsubstitute the encoder of traditional transformer for minim\nizing time \ncomplexity as well as\n \nproviding\n \nbetter performance. LGG\n-\nSA \nmodules are detailed below as follows\n:\n \n(a)\n \nLocal\n-\nGlobal Self\n-\nAttention\n \n \nInitially, the SA tends to extract the \ninterconnectedness among \nthe entire entities of both MRI and PET image input\ns\n \nindividually. \nTo identify the target, SA adapts three matrices that are key \n(\n\u0000\n)\n, \nquery \n(\n\u0000\n)\n \nand value \n(\n\u0000\n)\n. Th\ne\nse three matrices are defined as input \nlinear transforms \n\u0000\n. \nBesides, we introduce LGSA\n,\n \nas\n \nshown in\n \nfig.1\n,\n \nfor enhancing the significance of correlations. Here\n,\n \nthe local \nSA evaluates self\n-\nsympathies inside every window. \nNext\n, the\n \ntokens \ninside every window are accumulated as global token\ns\n. \nFor\n \nthe\n \naccumulation operations, we appl\ny\n \nmax pooling, stride convolution\n,\n \nand other techniques of \nthat \nL\nightweight \nD\nynamic \nC\nonvolution \n(LDC) execute effective\nly\n. Following the overall features of down\n-\nsampled, we execute Global SA with minimal expense. For \n\u0000\n∈\nℝ\nℋ\n×\n\u0000\n×\n\u0000\n \n, if we fix window size to \n\u0000\n,\n \nthen the entire process is \nmathematically expressed as\n:\n \n                        \n\u0000\n\u0000\u0000\u0000\n=\n\u0000\u0000\u0000\n(\n\u0000\n)\n                                 \n(10)\n \n                     \n\u0000\n\u0000\u0000\u0000\n=\n\u0000\u0000\u0000\n\u0000\n\u0000\u0000\u0000\n(\n\u0000\n\u0000\u0000\u0000\n)\n\u0000\n                          \n(11)\n \n                \n\u0000\n=\n\u0000\u0000\u0000\u0000\u0000\u0000\n\u0000\n\u0000\n\u0000\u0000\u0000\n,\n\u0000\u0000\n\u0000\u0000\u0000\u0000\u0000\u0000\n\u0000\n\u0000\n\u0000\u0000\u0000\n\u0000\n\u0000\n             \n \n      \n(12)\n \n \nWhere \n\u0000\n \nindicates the output, LSA is local self\n-\nattention\n,\n \nand \nGSA is equivalent global functions.\n \n(b)\n \nGaussian\n-\nWeighted Axial Attention\n \n \nContrasting Local Self\n-\nAttention (LSA) utilizing default SA, we \ndesigned Gaussian Weighted Axial Attention (GWAA) which \nimproves every query perception of adjacent via \ndeterminable\n \nLSA\nGSA\nAggregate\nUpsample\nC\nSqueeze\nLayer Norm\nLayer Norm\nNorm\nM\nK\nM\nV\nExternal Attention\nLGG\n-\nSA\n \nFig.1 LGG Architecture\n \nGaussian matrix, and meanwhile minimal time complexity \nas per \naxial attention. Let \n\u0000\n∈\nℝ\nℋ\n\u0000\n×\n\u0000\n\u0000\n \nsignifies the queries acquired from \naccumulation step, for query \n\u0000\n\u0000\n,\n\u0000\n \nin \n\u0000\n, we describe \n\u0000\n\u0000\n,\n\u0000\n \nas Euclidean \ndistance among \n\u0000\n\u0000\n,\n\u0000\n \nand it\n \ni\ns equivalent\n \nto\n \n\u0000\n\u0000\n,\n\u0000\n \nand \n\u0000\n\u0000\n,\n\u0000\n, where \n\u0000\n\u0000\n,\n\u0000\n \nand \n\u0000\n\u0000\n,\n\u0000\n \nare represented as matrices \ncomputed from tokens on \n\u0000\nth \nrow and \n\u0000\nth column after accumulation. \nAssume the similarity \namong \n\u0000\n \nand \n\u0000\n \nexistence \nֆ\n(\n\u0000\n,\n\u0000\n)\n \nand then \nweight of Gaussian \nbeing \n\u0000\n\u0000\n\u0000\n\u0000\n.\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n, \nthe output of final in position \n(\n\u0000\n,\n\u0000\n)\n \ncan be depicted as\n:\n \n         \n\u0000\n\u0000\n,\n\u0000\n=\n\u0000\n\u0000\n\u0000\n\u0000\n.\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n \n\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n\u0000\nֆ\n\u0000\n\u0000\n\u0000\n,\n\u0000\n,\n\u0000\n\u0000\n,\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n,\n\u0000\n             \n(13)\n \n \nMeanwhile, we need the variance \n\u0000\n \nto be determinable and then \naforementioned equation \ncan be also denoted as\n:\n \n\u0000\n\u0000\n,\n\u0000\n=\n\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n \n\u0000\n−\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n.\n\u0000\n\u0000\n+\nֆ\n\u0000\n\u0000\n\u0000\n,\n\u0000\n,\n\u0000\n\u0000\n,\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n,\n\u0000\n       \n(14) \n \n \nHere\n, \nwe generally utilize \n\u0000\n \nto denote the factor of coefficient \nbefore \n\u0000\n\u0000\n.\n\u0000\n\u0000\n,\n\u0000\u0000\n\u0000\n.\n\u0000\n\u0000\n \nfurther play as bias of correlative position, \nwhich\n \ncan underline the position information of MT. It enhances the model \nperformance for obviously affording correlative relations,\n \nand it is\n \nthe usual embedding of utter\n \npositional. \nAt last, the EA is introduced \nfor solving the issues which cannot exploit correlations among \ndiverse images. \n \n \n(ii)\n \nSemantic Segmentation using Furthered U\n-\nNet\n \n \nAfter extracting features with the Mixed Transformer, we \nemploy the Furthered U\n-\nNet (FU\n-\nNet) Algorithm to segment white \nmatter, grey matter, and cerebrospinal fluid. This segmentation \neffectively breaks down the infected areas, as depicted in Figure 2. \nIn \ncontrast to the traditional U\n-\nNet approach, our work incorporates \nB\natch \nN\normalization (BN) to enhance training stability and mitigate \ngradient vanishing issues. This optimization enhances the \nsegmentation performance, further aiding model convergence. The\n \nmathematical evaluation of the rational formula proceeds as follows:\n \n            \nΛ\n=\n\u0000\n\u0000\n\u0000\u0000\u0000\n[\n\u0000\n]\n\u0000\n\u0000\n∙\n\u0000\n+\n\u0000\n\u0000\n−\n\u0000\n.\n\u0000\n[\n\u0000\n]\n\u0000\n\u0000\u0000\u0000\n[\n\u0000\n]\n\u0000\n\u0000\n\u0000\n            \n  \n    \n(15)\n \n \nIn the equation \nabove, 'x' represents the input features, 'Λ' \ndenotes the standardized feature with values close to zero. The \nparameters 'ψ' and '\nɱ\n' are training parameters that are\n \nupdated during \nthe \nprocess. Subsequently, the loss function\n \n(cross\n-\nentropy) is used\n \nin the training phase. The\n \nAdam optimizer is utilized for the \noptimization tasks,\n \nThe\n \nupdating of\n \nparameter\ns\n \nwithin the algorithm \ncan be expressed as follows:\n \n                          \n\u0000\n\u0000\n=\n\u0000\n\u0000\n−\n\u0000\u0000\n√\n\u0000\n\u0000\n                                \n(16)\n \n              \n\u0000\n\u0000\n=\n\u0000\n\u0000\n×\n\u0000\n\u0000\n+\n(\n1\n−\n\u0000\n\u0000\n)\n\u0000\n\u0000\n(\n\u0000\n\u0000\n)\n              \n(17)\n \n            \n\u0000\n\u0000\n=\n\u0000\n\u0000\n×\n\u0000\n\u0000\n+\n(\n1\n−\n\u0000\n\u0000\n)\n[\n\u0000\n\u0000\n(\n\u0000\n\u0000\n)\n]\n\u0000\n              \n(18)\n \n \nWhere \n\u0000\n\u0000\n,\n\u0000\n\u0000\n \ndenoted as loss rate, \n\u0000\n \nis the learning rate, the \nparameters \n\u0000\n\u0000\n \nand \n\u0000\n\u0000\n \nare\n \nthe old and new parameters. \n\u0000\n \nrepresents \nthe morphology differs.\n \nMoreover, the algorithm can compute the \nlearning rates range in repetition to assure the parameter stability and \nefficiency of high computational.\n \nD.\n \nMulti\n-\nmodality\n-\nbased Alzheimer’s Diagnosis\n \n \nOnce the \nsegmentation is completed, the segmented image is \nfed into proposed Dual\n-\n3DM\n3\n-\nAD model. In that, the appropriate \nfeatures are extracted in multi\n-\nscale, and dimensionality is \nminimized by using the multi\n-\nhead attention mechanism, which is \nelaborated as follows:\n \n(i)\n \nMulti\n-\nscale Feature Extraction\n \n \nWe utilize two parallel ResNet\n-\n51 blocks as encoders for \nextracting the feature maps from both MRI and PET segmented 3D \nimages separately. For the utilization of encoder input, we direct the \nMRI and PET images in three channels by repeating their\n \nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2024.3357723\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n \nFig.2 Representation of Multi\n-\nmodalities Segmented Image\n \ninformation in single\n-\nchannel. \nThe encoder is convolution \nintegration, \nR\nectified \nL\ninear \nU\nnit (ReLU)\n, batch normalization and \nmax pooling (CRBM) followed through an alternate integration of \nResNet\n \nblock (\nR\nB) and \nE\nvolution \nDown sampling\n \nB\nlock (EDB). \nWe \nextract the feature \n\u0000\n\u0000\u0000\u0000\n \nsuch as textural, statistical, structural, edge, \nblobs, color and contour are extracted using\n \nthe\n \nmulti\n-\nscale feature \nextraction model. Additionally, the PET images are extracted \n\u0000\n\u0000\u0000\u0000\n \nafter every ResNet block. \nFrom encoders, we extract \n\u0000\n\u0000\u0000\u0000\n \nand \n\u0000\n\u0000\u0000\u0000\n \nfeatures at 1/4, 1/8, 1/16 and 1/32 scales in size of original image. \nAfter that,\n \nthe\n \nmulti\n-\nscale features are acquired in elementwise \naddition.\n \n(ii)\n \n \nDensely Allied Feature Accumulation      \n \n \n \nIn order to aggregate the features from MRI and PET, we \nadapted DAFA module for feature representation. Specifically, we \nintroduce \nC\nollective \nS\npatial \nA\nttention (CSA) and \nC\nollective \nC\nhannel \nA\nttention (C2A) for improving the spatial\n-\nwise and \nchannel\n-\nwise representation of semantic features. Here, the main \nintention of utilizing CSA and C2A\n \nis\n \nto perform multi\n-\nscale \nfeatures in diverse scales. To be more specific, both CSA and C2A \ncomprise of convolutional filters, query, value and key function\ns\n \nwhich provide \nappropriate weights for individual features to \naccumulate precisely. \nAdditionally,\n \nthe\n \nfeatures from multi\n-\n \nmodalities are combined by utilizing downsample association and \nupsample association of large\n-\nfiled for enhancing the multi\n-\nscale \nillustration. The DAFA accumulates features of MRI and PET as \n\u0000\n\u0000\u0000\u0000\n \nand \n\u0000\n\u0000\u0000\u0000\n. \n \n(a)\n \nUpsample Connections\n \n \nThe upsampling connections \n∪\n\u0000\n\u0000\n(\nճ\n)\n \naim to pass information \nfrom one layer to another, while maintaining or even enhancing \nspatial resolution. In which, \nboth MRI and PET pass features \ninformation for enhancing the spatial resolution by integrating \nupsampling operations.  \n \n(b)\n \nDownsample Connection   \n \n \nThe downsample\n \nconnection tends to interlink with both MRI \nand PET features for fusion, and it can be expressed as:\n \n\u0000\n\u0000\n\u0000\n(\nճ\n)\n=\n\u0000\nʋ\n\u0000\n\u0000\n\u0000\n(\nճ\n)\n+\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n(\nճ\n)\n\u0000\n\u0000\n             \n(19)\n \n \nWhere \nճ\n \ndenote\ns the\n \ninput vector, \n\u0000\nʋ\n \nis the ReLU activation \nfunction. The parameter \n\u0000\n\u0000\n \nand \n\u0000\n\u0000\n \nare 3x3 convolution layer along \nwith 2 stride and \n\u0000\n\u0000\n \nis a \n3x3 convolution layer along with 1 stride. \nHere, every convolution layer includes batch normalization \ntechnique. \n\u0000\n \nand \n\u0000\n \nare represented as channels of input and \noutput\n,\n \nrespectively.\n \n(\nc\n)\n \nCollective Spatial Attention\n \n \nAs per the mechanism of linear attention, we used the CSA to \ndesign the long\n-\nrange addictions of spatial dimension\n, and it\n \ncan \nmathematically\n \nbe\n \ndefined as\n:\n \n\u0000\u0000\u0000\n(\nճ\n)\n=\n∑\n\u0000\n(\nճ\n)\n\u0000\n,\n\u0000\n\u0000\n\u0000\n\u0000\n(\nճ\n)\n‖\n\u0000\n(\nճ\n)\n‖\n\u0000\n\u0000\n\u0000\n\u0000\n(\nճ\n)\n‖\n\u0000\n(\nճ\n)\n‖\n\u0000\n\u0000\n\u0000\n\u0000\n(\nճ\n)\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n(\nճ\n)\n‖\n\u0000\n(\nճ\n)\n‖\n\u0000\n\u0000\n∑\n\u0000\n\u0000\n(\nճ\n)\n‖\n\u0000\n(\nճ\n)\n‖\n\u0000\n\u0000\n\u0000\n,\n\u0000\n\u0000\n\u0000\n    \n         \n  \n(20)\n \nWhere\n,\n \n\u0000\n(\nճ\n)\n,\n\u0000\n(\nճ\n)\n \nand \n\u0000\n(\nճ\n)\n \nindicate the convolutional functions \nto compute the query matrix \n\u0000\n∈\nℝ\n\u0000\n×\n\u0000\n\u0000\n, key matrix \n\u0000\n∈\nℝ\n\u0000\n×\n\u0000\n\u0000\n \nand value matrix \n\u0000\n∈\nℝ\n\u0000\n×\n\u0000\n\u0000\n, \n\u0000\n \ndenotes \nthe\n \nnumber of pixels of \ninput feature maps. \n\u0000\n \nand \n\u0000\n \nare the dimension of flattened spatial \nand channel dimension. \n \n(d)\n \nCollective Channel Attention\n \n \nLikewise, CCA is modelled for extracting the long\n-\nrange\n \naddictions between channel dimension that can defined as: \n \n\u0000\u0000\u0000\n(\nճ\n)\n=\n∑\nℜ\n(\nճ\n)\n\u0000\n,\n\u0000\n\u0000\n\u0000\nℜ\n(\nճ\n)\n\u0000\n,\n\u0000\n\u0000\n\u0000\n(\nճ\n)\n‖\n\u0000\n(\nճ\n)\n‖\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n(\nճ\n)\n‖\n\u0000\n(\nճ\n)\n‖\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\nℜ\n(\nճ\n)\n‖\nℜ\n(\nճ\n)\n‖\n\u0000\n\u0000\n\u0000\n∑\n\u0000\nℜ\n(\nճ\n)\n‖\nℜ\n(\nճ\n)\n‖\n\u0000\n\u0000\n\u0000\n,\n\u0000\n\u0000\n\u0000\n      \n(21)\n \n \nWhere \nℜ\n(\nճ\n)\n \ndenotes the reshape function for flattening the \nspatial dimension. In summary, the primary difference lies in what \nactually these attention mechanisms focus on: spatial attention deals \nwith the spatial positions within the data, while channel attention \ndea\nls with the feature channels or dimensions. They can be used in \ncombination to enhance the representation and performance of the \nproposed model, depending on the nature of the classification task.\n \n(e)\n \nFeature Accumulation\n \n \nAt last, the features obtained from both MRI and PET features \n\u0000\u0000\n\u0000\n \nand \n\u0000\u0000\n\u0000\n \nare fused, which can be generated by the following \nmathematical equations:\n \n              \nɸ\n=\n\u0000\n\u0000\u0000\u0000\n+\n\u0000\n\u0000\u0000\u0000\n+\n\u0000\n                            \n(22)\n \n \nHere, \nɸ\n \nis the feature accumulation factor,  \n\u0000\nis the feature \nobtained from both MRI and PET indicated as \n\u0000\n\u0000\u0000\u0000\n \nand \n \n\u0000\n\u0000\u0000\u0000\n. \n\u0000\n \nis \ndenoted as upsample function of bilinear interpolation and spatial \nenhancement along with 2 scale factors. \n \n(iii)\n \nMulti\n-\nhead Attention Mechanism\n \n \nMulti\n-\nhead attention mechanism executes several linear \ntransformations at feature matrix of input and determines the \nattention illustrations of image across diverse linear transformation; \ntherefore, we acquire huge inclusive Alzheimer’s information. This \nm\nechanism is fundamentally integration of several self\n-\nattention \nscheme, \nkey \n(\n\u0000\n)\n, query \n(\n\u0000\n)\n \nand value \n(\n\u0000\n)\n. The primary intention \nof the scheme is a Scaled Dot product Attention (SDA). The function \nof SDA is expressed as:\n \n \nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2024.3357723\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n \n \n \n(b) Down sample connection\n \n(a) Up sample connection\n \n(c) Collective Spatial Attention \n \n(d) Collective Channel Attention \nMulti Head Attention\nSoftmax Layer\nCRBM\nDense Block\nDown sample \nBlock\nConv+BN\nConv+Dilated \nConv\nReLu\nL2 Norm\nLinear\nMat Mul\n \n(i) \n(ii) \nConcatenation\nMRI Segmented \nImage\nPET Segmented \nImage\n \nFig.3 Overa\nl\nl Architecture of \nProposed Dual\n-\n3DM\n3\n-\nAD Model\n\u0000\u0000\u0000\n(\n\u0000\n,\n\u0000\n,\n\u0000\n)\n=\n\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n\u0000\n\u0000\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n            \n    \n  \n(23)\n \n \nThe concept of multi\n-\nhead attention is to utilize diverse \nparameters \n\u0000\n\u0000\n\u0000\n,\n\u0000\n\u0000\n\u0000\n,\n\u0000\n\u0000\n\u0000\n \nto execute linear transformations on \n\u0000\n,\n\u0000\n,\n\u0000\n \nmatrices, and\n \nthe\n \nresult of input linear transformations as \nSDA.\n \nThe\n \ne\nstimation result is evaluated via \nℎ\n\u0000\u0000\u0000\n\u0000\n,\n \nwhich can be \nformulated as\n:\n \nℎ\n\u0000\u0000\u0000\n\u0000\n=\n\u0000\u0000\u0000\n\u0000\n\u0000\u0000\n\u0000\n\u0000\n,\n\u0000\n\u0000\n\u0000\n\u0000\n,\n\u0000\u0000\n\u0000\n\u0000\n\u0000\n        \n    \n      \n(24)\n \n \nNext, we concatenate the evaluated results \nℎ\n\u0000\u0000\u0000\n\u0000\n \nto \nℎ\n\u0000\u0000\u0000\n\u0000\n \nto \ncreate a matrix, \nand \nmultipl\ny\n \nit via parameter \n\u0000\n \nto conclude the final \nlinear transformation\n:\n \n             \n\u0000\u0000\u0000\u0000\n=\n\u0000\u0000\u0000\u0000\u0000\n\u0000\n\u0000\u0000\u0000\n(\n\u0000\n,\n\u0000\n,\n\u0000\n \n)\n       \n          \n   \n(25)\n \n          \n=\n\u0000\u0000\u0000\u0000\u0000\u0000\n(\nℎ\n\u0000\u0000\u0000\n\u0000\n,\n…\n,\nℎ\n\u0000\u0000\u0000\n\u0000\n)\n\u0000\n                   \n(26)\n \n(iv)\n \nOutput Layer of Alzheimer's Diagnosis\n \n \nThe \naverage pooling\n \nis executed\n \non \n\u0000\u0000\u0000\u0000\n \noutput matrix in \nmulti\n-\nhead attention layer to acquire the features vectors \n\u0000\n\u0000\u0000\n\u0000\u0000\u0000\n. We \npass the input \n\u0000\n\u0000\u0000\n\u0000\u0000\u0000\n \nvia fully connected layer to final softmax \nclassifier to obtain final Alzheimer diagnosis as\n:\n \nխ\n=\n\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\u0000\n\u0000\u0000\u0000\n+\n\u0000\n\u0000\n\u0000\n        \n    \n   \n(27)\n \n \nHere, \n\u0000\n\u0000\n \nis depicted as weight matrix and \n\u0000\n\u0000\n \nis bias. We \nutilize back propagation technique to optimize our proposed model, \nand the cross entropy is expressed as\n:\n \n\u0000\u0000\u0000\u0000\n=\n∑\n∑\nխ\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n \n\u0000\u0000\n \nխ\n\u0000\n\u0000\n+\n\u0000\n‖\n\u0000\n‖\n\u0000\n            \n(28)\n \n \nWhere\n,\n \n\u0000\n \nis denoted as training data size, \n\u0000\n \nis the number of \ndata classes, \nխ\n \nis represented as predicted class, \nխ\n\u0000\n \nis the actual class \nand \n\u0000\n‖\n\u0000\n‖\n\u0000\n \nis the default term cross\n-\nentropy.\n \nIV\n \nE\nXPERIMENTAL \nR\nESULTS\n \nIn this section, w\ne demonstrate the\n \neffectiveness of the\n \nproposed \nDual\n-\n3DM\n3\n-\nAD model\n \nin terms of\n \nAlzheimer detection\n. This \nsection \nis divided into\n \nthree sub\n-\nsections\n \nincluding simulation setup, \ncomparison analysis and research summary\n:\n \nA.\n \nSimulation Setup\n \nThe e\nntire model execution and evaluation are implemented \nby \nutilizing MATLAB 2020A\n. \nMoreover, \nwe \ndistributed the\n \ndataset as \n90:10 ratio\n, and the\n \n10\n-\nfold\n-\ncross validation\n \nis adopted\n. \nTo diagnosis \nAlzheimer's using MRI and PET scans,\n \nthe\n \nDual\n-\n3DM\n3\n-\nAD \nmodel \nis utilized as\n \na\n \nclassifier. \nWe set\n \n32 mini\n-\nbatch size, 100 epochs to \nfair analysis in 0.00008 learning rate. \nTab. 1 shows the hardware \nparameters.\n \nTable I \nHardware Parameters\n \nSimulation Parameter\n \nSetup\n \nGPU\n \nNVIDIA GTX 105\n \nCPU\n \n2.40 GHz\n \nRAM\n \n16GB\n \nIntel(R) Core\n \ni5\n-\n9300H\n \n \nB.\n \nExperiments \n \nThe proposed\n \nDual\n-\n3DM\n3\n-\nAD \nmodel performance\n \nis compared\n \nwith \nthe existing approaches with respect to sensitivity, accuracy, \nconfusion matrix, specificity, and ROC curve\n. We performed the \nclassification by \nCognitive Normal (CN) vs AD, AD vs Mild \nC\nognitive \nI\nmpairment (MCI) \nand CN vs MCI. \nAccuracy affords us \nthe true resultants proportion, which can be true negative or true \npositive. \nSensitivity \nappearances\n \nthe entire \nperformance\n \nof proposed \nmodel. \nSpecificity \nshows\n \nhow effectively the model is recognizing \nCN condition. \nROC curves and \nc\nonfusion matrices are visually \ncharacteristics \nperceptions regarding predictive analysis.\n \nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2024.3357723\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nC.\n \nComparative analysis \n \nW\ne elucidated the comparison between the proposed\n \nmodel and \nexisting works\n,\n \nwhere we have \ncontemplated\n \nwith two existing \nworks such as \n-\n \nThe \nprimary\n \nintention of this \npaper\n \nis to perform \nsegmentation and Alzheimer diagnosis\n \neffectively\n. \n \ni)\n \nComparison with \nD\niverse \nM\nodalities:  \n \n \nFor\n \nthe\n \ncomparative analysis between MRI, PET fused \ninformation,\n \nthe\n \nDual\n-\n3DM\n3\n-\nAD model is utilized for each of those \nmodalities. Fig 4(a)\n-\n(c) represents the confusion matrices and ROC \ncurves of CN vs AD classification acquired from diverse modalities. \nIn fig 5, class\n-\n1 illustrates CN\n,\n \nand class\n-\n2 illustrates AD. As \ndefined, classification by\n \nthe\n \nconsideration of fused data provide\ns\n \nROC curve about to top\n-\nleft recommending the fused data \nusefulness. \n \nTable II shows the comparative analysis in terms of \nperformance metrics, and it outlines that the fusion\n-\nbased \nclassification is more accurate than PET and MRI. Both MRI and \nPET data separately obtain minimal performance, which is justified \nthrough ineffic\niency of single modality to meet metabolic and \nstructural modifications instantaneously. Whereas, the multi\n-\nmodality fused data concentrates on these brain information. In pre\n-\nprocessing, the noise removal and skull stripping are performed, \nwhich removes t\nhe noise and unwanted tissues; therefore, \ncontemplating the amount of computation cost. Moreover, the multi\n-\nhead\n-\nbased attention mechanism minimizes the complexities. \nHenceforth, the Dual\n-\n3DM\n3\n-\nAD model testing utilizes 2 minutes on \nmachine with one GPU, which articulating the algorithm’s space \ncomplexity and optimum time.\n \n90\n70\n50\n80\nAD\nCN\nTrue Class\nPredicted Class\n85\n76\n60\n84\nAD\nCN\nTrue Class\nPredicted Class\n100\n90\n80\n95\nAD\nCN\nTrue Class\nPredicted Class\n(a)\n(b)\n(c)\n \nFig.4 Confusion matrix for proposed model (a) MRI, (b) PET and \n(c) Fused Data\n \n(ii)\n \nComparison with Diverse State\n-\nof\n-\nart Approaches\n \n     \nThe proposed Dual\n-\n3DM\n3\n-\nAD model is compared with several \nstate\n-\nof\n-\nthe\n-\nart approaches to demonstrate the proposed model efficacy for AD \nclassification. EPEE [22], Novel\n-\nCNN [23], DEMNET [24], EMLM [25], \nRELS\n-\nTSVM [26] and THS\n-\nGAN are the approaches utilized for the \ncomparison purpose. The comparison of Dual\n-\n3DM\n3\n-\nAD model \nperformance metrics with state\n-\nof\n-\nthe\n-\nart approaches is unveiled in Table\n \n \nFig.5 ROC curve for proposed model (a) MRI, (b) PET and (c) Fused Data\n \n \nI\nI\nI.\n \nThe baseline approaches are defined as follows\n:\n \n[i]\n \nEPEE: \nA deep learning based \napproach using EPEE is proposed \nfor Alzheimer diagnosis using MRI images\n,\n \nwhich performs better.\n \n[ii]\n \nNovel\n-\nCNN: \nEarly diagnosis of Alzheimer’s classification is \nproposed by designing neural \nnetwork\n-\nbased\n \nnovel\n-\nCNN using T2 weighted \nMRI scans.\n \n[iii]\n \nDEMNET: D\nL\n \nmodel is proposed for diagnosing Dementia and \nAlzheimer’s classification for handling unbalancing dataset.\n \n[iv]\n \nEMLM: A\nn\n \nearly d\netection\n \nfor Alzheimer's based on hippocampal \nand cortical local filed is proposed by adapting EMLM model.\n \n[v]\n \nRELS\n-\nTSVM: A \nDK\n \nbased Alzheimer's d\netection\n \nis implemented \nby utilizing multi\n-\nmodality data for obtaining accurate result.\n \n[vi]\n \nTHS\n-\nGAN: \nAn\n \nMRI based classification model THS\n-\nGAN is \nproposed for \nthe \nidentification of multi\n-\nclass Alzheimer’s disease.\n \n \nThe proposed Dual\n-\n3DM\n3\n-\nAD model exhibits superior \nperformance with 98% of accuracy, 97.8% of sensitivity, 97.5% of \nspecificity and 98.2% of f\n-\nmeasure for CN vs AD diagnosis. Figs 6\n-\n9 represent the performance metrics analysis of the proposed vs \nexisting works (accuracy, sensiti\nvity, specificity, and F\n-\nmeasure). \nThe proposed Dual\n-\n3DM\n3\n-\nAD model displays better convergence \ncharacteristics and persuasive accuracy. It is apparent that the Dual\n-\n3DM\n3\n-\nAD’s ROC curve is nearer to top\n-\nleft corner, depicting best \nperf\normance than any other existing approaches. Hence, the multi\n-\nmodal fusion based Dual\n-\n3DM\n3\n-\nAD model proves to be a betterment \nautomatic classification method.\n \n(iii)\n \nComparison with Diverse Machine Learning Approaches:\n \nWe compare the proposed Dual\n-\n3DM\n3\n-\nAD model with \nvarious \nmachine learning approaches. BEMD [21], RF [27] and SVM [28] \nare utilized as classifiers for Alzheimer’s diagnosis. The comparison \nof Dual\n-\n3DM\n3\n-\nAD performance metrics with the existing classifiers \nin terms of accuracy, sensitivity, specificity and f\n-\nmeasure is \nillustrated in Table IV. The RF model performed better than SVM \nand NB as an Alzheimer's classification model on entire \nperformance metrics. Also, the proposed work achieves maximum \naccuracy than other models. The reason for attaining lower ac\ncuracy \nby the machine learning approaches because they suffer from \nhandling large dataset and being insufficient in terms of extracting \nappropriate features.\n \nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2024.3357723\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n \n \n \nFig.6 Analysis of Accuracy\n \n \nFig.7 Analysis of Sensitivity\n \nTable I\nI\n \nPerformance analysis of proposed model for Alzheimer diagnosis with diverse modalities\n \nModality\n \nCN vs AD\n \nCN vs MCI\n \nAD vs MCI\n \nAcc\n \nSen\n \nSpe\n \nf\n-\nm\n \nAcc\n \nSen\n \nSpe\n \nf\n-\nm\n \nAcc\n \nSen\n \nSpe\n \nf\n-\nm\n \nMRI\n \n92\n \n91\n \n90.7\n \n91\n \n91.7\n \n91.4\n \n92\n \n91.8\n \n92.3\n \n91.8\n \n91.2\n \n91.5\n \nPET\n \n90\n \n91\n \n90.3\n \n90.6\n \n91.3\n \n91.2\n \n92\n \n92\n \n91\n \n93\n \n92\n \n92.8\n \nFusion\n \n98\n \n97.5\n \n98\n \n97.2\n \n97.9\n \n98.2\n \n98\n \n98\n \n98.2\n \n97.8\n \n97\n \n98\n \nTable II\nI\n \nComparison analysis of proposed model for Alzheimer diagnosis with Baseline approaches\n \nModality\n \nCN vs AD\n \nCN vs MCI\n \nAD vs MCI\n \nAcc\n \nSen\n \nSpe\n \nf\n-\nm\n \nAcc\n \nSen\n \nSpe\n \nf\n-\nm\n \nAcc\n \nSen\n \nSpe\n \nf\n-\nm\n \nEPEE\n \n0.978\n \n0.932\n \n0.939\n \n0.954\n \n0.967\n \n0.922\n \n0.943\n \n0.963\n \n0.978\n \n0.956\n \n0.929\n \n0.964\n \nNovel\n-\nCNN\n \n0.962\n \n0.925\n \n0.925\n \n0.951\n \n0.963\n \n0.903\n \n0.958\n \n0.945\n \n0.962\n \n0.945\n \n0.924\n \n0.941\n \nDEMNET\n \n0.957\n \n0.911\n \n0.917\n \n0.974\n \n0.947\n \n0.915\n \n0.933\n \n0.970\n \n0.957\n \n0.928\n \n0.907\n \n0.934\n \nEMLM\n \n0.878\n \n0.851\n \n0.898\n \n0.88\n \n0.847\n \n0.862\n \n0.843\n \n0.883\n \n0.878\n \n0.867\n \n0.888\n \n0.868\n \nRELS\n-\nTSVM\n \n0.936\n \n0.912\n \n0.91\n \n0.966\n \n0.967\n \n0.954\n \n0.92\n \n0.969\n \n0.936\n \n0.934\n \n0.920\n \n0.946\n \nTHS\n-\nGAN\n \n0.973\n \n0.965\n \n0.955\n \n0.976\n \n0.970\n \n0.966\n \n0.938\n \n0.971\n \n0.973\n \n0.945\n \n0.965\n \n0.966\n \nDual\n-\n3DM\n3\n-\nAD\n \n0.983\n \n0.974\n \n0.978\n \n0.98\n \n0.98\n \n0.979\n \n0.987\n \n0.981\n \n0.986\n \n0.98\n \n0.978\n \n0.985\n \n \nTable I\nV\n \nComparison analysis of proposed model for Alzheimer diagnosis with ML approaches\n \nModality\n \nCN vs AD\n \nCN vs MCI\n \nAD vs MCI\n \nAcc\n \nSen\n \nSpe\n \nf\n-\nm\n \nAcc\n \nSen\n \nSpe\n \nf\n-\nm\n \nAcc\n \nSen\n \nSpe\n \nf\n-\nm\n \nBEMD\n \n82\n \n83.1\n \n80.7\n \n81.5\n \n81.7\n \n82.4\n \n82\n \n81.8\n \n82.6\n \n82.7\n \n83.2\n \n81.5\n \nRF\n \n87\n \n87.5\n \n88\n \n87.2\n \n87.9\n \n88.2\n \n86\n \n86.3\n \n87.2\n \n87.8\n \n86\n \n87.3\n \nSVM\n \n80\n \n81.5\n \n80.15\n \n80.6\n \n81.8\n \n82.5\n \n82\n \n82.4\n \n81\n \n83\n \n85\n \n82.8\n \nDual\n-\n3DM\n3\n-\nAD\n \n0.983\n \n0.974\n \n0.978\n \n0.98\n \n0.98\n \n0.979\n \n0.987\n \n0.981\n \n0.986\n \n0.98\n \n0.978\n \n0.985\n \n \n \nFig.8 Analysis of \nSpecificity\n \n \n \nFig.9 Analysis of F\n-\nmeasure\n \n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\n30\n50\n60\n70\n90\n100\nAccuracy\nNo.of Epochs\nEPEE\nNovel-CNN\nDEMNET\nEMLM\nRELS-TSVM\nTHS-GAN\nDual-3DM3-AD\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\n30\n50\n60\n70\n90\n100\nSensitivity\nNo.of Epochs\nEPEE\nNovel-CNN\nDEMNET\nEMLM\nRELS-TSVM\nTHS-GAN\nDual-3DM3-AD\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\n30\n50\n60\n70\n90\n100\nSpecificity\nNo. of Epochs\nEPEE\nNovel-CNN\nDEMNET\nEMLM\nRELS-TSVM\nTHS-GAN\nDual-3DM3-AD\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\n1\n30\n50\n60\n70\n90\n100\nF\n-\nmeasure\nNo. of Epochs\nEPEE\nNovel-CNN\nDEMNET\nEMLM\nRELS-TSVM\nTHS-GAN\nDual-3DM3-AD\nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2024.3357723\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nD.\n \nEvaluation of Proposed \nDual\n-\n3DM\n3\n-\nAD Model\n \nTo validate the Multi\n-\nlevel Capsule Network and Dual Vision \nTransformer based Attention Mechanism\n-\nDual\n-\nAtten proposed \nframework, we accomplish ablation tests. For that, we have \nutilized SWLD\n-\n20K, Cresci\n-\n2017 and Cresci\n-\n2015 datasets to \naccord and understan\nd the influence of every layer and component \nof our proposed\n \nDual\n-\n3DM\n3\n-\nAD\n \nmodel. The introduction of a \nmulti\n-\nmodal fusion\n-\nbased approach is promising and indicates an \neffort to address the complex nature of AD diagnosis. Combining \nMRI and PET scans is a so\nund approach\n.\n \nThe use of sophisticated \ntechniques\n,\n \nsuch as QNLM, Morphology function, and BDM for \nimage preprocessing is a positive aspect. These techniques can \nsignificantly enhance image quality, which is crucial for accurate \ndiagnosis. The adoption of the Mixed\n-\ntransformer with Furthered \nU\n-\nNet for sema\nntic segmentation is a good choice\n,\n \nas it helps in \nidentifying and isolating relevant regions within the images, which \nis critical for extracting meaningful features. The incorporation of \na \nmulti\n-\nscale\n \nfeat\nure extraction module DCFAM demonstrates a \ncommitment to leveraging in\nsights\n \nfrom both scans effectively. \nThe use of a \nmulti\n-\nhead\n \nattention mechanism for feature \ndimensionality reduction is a suitable choice\n,\n \nas it can help \nmanag\ning\n \nthe complexity of the data and \nconcentrate\ns \nup\non the \ndesired\n \nfeatures. The application of a softmax layer for multi\n-\nclass \nAlzheimer's diagnosis is important for classifying the disease into \ndifferent stages. This is a valuable contribution\n,\n \nas it provides \nclinicians with more de\ntailed information. \n \nTo demonstrate its effectiveness, the proposed model \nhas been\n \ncompared to existing methods and benchmarked against them to \nestablish its superiority. In conclusion, while the proposed work \nappears promising and comprehensive, its true effectiveness can \nonly be determined through rigorous testing and validation on \nre\nal\n-\nworld data, and consideration of its practicality and ethical \nimplications. In this experiment, the ADNI and \nradiopharmaceutical 18F\n-\nFDG \ndataset is\n \ndistributed into training, \nvalidation and te\nsting as \n90%, 10%\n,\n \nand 15%\n, respectively\n. This \nis \nbecause\n \nwe adapted large scale of dataset, where 10 % of data \nis adequate for estimation of test set or validation set. Besides,\n \nthe\n \nutilization of large data in training can enhance the performance \nof deep neural network to train sufficiently. \n \nWe also tend to compare the evaluation of the proposed multi \nmodal approach with the single modal approach in terms of \naccuracy, specificity, sensitivity, and F\n-\nmeasure. For a multi \nmodal approach, the results we achieved are clearly depicted in fig \n(6)\n-\n(9\n)\n.\n \nW\nhereas for the single modal scenario MRI and PET\n,\n \nthe \nresults acquired by the MRI is higher than the PET. \nAlso, Tab. V \nunveils the utilized symbols.\n  \n \nTable V Symbol Definition\n \nSymbol\n \nDefinition\n \n\u0000\n\u0000\n \nDenoised Image\n \nDep\n(\n\u0000\n)\n \nDepth gradient hypothesis\n \ne\n\u0000\n,\ne\n\u0000\n,\ne\n\u0000\n \nHorizontal Coordinates\n \n\u0000\n,\n\u0000\n,\n\u0000\n \n \nQuery, Value and Key\n \n\u0000\n \nInput feature map\n \nΛ\n \nStandardized feature\n \nɱ\n \nTraining parameters\n \n\u0000\n \nLearning rate\n \n\u0000\n\u0000\n\u0000\n \nDownsample connection\n \nճ\n \nInput vector\n \n\u0000\n\u0000\u0000\u0000\n \nFeature of MRI\n \n\u0000\n\u0000\u0000\u0000\n \nFeature of PET\n \n\u0000\n \nFeature\n \nɸ\n \nFeature Accumulation\n \n\u0000\n \nTraining image size\n \n\u0000\n \nFeature Upsampling\n \n\u0000\n \nNumber of Classes\n \nIV.\n \nD\nISCUSSION\n \nThe effectiveness of the proposed Dual\n-\n3DM3\n-\nAD model for \nAlzheimer's diagnosis was rigorously evaluated, and the results \ndemonstrated its \npotential for accurate and early detection of the \ndisease using both MRI and PET image scans. In the initial stages \nof the study,\n \nthe\n \nextensive preprocessing techniques, including \nnoise reduction, skull stripping, and 3D image conversion, were \napplied using state\n-\nof\n-\nthe\n-\nart algorithms such as the QNLM, \nMorphology function, and BDM. These steps significantly \nenhanced the quality of the i\nnput images, ensuring that the \nsubsequent analysis was performed on clean and accurate data. \nThe model architecture itself \nwas designed for optimal \nperformance. The integration of a Mixed\n-\ntransformer with \nFurthered U\n-\nNet for semantic segmentation effectively minimized \ncomplexity, allowing for the extraction of meaningful features \nfrom both MRI and PET scans. The \nmulti\n-\nscale\n \nfeature extraction \nmodule played a crucial role in capturing relevant information \nfrom the segmented images. The model further benefited from the \nDCFAM, which efficiently aggregated the extracted features, \nenabling the utilization of both modalities. The \nmul\nti\n-\nhead\n \nattention mechanism was employed for feature dimensionality \nreduction, enhancing the model's ability to distinguish key patterns \nassociated with Alzheimer's disease. Our model overcome both \nunderfitting and overfitting issues as\n:\n \nComplexity Reduction with Mixed\n-\nTransformer and Furthered \nU\n-\nNet:\n \nThe use of a Mixed\n-\ntransformer and Furthered U\n-\nNet \nsuggests an effort to create a model with increased \nrepresentational capacity. This can help capture complex patterns \nin the data. By combining different transformer architectures and \nenhancing the U\n-\nNet,\n \nthe model may be better equipped to handle \nintricate relationships within the images. \n \nDual\n-\n3DM3\n-\nAD Model:\n \nThe Dual\n-\n3DM3\n-\nAD model is described \nas having a \nmulti\n-\nscale\n \nfeature extraction module. Multi\n-\nscale \nfeatures can capture information at different levels of granularity, \nwhich may assist in handling both finer details and more global \ncontext in the images.\n \nFeature Aggregation with Densely Connected Feature \nAggregator Module (DCFAM):\n \nThe DCFAM module is \nmentioned as a feature aggregator. Aggregating features from \ndifferent scales or sources can help in capturing a comprehensive \nrepresentation of the input data. Densely connected architectures \noften encourage feature reuse, which can b\ne beneficial for learning \ninformative representations.\n \nMulti\n-\nHead Attention Mechanism for Dimensionality \nReduction:\n \nThe use of a \nm\nulti\n-\nhead attention mechanism is stated \nfor feature dimensionality reduction. Attention mechanisms allow \nthe model to focus on relevant parts of the input. In this context, \nreducing dimensionality may aid in preventing overfitting by \npromoting more efficie\nnt use of information.\n \nSoftmax Layer for Multi\n-\nClass Alzheimer’s Diagnosis: \nThe \napplication of a softmax\n \nlayer for multi\n-\nclass Alzheimer’s \ndiagnosis indicates the usage of a common activation function for \nclassification tasks. This is crucial for preventing underfitting or \noverfitting in the final classification layer.\n \nV.\n \nC\nHALLENGES \nA\nND \nL\nIMITATIONS OF \nP\nROPOSED \nW\nORK\n \nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2024.3357723\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\nThe proposed \nDual\n-\n3DM\n3\n-\nAD \nmodel for Alzheimer's \ndiagnosis presents several limitations for its practical \nimplementation in real clinical environments. Firstly, the model's \nreliance on high\n-\nquality and diverse MRI and PET datasets may \npose challenges in real\n-\nworld settings\n,\n \nwhere data availability can \nbe limited. Additionally, the computational demands of the model, \nincluding preprocessing and complex neural network \narchitectures, may strain the resources of healthcare facilities. The \nlack of model interpret\nability hinders the understanding of how \ndiagnoses are arrived at, potentially impacting trust among \nhealthcare professionals. Variations in imaging standards and \nequipment in clinical settings must be addressed for the model to \nperform consistently. \n \nVI.\n \nC\nONCLUSION AND \nF\nUTURE \nW\nORK\n \nLack of training/testing data consideration and ineffective \nsegmentation are one of the major \nreasons\n \nfor low Alzheimer \ndiagnosis accuracy\n,\n \nwhich \nis\n \nstill \na\n \ncrucial concern. To alleviate \nthese issues, we present\ned\n \na promising avenue for a more \ncomprehensive understanding of AD staging. This paper \nintroduce\nd\n \nan innovative approach to address this challenge. We \npropose\nd\n \nthe Dual\n-\n3DM\n3\n-\nAD model, designed for accurate and \nearly Alzheimer's diagnosis\n,\n \nby leveraging both MRI and PET \nimage scans. Our methodology involve\nd\n \na series of preprocessing \nsteps, including noise reduction, skull stripping, and 3D image \nconversion, performed using the QNLM, Morphology function, \nand BDM, respectively, to \nenhance the \nimage quality.\n \nSubsequently, we employ\ned\n \na Mixed\n-\ntransformer with \nFurthered U\n-\nNet architecture for semantic segmentation, \neffectively reducing complexity. The Dual\n-\n3DM\n3\n-\nAD model \nincorporate\nd\n \na \nmulti\n-\nscale\n \nfeature extraction module to extract \npertinent features from the segmented images. These extracted \nfeatures \nwere\n \nthen aggregated using the \nd\nensely connected feature \naggregator module to make the most of both information sources. \nFurthermore, we employ a \nmulti\n-\nhead\n \nattention mechanism to \nreduce feature dimensionality, fol\nlowed by the application of a \nsoftmax layer for multi\n-\nclass Alzheimer's diagnosis. Our proposed \nDual\n-\n3DM\n3\n-\nAD model \nwa\ns implemented in MATLAB 2020A and \nrigorously compared with several baseline approaches\n \nby\n \nusing a \nrange of performance metrics, including accuracy, sensitivity, \nspecificity, f\n-\nmeasure, and ROC curve analysis. Remarkably, our \nwork surpasse\nd\n \nexisting models in multi\n-\nclass Alzheimer's \ndiagnosis, underscoring its potential as a valuable tool in the early \ndetection of this debilitating disease.  \nI\nn terms of\n \nfuture \nwork\n, we \nhave planned to propose\n \nan\n \nExplainable Artificial Intelligence \n(EAI) with computation reduction technique for better \nunderstanding of classification result\n \nwith the aim of further\n \nreducing\n \ncomputational complexity and includ\ning\n \nfeedback \nsystem. \n \nR\nEFERENC\nE\nS\n \n1.\n \nWang, Z., Song, J., Wang, Y., & Liu, W. (2023). Alzheimer’s Disease Classification \nDetection Based on Brain Electrical Signal Graph Structure.\n \n2023 3rd International \nConference on Frontiers of Electronics, Information and \nComputation Technologies \n(ICFEICT)\n, 294\n-\n300.\n \n2.\n \nMcFarland, K.N., & Chakrabarty, P. (2022). Microglia in Alzheimer’s Disease: a Key \nPlayer in the Transition Between Homeostasis and Pathogenesis.\n \nNeurotherapeutics, 19\n, \n186 \n-\n \n208.\n \n3.\n \nLathe, R., & St. Clair, D. (2023). Programmed ageing: decline of stem cell renewal, \nimmunosenescence, and Alzheimer's disease.\n \nBiological Reviews, 98\n.\n \n4.\n \nGruener, P. (2022). Alzheimer’s Disease in American Fiction. In: Beyond the Great \nForgetting. J.B. Metzler, Berlin, Heidelberg. \nhttps://doi.org/10.1007/978\n-\n3\n-\n662\n-\n66029\n-\n4_5\n \n5.\n \nPlascencia\n‐Villa, G., & Perry, G. (2020). Status and future directions of clinical trials in \nAlzheimer's disease.\n \nInternational review of neurobiology, 154\n, 3\n-\n50 .\n \n6.\n \nZhang, Y., Chen, H., Li, R., Sterling, K., & Song, W. (2023). Amyloid β\n-\nbased therapy \nfor Alzheimer’s disease: challenges, successes and future.\n \nSignal Transduction and \nTargeted Therapy, 8\n.\n \n7.\n \nMather, M. (2021). Noradrenaline in the aging brain: Promoting cognitive reserve or \naccelerating Alzheimer's disease?\n \nSeminars in cell & developmental biology\n.\n \n8.\n \nAhmad, M.F., Akbar, S., Hassan, S.A., Rehman, A., & Ayesha, N. (2021). Deep Learning \nApproach to Diagnose Alzheimer’s Disease through Magnetic Resonance Images.\n \n2021 \nInternational Conference on Innovative Computing (ICIC)\n, 1\n-\n6.\n \n9.\n \nNoor, M.B., Zenia, N.Z., Kaiser, M.S., Mamun, S.A., & Mahmud, M. (2020). Application \nof deep learning in detecting neurological disorders from magnetic resonance images: a \nsurvey on the detection of Alzheimer’s disease, Parkinson’s disease and \nschizophreni\na.\n \nBrain Informatics, 7\n.\n \n10.\n \nIqbal, S., N. Qureshi, A., Li, J., & Mahmood, T. (2023). On the Analyses of Medical \nImages Using Traditional Machine \nLearning Techniques and Convolutional Neural \nNetworks.\n \nArchives of Computational Methods in Engineering, 30\n, 3173 \n-\n \n3233.\n \n11.\n \nGuedj, E., Varrone, A., Boellaard, R., Albert, N.L., Barthel, H., van Berckel, B.N., \nBrendel, M., Cecchin, D., Ekmekcioglu, O., Garibotto, V., Lammertsma, A.A., Law, I., \nPeñuelas, I., Semah, F., Traub\n-\nWeidinger, T., van de Giessen, E., Van Weehaeghe, D., &\n \nMorbelli, S. (2021). EANM procedure guidelines for brain PET imaging using [18F]FDG, \nversion 3.\n \nEuropean Journal of Nuclear Medicine and Molecular Imaging, 49\n, 632 \n-\n \n651.\n \n12.\n \nPrice, B.R., Johnson, L.A., & Norris, C.M. (2021). Reactive astrocytes: The nexus of \npathological and clinical hallmarks of Alzheimer’s disease.\n \nAgeing research reviews, 68\n, \n101335 \n-\n \n101335.\n \n13.\n \nHong, J., Kang, S.K., Alberts, I.L., Lu, J., Sznitman, R., Lee, J.S., Rominger, A., Choi, \nH., & Shi, K. (2021). Image\n-\nlevel trajectory inference of tau pathology using variational \nautoencoder for Flortaucipir PET.\n \nEuropean Journal of Nuclear Medicine and Molecular \nImaging, 49\n, 3061 \n-\n \n3072.\n \n14.\n \nSolnik, M., Paduszyńska, N., Czarnecka, A.M., Synoradzki, K.J., Yousef, Y.A., \nChoragiewicz, T., Rejdak, R., Toro, M.D., Zweifel, S.A., Dyndor, K., & Fiedorowicz, M. \n(2022). Imaging of Uveal Melanoma\n—\nCurrent Standard and Methods in \nDevelopment.\n \nCancers, 14\n.\n \n15.\n \nPle\nș, H., Florian, I., Timiș, T.L., Covache\n-\nBusuioc, R., Glavan, L., Dumitrascu, D., Popa, \nA.A., Bordeianu, A., & Ciurea, A.V. (2023). Migraine: Advances in the Pathogenesis and \nTreatment.\n \nNeurology International\n.\n \n16.\n \nGupta, V., Chitranshi, N., Haan, J.D., Mirzaei, M., You, Y., Lim, J.K., Basavarajappa, D., \nGodinez, A., Angelantonio, S.D., Sachdev, P.S., Salekdeh, G.H., Bouwman, F.H., \nGraham, S.L., & Gupta, V. (2020). Retinal changes in Alzheimer's disease\n—\n \nintegrated \np\nrospects of imaging, functional and molecular advances.\n \nProgress in Retinal and Eye \nResearch, 82\n.\n \n17.\n \nHashimoto, S., Matsuba, Y., Takahashi, M., Kamano, N., Watamura, N., Sasaguri, H., \nTakado, Y., Yoshihara, Y., Saito, T., & Saido, T.C. (2023). Neuronal glutathione loss \nleads to neurodegeneration involving gasdermin activation.\n \nScientific Reports, 13\n.\n \n18.\n \nMatchett, B.J., Grinberg, L.T., Theofilas, P., & Murray, M.E. (2021). The mechanistic \nlink between selective vulnerability of the locus coeruleus and neurodegeneration in \nAlzheimer’s disease.\n \nActa Neuropathologica, 141\n, 631 \n-\n \n650.\n \n19.\n \nBlinkouskaya, Y., & Weickenmeier, J. (2021). Brain Shape Changes Associated With \nCerebral Atrophy in Healthy Aging and Alzheimer’s Disease.\n \nFrontiers in Mechanical \nEngineering, 7\n.\n \n20.\n \nSathiyamoorthi, V., Ilavarasi, A.K., Murugeswari, K., Ahmed, S.T., Devi, B.A., & \nKalipindi, M. (2020). A deep convolutional neural network based computer aided \ndiagnosis system for the prediction of Alzheimer's disease in MRI images.\n \nMeasurement\n, \n108838.\n \n21.\n \nWei, J.K., Vicnesh, J., Pham, T., Oh, S.L., Ciaccio, E.J., Acharya, U.R., Yeong, C.H., \nFabell, M.K., Rahmat, K., Vijayananthan, A., & Ramli, N. (2020). Automated detection \nof Alzheimer's disease using bi\n-\ndirectional empirical model decomposition. Pattern \nR\necognit. Lett., 135, 106\n-\n113.\n \n22.\n \nZaina, H.S., Brahim Belhaouari, S., Stanko, T., & Gorovoy, V. (2022). An Exemplar \nPyramid Feature Extraction Based Alzheimer Disease Classification Method. IEEE \nAccess, 10, 66511\n-\n66521.\n \n23.\n \nBasheera, S., & Ram, M.S. (2020). A novel CNN based Alzheimer's disease classification \nusing hybrid enhanced ICA segmented gray matter of MRI. Computerized medical \nimaging and graphics : the official journal of the Computerized Medical Imaging Society, \n81,\n \n101713 .\n \n24.\n \nMurugan, S., Venkatesan, C., Sumithra, M.G., Gao, X., Elakkiya, B., Akila, M., & \nSUBRAMANIAN, D. (2021). DEMNET: A Deep Learning Model for Early Diagnosis \nof Alzheimer Diseases and Dementia From MR Images. IEEE Access, 9, 90319\n-\n90329\n \n25.\n \nFabietti, M.I., Mahmud, M., Lotfi, A., Leparulo, A., Fontana, R., Vassanelli, S., & \nFasolato, C. (2023). Early Detection of Alzheimer’s Disease From Cortical and \nHippocampal Local Field Potentials Using an Ensembled Machine Learning \nModel.\n \nIEEE Transactions on Neural Systems and Rehabilitation Engineering, 31\n, 2839\n-\n2848.\n \n26.\n \nDwivedi, S., Goel, T., Tanveer, M., Murugan, R., & Sharma, R. (2022). Multimodal \nFusion\n-\nBased Deep Learning Network for Effective Diagnosis of Alzheimer’s \nDisease.\n \nIEEE MultiMedia, 29\n, 45\n-\n55.\n \n27.\n \nYu, W., Lei, B., Ng, M.K., Cheung, A.C., Shen, Y., & Wang, S. (2020). Tensorizing GAN \nWith High\n-\nOrder Pooling for Alzheimer’s Disease Assessment.\n \nIEEE Transactions on \nNeural Networks and Learning Systems, 33\n, 4945\n-\n4959.\n \n28.\n \nSong, M., Jung, H.Y., Lee, S., Kim, D., & Ahn, M. (2021). Diagnostic Classification and \nBiomarker Identification of Alzheimer’s Disease with Random Forest Algorithm †.\n \nBrain \nSciences, 11\n.\n \nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2024.3357723\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n29.\n \nBron, E.E., Klein, S., Papma, J.M., Jiskoot, L.C., Venkatraghavan, V., Linders, J., Aalten, \nP., Deyn, P.P., Biessels, G.J., Claassen, J.A., Middelkoop, H.A., Smits, M., Niessen, W.J., \nSwieten, J.V., Flier, W.M., Ramakers, I.H., & Lugt, A.V. (2020). Cross\n-\nc\nohort \ngeneralizability of deep and conventional machine learning for MRI\n-\nbased diagnosis and \nprediction of Alzheimer’s disease.\n \nNeuroImage : Clinical, 31\n.\n \n30.\n \nEtminani, K., Soliman, A., Davidsson, A., Chang, J.R., Martínez\n-\nSanchís, B., Byttner, S., \nCamacho, V., Bauckneht, M., Stegeran, R., Ressner, M., Agudelo\n-\nCifuentes, M., \nChincarini, A., Brendel, M., Rominger, A., Bruffaerts, R., Vandenberghe, R., Kramberger,\n \nM.G., Trost, M., Nicastro, N., Frisoni, G.B., Lemstra, A.W., Berckel, B.N., Pilotto, A., \nPadovani, A., Morbelli, S., Aarsland, D., Nobili, F., Garibotto, V., & Ochoa\n-\nFigueroa, M. \n(2021). A 3D deep learning model to predict the diagnosis of dementia with L\newy bodies, \nAlzheimer’s disease, and mild cognitive impairment using brain 18F\n-\nFDG \nPET.\n \nEuropean Journal of Nuclear Medicine and Molecular Imaging, 49\n, 563 \n-\n \n584.\n \n31.\n \nMartinez, C.S., Cuadra, M.B., & Jorge, J. (2022). BigBrain\n-\nMR: a new digital phantom \nwith anatomically\n-\nrealistic magnetic resonance properties at 100\n-\nµm resolution for \nmagnetic resonance methods development.\n \nNeuroImage, 273\n.\n \n32.\n \nKalantar\n-\nHormozi, H., Patel, R., Dai, A., Ziolkowski, J., Dong, H., Holmes, A.J., \nRaznahan, A., Devenyi, G.A., & Chakravarty, M.M. (2023). A cross\n-\nsectional and \nlongitudinal study of human brain development: The integration of cortical thickness, \nsurface a\nrea, gyrification index, and cortical curvature into a unified analytical \nframework.\n \nNeuroImage, 268\n.\n \n33.\n \nIrimia, A. (2020). Cross\n-\nSectional Volumes and Trajectories of the Human Brain, Gray \nMatter, White Matter and Cerebrospinal Fluid in 9473 Typically Aging \nAdults.\n \nNeuroinformatics, 19\n, 347\n-\n366.\n \n34.\n \nGharaibeh, N.Y., Abu\n-\nEin, A.A., Al\n-\nhazaimeh, O.M., Nahar, K.M., Abu\n-\nAin, W.A., & \nAl\n-\nNawashi, M.M. (2023). Swin Transformer\n-\nBased Segmentation and Multi\n-\nScale \nFeature Pyramid Fusion Module for Alzheimer's Disease with Machine Learning.\n \nInt. J. \nOnline Biomed. Eng., 19\n, 22\n-\n50.\n \n35.\n \nLiu, M., Li, F., Yan, H., Wang, K., Ma, Y., Shen, L., & Xu, M. (2019). A multi\n-\nmodel \ndeep convolutional neural network for automatic hippocampus segmentation and \nclassification in Alzheimer’s disease.\n \nNeuroImage, 208\n.\n \n36.\n \nSaratxaga, C.L., Moya, I., Picón, A., Acosta, M., Moreno\n-\nFernandez\n-\nde\n-\nLeceta, A., \nGarrote, E., & Bereciartua\n-\nPerez, A. (2021). MRI Deep Learning\n-\nBased Solution for \nAlzheimer’s Disease Prediction.\n \nJournal of Personalized Medicine, 11\n.\n \n37.\n \nHazarika, R.A., Maji, A.K., Sur, S.N., Paul, B.S., & Kandar, D. (2021). A Survey on \nClassification Algorithms of Brain Images in Alzheimer’s Disease Based on Feature \nExtraction Techniques.\n \nIEEE Access, 9\n, 58503\n-\n58536.\n \n38.\n \nWang, T., & Cao, L. (2021). Deep \nLearning Based Diagnosis of Alzheimer's Disease \nUsing Structural Magnetic Resonance Imaging: A Survey.\n \n2021 3rd International \nConference on Applied Machine Learning (ICAML)\n, 408\n-\n412.\n \n39.\n \nNeelaveni, J., & Devasana, M.S. (2020). Alzheimer Disease Prediction using Machine \nLearning Algorithms.\n \n2020 6th International Conference on Advanced Computing and \nCommunication Systems (ICACCS)\n, 101\n-\n104.\n \n40.\n \nPuente\n-\nCastro, A., Fernández\n-\nBlanco, E., Pazos, A., & Munteanu, C.R. (2020). \nAutomatic assessment of Alzheimer's disease diagnosis based on deep learning \ntechniques.\n \nComputers in biology and medicine, 120\n, 103764 .\n \n \n \nThis article has been accepted for publication in IEEE Transactions on Neural Systems and Rehabilitation Engineering. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/TNSRE.2024.3357723\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7136732935905457
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6501770615577698
    },
    {
      "name": "Softmax function",
      "score": 0.6485180854797363
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.6349881887435913
    },
    {
      "name": "Segmentation",
      "score": 0.5341576337814331
    },
    {
      "name": "Convolutional neural network",
      "score": 0.26355570554733276
    }
  ]
}