{
  "title": "SpellGCN: Incorporating Phonological and Visual Similarities into Language Models for Chinese Spelling Check",
  "url": "https://openalex.org/W3021607364",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2380493979",
      "name": "Cheng, Xingyi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A219224480",
      "name": "Xu Weidi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2514163317",
      "name": "Chen Kunlong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2055818573",
      "name": "Jiang Shao-hua",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1911990279",
      "name": "Wang Feng",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2387219596",
      "name": "Wang, Taifeng",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2157888020",
      "name": "Chu Wei",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2086730232",
      "name": "Qi Yuan",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2970763364",
    "https://openalex.org/W808955830",
    "https://openalex.org/W2963440544",
    "https://openalex.org/W2785643982",
    "https://openalex.org/W2251873470",
    "https://openalex.org/W2187089797",
    "https://openalex.org/W1495461096",
    "https://openalex.org/W2964308564",
    "https://openalex.org/W2962901607",
    "https://openalex.org/W2983735660",
    "https://openalex.org/W2971167892",
    "https://openalex.org/W2251349600",
    "https://openalex.org/W2904265202",
    "https://openalex.org/W2798416860",
    "https://openalex.org/W2908510526",
    "https://openalex.org/W2971959267",
    "https://openalex.org/W2250444785",
    "https://openalex.org/W2964036946",
    "https://openalex.org/W2952500220",
    "https://openalex.org/W2932399282",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2251568283"
  ],
  "abstract": "Chinese Spelling Check (CSC) is a task to detect and correct spelling errors in Chinese natural language. Existing methods have made attempts to incorporate the similarity knowledge between Chinese characters. However, they take the similarity knowledge as either an external input resource or just heuristic rules. This paper proposes to incorporate phonological and visual similarity knowledge into language models for CSC via a specialized graph convolutional network (SpellGCN). The model builds a graph over the characters, and SpellGCN is learned to map this graph into a set of inter-dependent character classifiers. These classifiers are applied to the representations extracted by another network, such as BERT, enabling the whole network to be end-to-end trainable. Experiments (The dataset and all code for this paper are available at https://github.com/ACL2020SpellGCN/SpellGCN) are conducted on three human-annotated datasets. Our method achieves superior performance against previous models by a large margin.",
  "full_text": "SpellGCN: Incorporating Phonological and Visual Similarities into\nLanguage Models for Chinese Spelling Check\nXingyi Chengâˆ— Weidi Xuâˆ— Kunlong Chen\nShaohua Jiang Feng Wang Taifeng Wang Wei Chu Yuan Qi\nAnt Financial Services Group\n{fanyin.cxy,weidi.xwd,kunlong.ckl,shaohua.jsh,zifan.wf,\ntaifeng.wang,weichu.cw,yuan.qi}@alibaba-inc.com\nAbstract\nChinese Spelling Check (CSC) is a task to de-\ntect and correct spelling errors in Chinese nat-\nural language. Existing methods have made\nattempts to incorporate the similarity knowl-\nedge between Chinese characters. However,\nthey take the similarity knowledge as either\nan external input resource or just heuristic\nrules. This paper proposes to incorporate\nphonological and visual similarity knowledge\ninto language models for CSC via a special-\nized graph convolutional network (SpellGCN).\nThe model builds a graph over the characters,\nand SpellGCN is learned to map this graph\ninto a set of inter-dependent character clas-\nsiï¬ers. These classiï¬ers are applied to the\nrepresentations extracted by another network,\nsuch as BERT, enabling the whole network to\nbe end-to-end trainable. Experiments 1 are\nconducted on three human-annotated datasets.\nOur method achieves superior performance\nagainst previous models by a large margin.\n1 Introduction\nSpelling errors are common in our daily life, caused\ntypically by human writing, automatic speech\nrecognition, and optical character recognition sys-\ntems. Among these errors, misspelling a character\nfrequently occurs due to the similarity between\ncharacters. In Chinese, many characters are phono-\nlogically and visually similar, but semantically very\ndifferent. According to Liu et al. (2010), about\n83% of errors are related to phonological similarity\nand 48% are related to visual similarity. The Chi-\nnese Spelling Check (CSC) task aims to detect and\ncorrect such misuse of the Chinese language. De-\nspite recent development, CSC remains a challeng-\ning task. Notably, the spelling checking on Chinese\nis very different from English, due to its language\nâˆ—Equal contribution.\n1The dataset and all code for this paper is available at\nhttps://github.com/ACL2020SpellGCN/SpellGCN\nInput é¤å…çš„æ¢ç»è´¹äº§é€‚åˆçº¦ä¼š\n(phonics) cÂ¯an tÂ¯ing dÂ¯e hu`an jÂ¯ing f`ei chÂ´an sh`Ä± hÂ´e yuÂ¯e hu`Ä±\nBERT é¤å…çš„æœˆæ¶ˆè´¹æœ€é€‚åˆçº¦ä¼š\n(phonics) cÂ¯an tÂ¯ing dÂ¯e yu`e xiÂ¯ao f`ei zu`Ä± sh`Ä± hÂ´e yuÂ¯e hu`Ä±\n+SpellGCN é¤å…çš„ç¯å¢ƒéå¸¸é€‚åˆçº¦ä¼š\n(phonics) cÂ¯an tÂ¯ing dÂ¯e huÂ´an j`Ä±ng fÂ¯ei chÂ´ang sh`Ä± hÂ´e yuÂ¯e hu`Ä±\nTable 1: A CSC data sample from SIGHAN 2014 (Yu\net al., 2014) with ID B1-3440-2, the incorrect/correct\ncharacters are in orange/blue. A BERT model modiï¬es\nthe text into a sentence that is semantically reasonable\nbut dissimilar in pronunciation. By incorporating both\nphonological and visual similarities, our new method\nSpellGCN can generate a sentence that is both seman-\ntically sensible and phonically similar to the original\nsentence. The sentence output from SpellGCN means\nâ€œthis restaurant is very suitable for datingâ€.\nnature. Chinese is a language consisting of many\npictographic characters without word delimiters.\nAnd the meaning of each character changes dramat-\nically when the context changes. Therefore, a CSC\nsystem needs to recognize the semantics and ag-\ngregate the surrounding information for necessary\nmodiï¬cations.\nPrevious methods followed the line of generative\nmodels. They used either language models (Liu\net al., 2013, 2010; Yu and Li, 2014) or sequence-\nto-sequence models (Wang et al., 2019). To fuse\nthe external knowledge of the similarity between\ncharacters, some of them leveraged a confusion set,\nwhich contains a set of similar character pairs. For\ninstance, Yu and Li (2014) proposed to produce\nseveral candidates by retrieving the confusion set\nand then ï¬lter them via language models. Wang\net al. (2019) used a pointer network to copy a simi-\nlar character from the confusion set. These meth-\nods attempted to utilize the similarity information\nto conï¬ne the candidates, rather than modeling the\nrelationship between characters explicitly.\nIn this paper, we propose a novel spelling check\narXiv:2004.14166v2  [cs.CL]  13 May 2020\nconvolutional graph network (SpellGCN) that cap-\ntures the pronunciation/shape similarity and ex-\nplore the prior dependencies between characters.\nSpeciï¬cally, two similarity graphs are constructed\nfor the pronunciation and shape relationship cor-\nrespondingly. SpellGCN takes the graphs as input\nand generates for each character a vector represen-\ntation after the interaction between similar charac-\nters. These representations are then constructed\ninto a character classiï¬er for the semantic repre-\nsentation extracted from another backbone module.\nWe use BERT (Devlin et al., 2019) due to its pow-\nerful semantic capacity. Combining the graph rep-\nresentations with BERT, SpellGCN can leverage\nthe similarity knowledge and generate the right cor-\nrections accordingly. Regarding the example as in\nTable 1, SpellGCN is able to modify the sentence\ncorrectly within the pronunciation constraint.\nExperiments were conducted on three open\nbenchmarks. The results demonstrate that Spell-\nGCN improves BERT evidently, outperforming all\ncompetitor models by a large margin.\nIn summary, our contributions are as follows:\nâ€¢We propose a novel end-to-end trainable Spell-\nGCN to integrate the pronunciation and shape\nsimilarities into the semantic space. Its essen-\ntial components such as the specialized graph\nconvolution and attentive combination opera-\ntions are carefully investigated.\nâ€¢We investigate the performance of SpellGCN\nboth quantitatively and qualitatively. Ex-\nperimental results indicate that our method\nachieves the best results on three benchmark\ndatasets.\n2 Related Work\nThe CSC task is a long-standing problem and has\nattracted much attention from the community. The\nresearch emerges in recent years (Jia et al., 2013;\nXin et al., 2014; Yu and Li, 2014; Tseng et al.,\n2015; Fung et al., 2017; Wang et al., 2019; Hong\net al., 2019), together with other topics, e.g., gram-\nmar error correction (GEC) (Rao et al., 2018; Ji\net al., 2017; Chollampatt et al., 2016; Ge et al.,\n2018). CSC focuses on detecting and correcting\ncharacter errors, while GEC also includes errors\nthat need deletion and insertion. Previous work\nhandles CSC using unsupervised language mod-\nels (Liu et al., 2013; Yu and Li, 2014). The errors\nare detected/corrected by evaluating the perplexity\nof sentences/phrases. However, these models were\nunable to condition the correction on the input sen-\ntence. To circumvent this problem, several discrim-\ninative sequence tagging methods were adopted for\nCSC (Wang et al., 2018). For more ï¬‚exibility and\nbetter performance, several sequence-to-sequence\nmodels were also employed (Wang et al., 2019;\nJi et al., 2017; Chollampatt et al., 2016; Ge et al.,\n2018), as well as BERT (Hong et al., 2019).\nRecent attention was paid to utilizing the exter-\nnal knowledge of character similarity. The simi-\nlarity knowledge can be gathered into a dictionary,\ni.e., confusion set, where similar pairs are stored.\nYu and Li (2014) ï¬rst used the dictionary to retrieve\nsimilar candidates for potential errors. Wang et al.\n(2019) incorporated a copy mechanism into a recur-\nrent neural model. When given similar characters\nas input, their model uses the copy mechanism to\ndirectly copy the character to the target sentence.\nIn a sense, these models face difï¬culty in model-\ning the relationship between similar characters as\nthe similarity information is solely used for candi-\ndate selection. To capture the pronunciation/shape\nsimilarity and explore the prior dependencies be-\ntween characters, we propose to use graph convo-\nlution network (GCN) (Kipf and Welling, 2017) to\nmodel character inter-dependence, which is com-\nbined with the pre-training of BERT (Devlin et al.,\n2019; Cheng et al., 2019) for the CSC task.\nGCN has been applied to model the relationship\non several tasks. Yan et al. (2019) equipped it into\nthe relation extraction task where relations con-\nstruct a hierarchical tree. Li et al. (2018); Cheng\net al. (2018) use it to model spatial-temporal to\npredict trafï¬c ï¬‚ow. GCN was also used to model\nthe relationship between labels in a multi-label\ntask (Chen et al., 2019). In this paper, it is the\nï¬rst time that GCN is applied successfully into the\nCSC task. The relationship in CSC is much differ-\nent from those tasks where objects in the graph are\nsemantically related. By contrast, the similar char-\nacters are semantically distinct in CSC. Therefore,\nwe deeply investigate the effect of our SpellGCN\nand propose several essential techniques.\n3 Approach\nIn this section, we elaborate on our method for\nCSC. Firstly, the problem formulation is presented.\nThen, we introduce the motivations for SpellGCN,\nfollowed by its detailed description. At last, we\npresent its application in the CSC task.\n3.1 Problem Formulation\nThe Chinese Spelling Check task aims to detect\nand correct the errors in the Chinese language.\nWhen given a text sequence X = {x1,x2,...,x n}\nconsisting of n characters, the model takes X\nas input and output a target character sequence\nY = {y1,y2,...,y n}. We formulate the task as a\nconditional generation problem by modeling and\nmaximizing the conditional probability p(Y|X).\n3.2 Motivations\nThe framework of the proposed method is depicted\nin Figure 1. It consists of two components, i.e., a\ncharacter representation extractor and a SpellGCN.\nThe extractor derives a representation vector for\neach character. Above the extractor, SpellGCN is\nused to model the inter-dependence between char-\nacters. It outputs target vectors containing the in-\nformation of similar characters after interactions.\nAs illustrated in Table 1, a vanilla language\nmodel is able to provide feasible corrections in\nsemantic meaning but faces the difï¬culty in meet-\ning the pronunciation constraint. Although the cor-\nrection â€œæœˆæ¶ˆè´¹æœ€â€ is semantically plausible, its\nphonics differs much from â€œ æ¢ç»è´¹äº§â€ and â€œç¯\nå¢ƒéå¸¸â€. This indicates that the similarity infor-\nmation between characters is necessary so that the\nmodel can learn to generate related answers. Previ-\nous methods have taken the similarity into consid-\neration. However, they typically regarded similar\ncharacters as potential candidates, neglecting their\ninter-relationship in terms of pronunciation and\nshape. This work makes a preliminary attempt to\nhandle this issue, trying to fuse both the symbolic\nspace (phonological and visual similarity knowl-\nedge) and the semantic space (language semantic\nknowledge) into one model. To achieve this, we\nleverage the power of graph neural network (GNN)\nto infuse the similarity knowledge directly. The\nessential idea is to update the representations by ag-\ngregating the information between similar charac-\nters. Intuitively, a model is likely to have a sense of\nsimilar symbols when equipped with our method.\nAmong various GNN models, we use GCN in\nour implementation. Since there are up to 5K Chi-\nnese characters in the graph, the light-weight GCN\nis more suitable for our problem. The proposed\nSpellGCN is depicted as follows in detail.\n3.3 Structure of SpellGCN\nSpellGCN requires two similarity graphs Ap,As\nfor pronunciation and shape similarities corre-\nspondingly, which are derived from an open-\nsourced confusion set (Wu et al., 2013). For sim-\nplicity, the superscript will be omitted if unnec-\nessary and A denotes one of these two similarity\ngraphs. Each similarity graph is a binary adjacent\nmatrix of size RNÃ—N , constructed from N charac-\nters in the confusion set. The edge Ai,j âˆˆ{0,1}\nbetween i-th character and j-th character denotes\nwhether the (i,j) pair exists in the confusion set.\nThe goal of SpellGCN is to learn a map function\nto map the input node embedding Hl âˆˆRNÃ—D\nof l-th layer (where D is the dimensionality of\ncharacter embedding) to a new representationHl+1\nvia convolutional operation deï¬ned by A. This\nmap function has two main sub-components: a\ngraph convolution operation and an attentive graph\ncombination operation.\nGraph Convolution Operation The graph con-\nvolution operation is to absorb the information\nfrom neighboring characters in the graph. In\neach layer, the light-weight convolution layer in\nGCN (Kipf and Welling, 2017) is adopted:\nf(A,Hl) = Ë†AHlWl\ng , (1)\nwhere Wl\ng âˆˆ RDÃ—D is a trainable matrix and\nË†A âˆˆRNÃ—N is the normalized version of the ad-\njacent matrix A. For the deï¬nition of Ë†A, we di-\nrect you to the original paper (Kipf and Welling,\n2017). Note that we use the character embedding of\nBERT as the initial node features H0, and we omit\nthe non-linearity function after convolution. Since\nwe adopted BERT as our extractor, which has its\nown learned semantic space, we remove the activa-\ntion function from the equation to keep the derived\nrepresentation identical with original space, rather\nthan a completely different space. During our ex-\nperiments, using non-linearity activation such as\nReLU is ineffective, resulting in a performance\ndrop.\nAttentive Graph Combination Operation The\ngraph convolution operation handles the similarity\nof a single graph. To combine the pronunciation\nand shape similarity graphs, the attention mecha-\nnism (Bahdanau et al., 2015) is adopted. For each\ncharacter, we represent the combination operation\nSpellGCN\nBERT Extractor\nâ€¦ \t\t\tğ¯ğ’Š$ğŸ \t\t\tğ¯ğ’Š$ğŸ â€¦\t\t\tğ¯ğ’Š\t\tğ¯ğ’Š$ğŸ‘\nâ€¦ åˆ° é€† â€¦ç«Ÿé‡\nğ„: Word Embedding\n\t\nLayer-1\nLayer-2\nPronunciation SimilarityGraph ShapeSimilarity Graph\nAttentiveCombination\nâ€¦ å¢ƒ é‡‘ äº•é•œäº° é™ å¯„ ç«Ÿ â€¦\nğ–: Generated Classifier\nâ€¦\nLayer-3\nâ€¦ åˆ° é€† â€¦å¢ƒé‡\nâ€¦ â€¦ â€¦\nâ€¦\nå¯„äº•\né™ å¢ƒ\né‡‘\nâ€¦\nâ€¦ â€¦\nç«Ÿ\nâ€¦ â€¦ â€¦\nâ€¦\næ™¯ç«\né•œ å¢ƒ\näº°\nâ€¦\nâ€¦ â€¦\nç«Ÿ\nDot Product\nOutoftheConfusionSet\nFigure 1: The framework of the proposed SpellGCN. Left: The characters in the input sentence are processed by\nthe extractor to obtain the semantic representation vectors.Right: The phonological or visual similarity knowledge\nof characters is learned by our SpellGCN. Two similarity graphs are used to model the pronunciation and shape\nsimilarities respectively, and they are combined via an attentive combination operation. Middle: The character\nembedding vectors derived from SpellGCN are used as the target character classiï¬ers .\nas follows:\nCl\ni =\nâˆ‘\nkâˆˆ{s,p}\nÎ±l\ni,kfk(Ak,Hl)i , (2)\nwhere Cl âˆˆRNÃ—D and fk(Ak,Hl)i is the i-th\nrow of convolved representation of graph k, Î±i,k is\na scalar for i-th character denoting the weight of\ngraph k. The weight Î±i,k is computed by\nÎ±i,k = exp(wafk(Ak,Hl)i/Î²)âˆ‘\nkâ€²exp(wafkâ€²(Akâ€²\n,Hl)i/Î²), (3)\nwhere wa âˆˆRD is a learnable vector shared across\nthe layers and Î² is a hyper-parameter which con-\ntrols the smoothness of attention weights. We\nfound Î²essential for the attention mechanism.\nAccumulated Output After graph convolution\nand attentive combination operations, we obtain a\nrepresentation Cl for l-th layer. To maintain the\noriginal semantic of the extractor, all outputs of\nprevious layers are accumulated as the output:\nHl+1 = Cl +\nlâˆ‘\ni=0\nHi . (4)\nIn this way, SpellGCN is able to focus on capturing\nthe knowledge of character similarity, leaving the\nresponsibility of semantic reasoning to the extrac-\ntor. Hopefully, each layer can learn to aggregate\nthe information for the speciï¬c hop. During the\nexperiments, the model failed when excluding H0.\n3.4 SpellGCN for Chinese Spelling Check\nHere, we introduce how to apply SpellGCN to the\nCSC task. Motivated by recent applications of\nGCN in relationship modeling (Chen et al., 2019;\nYan et al., 2019), we use the ï¬nal output of Spell-\nGCN to be classiï¬ers of the target characters.\nSimilarity Graphs from Confusion Set The\nsimilarity graphs used in SpellGCN are constructed\nfrom the confusion set provided in (Wu et al.,\n2013). It is a pre-deï¬ned set consisting of similar\ncharacters for most of (âˆ¼95%) the Chinese charac-\nters and these characters are categorized into ï¬ve\ncategories, i.e., (1) similar shape, (2) same pro-\nnunciation and same tone, (3) same pronunciation\nand different tone, (4) similar pronunciation and\nsame tone, (5) similar pronunciation and different\ntone. Since the pronunciation similarity is more\nï¬ne-grained compared with the shape similarity cat-\negory, we combine the pronunciation similarities\ninto one graph. Consequently, we construct two\ngraphs corresponding to pronunciation and shape\nsimilarities.\nCharacter Representation by Extractor The\nrepresentation of characters used for ï¬nal classi-\nï¬cation is given by an extractor. We can use any\nmodel that is able to output representation vectors\nV = {v1,v2,..., vn}(where vi âˆˆRD) for nchar-\nacters X = {x1,x2,...,x n}. In our experiment,\nwe adopt BERT as the backbone model. It takes X\nas input and uses the output of the last layer as V.\nWe conduct the experiment using the base version,\nwhich has 12 layers, 12 self-attention heads with a\nhidden size of 768 2.\n2This means D=768 in our experiment.\nSpellGCN as Character Classiï¬er When given\nthe representation vector vi of a character xi, the\nmodel needs to predict a target character through a\nfully-connected layer whose weight W âˆˆRMÃ—D\nis conï¬gured by the output of SpellGCN (M is the\nsize of the extractor vocabulary):\np(Ë†yi|X) =softmax(Wvi) . (5)\nConcretely, the output vectors of SpellGCN plays\nthe role of the classiï¬er in our task. We use the\noutput of the last layer of SpellGCN HL (where L\nis the number of layers) to classify the characters\nin the confusion set. And since the confusion set\nonly covers a subset of vocabulary, we use the\nword embedding of the extractor as the classiï¬er\nfor those excluded by the confusion set. In this way,\ndenoting ui âˆˆ{1,...,N }is the index of confusion\nset for the i-th character in the extractor vocabulary,\nW is presented by:\nWi =\n{\nHL\nui , if i-th character âˆˆconfusion set\nEi, otherwise ,\n(6)\nwhere E âˆˆRMÃ—D is the embedding matrix of ex-\ntractor. In brief, we use the embedding from Spell-\nGCN if the character is in the confusion set. Other-\nwise, the embedding vectors are used as in BERT.\nInstead of modeling a large compact graph con-\ntaining all characters in the extractor vocabulary,\nwe chose this implementation for computational\nefï¬ciency, since there are around 5K characters in\nthe confusion set and more than 20K characters in\nthe extractor vocabulary.\nOverall, the objective is to maximize the log\nlikelihood of target characters:\nL=\nâˆ‘\nX,Y\nâˆ‘\ni\nlog p(Ë†yi = yi|X) . (7)\n3.5 Prediction Inference\nThe CSC task consists of two sub-tasks in evalua-\ntion, i.e., detection and correction. Some previous\nwork (Yu and Li, 2014; Liu et al., 2013) used two\nmodels for these sub-tasks separately. In this work,\nwe simply use the character with the highest proba-\nbility arg maxË†yi p(Ë†yi|X) as the prediction for the\ncorrection task. And the detection is achieved by\nchecking whether the prediction matches the target\ncharacter yi.\n4 Experiments\nIn this section, we describe our experiment in de-\ntail. We ï¬rst present the training data and test data,\nTraining Data # Line Avg. Length # Errors\n(Wang et al., 2018) 271,329 44.4 382,704\nSIGHAN 2013 350 49.2 350\nSIGHAN 2014 6,526 49.7 10,087\nSIGHAN 2015 3,174 30.0 4,237\nTotal 281,379 44.4 397,378\nTest Data # Line Avg. Length # Errors\nSIGHAN 2013 1000(1000) 74.1 1,227\nSIGHAN 2014 1062(526) 50.1 782\nSIGHAN 2015 1100(550) 30.5 715\nGraph # Character # Edges\nPronunciation Similarity Graph 4753 112,687\nShape Similarity Graph 4738 115,561\nTable 2: Statistics information of the used data re-\nsources. The number in the bracket in #Line column\ndenotes the number of sentences with errors.\nas well as the evaluation metrics. Then we intro-\nduce our main results for SpellGCN. After that, the\nablation studies are made to analyze the effect of\nthe proposed components, followed by a case study.\nFinally, quantitative results are provided.\n4.1 Datasets\nTraining Data The training data is composed of\nthree training datasets (Wu et al., 2013; Yu et al.,\n2014; Tseng et al., 2015), which has 10K data\nsamples in total. Following (Wang et al., 2019),\nwe also include additional 271K samples as the\ntraining data, which are generated by an automatic\nmethod (Wang et al., 2018) 3.\nTest Data To evaluate the performance of the\nproposed method, we used three test datasets from\nthe SIGHAN 2013, SIGHAN 2014, SIGHAN 2015\nbenchmarks (Wu et al., 2013; Yu et al., 2014; Tseng\net al., 2015) as in (Wang et al., 2019). We also\nfollow the same data pre-processing procedure, i.e.,\nthe characters in these datasets are converted to\nsimpliï¬ed Chinese using OpenCC 4. The statistic\nof the data is listed in Table 2.\nBaseline Models We compare our method with\nï¬ve typical baselines.\nâ€¢LMC (Xie et al., 2015): This method utilizes\nthe confusion set to replace the characters and\nthen evaluates the modiï¬ed sentence via a N-\ngram Language Model.\n3https://github.com/wdimmy/Automatic-Corpus-\nGeneration\n4https://github.com/BYV oid/\nCharacter-level Sentence-level\nDetection-levelCorrection-levelDetection-levelCorrection-level\nSIGHAN 2013 D-P D-R D-F C-P C-R C-F D-P D-R D-F C-P C-R C-F\nLMC (Xie et al., 2015)79.8 50.0 61.577.6 22.7 35.1 (-) (-) (-) (-) (-) (-)\nSL (Wang et al., 2018)54.0 69.3 60.7 (-) (-) 52.1 (-) (-) (-) (-) (-) (-)\nPN (Wang et al., 2019)56.8 91.4 70.179.7 59.4 68.1 (-) (-) (-) (-) (-) (-)\nFASpell (Hong et al., 2019)(-) (-) (-) (-) (-) (-) 76.2 63.2 69.173.1 60.5 66.2\nBERT 80.6 88.4 84.398.1 87.2 92.379.0 72.8 75.877.7 71.6 74.6\nSpellGCN 82.6 88.9 85.798.4 88.4 93.180.1 74.4 77.278.3 72.7 75.4\nSIGHAN 2014 D-P D-R D-F C-P C-R C-F D-P D-R D-F C-P C-R C-F\nLMC (Xie et al., 2015)56.4 34.8 43.071.1 50.2 58.8 (-) (-) (-) (-) (-) (-)\nSL (Wang et al., 2018)51.9 66.2 58.2 (-) (-) 56.1 (-) (-) (-) (-) (-) (-)\nPN (Wang et al., 2019)63.2 82.5 71.679.3 68.9 73.7 (-) (-) (-) (-) (-) (-)\nFASpell (Hong et al., 2019)(-) (-) (-) (-) (-) (-) 61.0 53.5 57.059.4 52.0 55.4\nBERT 82.9 77.6 80.296.8 75.2 84.665.6 68.1 66.863.1 65.5 64.3\nSpellGCN 83.6 78.6 81.097.2 76.4 85.565.1 69.5 67.263.1 67.2 65.3\nSIGHAN 2015 D-P D-R D-F C-P C-R C-F D-P D-R D-F C-P C-R C-F\nLMC (Xie et al., 2015)83.8 26.2 40.071.1 50.2 58.8 (-) (-) (-) (-) (-) (-)\nSL (Wang et al., 2018)56.6 69.4 62.3 (-) (-) 57.1 (-) (-) (-) (-) (-) (-)\nPN (Wang et al., 2019)66.8 73.1 69.871.5 59.5 69.9 (-) (-) (-) (-) (-) (-)\nFASpell (Hong et al., 2019)(-) (-) (-) (-) (-) (-) 67.6 60.0 63.566.6 59.1 62.6\nBERT 87.5 85.7 86.695.2 81.5 87.873.7 78.2 75.970.9 75.2 73.0\nSpellGCN 88.9 87.7 88.395.7 83.9 89.474.8 80.7 77.772.1 77.7 75.9\nTable 3: The performance of our method and baseline models (%). D, C denote the detection, correction, respec-\ntively. P, R, F denote the precision, recall and F1 score, respectively. The results of BERT are from our own\nimplementation. Best results are in bold. We performed additional ï¬ne-tuning on SIGHAN13 for 6 epochs as the\ndata distribution in SIGHAN13 differs from other datasets, e.g. â€œçš„â€, â€œå¾—â€ and â€œåœ°â€ are rarely distinguished.\nâ€¢SL (Wang et al., 2018): This method proposes\na pipeline where a Sequence Labeling model\nis adopted for detection. The incorrect charac-\nters are marked as 1 (0 otherwise).\nâ€¢PN (Wang et al., 2019): This method incorpo-\nrates a Pointer Network to consider the extra\ncandidates from the confusion set.\nâ€¢FASpell (Hong et al., 2019): This model uti-\nlizes a specialized candidate selection method\nbased on the similarity metric. This metric\nis measured using some empirical methods,\ne.g., edit distance, rather than a pre-deï¬ned\nconfusion set.\nâ€¢BERT (Devlin et al., 2019): The word embed-\nding is used as the softmax layer on the top of\nBERT for the CSC task. We trained this model\nusing the same setting, i.e., the comparable\nmodel w/o SpellGCN.\nEvaluation Metrics The precision, recall and F1\nscores are reported as the evaluation metrics, which\nare commonly used in the CSC tasks. These met-\nrics are provided for the detection and correction\nsub-tasks. Besides the evaluation on the charac-\nter level, we also report the sentence-level metrics\non the detection and correction sub-tasks, which\nis more appealing for real-world applications. On\nthe sentence level, we consider a sentence to be\ncorrectly annotated only if all errors in the sentence\nare corrected as in (Hong et al., 2019) 5. On the\ncharacter level, we calculate the metrics using the\nevaluation script from (Wang et al., 2019) 6. We\nalso evaluated BERT and SpellGCN by the ofï¬cial\nevaluation metrics tools7, which gives False Posi-\ntive Rate (FTR), Accuracy and Precision/Recall/F1.\n4.2 Hyper-parameters\nOur code is based on the repository of BERT 8. We\nï¬ne-tune the models using AdamW (Loshchilov\nand Hutter, 2018) optimizer for 6 epochs with a\nbatch size of 32 and a learning rate of 5e-5. The\nnumber of the layer in SpellGCN is 2, and the at-\ntentive combination operation with factor 3 is used.\nAll experiments were conducted for 4 runs and the\naveraged metric is reported. The code and trained\nmodels will be released publicly after review (cur-\nrently, the code is attached in the supplementary\nï¬les).\n5https://github.com/iqiyi/FASPell\n6https://github.com/wdimmy/Confusionset-guided-\nPointer-Networks-for-Chinese-Spelling-Check\n7http://nlp.ee.ncu.edu.tw/resource/csc.html\n8https://github.com/google-research/bert\nSIGHAN 2014FPR D-A C-A D-P D-R D-F C-P C-R C-F\nBERT 15.3 76.8 75.7 81.9 68.9 74.9 81.4 66.7 73.3\nSpellGCN 14.1 77.7 76.9 83.1 69.5 75.7 82.8 67.8 74.5\nSIGHAN 2015FPR D-A C-A D-P D-R D-F C-P C-R C-F\nBERT 13.6 83.0 81.5 85.9 78.9 82.3 85.5 75.8 80.5\nSpellGCN 13.2 83.7 82.2 85.9 80.6 83.1 85.4 77.6 81.3\nTable 4: The performance of BERT and SpellGCN evaluated by ofï¬cial tools on SIGHAN 2014 and SIGHAN\n2015. FPR denotes the false positive rate and A denotes the accuracy. D-A and C-A denote detection accuracy and\ncorrection accuracy.\n4.3 Main Results\nTable 3 shows the performance of the proposed\nmethod on the three CSC datasets, compared with\nï¬ve typical CSC systems. When using SpellGCN,\nthe model achieves better results in all test sets\nagainst vanilla BERT, which veriï¬es its effective-\nness. The improvement is considerable with such a\nlarge amount of training data (cf. the comparison in\nFigure 2). This indicates the similarity knowledge\nis essential for CSC and it can hardly be learned\nby simply increasing the data amount. In terms of\nsentence-level F1score metric in the correction sub-\ntask, i.e., C-F score in the last column, the improve-\nments against previous best results (FASPell) are\n9.2%, 9.7% and 13.3% respectively. Nevertheless,\nit should be noted that FASpell was trained on dif-\nferent training data while this paper follows the set-\nting mentioned in the PN paper (Wang et al., 2019).\nIdeally, our method is compatible with FASpell\nand better results can be achieved when FASpell is\nemployed.\nFASpell used their own metrics, which are differ-\nent from the sentence-level false postive and false\nnegtivate counting strategy of the ofï¬cial evalua-\ntion toolkit. We used the scripts by PGNet and\nFASpell to compute their metrics for fair compari-\nson. We further add the ofï¬cial evaluation results\nof BERT and SpellGCN in Table 4. Actually, Spell-\nGCN consistently improves the performance when\nevaluated by the PGNet/FASpell scripts and the\nofï¬cial evaluation toolkit. We will add the FPR\nresults in our revision. The FPR scores are 14.1%\n(SpellGCN) v.s. 15.3% (BERT) on SIGHAN 14,\nand 13.2% (SpellGCN) v.s. 13.6% (BERT) on\nSIGHAN 15. FPR on SIGHAN 13 is statistically\nmeaningless since almost all the tested sentences\nhave the spelling errors.\n0 1 2 3 4 5 6\nepochs\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nBERT F1score\nSpellGCN F1score\nBERT Precision\nSpellGCN Precision\nBERT Recall\nSpellGCN Recall\nFigure 2: The test curves for sentence-level correction\nmetrics with and without SpellGCN w.r.t. the number\nof training epochs on SIGHAN 2015.\n4.4 Ablation Studies\nIn this subsection, we analyze the effect of several\ncomponents, including the number of layers and\nthe attention mechanism. The ablation experiments\nwere performed using 10K training data.\nEffect of the Number of Layers Generally, the\nperformance of a GCN varies with the number of\nlayers. We investigate how the number of Spell-\nGCN layers inï¬‚uence the performance in CSC. In\nthis comparison, the number of layers changes from\n1 to 4, and the results are illustrated in Figure 3.\nFor clarity, we report the character-level C-F on\nthe three test datasets. The results indicate that\nSpellGCN is able to make use of multiple layers.\nWith multiple layers, SpellGCN can aggregate the\ninformation in more hops and therefore, achieve\nbetter performance. However, the F1score drops\nwhen the number of layers is larger than 3. This is\nreasonable due to the over-smooth problem noted\nin (Yan et al., 2019). When the number of GCN\nlayers increases, the representations of neighboring\ncharacters in the similarity graph will get more and\nmore similar since they all are calculated via those\nof their neighbors in the similarity graph.\nSIGHAN13 SIGHAN14 SIGHAN15\n60\n62\n64\n66\n68\n1 2 3 4\nFigure 3: The character-level C-F results (%) w.r.t. the\ndepth of SpellGCN. The results were obtained with\n10K training samples.\ncombination method C-F\nbaseline (w/o SpellGCN) 67.0\nsum pooling 66.3\nmean pooling 67.5\nattentive combination (Î²=1) 67.8\nattentive combination (Î²=3) 68.2\nattentive combination (Î²=5) 68.0\nattentive combination (Î²=10) 67.7\nTable 5: The ablation results for graph combination\nmethod (%). The averaged character-level C-F scores\nof 4 runs on the SIGHAN 2013 are reported. The mod-\nels were trained with 10K training samples. Mean pool-\ning denotes that the output representation Cl of each\nlayer is the average of fkâˆˆ{P,S}(Ak,Hl), while sum\npooling summarizes fkâˆˆ{P,S}(Ak,Hl).\nEffect of Attention Mechanism We investigate\nhow to better combine the graphs in the SpellGCN\nlayer. Here, we compare the attention mechanism\nagainst sum-pooling and mean-pooling, with dif-\nferent hyper-parameter Î²mentioned in Section 3.3.\nThe experiments are conducted based on the 2-layer\nSpellGCN on SIGHAN 2013 test set. The results\npresented in Table 5 show that the sum pooling\nfails in the CSC task. We suggest that the sum\npooling is inconsistent with the normalization of\nGCN and fails to combine the information from\ndifferent channels (i.e., graphs). The mean pool-\ning is feasible but is surpassed by the attention\nmechanism. This indicates that the adaptive com-\nbination for each character node is beneï¬cial. We\nincorporate a hyper-parameter Î²into the attention\noperation since the dot products may grow large in\nmagnitude, pushing the softmax function into re-\ngions where it has extremely small gradients. With\nthese results, we chose the attention mechanism\nwith a Î²of 3 in SpellGCN.\nPronunciation: fË˜angâ†’fÂ´an, w`angâ†’w`ang\n...èµ°è·¯çœŸçš„éº»åŠï¼Œæˆ‘ä¹Ÿæ²¡æœ‰å–çš„ä¸œè¥¿ï¼Œåœ¨å®¶æ±ªäº†...\n...èµ°è·¯çœŸçš„éº»æœ¨ï¼Œæˆ‘ä¹Ÿæ²¡æœ‰å–çš„ä¸œè¥¿ï¼Œåœ¨å®¶å‘†äº†...\n...èµ°è·¯çœŸçš„éº»çƒ¦ï¼Œæˆ‘ä¹Ÿæ²¡æœ‰å–çš„ä¸œè¥¿ï¼Œåœ¨å®¶å¿˜äº†...\nPronunciation: yÂ¯inâ†’yË˜ing\n...å› ä¸ºå¦ˆå¦ˆæˆ–çˆ¸çˆ¸åœ¨çœ‹å½•éŸ³æœº...å¸®å°å­©å­è§£å†³é—®é¢˜...\n...å› ä¸ºå¦ˆå¦ˆæˆ–çˆ¸çˆ¸åœ¨çœ‹å½•éŸ³æœº...å¸®å°å­©å­è§£å†³é—®é¢˜...\n...å› ä¸ºå¦ˆå¦ˆæˆ–çˆ¸çˆ¸åœ¨çœ‹å½•å½±æœº...å¸®å°å­©å­è§£å†³é—®é¢˜...\nShape:å‘â†’å°š\n...ä¸è¿‡åœ¨è®¸å¤šä¼ ç»Ÿæ–‡åŒ–çš„å›½å®¶ï¼Œå¥³äººå‘æœªå¾—åˆ°å¹³ç­‰...\n...ä¸è¿‡åœ¨è®¸å¤šä¼ ç»Ÿæ–‡åŒ–çš„å›½å®¶ï¼Œå¥³äººä»æœªå¾—åˆ°å¹³ç­‰...\n...ä¸è¿‡åœ¨è®¸å¤šä¼ ç»Ÿæ–‡åŒ–çš„å›½å®¶ï¼Œå¥³äººå°šæœªå¾—åˆ°å¹³ç­‰...\nTable 6: Several prediction results on the test set. The\nï¬rst line in the block is the input sentence. The second\nline is corrected by BERT without SpellGCN. And the\nlast line is the result from SpellGCN. We highlight the\nincorrect/correct characters by orange/blue color.\n4.5 Case Study\nWe show several correction results to demonstrate\nthe properties of SpellGCN. In addition to the sam-\nple illustrated in Table 1, several prediction results\nare given in Table 6. From these cases, we can\ntell that our SpellGCN is capable of revising the\nincorrect characters into correct ones with the pro-\nnunciation and shape constraint. For instance, in\nthe ï¬rst case, â€œ éº»åŠ(fË˜ang)â€ is detected as errors\nand modiï¬ed into â€œéº»çƒ¦(fÂ´an)â€. Without pronuncia-\ntion similarity constraint, â€œéº»æœ¨(m`u)â€ becomes the\nmost probable answer. And surprisingly, in the sec-\nond case, our SpellGCN successfully modiï¬es the\ncharacter reasonable in the context. The meaning\nof input sentence â€œçœ‹å½•éŸ³æœºâ€ is â€œwatch the audio\nrecorderâ€, and our method corrects it into â€œçœ‹å½•å½±\næœºâ€ which means â€œwatch the video recorderâ€. We\nsuggest that SpellGCN injects a prior similarity be-\ntween â€œéŸ³â€ and â€œå½±â€ in the representation space so\nthat the model derives a higher posterior probabil-\nity of â€œå½±â€. In the last case, we show a correction\nresult under the shape constraint. In the confusion\nset, â€œå‘â€ is similar to â€œ å°šâ€ and therefore, using\nSpellGCN is able to retrieve the correct result.\n4.6 Character Embedding Visualization\nPrevious experiments have explored the perfor-\nmance of SpellGCN quantitatively in detail. To\nqualitatively study whether SpellGCN learns mean-\ningful representations, we dive into the target em-\nbedding space W derived from SpellGCN.\nIn Figure 4, the embedding of characters with\nphonics â€œch Â´angâ€ and â€œs `Ä±â€ is presented using t-\nSNE (Maaten and Hinton, 2008). The embedding\n/uni00000010/uni00000019/uni00000013/uni00000010/uni00000017/uni00000013/uni00000010/uni00000015/uni00000013/uni00000013/uni00000015/uni00000013/uni00000017/uni00000013/uni00000019/uni00000013\n/uni00000010/uni00000019/uni00000013\n/uni00000010/uni00000017/uni00000013\n/uni00000010/uni00000015/uni00000013\n/uni00000013\n/uni00000015/uni00000013\n/uni00000017/uni00000013\n(a) w/ SpellGCN\n/uni00000010/uni00000014/uni00000013/uni00000013/uni00000010/uni00000018/uni00000013/uni00000013 /uni00000018/uni00000013/uni00000014/uni00000013/uni00000013\n/uni00000010/uni00000014/uni00000013/uni00000013\n/uni00000010/uni0000001a/uni00000018\n/uni00000010/uni00000018/uni00000013\n/uni00000010/uni00000015/uni00000018\n/uni00000013\n/uni00000015/uni00000018\n/uni00000018/uni00000013\n/uni0000001a/uni00000018\n (b) w/o SpellGCN\nFigure 4: The scatter of similar characters of â€ é•¿â€ and\nâ€œç¥€â€ in terms of pronunciation by t-SNE.\n/uni00000010/uni00000014/uni00000013/uni00000013/uni00000010/uni0000001a/uni00000018/uni00000010/uni00000018/uni00000013/uni00000010/uni00000015/uni00000018/uni00000013/uni00000015/uni00000018/uni00000018/uni00000013/uni0000001a/uni00000018/uni00000014/uni00000013/uni00000013\n/uni00000010/uni00000014/uni00000013/uni00000013\n/uni00000010/uni00000018/uni00000013\n/uni00000013\n/uni00000018/uni00000013\n/uni00000014/uni00000013/uni00000013\n(a) w/ SpellGCN\n/uni00000010/uni00000014/uni00000013/uni00000013/uni00000010/uni00000018/uni00000013/uni00000013 /uni00000018/uni00000013/uni00000014/uni00000013/uni00000013\n/uni00000010/uni00000014/uni00000013/uni00000013\n/uni00000010/uni00000018/uni00000013\n/uni00000013\n/uni00000018/uni00000013\n/uni00000014/uni00000013/uni00000013\n (b) w/o SpellGCN\nFigure 5: The scatter of similar characters of â€ é•¿â€ and\nâ€œç¥€â€ in terms of shape by t-SNE.\nlearned by BERT captures the semantic similarity\nbut fails to model the similarity in terms of pro-\nnunciation for the CSC task. This is reasonable as\nthis similarity knowledge is absent in the model-\ning. In contrast, our SpellGCN successfully infuses\nthis prior knowledge into the embedding and the\nresulting embedding exhibits cluster patterns. The\nembedding of characters with these two different\npronunciations forms two clusters, corresponding\nto â€œchÂ´angâ€ and â€œs`Ä±â€ respectively. Due to this prop-\nerty, the model tends to recognize similar charac-\nters and hence is able to retrieve the answers under\npronunciation constraint. Figure 5 shows the same\nsituation for the shape similarity, where two sets of\ncharacters with the shape similar to â€œé•¿â€ and â€œç¥€â€\nare scattered. This veriï¬es the ability of SpellGCN\nin modeling shape similarity.\n5 Conclusions\nWe proposed SpellGCN for CSC to incorporate\nboth phonological and visual similarities into lan-\nguage models. The empirical comparison and the\nresults of analytical experiments verify its effective-\nness. Beyond CSC, SpellGCN can be generalized\nto other situations where speciï¬c prior knowledge\nis available, and to other languages by leveraging\nspeciï¬c similarity graphs analogously. Our method\ncan also be adapted to grammar error correction,\nwhich needs insertion and deletion, by utilizing\nmore ï¬‚exible extractors such as Levenshtein Trans-\nformer (Gu et al., 2019). We leave this direction to\nfuture work.\nReferences\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-\ngio. 2015. Neural machine translation by jointly\nlearning to align and translate. In 3rd Inter-\nnational Conference on Learning Representations,\nICLR 2015, San Diego, CA, USA, May 7-9, 2015,\nConference Track Proceedings.\nZhao-Min Chen, Xiu-Shen Wei, Peng Wang, and Yan-\nwen Guo. 2019. Multi-label image recognition with\ngraph convolutional networks. In IEEE Conference\non Computer Vision and Pattern Recognition, CVPR\n2019, Long Beach, CA, USA, June 16-20, 2019 ,\npages 5177â€“5186.\nXingyi Cheng, Weidi Xu, Kunlong Chen, Wei Wang,\nBin Bi, Ming Yan, Chen Wu, Luo Si, Wei Chu,\nand Taifeng Wang. 2019. Symmetric regulariza-\ntion based BERT for pair-wise semantic reasoning.\nCoRR, abs/1909.03405.\nXingyi Cheng, Ruiqing Zhang, Jie Zhou, and Wei Xu.\n2018. Deeptransport: Learning spatial-temporal de-\npendency for trafï¬c condition forecasting. In 2018\nInternational Joint Conference on Neural Networks,\nIJCNN 2018, Rio de Janeiro, Brazil, July 8-13, 2018,\npages 1â€“8. IEEE.\nShamil Chollampatt, Kaveh Taghipour, and Hwee Tou\nNg. 2016. Neural network translation models for\ngrammatical error correction. In Proceedings of the\nTwenty-Fifth International Joint Conference on Arti-\nï¬cial Intelligence, IJCAI 2016, New York, NY, USA,\n9-15 July 2016, pages 2768â€“2774.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, NAACL-HLT 2019, Minneapolis, MN,\nUSA, June 2-7, 2019, Volume 1 (Long and Short Pa-\npers), pages 4171â€“4186.\nGabriel Pui Cheong Fung, Maxime Debosschere, Ding-\nmin Wang, Bo Li, Jia Zhu, and Kam-Fai Wong. 2017.\nNLPTEA 2017 shared task - chinese spelling check.\nIn Proceedings of the 4th Workshop on Natural Lan-\nguage Processing Techniques for Educational Appli-\ncations, NLP-TEA@IJCNLP 2017, Taipei, Taiwan,\nDecember 1, 2017, pages 29â€“34.\nTao Ge, Furu Wei, and Ming Zhou. 2018. Fluency\nboost learning and inference for neural grammatical\nerror correction. In Proceedings of the 56th Annual\nMeeting of the Association for Computational Lin-\nguistics, ACL 2018, Melbourne, Australia, July 15-\n20, 2018, Volume 1: Long Papers, pages 1055â€“1065.\nJiatao Gu, Changhan Wang, and Jake Zhao. 2019. Lev-\nenshtein transformer. CoRR, abs/1905.11006.\nYuzhong Hong, Xianguo Yu, Neng He, Nan Liu, and\nJunhui Liu. 2019. Faspell: A fast, adaptable, sim-\nple, powerful chinese spell checker based on dae-\ndecoder paradigm. In Proceedings of the 5th Work-\nshop on Noisy User-generated Text (W-NUT 2019) ,\npages 160â€“169.\nJianshu Ji, Qinlong Wang, Kristina Toutanova, Yongen\nGong, Steven Truong, and Jianfeng Gao. 2017. A\nnested attention neural hybrid model for grammati-\ncal error correction. In Proceedings of the 55th An-\nnual Meeting of the Association for Computational\nLinguistics, ACL 2017, Vancouver, Canada, July 30\n- August 4, Volume 1: Long Papers, pages 753â€“762.\nZhongye Jia, Peilu Wang, and Hai Zhao. 2013.\nGraph model for chinese spell checking. In Pro-\nceedings of the Seventh SIGHAN Workshop on\nChinese Language Processing, SIGHAN@IJCNLP\n2013, Nagoya, Japan, October 14-18, 2013 , pages\n88â€“92.\nThomas N. Kipf and Max Welling. 2017. Semi-\nsupervised classiï¬cation with graph convolutional\nnetworks. In 5th International Conference on Learn-\ning Representations, ICLR 2017, Toulon, France,\nApril 24-26, 2017, Conference Track Proceedings.\nJing Li, Hao Peng, Lin Liu, Guixi Xiong, Bowen Du,\nHongyuan Ma, Lihong Wang, and Md. Zakirul Alam\nBhuiyan. 2018. Graph cnns for urban trafï¬c pas-\nsenger ï¬‚ows prediction. In 2018 IEEE SmartWorld,\nUbiquitous Intelligence & Computing, Advanced &\nTrusted Computing, Scalable Computing & Commu-\nnications, Cloud & Big Data Computing, Internet\nof People and Smart City Innovation, Smart-\nWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI\n2018, Guangzhou, China, October 8-12, 2018 ,\npages 29â€“36. IEEE.\nChao-Lin Liu, Min-Hua Lai, Yi-Hsuan Chuang, and\nChia-Ying Lee. 2010. Visually and phonologically\nsimilar characters in incorrect simpliï¬ed chinese\nwords. In COLING 2010, 23rd International Confer-\nence on Computational Linguistics, Posters Volume,\n23-27 August 2010, Beijing, China, pages 739â€“747.\nXiaodong Liu, Kevin Cheng, Yanyan Luo, Kevin\nDuh, and Yuji Matsumoto. 2013. A hybrid chi-\nnese spelling correction using language model and\nstatistical machine translation with reranking. In\nProceedings of the Seventh SIGHAN Workshop on\nChinese Language Processing, SIGHAN@IJCNLP\n2013, Nagoya, Japan, October 14-18, 2013 , pages\n54â€“58.\nIlya Loshchilov and Frank Hutter. 2018. Decoupled\nweight decay regularization.\nLaurens van der Maaten and Geoffrey Hinton. 2008.\nVisualizing data using t-sne. Journal of machine\nlearning research, 9(Nov):2579â€“2605.\nGaoqi Rao, Qi Gong, Baolin Zhang, and Endong Xun.\n2018. Overview of NLPTEA-2018 share task chi-\nnese grammatical error diagnosis. In Proceedings\nof the 5th Workshop on Natural Language Process-\ning Techniques for Educational Applications, NLP-\nTEA@ACL 2018, Melbourne, Australia, July 19,\n2018, pages 42â€“51.\nYuen-Hsien Tseng, Lung-Hao Lee, Li-Ping Chang, and\nHsin-Hsi Chen. 2015. Introduction to SIGHAN\n2015 bake-off for chinese spelling check. In\nProceedings of the Eighth SIGHAN Workshop on\nChinese Language Processing, SIGHAN@IJCNLP\n2015, Beijing, China, July 30-31, 2015 , pages 32â€“\n37.\nDingmin Wang, Yan Song, Jing Li, Jialong Han, and\nHaisong Zhang. 2018. A hybrid approach to auto-\nmatic corpus generation for chinese spelling check.\nIn Proceedings of the 2018 Conference on Empirical\nMethods in Natural Language Processing, Brussels,\nBelgium, October 31 - November 4, 2018 , pages\n2517â€“2527.\nDingmin Wang, Yi Tay, and Li Zhong. 2019.\nConfusionset-guided pointer networks for chinese\nspelling check. In Proceedings of the 57th Confer-\nence of the Association for Computational Linguis-\ntics, ACL 2019, Florence, Italy, July 28- August 2,\n2019, Volume 1: Long Papers, pages 5780â€“5785.\nShih-Hung Wu, Chao-Lin Liu, and Lung-Hao Lee.\n2013. Chinese spelling check evaluation at\nSIGHAN bake-off 2013. In Proceedings of the Sev-\nenth SIGHAN Workshop on Chinese Language Pro-\ncessing, SIGHAN@IJCNLP 2013, Nagoya, Japan,\nOctober 14-18, 2013, pages 35â€“42.\nWeijian Xie, Peijie Huang, Xinrui Zhang, Kaiduo\nHong, Qiang Huang, Bingzhou Chen, and Lei\nHuang. 2015. Chinese spelling check system based\non n-gram model. In Proceedings of the Eighth\nSIGHAN Workshop on Chinese Language Process-\ning, SIGHAN@IJCNLP 2015, Beijing, China, July\n30-31, 2015, pages 128â€“136.\nYang Xin, Hai Zhao, Yuzhu Wang, and Zhongye\nJia. 2014. An improved graph model for chinese\nspell checking. In Proceedings of The Third CIPS-\nSIGHAN Joint Conference on Chinese Language\nProcessing, Wuhan, China, October 20-21, 2014 ,\npages 157â€“166.\nHaoran Yan, Xiaolong Jin, Xiangbin Meng, Jiafeng\nGuo, and Xueqi Cheng. 2019. Event detection with\nmulti-order graph convolution and aggregated atten-\ntion. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n5770â€“5774.\nJunjie Yu and Zhenghua Li. 2014. Chinese spelling\nerror detection and correction based on language\nmodel, pronunciation, and shape. In Proceedings of\nThe Third CIPS-SIGHAN Joint Conference on Chi-\nnese Language Processing, Wuhan, China, October\n20-21, 2014, pages 220â€“223.\nLiang-Chih Yu, Lung-Hao Lee, Yuen-Hsien Tseng, and\nHsin-Hsi Chen. 2014. Overview of SIGHAN 2014\nbake-off for chinese spelling check. In Proceedings\nof The Third CIPS-SIGHAN Joint Conference on\nChinese Language Processing, Wuhan, China, Oc-\ntober 20-21, 2014, pages 126â€“132.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8301364779472351
    },
    {
      "name": "Spelling",
      "score": 0.7532892227172852
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6699842214584351
    },
    {
      "name": "Natural language processing",
      "score": 0.6324564218521118
    },
    {
      "name": "Similarity (geometry)",
      "score": 0.526762843132019
    },
    {
      "name": "Graph",
      "score": 0.5233056545257568
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.495251327753067
    },
    {
      "name": "Heuristic",
      "score": 0.478302538394928
    },
    {
      "name": "Margin (machine learning)",
      "score": 0.41728609800338745
    },
    {
      "name": "Chinese characters",
      "score": 0.4130837917327881
    },
    {
      "name": "Machine learning",
      "score": 0.21205127239227295
    },
    {
      "name": "Linguistics",
      "score": 0.07481628656387329
    },
    {
      "name": "Theoretical computer science",
      "score": 0.06685298681259155
    },
    {
      "name": "Image (mathematics)",
      "score": 0.06360498070716858
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    }
  ]
}