{
  "title": "Grammar-obeying program synthesis: A novel approach using large language models and many-objective genetic programming",
  "url": "https://openalex.org/W4404386737",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2023479128",
      "name": "Tao Ning",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4280993581",
      "name": "Ventresque, Anthony",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2743780781",
      "name": "Nallur, Vivek",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4283035258",
      "name": "Saber, Takfarinas",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6869926167",
    "https://openalex.org/W4388483640",
    "https://openalex.org/W4322631505",
    "https://openalex.org/W4386982649",
    "https://openalex.org/W6861295688",
    "https://openalex.org/W4391249841",
    "https://openalex.org/W4294811514",
    "https://openalex.org/W6847872654",
    "https://openalex.org/W4400203522",
    "https://openalex.org/W6754382280",
    "https://openalex.org/W2149362532",
    "https://openalex.org/W2092224777",
    "https://openalex.org/W3083478733",
    "https://openalex.org/W2956095626",
    "https://openalex.org/W2793552896",
    "https://openalex.org/W6760615869",
    "https://openalex.org/W6783076754",
    "https://openalex.org/W2901730283",
    "https://openalex.org/W6736215060",
    "https://openalex.org/W6853429700",
    "https://openalex.org/W2161052636",
    "https://openalex.org/W6745345617",
    "https://openalex.org/W6680698151",
    "https://openalex.org/W4252211664",
    "https://openalex.org/W6683347645",
    "https://openalex.org/W1978661986",
    "https://openalex.org/W2138756793",
    "https://openalex.org/W4321649710",
    "https://openalex.org/W2969867445",
    "https://openalex.org/W4391766565",
    "https://openalex.org/W2922424533",
    "https://openalex.org/W4379086787",
    "https://openalex.org/W4375959406",
    "https://openalex.org/W4391767060",
    "https://openalex.org/W3173777717",
    "https://openalex.org/W1517016597",
    "https://openalex.org/W1491280261",
    "https://openalex.org/W1559136395",
    "https://openalex.org/W4387838288",
    "https://openalex.org/W1506853907",
    "https://openalex.org/W2766078762"
  ],
  "abstract": null,
  "full_text": "G ram m ar-obeying program  synthesis: A\nnovel approach using large language m odels\nand m any-objective genetic program m ing\nTitle G ram m ar-obeying program  synthesis: A novel approach using\nlarge language m odels and m any-objective genetic program m ing\nAuthor(s) Tao, N ing;Ventresque, Anthony;N allur, Vivek;Saber, Takfarinas\nP ublication D ate 2024-11-15\nPublisher Elsevier\nR epository D O I https://doi.org/1 0 .1 0 1 6/j.csi.20 24.1 0 3938\nHighlights\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large Language Models and\nMany-Objective Genetic Programming\nNing Tao,Anthony Ventresque,Vivek Nallur,Takfarinas Saber\nâ€¢ LLMs are effective at generating correct programs for program synthesis tasks; however, they often fail to produce\nprograms that adhere to specified grammars.\nâ€¢ Five different LLMs were leveraged with a Similarity-Based Many-Objective G3P (SBMaOG3P) framework.\nâ€¢ The results on a well-known benchmark dataset demonstrate that SBMaOG3P is capable of finding correct programs\nthat obey the defined grammars, outperforming LLMs and the state-of-the-art G3P.\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large\nLanguage Models and Many-Objective Genetic Programming\nNing Taoa,âˆ—,1, Anthony Ventresqueb,2, Vivek Nallura,1 and Takfarinas Saberc,3\naSchool of Computer Science, University College Dublin, Dublin, Ireland\nbLero, School of Computer Science and Statistics, Trinity College Dublin, Dublin, Ireland\ncLero, School of Computer Science, University of Galway, Galway, Ireland\nARTICLE INFO\nKeywords:\nProgram Synthesis\nGrammar\nLLMs\nGrammar Guided GP\nMulti-objective\nABSTRACT\nProgramsynthesisisanimportantchallengethathasattractedsignificantresearchinterest,especially\nin recent years with advancements in Large Language Models (LLMs). Although LLMs have\ndemonstrated success in program synthesis, there remains a lack of trust in the generated code due to\ndocumentedrisks(e.g.,codewithknownandriskyvulnerabilities).Therefore,itisimportanttorestrict\nthe search space and avoid bad programs. In this work, pre-defined restricted Backus-Naur Form\n(BNF) grammars are utilised, which are considered â€˜safeâ€™, and the focus is on identifying the most\neffectivetechniquefor grammar-obeyingprogramsynthesis,wherethegeneratedcodemustbecorrect\nand conform to the predefined grammar. It is shown that while LLMs perform well in generating\ncorrectprograms,theyoftenfailtoproducecodethatadherestothegrammar.Toaddressthis,anovel\nSimilarity-BasedMany-ObjectiveGrammarGuidedGeneticProgramming(SBMaOG3P)approachis\nproposed,leveragingtheprogramsgeneratedbyLLMsintwoways:(i)asseedsfollowingagrammar\nmapping process and (ii) as targets for similarity measure objectives. Experiments on a well-known\nandwidelyusedprogramsynthesisdatasetindicatethattheproposedapproachsuccessfullyimproves\nthe rate of grammar-obeying program synthesis compared to various LLMs and the state-of-the-art\nGrammar-GuidedGeneticProgramming.Additionally,theproposedapproachsignificantlyimproved\nthesolutionintermsofthebestfitnessvalueofeachrunfor21outof28problemscomparedtoG3P.\n1. Introduction\nProgram synthesis seeks to streamline or automate pro-\ngramming tasks by offering a set of techniques that enable\ncode creation from a high-level description of task objec-\ntives(suchastextualdescriptions,input/outputexamples,or\nsketches).\nIn recent years, Large Language Models (LLMs) have\ndemonstrated success in executing a variety of software\nengineeringtasks[42,15,17,32,41,20],includingprogram\nsynthesis from natural language prompt. However, the code\ngenerated by LLMs often lacks trustworthiness and might\ninclude documented risks. (e.g., code contains known and\nriskyvulnerabilities[1,30]).ThepossibilityoffaultyLLM-\ngenerated code poses a substantial and escalating threat\nto software and its stakeholders. Additionally, the inherent\ngenerative nature of LLMs limits their effectiveness in cor-\nrecting errors through iterative prompting [31, 14].\nTo limit the search space and exclude programs that\nexhibit poor coding practices, use unreliable libraries or\nfunctionalities, or deviate from the desired design pattern,\nthe definition ofâ€œsafeâ€ grammars is considered. This en-\nsuresthatanygeneratedprogramadherestothesegrammars,\ntherebymitigatingsecurityrisksandenhancingcodequality.\nDefining â€œsafeâ€ grammars is a complex challenge by\nitself that requires extensive research to design and validate\nthem for various tasks. However, our focus in this work\nis ongrammar-obeying program synthesis, which is the\nning.tao@ucdconnect.ie (N. Tao);anthony.ventresque@tcd.ie (A.\nVentresque);vivek.nallur@ucd.ie (V. Nallur);\ntakfarinas.saber@universityofgalway.ie (T. Saber)\nORCID(s): 0000-0002-8154-547X (N. Tao)\nability to generate correct programs that obey the specified\ngrammar.\nIn this work, it is demonstrated that although five well-\nknown LLMs (i.e., ChatGPT, Gemma, LLaMa, Mistral,\nand Zephyr) are effective at generating correct programs\nfor program synthesis tasks, they frequently fail to produce\nprograms that adhere to specified grammars.\nA study by Tao et al. [37] has shown that it is possible\nto help improve LLMsâ€™ performance at grammar-obeying\nprogram synthesis by mapping their code to the predefined\ngrammar and evolving it using Grammar-Guided Genetic\nProgramming (G3P). While this approach brings some im-\nprovements, it only leverages one LLM-generated program\nat a time as a seedâ€“thus losing an important amount of\ninformation.\nOther works by Tao et al. [36, 35, 34] have shown that\nG3P can be further improved by leveraging the similarity\nof evolved programs to an â€œidealâ€ target code alongside the\ninput-output error rate. However, these studies were con-\nsidered correct target codes obtained from a fictive oracleâ€“\nmaking them inapplicable in practice.\nTao et al. [33] demonstrated in their recent research that\nintegrating ChatGPT solutions with a grammar-mapping\nprocess into a Many-objective G3P system can enhance the\nperformance of grammar-obeying program synthesis tasks.\nHowever, relying solely on ChatGPT solutions as the initial\nseed restricts the diversity of code structures.\nInthiswork,aSimilarity-BasedMany-ObjectiveGrammar-\nGuided Genetic Programming (SBMaOG3P) approach is\nproposed, which leverages programs generated by multiple\nLLMs in two ways:\nTao et al.:Preprint submitted to Elsevier Page 1 of 13\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large Language Models and Many-Objective Genetic\nProgramming\nâ€¢ Leveraging the similarity towards the programs gen-\nerated by 5 LLMs (i.e., ChatGPT, Gemma, LLaMa,\nMistral and Zephyr) in a many-objective approach.\nâ€¢ Leveraging the programs generated by the LLMs as\nseeds to the evolutionary process (following a map-\nping to the predefined grammar).\nThe effectiveness of the proposed method has been as-\nsessed by benchmarking it against the traditional G3P al-\ngorithm introduced by Forstenlechner et al. [6], and the\nlatest algorithm for grammar-obeying program synthesis\ndeveloped by Tao et al. [33]. The results show that our\nproposed approach found solutions for the majority of tasks\nconsidered and outperformed the state-of-the-art algorithm.\nHowever, in the default configuration, SBMaOG3P did not\noutperformtheLLMatgeneratingsolutionswhengrammar\nconstraints were ignored.\nThe structure of the paper is as follows: Section 2 pro-\nvides a summary of the relevant background and related\nwork. Section 3 presents our novel SBMaOG3P approach.\nThe details of our experimental setup are described in Sec-\ntion4.Section5discussestheresultsofourexperimentsand\nprovides an analysis. Finally, Section 6 concludes the paper\nand suggests directions for future research.\n2. Background and Related Work\n2.1. Genetic Programming\nGenetic Programming (GP) is a type of evolutionary\nalgorithm designed to automate creation and optimisation\nby repeatedly assessing their effectiveness in performing\nspecific tasks. GP aims to develop programs through the\nevolution of a population of individuals. These individuals\ninitiallycompriserandomlychosencandidates,typicallyill-\nsuitedfortheintendedfunction.GPutilisesgeneticoperators\ninspired by natural processes, such as crossover, mutation,\nand selection. Over time, a variety of GP systems have been\nintroduced, each with distinct characteristics (e.g., GP [13],\nCartesian GP [19], and Linear GP [3]).\n2.2. Grammar-Guided Genetic Programming\nG3P is a variant of Genetic Programming (GP) that\nleverages BNF grammar to define the search space. Gram-\nmatical Evolution [23] and Context-Free Grammar Genetic\nProgramming (CFG-GP) by Whigham [39] are two well-\nknown representations of G3P algorithms. By introducing\ngrammarrulesintotheevolutionprocess,theG3Palgorithm\nensures the reliability of the generated solutions, which\nare syntactically correct. This BNF grammar file is often\npredefined with a problem set that is suitable for various\napplications. It is widely utilised in automated program-\nming [21], transport system management [29], and wireless\ncommunications scheduling [16, 26, 28, 27, 25]. However,\ndesigninggrammarforeachproblemlimitsthescalabilityof\nthe G3P algorithm.\nIn response, Forstenlechner et al. [5] designed an auto-\nmatic grammar construction approach for G3P, where one\nBNFgrammardesigncanbeusedforvariousproblems.The\nmechanismbehindthisautomationinvolvesdesigningshort\ngrammars for each data type. The algorithm automatically\nselectstheappropriategrammaraslongastheuserprovides\nthe data type for the problem. Another benefit of designing\nshortgrammarforeachdatatypeisreducingthesearchspace\nby removing irrelevant grammar and reducing computation\ncosts and execution time. The authors [6] further extended\nthe grammar construction algorithm to include character\ndata types, which were previously handled as strings. In the\nupdatedapproach,theyalsointroducedrecursions,enriching\nthe diversity of grammar choices to tackle a wider range of\nproblems.\n2.3. Large Language Models\nLarge Language Models (LLMs) are AI algorithms that\nleverage extensive parameters and deep learning architec-\nture to understand and generate human language. They use\ntransformer-basedneuralnetworkstocapturelong-rangede-\npendenciesandcontextualrelationshipswithintext.Thisar-\nchitecture, combined with techniques such as self-attention\nmechanisms, has enabled LLMs to perform complex lan-\nguage tasks with high accuracy and fluency.\nLLMs can effectively tackle a wide range of real-world\nproblems, including programming, writing, and design [15,\n17, 32, 41, 20]. Notable examples include AI chatbots like\nOpenAIâ€™s ChatGPT [22] and Googleâ€™s Gemini [18], which\nuse LLMs as their core technology.\nChatGPT [22] is one of the most powerful AI chatbots,\ncapable of generating human-like responses based on user\ninput.Itcananswerusersâ€™questionsusingalargeknowledge\ncorpus.Beyondsimplequeries,itcanperformcomplexreal-\nworldtaskssuchaswritingemails,analysingandsummaris-\ning text, processing pictures, and even programming.\nLLMscangenerateprogramsbasedonuserintent.How-\never, they often produce inaccurate code due to ambiguous\ntaskdescriptionsandthecomplexityofprogrammingtasks.\nWang et al. [38] enhanced the programming capabilities of\nLLMs by leveraging BNF grammar as external knowledge\nand incorporating domain-specific constraints. In their ap-\nproach, they included grammar in the prompt that could\ngeneratesolutionsforthegiveninput-outputexampleswhile\nkeeping the grammar size minimal. This method allows\nLLMs to generate programs more accurately by predicting\nthe appropriate grammar for new tasks. In this research, we\nrequireLLMstogenerateprogramsthatadheretopredefined\nBNF grammar rather than allowing the model to predict the\ngrammar to ensure accurate responses.\n2.4. Program Similarity Assessment\nMeasuring code similarity is a critical task in program-\nming. It enables the identification of repetitive code, the\ndiscovery of similar bugs in software development, and\nplagiarism detection in assignment assessments [9]. This\nresearch uses program similarity for fitness evaluation in\nthe SBMaOG3P algorithm. Four similarity measures, rated\nhighest in a survey by Ragkhitwetsagul et al. [24], were\nselected.\nTao et al.:Preprint submitted to Elsevier Page 2 of 13\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large Language Models and Many-Objective Genetic\nProgramming\n2.4.1. FuzzyWuzzy\nFuzzyWuzzy[4]isdevelopedbasedonthediffliblibrary\nfor string searching. This library provides two similarity\nfunctions for string matching namedğ‘‡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘†ğ‘œğ‘Ÿğ‘¡ğ‘…ğ‘ğ‘¡ğ‘–ğ‘œ and\nğ‘‡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘†ğ‘’ğ‘¡ğ‘…ğ‘ğ‘¡ğ‘–ğ‘œ. The ğ‘‡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘†ğ‘œğ‘Ÿğ‘¡ğ‘…ğ‘ğ‘¡ğ‘–ğ‘œ function starts by\npreprocessing the string, which involves removing punctu-\nation, converting the string to lowercase letters, and sorting\nthe tokens. It then uses the sorted tokens to generate a\nsimilarity score. The ğ‘‡ğ‘œğ‘˜ğ‘’ğ‘›ğ‘†ğ‘’ğ‘¡ğ‘…ğ‘ğ‘¡ğ‘–ğ‘œ function differs by\nprocessing the tokens without sorting them. Although this\nlibrary is designed for string matching, researchers have\nfound it very efficient for program similarity detection [24].\n2.4.2. Cosine\nThe cosine similarity function is designed to calculate\nthe similarity between two vectors. This similarity measure\ncan be applied to program similarity calculation by tokenis-\ning the programs into vectors. The steps for performing\ncosine similarity calculation between two programs are as\nfollows:\nâ€¢ Preprocessing and tokenisation: The programme is\nsplitintotokens,removingirrelevantformattingsym-\nbols.\nâ€¢ Construct Frequency Vector: Iterate through the\ntokensgeneratedintheprevioussteptocreateatoken\nfrequency vector for each program.\nâ€¢ Similarity Score Calculation: The similarity be-\ntween two programmes is calculated using Eq. 1. In\nthis equation, the token frequency vectors from the\nprevious step are denoted as vectorsğ€ and ğ.\ncos(ğ€,ğ) = ğ€ â‹… ğ\nâ€–ğ€â€–â€–ğâ€– =\nâˆ‘ğ‘›\nğ‘–=1 ğ€ğ‘–ğğ‘–\nâˆšâˆ‘ğ‘›\nğ‘–=1 (ğ€ğ‘–)2\nâˆšâˆ‘ğ‘›\nğ‘–=1 (ğğ‘–)2\n(1)\n2.4.3. CCFinder\nCCFinder is a token-level code clone detection tool\ndesigned by Kamiya et al. [12]. It processes the programme\nusing the following steps to identify code clones: (i) Lex-\nical Analysis: The programme is tokenised by applying\nlanguage-specific lexical rules. (ii) Transformation: Each\ntoken from the previous step is transformed into a standard\nexpression to enable the system to identify code clones\nwith diverse expressions. (iii) Clone Matching: The main\ntechnique for identification leverages a suffix-tree matching\nalgorithm.(iv)Formatting:Eachclonepairisformattedand\nreported in this final step.\nThe tool is designed to identify code clones in large\nsource codebases. Considering that the programs for simi-\nlaritycalculationinthisresearcharefairlysmall,weapplied\nthe following adjustments to meet our requirements.\nâ€¢ Since CCFinder reports code clones rather than pro-\nvidingasimilarityscore,thefollowingequation(Eq.2)\nwas introduced to calculate the similarity score of the\nidentified clones. In this equation, the length of the\nclonedcodeisdividedbythelengthofthesourcecode\nto generate the similarity score.\nğ‘†ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿğ‘–ğ‘¡ğ‘¦(ğ‘,ğ‘) = ğ¿ğ‘’ğ‘›(ğ¶ğ‘™ğ‘œğ‘›ğ‘’(ğ‘,ğ‘))\nğ‘€ğ‘ğ‘¥(ğ¿ğ‘’ğ‘›(ğ‘),ğ¿ğ‘’ğ‘›(ğ‘)) (2)\nhere ğ¶ğ‘™ğ‘œğ‘›ğ‘’(ğ‘,ğ‘) denotes the longest code clone be-\ntween two programsğ‘ and ğ‘, whileğ¿ğ‘’ğ‘›(ğ‘) denotes\nthe length (i.e., number of characters) of the program\nğ‘.\nâ€¢ This research simplified the suffix-tree matching al-\ngorithm by calculating the common token length be-\ntween two code snippets using a two-dimensional\ntoken matrix. Each dimension represents the token\nsequence of the program.\nâ€¢ The code clone reporting step is removed as only the\nsimilarity score is needed for this research.\n2.4.4. SIM\nGitchell et al. [8] proposed a plagiarism detection tool\ncalledSIM,designedfordetectingplagiarisminCprogram-\nmingcourseassignments.Thetoolutilisesastringalignment\nalgorithmatthetokenleveltodetectsimilarcodestructures.\nThe advantage of the string alignment technique is that it\ncan identify similar code even if the programme sequence\nhas been locally modified.\nThe tool identifies plagiarism using the following steps:\n(i) splitting the programme into tokens and (ii) detecting\nsimilarity using an alignment algorithm. The tokenisation\nstep involves lexical analysis to retain fundamental pro-\ngramme parts such as keywords, identifiers, literals, and\noperators while removing meaningless structural symbols.\nThealignmentalgorithmdividesthesecondtokensequence\ninto multiple segments and uses each segment to align with\nthe first token sequence to calculate the similarity score.\n3. Proposed Approach\nThisstudyfocusesonaddressinggrammar-obeyingpro-\ngramsynthesisproblemsbyproducingcorrectprogramsthat\nadhere to a BNF grammar, thereby restricting the codeâ€™s\nstructureandtheavailablefunctions,methods,andlibraries.\nWe propose (i) prompting several LLMs to generate\nprograms based on a task description, (ii) mapping the\nprogram generated by the LLMs to programs that adhere\nto a predefined BNF grammar, (iii) feeding the mapped\nprogramsasaseedtoourSBMaOG3Pevolutionaryprocess,\nand (iv) performing the SBMaOG3P evolutionary process\nwhichusessimilaritymeasurestowardstheinitialprograms\ngenerated by LLMs as secondary objectives to guide the\nsearch process. All the data and algorithms used in this\nresearch, as well as the tools to run the experiment, are\navailable online1.\nThe overview of our proposed approach is shown in\nFigure 1. Our approach involves prompting 5 LLMs (i.e.,\n1https://github.com/TonBatbaatar/SBMaOG3P\nTao et al.:Preprint submitted to Elsevier Page 3 of 13\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large Language Models and Many-Objective Genetic\nProgramming\nChatGPT,Gemma,LLaMa,MistralandZephyr)togenerate\nprograms based on the provided textual description, and\nthen mapping each of these programs into the predefined\ngrammar.Additionally,ourapproachexpandstheG3Palgo-\nrithmthrough(i)theseedingofthegrammar-mappedLLM-\ngenerated programs into SBMaOG3Pâ€™s initial population\nand (ii) the utilisation of diverse code similarity measures\n(assecondaryobjectives)withinput-outputerrorrate(asthe\nprimary objective) to guide the evolution.\nFigure 1:Overview of Our Approach\n3.1. LLM Code Generation\nLLMs demonstrate exceptional abilities in generating\ncode based on user-provided prompts. Five popular LLMs\n(ChatGPT,Gemma,LLaMa,Mistral,andZephyr)areutilised\nto generate code snippets in two different ways: First, by\nproviding only textual task descriptions, and second, by\nincludingthetaskdescriptionalongwiththeBNFgrammar.\nGiven the high success rate observed in generating code for\nbenchmark problems, the LLMs were queried once for each\nproblem using the default temperature settings.\nArecentstudyhighlightsthesubstantialimpactofinput\nprompt quality on the effectiveness of LLMs [7, 40]. To en-\nsure the quality of the generated code, two different prompt\ntemplates were defined, each following a structured prompt\ntemplate, as shown below. Prompt Template 1 instructs the\nLLM to generate a program based on the taskâ€™s textual\ndescription, whereas Prompt Template 2 provides the LLM\nwith the required grammar alongside the task description.\nPrompt Template 1: Task Only\nMain task:Write a Python function without com-\nment, explanation, and example usage.\nTask description:{input_task_description}\nOutputprogramformat: Functionparametername\nhas to be in0, in1...(depends on how many param-\neters it needs), and return variable name has to be\nres0, res1...(depends on how many parameters it\nneeds).\nPrompt Template 2: Task with Specified Grammar\nMain task:Write a Python function without com-\nment, explanation, and example usage.\nTask description:{input_task_description}\nOutputprogramformat: Functionparametername\nhas to be in0, in1...(depends on how many param-\neters it needs), and return variable name has to be\nres0, res1...(depends on how many parameters it\nneeds).\nOutput program grammar: {in-\nput_task_BNFgrammar}\nFor Prompt Template 1, we start with theMain task,\noutlining the general goal of the query. Following this, the\nTask descriptionsection provides a detailed description of\neach task. Finally, theOutput program formatincludes ad-\nditional structuralinformation toformat theoutputprogram\nforourexperiment.BuildingonPromptTemplate1,Prompt\nTemplate 2 incorporates the specified BNF grammar in the\nOutput program grammarsection.\nNote that although two prompt templates were defined,\nbased on the experimental analysis, which indicates the\nweakness of LLMs when specifying the required grammar\nintheprompt(asdetailedbelow),PromptTemplate1isused\nin the proposed approach.\n3.2. Similarity-Based Many-Objective G3P\nIn this research, a similar Many-Objective G3P algo-\nrithm, proposed by Tao et al. [36], is utilised with the goal\nof guiding the search towards programs that are structurally\nsimilar to a target code. However, in our approach, instead\nof providing a unique target program provided by a fictive\noracleforsimilaritycalculation,weuseprogramsgenerated\nbyfivedistinctLLMs.Theabilitytoleveragemultipletarget\ncodesfromdiverseLLMsmakesouralgorithmscalabletoa\nwider range of problems â€“ taking advantage of the ability\nthat some LLMs have at synthesising programs to some\nspecific tasks while alleviating their limitations on others.\nFigure 2 shows the overview of SBMaOG3P. In ad-\ndition to evaluating input-output error rates, our approach\nincorporates code similarity measures with LLM-generated\ncode as secondary objectives. We considered four different\nsimilarity measures described in Section 2 for our system.\nOur algorithm evaluates a program within the population\nTao et al.:Preprint submitted to Elsevier Page 4 of 13\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large Language Models and Many-Objective Genetic\nProgramming\nFigure 2:Overview of SBMaOG3P\nusing five fitness functions: one primary error-based objec-\ntive and four similarity measures. The algorithm selects the\nhighest similarity score value for each similarity measure\nby comparing it against the programs generated by the five\ndifferent LLMs. However, our approach extends beyond\nmerecorrectnessevaluation.Byintroducingcodesimilarity\nmeasures as secondary objectives, our aim is not solely\nto identify the correct solution but, more importantly, to\nstrategicallysteerthesearchprocesstowardsmoreplausible\nprogram candidates.\nAlthoughSBMaOG3Pusesmultipleobjectivestoevolve\npopulation programs, our method considers a task solved\nby an individual only if it meets the primary objective.\nSpecifically, the individual must correctly pass all test cases\nfor the assigned task.\nIn this research, the tournament selector was adapted to\nhandlemultipleobjectives,enablingthealgorithmtoevolve\nprograms based on diverse criteria. During the selection of\nparents for the next generation, the standard G3P algorithm\nis followed for half of the individuals, with parents chosen\nbased on the input/output error rate. For the other half, one\nparent is selected using the primary objective (error rate)\nand the other using a secondary objective (code similarity).\nSince there are four different similarity measures used as\nsecondary objectives, these measures are evenly rotated\nthrough when selecting parents.\nDeciding which individuals will survive through evolu-\ntionisacrucialaspectofouralgorithm.Similartotheparent\nselection mechanism, we take all objectives into account\nduring this phase. The primary objective determines the\nsurvival of half of the population, while the remaining half\nis decided based on the four similarity measures.\n3.3. Seeding LLM Solutions to SBMaOG3P\nIn our SBMaOG3P approach, individual programs are\nrepresented as symbolic expression trees. Each node in\nthe tree corresponds to a specific code segment, and the\nconnections between nodes capture the structural informa-\ntion. The seeded programs must follow the same grammar\nrules and maintain the same tree structure to enable their\nevolution by SBMaOG3P (i.e., need by genetic operators\nsuch as crossover, mutation, and selection to function cor-\nrectly). Therefore, to seed LLM-generated programs in SB-\nMaOG3P, they must first be adapted to fit the predefined\ngrammar.\nSpecifyingtheBNFgrammarintheLLMprompt(using\nPrompt Template 2) reduced the success rate of LLMs at\nproducingcorrectprograms.TheLLMoftengeneratedcode\nthat did not address the problem description and included\nsnippets outside the defined grammar (see results below for\ndetails).Inresponse,LLM-generatedcodewasseededusing\ntask-only prompts (i.e., Prompt Template 1). A grammar\nmappingalgorithm,proposedin[37],wasusedtotransform\nprograms into ones that adhere to predefined grammars,\nenabling the structured evolution of LLM-generated code.\nThegrammarmappingalgorithmstartsbygeneratingan\nAbstract Syntax Tree (AST) [2] of the provided program.\nThen, it maps the AST into a symbolic expression tree\nfor SBMaOG3P, starting from the root node and iterating\nthroughitschildnodes,andconstructingtheoutputprogram\nrecursively. For each tree node, when there is no grammar\nconflict,thealgorithmconstructstheoutputtree.Otherwise,\nitbuildsoutputwithadummyexpression,whichcanbefur-\nther improved by the genetic programming process during\nevolution.Italsomapsthevariablesandconstants.Whenthe\nnodeisavariableâ€œNameâ€,themappingalgorithmchecksif\nit has previously been mapped, in which case, it maps it to\nthesameone.Ifthevariableâ€œNameâ€hasnotbeenpreviously\nmapped,thealgorithmmapsitusingthefirstunusedvariable\nname with the same data type.\nDuring the mapping process, the LLMs-generated code\nbecomeserroneouscodeduetogrammarconflict.Inthenext\nstep,weseed5grammar-mappedLLM-generatedcodesinto\nthe SBMaOG3Pâ€™s initial population for further fixing. The\nseeding process is demonstrated in the Figure 3.\nTao et al.:Preprint submitted to Elsevier Page 5 of 13\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large Language Models and Many-Objective Genetic\nProgramming\nFigure 3:Overview of SBMaOG3P with Seeding\n4. Experiment Setup\n4.1. Research Questions\nWe evaluate the performance of our approach by at-\ntemptingtoanswerthefollowingResearchQuestions(RQs):\nâ€¢ RQ1:HoweffectiveareLLMsatgrammar-obeying\nprogram synthesis?\nâ€¢ RQ2:CouldweimprovetheperformanceofLLMs\nat grammar-obeying program synthesis using SB-\nMaOG3P?\n4.2. Benchmark Dataset\nHelmuthandSpector[11,10]createdabenchmarksuite\nfor program synthesis problems, which contains 29 prob-\nlemsselectedfromintroductory-levelprogrammingcourses.\nThis benchmark suite provides detailed natural language\ndescriptionsforeachproblem,aswellastrainingandtesting\nsets. Four problems with its task description are shown in\nTable 1. Table 2 indicates the number of train and test cases\nfor each problem. In this research, our proposed system is\nevaluated with 28 problems from this benchmark suite. One\nproblem named â€œString Differencesâ€ is removed from our\nexperiment as in previous work by Forstenlechner [5]. The\noriginalbenchmarkprogramtestedwithPushGPoftenprints\nthe result, whereas in G3P, the results are return values.\nConsequently, the â€œString Differencesâ€ problem is excluded\nbecause it requires multiple return values with different\ndata types that our grammar cannot accommodate. In this\nexperiment,thesamegrammardefinedbyForstenlechneret\nal. [5]2 is used.\nNotethat,sinceLLMsarebeingused,thereisariskthat\nthe benchmark dataset may have already been included in\nthe training data of these models. However, this does not\nposeaproblemforourstudy.Eveniftheproblemsandtheir\ncorresponding code have been leaked, it is unlikely that the\n2Available at: https://github.com/t-h-e/HeuristicLab.CFGGP/tree/\nmaster/HeuristicLab.Problems.Instances.CFG/GrammarConstruction\nTable 1\nDescription of Four Example Problems in the Dataset\nProblem\nName\nDescription\nDouble Letters Given a string, print the string,\ndoubling every letter character, and\ntripling every exclamation point.\nAll other non-alphabetic and non-\nexclamation characters should be\nprinted a single time each.\nCollatz Num-\nbers\nGiven an integer, find the number\nof terms in the Collatz (hailstone)\nsequence starting from that integer.\nReplace Space\nwith Newline\nGiven a string input, print the string,\nreplacing spaces with newlines. Also,\nreturn the integer count of the\nnon-whitespace characters. The input\nstring will not have tabs or newlines.\nString Lengths\nBackwards\nGiven a vector of strings, print the\nlength of each string in the vector\nstarting with the last and ending with\nthe first.\ngrammars we use have also been leaked. This is evident\nfrom our experiments, where we observe that most of the\nLLM-generated code does not conform to the predefined\ngrammars. Therefore, while the generated code is often\ninteresting, it is not grammatically correct.\n4.3. Generating Programs Using LLMs\nUnlike PushGP, each individual in our SBMaOG3P al-\ngorithm is a code snippet (i.e., a function) rather than a\ncomplete program with a console output. The SBMaOG3P\nalgorithmevaluateseachindividualbycalculatingthefitness\nvalue based on the functionâ€™s return value compared to the\nexpected output of the test case. However, the benchmark is\ndesignedtooutputresultstotheconsole,whichisunsuitable\nfor our experiment. Using such program descriptions as\nTao et al.:Preprint submitted to Elsevier Page 6 of 13\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large Language Models and Many-Objective Genetic\nProgramming\nTable 2\nNumber of Train and Test Cases for Each Problem in the\nDataset\nName Train Test\nNumber IO 25 1000\nSmall Or Large 100 1000\nFor Loop Index 100 1000\nCompare String Lengths 100 1000\nDouble Letters 100 1000\nCollatz Numbers 200 2000\nReplace Space with Newline 100 1000\nEven Squares 100 1000\nWallis Pi 150 50\nString Lengths Backwards 100 1000\nLast Index of Zero 150 1000\nVector Average 100 1000\nCount Odds 200 2000\nMirror Image 100 1000\nSuper Anagrams 200 2000\nSum of Squares 50 50\nVectors Summed 150 1500\nX-Word Lines 150 2000\nPig Latin 200 1000\nNegative To Zero 200 2000\nScrabble Score 200 1000\nWord Stats File 100 1000\nChecksum 100 1000\nDigits 100 1000\nGrade 200 2000\nMedian 100 1000\nSmallest 100 1000\nSyllables 100 1000\nprompts for LLMs often results in programs with print\nstatementsinsteadoffunctionreturns.Toadapttheproblem\ndescriptions to our needs, we modified them to specify that\nthe program should return a value from a function instead\nof using aprint statement. For example, we replaced the\nkeyword â€œprintâ€ with â€œreturnâ€ in the task descriptions. The\nmodified problem descriptions are available online3.\n4.4. Parameter Settings\nAll five LLMs (ChatGPT, Zephyr4, Mistral5, Gemma6\nandLLaMa7)areusedwiththedefaulttemperaturesettings,\nand the version of each LLM is detailed in Table 3. we\nuse the standard G3P parameter settings as used in previous\nstudu [5]. We ran the evolution for each program synthesis\ntask 30 times. The benchmark suite suggested using 300\ngenerations for most tasks, while for straightforward syn-\nthesis tasks (â€œMedianâ€, â€œNumber IOâ€, and â€œSmallestâ€), 200\n3Available at: https://github.com/TonBatbaatar/SBMaOG3P/blob/main/\nProblem_Edited.csv\n4Available at: https://huggingface.co/HuggingFaceH4/\nzephyr-orpo-141b-A35b-v0.1\n5Available at: https://huggingface.co/mistralai/\nMistral-7B-Instruct-v0.2\n6Available at:https://huggingface.co/google/gemma-1.1-7b-it\n7Available at: https://huggingface.co/meta-llama/\nMeta-Llama-3-70B-Instruct\nTable 3\nExperiment Parameter Settings\nParameter Setting\nRuns 30\nGeneration 300 a\nPopulation size 1000\nTournament size 7\nCrossover probability 0.9\nMutation probability 0.05\nNode limit 250\nVariable per type 3\nMax execution time (s) 1\nChatGPT version GPT4\nZephyr version zephyr-orpo-141b-A35b-v0.1\nMistral version Mistral-7B-Instruct-v0.2\nGemma version gemma-1.1-7b-it\nLLaMa version Meta-Llama-3-70B-Instruct\na200 generations for â€œMedianâ€, â€œNumber IOâ€, and â€œSmallestâ€ as\nin [11]\ngenerations are enough. Other settings for our SBMaOG3P\nsystems are indicated in Table 3.\n5. Result\n5.1. Effectiveness of LLM at Grammar-Obeying\nProgram Synthesis (RQ1)\nTheeffectivenessofLLMsingrammar-obeyingprogram\nsynthesis is analysed by comparing the selected LLMs and\nG3Pwithtournamentselectiononbenchmarkproblems.The\nresults are presented in Table 4. Each LLM is evaluated\ntwice: once using the task-only prompt and once using the\nprompt with the task description and the specified BNF\ngrammar. For LLMsâ€™ solutions, a regular checkmark (/)\nindicatesthattheapproachsuccessfullysolvedthetaskusing\ntheBNFgrammar.Acirclecheckmark( )signifiesthatthe\napproach solved the task using a grammar not permitted by\nthe BNF grammar. A cross symbol (/reve) indicates that the\napproach failed to find a solution for the task. For the G3P\nalgorithm, a problem is marked with a regular checkmark\n(/)ifatleastonecorrectsolutionisfoundwithin100runs.\nConversely, if the G3P algorithm fails to evolve a correct\nsolution within 100 runs, it is marked unsuccessful (/reve).\nThe experiment demonstrates that LLMs performed ex-\nceptionally well in the program synthesis task. At least one\nLLM found correct solutions for 27 out of the 28 problems\nconsidered. Only one problem, â€œWallis Pi,â€ remained un-\nsolved, as the LLMs generated programs that calculate the\nvalue ofğœ‹\n2 orğœ‹instead ofğœ‹\n4 .\nTao et al.:Preprint submitted to Elsevier Page 7 of 13\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large Language Models and Many-Objective Genetic\nProgramming\nTable 4\nComparison of LLMs and G3P on Benchmark Problems\nBenchmark Problem G3P LLMs - Task Only LLMs - Task with Specified Grammar\nChatGPT Gemma LLaMa Mistral Zephyr ChatGPT Gemma LLaMa Mistral Zephyr\nNumber IO / / / / / / / /reve/ /reve/reve\nSmall Or Large / / / / / /reve\nFor Loop Index /reve / / / /reve/ /reve\nCompare String Lengths /reve / / /reve/reve\nDouble Letters /reve / /reve /reve\nCollatz Numbers /reve / / / / /reve/reve/reve/reve\nReplace Space with Newline/ / /reve / /\nEven Squares /reve /reve/reve\nWallis Pi /reve/reve/reve/reve/reve/reve/reve/reve/reve/reve/reve\nString Lengths Backwards/ /reve /reve\nLast Index of Zero / /reve/reve\nVector Average /reve /reve\nCount Odds / / / / / / \nMirror Image / /reve /reve\nSuper Anagrams /reve /reve /reve\nSum of Squares /reve / /reve/ /reve\nVectors Summed /reve /reve/ /reve/reve\nX-Word Lines /reve /reve/reve /reve/reve\nPig Latin /reve /reve /reve\nNegative To Zero / / / /reve/reve\nScrabble Score /reve /reve /reve /reve/ /reve\nWord Stats /reve /reve/reve/reve /reve /reve\nChecksum /reve /reve/ / \nDigits /reve/reve/reve /reve/reve/reve/reve /reve/reve\nGrade / / / / /reve\nMedian / /reve /reve/reve\nSmallest / / /\nSyllables / / / /reve / \nNumber of Problems Solved12 2 (24)a 5 (19)a 5 (21)a 3 (20)a 4 (22)a 10 (15)a 1 (11)a 11 (14)a 3 (3)a 2 (14)a\na number in the bracket indicates the problem solved using a grammar not permitted by the BNF grammar\nTao et al.:Preprint submitted to Elsevier Page 8 of 13\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large Language Models and Many-Objective Genetic\nProgramming\nTheperformanceoftheLLMswetestedisquitecompa-\nrable: ChatGPT, LLaMa, and Zephyr each solved 26 prob-\nlems, Gemma solved 24 problems, and Mistral solved 23\nproblems.However,theperformanceofLLMsongrammar-\nobeying program synthesis varies significantly. All five\nLLMs,whenpromptedwithonlythetaskdescription,solved\nno more than five problems obeying the BNF grammar.\nThe ability to generate code obeying the BNF grammar\nslightly improved for ChatGPT and LLaMa when using a\nprompting template that included both the task description\nandthespecifiedgrammar.Wealsoobservedthatprompting\nwith grammar reduced the code quality and the number of\nproblems for which the LLMs generated correct solutions.\nTherefore, we decided to seed the LLMsâ€™ generated code\nby mapping the grammar for the subsequent SBMaOG3P\nexperiments.\nIt is uncertain whether the impressive performance of\nLLMsinprogramsynthesisisduetothebenchmarkdatasets\nalready being included in their training data. However, we\ncan assert that the grammar of these problems was not\nleaked into the training set, considering that most LLMs\ngenerate programs using grammar rules not permitted by\nthe predefined BNF grammar. Therefore, while LLMs are\nproficientatprogramsynthesis,theystrugglewithgrammar-\nobeying program synthesis. Solution programs obtained by\nLLMs are available online8.\n5.2. Performance of Proposed Approach (RQ2)\nSince the proposed approach combines several compo-\nnents, its performance is assessed in two steps to identify\nthecontributionofeach:(i)theperformanceofthegrammar-\nmappingalgorithmand(ii)theperformanceofSBMaOG3P.\n5.2.1. Performance of the Grammar Mapping\nAlgorithm\nIn this subsection, the performance of the grammar\nmapping algorithm is analysed. All the code snippets gen-\nerated by the LLMs were successfully mapped to code that\nadheres to the BNF grammar. However, some information\nwas omitted due to grammar conflicts between the LLMsâ€™\ngenerated code and the predefined BNF grammar. Table 5\nsummarises each solutionâ€™s grammar mapping status for all\nconsidered LLMs. When the algorithm is able to map the\nLLMsâ€™ generated code without any grammar conflict, we\nmarkthemappingprocesswitharegularcheckmark( /).If\nthereisminorinformationlossduringthemappingprocess,\nwe indicate the mapping status with a circle checkmark\n(). If the mapping retains minimal information from the\nLLMsâ€™generatedcodeduetosignificantgrammarconflicts,\nwe mark it with a cross (/reve). The results show that the\nsolutions generated by ChatGPT and Zephyr are mapped\nwith relatively good information retention among the five\nconsidered LLMs. The mapping performance for solutions\nproduced by Gemma is poor because it fails to meet the\nrequired format in terms of code structure and the naming\n8Available at:https://github.com/TonBatbaatar/SBMaOG3P\nscheme of input parameters. By analysing the grammar-\nmappedcode,thegrammarconflictsaresummarisedintothe\nfollowing main categories:\nâ€¢ Wrong Code structure: The code for seeding re-\nquires a fixed number of variables in thereturn state-\nmentinsteadofusingafunctionorexpressiondirectly\nin thereturn statement.\nâ€¢ Violates Naming Scheme: The LLMsâ€™ generated\ncode snippet must follow the naming scheme for the\nfunctionâ€™sinputparametersasspecifiedintheprompt.\nâ€¢ Function/Library Mismatch: The LLMsâ€™ generated\ncodeoftenincludesfunctionsandlibrariesnotdefined\nin the BNF grammar. Even for functions that are de-\nfined in the BNF grammar, the number of parameters\noften mismatches.\nâ€¢ AdvancedPythonGrammar :TheLLMsoftensolve\nthe task using advanced Python grammar, such as\nlist comprehension, which is not defined in the BNF\ngrammar.\nâ€¢ DataTypeConflict :Thedatatypethatcanbeusedfor\neach problem is defined within the problemâ€™s gram-\nmar. When LLM-generated code uses data types that\nare not allowed for the current problem, the grammar\nmapping algorithm cannot map them.\n5.2.2. Performance of SBMaOG3P\nTheproposedapproachwasevaluatedbycomparingthe\nperformance of three distinct G3P variants: (1) G3P with\ntournament selection without seeding proposed by Forsten-\nlechneretal.[5,6],(2)thestate-of-the-artgrammar-obeying\nprogram synthesis algorithm (named SBMaOG3Pğ¶â„ğ‘ğ‘¡ğºğ‘ƒğ‘‡ )\nproposed by Tao et al. [33], and (3) our proposed algorithm\n(named SBMaOG3P5ğ¿ğ¿ğ‘€ğ‘ ).\nSBMaOG3Pğ¶â„ğ‘ğ‘¡ğºğ‘ƒğ‘‡ and SBMaOG3P5ğ¿ğ¿ğ‘€ğ‘  both use\ngrammar-mapped seeds in the initial population and utilise\ncodesimilarityassecondaryobjectives.Themaindifference\nbetween these two approaches is that SBMaOG3Pğ¶â„ğ‘ğ‘¡ğºğ‘ƒğ‘‡\nseeds only one grammar-mapped code generated by Chat-\nGPT and calculates the code similarity using the ChatGPT-\ngeneratedcodeasthetarget.Incontrast,SBMaOG3P 5ğ¿ğ¿ğ‘€ğ‘ \nseeds grammar-mapped programs generated by five LLMs\nandcalculatesthesimilarityscorebychoosingthemaximum\nsimilarity value using the five target codes.\nEach algorithm was run 30 times on the benchmark\ndataset, and the number of successful runs is reported in\nTable 6. A run is considered successful when the evolution\nfindsatleastonecorrectsolutionthatpassesalltrainingand\ntest cases.\nOverall,theproposedSBMaOG3P 5ğ¿ğ¿ğ‘€ğ‘  performedthe\nbest in both the number of solved problems and the success\nrate.Specifically,theproposedapproachsolved21problems\nwhile adhering to the predefined BNF grammar, which is 9\nmore problems solved compared to the G3P approach and 5\nmore problems compared to the SBMaOG3Pğ¶â„ğ‘ğ‘¡ğºğ‘ƒğ‘‡ .\nTao et al.:Preprint submitted to Elsevier Page 9 of 13\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large Language Models and Many-Objective Genetic\nProgramming\nTable 5\nGrammar Mapping Status For LLM-generated code\nBenchmark Problem ChatGPT Zephyr Mistral Gemma LLaMa\nNumberIO / / / /reve/\nSmall Or Large / / /reve/\nFor Loop Index / /reve/\nCompare String Lengths / /reve/reve/reve/\nDouble Letters / / /reve/\nCollatz Numbers / /reve /\nReplace Space with Newline / /reve\nEven Squares / /reve/reve/reve\nWallis Pi / / / \nString Lengths Backwards /reve /reve/reve/reve\nLast Index of Zero /reve/reve\nVector Average /reve/reve/reve\nCount Odds / /reve/ / /reve\nMirror Image / /reve/reve/reve\nSuper Anagrams /reve/reve/reve/reve/reve\nSum of Squares /reve/ /reve/reve/reve\nVectors Summed /reve/ /reve/reve\nX-Word Lines /reve/reve/reve/reve/reve\nPig Latin /reve /reve/\nNegative To Zero /reve/ /reve/reve/reve\nScrabble Score /reve/ /reve/reve/reve\nWord Stats /reve/reve/reve/reve/reve\nChecksum /reve/ /reve/reve/reve\nDigits / / /reve/reve/reve\nGrade / / /reve/reve/\nMedian / /reve/reve/reve/reve\nSmallest / /reve/reve/reve/reve\nSyllables / /reve/reve/reve/reve\nNumber of informative mapa 18 20 10 3 10\na Sum of mapping without information loss or minor information loss\nWhile the proposed approach did not evolve correct\nsolutions for the program synthesis task as effectively as\npopular LLMs, it excelled in grammar-obeying program\nsynthesis. Notably, by seeding grammar-mapped programs\ngenerated using prompts without specifying grammar, our\napproach successfully corrected LLM-generated solutions\nthat violated the grammar for 14 problems. Even compared\nto the solutions generated by LLMs prompted with the task\ndescription and the BNF grammar, our approach evolved\nprograms that fit the BNF grammar for 7 more problems.\nHowever, it failed to address the unsolved problem (â€œWallis\nPiâ€) in its default configuration.\nThe proposed approach evolved correct solutions for 21\nproblems, leaving 7 problems unsolved with the current\nconfiguration. We further examined the reasons for each\nunsuccessful problem.\nâ€¢ Wallis Pi: Although the seeded grammar-mapped\nLLM code was close to the correct solution (generat-\ningcodeforcalculating ğœ‹\n2 insteadof ğœ‹\n4 ),theevolution\ndid not correct the code with its default settings. We\nbelieve that increasing the computational power (i.e.,\nincreasing the number of generations) could enable\nthe evolution process to fix the erroneous code.\nâ€¢ Vector Average:For this problem, our proposed al-\ngorithmdidnotgainhelpfulinformationfromseeding\nsince all five LLMsâ€™ generated codes utilised theSum\nfunction,whichisnotsupportedbytheBNFgrammar.\nâ€¢ SuperAnagrams:Similartothepreviousproblem,all\nfive LLMsâ€™ seeds utilised advanced Python grammar\n(i.e.,listcomprehension)totacklethisproblem,which\nis not allowed in the BNF grammar.\nâ€¢ X-word lines, Word Stats:A large grammar con-\nflict involving the use of data types prevented our\nalgorithm from evolving a correct solution for these\ntwo string analysis problems. Specifically, all LLMsâ€™\nsolutions split the text using theSplit function and\nstored it in a list variable. However, the list variable\nis not provided in the BNF grammar for these two\nproblems, and theSplit function is defined within a\nfor loop that can not be used separately.\nTao et al.:Preprint submitted to Elsevier Page 10 of 13\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large Language Models and Many-Objective Genetic\nProgramming\nTable 6\nComparison of Proposed SBMaOG3P5ğ¿ğ¿ğ‘€ğ‘  Against State-of-the-Art System â€“ SBMaOG3Pğ¶â„ğ‘ğ‘¡ğºğ‘ƒğ‘‡ , and G3P\nBenchmark Problem G3P SBMaOG3P LLMs - Task Only LLMs - Task with Specified Grammar\nChatGPT 5 LLMs ChatGPT Gemma LLaMa Mistral Zephyr ChatGPT Gemma LLaMa Mistral Zephyr\nNumber IO 17 30 30 / / / / / / /reve/ /reve/reve\nSmall Or Large 0 30 30 / / / / /reve\nFor Loop Index 0 30 30 / / / /reve/ /reve\nCompare String Lengths 0 30 30 / / /reve/reve\nDouble Letters 0 30 30 / /reve /reve\nCollatz Numbers 0 30 30 / / / / /reve/reve/reve/reve\nReplace Space with Newline 1 12 30 / /reve / /\nEven Squares 0 0 30 /reve/reve\nWallis Pi 0 0 0 /reve/reve/reve/reve/reve/reve/reve/reve/reve/reve\nString Lengths Backwards 3 4 4 /reve /reve\nLast Index of Zero 6 30 30 /reve/reve\nVector Average 0 0 0 /reve\nCount Odds 0 30 30 / / / / / \nMirror Image 20 30 30 /reve /reve\nSuper Anagrams 0 0 0 /reve /reve\nSum of Squares 0 0 30 / /reve/ /reve\nVectors Summed 0 0 30 /reve/ /reve/reve\nX-Word Lines 0 0 0 /reve/reve /reve/reve\nPig Latin 0 0 30 /reve /reve\nNegative To Zero 1 3 30 / / /reve/reve\nScrabble Score 0 0 0 /reve /reve /reve/ /reve\nWord Stats 0 0 0 /reve/reve/reve /reve /reve\nChecksum 0 0 3 /reve/ / \nDigits 0 0 0 /reve/reve /reve/reve/reve/reve /reve/reve\nGrade 0 30 30 / / / /reve\nMedian 12 30 30 /reve /reve/reve\nSmallest 28 30 30 / /\nSyllables 0 30 30 / / /reve / \nNumber of Problems Solved 8 16 21 2 (24)a 5 (18)a 5 (21)a 3 (20)a 4 (22)a 10 (15)a 1 (11)a 11 (14)a 3 (3)a 2 (14)a\na number in the bracket indicates the problem solved using a grammar not permitted by the BNF grammar\nTao et al.:Preprint submitted to Elsevier Page 11 of 13\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large Language Models and Many-Objective Genetic\nProgramming\nTable 7\nThe P-value for the Wilcoxon Rank Sum Test Using\nBest Fitness of Each Run Comparing G3P and Proposed\nSBMaOG3P5ğ¿ğ¿ğ‘€ğ‘ \nProblem p-value\nNumberIO 0.034843\nLast Index of Zero 0.000751\nSmall Or Large 0.000062\nVector Average 0.143140\nFor Loop Index 0.000064\nCount Odds 0.000064\nCompare String Lengths 0.000033\nMirror Image 0.077872\nDouble Letters 0.000055\nSuper Anagrams 0.377587\nCollatz Numbers 0.000063\nSum of Squares 0.000064\nReplace Space with Newline 0.000224\nVectors Summed 0.000064\nEven Squares 0.000064\nX-Word Lines 0.795936\nWallis Pi 0.357296\nPig Latin 0.000064\nString Lengths Backwards 0.018616\nNegative To Zero 0.000228\nDigits 0.000064\nScrabble Score 0.421242\nGrade 0.000064\nWord Stats 0.279861\nMedian 0.005943\nChecksum 0.019464\nSmallest 0.168078\nSyllables 0.000064\nâ€¢ ScrabbleScore: Thisproblemassignsascoretoeach\nletterinastring,withthescoresstoredinalistaccord-\ningtotheBNFgrammar.WithoutprovidingtheLLMs\nwiththeformatofhowsuchascoreboardisdefinedin\nthegrammar,theirsolutionscannotgenerateahelpful\nseedingprogramtohandlethescoreboard.Thismakes\nthe seeding program inefficient in evaluating the cor-\nrect solution.\nâ€¢ Digits: This problem requires splitting digits from a\ngiven number. Similar to the â€œWallis Piâ€ problem,\nthe LLMsâ€™ seeds were close to the correct solution.\nHowever, they failed to handle negative numbers,\nwhich requires assigning a negative sign to the least\nsignificant digit.\nTheWilcoxonRankSumtestwasperformedonthebest\ntest fitness value (error-rated fitness value for SBMaOG3P)\nfrom each run of G3P and the proposed approach to deter-\nmine whether significant improvements in code generation\nperformanceexist.Table7showstheresultoftheWilcoxon\nRank Sum test. In the measurement, we used 0.05 as the\nthreshold for the significance level, and significant results\nare highlighted in the table.\nThe proposed approach significantly improved the so-\nlution in terms of the best fitness value of each run for\n21 problems compared to G3P with tournament selection.\nSurprisingly, we observed a significant improvement in the\nâ€œDigitsâ€ problem, even though the problem remained un-\nsolvedwithourapproach.Thisfurthersupportstheideathat\nhighercomputationalcosts(i.e.,moregenerationsandlarger\npopulation sizes) might improve the chances of solving the\nproblem.\n6. Conclusion and Future Work\nThis study proposed SBMaOG3P, which leverages code\ngenerated by five distinct LLMs (i.e., ChatGPT, Zephyr,\nGemma, LLaMa and Mistral) to tackle grammar-obeying\nprogram synthesis tasks by evolving programs that are syn-\ntacticallycorrectandadheretoaBNFgrammar.Byrestrict-\ning the grammar rules of the program, it is ensured that\nthe algorithm generates higher-quality programs without\nsecurity threats.\nThe proposed approach utilised LLM-generated code\nin two ways: (i) leveraging the similarity to the programs\ngenerated by LLMs and (ii) using the programs generated\nby the LLMs as seeds for the evolutionary process, with the\ngrammar mapped to fit the BNF grammar.\nAcomprehensiveevaluationoftheproposedmethodwas\nconductedusingtheGeneralProgramSynthesisBenchmark\nSuite 1. The experimental results indicate that the approach\nsuccessfully evolves accurate and grammar-compliant pro-\ngramsforvariousgrammar-obeyingprogramsynthesistasks,\noutperforming the state-of-the-art grammar-obeying pro-\ngram synthesis systems. However, there is still room for\nimprovement, as in its default setup, SBMaOG3P does not\nachieve the success rate of LLMs when the grammar-fitting\nconstraint is disregarded.\nIn our future research, we aim to improve the grammar\nmapping algorithm to support a wider variety of data struc-\ntures,therebymaximisingtheuseofgrammar-mappedcode\nin the evolutionary process. We also plan to evaluate the\nqualityofthecodegeneratedbyourapproach.Additionally,\nweintendtoexploretheimpactofemployingvariousmulti-\nobjective optimisation algorithms within SBMaOG3P.\nAcknowledgement\nThisworkwassupportedbyScienceFoundationIreland\ngrant 13/RC/2094_P2 to Lero - the Science Foundation\nIreland Research Centre for Software (www.lero.ie).\nReferences\n[1] O. Asare, M. Nagappan, and N. Asokan. Is githubâ€™s copilot as bad\nashumansatintroducingvulnerabilitiesincode? EmpiricalSoftware\nEngineering, 28(6):129, 2023.\n[2] I. D. Baxter, A. Yahin, L. Moura, M. Santâ€™Anna, and L. Bier. Clone\ndetection using abstract syntax trees. InICSME. IEEE, 1998.\n[3] M. Brameier, W. Banzhaf, and W. Banzhaf.Linear genetic program-\nming. Springer, 2007.\nTao et al.:Preprint submitted to Elsevier Page 12 of 13\nGrammar-Obeying Program Synthesis: A Novel Approach Using Large Language Models and Many-Objective Genetic\nProgramming\n[4] A. Cohen. Fuzzywuzzy: Fuzzy string matching in python, 2011.\n[5] S.Forstenlechner,D.Fagan,M.Nicolau,andM.Oâ€™Neill. Agrammar\ndesign pattern for arbitrary program synthesis problems in genetic\nprogramming. InGeneticProgramming:20thEuropeanConference,\nEuroGP2017,Amsterdam,TheNetherlands,April19-21,2017,Pro-\nceedings 20, pages 262â€“277. Springer, 2017.\n[6] S. Forstenlechner, D. Fagan, M. Nicolau, and M. Oâ€™Neill. Extending\nprogram synthesis grammars for grammar-guided genetic program-\nming. InPPSN. Springer, 2018.\n[7] T. Gao, A. Fisch, and D. Chen. Making pre-trained language models\nbetter few-shot learners.arXiv, 2020.\n[8] D. Gitchell and N. Tran. Sim: a utility for detecting similarity in\ncomputer programs.ACM Sigcse Bulletin, 1999.\n[9] B. Hartmann, D. MacDougall, J. Brandt, and S. R. Klemmer. What\nwouldotherprogrammersdo:suggestingsolutionstoerrormessages.\nInSIGCHI, 2010.\n[10] T.HelmuthandL.Spector. Detailedproblemdescriptionsforgeneral\nprogram synthesis benchmark suite. InUniversity of Massachusetts\nAmherst, 2015.\n[11] T. Helmuth and L. Spector. General program synthesis benchmark\nsuite. InGECCO, 2015.\n[12] T. Kamiya, S. Kusumoto, and K. Inoue. Ccfinder: A multilinguistic\ntoken-based code clone detection system for large scale source code.\nTSE, 2002.\n[13] J.R.Koza. GeneticprogrammingII:automaticdiscoveryofreusable\nprograms. MIT press, 1994.\n[14] S. Krishna, C. Agarwal, and H. Lakkaraju. Understanding the effects\nof iterative prompting on truthfulness.arXiv, 2024.\n[15] T.-O. Li, W. Zong, Y. Wang, H. Tian, Y. Wang, S.-C. Cheung, and\nJ. Kramer. Nuances are the key: Unlocking chatgpt to find failure-\ninducing tests with differential prompting. InIEEE/ACM ASE, pages\n14â€“26, 2023.\n[16] D. Lynch, T. Saber, S. Kucera, H. Claussen, and M. Oâ€™Neill. Evo-\nlutionary learning of link allocation algorithms for 5g heterogeneous\nwireless communications networks. InGECCO, 2019.\n[17] W. Ma, S. Liu, W. Wenhan, Q. Hu, Y. Liu, C. Zhang, L. Nie, and\nY. Liu. The scope of chatgpt in software engineering: A thorough\ninvestigation. arXiv, 2023.\n[18] J. Manyika and S. Hsiao. An overview of bard: an early experiment\nwith generative ai.AI. Google Static Documents, 2, 2023.\n[19] J. F. Miller and S. L. Harding. Cartesian genetic programming. In\nGECCO, 2008.\n[20] S.Minaee,T.Mikolov,N.Nikzad,M.Chenaghlu,R.Socher,X.Am-\natriain, and J. Gao. Large language models: A survey, 2024.\n[21] M. Oâ€™Neill, M. Nicolau, and A. Agapitos. Experiments in program\nsynthesis with grammatical evolution: A focus on integer sorting. In\nIEEE CEC, 2014.\n[22] OpenAI. Gpt-4 technical report, 2023.\n[23] M. Oâ€™Neill and C. Ryan. Grammatical evolution: Evolutionary\nautomatic programming in a arbitrary language, volume 4 of genetic\nprogramming, 2003.\n[24] C. Ragkhitwetsagul, J. Krinke, and D. Clark. A comparison of code\nsimilarity analysers.ESE, 2018.\n[25] T.Saber,D.Fagan,D.Lynch,S.Kucera,H.Claussen,andM.Oâ€™Neill.\nAhierarchicalapproachtogrammar-guidedgeneticprogrammingthe\ncase of scheduling in heterogeneous networks. InTPNC, 2018.\n[26] T.Saber,D.Fagan,D.Lynch,S.Kucera,H.Claussen,andM.Oâ€™Neill.\nMulti-level grammar genetic programming for scheduling in hetero-\ngeneous networks. InEuroGP, 2018.\n[27] T.Saber,D.Fagan,D.Lynch,S.Kucera,H.Claussen,andM.Oâ€™Neill.\nHierarchical grammar-guided genetic programming techniques for\nscheduling in heterogeneous networks. InIEEE CEC, 2020.\n[28] T.Saber,D.Fagan,D.Lynch,S.Kucera,H.Claussen,andM.Oâ€™Neill.\nA multi-level grammar approach to grammar-guided genetic pro-\ngramming:thecaseofschedulinginheterogeneousnetworks. GPEM,\n2019.\n[29] T.SaberandS.Wang. Evolvingbetterreroutingsurrogatetravelcosts\nwith grammar-guided genetic programming. InIEEE CEC, 2020.\n[30] R.Schuster,C.Song,E.Tromer,andV.Shmatikov.Youautocomplete\nme: Poisoning vulnerabilities in neural code completion. InUSENIX\nSecurity 21, pages 1559â€“1575, 2021.\n[31] K. Stechly, M. Marquez, and S. Kambhampati. Gpt-4 doesnâ€™t know\nitâ€™swrong:Ananalysisofiterativepromptingforreasoningproblems.\narXiv, 2023.\n[32] N. Surameery and M. Shakor. Use chat gpt to solve programming\nbugs. IJITCE, pages 17â€“22, 01 2023.\n[33] N. Tao, A. Ventresque, V. Nallur, and T. Saber. Enhancing program\nsynthesiswithlargelanguagemodelsusingmany-objectivegrammar-\nguided genetic programming.Algorithms, 17(7):287, 2024.\n[34] N. Tao, A. Ventresque, and T. Saber. Assessing similarity-based\ngrammar-guided genetic programming approaches for program syn-\nthesis. InOLA. Springer, 2022.\n[35] N.Tao,A.Ventresque,andT.Saber.Multi-objectivegrammar-guided\ngenetic programming with code similarity measurement for program\nsynthesis. InIEEE CEC, 2022.\n[36] N.Tao,A.Ventresque,andT.Saber.Many-objectivegrammar-guided\ngenetic programming with code similarity measurement for program\nsynthesis. InIEEE LACCI, 2023.\n[37] N. Tao, A. Ventresque, and T. Saber. Program synthesis with\ngenerativepre-trainedtransformersandgrammar-guidedgeneticpro-\ngramming grammar. InLA-CCI, pages 1â€“6. IEEE, 2023.\n[38] B. Wang, Z. Wang, X. Wang, Y. Cao, R. A Saurous, and Y. Kim.\nGrammar prompting for domain-specific language generation with\nlarge language models.Advances in Neural Information Processing\nSystems, 36, 2024.\n[39] P. A. Whigham. Grammatical bias for evolutionary learning.PhD\nThesis, University College, Australian Defence Force Academy, Uni-\nversity of New South Wales, Canberra, 1997.\n[40] J. White, Q. Fu, S. Hays, M. Sandborn, C. Olea, H. Gilbert, A. El-\nnashar, J. Spencer-Smith, and D. C. Schmidt. A prompt pattern\ncatalog to enhance prompt engineering with chatgpt.arXiv, 2023.\n[41] Z. Xie, Y. Chen, C. Zhi, S. Deng, and J. Yin. Chatunitest: a chatgpt-\nbased automated unit test generation tool.arXiv, 2023.\n[42] Z.ZhangandT.Saber. Assessingthecodeclonedetectioncapability\nof large language models. In2024 4th International Conference on\nCode Quality (ICCQ), pages 75â€“83. IEEE, 2024.\nTao et al.:Preprint submitted to Elsevier Page 13 of 13",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8134950995445251
    },
    {
      "name": "Programming language",
      "score": 0.652552604675293
    },
    {
      "name": "Genetic programming",
      "score": 0.6170505285263062
    },
    {
      "name": "Grammar",
      "score": 0.5891141891479492
    },
    {
      "name": "Natural language processing",
      "score": 0.40556854009628296
    },
    {
      "name": "Artificial intelligence",
      "score": 0.39103686809539795
    },
    {
      "name": "Linguistics",
      "score": 0.14260435104370117
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ]
}