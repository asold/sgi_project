{
  "title": "Large language models for human-machine collaborative particle accelerator tuning through natural language",
  "url": "https://openalex.org/W4405967751",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2097078449",
      "name": "Jan Kaiser",
      "affiliations": [
        "Deutsches Elektronen-Synchrotron DESY"
      ]
    },
    {
      "id": "https://openalex.org/A2604352910",
      "name": "Anne Lauscher",
      "affiliations": [
        "Universität Hamburg"
      ]
    },
    {
      "id": "https://openalex.org/A2153995963",
      "name": "Annika Eichler",
      "affiliations": [
        "Deutsches Elektronen-Synchrotron DESY",
        "Universität Hamburg",
        "Hamburg University of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2151888698",
    "https://openalex.org/W4401357902",
    "https://openalex.org/W1638050325",
    "https://openalex.org/W2897571879",
    "https://openalex.org/W2088047155",
    "https://openalex.org/W4311008391",
    "https://openalex.org/W4206315874",
    "https://openalex.org/W2884854169",
    "https://openalex.org/W3207615199",
    "https://openalex.org/W6792219651",
    "https://openalex.org/W3108809127",
    "https://openalex.org/W4366257353",
    "https://openalex.org/W4389727268",
    "https://openalex.org/W4399072168",
    "https://openalex.org/W4400411751",
    "https://openalex.org/W2946609015",
    "https://openalex.org/W3195726099",
    "https://openalex.org/W3101293163",
    "https://openalex.org/W3137965023"
  ],
  "abstract": "Autonomous tuning of particle accelerators is an active and challenging research field with the goal of enabling advanced accelerator technologies and cutting-edge high-impact applications, such as physics discovery, cancer research, and material sciences. A challenge with autonomous accelerator tuning remains that the most capable algorithms require experts in optimization and machine learning to implement them for every new tuning task. Here, we propose the use of large language models (LLMs) to tune particle accelerators. We demonstrate on a proof-of-principle example the ability of LLMs to tune an accelerator subsystem based on only a natural language prompt from the operator, and compare their performance to state-of-the-art optimization algorithms, such as Bayesian optimization and reinforcement learning–trained optimization. In doing so, we also show how LLMs can perform numerical optimization of a nonlinear real-world objective. Ultimately, this work represents another complex task that LLMs can solve and promises to help accelerate the deployment of autonomous tuning algorithms to day-to-day particle accelerator operations.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6797158122062683
    },
    {
      "name": "Bayesian optimization",
      "score": 0.6727168560028076
    },
    {
      "name": "Task (project management)",
      "score": 0.6464680433273315
    },
    {
      "name": "Software deployment",
      "score": 0.5718597769737244
    },
    {
      "name": "Reinforcement learning",
      "score": 0.4630676805973053
    },
    {
      "name": "Artificial intelligence",
      "score": 0.37134236097335815
    },
    {
      "name": "Simulation",
      "score": 0.32520216703414917
    },
    {
      "name": "Systems engineering",
      "score": 0.24050259590148926
    },
    {
      "name": "Software engineering",
      "score": 0.16599303483963013
    },
    {
      "name": "Engineering",
      "score": 0.11673703789710999
    }
  ]
}