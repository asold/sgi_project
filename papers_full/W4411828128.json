{
  "title": "Assessing the Accuracy of Diagnostic Capabilities of Large Language Models",
  "url": "https://openalex.org/W4411828128",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A4371683149",
      "name": "Andrada Elena Urdă-Cîmpean",
      "affiliations": [
        "Iuliu Hațieganu University of Medicine and Pharmacy"
      ]
    },
    {
      "id": "https://openalex.org/A1987279549",
      "name": "Daniel Corneliu Leucuța",
      "affiliations": [
        "Iuliu Hațieganu University of Medicine and Pharmacy"
      ]
    },
    {
      "id": "https://openalex.org/A2008121921",
      "name": "Cristina Drugan",
      "affiliations": [
        "Iuliu Hațieganu University of Medicine and Pharmacy"
      ]
    },
    {
      "id": "https://openalex.org/A4378523323",
      "name": "Alina Gabriela Duțu",
      "affiliations": [
        "Iuliu Hațieganu University of Medicine and Pharmacy"
      ]
    },
    {
      "id": "https://openalex.org/A2018801826",
      "name": "Tudor Călinici",
      "affiliations": [
        "Iuliu Hațieganu University of Medicine and Pharmacy"
      ]
    },
    {
      "id": "https://openalex.org/A2648430787",
      "name": "Tudor Drugan",
      "affiliations": [
        "Iuliu Hațieganu University of Medicine and Pharmacy"
      ]
    },
    {
      "id": "https://openalex.org/A4371683149",
      "name": "Andrada Elena Urdă-Cîmpean",
      "affiliations": [
        "Iuliu Hațieganu University of Medicine and Pharmacy"
      ]
    },
    {
      "id": "https://openalex.org/A1987279549",
      "name": "Daniel Corneliu Leucuța",
      "affiliations": [
        "Iuliu Hațieganu University of Medicine and Pharmacy"
      ]
    },
    {
      "id": "https://openalex.org/A2008121921",
      "name": "Cristina Drugan",
      "affiliations": [
        "Iuliu Hațieganu University of Medicine and Pharmacy"
      ]
    },
    {
      "id": "https://openalex.org/A4378523323",
      "name": "Alina Gabriela Duțu",
      "affiliations": [
        "Iuliu Hațieganu University of Medicine and Pharmacy"
      ]
    },
    {
      "id": "https://openalex.org/A2018801826",
      "name": "Tudor Călinici",
      "affiliations": [
        "Iuliu Hațieganu University of Medicine and Pharmacy"
      ]
    },
    {
      "id": "https://openalex.org/A2648430787",
      "name": "Tudor Drugan",
      "affiliations": [
        "Iuliu Hațieganu University of Medicine and Pharmacy"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4390631601",
    "https://openalex.org/W4407686803",
    "https://openalex.org/W4386973901",
    "https://openalex.org/W4404869747",
    "https://openalex.org/W4392196198",
    "https://openalex.org/W4404239891",
    "https://openalex.org/W4387824566",
    "https://openalex.org/W4405934528",
    "https://openalex.org/W4406945781",
    "https://openalex.org/W4403869417",
    "https://openalex.org/W4404138521",
    "https://openalex.org/W4408688552",
    "https://openalex.org/W4399864536",
    "https://openalex.org/W4409285424",
    "https://openalex.org/W4407565546",
    "https://openalex.org/W4409580450",
    "https://openalex.org/W4388014051",
    "https://openalex.org/W4405446768",
    "https://openalex.org/W6866521659",
    "https://openalex.org/W4406829669",
    "https://openalex.org/W4404851582",
    "https://openalex.org/W4406171745",
    "https://openalex.org/W4409794823",
    "https://openalex.org/W4404782528",
    "https://openalex.org/W4400324908",
    "https://openalex.org/W4385266429",
    "https://openalex.org/W4404795474",
    "https://openalex.org/W4396977148"
  ],
  "abstract": "Background: In recent years, numerous artificial intelligence applications, especially generative large language models, have evolved in the medical field. This study conducted a structured comparative analysis of four leading generative large language models (LLMs)—ChatGPT-4o (OpenAI), Grok-3 (xAI), Gemini-2.0 Flash (Google), and DeepSeek-V3 (DeepSeek)—to evaluate their diagnostic performance in clinical case scenarios. Methods: We assessed medical knowledge recall and clinical reasoning capabilities through staged, progressively complex cases, with responses graded by expert raters using a 0–5 scale. Results: All models performed better on knowledge-based questions than on reasoning tasks, highlighting the ongoing limitations in contextual diagnostic synthesis. Overall, DeepSeek outperformed the other models, achieving significantly higher scores across all evaluation dimensions (p &lt; 0.05), particularly in regards to medical reasoning tasks. Conclusions: While these findings support the feasibility of using LLMs for medical training and decision support, the study emphasizes the need for improved interpretability, prompt optimization, and rigorous benchmarking to ensure clinical reliability. This structured, comparative approach contributes to ongoing efforts to establish standardized evaluation frameworks for integrating LLMs into diagnostic workflows.",
  "full_text": null,
  "topic": "Interpretability",
  "concepts": [
    {
      "name": "Interpretability",
      "score": 0.7610874176025391
    },
    {
      "name": "Benchmarking",
      "score": 0.6122308969497681
    },
    {
      "name": "Workflow",
      "score": 0.5423356890678406
    },
    {
      "name": "Computer science",
      "score": 0.5395350456237793
    },
    {
      "name": "Artificial intelligence",
      "score": 0.45700371265411377
    },
    {
      "name": "Field (mathematics)",
      "score": 0.4185889959335327
    },
    {
      "name": "Generative grammar",
      "score": 0.4148905277252197
    },
    {
      "name": "Knowledge management",
      "score": 0.3442184627056122
    },
    {
      "name": "Data science",
      "score": 0.3393423557281494
    },
    {
      "name": "Machine learning",
      "score": 0.3324606418609619
    },
    {
      "name": "Marketing",
      "score": 0.0
    },
    {
      "name": "Business",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Database",
      "score": 0.0
    }
  ]
}