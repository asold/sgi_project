{
  "title": "Schrödinger's tree—On syntax and neural language models",
  "url": "https://openalex.org/W3205352824",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5003288044",
      "name": "Artur Kulmizev",
      "affiliations": [
        "Uppsala University"
      ]
    },
    {
      "id": "https://openalex.org/A5077063699",
      "name": "Joakim Nivre",
      "affiliations": [
        "RISE Research Institutes of Sweden",
        "Uppsala University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2996556191",
    "https://openalex.org/W6796130708",
    "https://openalex.org/W3202070718",
    "https://openalex.org/W4229781645",
    "https://openalex.org/W4285148079",
    "https://openalex.org/W2915977242",
    "https://openalex.org/W1508977358",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W2093483153",
    "https://openalex.org/W6696775231",
    "https://openalex.org/W3159900299",
    "https://openalex.org/W2000196122",
    "https://openalex.org/W3036487253",
    "https://openalex.org/W6760695106",
    "https://openalex.org/W3037115370",
    "https://openalex.org/W2901677362",
    "https://openalex.org/W2117823388",
    "https://openalex.org/W6608136629",
    "https://openalex.org/W2935760417",
    "https://openalex.org/W4237562413",
    "https://openalex.org/W3155682407",
    "https://openalex.org/W6757883768",
    "https://openalex.org/W6750153154",
    "https://openalex.org/W4294969216",
    "https://openalex.org/W6748778741",
    "https://openalex.org/W3001497429",
    "https://openalex.org/W1526308488",
    "https://openalex.org/W3200130628",
    "https://openalex.org/W2970862333",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2963026768",
    "https://openalex.org/W3034510440",
    "https://openalex.org/W2963430224",
    "https://openalex.org/W6605022081",
    "https://openalex.org/W3156570158",
    "https://openalex.org/W2009727972",
    "https://openalex.org/W2964117978",
    "https://openalex.org/W6771829773",
    "https://openalex.org/W3104739822",
    "https://openalex.org/W3035261420",
    "https://openalex.org/W3117738520",
    "https://openalex.org/W6748655984",
    "https://openalex.org/W6757961350",
    "https://openalex.org/W6733782738",
    "https://openalex.org/W3018827121",
    "https://openalex.org/W2549835527",
    "https://openalex.org/W6760434389",
    "https://openalex.org/W6766673545",
    "https://openalex.org/W3031914912",
    "https://openalex.org/W2888922637",
    "https://openalex.org/W3034763191",
    "https://openalex.org/W2951286828",
    "https://openalex.org/W6636510571",
    "https://openalex.org/W2998925391",
    "https://openalex.org/W3166920165",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W3154165903",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W3174169056",
    "https://openalex.org/W6783905346",
    "https://openalex.org/W6776442830",
    "https://openalex.org/W2962843521",
    "https://openalex.org/W2962833140",
    "https://openalex.org/W2889947987",
    "https://openalex.org/W6776606683",
    "https://openalex.org/W6676683561",
    "https://openalex.org/W2604314403",
    "https://openalex.org/W3152698349",
    "https://openalex.org/W3175606037",
    "https://openalex.org/W1567277581",
    "https://openalex.org/W6767464956",
    "https://openalex.org/W6762537594",
    "https://openalex.org/W6757635932",
    "https://openalex.org/W4210980659",
    "https://openalex.org/W2004827252",
    "https://openalex.org/W2903811997",
    "https://openalex.org/W3104235057",
    "https://openalex.org/W6762392948",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W2996728628",
    "https://openalex.org/W3212191244",
    "https://openalex.org/W2962961857",
    "https://openalex.org/W3111186274",
    "https://openalex.org/W3103536442",
    "https://openalex.org/W4238634189",
    "https://openalex.org/W4288351520",
    "https://openalex.org/W2900065283",
    "https://openalex.org/W199274192",
    "https://openalex.org/W2943552823",
    "https://openalex.org/W2970619710",
    "https://openalex.org/W4287118015",
    "https://openalex.org/W1847618513",
    "https://openalex.org/W2142708806",
    "https://openalex.org/W3138301265",
    "https://openalex.org/W2930957955",
    "https://openalex.org/W4233907442",
    "https://openalex.org/W4301259831",
    "https://openalex.org/W2996132992",
    "https://openalex.org/W1614298861",
    "https://openalex.org/W2321470647",
    "https://openalex.org/W4288631803",
    "https://openalex.org/W2614322402",
    "https://openalex.org/W1516184288",
    "https://openalex.org/W2912172494",
    "https://openalex.org/W2961535087",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W3100385063",
    "https://openalex.org/W4288633968",
    "https://openalex.org/W123237996"
  ],
  "abstract": "In the last half-decade, the field of natural language processing (NLP) has undergone two major transitions: the switch to neural networks as the primary modeling paradigm and the homogenization of the training regime (pre-train, then fine-tune). Amidst this process, language models have emerged as NLP's workhorse, displaying increasingly fluent generation capabilities and proving to be an indispensable means of knowledge transfer downstream. Due to the otherwise opaque, black-box nature of such models, researchers have employed aspects of linguistic theory in order to characterize their behavior. Questions central to syntax—the study of the hierarchical structure of language—have factored heavily into such work, shedding invaluable insights about models' inherent biases and their ability to make human-like generalizations. In this paper, we attempt to take stock of this growing body of literature. In doing so, we observe a lack of clarity across numerous dimensions, which influences the hypotheses that researchers form, as well as the conclusions they draw from their findings. To remedy this, we urge researchers to make careful considerations when investigating coding properties, selecting representations, and evaluating via downstream tasks. Furthermore, we outline the implications of the different types of research questions exhibited in studies on syntax, as well as the inherent pitfalls of aggregate metrics. Ultimately, we hope that our discussion adds nuance to the prospect of studying language models and paves the way for a less monolithic perspective on syntax in this context.",
  "full_text": "TYPE Conceptual Analysis\nPUBLISHED /one.tnum/seven.tnum October /two.tnum/zero.tnum/two.tnum/two.tnum\nDOI /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nOPEN ACCESS\nEDITED BY\nSebastian Padó,\nUniversity of Stuttgart, Germany\nREVIEWED BY\nWilliam Schuler,\nThe Ohio State University,\nUnited States\nFelice Dell’Orletta,\nNational Research Council (CNR), Italy\n*CORRESPONDENCE\nArtur Kulmizev\nartur.kulmizev@lingﬁl.uu.se\nSPECIALTY SECTION\nThis article was submitted to\nNatural Language Processing,\na section of the journal\nFrontiers in Artiﬁcial Intelligence\nRECEIVED /one.tnum/seven.tnum October /two.tnum/zero.tnum/two.tnum/one.tnum\nACCEPTED /zero.tnum/two.tnum September /two.tnum/zero.tnum/two.tnum/two.tnum\nPUBLISHED /one.tnum/seven.tnum October /two.tnum/zero.tnum/two.tnum/two.tnum\nCITATION\nKulmizev A and Nivre J (/two.tnum/zero.tnum/two.tnum/two.tnum)\nSchrödinger’s tree—On syntax and\nneural language models.\nFront. Artif. Intell./five.tnum:/seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum.\ndoi: /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nCOPYRIGHT\n© /two.tnum/zero.tnum/two.tnum/two.tnum Kulmizev and Nivre. This is an\nopen-access article distributed under\nthe terms of the\nCreative Commons\nAttribution License (CC BY) . The use,\ndistribution or reproduction in other\nforums is permitted, provided the\noriginal author(s) and the copyright\nowner(s) are credited and that the\noriginal publication in this journal is\ncited, in accordance with accepted\nacademic practice. No use, distribution\nor reproduction is permitted which\ndoes not comply with these terms.\nSchrödinger’s tree—On syntax\nand neural language models\nArtur Kulmizev/one.tnum* and Joakim Nivre /one.tnum,/two.tnum\n/one.tnumComputational Linguistics Group, Department of Linguistics and Philology, Uppsala University,\nUppsala, Sweden, /two.tnumRISE Research Institutes of Sweden, Kista, Sweden\nIn the last half-decade, the ﬁeld of natural language processin g (NLP) has\nundergone two major transitions: the switch to neural networks as the primary\nmodeling paradigm and the homogenization of the training reg ime (pre-\ntrain, then ﬁne-tune). Amidst this process, language models have emerged\nas NLP’s workhorse, displaying increasingly ﬂuent generatio n capabilities and\nproving to be an indispensable means of knowledge transfer down stream.\nDue to the otherwise opaque, black-box nature of such models, re searchers\nhave employed aspects of linguistic theory in order to characteri ze their\nbehavior. Questions central to syntax—the study of the hierar chical structure\nof language—have factored heavily into such work, shedding inv aluable\ninsights about models’ inherent biases and their ability to m ake human-like\ngeneralizations. In this paper, we attempt to take stock of this growing body of\nliterature. In doing so, we observe a lack of clarity across numerou s dimensions,\nwhich inﬂuences the hypotheses that researchers form, as well as the\nconclusions they draw from their ﬁndings. To remedy this, we urg e researchers\nto make careful considerations when investigating coding prope rties, selecting\nrepresentations, and evaluating via downstream tasks. Furthermore, we outline\nthe implications of the diﬀerent types of research questions e xhibited in studies\non syntax, as well as the inherent pitfalls of aggregate metri cs. Ultimately, we\nhope that our discussion adds nuance to the prospect of studying language\nmodels and paves the way for a less monolithic perspective on sy ntax in this\ncontext.\nKEYWORDS\nneural networks, language models, syntax, coding properties, representations, natural\nlanguage understanding\n/one.tnum. Introduction\nSyntax—how words are combined to form sentences in natural language—\nhas perhaps never garnered as much attention from NLP researchers as it do es\nin the present day. Naturally, its recent relevance at conferences is owed to\nthe deep learning paradigm, which the NLP community has embraced with\nopen arms since the midpoint of the last decade. Prior to this paradigm\nshift, questions central to syntax were often restricted to the parsing dom ain.\nThere, researchers were largely interested in developing supervised algor ithms for\nprocessing structured input—usually in the form of annotated constituency or\ndependency treebanks. Beyond parsing, syntax also often factored into rese archers’\nhypotheses about what information models may need to succeed in a given task .\nFrontiers in Artiﬁcial Intelligence /zero.tnum/one.tnum frontiersin.org\nKulmizev and Nivre /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nFeature engineering was a pivotal component of pre-neural NLP ,\nwhere text was ﬁltered through hand-crafted feature templates\nthat emphasized parts of speech, morphology, and tree structure,\nso as to inform simple, often linear models about the underlying\nsyntax of sentences.\nThe deep learning revolution of the mid 2010s quickly\nobviated the need for feature engineering, which was widely\nconsidered a time-consuming and painstaking process.\nEmbeddings—dense vectors representing the distributional\nproperties of words—quickly replaced the sparse, hand-crafted\nvectors of yore and boosted performance dramatically (\nMikolov\net al., 2013 ; Pennington et al., 2014 ). Such progress presented a\ntrade-oﬀ, however: accuracy at the expense of interpretability.\nIndeed, without the guiding hand of the feature engineer, it\nbecame diﬃcult to ascertain what properties of natural language\nthe new neural models—highly complex and non-linear—had\ncome to rely on.\nIt was this uncertainty that inspired a new line of inquiry\nwithin NLP , concerning what exactly models know and how\nthey come to learn it. Early insights from this domain intimated\nthat neural networks could capture facets of the hierarchical\nstructure of language, beyond the linear order of words in\na sentence. The Long Short Term Memory network (LSTM)\n(\nHochreiter and Schmidhuber, 1997 ) featured prominently in\nsuch studies, where researchers employed linguistic minimal\npairs (mostly based on agreement phenomena) in order to\ndemonstrate the model’s sensitivity to syntactic hierarchy\n(\nLinzen et al., 2016 ; Gulordava et al., 2018 ). Such ﬁndings were\ndeemed exciting mainly due the LSTM’s design as a sequence\nprocessor, which lacked the sort of structural supervision or\ninductive bias that one might encounter in the parsing literature.\nAmidst skyrocketing research budgets and the continued\nadvancement of processing hardware, NLP faced another\nparadigm shift in 2018–2019. Researchers began realizing that\nrepresentations for input words need not be ﬁxed to a single\nstatic vector per type (as with word embeddings), but can instead\nbe computed dynamically, with each word contextualized with\nrespect to the rest of the sentence (\nPeters et al., 2018 ). Per\nthis logic, it also became apparent that models capable of\ngenerating such representations could be ﬁne-tuned with respect\nto downstream tasks, with impressive gains in performance\nthereafter (\nHoward and Ruder, 2018 ). Language models—the\nbasis of classic word embedding algorithms—were a natural ﬁt\nfor this paradigm and became NLP’s backbone going forward.\nIn the modern day, models like BERT (\nDevlin et al.,\n2019), GPT ( Radford et al., 2019 ), and their successors feature\nprominently in NLP research, showcasing the eﬃcacy of\nthe pretrain-and-ﬁnetune paradigm. Naturally, the human-like\ngeneration capability of such models, as well as their success\non natural language understanding (NLU) benchmarks (\nWang\net al., 2018 , 2019), makes the question of what the models\nknow about language and how they acquire such knowledge\nand ever-pressing one. Increasingly, we ﬁnd, NLP researchers\nturn to the ﬁeld of syntax—with its decades of research,\ntheory, and debate—in order to answer such questions. In\nthis paper, we attempt to take stock of the ever-growing\nliterature on the syntactic capabilities of neural language\nmodels. In doing so, we observe a lack of clarity across\nnumerous dimensions, which inﬂuences the hypotheses that\nresearchers form, as well as the conclusions they draw from\ntheir ﬁndings. We argue that this failure of articulation results\nin a body of work whose hypotheses, methodologies, and\nconclusions comprise many conﬂicting insights, giving rise to\na paradoxical picture reminiscent of Schrödinger’s cat—where\nsyntax appears to be simultaneously dead and alive inside the\nblack box models. In particular, by framing studies around\naggregate metrics and benchmarks, syntax is often reduced\nto a monolithic phenomenon, which fails to do justice both\nto the complex interplay between diﬀerent manifestations of\nhierarchical structure in natural language and to the substantial\nvariation that exists across typologically diﬀerent languages.\nOur goal in this article is not to criticize earlier studies, which\nall provide valuable pieces of evidence for understanding the role\nof syntax in contemporary NLP , particularly language models.\nInstead, we propose a number of conceptual distinctions,\nthe consideration and articulation of which, we argue, can\nhelp us better understand the seemingly conﬂicting results,\nresolve some of the apparent contradictions, and pave the\nway for a more nuanced and articulated research agenda. To\nprovide the necessary background for this analysis, we begin by\nintroducing the concept of syntax from a bird’s eye perspective.\nWe then review a representative sample of investigations into\nthe syntactic capabilities of neural language models, which\nwe categorize as belonging to three diﬀerent paradigms. We\nsupplement this review by discussing what we perceive to be\nimportant distinctions about syntax left implicit in this body of\nwork. This leads to a discussion of diﬀerent classes of research\nquestions underlying the surveyed literature, and the role of\naggregate metrics in addressing these research questions. We\nconclude with some thoughts on how our analysis can inform\nour research methodology for the future.\n/two.tnum. Background: Aspects of syntax\nSyntax is usually described as the way that words are\ncombined into larger expressions like phrases and sentences.\nOn one hand, syntax can then be contrasted with morphology,\nwhich is concerned with the internal structure of words. On\nthe other hand, it can be contrasted with semantics, which\ndeals with the meaning of words, phrases and sentences—as\nopposed to their form. In reality, however, syntax is concerned\nwith the complex mapping between form and meaning at the\nphrase and sentence level. It is therefore important to make a\ndistinction between syntactic structure—an abstract hierarchical\nFrontiers in Artiﬁcial Intelligence /zero.tnum/two.tnum frontiersin.org\nKulmizev and Nivre /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nstructure that determines or constrains semantic composition—\nand coding properties —expressive devices such as word order,\nfunction words and morphological inﬂection that are used to\npartially encode the syntactic structure. To illustrate this point,\nlet us consider two equivalent sentences in Finnish and English:\n(1) koira jahtasi kissan huoneesta\ndog-NOM chase-PRS cat-ACC room-ELA\n‘a/the dog chased a/the cat from a/the room’\n(2) the dog chased the cat from the room\nMost linguists would agree that (1) and (2) not only mean\n(roughly) the same thing but also have a similar syntactic\nstructure, where the main verb ( jahtasi, chased) takes a subject\n(koira, the dog ), a direct object ( kissan, the cat ) and a locative\nmodiﬁer ( huoneesta, from the room ). However, the encoding of\nthis syntactic structure is quite diﬀerent in the two languages. In\nEnglish, the subject and object are primarily identiﬁed through\ntheir position relative to the verb, while the locative modiﬁer is\nintroduced by a preposition ( from). In Finnish, the role of all\nthree dependents of the verb is indicated by morphological case\ninﬂection, and constituent order is not signiﬁcant\n/one.tnum. Note also\nthat the overt coding properties (word order, function words,\nmorphological inﬂection) do not (always) uniquely determine\nthe syntactic structure. For example, in the English example, the\nphrase from the room could also function as a modiﬁer of the\nnoun phrase the cat , although this is a less likely interpretation\nin most contexts.\nWhile coding properties are concrete aspects of the sentence,\nthe syntactic structure is essentially an abstract concept that is\nnot directly observable. Nevertheless, linguists have over the\nyears accumulated compelling evidence for the existence of\na hierarchical structure over and above the sequential order\nof words. The most obvious type of evidence is perhaps the\noccurrence of structural ambiguity, where a single sequence of\nwords can be assigned multiple interpretations, exempliﬁed in\nthe following classic examples:\n(3) she saw the man with the telescope\n(4) old men and women\n(5) ﬂying planes can be dangerous\nThe principle of compositionality states that the meaning\nof a complex expression is determined by the meanings of its\nconstituent expressions and the rules used to combine them.\nSince the diﬀerent interpretations in the examples above are\nnot due to lexical ambiguity, they must be due to the rules\nused to combine the constituent expressions. Hence, they show\n/one.tnum In principle, the words of the Finnish sentence can be rearranged in\nany order without changing the syntactic roles, but some orders may be\nless natural and/or carry special pragmatic implications.\nthat diﬀerent syntactic structures can be realized by the same\nsequence of words. According to this view, the abstract syntactic\nstructure is closely connected to semantic composition and\nthe syntax-semantics interface. Other types of evidence for\na hierarchical syntactic structure come from substitution and\npermutation tests (see, e.g.,\nMatthews, 1981).\nWhile the existence of a hierarchical structure is hardly\ncontested today, the linguistic theories developed to account\nfor this structure vary in their theoretical assumptions as well\nas in their mathematical representations of syntactic structure.\nThe generative grammar tradition has been dominated by\ntheories based on phrase structure (constituency) (\nBloomﬁeld,\n1933; Chomsky, 1957 ), with successively more abstract\nrepresentations. An alternative conception of syntax is found\nin theories based on dependency structure (\nTesnière, 1959 ;\nMel’ˇcuk, 1988), which emphasize the functional role of linguistic\nexpressions over their constituent structure. A third theoretical\ntradition is that of categorial grammar (\nAjdukiewicz, 1935 ;\nSteedman, 2000 ), which is based on combinatory logic and\nassumes a close connection between syntax and semantic\ncomposition. To some degree, it is possible to convert syntactic\nrepresentations from one theoretical framework to another,\nbut the conversion is usually heuristic and lossy and, therefore,\nthe diﬀerent representations are not commensurable, strictly\nspeaking.\nThe existence of a wide range of syntactic theories arises\nfrom contested views on how a diverse range communicative\nprinciples, including the use of diﬀerent coding properties, can\ncome to exist across languages. For example, the Chomskyan\ntradition posits that an innate human grammar—a set of rules\nand processes that govern human cognition—is privy to a\nseries of language-speciﬁc transformations that result in such\nidiosyncrasies (\nChomsky, 1965 , 1981, 1995). Other accounts\nargue that syntax itself is shaped by functional or cognitive\nconstraints (\nZipf, 1949; Givón, 1995; Hawkins, 2004; Jaeger and\nTily, 2011 ; Gibson et al., 2019 ), such as managing memory\nload by preferring dependencies of shorter length ( Gibson,\n1998; Gibson et al., 2000 )—a process which can also inﬂuence\ncoding properties like word order ( Futrell et al., 2020 ; Hahn\net al., 2020 ). Cultural diﬀerences across languages are likewise\ntheorized to play a large role ( Evans and Levinson, 2009 ;\n), with complex morphosyntactic processes like polysynthesis\nbeing largely observable in small, non-industrial communities\nwith dense social-network structures (\nTrudgill, 2017 ). Directly\nor not, such debates revolve around the controversial poverty\nof the stimulus argument ( Lasnik and Lidz, 2017 )—linguistics’\nown spin on psychology’s nature vs. nurture debate—where the\nhuman capacity to acquire and generalize across structures is\nperceived as either predominantly learned or predominantly\ninnate.\nNeural networks—especially large scale language models—\nhave recently assumed an interesting place in this discussion.\nPrimarily, syntactic theory has oﬀered a useful toolkit for more\nFrontiers in Artiﬁcial Intelligence /zero.tnum/three.tnum frontiersin.org\nKulmizev and Nivre /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nﬁne-grained evaluation of language models, which have shown\nan ability to generate coherent, grammatical output, resembling\nthat of humans. To this end, researchers have employed well-\nstudied coding properties like subject-verb agreement (\nLinzen\net al., 2016 ) or phenomena like ﬁller-gap dependencies ( Wilcox\net al., 2018 ) to articulate exactly on which grounds a models’\noutput might be judged as grammatical or not. Such studies have\nserved as a welcome complement to the ubiqutious, yet opaque\nperplexity metric—a measure of how predictable sentences or\ndocuments are, given a model’s parameterization. In a sense,\nhowever, they can likewise be perceived as a means of sanity-\nchecking models’ behavior (\nBaroni, 2021), with paper titles often\nframed interrogatively: Do neural language models learn ?\nNonetheless, answering such questions is useful, and a concrete\nunderstanding of the ability of neural networks to generalize\nwith respect to natural language—as well as the algorithmic\nprocesses that underlie this capacity—could, in the least, provide\ninteresting perspectives on the age-old debates mentioned above\n(\nLinzen and Baroni, 2021 ).\n/three.tnum. Review: The quest for syntax\nIn this section, we review work belonging to what we\nperceive as the three dominant paradigms for attesting\nlanguage models’ knowledge of syntax—targeted syntactic\nevaluation, probing, and (downstream) NLU evaluation.\nThough comprehensive surveys of such studies can be found,\nfor example, in\nLinzen and Baroni (2021) or Manning\net al. (2020), our aim here is to relate them to the concepts and\ndistinctions discussed in the previous section. Readers interested\nin a more detailed description and analysis are referred to the\naforementioned work.\n/three.tnum./one.tnum. Targeted syntactic evaluation\nTargeted syntactic evaluation\n/two.tnum(TSE) is arguably the most\npopular framework for assessing neural networks’ ability to\nmake syntactic—therefore hierarchical—generalizations. At its\ncore, TSE is a black-box testing approach concerned with\nmeasuring model output (typically probabilities) with respect\nto a curated set of stimuli. Such stimuli are typically based on\nminimal pairs motivated by phenomena in the syntax literature.\nFor example, consider the (by now classic) example in sentences\n6a and 6b.\n(6) a. The keys to the cabinet are on the table.\nb. *The keys to the cabinet is on the table.\nc. *The key to the cabinets are on the table.\nd. The key to the cabinets is on the table.\n/two.tnum This term was coined, to the authors’ best knowledge, byMarvin and\nLinzen (/two.tnum/zero.tnum/one.tnum/eight.tnum).\nThe literature dictates that a competent English speaker\nwould rely on a structural analysis of the keys to the cabinet\nto infer number agreement between the plural subject ( keys)\nand the copula verb ( are). On the other hand, a purely\nsequential processing of the sentence would arrive at the\nopposite conclusion in 6b: is agrees with the adjacent singular\nnoun ( cabinet). To ascertain whether or not a language model\nM follows the former logic, one could, for example, compare\nthe probabilities assigned to the target verb be in 6a–6b, given\nthe context C = the keys to the cabinet , and examine whether\nPM(are|C) > PM(is|C). This can also be extended to full\nparadigms, where, in the case of 6, M has to assign higher\nprobabilities to both (6a) and (6d) with respect to (6b) and\n(6c). TSE (per this formulation) can thus be seen as based\non an accuracy metric, which, if returning a high value over\nn stimuli, implies that M is able to generalize with respect\nto the relevant syntactic phenomenon. It should be noted\nthat probability assigned to the word form x, per various\ntheoretical justiﬁcations, is sometimes replaced with surprisal,\ne.g., S = − log2PM(x|C), as in\nWilcox et al. (2018)\nand Futrell et al. (2019). Furthermore, in situations where the\nlocus of ungrammaticality does not lie on a single word (as\nin English subject-verb agreement), but is dependent on the\ninteraction of several words (e.g., as in negative polarity items),\nit is common to compare the probabilities or perplexities of\nentire sentences (\nJumelet and Hupkes, 2018 ; Marvin and Linzen,\n2018).\nThe TSE framework also allows for ﬂexibility in integrating\nmore complex sets of stimuli, as in the study on syntactic state\nby\nFutrell et al. (2019):\n(7) a. As the doctor studied the textbook, the nurse walked\ninto the oﬃce.\nb. *As the doctor studied the textbook.\nc. ?The doctor studied the textbook, the nurse walked\ninto the oﬃce.\nd. The doctor studied the textbook.\nWith respect to ( 7), Futrell et al. (2019) formulate a set\nof hypotheses, whereby they posit (1) that the surprisal at the\nmatrix clause after the comma (... the nurse walked into the\noﬃce .) should be lower for (7a) than for (7c) (the network knows\nit is in a subordinate clause per the subordinator as), and (2) that\nthe surprisal at the matrix clause should be higher for 7b than\n7d (the network expects a matrix clause per the subordinator).\nThough the aforementioned accuracy approach could likewise\nbe appropriated here as a summary statistic, researchers also\noften employ signiﬁcance testing in order to accept or reject\ntheir hypotheses. For example,\nFutrell et al. (2019) apply a linear\nmixed-eﬀect model on their models’ stimulus-level predictions\nin order to accept hypothesis (1) on behalf of all models,\nbut reject hypothesis (2) for all but two. This formulation—\nin line with common paradigms in psycholinguistics—leads\nthem to conclude that, while all models are partially capable\nFrontiers in Artiﬁcial Intelligence /zero.tnum/four.tnum frontiersin.org\nKulmizev and Nivre /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nof tracking syntactic state across subordinate and main clauses,\ncertain training conditions are required (large data or explicit\nstructural objectives) in order to fully capture the structural\nexpectations induced by subordinators. A similar methodology\nis employed in\nWilcox et al. (2018) for investigating ﬁller-gap\ndependencies.\nThe popularity of the TSE framework has precipitated the\ncreation of challenge suites, which oﬀer holistic measures\nof models’ performance across a variety of linguistic\nphenomena.\nMarvin and Linzen (2018) were among the\nﬁrst to introduce such datasets, employing a context-free\ngrammar to procedurally generate minimal pair sentences—\nsuch as 6a and 6b—for a variety of phenomena: agreement (of\nvarious kinds), reﬂexive anaphora, and negative polarity items.\nWarstadt et al. (2020) later presented a similar, automatically\ngenerated dataset of minimal pairs (BLiMP), albeit with\nwider coverage: 1,000 sentences per 67 paradigms belonging\nto 12 diﬀerent phenomena. The authors used BLiMP to\nstudy various popular language model architectures (LSTM,\nTransformer), whereby they associated average accuracy across\nphenomena with models’ linguistic knowledge. A similar suite\nwas contemporaneously introduced by\nHu et al. (2020), albeit in\nemploy of 2 × 2 templates like 6 for hand-curated stimuli culled\nfrom syntax textbooks. Like Warstadt et al. (2020), Hu et al.\n(2020) used their suite /three.tnumto study language model architectures,\nmost notably relating language models’ syntactic generalization\n(SG) score—measured in aggregate across phenomena—to their\ntest set perplexity.\nIt is important to note that the aforementioned datasets and\nchallenge suites are primarily designed to evaluate the syntactic\nknowledge of pre-trained models. Indeed, there exists a parallel\nline of work that aims at clarifying the generalization capacity of\npopular architectures (such as LSTMs or Transformers) when\ntrained from scratch on curated—often grammar-generated—\ndata. One such dataset is COGS (\nKim and Linzen, 2020 )—\na semantic parsing dataset constructed in such a way that\nthe evaluation (or generalization) set contains combinations\nof lexical items and syntactic structures that do not occur\nin the training set. In COGS, sequence-to-sequence models\ntrained on sentences where certain lexical items occur, for\nexample, only in subject position ( a hedgehog ate the cake )\nmust generalize over structural word order patterns when the\nsame lexical items appear in the object slot ( the baby liked\nthe hedgehog ). Another such dataset is CFQ (\nKeysers et al.,\n2019), which tests models’ ability to parse natural language into\nSPARQL when the distribution of compositional rules across\ntrain and test are purposefully divergent. In both cases, as\nwell as many others (see\nBaroni, 2020 for an overview), it\nhas been shown that out-of-the-box models like LSTMs and\nTransformers dramatically fail to generalize to samples outside\nof their training distributions (though specialized architectures\n/three.tnum This suite was later named SyntaxGym inGauthier et al. (/two.tnum/zero.tnum/two.tnum/zero.tnum).\ncan do so trivially). For example, Kim and Linzen (2020)\nreport that Transformers and Bi-LSTMs yield meager average\naccuracies of 0.31 and 0.05, respectively, on the Subject →\nObject rule described above. Though it must be acknowledged\nthat such setups diﬀer from TSE in targeting cold-started\nseq2seq models rather than pre-trained language models, and\nemploying synthetic rather than naturalistic data, they are\nsimilar in that they study model responses to controlled stimuli.\nMoreover, their focus on the compositional aspects of syntax\nmakes them an interesting alternative approach that may shed\nlight on some of the potential confounds potentially associated\nwith TSE.\n/three.tnum./two.tnum. Probing\nProbing\n/four.tnumis another popular paradigm for attesting NLP\nmodels’ acquisition of syntax. The key distinction between TSE\nand probing is that, while the former is concerned with model\nbehavior, the latter focuses explicitly on model representation. In\nthis context, behavior is likened to the probabilities assigned to\ncertain outputs (extracted, typically, from the output layer of a\nlanguage model), while representation refers to the intermediate\nhidden state vectors computed by the model. Mainly, probing\nis motivated as being necessary due to deep learning’s end-to-\nend nature: features are learned with respect to a given task,\nnot engineered like in traditional systems. Due to this fact,\nneural models’ representations are wholly uninterpretable to the\nhuman interlocutor and thus require intervention in order to\nunderstand what they portray.\nFormally speaking, probing is concerned with\nrepresentations h extracted from a model M for a given\ninput x: h = M(x). A representation h ∈ R1×d is typically a\nﬁxed-length dense vector corresponding to input word x (e.g.,\nkeys in 6a), where d is the hidden-state dimensionality of M. A\nprobe f for a given linguistic property A is a classiﬁer ﬁt on h to\nproduce output y ∈ Y, where Y is a ﬁnite label set: y = fA(h).\nFor properties that can be decoded from single words, such as\npart-of-speech (POS) tags, a trained probe fPOS must be able to\nassign the correct label to h with respect to the ground truth,\ne.g., ˆy = NOUN for M(keys). For properties concerning two or\nmore words, such as dependencies or phrases, a concatenation\nof hidden states corresponding to (possibly) discontiguous\ntokens xi, xj or a contiguous span of tokens xi, ..., xj is applied.\nIn this latter formulation, deemed edge-probing by\nTenney\net al. (2019b), one might expect a probe fDEP to decode\nˆy = NSUBJ for M(keys, are) and fCON to decode ˆy = PP\nfor M(on, the, table). Though probing models vary widely in\nterms of architecture, parameters, optimization, etc., the vast\nmajority of them assume a training set DA representative of\nproperty A on which f ’s parameters/Theta1can be ﬁt, like a treebank.\n/four.tnum Also known as diagnostic classiﬁcation(see, e.g., Hupkes et al., /two.tnum/zero.tnum/one.tnum/eight.tnum).\nFrontiers in Artiﬁcial Intelligence /zero.tnum/five.tnum frontiersin.org\nKulmizev and Nivre /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nSuch probes are then evaluated in standard supervised learning\nfashion via accuracy on a held out test set. If such accuracy is\nhigh, it can then be said that A is decodable from h, i.e., that\nM learns it. This framework was notably employed by\nLiu N.\nF. et al. (2019) and Tenney et al. (2019b), who concurrently\ndemonstrated that representations extracted from popular\ncontextual embedding models (ELMo, BERT, GPT) yielded\nexceedingly good performance on suites of linguistic tasks. Also\nnoteworthy is\nTenney et al. (2019a)’s study, which showed that\nBERT’s representations appear to evolve in capturing properties\nwith increasing levels of complexity, from lexical features to\nsyntax and semantics.\nWhile the aforementioned word-level approach is by far\nthe most popular probing setup, other methods for decoding\nthe syntactic structure of entire sentences have been proposed.\nOne model that is of particular interest is that of\nHewitt and\nManning (2019), who attempt to decode dependency structure\nfrom models’ vector spaces. To this end, they propose to\nlearn transformations over model representations, such that (1)\nthe squared l2 distance between any vectors hi, hj reﬂects the\ndistance between their corresponding words xi, xj in a parse\ntree, and (2) that the l2 norm of any vector hi reﬂects the\ndepth of its corresponding word xi in a parse tree. They ﬁnd\nthat this method is particularly eﬀective for decoding Stanford\nDependencies trees (\nde Marneﬀe et al., 2006 ) from ELMo\nand BERT representations, with respect to several lexical-only\nbaselines. Beyond\nHewitt and Manning (2019)’s method, which\ncan be imagined as doing parsing by proxy, other work has\ndirectly employed (underparameterized) dependency parsers\nas probes. For example,\nHewitt and Liang (2019) employ a\ngraph-based bilinear probe; Maudslay et al. (2020) investigate\nthe relation between probing and parsing; and Pimentel et al.\n(2020a) advocate for adding full dependency parsing to the\nprobing task suite. A potential advantage of probes that attempt\nto decode the syntactic structure of a complete sentence is\nthat they may shed light on the compositional aspects of\nsyntax—as well as a model’s encoding thereof—in a way that is\ncomplementary to the studies based on synthetic data discussed\nin Section 3.1.\nAt this stage, probing can be considered a ﬁeld of inquiry in\nits own right, with researchers presenting new models, metrics,\nand criticisms for every conference cycle. Naturally, the use of\nintermediary models trained on top of extracted representations\nwarrants caution from the interlocutor. Concerns expressed\nin the literature include but are not limited to the following:\nthe use of smaller, linear models vs. larger, nonlinear ones;\nappropriate baselines and evaluation metrics; properties being\nlearned by the probe vs. occurring in representations; properties\nbeing employed by the model in the original task vs. simply\nbeing decodable, etc. Though a full consideration of these\nmethodological concerns is outside the scope of this article, we\nrefer the interested reader to\nBelinkov (2022)—a comprehensive\nreview of the paradigm, open issues, and alternative approaches\nlike attention analysis.\n/three.tnum./three.tnum. NLU evaluation\nOutside of TSE and probing, another technique that\nhas recently attracted much attention is the evaluation of\nmodels (imbued with or deprived of syntactic knowledge)\non downstream tasks. The logic inherent to this line of\ninquiry is as follows: if a model has come to rely on human-\nlike knowledge of language (or some semblance thereof)\nto solve complex NLP tasks, then it should (1) perform\npoorly on such tasks when the surface form of an utterance\nhas been corrupted beyond (human) comprehension, and\n(2) perform better when imbued with the exact abstract\nstructure theorized by linguists as governing the surface form.\nSuch tasks are typically taken from the GLUE benchmark—\na suite of natural language understanding (NLU) datasets\n“designed to favor and encourage models that share general\nlinguistic knowledge across tasks” (\nWang et al., 2018 ).\nGLUE has served as the principal point of comparison for\npretraining architectures, where, as of writing, 15 models have\nsurpassed the published human performance on the same\ntasks.\nIn terms of input corruption, many studies have investigated\nthe eﬀect of word order on NLU task performance. Indeed,\nword order is the primary means of encoding syntactic argument\nstructure in English, and such work often hypothesizes that\nsensitivity to this particular property should result in lower\nNLU scores.\nGupta et al. (2021) demonstrate that this is\nnot the case for BERT when ﬁne-tuning on various GLUE\ntasks: sequences corrupted at test-time by means of shuﬄing,\nsorting, duplicating, and dropping tokens still retain 70–90%\nperformance of the non-perturbed input. Moreover, models\nappear to be as conﬁdent in assigning labels to perturbed inputs\nas they are to naturalistic ones. These results are corroborated\nby\nPham et al. (2020), who show that models predominantly\nseek salient words in sequences, with numerous attention heads\nspecializing themselves for this exact purpose.\nSinha et al. (2020)\nreport similar ﬁndings for various NLI datasets (in English\nand Chinese) across a variety of model architectures. They\nshow that models are insensitive to word reorderings, some\nof which can actually result in improved task performance.\nPerhaps most strinkingly,\nSinha et al. (2021) show that pre-\ntraining full-scale RoBERTa models on perturbed sentences\n(across n-grams of varying lengths) and ﬁne-tuning them on\nunaltered GLUE tasks leads to negligible performance loss. They\nalso report that a popular probe for dependency structure,\nthat of\nPimentel et al. (2020a), is able to decode trees from\nthe perturbed representations—even a unigram baseline with\nresampled words–with considerable accuracy.\nFrontiers in Artiﬁcial Intelligence /zero.tnum/six.tnum frontiersin.org\nKulmizev and Nivre /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nAs a conceptual counterpoint to the permutation-based\nline of research, several studies have posed the opposite\nquestion: does explicitly injecting syntactic structure into\nmodels’ representations or training objectives lead to better\ndownstream performance? The observations in such studies\nare similar to the aforementioned work, albeit slightly more\nsubtle: models that factor syntax into their decisions generally\ndo not beneﬁt in performance via its injection, which is taken\nto imply that such structure is redundant to the model, or not\nneeded at all. Most notably,\nGlavaš and Vuli ´c (2021) ﬁne-tune\nBERT and RoBERTa ( Liu Y. et al., 2019 ) as dependency parsers,\nbefore ﬁne-tuning the same models again on NLI, paraphrase\ndetection, and commonsense reasoning tasks. They show that,\nwhile intermediate parsing training (IPT) can produce near\nstate-of-the-art parsers, repurposing these parameters for NLU\ntasks leads to negligible improvement. A similar trend is shown\nin\nKuncoro et al. (2020), who train a BERT model distilled from\nan RNNG teacher ( Dyer et al., 2016 ). They, too, ﬁnd that, while\ntheir syntactically-aware model achieves top marks on a suite of\nparsing and otherwise syntactic tasks, the beneﬁts for ﬁne-tuning\non GLUE are scant, if any.\nSwayamdipta et al. (2019) corroborate\nthese ﬁndings for ELMo models conditioned on chunked input\nderived from phrase structure trees.\n/four.tnum. Discussion: A call for clarity and\ncaution\nAfter our general discussion of syntax, as well as our review\nof work exploring its role in contemporary language models,\nwe are now in a position to make a few basic distinctions.\nIn this section, we attempt to situate the ﬁndings of the\naforementioned studies along several dimensions that we deem\nimportant toward the advancement of our research agenda.\n/four.tnum./one.tnum. Coding properties are not syntax\nFirst, we would like to highlight the need to be clear about\nwhether a study is concerned with abstract syntactic structure,\novert coding properties, or with some relation between the\ntwo. A typical fallacy that may arise from not observing this\ndistinction is to conﬂate a particular coding property with the\nabstract syntactic structure that it partially encodes. Naturally,\nif we fall victim to this fallacy when interpreting certain\nﬁndings, we risk drawing conclusions based on insuﬃcient or\nirrelevant evidence. This applies to situations where we may\nbe tempted to employ coding properties as proxies of syntactic\nstructure—either for attesting models’ sensitivity to the latter or\nrefuting it.\nFor example, it is important to acknowledge that studying\nagreement via TSE gives us a glimpse into how language\nmodels capture the syntactic relationship between selected\nwords, such as verbs and their subjects. Per this view,\nhigh performance—even in the presence of various types of\nattractors—does not necessarily ential that a model has learned\nthe grammar of a language. Rather, it has simply shown\nitself to be particularly sensitive to a single coding property,\ngrammatical relation, or dependency type. Notably, English\nagreement is limited to expressing the number or person of\nthe subject on the ﬁnite main verb (when in the present\ntense). This amounts to being, in the vast majority of cases,\na binary distinction between correct and incorrect inﬂections,\nwhich bears a strong random choice baseline of 50% in the\ncase of TSE. Thus, when one considers types of agreement\nmanifested in other languages—such as number, gender, and\ncase agreement between nouns and their modifying adjectives\n(e.g., German, Russian), or polypersonal agreement between\na verb and multiple arguments (e.g., Basque, Georgian)—it\nbecomes diﬃcult to judge agreement as the primary mechanism\nby which syntax is encoded in English. Indeed, studies have\nshown that models tend to struggle with more expressive\nagreement mechanisms in morphologically rich languages\n(\nRavfogel et al., 2018 ). Such insights call not only for a\ntypologically driven research agenda, but also for nuance\nin interpreting positive ﬁndings for singular properties in\nselected languages.\nWe must also note that the above logic can apply in\nreverse: a model’s lack of sensitivity to a single coding\nproperty, for example, word order (\nDryer, 1992), does not imply\nthat the model has failed to acquire syntax as a byproduct\nof its training objective. Even in a language like English,\nwhere word order is very salient, it is not the only coding\nproperty that signals syntactic structure. Consider chases the\ncats the dog as a permutation of the dog chases the cats : it\nis not unreasonable for an English speaker to decode the\nargument structure of this permutation using subject-verb\nagreement alone. Indeed, recent research in psycholinguistics\nhas intimated that humans are relatively robust to permutations\nof linguistic form (\nTraxler, 2014 ). In the context of word\norder, Mollica et al. (2020) show that humans are able to\nprocess permuted sentences similarly to naturalistic ones,\nalbeit when local structure (measured via pointwise mutual\ninformation) is preserved. Recently, this has been corroborated\nfor models ﬁne-tuned on GLUE as well, with performance\ntherein strongly correlated with the extent of local structure\ncorruption (\nClouatre et al., 2022 ). With this in mind, one can\nsee that order perturbation studies do not provide enough\nevidence to conclude that models (or humans) are insensitive to\nsyntax. Instead, when conducting such studies, we must recall\nthat word order (or agreement, for that matter) is simply a\nsingle coding property in a mosaic of such properties, all of\nwhich are privy to underlying processes that drive composition\nand comprehension.\nFrontiers in Artiﬁcial Intelligence /zero.tnum/seven.tnum frontiersin.org\nKulmizev and Nivre /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\n/four.tnum./two.tnum. Syntactic representations are not\nlinguistic data\nAs a second point, if a study is concerned with syntactic\nstructure, we need to clarify whether it assumes a speciﬁc type of\nsyntactic representation, since the choice of representation may\naﬀect the results. Other things being equal, we may therefore\nprefer methods that do not presuppose speciﬁc syntactic\nrepresentations, since conclusions will otherwise be valid only\non the assumption that the chosen representation correctly\ncaptures syntactic structure. This consideration is even more\nimportant when we make use of automatically parsed data—\nas opposed to manually annotated sentences from treebanks—\nwhere otherwise sound syntactic representations may give\nmisleading results due to parsing errors. At the same time,\nit is important to note that avoiding syntactic representations\naltogether may be limiting in another way, as it may restrict\nour methodological repertoire. Thus, as long as we maintain a\ncritical attitude toward representation-dependent methods, they\nmay still provide us with valuable results that cannot be obtained\nwith other methods.\nTo illustrate the importance of representations in the context\nof probing, we can start by asking: does high UAS on a particular\ntreebank imply that those trees are indeed the structures encoded\nby a given model? Or can alternative, linguistically plausible\nstructures be decoded with comparable accuracy?\nKulmizev et al.\n(2020) explore this question when probing various models for\nUD, a dependency formalism which prioritizes content-word\nheads (\nde Marneﬀe et al., 2021 ), and Surface-Syntactic UD,\nwhich assumes a traditional function-word head style analysis\n(\nGerdes et al., 2018 ). They ﬁnd that, while the diﬀerence in\ndecoding UAS between the two formalisms is minimal for\nsome treebanks, other treebanks exhibit strong preferences\nfor either UD or SUD. They attribute such preferences to\na complex interplay between the formalisms’ inherent graph\nproperties (e.g., average tree height), the probe employed\nfor decoding (\nHewitt and Manning, 2019 ’s, in their case),\nannotation factors like tokenization, and morphology. Though\npreliminary,\nKulmizev et al. (2020)’s study is a cautionary tale\nin tree-based probing, where choice of representation directly\naﬀects what conclusions one may draw about models.\nWe can ask similar questions when attempting to imbue\nmodels with syntactic structure. For example, is the injection of\nUD trees into a model’s architecture enough to draw conclusions\nabout the role of syntax in downstream performance? Or do\nalternative, linguistically plausible representations exist that\nmodels might yet beneﬁt from? Beyond this, what privileges one\nparticular injection method, say intermediate parsing training\n(\nGlavaš and Vuli ´c, 2021 ), over another, such as knowledge\ndistillation from an RNNG teacher ( Kuncoro et al., 2020 )?\nA template for exploring such considerations can be found\nin\nWu et al. (2021), who report that infusing BERT with\nsemantic dependencies can provide modest gains on GLUE.\nIn that study, they compare the DM representation focused\nexplicitly on predicate-argument structure (\nIvanova et al., 2012 )\nwith the more syntactically oriented UD, ﬁnding that the\nformer leads to slightly better performance\n/five.tnum. Furthermore,\nthey compare their chosen infusion method—semantic graph\nembeddings learned via a relational graph convolution encoder\n(\nSchlichtkrull et al., 2018 )—with other means of injecting\nstructure into representations, where their method performs\nbest in most cases.\n/four.tnum./three.tnum. Data, model, and task\nIn any scientiﬁc pursuit, it is vital to acknowledge the (often\nvast) number of independent variables in play. For example,\nin studies concerning syntax in language models, we might\nacknowledge that our choice of model can be decomposed into\nvarious factors: architecture (Transformer, LSTM, etc.), pre-\ntraining task (auto-regressive or masked language modeling,\ninﬁlling, etc.), pre-training data (size and domain thereof),\nmodel size, hyper-parameters, etc. Similarly, we might make\nconsiderations as how to source our experimental data\n(sampling corpora, grammar-constrained generation, crowd-\nsourcing, etc.) and how much of it to utilize. Indeed, it is not\nrealistic to demand that future studies in this domain account\nfor every aforementioned confound or enumerate all possible\ncaveats. However, we nonetheless deem it vital for them to\nclearly articulate the interaction of data D, model M, and task T\nas it pertains to the particular aspect of syntax A that is in focus.\nAs noted earlier, this is the most easily done with TSE, where\nmodels are evaluated in their intended capacity (without an\nintermediary T), and D is employed as a representative sample\nof A (sourcing caveats notwithstanding). It is more complicated\nfor probing studies for two reasons. First, although T can be\na task related to syntax, A is typically not speciﬁed (outside a\ngeneral notion of, e.g., tree structure). This becomes problematic\nwhen treating decoding accuracy as a measurement of the\namount of syntactic knowledge in M’s representations, since the\nscore is an aggregate dominated by easy, local constructions\nat the expense of more complex constructions that are more\nimportant from the point of view of hierarchical structure and\ncompositionality. Second, the involvement of an intermediary\nprobe f is a complication here, as it is not immediately clear\nwhether syntax is actually encoded in M, or if it can be learned\ndirectly from D.\nRavichander et al. (2021) demonstrate evidence\nof the latter, showing that f can “decode” A (verb tense, subject\nand object number, in their case) even if M was not exposed to\nany variation within A during pre-training (in other words, M\n/five.tnum Interestingly, both syntactic and semantic models seem to\noutperform the ﬁne-tuned RoBERTa baseline.\nFrontiers in\nArtiﬁcial Intelligence /zero.tnum/eight.tnum frontiersin.org\nKulmizev and Nivre /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nhad only seen, e.g., past-tense verbs). Although some proposals\nattempt to mitigate such confounds\n/six.tnum, applying these methods\nrequires researchers to conduct a survey of all such approaches\nand make a principled choice in employing one over another,\nwhich, we argue, centers f rather than the intended subject of\nstudy: M.\nIn downstream evaluation studies, the association between\nD, M, and T is yet trickier to disentangle. Similarly to probing,\nsuch studies entail ﬁne-tuning the parameters of a pre-trained\nM on a separate task T, leading to an updated model M′. If\nA is considered, it is often with the goal of evaluating that\nparticular aspect’s importance in solving T, given a version of\nD that is corrupted accordingly (e.g., scrambled word order).\nAlternatively, syntax can be operationalized as a general notion\n(e.g., constituency structure) that is meant to inform M when\nperforming across T. In either setup, M′’s performance on T\n(typically an NLU task like entailment) is typically attributed to\nM, where syntax is hypothesized as a necessity. Assembled this\nway, such experiments lead us to put our full trust in T, which\nwe can employ as a prism through which to opine on M. This\nnecessitates that T is indeed well-motivated and designed, and\ndiﬃcult to exploit via heuristics inherent to D—its attestation.\nAdditionally, this presupposes that we possess a explanations of\nhow humans employ syntax to solve T and that we can elicit\ncomparative explanations from M.\nIf we believe the above to be true, we can hypothesize that,\nby performing well on such tasks, our models possess whatever\nlatent ability humans do in solving them—see, e.g.,\nSinha et al.\n(2020): “models should have to know the syntax ﬁrst, [. . . ] if\nperforming any particular NLU task that genuinely requires a\nhumanlike understanding of meaning.” Unfortunately, in the\ncontext of NLI (which\nSinha et al., 2020 study) this is a highly\ndubious claim: the crowd-sourced nature of such datasets makes\nthem prone to annotation artefacts (e.g., subsequence overlap\nbetween premise/hypothesis, lexical choice across inference\nclasses, sentence length, etc.), which models often exploit as\nheuristics, thus leading to highly inﬂated performance metrics\n(\nGururangan et al., 2018 ; Poliak et al., 2018 ; McCoy et al., 2019 ).\nFurthermore, though datasets for some tasks are supplemented\nwith free-text rationales provided by annotators (\nCamburu et al.,\n2018; Rajani et al., 2019 ), self-rationalizing models introduce\nadditional hurdles in terms of evaluation (what merits a model’s\nrationale as being acceptable?) and interpretation (how faithful\nis a model’s rationale to the label it generated?) (\nWiegreﬀe et al.,\n2020; Jacovi and Goldberg, 2021 ).\nUltimately, the extent of trust we place in M (performing as\nhypothesized) over T (being correctly expressed) may inﬂuence\nnot only our hypotheses, but also the conclusions we draw from\nour ﬁndings. For example, consider\nPham et al. (2020) as a\n/six.tnum See, e.g., information-theoretic probing measures(Pimentel et al.,\n/two.tnum/zero.tnum/two.tnum/zero.tnumb; Voita and Titov, /two.tnum/zero.tnum/two.tnum/zero.tnum; Hewitt et al., /two.tnum/zero.tnum/two.tnum/one.tnum), control tasks (Hewitt\nand Liang, /two.tnum/zero.tnum/one.tnum/nine.tnum), or causal intervention (Elazar et al., /two.tnum/zero.tnum/two.tnum/one.tnum).\ncounterpoint to Sinha et al. (2020). Though the observations\nregarding BERT-based models’ insensitivity to word order are\nlargely similar, the former are more critical of the task (“GLUE\ndoes not necessarily require syntactic information or complex\nreasoning”), and the latter of the model (“current models do\nnot yet ‘know syntax’ in the fully systematic and human-like\nway we would like them to”). The interpretation of M is crucial\nhere, as both studies are concerned with M′ (a textual entailment\nrecognizer) rather than M (a language model). To this end, the\naccuracy-based performance of the former cannot, in principle,\nbe used to interpret the syntactic knowledge of the latter, which\nis evaluated via diﬀerent paradigms (perplexity or cross-entropy\nloss) and the weights of which have been overridden. By the same\ntoken, it is likewise important to avoid conﬂating a particular\nM (e.g., language models) with the architecture on which it is\nbased (e.g., Transformers or LSTMs). This point is particularly\nsalient if we consider work that targets models’ inductive biases,\nwhich demonstrably shows that popular architectures often fail\nin making trivial, human-like generalizations (\nLake and Baroni,\n2018; Keysers et al., 2019 ; Lake et al., 2019 ; Gandhi and Lake,\n2020; Kim and Linzen, 2020 ). It is therefore important to\nrecognize that the success evinced, for example, in, TSE studies\nis a function of a neural network architecture applied speciﬁcally\nto a language modeling task, and that these results alone do not\njustify claims about the capacity of the architecture in general.\n/four.tnum./four.tnum. What are the research questions?\nIn addition to clarifying the role of data, model, and task in\na given study, we also need to be clear about what our research\nquestions are. For example, given a model M, a task T, a training\ndataset D and an aspect of syntax A, we may ask (at least) the\nfollowing three questions:\n1. To what degree does M learn A when trained on D to perform\nT?\n2. To what degree can M learn A when trained on D to perform\nT?\n3. To what degree does M need to learn A when trained on D to\nperform T?\nQuestions of type 1 are the most straightforward to investigate\nas long as we have a valid and reliable method for measuring\nthe degree to which M learns A in the context of D and T. This\nis quite a big assumption in itself, and one that we will return\nto shortly, but we will focus ﬁrst on the logic for answering\ndiﬀerent research questions. Questions of type 2 are modal\nin nature and therefore hard to investigate empirically, except\nindirectly by investigating questions of type 1. For example,\nin the pioneering study by\nLinzen et al. (2016), discussed in\nSection 3, the authors were primarily interested in whether\nan LSTM ( M) can learn “syntax-sensitive dependencies” ( A)—\na question of type 2. To investigate this, they examined the\nFrontiers in Artiﬁcial Intelligence /zero.tnum/nine.tnum frontiersin.org\nKulmizev and Nivre /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nactual learning behavior of the model in two speciﬁc settings\n(questions of type 1): (a) when trained on unlabeled text ( DU )\nfor the task of language modeling ( TLM), and (b) when trained\non labeled sentences ( DL) for a speciﬁc agreement decision task\n(TA). The results were largely negative in the ﬁrst case and\npositive in the second. From the positive result, they could\nconclude that the model can learn the relevant dependencies\nwhen trained on DL for TA; from the negative results, they\ncould however only conclude that there was no evidence that\nthe model was capable of learning the relevant aspect of syntax\nwhen trained on DU for TLM. This illustrates the fundamental\nasymmetry between positive and negative results when it comes\nto generalizations about possibility. A single positive result—if\ninterpreted correctly—is suﬃcient to establish that something is\npossible, while any number of negative results are in principle\ninconclusive\n/seven.tnum. Indeed, as discussed in Section 3, the later study\nby Gulordava et al. (2018) managed to obtain positive results\nalso in a setting similar to the ﬁrst scenario of Linzen et al.\n(2016), from which they concluded that LSTMs are capable of\nlearning at least one aspect of syntactic structure without explicit\nsupervision. A similar conclusion was reached by\nGoldberg\n(2019) for the Transformer-based BERT model. The results are\nnot directly comparable, because the latter study constructs the\nevaluation as a bidirectional masked language modeling task, but\nthey are compatible in that none of the models have been trained\nwith explicit syntactic supervision.\nQuestions of type 3 are more complex still, because they\ninvolve causality as well as modality. More precisely, they\ncombine the question of whether learning A results in better\nperformance of M on T (causality) with the question of\nwhether learning A is necessary to achieve better performance\n(modality). A typical example is the study of\nGlavaš and Vuli ´c\n(2021), discussed in Section 3, where the authors study the eﬀect\nof intermediate parser training of a pre-trained language model\nlater ﬁne-tuned for various language understanding tasks. The\nunderlying research question is whether knowledge of syntax\nis needed for language understanding—a question of type 3—\nand the lack of improvement may suggest a negative answer,\nbut this conclusion is only warranted if it can also be shown (a)\nthat the model has actually learned (some aspects of) syntax and\n(b) that this knowledge causally aﬀects the model’s behavior on\nthe downstream task (and still fails to improve performance).\nNote, however, that a positive improvement would not be\nmore conclusive in this case, because it would only show that\nimprovement is possible, not that it is necessary. This illustrates\nthe complexity involved when relating experimental results to\nresearch questions and points to the need for careful meta-\nanalysis.\n/seven.tnum This is the mirror image of the case of necessity, underlying the\nfamous quotation attributed (probably incorrectly) to Einstein: “No\namount of experimentation can ever prove me right; a single experi ment\ncan prove me wrong”.\n/four.tnum./five.tnum. Aggregate metrics may be\nmisleading—but are necessary\nLet us ﬁnally turn to the question of how we can measure\nthe degree to which a model M learns some aspect of syntax\nA when trained on data set D to perform task T—a question\nthat is crucial to all studies in this area, regardless of what\nthe more general research questions are. As we have seen in\nSection 3, the answer usually involves measuring performance\non an appropriate task T′, although the exact solution depends\non the type of study. In TSE studies, T′ is typically the\ntask of discriminating positive from negative instances of\nsome grammatical pattern, for example by assigning higher\nprobability to the positive instance in a minimal pair. In\nprobing, T′ is a supervised classiﬁcation task assumed to reﬂect\nsyntactic knowledge. And in NLU evaluation, T′ is simply the\ndownstream language understanding task and thus normally\ncoincides with the main task T. Each of these paradigms\ncomes with its own methodological pitfalls, which have been\nextensively discussed in particular in the case of probing, but\nwe will focus here on the complexities that are common to all\nof them.\nFirst of all, we note that performance on T′ is almost always\nmeasured by averaging over individual test instances. In the\nsimplest case, this may just be the arithmetic mean of a 0–\n1 loss metric, such as the accuracy reported for a probing\nclassiﬁer predicting part-of-speech tags. In other cases, it may\nbe a more or less sophisticated macro-average, like an average\nover diﬀerent grammatical patterns in a TSE study. In all\ncases, however, such aggregate measures need to be interpreted\ncarefully. First of all, how do we know whether a given metric\nvalue indicates presence or absence of syntactic knowledge?\nDoes a value of 0.5 mean that the glass is half full or half empty?\nThis highlights the importance of relevant and informative\nbaselines, a point that has been made in the literature before\nbut that has perhaps not been fully appreciated. In addition,\nstatistical signiﬁcance tests should be used as appropriate.\nSecond, it is in the nature of aggregate metrics that they can\neasily be misleading by hiding important variation, especially\nif the distribution of diﬀerent types of phenomena is heavily\nskewed. For example, in the related ﬁeld of syntactic parser\nevaluation,\nRimell et al. (2009) have shown that parsers with\nvery respectable performance according to standard aggregate\nmetrics like EV ALB can have close to zero accuracy on certain\ntypes of unbounded dependency constructions. Moreover,\naggregation may hide important variation in a number of\ndiﬀerent ways. If we use naturally occurring text in our test\nsets, certain words and constructions will inevitably be much\nmore frequent than others and therefore dominate the aggregate\nscores in the same way as for syntactic parser evaluation. As a\nresult of this,\nNewman et al. (2021) argue that standard metrics\nused in TSE overestimate the systematicity of language model\nbehavior. If in addition we aggregate over diﬀerent syntactic\nFrontiers in Artiﬁcial Intelligence /one.tnum/zero.tnum frontiersin.org\nKulmizev and Nivre /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nphenomena, we may hide the fact that diﬀerent phenomena are\ncaptured to diﬀerent degrees. And if we aggregate over multiple\nlanguages—or only report results for a single language—we\nmay neglect important language-speciﬁc properties and risk\nover-generalization.\nLastly, we must consider the role aggregation plays in\nthe interpretation of models’ performance on benchmarks like\nBLiMP , SyntaxGym, or GLUE. At its core, such an enterprise\nentails that all aspects of syntax or language understanding—\nat least those of particular salience—have been successfully\nenumerated. Given the abstract nature of these notions, and\nthe extent of debate regarding them, it is naturally doubtful\nthat such an enumeration could ever be attained. Relaxing this\nsomewhat, in assuming a salient set of aspects has indeed been\ncollected, one must likewise assume—before aggregating—that\na principled weighting of such aspects exists. This is especially\nrelevant when dealing with a space of tasks or phenomena where\nﬁne-grained categorizations are likewise included—for instance,\nthe six subject-verb agreement settings attested in BLiMP. In\nsuch cases, one must not only choose between micro and macro\naveraging across phenomena and their ﬁne-grained attestations,\nbut also articulate whether or not all phenomena lie on an\nequal playing ﬁeld—in other words, that they are all equally (1)\ndiﬃcult to attest and (2) salient for evaluation. Certainly, in the\nvast majority of cases we assume a uniform weighting of classes\nwhen aggregating, since introducing hand-selected weights may\nintroduce bias that we would otherwise prefer to avoid. However,\nwe must not fail to acknowledge that benchmarks, in themselves,\nare inﬂuenced by designers’ theories on what component parts\nadequately represent abstract notions like syntax or language\nunderstanding.\nThere is unfortunately no simple remedy to the complexities\ndiscussed in this section. In particular, giving up aggregate\nmetrics is deﬁnitely not an option, since they are necessary\nfor statistical signiﬁcance testing and generalization. However,\nwe believe that progress can be made by avoiding multiple\naggregations and by making sure that we select our aggregate\nmetrics to match our research questions and hypothesis. For\nexample, if we want to know whether a model learns a general\nsubject-verb relation, as opposed to memorizes agreement\npatterns for a small class of high-frequency verbs, then a macro-\naverage over frequency classes will tell us more than a micro-\naverage over all verb tokens.\n/five.tnum. Conclusion\nThe rapid progress in NLP thanks to deeper and larger\nneural network models trained on very large data sets\nwith little or no linguistic supervision raises a number of\nquestions concerning the status of traditional linguistic notions\nand theories in this landscape. Is there still a role for\ntraditional techniques like supervised syntactic parsing? If not,\nis this because neural language models learn the relevant\ngeneralizations about linguistic structure without explicit\nsupervision, or because language understanding does not\nreally depend on such generalizations in the way traditionally\nassumed? If the latter, does this hold only for language\nunderstanding by machines, or does it also have implications for\nhuman language understanding?\nThese are exciting questions and it is therefore not surprising\nthat we have seen a considerable body of research in this area\nrecently. They are also diﬃcult questions, and the methodology\nfor tackling them is still under development, so it is also\nnot surprising that results so far have been inconclusive and\nsometimes contradictory. As stated in the introduction, the goal\nof this article has not been to criticize previous eﬀorts, but\nto contribute to our understanding of methods and results by\narticulating and discussing some of the inherent complexities\nin this research area. Without pretending to have any complete\nsolutions, we want to conclude with some tentative conclusions\nand recommendations for future research, echoing the main\npoints made throughout the paper.\nOf the three approaches we have reviewed in Section 3, we\nare least optimistic about NLU evaluation, for several reasons.\nFirst, the research question that these studies address—whether\nsyntactic knowledge is needed for a given task—is the hardest\nto tackle because it involves causality as well as modality.\nSecond, it is often unclear what relation holds between the\noriginal pre-trained language model and its ﬁne-tuned version.\nLast but not least, the whole endeavor is undermined by the\nuncertain status of current benchmark data sets when it comes\nto assessing language understanding. Taken together, these\narguments appear to be fatal, and we think little can be salvaged\nfrom this approach.\nWhen it comes to TSE and probing, we are slightly\nmore optimistic, as long as a certain methodological rigor is\nmaintained, as argued in Section 4. We need to be clear about\nwhat conception of syntax underlies our investigations, which\naspects of syntax are being studied, and whether we make\nspeciﬁc assumptions about syntactic representations. We need\nto explicitly discuss what research questions are being asked,\nand how they can be elucidated by the speciﬁc experiments we\nperform. We need to be careful when interpreting aggregate\nresults, always looking for alternative metrics and additional\nanalysis, and making sure to consider evidence from multiple\nlanguages if we want to draw conclusions about natural language\nin general. And we should in general resist the temptation to\ndraw strong conclusions from any single study, which is usually\nimpossible given the complex interplay of research questions,\nmethodology, and data.\nTo make further progress, we also need to reﬁne our\nmethods of investigation. One way to do this is to combine\ndiﬀerent techniques in order to get a more complete picture of\nhow a model processes a given type of phenomena. An obvious\nidea here is to combine probing and TSE, so that we can obtain\nFrontiers in Artiﬁcial Intelligence /one.tnum/one.tnum frontiersin.org\nKulmizev and Nivre /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nsystematic probing evidence related to speciﬁc phenomena,\nrather than aggregated over a heterogeneous test set, as is the\ntypical practice today. A combination of techniques may also be\nused to bring downstream tasks back into the picture. In a recent\nstudy,\nPérez-Mayos et al. (2021) uses structural probing, not to\nassess whether a single static model has learned syntax or not,\nbut to track how syntactic capabilities evolve as a pre-trained\nmodel is ﬁne-tuned for diﬀerent tasks. One could imagine a\nsimilar experimental design using TSE instead of (or together\nwith) probing. Another idea worth exploring is to increase the\ncomplexity of stimuli used for TSE or probing. The ability\nto produce and understand arbitrarily nested structures is a\nhallmark of compositionality and underexploited for analytical\npurposes.\nMany researchers today seem to hold the view that, as\nlanguage models get more and more powerful, their ability to\nlearn syntax increases but the necessity to do so decreases for\nmost tasks that we want them to handle. This may well be true,\nand maybe in this sense syntax is both dead and alive inside the\nblack box. The evidence, however, is still far from conclusive, and\nwe need more data as well as deeper analysis to make it so.\nAuthor contributions\nAll authors listed have made a substantial, direct, and\nintellectual contribution to the work and approved it for\npublication.\nConﬂict of interest\nThe authors declare that the research was conducted in the\nabsence of any commercial or ﬁnancial relationships that could\nbe construed as a potential conﬂict of interest.\nPublisher’s note\nAll claims expressed in this article are solely those of the\nauthors and do not necessarily represent those of their aﬃliated\norganizations, or those of the publisher, the editors and the\nreviewers. Any product that may be evaluated in this article, or\nclaim that may be made by its manufacturer, is not guaranteed\nor endorsed by the publisher.\nReferences\nAjdukiewicz, K. (1935). Die syntaktische Konnexität. Stud. Philos. 1, 1–27.\nBaroni, M. (2020). Linguistic generalization and compositio nality in\nmodern artiﬁcial neural networks. Philos. Trans. R. Soc. B 375:20190307.\ndoi: 10.1098/rstb.2019.0307\nBaroni, M. (2021). On the proper role of linguistically-oriented d eep net analysis\nin linguistic theorizing. arXiv preprint arXiv:2106.08694 .\nBelinkov, Y. (2022). Probing classiﬁers: promises, shortcomi ngs, and advances.\narXiv:2102.12452 48, 207–219. doi: 10.1162/coli_a_00422\nBloomﬁeld, L. (1933). Language. Holt, Rinehart and Winston. Available online\nat: https://books.google.be/books?id=LzxsAAAAIAAJ\nCamburu, O.-M., Rocktäschel, T., Lukasiewicz, T., and Blunso m, P.\n(2018). “e-SNLI: natural language inference with natural lan guage explanations, ”\nin Advances in Neural Information Processing Systems, Vol. 31 . Curran\nAssociates Inc. Available online at: https://proceedings.neurips.cc/paper/2018/ﬁle/\n4c7a167bb329bd92580a99ce422d6fa6-Paper.pdf\nChomsky, N. (1957). Syntactic Structures . The Hague: Mouton.\ndoi: 10.1515/9783112316009\nChomsky, N. (1965). Aspects of the Theory of Syntax . Cambridge, MA: MIT\nPress. doi: 10.21236/AD0616323\nChomsky, N. (1981). Lectures on Government and Binding, Vol. 9 . Dordrecht:\nForis.\nChomsky, N. (1995). The Minimalist Program . Cambridge, MA: MIT Press.\nClouatre, L., Parthasarathi, P., Zouaq, A., and Chandar, S. (2 022). “Local\nstructure matters most: perturbation study in NLU, ” in Findings of the Association\nfor Computational Linguistics: ACL 2022 (Dublin: Association for Computational\nLinguistics), 3712–3731. doi: 10.18653/v1/2022.ﬁndings -acl.293\nde Marneﬀe, M., Manning, C. D., Nivre, J., and Zeman, D. (2021 ). Universal\ndependencies. Comput. Linguist. 47, 255–308. doi: 10.1162/coli_a_00402\nde Marneﬀe, M.-C., MacCartney, B., and Manning, C. D. (2006) . “Generating\ntyped dependency parses from phrase structure parses, ” in Proceedings of the Fifth\nInternational Conference on Language Resources and Evaluation (LREC’06) (Genoa:\nEuropean Language Resources Association).\nDevlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2019). “ BERT: pre-training\nof deep bidirectional transformers for language understand ing, ” in Proceedings\nof the 2019 Conference of the North American Chapter of the Association fo r\nComputational Linguistics: Human Language Technologies, Volume 1 (Lo ng and\nShort Papers) (Minneapolis, MN), 4171–4186. doi: 10.18653/v1/N19-1423\nDryer, M. S. (1992). The greenbergian word order correlation s. Language 68,\n81–138. doi: 10.1353/lan.1992.0028\nDyer, C., Kuncoro, A., Ballesteros, M., and Smith, N. A. (2016) . “Recurrent\nneural network grammars, ” in Proceedings of the 2016 Conference of the\nNorth American Chapter of the Association for Computational Lingui stics:\nHuman Language Technologies (San Diego, CA: Association for Computational\nLinguistics), 199–209. doi: 10.18653/v1/N16-1024\nElazar, Y., Ravfogel, S., Jacovi, A., and Goldberg, Y. (2021). Am nesic probing:\nbehavioral explanation with amnesic counterfactuals. Trans. Assoc. Comput.\nLinguist. 9, 160–175. doi: 10.1162/tacl_a_00359\nEvans, N., and Levinson, S. C. (2009). The myth of language uni versals: language\ndiversity and its importance for cognitive science. Behav. Brain Sci . 32, 429–448.\ndoi: 10.1017/S0140525X0999094X\nFutrell, R., Levy, R. P., and Gibson, E. (2020). Dependency localit y\nas an explanatory principle for word order. Language 96, 371–412.\ndoi: 10.1353/lan.2020.0024\nFutrell, R., Wilcox, E., Morita, T., Qian, P., Ballesteros, M., an d Levy, R. (2019).\n“Neural language models as psycholinguistic subjects: represen tations of syntactic\nstate, ” inProceedings of the 2019 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technolo gies, Volume\n1 (Long and Short Papers) (Minneapolis, MN), 32–42. doi: 10.18653/v1/N19-\n1004\nGandhi, K., and Lake, B. M. (2020). “Mutual exclusivity as a ch allenge for\ndeep neural networks, ” in Advances in Neural Information Processing Systems, Vol.\n33. Curran Associates Inc, 14182–14192. Available online at: https://proceedings.\nneurips.cc/paper/2020/ﬁle/a378383b89e6719e15cd1aa45478627c-Paper.pdf\nGauthier, J., Hu, J., Wilcox, E., Qian, P., and Levy, R. (2020) . “SyntaxGym:\nan online platform for targeted evaluation of language models, ” in Proceedings of\nthe 58th Annual Meeting of the Association for Computational Linguis tics: System\nDemonstrations, 70–76. doi: 10.18653/v1/2020.acl-demos.10\nGerdes, K., Guillaume, B., Kahane, S., and Perrier, G. (2018). SUD or surface-\nsyntactic universal dependencies: an annotation scheme nea r-isomorphic to UD.\nEMNLP 2018:66. doi: 10.18653/v1/W18-6008\nFrontiers in Artiﬁcial Intelligence /one.tnum/two.tnum frontiersin.org\nKulmizev and Nivre /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nGibson, E. (1998). Linguistic complexity: Locality of syntacti c dependencies.\nCognition 68, 1–76. doi: 10.1016/S0010-0277(98)00034-1\nGibson, E. (2000). The dependency locality theory: a distance-b ased theory of\nlinguistic complexity. Image Lang. Brain 2000, 95–126.\nGibson, E., Futrell, R., Piantadosi, S. P., Dautriche, I., Maho wald, K., Bergen, L.,\net al. (2019). How eﬃciency shapes human language. Trends Cogn. Sci. 23, 389–407.\ndoi: 10.1016/j.tics.2019.02.003\nGivón, T. (1995). Functionalism and Grammar . Amsterdam; Philadelphia, PA:\nJohn Benjamins Publishing.\nGlavaš, G., and Vuli ´c, I. (2021). “Is supervised syntactic parsing beneﬁcial for\nlanguage understanding tasks? An empirical investigation, ” in Proceedings of the\n16th Conference of the European Chapter of the Association for Computatio nal\nLinguistics: Main Volume, 3090–3104. doi: 10.18653/v1/2021.eacl-main.270\nGoldberg, Y. (2019). Assessing Bert’s syntactic abilities. arXiv preprint\narXiv:1901.05287.\nGulordava, K., Bojanowski, P., Grave, É., Linzen, T., and Baron i, M. (2018).\n“Colorless green recurrent networks dream hierarchically, ” in Proceedings of\nthe 2018 Conference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies, Volume 1 (Lon g Papers)\n(New Orleans, LA), 1195–1205. doi: 10.18653/v1/N18-1108\nGupta, A., Kvernadze, G., and Srikumar, V. (2021). “Bert & family eat word salad:\nexperiments with text understanding,” in Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence, Vol. 35 , 12946–12954.\nGururangan, S., Swayamdipta, S., Levy, O., Schwartz, R., Bowm an, S., and\nSmith, N. A. (2018). “Annotation artifacts in natural langua ge inference data, ” in\nProceedings of the 2018 Conference of the North American Chapter of the Asso ciation\nfor Computational Linguistics: Human Language Technologies, Volume 2 (S hort\nPapers) (New Orleans, LA: Association for Computational Linguistics ), 107–112.\ndoi: 10.18653/v1/N18-2017\nHahn, M., Jurafsky, D., and Futrell, R. (2020). Universals of wo rd order reﬂect\noptimization of grammars for eﬃcient communication. Proc. Natl. Acad. Sci.\nU.S.A. 117, 2347–2353. doi: 10.1073/pnas.1910923117\nHawkins, J. A. (2004). Eﬃciency and Complexity in Grammars . Oxford\nUniversity Press. doi: 10.1093/acprof:oso/9780199252695 .001.0001\nHewitt, J., Ethayarajh, K., Liang, P., and Manning, C. (2021 ). “Conditional\nprobing: measuring usable information beyond a baseline, ” in Proceedings\nof the 2021 Conference on Empirical Methods in Natural Language\nProcessing (Punta Cana: Association for Computational Linguistics).\ndoi: 10.18653/v1/2021.emnlp-main.122\nHewitt, J., and Liang, P. (2019). “Designing and interpretin g probes with\ncontrol tasks, ” in Proceedings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and the 9th International Joint Con ference on\nNatural Language Processing (EMNLP-IJCNLP) (Hong Kong: Association for\nComputational Linguistics), 2733–2743. doi: 10.18653/v1/ D19-1275\nHewitt, J., and Manning, C. D. (2019). “A structural probe for ﬁnding\nsyntax in word representations, ” in Proceedings of the 2019 Conference of the\nNorth American Chapter of the Association for Computational Lingui stics: Human\nLanguage Technologies, Volume 1 (Long and Short Papers) (Minneapolis, MN),\nAssociation for Computational Linguistics, 4129–4138. doi : 10.18653/v1/N19-1419\nHochreiter, S., and Schmidhuber, J. (1997). Long short-ter m memory. Neural\nComput. 9, 1735–1780. doi: 10.1162/neco.1997.9.8.1735\nHoward, J., and Ruder, S. (2018). “Universal language model ﬁ ne-tuning for\ntext classiﬁcation, ” in Proceedings of the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) (Melbourne, QLD: Association\nfor Computational Linguistics), 328–339. doi: 10.18653/v1 /P18-1031\nHu, J., Gauthier, J., Qian, P., Wilcox, E., and Levy, R. P. (202 0). A systematic\nassessment of syntactic generalization in neural language mo dels. arXiv preprint\narXiv:2005.03692. doi: 10.18653/v1/2020.acl-main.158\nHupkes, D., Veldhoen, S., and Zuidema, W. (2018). Visualizatio n and\n‘diagnostic classiﬁers’ reveal how recurrent and recursive neural networks process\nhierarchical structure. J. Artif. Intell. Res . 61, 907–926. doi: 10.1613/jair.1.\n11196\nIvanova, A., Oepen, S., Ørelid, L., and Flickinger, D. (2012). “ Who did what to\nwhom? A contrastive study of syntacto-semantic dependencie s, ” inProceedings of\nthe Sixth Linguistic Annotation Workshop , 2–11.\nJacovi, A., and Goldberg, Y. (2021). Aligning faithful interpre tations\nwith their social attribution. Trans. Assoc. Comput. Linguist . 9, 294–310.\ndoi: 10.1162/tacl_a_00367\nJaeger, T. F., and Tily, H. (2011). On language “utility”: proces sing\ncomplexity and communicative eﬃciency. Wiley Interdiscip. Rev . 2, 323–335.\ndoi: 10.1002/wcs.126\nJumelet, J., and Hupkes, D. (2018). “Do language models understa nd anything?\nOn the ability of LSTMs to understand negative polarity items, ” in Proceedings\nof the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpret ing Neural\nNetworks for NLP (Brussels: Association for Computational Linguistics), 222 –231.\ndoi: 10.18653/v1/W18-5424\nKeysers, D., Schärli, N., Scales, N., Buisman, H., Furrer, D., Kashubin, S.,\net al. (2019). Measuring compositional generalization: a compr ehensive method\non realistic data. arXiv preprint arXiv:1912.09713 .\nKim, N., and Linzen, T. (2020). “COGS: a compositional generali zation\nchallenge based on semantic interpretation, ” in Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Processing (EMNLP) (Association\nfor Computational Linguistics), 9087–9105. doi: 10.18653/ v1/2020.emnlp-\nmain.731\nKulmizev, A., Ravishankar, V., Abdou, M., and Nivre, J. (2020 ). Do neural\nlanguage models show preferences for syntactic formalisms? arXiv:2004.14096.\n4077–4091. doi: 10.18653/v1/2020.acl-main.375\nKuncoro, A., Kong, L., Fried, D., Yogatama, D., Rimell, L., Dye r, C., et al. (2020).\nSyntactic structure distillation pretraining for bidirectio nal encoders. Trans. Assoc.\nComput. Linguist. 8, 776–794. doi: 10.1162/tacl_a_00345\nLake, B., and Baroni, M. (2018). “Generalization without syst ematicity: on the\ncompositional skills of sequence-to-sequence recurrent networ ks, ” inInternational\nConference on Machine Learning , 2873–2882.\nLake, B. M., Linzen, T., and Baroni, M. (2019). Human few-sho t learning of\ncompositional instructions. arXiv preprint arXiv:1901.04587 .\nLasnik, H., and Lidz, J. L. (2017). “The argument from the pove rty of the\nstimulus, ” in The Oxford Handbook of Universal Grammar (Oxford University\nPress), 221–248. doi: 10.1093/oxfordhb/9780199573776.0 13.10\nLinzen, T., and Baroni, M. (2021). Syntactic structure from deep learning. Annu.\nRev. Linguist. 7, 195–212. doi: 10.1146/annurev-linguistics-032020-05 1035\nLinzen, T., Dupoux, E., and Goldberg, Y. (2016). Assessing the a bility of LSTMs\nto learn syntax-sensitive dependencies. Trans. Assoc. Comput. Linguist . 4, 521–535.\ndoi: 10.1162/tacl_a_00115\nLiu, N. F., Gardner, M., Belinkov, Y., Peters, M. E., and Smith , N. A.\n(2019). “Linguistic knowledge and transferability of contex tual representations, ” in\nProceedings of the 2019 Conference of the North American Chapter of the Asso ciation\nfor Computational Linguistics: Human Language Technologies, Volume 1 ( Long\nand Short Papers) (Minneapolis, MI: Association for Computational Linguistics ),\n1073–1094. doi: 10.18653/v1/N19-1112\nLiu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., et al. (20 19). Roberta: a\nrobustly optimized Bert pretraining approach. arXiv preprint arXiv:1907.11692 .\nManning, C. D., Clark, K., Hewitt, J., Khandelwal, U., and Levy,\nO. (2020). Emergent linguistic structure in artiﬁcial neura l networks\ntrained by self-supervision. Proc. Natl. Acad. Sci. U.S.A . 117, 30046–30054.\ndoi: 10.1073/pnas.1907367117\nMarvin, R., and Linzen, T. (2018). “Targeted syntactic evalu ation of language\nmodels, ” in Proceedings of the 2018 Conference on Empirical Methods in Natural\nLanguage Processing (Brussels), 1192–1202. doi: 10.18653/v1/D18-1151\nMatthews, P. H. (1981). “Syntax, ” in Cambridge textbooks in linguistics .\nCambridge University Press. Available online at:\nhttps://books.google.be/books?\nid=jLNb1EI39JwC\nMaudslay, R. H., Valvoda, J., Pimentel, T., Williams, A., and Cott erell,\nR. (2020). “A tale of a probe and a parser, ” in Proceedings of the 58th\nAnnual Meeting of the Association for Computational Linguistics , 7389–7395.\ndoi: 10.18653/v1/2020.acl-main.659\nMcCoy, T., Pavlick, E., and Linzen, T. (2019). “Right for the w rong\nreasons: diagnosing syntactic heuristics in natural langua ge inference, ” in\nProceedings of the 57th Annual Meeting of the Association for Computati onal\nLinguistics (Florence: Association for Computational Linguistics), 342 8–3448.\ndoi: 10.18653/v1/P19-1334\nMel’ˇcuk, I. (1988). Dependency Syntax: Theory and Practice . Albany, NY: State\nUniversity of New York Press.\nMikolov, T., Chen, K., Corrado, G., and Dean, J. (2013). Eﬃcien t estimation of\nword representations in vector space. arXiv preprint arXiv:1301.3781 .\nMollica, F., Siegelman, M., Diachek, E., Piantadosi, S. T., Min eroﬀ, Z., Futrell,\nR., et al. (2020). Composition is the core driver of the language -selective network.\nNeurobiol. Lang. 1, 104–134. doi: 10.1162/nol_a_00005\nNewman, B., Ang, K., Gong, J., and Hewitt, J. (2021). “Reﬁning targeted syntactic\nevaluation of language models, ” in Proceedings of the 2021 Conference of the\nNorth American Chapter of the Association for Computational Lingui stics: Human\nLanguage Technologies . Association for Computational Linguistics, 3710–3723.\ndoi: 10.18653/v1/2021.naacl-main.290\nFrontiers in Artiﬁcial Intelligence /one.tnum/three.tnum frontiersin.org\nKulmizev and Nivre /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/frai./two.tnum/zero.tnum/two.tnum/two.tnum./seven.tnum/nine.tnum/six.tnum/seven.tnum/eight.tnum/eight.tnum\nPennington, J., Socher, R., and Manning, C. (2014). Glove: glob al vectors for\nword representation. 1532–1543. doi: 10.3115/v1/D14-1162\nPérez-Mayos, L., Carlini, R., Ballesteros, M., and Wanner, L. ( 2021). “On\nthe evolution of syntactic information encoded by BERT’s con textualized\nrepresentations, ” in Proceedings of the 16th Conference of the European\nChapter of the Association for Computational Linguistics: Main Volum e.\ndoi: 10.18653/v1/2021.eacl-main.191\nPeters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., et al.\n(2018). “Deep contextualized word representations, ’ in Proceedings of the 2018\nConference of the North American Chapter of the Association for Computati onal\nLinguistics: Human Language Technologies, Volume 1 (Long Papers) (New Orleans,\nLA), 2227–2237. doi: 10.18653/v1/N18-1202\nPham, T. M., Bui, T., Mai, L., and Nguyen, A. (2020). Out of\norder: how important is the sequential order of words in a sente nce in\nnatural language understanding tasks? arXiv preprint arXiv:2012.15180 .\ndoi: 10.18653/v1/2021.ﬁndings-acl.98\nPimentel, T., Saphra, N., Williams, A., and Cotterell, R. (2020a). “Pareto probing:\ntrading oﬀ accuracy for complexity, ” in Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing (EMNLP) (Association for\nComputational Linguistics), 3138–3153. doi: 10.18653/v1/ 2020.emnlp-main.254\nPimentel, T., Valvoda, J., Hall Maudslay, R., Zmigrod, R., William s,\nA., and Cotterell, R. (2020b). “Information-theoretic probin g for\nlinguistic structure, ” in Proceedings of the 58th Annual Meeting\nof the Association for Computational Linguistics (Association for\nComputational Linguistics), 4609–4622. doi: 10.18653/v1/ 2020.acl-\nmain.420\nPoliak, A., Naradowsky, J., Haldar, A., Rudinger, R., and Van D urme, B.\n(2018). “Hypothesis only baselines in natural language inferen ce, ” in Proceedings\nof the Seventh Joint Conference on Lexical and Computational Semantics\n(New Orleans, LA: Association for Computational Linguistics ), 180–191.\ndoi: 10.18653/v1/S18-2023\nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskeve r, I., et al. (2019).\nLanguage models are unsupervised multitask learners. OpenAI Blog 1:9.\nRajani, N. F., McCann, B., Xiong, C., and Socher, R. (2019). “ Explain\nyourself! Leveraging language models for commonsense reasoni ng, ” in\nProceedings of the 57th Annual Meeting of the Association for Computati onal\nLinguistics (Florence: Association for Computational Linguistics), 493 2–4942.\ndoi: 10.18653/v1/P19-1487\nRavfogel, S., Goldberg, Y., and Tyers, F. (2018). “Can LSTM learn\nto capture agreement? The case of Basque, ” in Proceedings of the 2018\nEMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural N etworks\nfor NLP (Brussels: Association for Computational Linguistics), 493 2–4942.\ndoi: 10.18653/v1/W18-5412\nRavichander, A., Belinkov, Y., and Hovy, E. (2021). “Probing the probing\nparadigm: does probing accuracy entail task relevance?, ” in Proceedings of the\n16th Conference of the European Chapter of the Association for Computatio nal\nLinguistics: Main Volume (Association for Computational Linguistics), 3363–3377.\ndoi: 10.18653/v1/2021.eacl-main.295\nRimell, L., Clark, S., and Steedman, M. (2009). “Unbounded depen dency\nrecovery for parser evaluation, ” in Proceedings of the 2009 Conference on\nEmpirical Methods in Natural Language Processing (Singapore), 813–821.\ndoi: 10.3115/1699571.1699619\nSchlichtkrull, M., Kipf, T. N., Bloem, P., Van Den Berg, R., Titov, I.,\nand Welling, M. (2018). “Modeling relational data with graph conv olutional\nnetworks, ” in European Semantic Web Conference (Cham: Springer), 593–607.\ndoi: 10.1007/978-3-319-93417-4_38\nSinha, K., Jia, R., Hupkes, D., Pineau, J., Williams, A., and Kie la, D. (2021).\n“Masked language modeling and the distributional hypothesis: order word matters\npre-training for little, ” in Proceedings of the 2021 Conference on Empirical Methods\nin Natural Language Processing (Punta Cana: Association for Computational\nLinguistics. doi: 10.18653/v1/2021.emnlp-main.230\nSinha, K., Parthasarathi, P., Pineau, J., and Williams, A. (20 20).\nUnnatural language inference. arXiv preprint arXiv:2101.00010 .\ndoi: 10.18653/v1/2021.acl-long.569\nSteedman, M. (2000). The Syntactic Process . Cambridge, MA: MIT Press.\ndoi: 10.7551/mitpress/6591.001.0001\nSwayamdipta, S., Peters, M., Roof, B., Dyer, C., and Smith, N. A. (2019). Shallow\nsyntax in deep water. arXiv preprint arXiv:1908 .11047.\nTenney, I., Das, D., and Pavlick, E. (2019a). “BERT rediscove rs the classical\nNLP pipeline, ” in Proceedings of the 57th Annual Meeting of the Association for\nComputational Linguistics (Florence: Association for Computational Linguistics),\n4593–4601. doi: 10.18653/v1/P19-1452\nTenney, I., Xia, P., Chen, B., Wang, A., Poliak, A., McCoy, R. T ., et al. (2019b).\nWhat do you learn from context? Probing for sentence structur e in contextualized\nword representations. arXiv preprint arXiv:1905.06316 .\nTesnière, L. (1959). ’Eléments de Syntaxe Structurale. Editions Klincksieck.\nTomasello, M. (2009). The Cultural Origins of Human Cognition . Harvard\nUniversity Press. doi: 10.2307/j.ctvjsf4jc\nTraxler, M. J. (2014). Trends in syntactic parsing: anticipati on, Bayesian\nestimation, and good-enough parsing. Trends Cogn. Sci . 18, 605–611.\ndoi: 10.1016/j.tics.2014.08.001\nTrudgill, P. (2017). “The anthropological setting of polysynthes is, ”\nin The Oxford Handbook of Polysynthesis (Oxford University Press).\ndoi: 10.1093/oxfordhb/9780199683208.013.13\nVoita, E., and Titov, I. (2020). “Information-theoretic pro bing with minimum\ndescription length, ” in Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP) (Association for Computational\nLinguistics), 183–196. doi: 10.18653/v1/2020.emnlp-main. 14\nWang, A., Pruksachatkun, Y., Nangia, N., Singh, A., Michael, J., Hill, F.,\net al. (2019). Superglue: a stickier benchmark for general-purpos e language\nunderstanding systems. arXiv preprint arXiv:1905.00537 .\nWang, A., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S. R.\n(2018). Glue: a multi-task benchmark and analysis platform for nat ural language\nunderstanding. arXiv preprint arXiv:1804.07461 . doi: 10.18653/v1/W18-5446\nWarstadt, A., Parrish, A., Liu, H., Mohananey, A., Peng, W., Wang, S.-F., et al.\n(2020). Blimp: The benchmark of linguistic minimal pairs for Eng lish. Trans. Assoc.\nComput. Linguist. 8, 377–392. doi: 10.1162/tacl_a_00321\nWiegreﬀe, S., Marasovi ´c, A., and Smith, N. A. (2020). Measuring association\nbetween labels and free-text rationales. arXiv preprint arXiv:2010.12762 .\ndoi: 10.18653/v1/2021.emnlp-main.804\nWilcox, E., Levy, R., Morita, T., and Futrell, R. (2018). “What d o RNN\nlanguage models learn about ﬁller-gap dependencies?, ” in Proceedings of the\n2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting N eural\nNetworks for NLP (Brussels: Association for Computational Linguistics), 211 –221.\ndoi: 10.18653/v1/W18-5423\nWu, Z., Peng, H., and Smith, N. A. (2021). Infusing ﬁnetuning with\nsemantic dependencies. Trans. Assoc. Comput. Linguist . 9, 226–242.\ndoi: 10.1162/tacl_a_00363\nZipf, G. (1949). Human Behavior and the Principle of Least Eﬀort: An\nIntroduction to Human Ecology . Addison-Wesley Press.\nFrontiers in Artiﬁcial Intelligence /one.tnum/four.tnum frontiersin.org",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7232443690299988
    },
    {
      "name": "Syntax",
      "score": 0.659828245639801
    },
    {
      "name": "CLARITY",
      "score": 0.5972062349319458
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5261390209197998
    },
    {
      "name": "Language model",
      "score": 0.463385671377182
    },
    {
      "name": "Natural language processing",
      "score": 0.45827412605285645
    },
    {
      "name": "Cognitive science",
      "score": 0.44511258602142334
    },
    {
      "name": "Linguistics",
      "score": 0.3502974510192871
    },
    {
      "name": "Psychology",
      "score": 0.17810171842575073
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I123387679",
      "name": "Uppsala University",
      "country": "SE"
    },
    {
      "id": "https://openalex.org/I2800664555",
      "name": "RISE Research Institutes of Sweden",
      "country": "SE"
    }
  ]
}