{
    "title": "Ten simple rules for using large language models in science, version 1.0",
    "url": "https://openalex.org/W4391381020",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A4296638541",
            "name": "Gabriel Reuben Smith",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A2151067781",
            "name": "Carolina Bello",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A4221447049",
            "name": "Lalasia Bialic-Murphy",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A2134186343",
            "name": "Emily Clark",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A2560140858",
            "name": "Camille S. Delavaux",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A4322338167",
            "name": "Camille Fournier de Laurière",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A2807566870",
            "name": "Johan van den Hoogen",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A1924170951",
            "name": "Thomas Lauber",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A2113900745",
            "name": "Haozhi Ma",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A2100333532",
            "name": "Daniel S. Maynard",
            "affiliations": [
                "ETH Zurich",
                "University College London"
            ]
        },
        {
            "id": "https://openalex.org/A2787429651",
            "name": "Matthew Mirman",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2312777836",
            "name": "Lidong Mo",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A4364642821",
            "name": "Dominic Rebindaine",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A5093827703",
            "name": "Josephine Elena Reek",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A2096276885",
            "name": "Leland K. Werden",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A2129050610",
            "name": "Zhaofei Wu",
            "affiliations": [
                "Beijing Normal University",
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A2642349780",
            "name": "Gayoung Yang",
            "affiliations": [
                "ETH Zurich",
                "Sorbonne Université",
                "Université Sorbonne Nouvelle"
            ]
        },
        {
            "id": "https://openalex.org/A2144727155",
            "name": "QingZhou Zhao",
            "affiliations": [
                "ETH Zurich",
                "Nanjing Agricultural University"
            ]
        },
        {
            "id": "https://openalex.org/A2768342444",
            "name": "Constantin M. Zohner",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A2095012931",
            "name": "Thomas W. Crowther",
            "affiliations": [
                "ETH Zurich"
            ]
        },
        {
            "id": "https://openalex.org/A4296638541",
            "name": "Gabriel Reuben Smith",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2151067781",
            "name": "Carolina Bello",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4221447049",
            "name": "Lalasia Bialic-Murphy",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2134186343",
            "name": "Emily Clark",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2560140858",
            "name": "Camille S. Delavaux",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4322338167",
            "name": "Camille Fournier de Laurière",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2807566870",
            "name": "Johan van den Hoogen",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1924170951",
            "name": "Thomas Lauber",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2113900745",
            "name": "Haozhi Ma",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2100333532",
            "name": "Daniel S. Maynard",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2787429651",
            "name": "Matthew Mirman",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2312777836",
            "name": "Lidong Mo",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4364642821",
            "name": "Dominic Rebindaine",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5093827703",
            "name": "Josephine Elena Reek",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2096276885",
            "name": "Leland K. Werden",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2129050610",
            "name": "Zhaofei Wu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2642349780",
            "name": "Gayoung Yang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2144727155",
            "name": "QingZhou Zhao",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2768342444",
            "name": "Constantin M. Zohner",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2095012931",
            "name": "Thomas W. Crowther",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4319083882",
        "https://openalex.org/W4319332853",
        "https://openalex.org/W4319301446",
        "https://openalex.org/W4317607715",
        "https://openalex.org/W4317853296",
        "https://openalex.org/W6762841066",
        "https://openalex.org/W4318263917",
        "https://openalex.org/W4306176220",
        "https://openalex.org/W4362514994",
        "https://openalex.org/W4383295360",
        "https://openalex.org/W4367188881",
        "https://openalex.org/W4319773014",
        "https://openalex.org/W4322626948",
        "https://openalex.org/W4321605350",
        "https://openalex.org/W6850342999",
        "https://openalex.org/W2008535554",
        "https://openalex.org/W2336426693",
        "https://openalex.org/W2804910112",
        "https://openalex.org/W2963407560",
        "https://openalex.org/W4234473732",
        "https://openalex.org/W4205644940",
        "https://openalex.org/W4324129401",
        "https://openalex.org/W2768281947",
        "https://openalex.org/W6850919931",
        "https://openalex.org/W2995623752",
        "https://openalex.org/W3196961071",
        "https://openalex.org/W4367049580",
        "https://openalex.org/W2605932719",
        "https://openalex.org/W4306377212",
        "https://openalex.org/W4210393630",
        "https://openalex.org/W4386249234",
        "https://openalex.org/W4375949262",
        "https://openalex.org/W2751650523",
        "https://openalex.org/W2899962821",
        "https://openalex.org/W4323812846",
        "https://openalex.org/W3205255111"
    ],
    "abstract": "Box 1-An LLM suggests 10 simple rules governing its own usage in scienceHere, we ask ChatGPT to generate a list of 10 simple rules for using LLMs in science in order to illustrate its ability to provide detailed, human-like responses to short prompts. Q1:Can you provide me with a list of ten simple rules for using large language models in science?R1 (ChatGPT 3.5): Certainly!Here are ten simple rules for using large language models in science:1. Understand the limitations: Recognize that large language models like GPT-3 are powerful but not infallible.They may produce accurate-sounding information, but they can also generate false or biased content.Exercise caution and critical thinking.2. Validate and verify: Always cross-reference information generated by language models with reliable sources.Verify the accuracy of claims, check for",
    "full_text": "EDUCATIO N\nTen simple rules for using large language\nmodels in science, version 1.0\nGabriel Reuben Smith\nID\n1\n*, Carolina Bello\nID\n1\n, Lalasia Bialic-Murphy\nID\n1\n, Emily Clark\n1\n,\nCamille S. Delavaux\nID\n1\n, Camille Fournier de Lauriere\n1\n, Johan van den Hoogen\n1\n,\nThomas Lauber\nID\n1\n, Haozhi Ma\nID\n1\n, Daniel S. Maynard\nID\n1,2\n, Matthew Mirman\n3\n, Lidong Mo\nID\n1\n,\nDominic Rebindaine\nID\n1\n, Josephine Elena Reek\nID\n1\n, Leland K. Werden\nID\n1\n, Zhaofei Wu\n1,4\n,\nGayoung Yang\nID\n1,5\n, Qingzhou Zhao\nID\n1,6\n, Constantin M. Zohner\nID\n1\n, Thomas W. Crowther\n1\n1 Department of Environment al Systems Science, Institute of Integrat ive Biology, ETH Zu ¨ rich, Zu ¨ rich,\nSwitzerlan d, 2 Department of Genetics, Evolution and Environm ent, University College London , London,\nUnited Kingdom , 3 Anarchy, San Francisc o, California, United States of America, 4 College of Water\nSciences, Beijing Normal University , Beijing, China, 5 Sorbonne Universite ´ , Paris, France, 6 College of\nResourc es and Environm ental Sciences, Nanjing Agricultural University, Nanjing, Jiangsu, China\n* gabriel.s mith@usy s.ethz.ch\nIntroduction\nGenerative artificial intelligence (AI) tools, including large language models (LLMs), are\nexpected to radically alter the way we live and work, with as many as 300 million jobs at risk\n[1]. Arguably the most well-known LLM currently is GPT (generative pre-trained trans-\nformer), developed by American company OpenAI [2]. Since its release in late 2022, GPT’s\nchatbot interface, ChatGPT, has exploded in popularity, setting a new record for the fastest\ngrowing user base in history [3]. The appeal of GPT and other LLMs stem from their ability to\neffectively carry out multistep tasks and provide clear, human-like responses to complicated\nqueries and prompts (Box 1). Unsurprisingly, this capacity is catching the eye of scientists [4].\nBox 1—An LLM suggests 10 simple rules governing its own usage\nin science\nHere, we ask ChatGPT to generate a list of 10 simple rules for using LLMs in science in\norder to illustrate its ability to provide detailed, human-like responses to short prompts.\nQ1: Can you provide me with a list of ten simple rules for using large language models\nin science?\nR1 (ChatGPT 3.5): Certainly! Here are ten simple rules for\nusing large language models in science:\n1. Understand the limitations: Recognize that large\nlanguage models like GPT-3 are powerful but not\ninfallible. They may produce accurate-sounding\ninformation, but they can also generate false or biased\ncontent. Exercise caution and critical thinking.\n2. Validate and verify: Always cross-reference\ninformation generated by language models with reliable\nsources. Verify the accuracy of claims, check for\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 1 / 19\na1111111111\na1111111111\na1111111111\na1111111111\na1111111111\nOPEN ACCESS\nCitation: Smith GR, Bello C, Bialic-Mur phy L, Clark\nE, Delavaux CS, Fournier de Lauriere C, et al.\n(2024) Ten simple rules for using large language\nmodels in science, version 1.0. PLoS Comput Biol\n20(1): e1011767. https:// doi.org/10.1371 /journal.\npcbi.1011767\nEditor: Russell Schwartz, Carnegie Mellon\nUniversity , UNITED STATES\nPublished: January 31, 2024\nCopyright: © 2024 Smith et al. This is an open\naccess article distributed under the terms of the\nCreative Commons Attribution License, which\npermits unrestricte d use, distribu tion, and\nreproduction in any medium, provided the original\nauthor and source are credited.\nFunding: GRS, CB, LB-M, EC, CSD, CFdL, JvdH,\nTL, HM, LM, DR, LKW, and TWC were funded by\nDOB Ecology and the Bernina Initiative. CSD was\nalso funded by the Swiss National Science\nFoundation (Postdoctor al Fellowship\n#TMPFP3_ 209925). DSM, CMZ, and GRS were\nfunded by Ambizione grants PZ00P3_193 612,\nPZ00P3_19364 6, and PZ00P3_2161 94\nrespective ly, from the Swiss National Science\nFoundation. GY was funded by the French Foreign\nMinistry (Grant number 102390W ). ZW and QZ\nwere funded by the China Schola rship Council\n(Nos. 202206040 112 and 202206850 027,\nrespective ly). The funders had no role in study\nconsistency, and corroborate the findings through\nempirical evidence or expert opinions.\n3. Train with caution: When fine-tuning a language model\nfor a specific scientific task, carefully design and\ncurate the training data. Ensure the data is\nrepresentative, diverse, and free from biases that may\ninfluence the model’s outputs.\n4. Provide context and instructions: Clearly specify the\nintended context and constraints when using a large\nlanguage model. This helps narrow down the results and\nensures the model generates more relevant and accurate\nresponses.\n5. Understand the biases: Large language models learn from\nthe data they are trained on, which can contain\nsocietal biases. Be aware of these biases and take\nsteps to mitigate them by using diverse training data\nand evaluating the outputs for fairness.\n6. Collaborate and share knowledge: Engage in open\ndialogue with other researchers and scientists working\nwith language models. Share experiences, discuss\nchallenges, and collectively work towards best\npractices for using these models in scientific\nresearch.\n7. Maintain transparency: When presenting work that\nincorporates the use of large language models, disclose\nthe methodology, tools, and limitations. Be\ntransparent about the role of the language model in the\nresearch process and acknowledge its potential impact\non the results.\n8. Ethical considerations: Consider the ethical\nimplications of using language models in science. Be\nmindful of privacy concerns, consent, and potential\nmisuse of generated content. Respect ethical\nguidelines and seek approval when working with\nsensitive or personal data.\n9. Avoid overreliance: Large language models can be a\nvaluable tool, but they should not replace critical\nthinking, domain expertise, or rigorous scientific\nmethods. Use them as a supportive tool alongside other\nresearch methodologies.\n10. Contribute to responsible AI development: Actively\nparticipate in efforts to improve large language\nmodels and promote responsible AI practices. Provide\nfeedback to developers, collaborate on research, and\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 2 / 19\ndesign, data collection and analysis, decision to\npublish, or preparation of the manuscript.\nCompeting interests : MM is the founder and CEO\nof an LLM startup.\nIndeed, there is increasing interest in using GPT and other LLMs to accelerate scientific\nprogress for the benefit of humankind [5]. However, specific challenges concerning possible\nmisuse of LLMs in science are arising [6] in tandem with broader concerns about potential\nsocietal disruption and ethical risks [7,8]. As such, there is an urgent need for the scientific\ncommunity to establish general guiding principles for the appropriate use of LLMs and other\ngenerative AI tools to maximise benefit and minimise harm [9,10].\nHere, we propose a set of 10 simple rules for using LLMs in science, drawn from our own\nexperimentation as cautiously optimistic environmental scientists curious about novel tools to\nstreamline research. We note that the list is grounded in our expertise as scientists and experi-\nence as end-users of LLMs (GPT specifically), not as AI developers. We also note that we do\nnot here address other sorts of generative AI, which could also be increasingly used for scien-\ntific research in the future.\nWe suggest safeguards against 5 areas of concern to be wary of (Rules 1 to 5), comple-\nmented by suggestions for areas where LLMs have potential to support scientific research if\nsufficient care is taken to avoid issues (Rules 6 to 10). Since LLMs are predictive language\nmodels, our use suggestions focus on language-centric aspects of scientific research, such as\ncomputer coding, writing, and publishing.\nAs developments in this field are rapid and outcomes often unpredictable [11], we envision\nthat these guidelines can provide a starting point, not an end point; they will likely need to be\nrevisited and adapted as circumstances change. We envision, additionally, that our list may\nalso provide a basis for better standardised reporting and documentation (S1 Appendix) usable\nacross journals, allowing researchers who are submitting manuscripts to document their use\n(s) of LLMs and affirm that they have appropriately considered potential problem areas.\nSafeguards\n1. Follow the rules of the target journal. It’s essential to consult and follow an up-to-date\nversion of the rules for the target journal prior to using an LLM for research. As these tools\ngain in popularity, journals are likely to provide explicit guidelines on what they consider to be\nacceptable or unacceptable uses in submitted manuscripts. Several journals have already issued\nstatements on this topic [12], but these guidelines may be updated and changed as scientists\nincreasingly experiment with LLMs and discover new uses. In fact, we anticipate that a key ele-\nment of scientific ethics may soon concern proper disclosure of generative AI usage for\nresearch.\nImportantly, different journals might adopt substantially different policies. If this occurs,\nwork developed with one journal in mind could be fundamentally inadmissible in another\neven if the topic and novelty would otherwise be well-matched. This problem could potentially\nbe mitigated by alignment along a standardised framework for reporting of generative AI use\nin science. We include an example document of this sort in the appendix of this paper (S1\nAppendix), specifically for LLMs and based upon the rules given here. This document should\nadvocate for ethical and inclusive use of these models\nin science and society.\nRemember, these rules provide general guidance, and it’s\nimportant to adapt them to specific scientific disciplines\nand contexts.\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 3 / 19\nbe adapted and modified as new or use-specific challenges arise. If there is uncertainty con-\ncerning a given use, we encourage authors to discuss with editors and make use of the\nacknowledgements section of their papers to disclose their use of generative AI with sufficient\ndetail.\n2. Outline relevant risks before LLM use. Because LLM use can lead not only to benefit\nbut also to harm [13], researchers who would like to use one for their project should also first\noutline relevant risks [14]. Based on an assessment of the risks posed by a particular use case,\nan approach can be decided upon that maximises benefit and minimises potential harm.\nFor some risks, mitigation may be straightforward. For example, erroneous LLM-generated\ncontent can be caught and corrected by thoroughly and critically proofreading (Rule 5). How-\never, other well-documented LLM risks are too complex to be amenable to complete mitiga-\ntion by a single researcher or team. In these cases, a researcher can instead qualitatively\nevaluate the extent to which their project might exacerbate the problem and make modifica-\ntions to limit the specific negative impact of their work.AU : Ple ase conf irm tha tal lhea ding lev elsa rer epr ese nted cor rec tly:\nFor example, if LLMs prove to be a boon to scientific research, variation in LLM accessibil-\nity and user-skill risks contributing to an unequal playing field for scientists competing for\nfunding and employment. For this problem, a partial solution may take the form of researchers\nmaking LLM prompts they have used for their research freely available in the spirit of open sci-\nence, so that others may learn from them. A second concern revolves around biases in a mod-\nel’s underlying training data, which could cause its output to not only reinforce harmful\nsocietal prejudices [13,14] but also hamper scientific creativity by hewing closely to existing\nscientific narratives without emphasising knowledge gaps [15,16]. This problem may be\naddressed in part by checking LLM-generated content specifically for evidence of bias and\nusing LLMs only in later stages of scientific work, after creative inquiry and hypothesis testing\nhave already occurred.\n3. Avoid plagiarism. Because generative AI presents new challenges for legal frameworks\nsurrounding copyright and intellectual property, researchers must proactively ensure that\ntheir LLM use is not considered plagiarism within its relevant context. Indeed, beyond trans-\nparently unethical uses of LLMs, for example, to defeat plagiarism-detecti on software [17],\nsubtle issues surrounding plagiarism can also arise in everyday use of LLMs for science.\nAs long as an LLM is not considered a legal person, unattributed use of the text they pro-\nduce would not seem to be plagiarism under most current legal definitions. However, it may\nbe inadmissible for other reasons—for example, directly incorporating text from GPT into a\nmanuscript currently violates some journal rules [12], rendering this an unacceptable usage\n(Rule 1). Nevertheless, debate continues about how precisely guidelines and concepts of aca-\ndemic integrity ought to evolve in response to the increasing availability of generative AI\n[18,19], with no clear settled consensus yet. We anticipate that norms surrounding incorpo-\nration and declaration of LLM-generated text (after fact-checking) in scientific literature may\nchange considerably in the near future. Currently, researchers might best conceptualise LLM-\nproduced text as a third-party source, which can inform but not replace their own writing.\n4. Respect confidentiality. Unlike use of standard analytical tools, sharing confidential\ndata or information with an LLM represents a potential breach of contract and must be\navoided unless explicit permission is obtained. This is important to note because researchers\nwishing to debug computer code (Rule 6), summarise content (Rule 7), or improve manu-\nscript writing (Rule 10) might wish to share code, data, or writing with an LLM.\nThough tempting, doing so presents a major potential problem because it remains unclear\nwhether GPT in particular might “remember” this information and then share it with third\nparties who ask similar questions. In fact, OpenAI states that conversations that GPT (in the\ncontext of OpenAI consumer services) has are indeed used for further training of the model\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 4 / 19\n[20]. Scientists who work with sensitive, confidential data, for example medical records, must\nkeep this in mind. Similar caution may be called for regarding preliminary scientific findings\nthat are not yet ready for publication. We suggest that until there is sufficient clarity on this\ntopic, data of this sort should not be transmitted to GPT, even if data confidentiality agree-\nments (which may have been drafted before the advent of widespread LLM availability) do not\nexplicitly rule out such an activity.\n5. Verify the truthfulness of content generated by an LLM. Content generated by an\nLLM must always be double-checked by a subject matter expert for factual accuracy. LLMs are\nwell known to “hallucinate”—in other words, to give seemingly correct but false answers—par-\nticularly in response to complex questions (Box 2) [21]. Problematically, the model’s eloquence\ncan cause users to overlook false statements or references. This issue is an example of the “halo\neffect,” a well-known cognitive bias where an individual’s specific positive traits (e.g., elo-\nquence) are mistakenly interpreted as evidence of a general “goodness” that extends beyond\nthese specific traits [22]. In the case of an LLM, the quality of the presentation may be uncon-\nsciously assumed to match the veracity of the content.\nBox 2—Examples of LLM hallucination\nHere, we request factual, referenced information from ChatGPT. In response, we receive\napparently convincing answers which actually contain subtle, potentially misleading\ninaccuracies.\nQ1: Provide a referenced estimate of the amount of vegetation biomass on planet Earth.\nR1 (ChatGPT3.5): As of my knowledge cutoff in September\n2021, estimating the exact amount of vegetation biomass on\nplanet Earth is challenging due to the vastness and\ncomplexity of ecosystems. However, scientists have made\nvarious estimations using different methods and data\nsources. It’s important to note that these estimates can\nvary depending on the specific criteria and assumptions\nused in the calculations.\nOne study published in the journal Nature in 2020 provides\nan estimate of global vegetation biomass based on satellite\nobservations and ground measurements. The research suggests\nthat the Earth’s total vegetation biomass is approximately\n450 billion metric tons (gigatons). This includes all the\nvegetation on land, including forests, grasslands,\nshrublands, and other types of vegetation.\nHere is the reference for the study:\nZhu, Z., et al. (2020). Greening of the Earth and its\ndrivers. Nature, 597(7871), 405-409. doi: 10.1038/s41586-\n020-2474-6.\nPlease keep in mind that new studies and advancements in\nremote sensing technologies may have provided more accurate\nestimates since my last update. It is advisable to consult\nrecent scientific literature for the most up-to-date\ninformation on the subject.\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 5 / 19\nInaccuracies: This is a good example of a seemingly correct answer with some critical\nmistakes. The paper “Greening of the Earth and its drivers” was indeed published by\nZhu and colleagues [23], but in Nature Climate Change, 2016 (doi: 10.1038/\nnclimate3004), not in Nature. Moreover, in Zhu and colleagues (2016), no estimate was\nprovided of Earth’s total vegetation biomass. The estimate of 450 Gt C can instead be\ntraced to Bar-On and colleagues (2018) [24].\nQ2: What are the geospatial patterns of soil nematodes at a global scale? Provide refer-\nences to the statements provided.\nR2 (ChatGPT4): As of my last update in September 2021, the\nmost comprehensive study on the global distribution of soil\nnematodes was published in 2019 in the journal \"Nature\". The\nresearch was conducted by Van den Hoogen et al., who\nassembled a global soil nematode dataset covering all\ncontinents and biomes.\nHere are some of the key findings from the study:\nSoil nematodes are ubiquitous and are found in every type of\necosystem, from the tropics to the Arctic and Antarctic, and\nfrom lowland areas to high mountain ranges.\nNematode density, or the number of nematodes per unit of\nsoil, tends to decrease with increasing latitude. This\nmeans that nematode densities are generally higher in the\ntropics than in temperate or polar regions.\nThe highest nematode densities were found in grasslands and\nforests, and the lowest densities were found in deserts and\ntundra.\nNematode communities vary greatly in their composition\ndepending on the ecosystem. For example, bacterial-feeding\nnematodes are more common in ecosystems with high organic\nmatter content, while fungal-feeding nematodes are more\ncommon in ecosystems with low organic matter content.\nThe total global soil nematode population was estimated to\nbe around 0.3 x 10^20 (or 30 quintillion) individuals,\nmaking them the most abundant group of animals on Earth.\nReference:\nVan den Hoogen, J., Geisen, S., Routh, D., Ferris, H.,\nTraunspurger, W., Wardle, D. A., & & Crowther, T. W. (2019).\nSoil nematode abundance and functional group composition at\na global scale. Nature, 572(7768), 194-198. doi: 10.1038/\ns41586-019-1418-6\nInaccuracies: Again, the answer provided is seemingly correct but contains errors. In\nthe referenced paper [25], the estimated number of soil nematodes is actually\n4.4 × 10^20, with a total biomass of 0.3 Gt. Additionally, the latitudinal patterns\ndescribed in the paper are the opposite from ChatGPT’s answer. Finally, the paper\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 6 / 19\nSafeguarding against hallucinations may be easy or difficult, depending on the nature of the\ntask that the LLM has been asked to perform. For example, a citation can be quickly cross-\nchecked for accuracy and code can simply be executed to test whether it does what it is sup-\nposed to. But if one asks an LLM to summarise an article or transcribe a meeting (as in Rule\n7), checking for accuracy might be much more challenging and time-consuming. The diffi-\nculty of checking in these cases might tempt users to trust responses uncritically—a tendency\nagainst which we must be on guard.\nUse suggestions\n6. Use an LLM to perform a more inclusive data search. An LLM can assist researchers\nwith data gathering for scientific meta-analyses or syntheses by collating “grey literature”\nresources—reports issued by governmental and nongovernmental organisations rather than\nscientific journals. This is helpful because while there are established methods for systemati-\ncally searching the scientific literature using databases such as Web of Science [26], these\napproaches may neglect grey literature [27]. This oversight is particularly problematic in\napplied fields such as conservation and ecological restoration, where the insights of on-the-\nground practitioners are of central importance.\nResearchers can use GPT and other LLMs to collate and synthesise findings from grey liter-\nature (Box 3), which allows for easier incorporation into systematic reviews and facilitates\nknowledge sharing across organisations [28]. However, unless the LLM has internet access (as\nwith some GPT plugins or Microsoft’s NewBing), the ability of the model to excel at this task\nmay be limited by how comprehensive and recent its training corpus is. In the example below\n(Box 3), ChatGPT provides a helpful overview of organisations with relevant information but\nsome finer-scale details (e.g., ChatGPT’s estimation of website contents) are erroneous, either\ndue to model hallucination (Rule 5) or, potentially, changes occurring after the training data\nsnapshot was taken.\ncontains no statements supporting a link between bacterial-feeding or fungal-feeding\nnematodes and organic matter content.\nBox 3—Performing an LLM-assisted grey literature search\nHere, we use ChatGPT to generate a preliminary list of organisations that work in some\naspect of forest restoration and which may have published reports online detailing the\nimpact of their work.\nQ1: Please generate a list of forest restoration organizations that publish data on the bio-\ndiversity and carbon outcomes of their work.\nR1: Certainly! Here is a list of forest restoration\norganizations that publish data on the biodiversity and\ncarbon outcomes of their work:\n1. The Nature Conservancy: The Nature Conservancy is a\nglobal environmental organization that works to protect and\nrestore critical habitats, including forests. They publish\nregular reports on their conservation efforts, including\ndata on biodiversity and carbon sequestration.\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 7 / 19\n2. Trees for the Future: Trees for the Future is a non-\nprofit organization that works with local communities to\nplant trees and restore degraded lands. They publish annual\nreports that detail the impact of their work, including data\non biodiversity and carbon sequestration.\n3. Rainforest Alliance: The Rainforest Alliance is an\ninternational organization that works to conserve\nbiodiversity and promote sustainable livelihoods through\nresponsible land use practices. They publish regular\nreports on their forest conservation efforts, including\ndata on carbon sequestration and biodiversity.\n4. World Wildlife Fund: The World Wildlife Fund is a global\nconservation organization that works to protect and restore\ncritical habitats, including forests. They publish regular\nreports on their conservation efforts, including data on\nbiodiversity and carbon sequestration.\n5. Forest Stewardship Council: The Forest Stewardship\nCouncil is an international organization that promotes\nresponsible forest management practices. They publish\nregular reports on their certification process.\nQ2: Have these organizations published reports on their work online?\nR2: Yes, these organizations typically have published\nreports on their work available online. While I don’t have\nreal-time access to the internet, I can provide you with\ngeneral information about where to find these reports. You\ncan visit the websites of these organizations and look for\nsections such as “Publications,” “Reports,” or “Impact” to\nfind detailed information about their forest restoration\nprojects, including data on biodiversity and carbon\noutcomes.\nFor example:\n1. The Nature Conservancy: Visit their website at nature.\norg and explore their “Our Work” or “Publications”\nsections.\n2. Trees for the Future: Visit their website at trees.org\nand look for sections like “Impact” or “Resources” for\naccess to their reports.\n3. Rainforest Alliance: Visit their website at rainforest-\nalliance.org and search for sections such as “Our Work” or\n“Publications” to find their reports.\n4. World Wildlife Fund: Visit their website at wwf.org and\nexplore their “Conservation” or “Publications” sections for\naccess to their reports.\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 8 / 19\n5. Forest Stewardship Council: Visit their website at fsc.\norg and look for sections like “Resources” or\n“Publications” for their reports on responsible forest\nmanagement.\nPlease note that the availability and specific locations of\nthese reports may vary over time, so it’s best to explore\nthe respective websites or use their search functions to\nlocate the most up-to-date information.\nQ3: Please turn this into a table that facilitates finding and extracting data from the\nreports for these organizations, and 5 other relevant organizations.\nR3: Certainly! Here is a table that includes the\norganizations mentioned earlier, as well as five additional\nforest restoration organizations, along with relevant\ninformation that can facilitate finding and extracting data\nfrom their reports:\n[Table not shown for brevity, see Q4 for follow up that adds\ncolumn on geographical scope]\nNote that this table is not exhaustive and there may be\nadditional relevant sections and types of reports available\non each organization’s website. However, this should\nprovide a good starting point for finding and extracting\ndata from their reports.\nQ4: Please add a column to this table that describes the geographic scope of each\norganization.\nR4: Certainly! Here is an updated table that includes the\norganizations mentioned earlier, along with five additional\nforest restoration organizations, relevant sections on\ntheir website, types of reports they publish, and the\ngeographic scope of their work:\nOrganization Name Website Relevant Sections Types of Reports Geographical Scope\nThe Nature\nConservancy\nhttps://www.nature.\norg/\nOur Work,\nPublications\nAnnual reports, Impact\nreports, Biodiversity and\nCarbon reports\nGlobal\nTrees for the\nFuture\nhttps://trees.org/ Impact, Resources Annual reports, Impact\nreports, Biodiversity and\nCarbon reports\nAfrica, Asia, Latin\nAmerica, and the\nCaribbean\nRainforest\nAlliance\nhttps://www.\nrainforest-alliance.\norg/\nOur Work,\nPublications\nAnnual reports, Impact\nreports, Biodiversity and\nCarbon reports\nGlobal\nWorld Wildlife\nFund\nhttps://www.\nworldwildlife.org/\nConservation,\nPublications\nAnnual reports, Impact\nreports, Biodiversity and\nCarbon reports\nGlobal\nForest\nStewardship\nCouncil\nhttps://fsc.org/ Resources,\nPublications\nCertification reports,\nBiodiversity and Carbon\nreports\nGlobal\nEden\nReforestation\nProjects\nhttps://edenprojects.\norg/\nImpact, Stories Annual reports, Impact\nreports, Biodiversity and\nCarbon reports\nAfrica, Asia, Haiti,\nMadagascar, and Central\nAmerica\n(Continued )\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 9 / 19\n7. Use an LLM to summarise content. To help researchers make more efficient use of\ntheir time, an LLM can quickly generate short summaries based on lengthy input content. This\nis helpful because as a scientist, it’s essential to regularly read new literature, but balancing this\ntask with the duties of our own research, teaching, and supervision can be challenging. Yet,\nresearchers who fail to strike a good balance and don’t frequently investigate new literature\ncan miss out on findings that might helpfully inform and shape their own research programs,\nor which would be relevant to classes that they are teaching.\nCurrently, several third-party plugins for GPT (e.g., ChatPDF.com, UseChatGPT.AI, GPT\nAcademic, SciSpace copilot) can be used to generate summaries based on open-access scien-\ntific literature, complete with main points, findings, and contributions. Microsoft’s NewBing\nsearch engine, which incorporates GPT-4, can also be used for this purpose. With tailored\nstructural prompts (Box 4), a researcher can specify the length, style, and format they prefer\nfor a summary. ChatGPT can also respond to follow-up questions requesting more details, if\nneeded, producing a kind of interactive abstract. Yet, just as with standard abstracts, if a work\nappears to be of interest, appropriately contextualising and fully understanding the main find-\nings requires that a researcher read the full paper.\nAn LLM can even be used to produce summaries of internal documents, for example meet-\ning minutes, if meeting participants give their consent and no confidential information was\nshared (Rule 4). To facilitate this process, speech-to-text transcription software can first be\nused to produce a full written record of a meeting. Then, this transcribed meeting can be\nshared with the LLM, which can be tasked with producing a summary. For this use, the ade-\nquacy of the summary should of course be verified by the meeting participants to ensure that\nimportant points have not been left out nor misrepresented.\n8. Use an LLM to refine written English in formal and informal communication. An\nLLM can facilitate clearer and more idiomatic usage of English, the lingua franca of the\n6. (Continu ed )\nThe Arbor Day\nFoundation\nhttps://www.arborday.\norg/\nPrograms, Reports Annual reports, Impact\nreports, Biodiversity and\nCarbon reports\nUnited States and\ninternationally\nAmerican Forests https://www.\namericanforests.org/\nOur Work,\nPublications\nAnnual reports, Impact\nreports, Biodiversity and\nCarbon reports\nUnited States and\ninternationally\nTrees, Water &\nPeople\nhttps://www.\ntreeswaterpeople.org/\nOur Programs,\nReports\nAnnual reports, Impact\nreports, Biodiversity and\nCarbon reports\nLatin America and the\nUnited States\nConservation\nInternational\nhttps://www.\nconservation.org/\nOur Work,\nPublications\nAnnual reports, Impact\nreports, Biodiversity and\nCarbon reports\nGlobal\nhttps://do i.org/10.1371/j ournal.pc bi.1011767. t001\nNote that the geographic scope of each organization's work\nmay vary over time, and this information is accurate as of\nthe knowledge cutoff date for my training.\nAll organisations identified were relevant and many publish data or summaries of their\nimpacts in annual reports somewhere on their websites. An extended list of additional orga-\nnisations was provided with 1 additional prompt, and it is easy to export the list in a standard\nformat (e.g.,.csv). However, the list does contain several inaccuracies (see Rule 5). For exam-\nple, the “Relevant Sections” column often listed website sections that did not actually exist.\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 10 / 19\nBox 4—Using GPT to summarise scientific literature\nHere, we use GPT-4 (via NewBing) to summarise a recently published open-access sci-\nentific paper.\nQ1: I want you to act as a scientific paper summarizer. I will give you the URL of a scien-\ntific article. I want you to reply with a bold title for each section including the general\ninformation of this paper, the background of this research, the addressed question and\nhypothesis, the key findings, and major contributions. The summary of each section\nshould be logical, concise, clear, and informative. Make sure the summary includes most\nof the key information and can grip the audience. The URL is: https://www.nature.com/\narticles/s41467-02 2-30888-2.\nR1 (GPT-4 via NewBing): General information: The article is\ntitled “Global relationships in tree functional traits” and\nit was published in Nature Communications on 08 June 2022.\nThe authors are Daniel S. Maynard, Lalasia Bialic-Murphy,\nConstantin M. Zohner, Colin Averill, Johan van den Hoogen,\nHaozhi Ma, Lidong Mo, Gabriel Reuben Smith, Alicia T. R.\nAcosta, Isabelle Aubin, Erika Berenguer, Coline C. F.\nBoonman, Jane A. Catford, Bruno E. L. Cerabolini, Arildo S.\nDias, Andrés González-Melo, Peter Hietz, Christopher H.\nLusk, Akira S. Mori, Ülo Niinemets, Valério D. Pillar, Bruno\nX. Pinho, Julieta A. Rosell, Frank M. Schurr and Thomas W.\nCrowther1.\nBackground: Trees are subject to unique physiological,\nmechanical and ecological pressures due to their massive\nenergetic investments in woody support structures.\nFunctional traits are the physiological and morphological\nfeatures that determine how trees interact with, influence\nand respond to their environment. Understanding the\npatterns and trade-offs in tree functional traits is\nchallenging because of the diversity and complexity of tree\nform and function.\nQuestion and hypothesis: The authors aim to quantify the\nmultidimensional relationships in tree trait expression\nacross 18 functional traits encompassing leaf, seed, bark,\nwood, crown and root characteristics. They hypothesize that\nthese traits reflect two main axes: one related to leaf\neconomics (i.e., the trade-off between resource acquisition\nand conservation) and the other related to tree size and\ncompetition for light (i.e., the trade-off between growth\nand survival). They also expect that these axes show\nenvironmental convergence across temperature, moisture and\nelevation gradients.\nKey findings: The authors find that nearly half of trait\nvariation is captured by the two hypothesized axes1. They\nalso find that these axes exhibit correlated responses to\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 11 / 19\ninternational scientific community. This can be especially helpful for researchers who speak\nEnglish as a second language, who may face unique obstacles in the English-dominated envi-\nronment of global science.\nUnfortunately, peer review tends to disadvantage authors from the developing world and\nnon-English speaking countries [29] and researchers who speak English as a second language\nsometimes receive rude, discouraging remarks from referees [30]. Coupled with journal adop-\ntion of double-blind reviewing practices [31], an LLM can help to address this problem by\ncopyediting manuscripts and other communication to ensure that English is used idiomati-\ncally [32], reducing opportunities for bias from referees. Importantly, before using an LLM in\nthis way journal guidelines must be consulted (Rule 1). If such a use is not explicitly permitted\nunder journal policy, we suggest the model’s role as manuscript copyeditor should be directly\ncommunicated to journal editors.\nAn LLM’s ability to proofread and copyedit can also be helpfully extended to informal com-\nmunication as well. For example, an LLM can also be used to verify that e-mails and presenta-\ntions written in English capture the appropriate tone, which can be a challenge even for\nresearchers whose first language is English. Skilfully handling informal communication is\nimportant for researchers who seek to establish collaborative networks with peers they haven’t\nyet met in person (e.g., [33]). Since collaboration supports both basic scientific progress and\nscientific career development [34], minimising the barriers posed by language in this sphere\npromises significant benefit.\n9. Use an LLM to improve scientific coding. An LLM can help scientists to write com-\nputer code more quickly and efficiently [35], as LLMs excel not only in natural language pro-\ncessing but also in programming tasks across diverse programming languages. Models can be\nused to generate initial code snippets or to improve the structure, efficiency, and readability of\nexisting code. This can be done, for example, by (i) arranging code into logical sections like\nfunctions, classes and modules; (ii) refactoring code by suggesting better naming conventions,\neliminating code duplication, and improving overall code readability; (iii) suggesting alterna-\ntive algorithms or data structures that may improve efficiency and performance of the code; or\n(iv) writing clearer code annotations.\nAn LLM can also aid in debugging and error detection (Box 5). Yet, suggestions from LLMs\nmay not necessarily provide the most efficient code or follow established best practices in the\nenvironmental factors1. Moreover, they identify eight\ndistinct clusters of traits that capture the full\ndimensionality of trait space. These clusters reflect\ndifferent aspects of tree form and function such as drought\ntolerance, shade tolerance, dispersal ability and nutrient\ncycling.\nMajor contributions: The authors identify a core set of\ntraits needed to quantify global patterns in functional\nbiodiversity. They also contribute to the fundamental\nunderstanding of the functioning of forests worldwide by\nrevealing how tree traits shape their water, nutrient and\nlight economies1. They suggest that their trait framework\ncan be used to improve forest management and conservation\nstrategies.\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 12 / 19\nBox 5—Using GPT to debug computer code\nHere, the user provides ChatGPT with Google Earth Engine code (rendered as [. . .] in\nthe example) that is meant to perform a set of statistical aggregation and spatial calcula-\ntions within ecoregions [36] but is instead returning an error. ChatGPT identifies the\ncause of the error and suggests solutions. The initial suggested code returns a new error,\nbut with further prompting ChatGPT successfully corrects the error to produce func-\ntional code.\nQ1: [. . .] Here is my code in Google Earth Engine. I get this message error: Too many\nconcurrent aggregations. Can you help me to find a solution?\nR1: The error “Too many concurrent aggregations” occurs\nwhen you are trying to perform too many reduceRegion or\nother aggregation operations simultaneously. In your code,\nyou are using both reduceRegion and map functions over a\nlarge list of ecoIds. The reduceRegion is applied inside the\nmap function, which may cause too many concurrent\naggregation operations to run.\nTo fix this issue, you can try the following approaches:\n1. Split your ecoIds list into smaller chunks and process\neach chunk separately, then combine the results. You can use\nthe ee.List.slice() function to achieve this.\n2. Limit the number of ecoIds you process at once. You can\nexperiment with different numbers of ecoIds to find the\noptimal number that doesn’t cause the error.\n3. You can try to use other Earth Engine functions to\nperform the operations you need, such as reducing the number\nof aggregations by using simpler reducers or using other\nfunctions that don’t involve aggregation.\nHere is an example of how to split the ecoIds list into\nsmaller chunks and process them separately:\n// Define a function to process a chunk of ecoIds\nfunction processEcoIdsChunk(chunk) {\nvar chunkImageCollection = ee.ImageCollection(chunk.map\n(function(id) {\n// Your existing code for processing each ecoId\n}));\nreturn chunkImageCollection.mosaic();\n}\n// Split the ecoIds list into smaller chunks\nvar chunkSize = 10; // Adjust this value to find the optimal\nchunk size\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 13 / 19\nvar numChunks = ecoIds.length().divide(chun kSize).ceil();\nvar ecoIdsChunks = ee.List.sequence(0, numChunks.subtract\n(1)).map(function(chunkIndex) {\nvar startIndex = ee.Number(chunkIndex).multiply\n(chunkSize);\nvar endIndex = startIndex.add(chunkSize).min(ecoIds.length\n());\nreturn ecoIds.slice(startIndex, endIndex);\n});\n// Process each chunk and combine the results\nvar processedChunks = ecoIdsChunks.map(processEcoIdsChunk);\nvar imageWithPotValues = ee.ImageCollection\n(processedChunks).mosaic();\n// Add the layer to the map and print results\nprint(imageWithPotValues);\nMap.addLayer(imageWithPotValues);\nThis code will divide the ecoIds list into smaller chunks\nand process them one by one, potentially reducing the number\nof concurrent aggregations and avoiding the error. You may\nneed to experiment with the chunkSize value to find the\noptimal size that doesn’t cause the error.\nQ2: “Line 20: chunk.map is not a function” I get this error when running the code. Is\nthis because I didn’t implement the function the right way?\nR2: My apologies for the confusion. The error is occurring\nbecause the ‘chunk’ variable in the ‘processEcoIdsChunk’\nfunction is of type ‘ee.List’, but the ‘map()’ function is\nbeing called on it as if it were a JavaScript array. To fix\nthis, you need to cast ‘chunk’ to an ‘ee.List’ before\ncalling the ‘map()’ function on it. Here’s how to do that:\nReplace this line:\nvar chunkImageCollection = ee.ImageCollection(chunk.map\n(function(id) {\nWith this line:\nvar chunkImageCollection = ee.ImageCollection(ee.List\n(chunk).map(function(id) {\nNow, the ‘chunk’ variable is cast to an ‘ee.List’, allowing\nyou to call the ‘map()’ function without issues. This should\nresolve the error, and your code should work as expected.\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 14 / 19\nfield; depending on how recent the training data are, deprecated functions and packages may\nalso be used. In all cases, it’s crucial to verify the functionality of any provided code to ensure\nthat it aligns with the user’s specific needs.\nAn LLM can also facilitate code translation from one programming language to another,\nwhich can prove invaluable when packages or libraries needed for a specific analysis are only\navailable in an unfamiliar language. In addition to translating between different programming\nlanguages, LLMs can also translate computer code into natural language. In other words, they\ncan explain to a user in intuitive terms what each section of code does and generate documen-\ntation directly from the code itself. This can be invaluable when working with sporadically\ndocumented code.\nImportantly, the effective use of LLMs heavily depends on the user’s ability to craft precise,\nwell-defined prompts that clearly outline the task at hand. In the context of scientific coding,\nthis means the user must already have a strong understanding of the coding language in ques-\ntion as well as a good conceptual comprehension of the task. As such, the current generation\nof LLMs do not represent an alternative to developing this fundamental capacity, but rather a\nway to quickly address challenges that arise in coding.\n10. Use an LLM to jump-start your scientific writing process. Researchers can overcome\nwriter’s block and “blank page anxiety” by asking an LLM to produce an outline for their sci-\nentific paper (Box 1; Box 6). This can be helpful because writing is a major hurdle for many\nresearchers [37], with some of the biggest obstacles posing a challenge at the initial outset of a\nproject’s writing phase [38]. In addition to providing a starting point, an LLM can help to\norganise subsections, offer relevant examples, and fine-tune the overall flow of the manuscript.\nIn this way, an LLM can act for researchers as a fast and inexpensive proofreader and\ncopyeditor.\nBox 6—Using GPT to produce a tailored paper outline\nQ1: Give me a 4-heading structure for a research article. Topic: Climate change effects\non biodiversity in the tropics Context: Ecology Language: Academic Tone: Formal.\nR1: I. Introduction\nA. Background on climate change and its global impact\nB. Importance of studying climate change effects on\nbiodiversity in the tropics\nC. Research question and objectives\nII. Literature Review\nA. Overview of climate change impacts on biodiversity\nworldwide\nB. Key studies and findings on climate change effects on\nbiodiversity in the tropics\nC. Knowledge gaps and research limitations\nIII. Methodology\nA. Study area and data collection\nB. Variables and measurements\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 15 / 19\nImportantly, however, an LLM cannot be assumed to provide reliable factual information\n(see Rule 5). Thus, just as with suggestions from a proofreader who may not have subject\nexpertise, erroneous statements can inadvertently appear (admittedly perhaps for different rea-\nsons). Additionally, while an LLM can propose a structure for a researcher’s manuscript, there\nis no guarantee that this structure is the best choice for the author’s purposes. Authors must\ntherefore still carefully evaluate and revise LLM suggestions using their own expertise, while\nensuring that they do not directly incorporate LLM-generated text into their manuscript if\ndoing so would contravene journal rules or constitute plagiarism (Rules 1 and 4).\nConclusions\nIn addition to transforming the world economy [1], generative AI tools like LLMs will likely\ntransform the way we do science [5]. Alongside great potential benefits stand great potential\ndangers, and within both of these categories are certain to be uses of generative AI that we\n(and others) have not anticipated. Indeed, as we explore these new tools, we must not lose\nsight of the unresolved dilemmas that still surround generative AI technology [7,16]. Some of\nthe challenges relevant for research include the use of unspecified, potentially biased training\ndatasets for commercial models [16], an implicit attachment to existing scientific paradigms\n[15], and a sizeable carbon footprint [39]. Issues such as these are sufficiently complex so as to\npreclude simple, actionable solutions, such as those we can offer here.\nNevertheless, we suggest that reduction of potential harm in LLM use for science may\nalready be supported by following Rules 1 to 5. With these caveats firmly in mind, a charitable\nresearcher may conceive of GPT and other LLMs as a research assistant, copyeditor, or consul-\ntant (Rules 6 to 10) who is imperfect and does not possess subject knowledge, thus sometimes\nmaking erroneous suggestions or statements.\nBefore beginning, researchers must ensure that their planned LLM use complies with jour-\nnal guidelines (Rule 1) and does not appear to pose substantial, unmitigable risk (Rule 2). To\navoid plagiarism (Rule 3), LLM-generated content should not be used without appropriate\nattribution, and at no point should confidential information be shared in the course of model\nC. Statistical or analytical methods used\nIV. Results and Discussion\nA. Presentation of findings related to climate change\neffects on biodiversity in the tropics\nB. Discussion of the results in the context of existing\nliterature\nC. Implications and potential future directions\nV. Conclusion\nA. Summary of the main findings\nB. Significance of the research and its contribution to the\nfield\nC. Recommendations for future research and policy\nimplications\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 16 / 19\nusage (Rule 4). Finally, due to the possibility of hallucination, all LLM-generated content must\nbe fact checked (Rule 5). If these guidelines are respected and regularly revised as circum-\nstances develop, we believe that generative AI tools like LLMs stand to significantly accelerate\nscientific progress for the benefit of humankind.\nSupporting information\nS1 Appendix. An example reporting document for large language model use in science.\n(PDF)\nAcknowledgmen ts\nWe thank F Ardila Camelo for insightful comments and helpful suggestions.\nAuthor Contributions\nConceptualization: Gabriel Reuben Smith.\nFunding acquisition: Gabriel Reuben Smith, Camille S. Delavaux, Daniel S. Maynard, Zhaofei\nWu, Gayoung Yang, Qingzhou Zhao, Constantin M. Zohner, Thomas W. Crowther.\nInvestigation: Gabriel Reuben Smith, Carolina Bello, Lalasia Bialic-Murphy, Emily Clark,\nCamille S. Delavaux, Camille Fournier de Lauriere, Johan van den Hoogen, Thomas Lau-\nber, Haozhi Ma, Daniel S. Maynard, Matthew Mirman, Lidong Mo, Dominic Rebindaine,\nJosephine Elena Reek, Leland K. Werden, Zhaofei Wu, Gayoung Yang, Qingzhou Zhao,\nConstantin M. Zohner, Thomas W. Crowther.\nProject administration: Gabriel Reuben Smith.\nSupervision: Thomas W. Crowther.\nWriting – original draft: Gabriel Reuben Smith, Carolina Bello, Lalasia Bialic-Murphy, Emily\nClark, Camille S. Delavaux, Camille Fournier de Lauriere, Johan van den Hoogen, Thomas\nLauber, Haozhi Ma, Daniel S. Maynard, Matthew Mirman, Lidong Mo, Dominic Rebin-\ndaine, Josephine Elena Reek, Leland K. Werden, Zhaofei Wu, Gayoung Yang, Qingzhou\nZhao, Constantin M. Zohner, Thomas W. Crowther.\nWriting – review & editing: Gabriel Reuben Smith, Carolina Bello, Lalasia Bialic-Murphy,\nEmily Clark, Camille S. Delavaux, Camille Fournier de Lauriere, Johan van den Hoogen,\nThomas Lauber, Haozhi Ma, Daniel S. Maynard, Matthew Mirman, Lidong Mo, Dominic\nRebindaine, Josephine Elena Reek, Leland K. Werden, Zhaofei Wu, Gayoung Yang, Qingz-\nhou Zhao, Constantin M. Zohner, Thomas W. Crowther.\nReferences\n1. Hatzius J, Briggs J, Kodnani D, Pierdom enico G. The Potentia lly Large Effects of Artificial Intelligenc e\non Economic Growth. 2023 Mar. Availab le from: https://ww w.gspublishin g.com/co ntent/rese arch/en/\nreports/20 23/03/27/d64e0 52b-0f 6e-45d7-9 67b-d7be35 fabd16.htm l.\n2. OpenAI. Introduci ng ChatGPT . [cited 2023 Jun 19]. Availab le from: https://opena i.com/ blog/chatgp t.\n3. Hu K. ChatGPT sets record for fastest -growing user base—a nalyst note. Reuters. 2 Feb 2023. Avail-\nable from: https://www .reuters.co m/technolog y/chatgpt-se ts-record-fast est-growing-us er-base-\nanalyst-no te-2023-02 -01/.\n4. van Dis EAM, Bollen J, Zuidema W, van Rooij R, Bockting CL. ChatGPT: five priorities for research .\nNature. 2023; 614:224– 226. https://doi.or g/10.103 8/d41586-02 3-00288-7 PMID: 36737653\n5. Stokel-W alker C, Van Noorden R. What ChatGP T and generativ e AI mean for science. Nature. 2023;\n614:214–21 6. https://doi.or g/10.1038 /d41586-023 -00340-6 PMID: 36747115\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 17 / 19\n6. Liebrenz M, Schleifer R, Buadze A, Bhugra D, Smith A. Generatin g scholarly content with ChatGPT :\nethical challeng es for medical publishing . The Lancet Digital Health. Elsevier Ltd; 2023. p. e105–e 106.\nhttps://doi.or g/10.101 6/S2589-75 00(23)000 19-5 PMID: 36754725\n7. Harris T, Raskin A. The A.I. Dilemma. United States of America: Center for Huma ne Technology ; 2023.\n8. Weidinger L, Uesato J, Rauh M, Griffin C, Sen Huang P, l J, et al. Taxonomy of Risks posed by Lan-\nguage Models. ACM Internat ional Conference Proceeding Series. Association for Comp uting Machin-\nery; 2022. p. 214–229. https://doi. org/10.1145/3 531146. 3533088\n9. The AI writing on the wall. Nat Mach Intell. 2023; 5:1–1. https:// doi.org/10.10 38/s4225 6-023-006 13-9\n10. Tools such as ChatGPT threaten transparent science ; here are our ground rules for their use. Nature.\n2023; 613:612 –612. https://doi.or g/10.103 8/d41586-02 3-00191-1 PMID: 366940 20\n11. Yampolskiy RV. Unpredi ctability of AI. ArXiv. 2019. Availab le from: http://arxiv. org/abs/1905. 13053.\n12. Thorp HH. ChatGP T is fun, but not an author. Science. American Association for the Advancem ent of\nScience. 2023. p. 313. https://doi.or g/10.1126/s cience.adg 7879 PMID: 367014 46\n13. Shelby R, Risman i S, Henne K, Aj M, Rostamzad eh N, Nicholas P, et al. Sociotech nical Harms of Algo-\nrithmic Systems: Scoping a Taxonomy for Harm Reduct ion. ACM. 2023:723–741 . https://doi.or g/10.\n1145/36002 11.3604673\n14. Derczynski L, Kirk HR, Balachandra n V, Kumar S, Tsvetkov Y, Leiser MR, et al. Assessing Langua ge\nModel Deployment with Risk Cards. ArXiv. 2023. Availab le from: http://arxiv .org/abs/2 303.18190.\n15. Leslie D. Does the sun rise for ChatGPT ? Scientific discov ery in the age of generativ e AI. AI and Ethics.\n2023. https://d oi.org/10.100 7/s43681 -023-0031 5-3\n16. Birhane A, Kasirzadeh A, Leslie D, Wachter S. Science in the age of large language models. Nature\nReviews Physics. Springer. Nature. 2023:277–2 80. https://doi.or g/10.103 8/s42254-023- 00581-4\n17. Khalil M, Er E. Will ChatGP T get you caught? Rethinking of Plagiarism Detection. ArXiv. 2023. Availab le\nfrom: http://arxiv.or g/abs/230 2.04335.\n18. Anders BA. Is using ChatGP T cheating, plagiarism, both, neither, or forward thinking? Patterns. 2023;\n4:100694. https://doi.or g/10.1016/ j.patter.2023.1 00694 PMID: 36960444\n19. Perkins M. Academic integrity considerat ions of AI Large Language Models in the post-pan demic era:\nChatGP T and beyond. Journal of University Teaching and Learning. Practice. 2023:20 . https://doi.or g/\n10.53761/ 1.20.02.07\n20. Markovsk i Y. How your data is used to improve model performance. [cited 2023 Jun 25]. Available from:\nhttps://help.o penai.com /en/articles /5722486-ho w-your-d ata-is-used-to -improve -model-per formance.\n21. Borji A. A Categorica l Archive of ChatGP T Failures. ArXiv. 2023. Available from: http://arxiv.or g/abs/\n2302.03494 .\n22. Thorndik e EL. A constant error in psychologic al ratings. J Appl Psycho l. 1920; 4:25–29. https:// doi.org/\n10.1037/ h0071663\n23. Zhu Z, Piao S, Myneni RB, Huang M, Zeng Z, Canadell JG, et al. Greening of the Earth and its drivers.\nNat Clim Chang. 2016; 6:791–795. https:// doi.org/10.10 38/nclimate 3004\n24. Bar-On YM, Phillips R, Milo R. The biomass distribu tion on Earth. Proc Natl Acad Sci U S A. 2018;\n115:6506–6 511. https://doi.or g/10.107 3/pnas.171 1842115 PMID: 29784790\n25. van den Hoogen J, Geisen S, Routh D, Ferris H, Traunspu rger W, Wardle DA, et al. Soil nematode\nabundanc e and functional group compos ition at a global scale. Nature. 2019; 572:194–19 8. https://doi.\norg/10.1038/ s41586-019- 1418-6 PMID: 3134128 1\n26. Gough D, Oliver S, Thomas J, editors. An Introduction to Systematic Reviews. 2nd ed. London, United\nKingdom : SAGE Publicat ions Ltd; 2017.\n27. Paez A. Gray literature: An importan t resource in systematic reviews. J Evid Based Med. 2017; 10:233–\n240. https://do i.org/10.1111 /jebm.122 66 PMID: 288575 05\n28. Ladouce ur E, Shackelfo rd N, Bouazza K, Brudvig L, Bucharov a A, Conradi T, et al. Knowled ge sharing\nfor shared success in the decade on ecosystem restorat ion. Ecol Solut Evid. 2022:3. https://doi.or g/10.\n1002/2688-8 319.121 17\n29. Smith OM, Davis KL, Pizza RB, Waterman R, Dobson KC, Foster B, et al. Peer review perpet uates bar-\nriers for historical ly excluded groups. Nat Ecol Evol. 2023. https://doi.or g/10.103 8/s41559-023- 01999-w\nPMID: 369147 73\n30. Romero-O livares AL. Research ers, don’t be rude to nonnative English speakers. Science. 2019.\nhttps://doi.or g/10.112 6/science.c aredit.aaz7179\n31. Tomkins A, Zhang M, Heavlin WD. Reviewe r bias in single- versus double-bli nd peer review. Proc Natl\nAcad Sci U S A. 2017; 114:127 08–12713. https://doi. org/10.1073/p nas.1707 323114 PMID: 291383 17\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 18 / 19\n32. Berdejo-E spinola V, Amano T. AI tools can improve equity in science. Science. 1979; 2023(37 9):991–\n991. https://do i.org/10.1126 /science. adg9714 PMID: 36893248\n33. Smith GR, Crowther TW, Eisenhauer N, van den Hoogen J. Building a global database of soil microbial\nbiomass and function: a call for collabor ation. Soil Org. 2019; 91:140–143. https://doi.or g/10.25674/\nso91iss3pp1 40 PMID: 32577136\n34. van der Wal JEM, Thorog ood R, Horrocks NPC. Collabor ation enhances career progression in aca-\ndemic science, especially for female researchers . Proc Biol Sci. 2021; 288:202 10219. https://doi.or g/\n10.1098/ rspb.2021.0219 PMID: 34493075\n35. Merow C, Serra-Diaz JM, Enquist BJ, Wilson AM. AI chatbots can boost scientific coding. Nat Ecol\nEvol. 2023:96 0–962. https://doi.o rg/10.1038/s41 559-023-02 063-3 PMID: 37100951\n36. Dinerstein E, Olson D, Joshi A, Vynne C, Burgess ND, Wikramana yake E, et al. An Ecoregion- Based\nApproach to Protecti ng Half the Terrestrial Realm. Bioscience . 2017; 67:534–545. https:// doi.org/10.\n1093/bios ci/bix014 PMID: 28608869\n37. Aydin A, Yu ¨ ru ¨ k SE, Reisoğl u İ, Goktas Y. Main barriers and possible enablers of academician s while\npublishing. Scientome trics. 2023; 128:623–650. https://d oi.org/10.100 7/s11192 -022-0452 8-x PMID:\n36274791\n38. Ahmed SJ, Gu ¨ ss CD. An Analysis of Writer’s Block: Causes and Soluti ons. Creat Res J. 2022; 34:339–\n354. https://do i.org/10.1080 /1040041 9.2022.203143 6\n39. Bender EM, Gebru T, McMill an-Major A, Shmitchel l S. On the dangers of stochas tic parrots: Can lan-\nguage models be too big? FAccT 2021— Proceedings of the 2021 ACM Conferen ce on Fairness,\nAccountab ility, and Transparency . Association for Computing Machiner y, Inc. 2021. p. 610–623.\nhttps://doi.or g/10.114 5/3442188.34 45922\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011767 January 31, 2024 19 / 19"
}