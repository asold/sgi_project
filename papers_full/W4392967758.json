{
    "title": "HomoGenius: a Foundation Model of Homogenization for Rapid Prediction of Effective Mechanical Properties using Neural Operators",
    "url": "https://openalex.org/W4392967758",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2157904348",
            "name": "Yizheng Wang",
            "affiliations": [
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A2068388382",
            "name": "Xiang Li",
            "affiliations": [
                "Hainan Normal University"
            ]
        },
        {
            "id": "https://openalex.org/A2319794095",
            "name": "Ziming Yan",
            "affiliations": [
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A2098769754",
            "name": "Yu-Qing Du",
            "affiliations": [
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A3037294611",
            "name": "Jinshuai Bai",
            "affiliations": [
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A2171982520",
            "name": "Bokai Liu",
            "affiliations": [
                "Umeå University"
            ]
        },
        {
            "id": "https://openalex.org/A2013128078",
            "name": "Timon Rabczuk",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2099366239",
            "name": "Yinghua Liu",
            "affiliations": [
                "Tsinghua University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3163993681",
        "https://openalex.org/W6600175564",
        "https://openalex.org/W6600339963",
        "https://openalex.org/W6819060087",
        "https://openalex.org/W4225906496",
        "https://openalex.org/W1991743075",
        "https://openalex.org/W2015925618",
        "https://openalex.org/W2146401910",
        "https://openalex.org/W2939258959",
        "https://openalex.org/W2101021285",
        "https://openalex.org/W4210423197",
        "https://openalex.org/W3214496267",
        "https://openalex.org/W2782232760",
        "https://openalex.org/W2171923911",
        "https://openalex.org/W48302177",
        "https://openalex.org/W2811388867",
        "https://openalex.org/W2549301129",
        "https://openalex.org/W2194775991",
        "https://openalex.org/W1989993440",
        "https://openalex.org/W4387117710",
        "https://openalex.org/W2805490233",
        "https://openalex.org/W2152058477",
        "https://openalex.org/W1984332354",
        "https://openalex.org/W2081085308",
        "https://openalex.org/W2932601918",
        "https://openalex.org/W4299792679",
        "https://openalex.org/W2118065565",
        "https://openalex.org/W2793544513",
        "https://openalex.org/W2962216334",
        "https://openalex.org/W4287264286",
        "https://openalex.org/W3101173115",
        "https://openalex.org/W4281478279",
        "https://openalex.org/W4223461113",
        "https://openalex.org/W3150630572",
        "https://openalex.org/W2789271228",
        "https://openalex.org/W2088057495",
        "https://openalex.org/W2051236172",
        "https://openalex.org/W4386906897",
        "https://openalex.org/W3173511169",
        "https://openalex.org/W2979786244",
        "https://openalex.org/W3081214735",
        "https://openalex.org/W4383218913",
        "https://openalex.org/W2062325236",
        "https://openalex.org/W2092737754",
        "https://openalex.org/W2077098498",
        "https://openalex.org/W2899283552",
        "https://openalex.org/W2094751519",
        "https://openalex.org/W1989170623",
        "https://openalex.org/W2964473292",
        "https://openalex.org/W2108253958",
        "https://openalex.org/W3008239204",
        "https://openalex.org/W2075115394",
        "https://openalex.org/W2030749064",
        "https://openalex.org/W2139923370",
        "https://openalex.org/W4319452154",
        "https://openalex.org/W3205468886",
        "https://openalex.org/W2949224652",
        "https://openalex.org/W2074176021",
        "https://openalex.org/W4281725518",
        "https://openalex.org/W3120338085",
        "https://openalex.org/W2086340132",
        "https://openalex.org/W4384561839",
        "https://openalex.org/W2032196855",
        "https://openalex.org/W3118310857",
        "https://openalex.org/W4367055058",
        "https://openalex.org/W4287077061"
    ],
    "abstract": "<title>Abstract</title> Homogenization is an essential tool for studying multiscale physical phenomena. However, traditional numerical homogenization, heavily reliant on finite element analysis, requires extensive computation costs, particularly in handling complex geometries, materials, and high-resolution problems. To address these limitations, we propose a numerical homogenization model based on operator learning: HomoGenius. The proposed model can quickly provide homogenization results for arbitrary geometries, materials, and resolutions, increasing the efficiency by a factor of 80 compared to traditional numerical homogenization methods. We validate effectiveness of our model in predicting the effective elastic modulus on periodic materials (TPMS: Triply Periodic Minimal Surface), including complex geometries, various Poisson's ratios and elastic modulus, and different resolutions for training and testing. The results show that our model possesses high precision, super efficiency, and learning capability.",
    "full_text": "HomoGenius: a Foundation Model of\nHomogenization for Rapid Prediction of Effective\nMechanical Properties using Neural Operators\nyizheng Wang \nTsinghua University https://orcid.org/0000-0002-3899-7008\nXiang Li \nHainan Normal University\nZiming Yan \nTsinghua University\nYuqing Du \nTsinghua University\nJinshuai Bai \nTsinghua University\nBokai Liu \nUmeå University\nTimon Rabczuk \nBauhaus University\nyinghua Liu  \n \nTsinghua University\nArticle\nKeywords: Homogenization, Physics-informed neural network, Neural operator, Fourier neural operator,\nDeep learning, Effective modulus\nPosted Date: March 19th, 2024\nDOI: https://doi.org/10.21203/rs.3.rs-3994416/v1\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nAdditional Declarations: There is NO Competing Interest.\n\nHomoGenius: a F oundation Model of Homogenization for Rapid Prediction of Eﬀective1\nMechanical Properties using Neural Operators2\nYizheng W ang a,b, Xiang Li d,∗, Ziming Y an a, Y uqing Du a, Jinshuai Bai a,e, Bokai Liu c, Timon Rabczuk b,∗, Yinghua Liu a,∗3\naDepartment of Engineering Mechanics, Tsinghua University, Beijing 100084, China4\nbInstitute of Structural Mechanics, Bauhaus-Universität Weimar, Marienstr. 15, D-99423 Weimar, Germany5\ncIntelligent Human-Buildings Interactions Lab, Department of Applied Physics and Electronics, Umeå University, 901 87 Umeå, Sweden6\ndSchool of Information Science and Technology Hainan Normal University, Haikou 570206, P. R. China7\neSchool of Mechanical, Medical and Process Engineering, Queensland University of Technology, Brisbane, QLD 4000, Australia8\nAbstract9\nHomogenization is an essential tool for studying multiscale physical phenomena. However, traditional numerical homogenization,\nheavily reliant on őnite element analysis, requires extensive computation costs, particularly in handling complex geometries,\nmaterials, and high-resolution problems. T o address these limitations, we propose a numerical homogenization model based\non operator learning: HomoGenius. The proposed model can quickly provide homogenization results for arbitrary geometries,\nmaterials, and resolutions, increasing the efficiency by a factor of 80 compared to traditional numerical homogenization methods.\nW e validate effectiveness of our model in predicting the effective elastic modulus on periodic materials (TPMS: T riply Periodic\nMinimal Surface), including complex geometries, various Poisson’s ratios and elastic modulus, and different resolutions for\ntraining and testing. The results show that our model possesses high precision, super efficiency , and learning capability .\nKeywords: Homogenization, Physics-informed neural network, Neural operator, F ourier neural operator, Deep learning,10\nEffective modulus11\n1. Introduction12\nThe homogenization method is a mathematical method for studying the macroscale performance of multiscale structures13\nor materials. The core idea of the homogenization method is to use a mathematical model to simplify the complex structural14\nbehavior on the microscale to a homogenized representation on the macroscale. The homogenization method plays an important15\nrole in the őeld of mechanics and engineering. The homogenization method in mechanics allows researchers to predict the16\nmechanical behavior at the macroscale from the material structures at the microscale. In this way , researchers can perform the17\nmechanical analysis only on the macro-level model while maintaining an acceptance level of accuracy in the analysis, signiőcantly18\nreducing the complexity and cost of the calculations [ 1, 2, 3]. F or example, researchers have applied homogenization methods19\nto study the macroscopic material properties of various materials, such as őber-reinforced composites [ 4], particulate composites20\n[5], laminated composites [ 6]; metamateiral such as photonic crystals [ 7], phononic crystals [ 8], auxetic materials with negative21\nPoisson’s ratio [ 9], electromagnetic metamaterial [ 10]; porous media such as rock [ 11], wood [ 12], trabecular bone [ 13, 14], lattice22\nmaterials [ 15, 16], various cellular materials [ 17, 18, 19], functionally graded materials [ 20, 21]. As a result, the homogenization23\nmethod is essential in science and engineering.24\nThe common branches of homogenization include direct, asymptotic, statistical and numerical methods [ 3, 22, 23, 24]. In25\nthe numerical (or computational) homogenization method, numerical methods such as the őnite element method are usually26\nused as a bridge between different scales for solving partial differential equations (PDEs). In the numerical homogenization27\nmethod, numerical simulations and analyses are obtained by solving PDEs at the microscale level, and the numerical results28\nare then converted into macroscopic material properties. V arious numerical tools for solving PDEs, including the őnite element29\nmethod [ 25], the boundary element method [ 26], the meshless method [ 27], discrete element method [ 28], extended őnite element30\nmethod (XFEM) [ 29], spectral method [ 30], and molecular dynamics [ 31] have been incorporated with numerical homogenization.31\nHowever, the numerical computation of PDEs, especially using the őnite element method, plays the most important role in the32\nprocess of numerical homogenization, yet it involves a signiőcantly large amount of computation. Therefore, reducing the33\ncomputational load during numerical homogenization is of critical importance.34\nThe recent advancements in the őeld of AI for PDEs have introduced a new data-driven paradigm, signiőcantly reducing35\nthe computational time for solving PDEs [ 32]. Given that solving PDEs is a critical step in homogenization, employing AI36\ntechnologies has the potential to greatly increase the computational efficiency of homogenization, which serves as the motivation37\nfor our foundation model of homogenization. The core of AI for PDEs is data-driven, and human understanding of nature38\nhas always heavily relied on data observed from the natural world. This can be traced back to the time of Kepler, who39\ndiscovered the well-known law of planetary motion from massive documented data. Recently , the revival of machine learning40\nmethods has spurred a renaissance of data-driven scientiőc computing [ 33]. W e introduce some of latest research in AI for41\n∗ Corresponding author\nEmail addresses: li_xiang@hainnu.edu.cn (Xiang Li), timon.rabczuk@uni-weimar.de (Timon Rabczuk), yhliu@tsinghua.edu.cn (Yinghua Liu)\nFebruary 27, 2024\n2\nPDEs. A groundbreaking approach introduced in 2019 is based on Physics-Informed Neural Networks (PINNs) [ 34], presenting42\na novel scientiőc computing method using deep learning [ 35]. PINNs integrates data and physical equations through neural43\nnetworks and exhibits unique advantages in inverse problems and high-dimensional scenarios [ 36]. Recently , operator learning44\nhas gained considerable attention [ 37]. Notable works in neural operators include DeepONet [ 37] and F ourier neural operator45\n(FNO) [ 38]. Initially , operator learning was essentially a data-driven approach, differing from traditional methods by possessing46\nreliable mathematical support and discrete invariance [ 39]. The theoretical foundation of DeepONet is based on a universal47\napproximation to nonlinear operators [ 40] that neural networks can approximate any continuous operator. FNO, on the other48\nhand, is grounded in F ourier transforms [ 41, 42]. Discrete invariance implies the ability to train and test on arbitrary grids without49\nthe need for retraining when the grid discretization changes. This feature is important in practical engineering applications [ 43],50\nespecially in our numerical homogenization process. The most signiőcant advantage of employing operator learning to solve51\nPDEs is the substantial acceleration of computations, and the efficiency of operator learning is several orders of magnitude52\nhigher than traditional numerical algorithms [ 32], especially in numerical weather prediction [ 44, 45]. The recent advancements53\nin operator learning involve integrating physics equations with operator learning, known as Physics-Informed Neural Operator54\n(PINO) [ 46, 47, 48, 49]. PINO utilizes operator learning to achieve an initial solution that closely approximates the true solution,55\nand then leverages physical equations for őne-tuning from this initial solution to attain a solution with enhanced accuracy .56\nTherefore, we are motivated to integrate operator learning into the homogenization process to reduce the computational57\nload by several orders of magnitude. In this study , we have chosen to illustrate the proposed numerical homogenization method58\nsupported by neural operators using a type of cellular materials. Cellular materials are characterized by porous microstructures59\nleading to low weight and exceptional mechanical performance. The superior speciőc material properties and engineering values60\nof natural cellular materials such as wood and cork have motivated the development of artiőcial cellular materials to achieve high61\nspeciőc stiffness and [ 50, 51], strength [ 52], negative Poisson’s ratio [ 53, 54], energy absorption [ 55][56], thermal insulation [ 57],62\nand acoustic manipulation [ 58]. Advances in artiőcial cellular materials are paving the way for applications in aerospace [ 59],63\nautomotive [ 60], medical implants [ 61, 62], soft robotics [ 63][64] and electronic devices [ 65]. T riply Periodic Minimal Surfaces64\n(TPMS) is a type of artiőcial cellular material with topology-driven properties. The concept of TPMS was őrst proposed by65\nHermann Schwarz in 1865 [ 66]. Several commonly used TPMS models are Schwarz Primitive, Schwarz Diamond, Neovious,66\nSchoen Gyroid, Schoen IWP , Schoen FRD, Fischer Kosh S. TPMS surfaces are spatially periodic in all three dimensions and67\nhave zero mean curvature [ 67]. TPMS materials are characterized by exceptional strength-to-weight and surface-to-volume ratios68\nand have therefore been successfully used in various engineering applications, including artiőcial implants [ 68], heat exchangers69\n[69], energy absorption [ 70], soft robotics [ 71], energy storage [ 72], sound absorption [ 73]. The homogenization method has been70\nsuccessfully used to characterize the effective mechanical properties of TPMS [ 74, 75, 76]. However, there are few research works71\nthat have integrated the modern neural operator into the numerical homogenization method.72\nTherefore, in this research, we propose the numerical homogenization model using the neural operator. In particular, our73\nmodel exhibits three major characteristics: (1)Compared to traditional methods, our model demonstrates high accuracy and74\nsuper efficiency , being 1,000 times faster in terms of the prediction of the őeld, and possesses the ability to perform homogenization75\ncomputations on any geometric shape. (2)Our model is capable of rapid homogenization calculations for any material, including76\nthose deőned by various elastic modulus and Poisson’s ratios. (3)Beneőting from the discretization-invariant of operator learning,77\nour model can handle data of any resolution, meaning the training and testing resolutions can be entirely distinct. The model78\ncan be trained with low-resolution datasets and tested with high-resolution datasets, thereby showcasing a ŕexible learning79\ncapability . Throughout this article, we demonstrate the capabilities of the proposed foundation model of homogenization by80\napplying it to various TPMS including different geometry , different materials, and different resolutions.81\n2. Results82\n2.1. HomoGenius: Foundation model of homogenization83\nHomogenization is essential in natural sciences and engineering, where traditional methods mainly depend on őnite element84\nanalysis (FEA). However, introducing a new geometric structure or material necessitates a recalculation of FEA, incurring85\nsigniőcant computational costs, especially for high resolution and complex geometries. Thus, enhancing the efficiency of86\nhomogenization processes for complex geometries and super high resolution is of paramount importance. Our solution, HomoGenius87\nshown in Fig. 1 , utilizes operator learning to substantially improve homogenization efficiency . Provided the training and test88\ndatasets are similarly distributed, HomoGenius can facilitate rapid homogenization calculations across any geometry , material,89\nand even across different resolutions. More details are elaborated in Methods. F ollowing, we will demonstrate our model’s90\nexceptional performance across various geometries, different materials, and diverse resolutions through numerical experiments.91\n2.2. Diﬀerent geometry92\nT o assess the performance of HomoGenius across various geometries, we employed a range of periodic structures known as93\nT riply Periodic Minimal Surfaces (TPMS). TPMS represents a classical type of periodic structure in artiőcial cellular materials,94\ncharacterized by its topology-driven properties.95\n3\nW e introduce the mathematical model of the TPMS. A minimal surface is characterized to have a zero value of mean curvature96\nat any given point of the surface. TPMS is inőnitely periodic in three-dimensional space. Level-set approximation is a commonly97\nused approach to represent a minimal surface. The mathematical model of TPMS features level-set equations combined with98\na series of trigonometric functions, which enables TPMS ŕexibility manipulation of its topology and mechanical properties.99\nLevel-set equations are normally described by100\nϕ(x, y, z ) = c, (1)\nwhere x, y, and z are the spatial coordinates. ϕ(x, y, z ) on the left hand side of the equation represents a diffusive őeld in the 3D101\nspace. ϕ = c denotes the level-set value c segments the 3d space of a TPMS unit cell into two connected sub-domains, with each102\nsub-domain representing solid material and void, respectively . The value of c can be used to indicate the volumetric portion of103\nvoid. The porosity of the TPMS unit cell can be hence manipulated by adjusting c value. Iso-surface of TPMS means that an104\niso-value equals c.105\nA broadly utilized level-set equation of TPMS is named Schwarz Primitive formatted by106\ncos(2πx) + cos(2 πy) + cos(2 πz) = c (2)\nThe above level-set equation denotes a zero-thickness shell-like topology , known as the minimal surface. W e need to further107\ngenerate load-bearing TPMS lattice material based on the minimal surfaces. T wo types of TPMS lattices are formulated based108\non minimal surfaces. The őrst type is named by łsolid-networksž, satisfying109\nϕ(x, y, z ) > c (3)\nF or \"solid-networks\" TPMS cells, the volume with the diffusive őeld value ϕ(x, y, z ) > c is recognized as solid material, while110\nthe rest of the unit cell is recognized as void or pore. The second type is named \"sheet-networks\". The \"sheet-networks\" TPMS111\nis governed by112\n−c ≤ ϕ(x, y, z ) ≤ c (4)\nAs its name suggests, \"sheet-networks\" selects a thin layer of volume around the zero-thickness shell of ϕ(x, y, z ) = c, representing113\na sheet-like topology of unit cell. The \"solid-networks\" and \"sheet-networks\" TPMS present distinguishable topology characteristics114\nand elastic mechanical properties, offering more ŕexibility to its \"topology-driven\" capability .115\nAnother key topological parameter for TPMS is volume fraction (or relative density). V olume fraction refers to the ratio116\nbetween the volume of solid material and the volume of the entire TPMS unit cell. V olume fraction is directly related to the117\neffective modulus and stiffness of a TPMS unit cell, and hereby affects the homogenization elastic matrix.118\nIn this study , we created a series of TPMS unit cells for training and verifying the proposed neural operator based homogenization119\nmethod. In this study , we selected 3 different TPMS level-set equations, including \"Schoen Gyroid\", \"Schwarz Diamond\", and120\n\"Fischer Kosh S\". The level-set equations for each unit cell type are listed:121\nSchoenGyroid : sin(2 πx) cos(2πy) + sin(2 πy) cos(2πz) + sin(2 πz) cos(2πx) = c\nSchwarzDiamond : cos(2 πx) cos(2πy) cos(2πz) − sin(2πx) sin(2πy) sin(2πz) = c\nF ischerKoshS : cos(4 πx) sin(2πy) cos(2πz) + cos(2 πx) cos(4πy) sin(2πz) + sin(2 πx) cos(2πy) cos(4πz) = c\n(5)\nW e generated 1800 TPMS unit cells with resolution 128*128*128 (The resolution of training and testing set are both 128)122\nfor studying the proposed homogenization method. These 1800 unit cells are divided into 3 groups (\"Sheet-networks\": Schoen123\nGyroid, Schwarz Diamond, and Fischer Kosh S). F or each TPMS category , we acquired 600 different geometric structure data124\nsets with varying volume fractions. The level-set equation and TPMS type of each group are listed in Eq. (5). Speciőcally ,125\nthe volume fraction of datasets varies from 0.26 to 0.66, in accordance with a uniform distribution. These datasets were then126\nprocessed through a traditional őnite element program for homogenization to calculate the corresponding displacement őelds127\nand the effective modulus. The input data were the Poisson’s ratios, meaning the 3D matrix contained zeros where there was128\nno material, and the corresponding Poisson’s ratio values at material points.129\nFig. 2 a,b,c shows geometric data for three \"sheet-networks\" types (Schoen Gyroid, Schwarz Diamond, and Fischer Kosh S) of130\nclassical and complex TPMS materials respectively . In this part of the experiment, we kept the Poisson’s ratio constant to focus131\non the HomoGenius model’s generalization ability across different geometries. The HomoGenius model generated the 18 needed132\ndisplacement őelds for the homogenization process (three displacement őelds for each of the six types of loading). Due to the133\nextensive amount of model output, we showcased a comparison of the displacement őelds under the őrst type of loading between134\nHomoGenius and the reference solution from FEM, as illustrated in Fig. 2 . It is evident that HomoGenius possesses robust135\ngeneralization capabilities; The last column of matrix plots in Fig. 2 represents the calculation of relative errors between the136\neffective elastic modulus computed by HomoGenius and the Finite Element Method (FEM), where the matrix has a 6 × 6 shape.137\nThe relative error is calculated by dividing the results from HomoGenius by the FEM results at corresponding positions. The138\nareas in pure black were not included in the relative error calculation because the reference values are close to zero. T able 1 shows139\nHomoGenius achieves results nearly identical to the reference solutions under such complex geometric structures, with relative140\n4\nerror of 4.61% on the test set, and a speed increase of 1,000 times for resolution 128*128*128 compared to standard őnite element141\nanalysis in terms of displacement őeld (őnite element calculation: 2588 seconds, HomoGenius: 2.80 seconds). After obtaining the142\ndisplacement őelds via HomoGenius, we integrated these őelds into the homogenization process to determine the őnal effective143\nmodulus. Compared to the effective modulus obtained through HomoGenius, our tests across various geometries yielded excellent144\nresults, with the average relative error being only about 1.58%. The relative error refers to the comparison between the effective145\nelastic modulus obtained by HomoGenius and the Finite Element Method (the reference solution), calculated as the relative146\ndiscrepancy . In terms of efficiency , HomoGenius can enhance the overall homogenization speed by approximately 80 times.147\nThe traditional homogenization method requires 2618 seconds, which includes 2588 seconds for őnite element computation148\nand 30 seconds to process displacement őeld data to obtain the effective elastic modulus. In contrast, HomoGenius requires149\nonly 32.8 seconds, comprising 2.8 seconds for required őeld prediction and the őxed 30 seconds for homogenization as in the150\ntraditional process (the 30 seconds in homogenization remains őxed, as the effective elastic modulus is determined through matrix151\noperations after obtaining the displacement őeld). Compared to traditional methods, the acceleration ratio of HomoGenius can152\napproach up to 1000 times at sufficiently high resolutions. The key to improving homogenization efficiency is to accelerate153\nthe prediction of the displacement őeld required in homogenization. Thus, the core reason that HomoGenius is faster than154\ntraditional algorithms lies in the utilization of operator learning to boost the efficiency of displacement őeld prediction, thereby155\nenhancing the overall homogenization efficiency . The results show HomoGenius closely approximates the reference solutions156\nobtained from FEM, indicating that HomoGenius can effectively substitute őnite element analysis. HomoGenius enables the157\nrapid prediction of displacement őelds corresponding to various geometries, thereby signiőcantly accelerating the overall speed158\nof the homogenization process.159\nT o further explore the performance of HomoGenius, our next numerical experiments will test HomoGenius’s performance160\nwith inputs of different materials and geometries simultaneously , evaluating how well HomoGenius performs.161\n2.3. Diﬀerent material162\nUnlike the geometric experiments mentioned before, this experiment modiőes the input Poisson’s ratio to account for different163\nmaterials. The decision not to consider varying Y oung’s modulus because that őnal effective modulus can be linearly adjusted164\nby simply multiplying by the Y oung’s modulus at the end. Therefore, in different materials, we only need to consider different165\nPoisson’s ratios. It should be noted that the Poisson’s ratio here is a function őeld However, for simplicity , we employed a166\nconstant őeld. F or this experimental dataset, we expanded the variety of TPMS to six types, with Poisson’s ratios ranging167\nfrom 0.1 to 0.4, totaling 3600=600*6 datasets of 64x64x64 resolution (The resolution of training and testing set are both 64).168\nThe volume fraction (0.26 to 0.66) is the same as the experiment in geometry . Fig. 3 a,b,c,d,e,f correspond to the six different169\ntypes of TPMS, respectively (Schoen Gyroid: \"Solid-networks\" and \"Sheet-networks\", Schwarz Diamond: \"Solid-networks\" and170\n\"Sheet-networks\", and Fischer Kosh S: \"Solid-networks\" and \"Sheet-networks\").171\nT raining and testing within this dataset, as illustrated in Fig. 3 , reveal that our HomoGenius model achieved impressive172\ngeneralization performance. Fig. 3 shows that the displacement őelds predicted by HomoGenius closely match those of the őnite173\nelement reference solution. F urthermore, HomoGenius can rapidly output the corresponding displacement őelds for any geometry174\nand material, which are then incorporated into the conventional homogenization process to determine the őnal effective modulus.175\nDuring training, HomoGenius converges quickly , reaching a training error of 3.25% and a testing error of 5.36% within just 300176\nepochs. Additionally , its computational speed is nearly 1,000 times faster than traditional őnite element analysis (FEA takes177\nabout 150 seconds at a resolution of 64, compared to 0.2 seconds for HomoGenius). It is noteworthy that, unlike the geometric178\nexamples mentioned earlier, this section employs a resolution of 64 instead of 128 for different materials, thereby reducing179\nthe computation time for both traditional methods and HomoGenius accordingly . When incorporated into the conventional180\nhomogenization program, the maximal relative error in the őnal effective elastic modulus is less than 5% and the average relative181\nerror is 1.60%, indicating the high accuracy and super efficiency of our proposed HomoGenius model. The effective elastic182\nmodulus in the homogenization process is determined based on the corresponding displacement őelds. Therefore, the accuracy183\nof the effective elastic modulus directly depends on the precision of the model’s displacement őeld predictions.184\nGiven the diversity in data resolutions in practical scenarios, for example, high-performance computers can compute őnite185\nelement results at higher resolutions, while standard computers may only handle lower resolutions, so learning from data of any186\nresolution is crucial for the model’s applicability . Therefore, the next section of our experiments will test the model’s capability187\nin the cross-resolution numerical homogenization process.188\n2.4. Diﬀerent resolution189\nThe experiments involving different resolutions refer to training the model at lower resolutions and then testing it at higher190\nresolutions. W e conducted training with datasets at resolutions of 32x32x32, 64x64x64, and 128x128x128, and performed tests on191\nall at a resolution of 128x128x128 to evaluate the model’s cross-resolution performance. The convergence curves of the test errors192\nacross the 18 displacement őelds (three directions under six types of loads), as shown in Fig. 4 a, indicate that the test errors193\nfor training sets at 32, 64, and 128 resolutions on the 128-resolution test set are approximately 20%, 15%, and 3%, respectively .194\nT raining on a dataset with a resolution of 32 results in larger errors primarily due to the insufficient resolution of the training195\ndata. This leads to non-negligible geometric discretization errors, meaning that even the best model will still incur this type196\n5\nT able 1\nThe comparison between HomoGenius and the traditional numerical homogenization method (Finite element method) in terms of accuracy and eﬃciency\nbased on diﬀerent training resolutions (32, 64, 128) and same testing resolution (128). The time in the table refers speciﬁcally to the prediction time\nfor displacement ﬁeld.\nT rain Res. Time: FEM (s) Time: HomoGenius (s) Dis: T rain error Dis: T est error Effective modulus error\n32x32x32\n2588 2.80\n0.0578 0.2133 0.1537\n64x64x64 0.0860 0.1347 0.1074\n128x128x128 0.0747 0.0461 0.0158\nof error. However, the better the model, the closer the model will get to the theoretical value of the discretization error. The197\ncloser the resolutions of the training and test sets, the better the model performs. Fig. 4 b presents the displacement őeld results198\nfor training sets at 32 and 128 resolutions, demonstrating that transitioning from low to high resolution has an excellent level199\nof generalization capability . The relative test errors for the effective modulus performance are 15.37% and 1.58% for training200\nsets at 32 and 128 resolutions respectively , shown in T able 1 . Owing to HomoGenius’s capacity to operate across resolutions,201\nit theoretically can predict outcomes at any resolution. Thus, we test HomoGenius’s capabilities at an ultra-high resolution202\n(256), with results depicted in Fig. 4 b. At a resolution of 256, compared to predictions at a resolution of 128, HomoGenius203\ndemonstrates amazing robustness. Notably , traditional algorithms take close to 12 hours to solve structures at a resolution of204\n256, whereas HomoGenius requires merely 20 seconds. W e also experimented with training on three types of TPMS within205\nonly \"Sheet-networks\" (Schoen Gyroid, Schwarz Diamond, and Fischer Kosh S) but tested on the same three types of TPMS206\nin \"Solid-networks\". HomoGenius achieved impressive results in this scenario. However, when testing on structures generated207\nby Gaussian Random Fields (GRF), HomoGenius showed limitations. This indicates that HomoGenius needs the training and208\ntesting data distributions to be similar in order to achieve great performance.209\nHence, the model exhibits commendable performance across different resolutions. F urthermore, if data at lower resolutions210\ncontain errors, it could diminish the model’s performance. Since HomoGenius can assimilate data of varying resolutions, exploring211\nhow to better train models, especially when lower resolution data contain errors, is crucial for future research.212\n3. Discussion213\nIn this paper, we introduce a foundation model of homogenization, HomoGenius. HomoGenius demonstrates exceptional214\nperformance across various geometries, materials, and resolutions. W e have thoroughly validated the model with TPMS215\nmaterials. The backbone of this model is the F ourier neural operator, and other operator learning algorithms could potentially216\nbe used in the backbone. Compared to traditional őnite element homogenization programs, HomoGenius offers an efficiency217\nimprovement of nearly 1,000 times in terms of the prediction of required őeld and nearly 20 times (The improvement factor of218\nHomoGenius increases with the resolution) in terms of the total homogenization process, with accuracy closely matching that219\nof őnite element reference solutions. Therefore, it possesses super efficiency and high accuracy . Additionally , by integrating220\ndata across different resolutions, HomoGenius can continuously learn, using data of any resolution, hence showcasing learning221\ncapability and approaching Artiőcial General Intelligence (AGI) in numerical homogenization.222\nHowever, HomoGenius currently has limitations, such as primarily considering uniformly distributed data and only periodic223\nstructures, as well as how to better integrate low-resolution data with errors into the model. The model’s success is attributed224\nto its strong őtting capability for őeld approximation, suggesting that it could theoretically excel with non-periodic structures225\nas well. Although the model has not yet been validated for numerical homogenization in other physical problems, such as226\nthermal conductivity , but focused on more challenging issues like effective modulus in this paper, using this approach to study227\nthe prediction of effective properties for other physical problems presents an exciting research direction for the future.228\n4. Methods229\nW e herein introduce the method of HomoGenius as shown in Fig. 1 . Our discussion is structured into two main sections.230\nInitially , we introduce traditional homogenization methods and the dataset calculated from traditional homogenization methods231\nusing őnite element method (FEM). Subsequently , we present the neural network framework of our HomoGenius, i.e., FNO:232\nF ourier neural operator. F urthermore, we elaborate on the integration of FNO with the homogenization process.233\n4.1. The process of traditional numerical homogenization234\nNumerical homogenization is a practical method to calculate the effective macroscopic elastic matrix of periodic composite235\nmaterial. In this section, we brieŕy elaborate the principles of the homogenization method for calculating the effective elastic236\nmatrix. F or simplicity , we consider a material consisting of solid material and void. ES\nijkl denotes the isotropic elastic matrix237\n6\nof the solid material. F or calculating the homogenized elastic matrix EH\nijkl , we applied 6 unit strain őelds over the unit cell,238\nincluding three normal strain and three shear strain őelds. The 6 unit strain őelds εmacro\ni are deőned as239\nεmacro\ni =\n(\nδ1i δ2i δ3i δ4i δ5i δ6i\n) T\nfor i = 1 , 2, 3, 4, 5, 6 (6)\nwhere δ1i is Kronecker delta (I=1,2,3,4,5,6). F or instance,240\nεmacro\n1 =\n(1 0 0 0 0 0 ) T\nfor i = 1 (7)\nThe homogenized elastic matrix EH\nijkl is calculated according to the following equation241\nEH\nijkl = 1\n|Ω |\nˆ\nΩ\nEpqrs\n(\nε(0)(ij)\npq − ε(ij)\npq\n) (\nε(0)(kl)\nrs − ε(kl)\nrs\n)\ndΩ (8)\nIn this equation, Epqrs denotes the local elastic matrix of the TPMS unit cell, and Epqrs obeys242\nEijkl =\n{\nES\nijkl for solid material ,\n0 for void . (9)\n|Ω | represents the volume of the unit cell domain. ε(0)(ij)\npq shown in Eq. (6), denotes a macroscopic unit strain őeld imposed on243\nΩ . ε(ij)\npq , on the other hand, denotes the local strain őeld calculated by244\nϵ(ij)\npq = ϵpq\n(\nXij )\n= 1\n2\n(\nXij\np,q + Xij\nq,p\n)\n(10)\nIn this equation, Xij denotes the real displacement őeld under by applying the macroscopic unit strain őeld over Ω . εpq(Xkl)245\nis calculated by solving the following elasticity equation246\nˆ\nΩ\nEijkl εij (X∗ )εpq(Xkl)dΩ =\nˆ\nΩ\nEijkl εij (X∗ )ε0(kl)\npq dΩ (11)\n, where X∗ refers to a virtual displacement őeld. The őnite element method is usually used to solve the real displacement őeld247\nXkl in the above equation. The stiffness matrix of the őnite element method is calculated by248\nK =\nN∑\ne=1\nˆ\nVe\nBT\ne CeBe dVe (12)\nwhere Ve is the element volume. Be is the strain-displacment matrix. Ce is the elastic matrix. F or this study , the three-249\ndimensional isotropic Ce is deőned by250\nCe =\n\n\n\n\n\n\n\n\nλ + 2µ λ λ 0 0 0\nλ λ + 2µ λ 0 0 0\nλ λ λ + 2µ 0 0 0\n0 0 0 µ 0 0\n0 0 0 0 µ 0\n0 0 0 0 0 µ\n\n\n\n\n\n\n\n\n(13)\nwhere λ and µ are Lame constants determined by different material. The load vector of the őnite element method is calculated251\nby252\nfi =\n∑\ne\nˆ\nVe\nBT\ne Ceεi\ne dVe (14)\nwhere εi\ne corresponds to the unit strain őelds as deőned in Eq.\n(6). Then, the real displacement őeld χ i is determined by solving253\nthe following linear equations254\nKχ i = fi, i = 1 , . . . , 6 (15)\nwhere i = 1 , . . . , 6 represents the 6 unit strain instances. The real strain őeld is solved by255\nε(i) = Bχ i (16)\nThe ’real’ strain ε(i) is őnally substituted into Eq. (8) to solve the homogenized elastic matrix EH\nijkl .256\nW e observe that the crux of the homogenization process necessitates the computation of displacement őelds under six different257\nload conditions. T raditional approaches rely on őnite element analysis introduced above, consuming substantial amounts of time258\nfor computation. Different geometry and material should be recalculated to get the corresponding displacement őeld. Thus,259\nenhancing the speed of calculating displacement őelds naturally leads to a signiőcant improvement in the efficiency of the total260\nhomogenization process. W e employ operator learning as a substitute for őnite element computations. Below, we introduce our261\ndataset calculated from the traditional homogenization process.262\n7\n4.2. Dataset263\nThe core concept of our approach is remarkably straightforward: we őrst obtain a vast dataset: various Poisson’s ratios and264\ngeometric conőgurations as input data, the 18 displacement őelds subjected to six different loading conditions as output data265\n(three directions:x, y , and z for each of the six types of loading). T raining is conducted using the F ourier neural operator (FNO),266\nwith a material matrix as the input and 18 displacement őelds as the output. The material matrix is a 3D matrix of resolution267\n128*128*128 and 64*64*64, populated with zeros and Poisson’s ratios. Given our focus on linear elasticity homogenization, we268\nset Y oung’s modulus to 1 during training, simplifying the őnal calculation of the effective modulus by linearly multiplying by269\nthe Y oung’s modulus. Our data, computed with a supercomputer (900 CPU nodes each with 192G of memory and 80 V100270\nGPUs), includes 1800 sets of TPMS geometries each with 2,097,152 elements (resolution 128*128*128) and 3600 sets each with271\n262,144 elements (resolution 64*64*64), covering various geometries and Poisson’s ratios, totaling approximately 325G of data.272\nComputing data at a resolution of 128 on a system with 192 GB of memory and 56 CPU cores requires an average of 2500273\nseconds (total CPU time of 128: 1800*2500=52 days). Due to the iterative method of our custom-written traditional őnite274\nelement homogenization code, the time for traditional numerical homogenization is not őxed, so we can only provide an average275\ntime. F or data at a resolution of 64, under the same hardware conditions, the average computation time is 150 seconds (total276\nCPU time of 64: 3600*150=6.25 days). Currently , our model runs on a single V100 card (32G). In the Geometry case study , we277\nutilized 400 pieces of data at a resolution of 128 for training, with a test set comprising 50 pieces at the same resolution. The278\ndataset was chosen this way due to the memory constraints of a single V100 GPU card (32G), but the volume of data is sufficient279\nto demonstrate the exceptional generalization ability of HomoGenius. Moreover, we have made available 1800 pieces of data280\nat a resolution of 128 for training HomoGenius on a larger dataset, requiring only multi-card training to proceed. In material281\nexperiments, we employed 3600 pieces of data at a resolution of 64, with 3000 for training and 600 for testing. Noting that we282\ndid not use őnite element analysis software like Abaqus to obtain data; instead, we developed the numerical homogenization283\ncode in MA TLAB and Python.284\n4.3. Fourier neural network for homogenization285\nThe crucial steps in calculating the effective modulus involve obtaining the displacement őeld σ in six load cases. However,286\ntraditional methods involve obtaining the displacement őeld through őnite element method (FEM) in 6 time due to six load287\ncases, but for different geometric or material (such as Poisson’s rate or Y oung’s modulus) conőgurations, we need to recompute288\nusing FEM. As the material becomes more heterogeneous and complex, the computational demands of FEM become a bottleneck289\nin efficiency . Therefore, enhancing the speed of displacement prediction is essential for improving the efficiency of calculating290\neffective modulus in homogenization. Here, we adopt the F ourier neural operator (FNO) [ 38] as a backbone in our proposed291\nHomoGenius, because FNO is an algorithm that has garnered signiőcant attention in the őeld of AI for science (AI4Science)292\n[77] for solving PDEs, especially in weather prediciton [ 45, 44]. FNO can signiőcantly accelerate displacement calculations, and293\nour numerical experiments in Results show that, compared to traditional őnite element methods, the speed can be increased by294\nover 1,000 times (FEM takes 2588s, while FNO only takes 2.80s). Thus, the proposed HomoGenius can greatly accelerate the295\ncalculation of effective properties.296\nFNO has garnered signiőcant attention as an algorithm in neural operator learning. Therefore, before delving into the details297\nof FNO, let’s őrst introduce neural operator learning [ 39] for better understanding FNO.298\nNeural operator learning is a data-driven algorithm widely employed in science and engineering, particularly for mapping299\nrelationships between different functions. The advantages of the neural operator is the invariance to discretization, and the300\nconcept of discretization-invariant include:301\n1. The ability to handle input data of arbitrary resolutions.302\n2. The capability to produce output at any given location.303\n3. Convergence of results as the grid is reőned.304\nIn contrast to conventional data-driven methods based on neural networks, which are often sensitive to discretization levels305\nand may require retraining when changing input-output function resolutions, neural operator learning exhibits invariance to306\ndiscretization. This property makes it a valuable data-driven algorithm model, as highlighted by its practical applications [ 43].307\nThe feature of invariance to discretization mean that we can train the model in the coarse mesh and predict the result in308\nthe őne mesh. It is a great advantage of our large model that training data can possess arbitrary resolution in our proposed309\nHomoGenius. It is imperative to ensure data reliability and convergence. This requirement delineates a promising research310\ndirection how to effectively train models with data that may contain errors. Given the HomoGenius’s capability to assimilate311\ndata of any resolution, the model has remarkable learning capabilities, which means the model can continually incorporate data,312\nultimately evolving into a super model capable of homogenizing across any geometry and material. The model excel in high313\nprecision and super efficiency , particularly in terms of efficiency . The homogenization model is like a smart physicist who learns314\nfrom a lot of data., like Newton in Fig. 1 .315\nMoreover, not all őtting algorithms can be classiőed as neural operators. Neural operators not only need to satisfy the316\ninvariance to discretization but also meet the requirements of generalized approximation for continuous operators [ 40]. This317\n8\ncharacteristic ensures the advantage of neural operators in learning the family of PDEs. Through operator learning, we can318\ngrasp the implicit mappings of PDEs, meaning the rapid prediction of solution spaces from input spaces (such as boundary319\nconditions, geometric shapes, and material properties). W e can conceptualize PDEs as implicit mappings from input spaces to320\nsolution spaces. Because this mapping is challenging to explicitly represent, the traditional PDEs solver can be used to obtain the321\ndata for approximating the implicit mapping. And the tool of approximating the implicit mapping can be neural operator due322\nto the powerful approximation capabilities. Among neural operators, F ourier neural operator (FNO) stands out as a category323\nwith superior performance. The algorithmic design of neural operator learning revolves around the core operation of kernel324\nintegration within the neural operator layer shown in Fig. 1 :325\nH(t)(v(t); θ(t)\nk )(x) =\nˆ\nD(t)\nk(t)(x, y; θ(t)\nk )v(t)(y)dy, (17)\nwhere v(t) represents the input to the neural operator layer, k(t)(x, y; θ(t)\nk ) is the kernel function approximated using a neural326\nnetwork with parameters θ(t)\nk . The kernel integration algorithm transforms the function v(t) through integration into another327\ntype of function Ht(v(t))(x) by the action of the kernel operator Ht. The index t refers to the t-th layer of the neural operator.328\nConsequently , the overall computation ŕow of operator learning is expressed as:329\nGθ (a(x); θ) = Q(v(T +1); θQ) ◦ σ[H(T )(v(T ); θ(T )\nk ) + W (T )(v(T ); θ(T )\nw ) + b(T )(θ(T )\nb )] ◦ · · ·\n◦ σ[H(1)(v(1); θ(1)\nk ) + W (1)(v(1); θ(1)\nw ) + b(1)(θ(1)\nb )] ◦ P (a(x); θP )\n, (18)\nwhere P and Q are responsible for dimensionality expansion and reduction of the original data, and their respective learnable330\nparameters are θP and θQ. H(t), W (t), and b(t) represent kernel integration, linear transformation, and bias, with corresponding331\nlearnable parameters θ(t)\nk , θ(t)\nw , and θ(t)\nb . It is noteworthy that these learnable parameters are typically approximated using neural332\nnetworks. Different kernel integration algorithms give rise to various operator learning algorithms, making the design of kernel333\nintegration algorithms a core aspect of operator learning. FNO is the speciőc instantiation of kernel integration algorithms using334\nF ourier transforms. Theorems suggest that the formulation in Eq. (18) meets the requirements of generalized approximation335\n[41, 42], indicating that operator learning algorithms designed according to Eq. (18) possess favorable convergence properties.336\nAdditionally , the DeepONet (another important operator learning algorithm) [ 37] also satisőes generalized approximation337\nrequirements [ 40]. Although its design differs from that of FNO, DeepONet also exhibits excellent convergence properties.338\nT wo of the most typical algorithms in operator learning are DeepONet and FNO. In the following sections, we will focus on339\nproviding a detailed introduction to the FNO algorithm.340\nF ourier Neural Operator (FNO) is an speciőc neural operator [ 38] that has garnered signiőcant attention due to its efficiency341\nand accuracy . Its core idea involves integrating F ourier transform into neural operator, speciőcally representing Eq. (17) using342\nF ourier transform:343\nH(t)(v(t); θ(t)\nk )(x) =\nˆ\nD(t)\nk(t)(x, y; θ(t)\nk )v(t)(y)dy = F− 1 ◦ ℜ ◦ F (v(t)(x)), (19)\nwhere F and F− 1 are the F ourier transform and its inverse, respectively , and ℜ denotes linear transformation. T o explain344\nthe FNO algorithm’s process in detail, we combine the FNO algorithm framework with an speciőc example. Considering a345\ntwo-dimensional steady-state heat conduction equation:346\n{\nDomain: −∇ · (K(x, y)∇T (x, y)) = f(x, y)\nBoundary: T (x, y) = u(x, y) , (20)\nwhere T (x, y) is the temperature őeld to be solved, K(x, y) is the non-uniform thermal conductivity őeld, and once the boundary347\ncondition u(x, y), thermal conductivity K(x, y), and heat source f(x, y) are determined, the solution T (x, y) can be uniquely348\ndetermined. In this problem, the input is the thermal conductivity K ∈ Rdi , where di is total sample points of thermal349\nconductivity , e.g., di = 128 ∗ 128 If there are evenly 128 points on each side of the two-dimensional heat conduction problem. In350\nthis example, the thermal conductivity K is equivalent to a(x) in Eq. (18) in FNO, and the output is the steady-state temperature351\nőeld T (x, y) if the boundary condition is őxed. The FNO algorithm proceeds by őrst using a fully connected neural network P352\nto lift the input a(x) to dc dimensions (i.e., P : R → Rdc , where dc is analogous to channels in computer vision):353\nv(0)(x) = P (a(x)) ∈ Rdi∗dc . (21)\nNext, v(0)(x) is passed through F ourier Layer 1. Firstly , a F ourier transform is applied to each channel of v(0)(x), resulting354\nin355\nf(1)(x) = F(v(0)(x)) ∈ Cdi∗dc . (22)\n9\nHigh-frequency components are őltered out, retaining only low frequencies by truncating at a frequency of dm (1 ≤ dm ≤ di).356\nTherefore, the data structure transforms to f(1)(x) ∈ Cdm∗dc . A linear transformation ℜ (ℜ : Rdc → Rdc ) is then applied to357\neach frequency channel:358\nf(1)\nL (x) = ℜ(f(1)(x)) ∈ Cdm∗dc , (23)\nwhere there are dm different linear transformation matrices. Because different frequencies use different linear transformations, a359\nset of linear transformation matrices Rdc∗dc∗dm is employed. After the linear transformation ℜ, the dimension structure of the360\ndata remains unchanged. Since F ourier inverse transform is required in the next step, zero-padding is performed to reintroduce361\nthe high-frequency components removed during truncation. An inverse F ourier transform to f(1)\nL (x) is applied:362\nv(1)\nf = F− 1(f(1)\nL (x)) ∈ Rdi∗dc . (24)\nThe advantage of the ℜ linear transformation lies in learning the mapping relationships between data in the F ourier frequency363\nspace. F urthermore, ℜ acts as a form of regularization due to high-frequency őltering, reducing overőtting and enhancing the364\nmodel’s generalization.365\nAdditionally , following the idea of residual networks [ 78], a linear transformation is directly applied to the channels of v(0)(x).366\nThis linear transformation, which is the same for points, involves only one linear transformation W ∈ Rdc∗dc :367\nv(1)\nL = W (v(0)(x)) ∈ Rdi∗dc , (25)\nW use the residual network concept to reintroduces high-frequency components removed by the F ourier transform into the368\nnetwork for learning. As a result, the residual connection of W prevents a degradation in predictive performance caused by the369\nremoval of high-frequency components.370\nThe results of F ourier transform and linear transformation are combined:371\nv(1)(x) = σ(v(1)\nf + v(1)\nL + b(1)) ∈ Rdi∗dc , (26)\nwhere b(1) is the bias. The introduction of non-linear transformations σ is not only to increase the expressive power of the372\nnetwork but also simultaneously enhances the őtting capability of high frequencies. The F ourier layer is the core of FNO’s373\ncomputation. The above operations are repeated T times to obtain v(T )(x), which is then reduced to the target dimension by374\nQ. In the case of the steady-state heat conduction problem, Q : Rdc → R, and FNO computation is over.375\nFNO has two major advantages: őrstly , due to F ourier transformation őltering out high-frequency modes, it can improve376\nthe model’s speed and generalization ability , reducing overőtting; secondly , it exhibits discretization-invariant. Since all FNO377\noperations are point-wise computations independent of the data grid, it possesses the advantage of discretization-invariant.378\nFNO layers are repeated T times, followed by dimension reduction to obtain the őnal output. Below, we illustrate how to379\npredict the effective modulus in the proposed HomoGenius with FNO.380\nUsing the dataset obtained from the traditional homogenization process, we began training our HomoGenius. The training381\ntime for resolution 128 is about 5 hours per 100 epoch (3D FNO with mode 18 in one V100: 32G), and the training time for382\nresolution 64 is about 3 hours per 100 epoch (3D FNO with mode 32 in one V100: 32G). The model’s mode and the amount383\nof data can be conőgured according to one’s hardware conditions. The model takes a material matrix with four channels as384\ninputÐspeciőcally , one for the material’s Poisson’s ratio and three for the spatial coordinates (x, y , and z)Ðand produces an385\n18-channel displacement őeld as output. T o address the varying magnitudes across different displacement őelds, we implemented386\nnormalization techniques to ensure consistency across the displacement channels. Our model is capable of rapidly predicting387\nthe 18 necessary displacement őelds for homogenization when given any Poisson’s ratio within the range of 0.1 to 0.4, any value388\nof elastic modulus, and any TPMS (T riply Periodic Minimal Surface) structure. It is important to note that we focused on389\nPoisson’s ratios ranging from 0.1 to 0.4 because this range is most commonly encountered in engineering applications. However,390\nour approach allows for the use of a broader range of Poisson’s ratios in the dataset.391\nAfter obtaining the displacement őelds required for homogenization, we incorporate them into the conventional homogenization392\nprocess in Eq. (8), to ultimately derive the effective modulus.393\nIt’s worth noting that we only demonstrate the potential of FNO in homogenization. W e believe that in other engineering394\nproblems, FNO is highly recommended as long as it involves mapping from functions to functions.395\nData A vailability396\nAll the used datasets (325G) from super computer in this study are available in OneDrive https://1drv.ms/f/s!AksHfblN397\nspn5kopiSGwZrDnan-C_lA?e=dPkLbq.398\n10\nCode A vailability399\nAll the source codes to reproduce the results in this study are available in https://github.com/yizheng-wang/Research400\n-on-Solving-Partial-Differential-Equations-of-Solid-Mechanics-Based-on-PINN/tree/main/HomoGenius .401\nAcknowledgement402\nThis work is supported by the National Natural Science F oundation of China (No.12162012 and No.12332005) and Hainan403\nProvincial Natural Science F oundation of China (No.121RC536). The authors would like to thank Shuaifeng Ma for helpful404\ndiscussions.405\nAuthor Contributions Statement406\nYizheng W ang designed the HomoGenius model, performed the numerical experiment, and wrote the paper. Xiang Li407\ndesigned the traditional numerical algorithm, compute the data, and wrote the paper. Ziming Y an designed the traditional408\nnumerical algorithm and revise the paper. Timon Rabczuk reviewed the paper and supervised the project. Y uqing Du revised409\nthe picture and participated in discussions. Bokai Liu and Jinshuai Bai reviewed the paper. Yinghua Liu supervised the project410\nand provide supercomputer computing resources.411\nCompeting Interests Statement412\nThe authors declare no competing interests.413\n11\nHomogenization\nPhysical Laws\nPDEs Solver\nData\nFoundation Model of AI4PDE \u001b\n-FBSOJOH\u0001$BQBCJMJUZ\n4VQFS\u0001&GGJDJFODZ\n)JHI\u00011SFDJTJPO\nFourier Neural Operator\nFourier Layer 1 Fourier Layer t Fourier Layer T\nℜ\nm\no\nd\ne\n\nm\no\nd\ne\n1−\n\nW\nP\nQ\nu\n( 1) t −\nv\n( ) t\nv\nσ\nNeural Operator:\nFourier Neural Operator\nTraining\nFEM\nData generation\nPhysical Laws(optional)\n( )( )\n(0)( ) ( ) (0)( ) ( )\n1\n| |\nH ij ij kl kl\nijkl pqrs pq pq rs rs\nE E d ε ε ε ε\nΩ\n= − − Ω\nΩ\n∫\nElastic modulus tensor is calculated:\nHomoGenius\nd\nc\nb\ne\na\n6 loads\nFig. 1. Schematic Architecture of HomoGenius . a, Input and output of the HomoGenius model. The input includes materials requiring\nhomogenization, characterized by various geometric shapes and material properties, while the output is the displacement ﬁeld necessary for\nhomogenization. b, Graphical abstract of the HomoGenius model. Utilizing existing PDEs solvers to solve the corresponding PDEs, and gather\nthe required data for the homogenization. This data is then used to learn the mappings behind the PDEs using the foundation model of AI for PDEs.\nc, Data source. The data is sourced from FEM solvers, with supercomputers being used to obtain a large amount of numerical homogenization data.\nd, Backbone of the HomoGenius model. The F ourier neural operator is employed as the model’s backbone. The speciﬁc algorithmic process and its\nexplanations are provided in\nMethods. e, The traditional homogenization steps. The process requires solving for displacement ﬁelds under six diﬀerent\ntypes of loads. The eﬀective elastic modulus is then determined using the numerical homogenization algorithm with the displacement ﬁeld from F ourier\nneural operator.\n12\nReference HomoGenius HomoGenius HomoGenius\nHomoGenius HomoGenius HomoGenius\nHomoGenius HomoGenius HomoGenius\nReference Reference \nDisplacement X\nInput\nGeometry Displacement Y Displacement Z\nReference Reference Reference \nDisplacement X\nInput\nGeometry Displacement Y Displacement Z\nReference Reference Reference \nDisplacement X\nInput\nGeometry Displacement Y Displacement Z\na\nb\nc\nFig. 2. Prediction results of the proposed HomoGenius model across diﬀerent geometries . a, b, c correspond to three distinct types of\nT riply Periodic Minimal Surfaces (TPMS): Schoen Gyroid, Schwarz Diamond, and Fischer-Koch S, respectively . In each a,b,c, the ﬁrst row displays a\ncomparison between the predictions made by HomoGenius and the reference solution obtained from Finite Element Method. The second, third, and\nfourth rows in a,b,c show comparisons across diﬀerent cross-sections. The right side of a,b,c presents the relative error in the corresponding positions\nwithin the eﬀective elastic modulus matrix between the eﬀective elastic modulus predicted by the HomoGenius model and that obtained through\ntraditional ﬁnite element homogenization (reference solution).\n13\nReference HomoGenius HomoGenius HomoGenius\nHomoGenius HomoGenius HomoGenius\nHomoGenius HomoGenius HomoGenius\nHomoGenius HomoGenius HomoGenius\nHomoGenius HomoGenius HomoGenius\nHomoGenius HomoGenius HomoGenius\nReference Reference Input\nPoisson's ratio = 0.28 \na\nReference Reference Reference Input\nPoisson's ratio = 0.37 \nc\nReference Reference Reference Input\nPoisson's ratio = 0.14 \nb\nReference Reference Reference Input\nPoisson's ratio = 0.25 \nd\nReference Reference Reference Input\nPoisson's ratio = 0.30  \nf \nReference Reference Reference Input\nPoisson's ratio = 0.20 \ne\nDisplacement X Displacement Y Displacement Z\nDisplacement X Displacement Y Displacement Z\nDisplacement X Displacement Y Displacement Z\nDisplacement X Displacement Y Displacement Z\nDisplacement X Displacement Y Displacement Z\nDisplacement X Displacement Y Displacement Z\nFig. 3. Prediction results of the proposed HomoGenius model across diﬀerent geometries and materials (Poisson’s ratio and Y oung’s\nmodulus). a, b, c, d, e, and f correspond to six distinct types of T riply Periodic Minimal Surfaces (TPMS): Schoen Gyroid (\"Solid-networks\"\nand \"Sheet-networks\"), Schwarz Diamond (\"Solid-networks\" and \"Sheet-networks), and Fischer Kosh S (\"Solid-networks\" and \"Sheet-networks\"),\nrespectively . In each pic, the ﬁrst row displays a comparison between the predictions made by HomoGenius and the reference solution obtained from\nthe Finite Element Method (FEM). The second row shows comparisons across the cross-sections. The right side of each pic presents the relative error\nin the corresponding positions within the eﬀective elastic modulus matrix, comparing the eﬀective elastic modulus predicted by the HomoGenius model\nwith that obtained through traditional ﬁnite element homogenization (reference solution).\n14\na\nb Low resolution (32)\nhigh resolution (128)\nTraining data at different resolutions Reference (128)\nHomoGenius infer \nat high resolution (128)\nHomoGenius infer \nat super resolution (256)\nRelative error: effective modulus\nFig. 4. Results of HomoGenius across diﬀerent resolutions . a, The evolution trend of the relative error of HomoGenius: Displacement ﬁelds\nin three directions under six types of loads, with each image representing training data at resolutions of 32, 64, and 128, while the test set results are\nat a high resolution of 128. b, Prediction results at various resolutions: The ﬁrst and second row shows results for the training set at a resolution\nof 32 and 128. The ﬁrst column displays the topological structures at diﬀerent resolutions, and the second column presents the training data for\ncorresponding topological structures. \"Reference (128)\" refers to the three-dimensional contour maps of displacement in the test set. HomoGenius\npredicts displacement ﬁelds not only at the resolution of 128, as shown in the fourth column, but also at an ultra-high resolution of 256, as demonstrated\nin the ﬁfth column. The last column shows the relative error results between the eﬀective elastic modulus matrix from HomoGenius and the reference\nsolution from FEM in numerical homogenization.\n15\nReferences414\n[1] Z. Hashin, S. Shtrikman, A variational approach to the theory of the effective magnetic permeability of multiphase materials,415\nJournal of applied Physics 33 (10) (1962) 3125–3131.416\n[2] Z. Hashin, S. Shtrikman, A variational approach to the theory of the elastic behaviour of multiphase materials, Journal of417\nthe Mechanics and Physics of Solids 11 (2) (1963) 127–140.418\n[3] R. Hill, Elastic properties of reinforced solids: some theoretical principles, Journal of the Mechanics and Physics of Solids419\n11 (5) (1963) 357–372.420\n[4] W. Tian, L. Qi, C. Su, J. Liang, J. Zhou, Numerical evaluation on mechanical properties of short-őber-reinforced metal421\nmatrix composites: T wo-step mean-őeld homogenization procedure, Composite Structures 139 (2016) 96–103.422\n[5] H. Okada, Y. F ukui, N. Kumazawa, Homogenization analysis for particulate composite materials using the boundary element423\nmethod, Computer Modeling in Engineering and Sciences 5 (2) (2004) 135–150.424\n[6] V. Carvelli, C. Poggi, A homogenization procedure for the numerical analysis of woven fabric composites, Composites Part425\nA: Applied Science and Manufacturing 32 (10) (2001) 1425–1432.426\n[7] P . Halevi, A. Krokhin, J. Arriaga, Photonic crystal optics and homogenization of 2d periodic composites, Physical review427\nletters 82 (4) (1999) 719.428\n[8] T. Antonakakis, R. Craster, S. Guenneau, High-frequency homogenization of zero-frequency stop band photonic and429\nphononic crystals, New Journal of Physics 15 (10) (2013) 103014.430\n[9] F. Dos Reis, J. Ganghoffer, Equivalent mechanical properties of auxetic lattices from discrete homogenization,431\nComputational Materials Science 51 (1) (2012) 314–321.432\n[10] A. Ciattoni, C. Rizza, Nonlocal homogenization theory in metamaterials: Effective electromagnetic spatial dispersion and433\nartiőcial chirality , Physical Review B 91 (18) (2015) 184207.434\n[11] Z. Huang, J. Y ao, Y. Li, C. W ang, X. Lv, Numerical calculation of equivalent permeability tensor for fractured vuggy porous435\nmedia based on homogenization theory , Communications in Computational Physics 9 (1) (2011) 180–204.436\n[12] A. R. Díaz, E. I. S. Flores, S. J. Y anez, D. A. V asco, J. C. Pina, C. F. Guzmán, Multiscale modeling of the thermal437\nconductivity of wood and its application to cross-laminated timber, International Journal of Thermal Sciences 144 (2019)438\n79–92.439\n[13] S. J. Hollister, D. F yhrie, K. Jepsen, S. A. Goldstein, Application of homogenization theory to the study of trabecular bone440\nmechanics, Journal of biomechanics 24 (9) (1991) 825–839.441\n[14] P . Makowski, A. John, W. Kuś, G. Kokot, Multiscale modeling of the simpliőed trabecular bone structure, Mechanika (2013)442\n156–161.443\n[15] O. W eeger, Numerical homogenization of second gradient, linear elastic constitutive models for cubic 3d beam-lattice444\nmetamaterials, International Journal of Solids and Structures 224 (2021) 111037.445\n[16] S. Arabnejad, D. Pasini, Mechanical properties of lattice materials via asymptotic homogenization and comparison with446\nalternative homogenization methods, International Journal of Mechanical Sciences 77 (2013) 249–262.447\n[17] A. Düster, H.-G. Sehlhorst, E. Rank, Numerical homogenization of heterogeneous and cellular materials utilizing the őnite448\ncell method, Computational Mechanics 50 (2012) 413–431.449\n[18] V.-D. Nguyen, L. Noels, Computational homogenization of cellular materials, International Journal of Solids and Structures450\n51 (11-12) (2014) 2183–2203.451\n[19] G. Dong, Y. T ang, Y. F. Zhao, A 149 line homogenization code for three-dimensional cellular materials written in matlab,452\nJournal of Engineering Materials and T echnology 141 (1) (2019) 011005.453\n[20] A. Anthoine, Second-order homogenisation of functionally graded materials, International Journal of Solids and Structures454\n47 (11-12) (2010) 1477–1489.455\n[21] S. Hasanov, A. Gupta, F. Alifui-Segbaya, I. Fidan, Hierarchical homogenization and experimental evaluation of functionally456\ngraded materials manufactured by the fused őlament fabrication process, Composite Structures 275 (2021) 114488.457\n16\n[22] A. L. Kalamkarov, I. V. Andrianov, V. V. Danishevs’ kyy , Asymptotic homogenization of composite materials and structures458\n(2009).459\n[23] M. Baniassadi, A. Laachachi, F. Hassouna, F. Addiego, R. Muller, H. Garmestani, S. Ahzi, V. T oniazzo, D. Ruch, Mechanical460\nand thermal behavior of nanoclay based polymer nanocomposites using statistical homogenization approach, Composites461\nscience and technology 71 (16) (2011) 1930–1935.462\n[24] B. Hassani, E. Hinton, A review of homogenization and topology optimization iÐhomogenization theory for media with463\nperiodic structure, Computers & Structures 69 (6) (1998) 707–717.464\n[25] E. Andreassen, C. S. Andreasen, How to determine composite material properties using numerical homogenization,465\nComputational Materials Science 83 (2014) 488–495.466\n[26] H. Okada, Y. F ukui, N. Kumazawa, Homogenization method for heterogeneous material based on boundary element method,467\nComputers & Structures 79 (20-21) (2001) 1987–2007.468\n[27] D. Rodrigues, J. Belinha, F. Pires, L. Dinis, R. N. Jorge, Homogenization technique for heterogeneous composite materials469\nusing meshless methods, Engineering analysis with boundary elements 92 (2018) 73–89.470\n[28] C. W ellmann, C. Lillie, P . W riggers, Homogenization of granular material modeled by a three-dimensional discrete element471\nmethod, Computers and Geotechnics 35 (3) (2008) 394–405.472\n[29] E. Gal, E. Suday , H. W aisman, Homogenization of materials having inclusions surrounded by layers modeled by the extended473\nőnite element method, International Journal for Multiscale Computational Engineering 11 (3) (2013).474\n[30] C. Bellis, R. F errier, Numerical homogenization by an adaptive fourier spectral method on non-uniform grids using optimal475\ntransport, Computer Methods in Applied Mechanics and Engineering 419 (2024) 116658.476\n[31] H. Shin, S. Y ang, S. Chang, S. Y u, M. Cho, Multiscale homogenization modeling for thermal transport properties of polymer477\nnanocomposites with kapitza thermal resistance, Polymer 54 (5) (2013) 1543–1554.478\n[32] K. Hao, Ai has cracked a key mathematical puzzle for understanding our world, MIT T echnology Review. https://www.479\ntechnologyreview. com/2020/10/30/1011435/ai-fourier-neural-network-cracks-navier-stokes-and-partial-differential-480\nequations/. Zugegriffen am 15 (2020) 2021.481\n[33] C. Rao, P . Ren, Q. W ang, O. Buyukozturk, H. Sun, Y. Liu, Encoding physics to learn reaction–diffusion processes, Nature482\nMachine Intelligence 5 (7) (2023) 765–779.483\n[34] M. Raissi, P . Perdikaris, G. E. Karniadakis, Physics-informed neural networks: A deep learning framework for solving484\nforward and inverse problems involving nonlinear partial differential equations, Journal of Computational Physics 378485\n(2019) 686–707.486\n[35] S. Cuomo, V. S. Di Cola, F. Giampaolo, G. Rozza, M. Raissi, F. Piccialli, Scientiőc machine learning through physics–487\ninformed neural networks: Where we are and what’s next, Journal of Scientiőc Computing 92 (3) (2022) 88.488\n[36] G. E. Karniadakis, I. G. Kevrekidis, L. Lu, P . Perdikaris, S. W ang, L. Y ang, Physics-informed machine learning, Nature489\nReviews Physics 3 (6) (2021) 422–440. doi:10.1038/s42254-021-00314-5 .490\n[37] L. Lu, P . Jin, G. Pang, Z. Zhang, G. E. Karniadakis, Learning nonlinear operators via deeponet based on the universal491\napproximation theorem of operators, Nature Machine Intelligence 3 (3) (2021) 218–229. doi:10.1038/s42256-021-00302492\n-5.493\n[38] Z. Li, N. Kovachki, K. Azizzadenesheli, B. Liu, K. Bhattacharya, A. Stuart, A. Anandkumar, F ourier neural operator for494\nparametric partial differential equations, arXiv preprint arXiv:2010.08895 (2020).495\n[39] N. B. Kovachki, Z. Li, B. Liu, K. Azizzadenesheli, K. Bhattacharya, A. M. Stuart, A. Anandkumar, Neural operator:496\nLearning maps between function spaces with applications to pdes., J. Mach. Learn. Res. 24 (89) (2023) 1–97.497\n[40] T. Chen, H. Chen, Universal approximation to nonlinear operators by neural networks with arbitrary activation functions498\nand its application to dynamical systems, IEEE T ransactions on Neural Networks 6 (4) (1995) 911–917.499\n[41] T. De Ryck, S. Mishra, Generic bounds on the approximation error for physics-informed (and) operator learning, Advances500\nin Neural Information Processing Systems 35 (2022) 10945–10958.501\n[42] N. Kovachki, S. Lanthaler, S. Mishra, On universal approximation and error bounds for fourier neural operators, The Journal502\nof Machine Learning Research 22 (1) (2021) 13237–13312.503\n17\n[43] G. W en, Z. Li, K. Azizzadenesheli, A. Anandkumar, S. M. Benson, U-fnoÐan enhanced fourier neural operator-based504\ndeep-learning model for multiphase ŕow, Advances in W ater Resources 163 (2022) 104180.505\n[44] J. Pathak, S. Subramanian, P . Harrington, S. Raja, A. Chattopadhyay , M. Mardani, T. Kurth, D. Hall, Z. Li,506\nK. Azizzadenesheli, et al., F ourcastnet: A global data-driven high-resolution weather model using adaptive fourier neural507\noperators, arXiv preprint arXiv:2202.11214 (2022).508\n[45] K. Bi, L. Xie, H. Zhang, X. Chen, X. Gu, Q. Tian, Accurate medium-range global weather forecasting with 3d neural509\nnetworks, Nature (2023) 1–6.510\n[46] S. Goswami, M. Yin, Y. Y u, G. E. Karniadakis, A physics-informed variational deeponet for predicting crack path in511\nquasi-brittle materials, Computer Methods in Applied Mechanics and Engineering 391 (2022) 114587.512\n[47] Z. Li, H. Zheng, N. Kovachki, D. Jin, H. Chen, B. Liu, K. Azizzadenesheli, A. Anandkumar, Physics-informed neural513\noperator for learning partial differential equations, arXiv preprint arXiv:2111.03794 (2021).514\n[48] S. W ang, H. W ang, P . Perdikaris, Learning the solution operator of parametric partial differential equations with physics-515\ninformed deeponets, Science advances 7 (40) (2021) eabi8605.516\n[49] Y. W ang, J. Sun, T. Rabczuk, Y. Liu, A deep complementary energy method for solid mechanics using minimum517\ncomplementary energy principle, arXiv preprint arXiv:2302.01538 (2023).518\n[50] T. A. Schaedler, A. J. Jacobsen, A. T orrents, A. E. Sorensen, J. Lian, J. R. Greer, L. V aldevit, W. B. Carter, Ultralight519\nmetallic microlattices, Science 334 (6058) (2011) 962–965.520\n[51] X. Zheng, H. Lee, T. H. W eisgraber, M. Shusteff, J. DeOtte, E. B. Duoss, J. D. Kuntz, M. M. Biener, Q. Ge, J. A. Jackson,521\net al., Ultralight, ultrastiff mechanical metamaterials, Science 344 (6190) (2014) 1373–1377.522\n[52] J. Bauer, S. Hengsbach, I. T esari, R. Schwaiger, O. Kraft, High-strength cellular ceramic composites with 3d523\nmicroarchitecture, Proceedings of the National Academy of Sciences 111 (7) (2014) 2453–2458.524\n[53] X. Zhang, D. Y ang, Mechanical properties of auxetic cellular material consisting of re-entrant hexagonal honeycombs,525\nMaterials 9 (11) (2016) 900.526\n[54] J. N. Grima, R. Gatt, N. Ravirala, A. Alderson, K. E. Evans, Negative poisson’s ratios in cellular foam materials, Materials527\nScience and Engineering: A 423 (1-2) (2006) 214–218.528\n[55] Y. Y. T ay , C. S. Lim, H. M. Lankarani, A őnite element analysis of high-energy absorption cellular materials in enhancing529\npassive safety of road vehicles in side-impact accidents, International Journal of Crashworthiness 19 (3) (2014) 288–300.530\n[56] F. Xu, X. Zhang, H. Zhang, A review on functionally graded structures and materials for energy absorption, Engineering531\nStructures 171 (2018) 309–325.532\n[57] J. Li, H. Li, L. Xu, L. W ang, Z. Hu, L. Liu, Y. Huang, N. A. Kotov, Biomimetic nanoporous aerogels from branched aramid533\nnanoőbers combining high heat insulation and compressive strength, SmartMat 2 (1) (2021) 76–87.534\n[58] M. Al-Zubi, E. A yorinde, G. Witus, M. Dundar, M. W arriach, Y. Murty , Vibro-acoustic characterization and optimization535\nof periodic cellular material structures (pcms) for nvh applications, Journal of Materials Science Research 2 (4) (2013) 64.536\n[59] J. Hohe, V. Hardenacke, V. F ascio, Y. Girard, J. Baumeister, K. Stöbener, J. W eise, D. Lehmhus, S. Pattofatto, H. Zeng,537\net al., Numerical and experimental design of graded cellular sandwich cores for multi-functional aerospace applications,538\nMaterials & Design 39 (2012) 20–32.539\n[60] A. Baroutaji, A. Arjunan, A. Niknejad, T. T ran, A. G. Olabi, Application of cellular material in crashworthiness applications:540\nan overview (2019).541\n[61] M. Benedetti, A. Du Plessis, R. Ritchie, M. Dallago, S. M. J. Razavi, F. Berto, Architected cellular materials: A review on542\ntheir mechanical properties towards fatigue-tolerant design and fabrication, Materials Science and Engineering: R: Reports543\n144 (2021) 100606.544\n[62] A. Baroutaji, A. Arjunan, J. Robinsion, M. Ramadan, M. A. Abdelkareem, A.-G. Olabi, Metallic meta-biomaterial as545\nbiomedical implants (2021).546\n[63] H. Lee, Y. Jang, J. K. Choe, S. Lee, H. Song, J. P . Lee, N. Lone, J. Kim, 3d-printed programmable tensegrity for soft547\nrobotics, Science Robotics 5 (45) (2020) eaay9024.548\n18\n[64] D. Goswami, S. Liu, A. Pal, L. G. Silva, R. V. Martinez, 3d-architected soft machines with topologically encoded motion,549\nAdvanced functional materials 29 (24) (2019) 1808713.550\n[65] Y. Jiang, Z. Liu, N. Matsuhisa, D. Qi, W. R. Leow, H. Y ang, J. Y u, G. Chen, Y. Liu, C. W an, et al., Auxetic mechanical551\nmetamaterials to enhance sensitivity of stretchable strain sensors, Advanced Materials 30 (12) (2018) 1706589.552\n[66] H. A. Schwarz, Gesammelte mathematische abhandlungen, V ol. 260, American Mathematical Soc., 1972.553\n[67] L. Han, S. Che, An overview of materials with triply periodic minimal surfaces and related geometry: from biological554\nstructures to self-assembled systems, Advanced Materials 30 (17) (2018) 1705708.555\n[68] D. Barba, E. Alabort, R. Reed, Synthetic bone: Design by additive manufacturing, Acta biomaterialia 97 (2019) 637–656.556\n[69] R. Attarzadeh, S.-H. Attarzadeh-Niaki, C. Duwig, Multi-objective optimization of tpms-based heat exchangers for low-557\ntemperature waste heat recovery , Applied Thermal Engineering 212 (2022) 118448.558\n[70] S. Y u, J. Sun, J. Bai, Investigation of functionally graded tpms structures fabricated by additive manufacturing, Materials559\n& Design 182 (2019) 108021.560\n[71] I. Hussain, O. Al-Ketan, F. Renda, M. Malvezzi, D. Prattichizzo, L. Seneviratne, R. K. Abu Al-Rub, D. Gan, Design and561\nprototyping soft–rigid tendon-driven modular grippers using interpenetrating phase composites materials, The International562\nJournal of Robotics Research 39 (14) (2020) 1635–1646.563\n[72] Z. A. Qureshi, E. Elnajjar, O. Al-Ketan, R. A. Al-Rub, S. B. Al-Omari, Heat transfer performance of a őnned metal564\nfoam-phase change material (fmf-pcm) system incorporating triply periodic minimal surfaces (tpms), International Journal565\nof Heat and Mass T ransfer 170 (2021) 121001.566\n[73] P . Zhang, Z. Li, B. Liu, Y. Zhou, M. Zhao, G. Sun, S. Pei, X. Kong, P . Bai, Sound absorption performance of micro-567\nperforated plate sandwich structure based on triply periodic minimal surface, Journal of Materials Research and T echnology568\n27 (2023) 386–400.569\n[74] M. Modrek, A. Viswanath, K. A. Khan, M. I. H. Ali, R. K. A. Al-Rub, An optimization case study to design additively570\nmanufacturable porous heat sinks based on triply periodic minimal surface (tpms) lattices, Case Studies in Thermal571\nEngineering 36 (2022) 102161.572\n[75] J. F u, P . Sun, Y. Du, H. Li, X. Zhou, Q. Tian, Isotropic design and mechanical characterization of tpms-based hollow573\ncellular structures, Composite Structures 279 (2022) 114818.574\n[76] A. Pais, J. L. Alves, R. N. Jorge, J. Belinha, Multiscale homogenization techniques for tpms foam material for biomedical575\nstructural applications, Bioengineering 10 (5) (2023) 515.576\n[77] H. W ang, T. F u, Y. Du, W. Gao, K. Huang, Z. Liu, P . Chandak, S. Liu, P . V an Katwyk, A. Deac, et al., Scientiőc discovery577\nin the age of artiőcial intelligence, Nature 620 (7972) (2023) 47–60.578\n[78] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in: Proceedings of the IEEE conference on579\ncomputer vision and pattern recognition, 2016, pp. 770–778.580"
}