{
    "title": "Fine-tuned large Language model for extracting newly identified acute brain infarcts based on computed tomography or magnetic resonance imaging reports",
    "url": "https://openalex.org/W4410933388",
    "year": 2025,
    "authors": [
        {
            "id": null,
            "name": "Fujita, Nana",
            "affiliations": [
                "National Center for Global Health and Medicine"
            ]
        },
        {
            "id": "https://openalex.org/A2527788263",
            "name": "Yasaka Koichiro",
            "affiliations": [
                "The University of Tokyo"
            ]
        },
        {
            "id": "https://openalex.org/A2745839033",
            "name": "Kiryu Shigeru",
            "affiliations": [
                "International University of Health and Welfare"
            ]
        },
        {
            "id": "https://openalex.org/A2167694922",
            "name": "Abe Osamu",
            "affiliations": [
                "The University of Tokyo"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4391169031",
        "https://openalex.org/W3087226138",
        "https://openalex.org/W3043509097",
        "https://openalex.org/W2931102071",
        "https://openalex.org/W2795147622",
        "https://openalex.org/W3204240300",
        "https://openalex.org/W2003694524",
        "https://openalex.org/W2338526423",
        "https://openalex.org/W4409480685",
        "https://openalex.org/W4405364455",
        "https://openalex.org/W3200849552",
        "https://openalex.org/W4362522726",
        "https://openalex.org/W4407161216",
        "https://openalex.org/W4383186888",
        "https://openalex.org/W4386757338",
        "https://openalex.org/W4400226676",
        "https://openalex.org/W4400595639",
        "https://openalex.org/W4401881840",
        "https://openalex.org/W4387473486",
        "https://openalex.org/W2765571304",
        "https://openalex.org/W4396600570",
        "https://openalex.org/W4399505065"
    ],
    "abstract": "Abstract Purpose This study aimed to develop an automated early warning system using a large language model (LLM) to identify acute to subacute brain infarction from free-text computed tomography (CT) or magnetic resonance imaging (MRI) radiology reports. Methods In this retrospective study, 5,573, 1,883, and 834 patients were included in the training (mean age, 67.5 ± 17.2 years; 2,831 males), validation (mean age, 61.5 ± 18.3 years; 994 males), and test (mean age, 66.5 ± 16.1 years; 488 males) datasets. An LLM (Japanese Bidirectional Encoder Representations from Transformers model) was fine-tuned to classify the CT and MRI reports into three groups (group 0, newly identified acute to subacute infarction; group 1, known acute to subacute infarction or old infarction; group 2, without infarction). The training and validation processes were repeated 15 times, and the best-performing model on the validation dataset was selected to further evaluate its performance on the test dataset. Results The best fine-tuned model exhibited sensitivities of 0.891, 0.905, and 0.959 for groups 0, 1, and 2, respectively, in the test dataset. The macrosensitivity (the average of sensitivity for all groups) and accuracy were 0.918 and 0.923, respectively. The model’s performance in extracting newly identified acute brain infarcts was high, with an area under the receiver operating characteristic curve of 0.979 (95% confidence interval, 0.956–1.000). The average prediction time was 0.115 ± 0.037 s per patient. Conclusion A fine-tuned LLM could extract newly identified acute to subacute brain infarcts based on CT or MRI findings with high performance.",
    "full_text": "ORIGINAL ARTICLE\nEmergency Radiology (2025) 32:495–501\nhttps://doi.org/10.1007/s10140-025-02354-1\nIntroduction\nStroke is the fifth leading cause of death in the United \nStates [1] and the second leading cause of death worldwide \n[2]. Furthermore, stroke is the leading cause of acquired \nlong-term disability [ 2]. Specifically, cerebral infarction \nis a common form of stroke. The treatment of acute cere -\nbral infarction has advanced significantly in recent years \n[3], with the establishment of intravenous thrombolysis \nand endovascular therapy for occluded cerebral arteries. \nHowever, some patients are ineligible for these therapies, \nor do not achieve functional improvement despite receiv -\ning treatment. Recognition of subacute brain infarcts is also \nimportant. The combination of aspirin and clopidogrel dur -\ning the subacute phase of stroke is known to be effective in \n \r Koichiro Yasaka\nkoyasaka@gmail.com\n1 Department of Radiology, National Center for Global Health \nand Medicine, Japan Institute for Health Security, Tokyo, \nJapan\n2 Department of Radiology, The University of Tokyo, Tokyo, \nJapan\n3 Department of Radiology, International University of Health \nand Welfare, Narita, Japan\nAbstract\nPurpose This study aimed to develop an automated early warning system using a large language model (LLM) to identify \nacute to subacute brain infarction from free-text computed tomography (CT) or magnetic resonance imaging (MRI) radiol -\nogy reports.\nMethods In this retrospective study, 5,573, 1,883, and 834 patients were included in the training (mean age, 67.5 ± 17.2 \nyears; 2,831 males), validation (mean age, 61.5 ± 18.3 years; 994 males), and test (mean age, 66.5 ± 16.1 years; 488 males) \ndatasets. An LLM (Japanese Bidirectional Encoder Representations from Transformers model) was fine-tuned to classify the \nCT and MRI reports into three groups (group 0, newly identified acute to subacute infarction; group 1, known acute to sub-\nacute infarction or old infarction; group 2, without infarction). The training and validation processes were repeated 15 times, \nand the best-performing model on the validation dataset was selected to further evaluate its performance on the test dataset.\nResults The best fine-tuned model exhibited sensitivities of 0.891, 0.905, and 0.959 for groups 0, 1, and 2, respectively, \nin the test dataset. The macrosensitivity (the average of sensitivity for all groups) and accuracy were 0.918 and 0.923, \nrespectively. The model’s performance in extracting newly identified acute brain infarcts was high, with an area under the \nreceiver operating characteristic curve of 0.979 (95% confidence interval, 0.956–1.000). The average prediction time was \n0.115 ± 0.037 s per patient.\nConclusion A fine-tuned LLM could extract newly identified acute to subacute brain infarcts based on CT or MRI findings \nwith high performance.\nKeywords Brain infarction · Artificial intelligence · Natural language processing · Large language model · Magnetic \nresonance imaging · Computed tomography\nReceived: 17 April 2025 / Accepted: 27 May 2025 / Published online: 2 June 2025\n© The Author(s) 2025\nFine-tuned large Language model for extracting newly identified \nacute brain infarcts based on computed tomography or magnetic \nresonance imaging reports\nNana Fujita1  · Koichiro Yasaka2  · Shigeru Kiryu3  · Osamu Abe2\n1 3\nEmergency Radiology (2025) 32:495–501\npreventing recurrence without increasing the risk of intra -\ncerebral hemorrhage or major bleeding [ 4]. Approximately \n75% of patients experience some degree of disability [ 5]. \nPatients may experience severe functional impairment that \nhas a lasting impact on their activities of daily living and \nquality of life. Stroke also has serious consequences for \nsociety and the patient’s family [6]. Imaging modalities play \na critical role in the management of stroke.\nMagnetic resonance imaging (MRI) is the standard \nmodality for diagnosing cerebral infarction due to its high \nsensitivity, especially for detecting acute infarcts. Although \nless sensitive, computed tomography (CT) can also visu -\nalize acute lesions and remains useful in clinical practice. \nDetection of both acute and subacute brain infarcts helps \nin the appropriate management of patients [ 4]. However, \nin some cases, these radiological examinations and reports \nare not adequately reviewed [ 7], which may delay the rec -\nognition of the patient’s impending condition. Automated \nsystems that extract acute-to-subacute cerebral infarction \nreports can serve as a warning mechanism, preventing cli -\nnicians from overlooking unexpected strokes and facilitate \nrapid assessment. However, the free-text nature of radiology \nreports makes automated analysis difficult [8].\nNatural language processing (NLP), a branch of artificial \nintelligence, enables computers to understand and interact \nwith human language. Fine-tuned large language models \n(LLMs) based on BERT have advanced clinical NLP, includ-\ning applications in radiology [9] with promising potential in \nvarious tasks [10–15]. Fine-tuning BERT on radiology-spe-\ncific datasets improves its performance in radiology-related \ntasks, such as report classification. Previous studies have \nreported that LLMs can efficiently extract and classify target \npatients from medical image management and processing \nsystems with high accuracy and speed for various condi -\ntions, including pretreatment lung cancer [16], brain tumors \n[17], and progressive bone metastases [ 18]. However, no \nstudy has investigated the use of LLMs to classify isch -\nemic stroke, distinguishing between acute to subacute and \nchronic phases, from unstructured radiology reports.\nThis study evaluated the performance of a fine-tuned \nLLM in classifying patients with newly identified acute \nto subacute ischemic stroke, those with chronic ischemic \nstroke, and nonstroke cases based on CT or MRI findings \nfrom unstructured radiology reports. By exploiting the \nability of LLMs to quickly and accurately extract relevant \npatient information from large datasets, this approach can \nsignificantly improve stroke management efficiency and \ntimeliness.\nMaterials and methods\nOur Institutional Review Board approved this retrospective \nstudy, which waived the requirement for written informed \nconsent considering the retrospective nature of this study.\nDatasets\nWe searched the medical image management and pro -\ncessing systems of our hospital for eligible cases (Fig. 1). \nAmong patients who underwent head CT or MRI during \nthree time periods—January 2023 to February 2024, Janu -\nary 2022, and January to February 2019—reports contain -\ning the keyword “cerebral infarction” in either the clinical \nindication or imaging diagnosis fields were extracted and \nsaved in CSV format. They were designated as the training, \nFig. 1 Schematic of the process of data extraction, training, and performance evaluation of the large language model\n \n1 3\n496\nEmergency Radiology (2025) 32:495–501\nvalidation, and test datasets, respectively. The number of \npatients included in each dataset was 5,573, 1,883, and 834, \nrespectively. To enhance the robustness of the results, the \ntraining, validation, and test datasets were designed to use \ndata from different time periods. This allowed us to evaluate \nthe trained models on datasets external to time. All reports \nwere written mainly in Japanese by radiologists with ≥ 5 \nyears of imaging experience.\nUndersampling of training datasets\nTo address class imbalance in the training dataset (308, \n2,359, and 2,906 patients in groups 0, 1, and 2, respec -\ntively), we randomly undersampled groups 1 and 2 to 500 \npatients each (Fig. 1). This was done to prevent model bias \ntoward the majority classes and improve overall classifica -\ntion performance.\nReference standard\nThe clinical indication and imaging diagnosis sections of \nthe radiology reports were reviewed, and the reports were \nclassified into three groups: group 0, patients with newly \nidentified acute to subacute infarction; group 1, patients \nwith known existing acute to subacute infarction or old \ninfarction; and group 2, patients without infarction. These \nassessments were performed by a radiologist with 7 years of \nimaging experience under the supervision of a senior radi -\nologist (14 years of imaging experience).\nFine-tuning of the pretrained LLM\nWe used a Japanese language model called BERT (ver -\nsion 3) (  h t t p  s : /  / h u g  g i  n g f  a c e .  c o /  c l -  t o h  o k u  / b e r  t -  b a s e - j a p a n e s \ne), developed by Tohoku University and pretrained using \nJapanese Wikipedia articles available up to September 1, \n2019. The model works through 12 processing layers - these \nare like steps in its thinking process, allowing it to gradu -\nally build a deeper understanding of the text. It also uses \n12 “attention heads” in each layer, which help the model \nfocus on different parts of a sentence at the same time and \ncapture context more accurately. In total, the model has \napproximately 110 million parameters—adjustable settings \nthat it fine-tunes during training to improve language under-\nstanding. To process Japanese text, the model uses a method \ncalled subword tokenization, which breaks sentences into \nsmaller parts of words. This is especially useful in Japa -\nnese, where words are not separated by spaces, and it allows \nthe model to recognize and understand even rare or unfa -\nmiliar terms by analyzing their components. Fine-tuning \n(custom training) of the pretrained model was performed \non a workstation equipped with an Intel Core i9-9900 K \nprocessor, NVIDIA Quadro P5000 graphics card, and 64 GB \nof random-access memory, using Python (version 3.10.13) \n(https://www.python.org/) and the Hugging Face  T r a n s f o r \nm e r s library (version 4.35.2) ( https://huggingface.co/). The \nmodel was adapted for our specific classification task using \na built-in method from the library designed for categorizing \ntext (AutoModelForSequenceClassification). It was trained \nto assign each report to one of three predefined categories. \nFor each report, the model generated a set of numerical \nscores (logits), one for each category, and the category with \nthe highest score was selected as the predicted outcome. \nThe training session was repeated 15 times with the same \nhyperparameters and training data to account for the inher -\nent randomness in the fine-tuning process. Based on the \nmodel’s performance on the training and validation datas -\nets, the number of epochs (10 epochs) for fine-tuning was \ndetermined empirically. The other hyperparameters were set \nto default values from the Transformers library. In each ses-\nsion, the model was fine-tuned on the training dataset, and \nits performance was assessed on the validation dataset. To \nenhance the model’s generalizability, CT and MRI reports \nwere used in these processes. The code used for fine-tuning \nis available upon reasonable request.\nTest phase of fine-tuned LLM\nThe performance of the fine-tuned mode, which exhibited \nthe highest macrosensitivity (average of sensitivity for all \ngroups) plus accuracy, was further evaluated using the time-\nindependent test dataset (Fig. 1). The sensitivity, macro -\nsensitivity, accuracy, and time required for prediction were \nrecorded.\nStatistical analysis\nStatistical analyses were performed using R (version 4.1.2; \nhttps://www.r-project.org/). The performance of the  fi   n e - t u \nn e d model in differentiating group 0 from groups 1 and 2 \nwas evaluated using receiver operating characteristic curve \nanalysis, and the area under the ROC curve (AUC) was cal-\nculated. In this analysis, the model’s output value for group \n0 was used. The sensitivity for each group and the accu -\nracy of CT were compared with those of MRI using Fisher’s \nexact test. The macrosensitivity of CT was compared with \nthat of MRI using the paired t-test. P-values < 0.050 were \nused to denote statistical significance.\n1 3\n497\nEmergency Radiology (2025) 32:495–501\n488 males/346 females in the training, validation, and test \ndatasets, respectively.\nTraining and validation for model selection\nTable 2 summarizes the performance of the models in each \ntraining session on the validation dataset. The median mac-\nrosensitivity and accuracy among the 15 sessions were 0.878 \nand 0.841, respectively. For further performance evaluation \non the test dataset, the model from the 14th training session, \nwhich exhibited the highest macrosensitivity (0.916) and \naccuracy (0.844), was selected as the final model.\nPerformance of the fine-tuned LLM on the test \ndataset\nTable 3 presents the confusion matrices of the fine-tuned \nmodel. On the test dataset, the number of group 0 was 79, \nof which 49 were true positives and 30 were false positives. \nThe precision and false discovery rate of groups 0 were 0.620 \nand 0.380, respectively. Table 4 shows the sensitivity and \naccuracy data for the best fine-tuned model. The sensitivi -\nties of groups 0, 1, and 2 of the best fine-tuned model were \n0.891, 0.905, and 0.959, respectively. The macrosensitivity \nResults\nDatasets\nTable 1 presents patient background information. In the \ntraining dataset, the numbers of patients in groups 0, 1, and \n2 were 308, 2,359, and 2,906, respectively. In the validation \ndataset, the numbers were 31, 259, and 1,503, respectively. \nIn the test dataset, the numbers were 55, 486, and 293, \nrespectively. The mean ages of the patients were 67.5 ± 17.2, \n61.5 ± 18.3, and 66.5 ± 16.1 years in the training, validation, \nand test datasets, respectively. The sex distribution was \n2,831 males/2,742 females, 994 males/889 females, and \nTable 1 Patient background information and group distribution of each \ndataset\nTraining Validation Test\nAge (mean ± standard devia-\ntion) (years)\n67.5 ± 17.2 61.5 ± 18.3 66.5 ± 16.1\nSex (male/female) 2831/2742 994/889 488/346\nNumber of reports 5,573 1,883 834\nModality\n   CT 2,321 828 413\n   MRI 3,252 1,055 421\nNumber of patients in each \ngroup\n   Group 0 308 31 55\n   Group 1 2,359 259 486\n   Group 2 2,906 1,503 293\nTable 2 Model performance on the validation dataset\nSensitivity Accuracy\nModel Group 0 Group 1 Group 2 Macrosensitivity\n1 0.903 0.884 0.820 0.869 0.831\n2 0.968 0.915 0.825 0.903 0.840\n3 0.968 0.853 0.837 0.886 0.841\n4 1.000 0.896 0.831 0.909 0.842\n5 0.871 0.714 0.861 0.816 0.841\n6 0.968 0.834 0.842 0.881 0.843\n7 1.000 0.873 0.834 0.902 0.842\n8 0.935 0.822 0.841 0.866 0.840\n9 0.871 0.606 0.878 0.785 0.840\n10 1.000 0.807 0.842 0.883 0.840\n11 0.871 0.587 0.883 0.780 0.842\n12 0.935 0.865 0.833 0.878 0.839\n13 0.935 0.768 0.851 0.851 0.841\n14 1.000 0.919 0.829 0.916 0.844\n15 0.935 0.857 0.836 0.876 0.841\nMedian 0.935 0.853 0.837 0.878 0.841\nGroup 0, newly identified acute to subacute infarction; group 1, exist -\ning acute to subacute infarction or old infarction; group 2, without \ninfarction. Macrosensitivity is the average sensitivity for all groups. \nThe model in the 14th training session exhibited the highest macro -\nsensitivity and accuracy\nTable 3 Confusion matrices of the best fine-tuned model in the test \ndataset\nReference\nModality Prediction Group 0 Group 1 Group 2\nAll n 55 486 293\nGroup 0 49 28 2\nGroup 1 5 440 10\nGroup 2 1 18 281\nCT n 16 241 156\nGroup 0 13 15 1\nGroup 1 3 215 6\nGroup 2 0 11 149\nMRI n 39 245 137\nGroup 0 36 13 1\nGroup 1 2 225 4\nGroup 2 1 7 132\nGroup 0, newly identified acute to subacute infarction; group 1, exist -\ning acute to subacute infarction or old infarction; group 2, without \ninfarction\nTable 4 Performance of the best fine-tuned model in the test dataset\nSensitivity Accuracy\nGroup 0 Group 1 Group 2 Macrosensitivity\nAll 0.891 0.905 0.959 0.918 0.923\nCT 0.813 0.892 0.955 0.887 0.913\nMRI 0.923 0.918 0.964 0.935 0.933\nP-values 0.342 0.355 0.776 0.262 0.299\nThe sensitivity for each group and the accuracy of CT were compared \nwith those of MRI using Fisher’s exact test. The macrosensitivity of \nCT was compared with that of MRI using paired t-test\n1 3\n498\nEmergency Radiology (2025) 32:495–501\n0.956–1.000), 0.988 (95% CI, 0.977–0.999), and 0.975 \n(95% CI, 0.945–1.000), respectively (Fig. 2).\nThe average time required to make a prediction was \n0.115 ± 0.037 s per patient.\nand accuracy of the best fine-tuned model were 0.918 and \n0.923, respectively. No statistically significant difference in \nsensitivity and accuracy was observed between the CT and \nMRI reports.\nThe model’s performance in discriminating group 0 from \ngroups 1 and 2 for all data, CT data, and MRI data was \nhigh, with AUCs of 0.979 (95% confidence interval [CI], \nFig. 2 Receiver operating characteristic curve analysis for discriminating group 0 from groups 1 and 2 using the fine-tuned model in the test dataset. \nThe area under the receiver operating characteristic curve values were 0.979, 0.988, and 0.975 for all data (a), CT (b), and MRI (c), respectively\n \n1 3\n499\nEmergency Radiology (2025) 32:495–501\nfrom groups 1 and 2 achieved a high value (AUC of 0.979). \nIn addition to sensitivity and accuracy, the precision and the \nfalse discovery rate are another important metrics for evalu-\nating the practical performance of a clinical decision-sup -\nport system. In our test set, the model generated 79 alerts for \npossible acute or subacute infarction, of which 49 were true \npositives and 30 were false positives, yielding a precision of \n0.620 and a false discovery rate of 0.380. This may be due to \nthe relatively low prevalence of acute or subacute infarction. \nThis relatively low precision may impact clinical practice \nby increasing physicians’ workload, causing alarm fatigue. \nFurther learning that increases precision while maintaining \nsensitivity would strengthen the system’s usefulness as an \nearly warning tool and increase its potential utility.\nThis study has several limitations. First, there was an \nimbalance in the number of patients between the groups. \nHowever, we managed to address this problem by under -\nsampling the data for groups 1 and 2 in the training data -\nset to balance the sensitivity between the groups. Second, \nour model was developed and evaluated using data exclu -\nsively from our institution, and its performance on external \ndatasets is unknown. According to Walston et al., although \nrandom splitting, cross-validation, and leave-one-out meth-\nods are categorized as internal validation, the use of tem -\nporal and geographic sets is regarded as external validation \n[21]. In this study, a temporally external dataset was used \nto enhance the robustness of the results. Third, this study \nfocused only on stroke classification and did not evaluate \nthe model’s ability to identify other pathologies. Further \nresearch is required to evaluate its performance in detect -\ning other conditions. Fourth, we selected the target cases \nbased on keyword search, specifically those containing the \nterm “cerebral infarction.” The present results reflect the \nperformance after applying a language model following the \nkeyword search, and therefore, both processes—keyword \nfiltering and model-based analysis—are necessary. If all \ncases were included without keyword filtering, there is a \nrisk that the reported performance could not be maintained. \nHowever, keyword search itself is a simple and accurate \nprocedure that can be implemented easily at any facility, \nand thus we believe it does not pose a significant barrier to \napplying our results in clinical practice. Finally, a Japanese \nBERT model was used, and the model performance may \nvary in different languages. Therefore, whether our results \nare directly applicable to other languages remains unclear.\nIn conclusion, this study demonstrated that a fine-tuned \nLLM achieves high performance in classifying patients with \nnewly identified acute to subacute stroke from unstructured \nradiology reports. Implementation of this approach in clini-\ncal practice could help prevent overlooked cases of acute to \nsubacute ischemic stroke and improve the efficiency of case \nselection for research.\nDiscussion\nThis study evaluated the feasibility of a fine-tuned LLM for \nclassifying patients into three categories—newly identified \nacute to subacute ischemic stroke, known existing acute \nto subacute infarction or old infarction, and nonstroke—\nbased on unstructured CT and MRI reports. The optimized \nfine-tuned model exhibited high performance in stroke \nclassification.\nA BERT-based fine-tuned model is well suited for inte -\ngrating NLP into radiology for several reasons. First, it can \nbe efficiently fine-tuned using publicly available pretrained \nmodels with minimal GPU resources and short training \ntimes, thereby eliminating the need for complex rule-setting \nor extensive programming. Second, unlike ChatGPT, which \nrequires data to be uploaded to external servers, this model \nensures privacy and security—critical considerations in the \nmedical field—by allowing local fine-tuning [19].\nPrevious studies have reported the high performance \nof Japanese BERT models in identifying clinically signifi -\ncant radiology reports [ 11, 16, 18]. For example, Kanzawa \net al. reported that brain MRI reports could be accurately \nclassified into three categories: no brain tumor, posttreat -\nment brain tumor, and pretreatment brain tumor [ 17]. Our \nresults are consistent with those of previous studies and \nreinforce the potential of NLP models to improve the effi -\nciency of radiology report processing. These results sug -\ngest that our model has promising clinical applications. It \ncan be applied following the extraction of radiology reports \ncontaining the term “cerebral infarction” and integrating it \ninto a medical image management and processing systems \nwould further facilitate its use in routine practice. It could \nserve as the basis for an alert system that promptly notifies \nclinicians of patients with acute ischemic stroke requiring \nimmediate intervention and subacute brain infarcts who \nalso requires appropriate clinical management [ 4]. Further-\nmore, the model can streamline patient selection for large-\nscale research studies, including deep learning and machine \nlearning applications, making it a valuable tool for clinical \nand research settings.\nClass imbalance causes sensitivity discrepancies between \ndifferent groups [ 20]. Common approaches to address this \nproblem include undersampling and oversampling. How -\never, oversampling carries the risk of overfitting, whereby \nthe model becomes overly specialized in the minority class \nand loses generalizability to unseen data. In this study, \noversampling was not feasible because of the extreme \nimbalance in the dataset, with group 0 (n = 308) being signif-\nicantly smaller than groups 1 ( n = 2,359) and 2 ( n = 2,906). \nTherefore, an undersampling approach was used, adjusting \nthe number of cases in groups 1 and 2 to n = 500 each. With \nthis approach, the performance of differentiating group 0 \n1 3\n500\nEmergency Radiology (2025) 32:495–501\n9. Yasaka K, Abe O (2025) A new step forward in the extraction of \nappropriate radiology reports. Radiology 315(1):e250867.  h t t p  s : /  \n/ d o i  . o  r g /  1 0 . 1  1 4 8  / r a  d i o l . 2 5 0 8 6 7\n10. Yasaka K, Nomura T, Kamohara J et al (2024) Classification of \ninterventional radiology reports into technique categories with a \nFine-Tuned large Language model. J Imaging Inf Med Doi.  h t t p  s \n: /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 1  0 2 7 8 - 0 2 4 - 0 1 3 7 0 - w\n11. Nakamura Y , Hanaoka S, Nomura Y et al (2021) Automatic detec-\ntion of actionable radiology reports using bidirectional encoder \nrepresentations from Transformers. BMC Med Inf Decis Mak \n21(1):262.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 8 6  / s 1  2 9 1 1 - 0 2 1 - 0 1 6 2 3 - 6\n12. Adams LC, Truhn D, Busch F et al (2023) Leveraging GPT-4 \nfor post hoc transformation of Free-text radiology reports into \nstructured reporting: A multilingual feasibility study. Radiology \n307(4):e230725.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 4 8  / r a  d i o l . 2 3 0 7 2 5\n13. Kanemaru N, Yasaka K, Okimoto N et al (2025) Efficacy of Fine-\nTuned large Language model in CT protocol assignment as clini-\ncal Decision-Supporting system. J Imaging Inf Med Doi.  h t t p  s : /  / \nd o i  . o  r g /  1 0 . 1  0 0 7  / s 1  0 2 7 8 - 0 2 5 - 0 1 4 3 3 - 6\n14. Kottlors J, Bratke G, Rauen P et al (2023) Feasibility of differen-\ntial diagnosis based on imaging patterns using a large Language \nmodel. Radiology 308(1):e231167.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 4 8  / r a  d i o l \n. 2 3 1 1 6 7\n15. Nakaura T, Yoshida N, Kobayashi N et al (2024) Preliminary \nassessment of automated radiology report generation with gen -\nerative pre-trained transformers: comparing results to radiologist-\ngenerated reports. Jpn J Radiol 42(2):190–200.  h t t p  s : /  / d o i  . o  r g /  1 0 \n. 1  0 0 7  / s 1  1 6 0 4 - 0 2 3 - 0 1 4 8 7 - y\n16. Yasaka K, Kanzawa J, Kanemaru N, Koshino S, Abe O (2024) \nFine-Tuned large Language model for extracting patients on pre-\ntreatment for lung Cancer from a picture archiving and commu -\nnication system based on radiological reports. J Imaging Inf Med \nDoi.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 1  0 2 7 8 - 0 2 4 - 0 1 1 8 6 - 8\n17. Kanzawa J, Yasaka K, Fujita N, Fujiwara S, Abe O (2024) Auto-\nmated classification of brain MRI reports using fine-tuned large \nLanguage models. Neuroradiology.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 0  0 2 \n3 4 - 0 2 4 - 0 3 4 2 7 - 7\n18. Kanemaru N, Yasaka K, Fujita N, Kanzawa J, Abe O (2024) The \nFine-Tuned large Language model for extracting the progressive \nbone metastasis from unstructured radiology reports. J Imaging \nInf Med.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 1  0 2 7 8 - 0 2 4 - 0 1 2 4 2 - 3\n19. Cai W (2023) Feasibility and prospect of Privacy-preserving \nlarge Language models in radiology. Radiology 309(1):e232335.  \nh t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 4 8  / r a  d i o l . 2 3 2 3 3 5\n20. Yasaka K, Akai H, Abe O, Kiryu S (2018) Deep learning with \nconvolutional neural network for differentiation of liver masses at \ndynamic Contrast-enhanced CT: A preliminary study. Radiology \n286(3):887–896.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 4 8  / r a  d i o l . 2 0 1 7 1 7 0 7 0 6\n21. Walston SL, Seki H, Takita H et al (2024) Data set terminology of \ndeep learning in medicine: a historical review and recommenda -\ntion. Jpn J Radiol 42(10):1100–1109.  h t t p s :   /  / d o  i . o  r  g  /  1 0  . 1 0   0 7 /  s 1 1  \n6 0 4 -  0 2 4 - 0  1 6 0 8 - 1\nPublisher’s note Springer Nature remains neutral with regard to juris-\ndictional claims in published maps and institutional affiliations.\nFunding Open Access funding provided by The University of Tokyo.\nData availability My manuscript has no associated data or the data will \nnot be deposited.\nDeclarations\nCompeting interests None.\nOpen Access   This article is licensed under a Creative Commons \nAttribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the \nsource, provide a link to the Creative Commons licence, and indicate \nif changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless \nindicated otherwise in a credit line to the material. If material is not \nincluded in the article’s Creative Commons licence and your intended \nuse is not permitted by statutory regulation or exceeds the permitted \nuse, you will need to obtain permission directly from the copyright \nholder. To view a copy of this licence, visit  h t t p  : / /  c r e a  t i  v e c  o m m o  n s .  o \nr g  / l i c e n s e s / b y / 4 . 0 /.\nReferences\n1. Martin SS, Aday AW, Almarzooq ZI et al (2024) 2024 heart dis-\nease and stroke statistics: A report of US and global data from the \nAmerican heart association. Circulation 149(8):e347–e913.  h t t p  s \n: /  / d o i  . o  r g /  1 0 . 1  1 6 1  / C I  R . 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 9\n2. Herpich F, Rincon F (2020) Management of acute ischemic \nstroke. Crit Care Med 48(11):1654–1663.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 9 \n7  / C C  M . 0 0 0 0 0 0 0 0 0 0 0 0 4 5 9 7\n3. Powers WJ (2020) Acute ischemic stroke. N Engl J Med \n383(3):252–260.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 5 6  / N E  J M c p 1 9 1 7 0 3 0\n4. Rahman H, Khan SU, Nasir F, Hammad T, Meyer MA, Kaluski \nE (2019) Optimal duration of aspirin plus clopidogrel after isch -\nemic stroke or transient ischemic attack. Stroke 50(4):947–953.  h \nt t p  s : /  / d o i  . o  r g /  1 0 . 1  1 6 1  / S T  R O K E A H A . 1 1 8 . 0 2 3 9 7 8\n5. Jin X, Zou Y , Zhai J, Liu J, Huang B (2018) Refractory Myco -\nplasma pneumoniae pneumonia with concomitant acute cerebral \ninfarction in a child: A case report and literature review. Med \n(Baltim) 97(13):e0103.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 9 7  / M D  . 0 0 0 0 0 0 0 0 0 0 \n0 1 0 1 0 3\n6. Maeshima S, Osawa A Community-Based Rehabilitation After \nBrain Infarction in Japan: From the Acute Phase to Home. In: \nPluta R, editor. Cerebral Ischemia. Brisbane (AU)2021\n7. Callen JL, Westbrook JI, Georgiou A, Li J (2012) Failure to fol -\nlow-up test results for ambulatory patients: a systematic review. J \nGen Intern Med 27(10):1334–1348.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 1  1 6 \n0 6 - 0 1 1 - 1 9 4 9 - 5\n8. Pons E, Braun LM, Hunink MG, Kors JA (2016) Natural Lan -\nguage processing in radiology: A systematic review. Radiology \n279(2):329–343.  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 4 8  / r a  d i o l . 1 6 1 4 2 7 7 0\n1 3\n501"
}