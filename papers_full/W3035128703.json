{
  "title": "Wat zei je? Detecting Out-of-Distribution Translations with Variational Transformers",
  "url": "https://openalex.org/W3035128703",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5041315782",
      "name": "Tim Z. Xiao",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5079288315",
      "name": "Aidan N. Gomez",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5029186201",
      "name": "Yarin Gal",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3101380508",
    "https://openalex.org/W2021618504",
    "https://openalex.org/W2806311723",
    "https://openalex.org/W2950517871",
    "https://openalex.org/W1516111018",
    "https://openalex.org/W2918914336",
    "https://openalex.org/W2592929672",
    "https://openalex.org/W366402269",
    "https://openalex.org/W2900297252",
    "https://openalex.org/W2626967530",
    "https://openalex.org/W2418388682",
    "https://openalex.org/W2514694861",
    "https://openalex.org/W2006969979",
    "https://openalex.org/W2949335953",
    "https://openalex.org/W2133564696",
    "https://openalex.org/W2946593308",
    "https://openalex.org/W2951965145",
    "https://openalex.org/W2149327368",
    "https://openalex.org/W2251333340",
    "https://openalex.org/W2525778437",
    "https://openalex.org/W2119859848",
    "https://openalex.org/W2621975677",
    "https://openalex.org/W2971561076",
    "https://openalex.org/W2805762288",
    "https://openalex.org/W1027701877",
    "https://openalex.org/W2626778328",
    "https://openalex.org/W2963418779",
    "https://openalex.org/W3104630509",
    "https://openalex.org/W2038698865",
    "https://openalex.org/W2146574666",
    "https://openalex.org/W1753482797",
    "https://openalex.org/W2951786554",
    "https://openalex.org/W2750586355",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W2757980860"
  ],
  "abstract": "We detect out-of-training-distribution sentences in Neural Machine Translation using the Bayesian Deep Learning equivalent of Transformer models. For this we develop a new measure of uncertainty designed specifically for long sequences of discrete random variables -- i.e. words in the output sentence. Our new measure of uncertainty solves a major intractability in the naive application of existing approaches on long sentences. We use our new measure on a Transformer model trained with dropout approximate inference. On the task of German-English translation using WMT13 and Europarl, we show that with dropout uncertainty our measure is able to identify when Dutch source sentences, sentences which use the same word types as German, are given to the model instead of German.",
  "full_text": "Wat zei je?\nDetecting Out-of-Distribution Translations with\nVariational Transformers\nTim Z. Xiao\ntim.z.xiao@outlook.com\nAidan N. Gomez\naidan.gomez@cs.ox.ac.uk\nYarin Gal\nyarin@cs.ox.ac.uk\nOxford Applied and Theoretical Machine Learning Group\nDepartment of Computer Science\nUniversity of Oxford\nAbstract\nWe detect out-of-training-distribution sentences in Neural Machine Translation\nusing the Bayesian Deep Learning equivalent of Transformer models. For this we\ndevelop a new measure of uncertainty designed speciﬁcally for long sequences of\ndiscrete random variables—i.e. words in the output sentence. Our new measure\nof uncertainty solves a major intractability in the naive application of existing\napproaches on long sentences. We use our new measure on a Transformer model\ntrained with dropout approximate inference. On the task of German-English\ntranslation using WMT13 and Europarl, we show that with dropout uncertainty our\nmeasure is able to identify when Dutch source sentences, sentences which use the\nsame word types as German, are given to the model instead of German.\n1 Introduction\nStatistical Machine Translation (SMT, [5, 31]), built on top of probabilistic modelling foundations\nsuch as the IBM alignment models [ 40, 5, 9], has largely been replaced in recent years following\nthe emergence of Neural Machine Translation approaches (NMT, [17, 1, 26, 38]). This change has\nbrought with it huge performance gains to the ﬁeld [ 34], but at the same time we have lost many\ndesirable properties of these models. Statistical probabilistic models can inform us when they are\nguessing at random on inputs they never saw before [12]. This information can be used, for example,\nto detect out-of-training-distribution examples for selective classiﬁcation by referring uncertain inputs\nto an expert for annotation [24], or for a human-in-the-loop approach to reduce data labelling costs\n[11, 41, 20].\nWith new tools in machine learning we can now incorporate such probabilistic foundations into\ndeep learning NLP models without sacriﬁcing performance. This ﬁeld, known as Bayesian Deep\nLearning (BDL, [30, 8]), is concerned with the development of scalable tools which captureepistemic\nuncertainty—the model’s notion of “I don’t know”, a measure of a model’s lack of knowledge e.g.\ndue to lack of training data, or when an input is given to the model which is very dissimilar to what\nthe model has seen before. Such BDL tools have been used extensively in the Computer Vision\nliterature [18, 25], and have been demonstrated to be of practical use for applications including\nmedical imaging [25, 29], robotics [10, 6], and astronomy [15, 36, 14].\nIn this paper we extend these tools, often used for vision tasks, to the language domain. We\ndemonstrate how these tools can be used effectively on the task of selective classiﬁcation in NMT\nby identifying source sentences the translation model has never seen before, and referring such\nsource sentences to an expert for translation. We demonstrate this with state-of-the-art Transformer\nPreprint. Under review.\narXiv:2006.08344v1  [cs.CL]  8 Jun 2020\nmodels, and show how model performance increases when rejecting sentences the model is uncertain\nabout—i.e. the model’s measure of epistemic uncertainty correlates with mistranslations.\nFor this we develop several measures of epistemic uncertainty for applications in natural language\nprocessing, concentrating on the task of machine translation (§3). We compare these measures\nboth with standard deterministic Transformer models, as well as with Variational Transformers,\na new approach we introduce to capture epistemic uncertainty in sequence models using dropout\napproximate inference [ 8]. We give an extensive analysis of the methodology, and compare the\ndifferent approaches quantitatively in the out-of-training-distribution settings (§4), which shows\nour purposed uncertainty estimate BLEUVar works well for measuring the epistemic uncertainty\nfor machine translation. We also analyse the performance of BLEUVar qualitatively from both the\ninﬂuence of sentence length and from the linguistic perspective. We ﬁnish with a discussion in\npotential use cases for the new methodogy proposed.\nThe closest NLP task to the above problem deﬁnition is the quality estimation (QE) task in Machine\nTranslation [37, 3], which tries to solve a similar problem by predicting the quality of a translation\nwith a score called Human Translation Error Rate (HTER, [35]). This is done by training a surrogate\nQE model on source sentences and their corresponding machine-generated translations in a speciﬁc\ndomain, with the target of the surrogate to predict the the percentage of edits needed to be ﬁxed.\nWhile many methods have been shown to successfully solve the task of estimating the quality of\ntranslations [19, 27, 28, 21], by deﬁnition QE crucially relies on examples of mistranslations to train\nthe surrogate. The assumption that such training data is available is often violated in practice though\n(e.g. in active learning), thus existing approaches in QE research cannot generally be used to detect\nout-of-training-distribution examples (see Appendix B for detail discussion about the differences\nbetween QE and our task, as well as other related work that is similar to ours but not solving the same\nproblem).\n2 Background: Uncertainty in Deep Learning\nFor most machine learning models, the optimisation objectives give us a point estimate of the\nmodel parameters, which maximise the likelihood of the model generating the training data (i.e.\np(Y|X,ω = ω∗), ω∗∈Ω s.t. Ω is the set of all possible model parameters, Y,X are the training\ndata). Such point estimate will provide us with a very good prediction when the test data follows\nthe same distribution as the training data distribution. Given a new input x∗at test time, the model\nprediction for the corresponding y∗is\nˆy∗= arg max\ny∗\np(y∗|x∗,ω∗). (1)\nHowever, we cannot expect the model to perform well on out-of-distribution (OOD) data which it\nnever saw before. Instead, we would wish for the model to indicate its uncertainty towards such\ninputs. We could use p(ˆy∗|x∗,ω∗) as an estimate for model uncertainty, but as we show below,\nit would not be a well calibrated one. It might be the case that many ω might give equally good\npredictions on the train set, but might widely disagree with their predictions on OOD data. In fact, ω∗\nmight give arbitrary predictions on OOD training data which is very dissimilar to previously observed\ninputs. Thus, a high score does not distinguish whether x∗is OOD or not, and whether we should\ntrust the model’s prediction.\n2.1 Bayesian Inference\nBayesian probabilistic models capture the notion of uncertainty explicitly. Rather than considering a\nsingle point estimate ω∗, Bayesian models aim to derive the entire distribution of ωfrom the training\ndata. The resulting distribution is called posterior distribution\np(ω|X,Y ) = p(Y|X,ω)p(ω)\np(Y|X) . (2)\nAt test time, we can make prediction about the corresponding y∗by integrating out all possible ω\np(y∗|x∗,X,Y ) =\n∫\np(y∗|x∗,ω)p(ω|X,Y )dω. (3)\n2\nUsing the variance of the predictive distribution p(y∗|x∗,X,Y ) as the uncertainty measure would\nhave taken into account the variance of ω. Hence, an uncertainty measure based on this quantity\ncould be a strong indicator for x∗being OOD.\n2.2 Approximate Inference\nThe difﬁculty for doing Bayesian inference comes from the intractability of calculating the evidence\np(Y|X) =\n∫\np(Y|X,ω)p(ω)dω. (4)\nThere might be closed form solution for a simple model. But for most interesting problems, it is too\ndifﬁcult to compute an exact solution. Therefore, approximations are often used for such inference\nproblems.\nVariational inference (VI) is a pragmatic popular method for doing approximate inference [16]. The\nmethod involves deﬁning an approximating distribution qθ(ω), and trying to ﬁnd the parameter θfor\nthat minimises the Kullback-Leibler (KL) divergence [22] between qθ(ω) and the posterior\nKL(qθ(ω)∥p(ω|X,Y )) =\n∫\nqθ(ω)log qθ(ω)\np(ω|X,Y )dω. (5)\nThe resulting θ∗gives us the closest approximation for the posterior in the family of distribution\nqθ(ω). However, calculating the KL divergence here is also intractable as we still have to do the\nintegration for the evidence in posterior.\nFortunately, a tractable and equivalent objective for minimising the KL divergence is to maximise the\nevidence lower bound (ELBO, [4]) of qθ(ω)\nELBO(qθ) =\n∫\nqθ(ω)log p(Y|X,ω)dω−KL(qθ(ω)∥p(ω)). (6)\nThis is tractable as we know all the distributions (both qθ(ω), p(Y|X,ω) and p(ω) are deﬁned by the\nmodel or by our assumptions).\n2.3 Bayesian Inference in Deep Learning\nAlmost all deep models treat the units in a deep neural network as deterministic functions. To adapt\nBayesian methods in deep learning, we need to ﬁrst turn our model into a probabilistic model. It\ncan be done by modelling the weights in each unit of the network as samples from probability\ndistributions. Such networks are called Bayesian neural networks [30]. One major challenge with\nBayesian neural networks is that the integration in ELBO becomes intractable when we have more\nthan one hidden layer [8].\nMany works have tried tackling this problem. One practical method proposed by Gal [8] is MC\nDropout. Gal [8] showed that optimising any neural networks with dropout can be viewed as an\napproximate inference in a probabilistic model (when dropout pis tuned correctly), which implies\nthat a trained neural network with dropout can be interpreted as a Bayesian neural network [ 8].\nStochastic forward passes with dropout ‘turned-on’ at test time then correspond to draws from the\npredictive distribution. Here we extend on these ideas and propose the Variational Transformer,\nwhich is based on MC Dropout applied to the original Transformer model. We perform extensive\nempirical evaluation with this model on the task of NMT. Representing uncertainty in a translation\nmodel is the ﬁrst step towards detecting OOD data. We next discuss how to use this uncertainty\neffectively, and provide the main contribution of this work.\n3 Measures of Uncertainty for NMT\nPrincipally, we care about measuring the variance of a model’s outputs around some given input\npoint. In the context of a simple classiﬁer model, the solution is often found by measuring the mutual\ninformation between the predicted discrete distribution and model parameters, evaluating the output’s\nentropy, or simply computing the variance of model outputs [8]. In the domain of language, however,\nthere are many semantically equivalent alternatives to the same prediction, and it is a difﬁcult matter\n3\nto measure the disagreement between the predicted discrete sequences, which in turn complicates\nthe estimation of variance in the output space. Much worse, when attempting to naively use MI or\nentropy with long sequences or large sets of discrete random variables, we quickly discover that even\napproximate integration over the product space becomes prohibitive [20].\nIn order to capture epistemic uncertainty in the task of NMT, we propose several measures of\nuncertainty appropriate for long sequences of discrete variables (Beam Score and Sequence Probability\nare measures similar to [42]):\n1. Beam Score:we assign a conﬁdence to output ygenerated (using beam search) from input\nxusing the score assigned to y’s beam [43], wherelength_penalty(y; α) =\n(\n5+|y|\n5+1\n)α\n.\nBS = log (pω∗(y|x))\nlength_penalty(y; 0.6) (7)\n2. Sequence Probability:we assign a conﬁdence to the deterministic model output ygener-\nated from input xby taking the log predictive probability under the weight distribution.\nSP = log\n(\nEω∼qθ∗(ω) pω(y|x)\n)\nlength_penalty(y; 0.6) (8)\n3. BLEU Variance: ideally, we would like to measure the variance of outputs y as the\nuncertainty at an input x, i.e.:\nVar = Eω∼qθ∗(ω)Ey∼pω(y|x) (y−µ)2 = Eω∼qθ∗(ω)Ey,y′∼pω(y|x)\n1\n2 (y−y′)2 , (9)\nwhere µ= Ey∼pω(y|x)[y]. If we treat sentences as points in some high dimensional space,\n||y−y′||corresponds to a distance between these two points, which is a numerical value\nrepresenting the difference between two sentences. Thus, any metric for measuring the\ndifference between sentences will allow us to calculate the variance of output y. In our\nexperiments we choose BLEU [33]. The BLEU score of a candidate text to the reference\ntext is a number between 0 and 1, with the value closer to 1 indicating the two texts are more\nsimilar1. Now, we can estimate the variance at an input xby producing pairs of outputs\nfrom the model and measuring the squared complement of the BLEU between them, i.e.\n||y−y′||2 := (1 −BLEU(y,y′))2, and we have:\nBLEUVar = Eω∼qθ∗(ω)Ey,y′∼pω(y|x) (1 −BLEU(y,y′))2 (10)\nFor the beam score we use the deterministic model found by gradient descent and simply take the\nprobabilities from under its output probabilities. This will be our baseline. For sequence probability\nand BLEU variance we use MC Dropout [ 8] and take a number of samples ( N) to estimate the\nexpectations2:\nSP ≈\nlog\n(∑N\ni=1 pωi(y|x)\n)\nlength_penalty(y; 0.6) (11)\nFor the BLEUVar approximation, we opt for decoding outputs using beam search applied to different\nmodel samples (realised by randomising the dropout masks) and measuring the complement BLEU\nbetween pairs of these examples.\nBLEUVar ≈\nN∑\ni=1\nN∑\nj̸=i\n(\n1 −BLEU(decωi(x),decωj(x))\n)2\n. (12)\nAdditionally, out of the N sample sequences generated by BLEUVar, we need to choose one or\ngenerate a new sequence as the result for a speciﬁc input. In regression, the mean of the samples\nis normally chosen as the result, which is an approximation for the predictive mean. In our case,\nthe ‘mean’ ofN sentences is hard to derive or even not properly deﬁned. Therefore, we use the\n1A common practice in the NMT literature is to scale it up by ×100, i.e. in the range of [0, 100].\n2The approximations below should have constant scaling factors, but these don’t impact our evaluation metric\n(performance-retention curves) so we leave them out for simplicity.\n4\nsampled sequence that is the closest to the ideal ‘mean’ as an approximation. Since we can measure\nthe disagreement between any two sentences using BLEU, the sequence that is the closest to the\n‘mean’ of theN samples must have the smallest disagreement with rest of the N−1 samples. Hence,\nthe ﬁnal output sequence of the method BLEU Variance is:\n˜µ= arg min\nyi\n( N∑\n∀j̸=i\n(\n1 −BLEU(yi,y′\nj)\n)\n+\nN∑\n∀j̸=i\n(\n1 −BLEU(y′\nj,yi)\n))\n. (13)\nOne remark for the above three methods is that the two methods BS and SP have the same resulting\ntranslation ygiven x, but with different values as its uncertainty estimates. For the method BLEUVar,\nit uses ˜µfor the resulting translation, and a value in a different range as the uncertainty estimate.\nThis is reﬂected in the plots from the experiments section. For example, in Figure 7 (b), BS and SP\nconverged into the same value, while BLEUVar converged to a different value.\n3.1 Evaluating Uncertainty in Sequence Models\nA number of uncertainty evaluation metrics have been proposed for standard classiﬁer networks such\nas the popular ECE and MSE metrics [ 13]; however, for sequence modelling these classiﬁcation-\nspeciﬁc metrics are not applicable. Instead, we opt for the performance versus retention curve method\nfor evaluating our uncertainty measures following Filos et al. [7].\nThe performance-retention curve indicates how well an uncertainty measure would perform if the\nk% least certain outputs were deleted from the test dataset. The x-axis ranges along the fraction\nof data retained, while the y-axis measures some performance metric of the model on the retained\ndata. A performance-retention curve of a well-calibrated uncertainty measure will see a clear and\nsustained improvement in performance as low-conﬁdence predictions are excluded from the test set;\nwhile a poorly-calibrated model will yield a curve that either lacks a trend or tends to lay beneath the\nwell-calibrated metric’s curve.\n4 Experiments\nExperiments consist of evaluations on both in-distribution (see Appendix A) and out-of-distribution\ntest sets. The implementation of the Transformer architecture we use is taken from the Tensor2Tensor\n[39] repository.\nAs discussed in the previous sections we use performance-retention curves to evaluate the different\nuncertainty estimates of our models. We also use scatter plots of the uncertainty versus pairwise\nBLEU of the predictions to offer another gauge of model uncertainty (see Appendix A.2) To visualise\nthe quality of uncertainty estimates for Transformers, we can order the generated sequence based\non their uncertainty estimates from the most conﬁdent to the most uncertain, and plot BLEU scores\nas a function of the fraction of data retained starting from the least uncertain output. For a good\nuncertainty estimate, we are expecting to see the BLEU scores decrease when the fraction of retained\ndata increases.\nThe following datasets were used in our experiments:\n• WMT EN ↔DE: The training set for translation tasks between English (EN) and\nGerman (DE) composed of news-commentary-v13 with 284k sentences pairs, wmt13-\ncommoncrawl with 2.4msentences pairs and europarl-v7 with 1.9msentences pairs, in\ntotal 4.6msentences pairs. The test set was the newstest2014 with size 3k from WMT\n2014.\n• WMT NL→EN: The test set for Dutch (NL) to English (EN) translation was a subset (size\n3ksentences pairs) of news-commentary-v14.\nIn the experiments below, we denote the results from methods beam score, sequence probability, and\nBLEU Variance as BS, SP and BLEUVar respectively. If a sufﬁx is added such as BLEUVar-10, then\nthe sufﬁx 10 indicates the number of samples taken during MC dropout.\n5\n4.1 Out-of-Distribution Experiments\nThe in-distribution tests showed in Appendix A illustrate that when the training set is large enough,\nthe three uncertainty estimates have similar performance if the test set is in the same domain as the\ntraining set. However, when the training set only has limited data (e.g. 50k compares to 4.6m),\nBLEUVar outperforms BS and SP even though the test set is in the same domain as the training set.\nOne explanation is that with the limited amount of training data, the model was not able to learn a\ndistribution that capture the data from the test set. Therefore, to some extend, the test data are slightly\nout-of-distribution.\nIn this section, we will have a look of experiments under two different obviously out-of-distribution\nsettings (which in our application is equivalent to a domain shift) for evaluating our uncertainty\nestimates.\nThe ﬁrst experiment exploits the fact that the wordings and the sentence patterns might vary across\ndifferent content domains in the same language. For example, sentences from a legal document and\nsentences from social media are different in terms of formality, even though they can both be in the\nsame language. If we train a model using data from one domain and test it with data from another\ndomain, then such input would be out-of-distribution for the model.\nThe second experiment explores an extreme case of out-of-distribution setting. Given a trained model\nfor translation task from language Ato language B, if we test it on input from languageCs.t. C ̸= A,\nit would be an out-of-distribution input.\n4.1.1 Uncertainty Caused by Different Content Domains\n0.0 0.2 0.4 0.6 0.8 1.0\nFraction of data retained\n10\n20\n30\n40\n50\n60\n70BLEU\nBS\nSP-10\nBLEUVar-10\n(a) In-domain test set newstest2014 (size 3k)\n0.0 0.2 0.4 0.6 0.8 1.0\nFraction of data retained\n10\n20\n30\n40\n50\n60\n70BLEU\nBS\nSP-10\nBLEUVar-10 (b) Out-of-domain test set Europarl (size 3k)\nFigure 1:Uncertainty measure comparisons using the same-domain test set newstest2014 (left)\nand out-of-training-domain test set Europarl (right). The Transformer model was trained for DE\nto EN tasks with the news-commentary-v13 EN-DE training set (size 284k) using 350k steps.\nTo evaluate our uncertainty measures on out-of-content-domain test set, we trained a model using\nonly the news-commentary-v13 data for German to English (DE-EN) task. This training set has 284k\nsamples in the domain of news commentary. During test time, we used both the in-domain test data\n(newstest2014) and the out-of-domain test data (a subset of Europarl). newstest2014 is in the same\ndomain as the training set. Europarl contains samples extracted from the proceedings of the European\nParliament, which has a different domain than news commentary.\nWe expect a good uncertainty measure to perform well in both in-domain and out-of-domain test set.\nAs shown in Figure 1, BLEUVar outperforms the other two measures by a large margin for both test\nsets. In particular, the unstable performance of BS on the out-of-domain test data indicating such\nuncertainty measure might be not be reliable on out-of-distribution data, i.e. data it never saw before.\n4.1.2 Uncertainty Caused by Different Language Domains\nWe trained a Transformer model on WMT13 and Europarl DE (German) to EN (English) sentence\npairs (obtaining BLEU 33 on the WMT14 test set). We then evaluated the model on out-of-training-\ndistribution input sentences in NL (Dutch), which shares a large overlapping vocabulary with German\n(hence input sentences look plausible to non-native speakers). One would hope that such data falling\noutside of the training distribution would produce model predictions with high uncertainty.\n6\n0.0 0.2 0.4 0.6 0.8 1.0\nFraction of data retained\n0\n10\n20\n30\n40\n50\n60\n70BLEU\nBS\nSP-10\nBLEUVar-10\n(a) DE to EN (size 3k)\n0.0 0.2 0.4 0.6 0.8 1.0\nFraction of data retained\n0\n10\n20\n30\n40\n50\n60\n70BLEU\nBS\nSP-10\nBLEUVar-10 (b) NL to EN (size 3k)\n0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\nFraction of data retained\n0\n10\n20\n30\n40\n50\n60\n70BLEU\nBS\nSP-10\nBLEUVar-10\nReference (DE to EN) (c) DE+NL to EN (size 6k)\nFigure 2:Uncertainty measure comparisons using the in-distribution DE-EN test set (a), out-of-\ndistribution NL-EN test set (b) and the combined DE+NL to EN test set (c). The Reference line\nin (c) corresponds to the BS plot from (a), which only has 3k test data. Therefore it only reaches\nthe fraction 0.5 in this graph. The model was trained for DE to EN task with the full EN-DE\ntraining set (size 4.6m) using 350k steps.\nThe BLEU scores differences between Figure 2(a) and (b) shows that feeding Dutch (NL) sentences\ninto a German to English model does not result in meaningful translations in general. Nevertheless,\nBLEUVar still provide a better uncertainty estimate with Dutch input (see Figure 2(b)).\nIn addition, Figure 2(c) shows the performance-retention curves for the combined DE+NL test set,\nin which BLEUVar outperforms BS and SP by a large margin. The fact that BLEUVar is close to\nthe DE-EN reference curve indicates most of the DE input has been assigned with high conﬁdence\ncorrectly. As the left half of the BLEUVar curve, which corresponds to the most certain half of the\ntest data, nearly resembles the result from Figure 2(a).\nA more interesting result is shown in Figure 3. Given the combined DE+NL test set, BLEUVar is able\nto nicely separate the test set into to two cluster (DE and NL) using only the uncertainty estimates\nwithout evaluating on the target translation.\n40\n 30\n 20\n 10\n 0\nUncertainty : BS score (deterministic probability)\n0\n200\n400\n600\n800\n1000Count\nBS (DE-EN)\nBS (NL-EN)\n(a) BS histogram on a mixed test set (Left\ncorresponds to higher uncertainty)\n40\n 30\n 20\n 10\n 0\nUncertainty : calibrated model confidence from SP-10\n0\n100\n200\n300\n400\n500Count\nSP-10 (DE-EN)\nSP-10 (NL-EN)\n(b) SP-10 histogram on a mixed test set (Left\ncorresponds to higher uncertainty)\n0 2000 4000 6000 8000\nUncertainty : variances from BLEUVar-10\n0\n50\n100\n150\n200Count\nBLEUVar-10 (DE-EN)\nBLEUVar-10 (NL-EN)\n(c) BLEUVar-10 histogram3 on a mixed test\nset (Right corresponds to higher uncertainty)\nFigure 3:Histograms show uncertainty value for DE-EN (green) and NL-EN (red). Note how\nBLEUVar-10 is able to clearly separate the in-distribution (green) from out-of-distribution (red).\nThe model was trained for DE to EN task with the full EN-DE training set (size 4.6m) using\n350k steps.\n7\nNote that we do not try to solve the problem of language detection here. Instead, we use it as an\nextreme example to show that our uncertainty metric is able to assign very high uncertainty scores\ntowards out-of-distribution test data while being more conﬁdent towards in-distribution data. But our\nmethodology was not trained speciﬁcally nor designed for language detection. However, being able\nto separate the two shows that our methods do reﬂect the uncertainty of the model very well, it also\nshows that Bayesian deep NLP models can be very powerful.\n4.2 Analysis of Sentence Length versus Uncertainty\nUse sentences with different lengths and uncertainties from section §4.1.2 as examples, we can\nsee from the Table 1 that long sentences do not necessarily have consistently low/high uncertainty\n(BLEUVar). For the in-distribution test data, the model is very certain for sentences of length around\n21-50, this is because the training sentences length distribution is centred around these sentence\nlengths (with 54% of the training data in this interval). For the OOD test data, the model is very\nuncertain across all sentence lengths, and as the sentences get longer the model becomes more\nuncertain. Note that average uncertainty for the shortest OOD sentences is ∼4700, which is much\ngreater than the average uncertainty for the longest in-distribution sentences, ∼2700.\nLengths 1-10 11-20 21-30 31-40 41-50 51+\nDE-EN (In-dist) 2579.93 1867.11 1613.95 1507.85 1502.78 2794.11\nNL-EN (OOD) 4772.16 5388.25 5579.82 6039.02 6705.95 7042.69\nTable 1:Average BLEUVar for output sentences of various lengths from Figure 2.\nAn important point is that it is not necessary that all the short sentences must have low uncertainty,\neven for sentences in-distribution. I.e., our uncertainty metric is not simply a measure of sentence\nlengths (or even correlated with it).\nWe further extended the experiment design and added a naive baseline which simply looks at the\nsentence length to reject sentences (ordering test data using sentence_length\nlongest_sentence_length, i.e. from short\nsentences to long sentences). Calculating BLEU scores at different retention rates (as in Figure 2(a),\nsee Table 2), we see that the curve is much lower than BLEUVar. In fact, the performance of sentence\nlength referral is worse than another naive baseline: randomly referring sentences without looking at\nthem at all.\nRetention Sentence length Random referral BLEUVar\n0.2 29.62 32.06 42.87\n0.3 31.48 31.93 41.28\n0.4 32.38 32.26 39.39\nTable 2:BLEU scores at different retention rates under three ordering (sentence length here is\nsystem output sentence length; source sentence length behaves the same).\n4.3 Introspection into the Model Uncertainty from the Linguistic Perspective\nBased on experiments in section §4.1.2, below are some example sentence translations sampled from\nthe model (and with which we estimate the model uncertainty). As a reminder, the uncertainty here\n(BLEUVar) is the level of disagreement between sampled sentences, as determined by pairwise-\nBLEU (pairwise between each model output and the other model outputs). For a very conﬁdent\ntranslation from an in-distribution input (i.e. German), refer to Appendix C.1 Table 4. We can see\nthat all translations sampled from the model are consistent with each other, and the model has no\nuncertainty at all. For other less certain in-distribution translations as showed in in Appendix C.2\nTable 5, we can see that each translation sampled from the model is inconsistent with the others in\nsubtle ways, leading to a larger variability in pair-wise BLEU scores. The model has high uncertainty,\n3With the common practice of BLEU (i.e. ×100), the BLEUVar value results in×1002 in the plots.\n8\nbut still lower than that of the average OOD sentence. In contrast, Table 3 shows 3 truncated samples\nfrom OOD input (i.e. Dutch), the complete table with 5 full samples can be found in Appendix\nC.3. Here each translation sampled from the model is wildly inconsistent with the others, with\nsome translations reminiscent of nonsense translations often encountered with neural systems when\nthese are run on inputs they never saw before. We can identify these bad translations by the large\nvariability in pair-wise BLEU scores. The model has much higher uncertainty than that of the average\nin-distribution sentences.\nSource sentence(NL) :\nDe debiteurenlanden zouden hun concurrentiekracht terugkrijgen; hun schulden zouden in reële termen\nafnemen; de dreiging van staatsbankroeten zou - met de ECB onder hun controle - verdwijnen, en hun\nleenkosten zouden dalen naar een niveau dat vergelijkbaar is met dat van het Verenigd Koninkrijk.\nReference translation(EN) : (only used to compute “BLEU to reference”)\nDebtor countries would regain their competitiveness; their debt would diminish in real terms; and, with\nthe ECB under their control, the threat of default would disappear and their borrowing costs would fall\nto levels comparable to that in the United Kingdom.\nModel predictive-mean translation(EN) : (averaging over predictive probabilities during decoding)\nThe debitenlands were to compete with the rivalrivalrivalrivalrivalrivalrivalrivals of terugkrijgen; they\nwere in debt in the countries of afafafafafafafafafafafafafafafafafafafafafafafafafaf\nTranslation “BLEU to reference”: 1.9\nTranslation uncertainty: 8617\nTranslations sampled from the model: (3 shorten samples from predictive probabilities during decoding)\n1 The debitenlands were the ones to compete in their rivalrivalrivalrivalrivalrivalrivals of them; they were\ndebt-denominated in their afafafafafafafafen; the tripthirthirthirwent of state bankrbankrbankrbankru -\nwith the ECB in its control the run - the run-off - the run - the run-run run run run run of the ECB.\n2 In the debdebdebdebdebits were competitive in terms of law; those debt owed in debt in debt; the three\nof state bankrbankrbankr - with the ECB, in its, in its, in its, in its control - business - business - the ECB,\nin its, in the control - the dispute, the - business - the dispute, the dispute,\n3 At the time of its independence, it was a rivalrivalrivalrivalrivalrivaleach one; the debts of the poor; the\nthree-three of the bankrbankrbankrall - with the ECB in its control of the ones - the ones in question -\nthe parties in question, the countries in the future; the three of the bankrbankrbankrbankrbankr\nTable 3:Out-of-distribution NL source sentence from the experiment in Figure 2(c).\n5 Future Directions\nWith the new tools above we can now develop NMT systems which can be deployed in scenarios\nwhere high trust is required of the system, for example in legal applications. With the new tools\nproposed we can integrate expert annotation in the deployment phase of the system by referring\nuncertain sentences to human annotation instead of automatic one. Further, with these new tools\nfuture research could examine human-in-the-loop approaches to NLP. Such approaches will allow us\nto develop NLP tools in scenarios when hand-labelling of data is too costly, for example language\nwith scarce resources.\n9\nBroader Impact\nBoth the industry and the users of NMT applications can potentially be beneﬁt from our purposed\nmethods. For the industry, an effective uncertainty estimate can be used as a criterion to select the\nmost informative data to be labelled for active learning, where a NMT model can be trained efﬁciently\nwith a limited amount of labelled data. This is important for the NMT industry, where it is difﬁcult\nand expensive to acquire labelled training data as human translators are involved in labelling the data.\nMoreover, the ability to detect the uncertain translations is important for the NMT users. In many\nscenarios where a large amount of texts need to be translated (e.g. legal documents, literature), people\nstill prefer human translator to machine translation. One reason is that even though the current NMT\nmodels have achieved amazing performance for in-distribution data, they are not able to express their\nuncertainties when a given input is out-of-distribution. For these uncertain input (OOD data), the\nmodel is unlikely to generate a good translation (e.g. Figure 4). Given a high uncertainty score, a\nNMT model can reject a translation and notiﬁed the user that it is not certain about an translation. Our\nBLEUVar provides an effective uncertainty measure for NMT models to detect out-of-distribution\ninput. BLEUVar is very likely to help the industry and the users of NMT applications to improve\ntheir experience in developing and using the latest state-of-the-art NMT models.\nFigure 4:A screenshot from Google Translate for OOD data.\nAlthough our method is designed to identify translation failures in NMT systems, one limitation\nis that it might underestimate the model uncertainty, which is known for all variational inference\nmethods [2]. Therefore, it is possible that some out-of-distribution input are not captured by our\nuncertainty estimate. Fortunately, NMT models are not usually used in mission critical system.\nNevertheless, more work is needed in investigating NMT uncertainty if we want to make the most\nout of the powerful NMT models.\nAs for bias: A biased model, in many cases, is caused by biases in the training data. It implies that\nfrom the perspective of the biased model, the unbiased data is out-of-distribution. Since our purposed\nuncertainty estimate can detect out-of-distribution data, it might have the potential to be used in\ninvestigating whether the trained model is biased or not. Therefore, our method might be able to help\nreduce bias in NMT model.\nReferences\n[1] D. Bahdanau, K. Cho, and Y . Bengio. Neural machine translation by jointly learning to\nalign and translate. In Y . Bengio and Y . LeCun, editors, 3rd International Conference on\nLearning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track\nProceedings, 2015.\n[2] D. Barber, A. T. Cemgil, and S. Chiappa. Bayesian time series models. Cambridge University\nPress, 2011.\n[3] J. Blatz, E. Fitzgerald, G. Foster, S. Gandrabur, C. Goutte, A. Kulesza, A. Sanchis, and\nN. Uefﬁng. Conﬁdence estimation for machine translation. In Coling 2004: Proceedings of the\n20th International Conference on Computational Linguistics, pages 315–321, 2004.\n[4] D. M. Blei, A. Kucukelbir, and J. D. McAuliffe. Variational inference: A review for statisticians.\nJournal of the American Statistical Association, 112(518):859–877, 2017.\n10\n[5] P. F. Brown, V . J. D. Pietra, S. A. D. Pietra, and R. L. Mercer. The mathematics of statistical\nmachine translation: Parameter estimation. Computational linguistics, 19(2):263–311, 1993.\n[6] K. Chua, R. Calandra, R. McAllister, and S. Levine. Deep reinforcement learning in a handful\nof trials using probabilistic dynamics models. In Advances in Neural Information Processing\nSystems, pages 4754–4765, 2018.\n[7] A. Filos, S. Farquhar, A. N. Gomez, T. G. J. Rudner, Z. Kenton, L. Smith, M. Alizadeh,\nA. de Kroon, and Y . Gal. Benchmarking bayesian deep learning with diabetic retinopathy\ndiagnosis. https://github.com/OATML/bdl-benchmarks, 2019.\n[8] Y . Gal. Uncertainty in deep learning. PhD thesis, PhD thesis, University of Cambridge, 2016.\n[9] Y . Gal and P. Blunsom. A systematic Bayesian treatment of the IBM alignment models. In\nProceedings of the 2013 Conference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies, pages 969–977, Atlanta, Georgia,\nJune 2013. Association for Computational Linguistics. URL https://www.aclweb.org/\nanthology/N13-1117.\n[10] Y . Gal, R. McAllister, and C. E. Rasmussen. Improving pilco with bayesian neural network\ndynamics models. In Data-Efﬁcient Machine Learning workshop, ICML, volume 4, 2016.\n[11] Y . Gal, R. Islam, and Z. Ghahramani. Deep bayesian active learning with image data. In\nProceedings of the 34th International Conference on Machine Learning-Volume 70 , pages\n1183–1192. JMLR. org, 2017.\n[12] Z. Ghahramani. Probabilistic machine learning and artiﬁcial intelligence. Nature, 521(7553):\n452–459, 2015.\n[13] C. Guo, G. Pleiss, Y . Sun, and K. Q. Weinberger. On calibration of modern neural networks.\nIn Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages\n1321–1330. JMLR. org, 2017.\n[14] Y . D. Hezaveh, L. P. Levasseur, and P. J. Marshall. Fast automated analysis of strong gravitational\nlenses with convolutional neural networks. Nature, 548(7669):555, 2017.\n[15] M. Hon, D. Stello, and J. C. Zinn. Detecting solar-like oscillations in red giants with deep\nlearning. The Astrophysical Journal, 859(1):64, 2018.\n[16] M. I. Jordan, Z. Ghahramani, T. S. Jaakkola, and L. K. Saul. An introduction to variational\nmethods for graphical models. Machine learning, 37(2):183–233, 1999.\n[17] N. Kalchbrenner and P. Blunsom. Recurrent continuous translation models. In Proceedings\nof the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1700–\n1709, Seattle, Washington, USA, Oct. 2013. Association for Computational Linguistics. URL\nhttps://www.aclweb.org/anthology/D13-1176.\n[18] A. Kendall and Y . Gal. What uncertainties do we need in bayesian deep learning for computer\nvision? In Advances in Neural Information Processing Systems, pages 5574–5584, 2017.\n[19] H. Kim, J.-H. Lee, and S.-H. Na. Predictor-estimator using multilevel task learning with stack\npropagation for neural quality estimation. In Proceedings of the Second Conference on Machine\nTranslation, pages 562–568, 2017.\n[20] A. Kirsch, J. van Amersfoort, and Y . Gal. Batchbald: Efﬁcient and diverse batch acquisition for\ndeep bayesian active learning. In Advances in Neural Information Processing Systems, pages\n7024–7035, 2019.\n[21] J. Kreutzer, S. Schamoni, and S. Riezler. Quality estimation from scratch (quetch): Deep\nlearning for word-level translation quality estimation. In Proceedings of the Tenth Workshop on\nStatistical Machine Translation, pages 316–322, 2015.\n[22] S. Kullback and R. A. Leibler. On information and sufﬁciency. The annals of mathematical\nstatistics, 22(1):79–86, 1951.\n11\n[23] A. Kumar and S. Sarawagi. Calibration of encoder decoder models for neural machine transla-\ntion. arXiv:1903.00802, 2019.\n[24] C. Leibig, V . Allken, M. S. Ayhan, P. Berens, and S. Wahl. Leveraging uncertainty information\nfrom deep neural networks for disease detection. Scientiﬁc reports, 7(1):17816, 2017.\n[25] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi, M. Ghafoorian, J. A. Van\nDer Laak, B. Van Ginneken, and C. I. Sánchez. A survey on deep learning in medical image\nanalysis. Medical image analysis, 42:60–88, 2017.\n[26] M.-T. Luong, H. Pham, and C. D. Manning. Effective approaches to attention-based neural\nmachine translation. arXiv:1508.04025, 2015.\n[27] A. F. Martins, R. Astudillo, C. Hokamp, and F. Kepler. Unbabel’s participation in the wmt16\nword-level translation quality estimation shared task. In Proceedings of the First Conference on\nMachine Translation: Volume 2, Shared Task Papers, pages 806–811, 2016.\n[28] A. F. Martins, M. Junczys-Dowmunt, F. N. Kepler, R. Astudillo, C. Hokamp, and R. Grund-\nkiewicz. Pushing the limits of translation quality estimation. Transactions of the Association\nfor Computational Linguistics, 5:205–218, 2017.\n[29] T. Nair, D. Precup, D. L. Arnold, and T. Arbel. Exploring uncertainty measures in deep networks\nfor multiple sclerosis lesion detection and segmentation. Medical image analysis, 59:101557,\n2020.\n[30] R. M. Neal. Bayesian learning for neural networks, volume 118. Springer Science & Business\nMedia, 2012.\n[31] F. J. Och. Minimum error rate training in statistical machine translation. In Proceedings of the\n41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 160–167.\nAssociation for Computational Linguistics, 2003.\n[32] M. Ott, S. Edunov, D. Grangier, and M. Auli. Scaling neural machine translation. InProceedings\nof the Third Conference on Machine Translation: Research Papers, WMT 2018, Belgium,\nBrussels, October 31 - November 1, 2018, pages 1–9. Association for Computational Linguistics,\n2018.\n[33] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. Bleu: a method for automatic evaluation of ma-\nchine translation. In Proceedings of the 40th annual meeting on Association for Computational\nLinguistics, pages 311–318. Association for Computational Linguistics, 2002.\n[34] R. Sennrich, B. Haddow, and A. Birch. Edinburgh neural machine translation systems for WMT\n16. In Proceedings of the First Conference on Machine Translation, WMT 2016, colocated\nwith ACL 2016, August 11-12, Berlin, Germany, pages 371–376. The Association for Computer\nLinguistics, 2016.\n[35] M. Snover, B. Dorr, R. Schwartz, L. Micciulla, and J. Makhoul. A study of translation edit rate\nwith targeted human annotation. In Proceedings of association for machine translation in the\nAmericas, volume 200, 2006.\n[36] F. Soboczenski, M. D. Himes, M. D. O’Beirne, S. Zorzan, A. G. Baydin, A. D. Cobb, Y . Gal,\nD. Angerhausen, M. Mascaro, G. N. Arney, et al. Bayesian deep learning for exoplanet\natmospheric retrieval. arXiv:1811.03390, 2018.\n[37] L. Specia, D. Raj, and M. Turchi. Machine translation evaluation versus quality estimation.\nMachine translation, 24(1):39–50, 2010.\n[38] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and\nI. Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems,\npages 5998–6008, 2017.\n12\n[39] A. Vaswani, S. Bengio, E. Brevdo, F. Chollet, A. N. Gomez, S. Gouws, L. Jones, L. Kaiser,\nN. Kalchbrenner, N. Parmar, R. Sepassi, N. Shazeer, and J. Uszkoreit. Tensor2tensor for neural\nmachine translation. In C. Cherry and G. Neubig, editors, Proceedings of the 13th Conference\nof the Association for Machine Translation in the Americas, AMTA 2018, Boston, MA, USA,\nMarch 17-21, 2018 - Volume 1: Research Papers, pages 193–199. Association for Machine\nTranslation in the Americas, 2018.\n[40] S. V ogel, H. Ney, and C. Tillmann. Hmm-based word alignment in statistical translation. In\nProceedings of the 16th conference on Computational linguistics-Volume 2, pages 836–841.\nAssociation for Computational Linguistics, 1996.\n[41] M. Walmsley, L. Smith, C. Lintott, Y . Gal, S. Bamford, H. Dickinson, L. Fortson, S. Kruk,\nK. Masters, C. Scarlata, et al. Galaxy zoo: Probabilistic morphology through bayesian cnns and\nactive learning. Monthly Notices of the Royal Astronomical Society, 2019.\n[42] S. Wang, Y . Liu, C. Wang, H. Luan, and M. Sun. Improving back-translation with uncertainty-\nbased conﬁdence estimation. In K. Inui, J. Jiang, V . Ng, and X. Wan, editors, Proceedings\nof the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong\nKong, China, November 3-7, 2019, pages 791–802. Association for Computational Linguistics,\n2019.\n[43] Y . Wu, M. Schuster, Z. Chen, Q. V . Le, M. Norouzi, W. Macherey, M. Krikun, Y . Cao, Q. Gao,\nK. Macherey, et al. Google’s neural machine translation system: Bridging the gap between\nhuman and machine translation. arXiv:1609.08144, 2016.\n[44] E. N. Zalta, U. Nodelman, C. Allen, and R. L. Anderson. Stanford encyclopedia of philosophy,\n1995.\n13\nA In-Distribution Experiments\nThis section details our experiments on data that lays within the training distribution for the WMT\nEnglish (EN) →German (DE) and English (EN)→Vietnamese (VI) tasks. We explore the calibration\nof Transformer models in this setting and evaluate the effectiveness of using MC Dropout and the\nproposed methods to measure the model uncertainty.\nIn addition to WMT13 dataset for EN →DE tasks mentioned in the previous section, we use the\nIWSLT 2015dataset for translation tasks from EN to VI. There are 133k sentences pairs in the\nIWSLT 2015training set and 1.3ksentences pairs in the IWSLT 2015test set. Both the training and\ntest data for IWSLT 2015come from the domain of TED talks.\nA.1 Evaluating Model Calibration\n0.0 0.2 0.4 0.6 0.8 1.0\nFraction of data retained\n30\n40\n50\n60BLEU\nBS\nBLEUVar-10\nBLEUVar-50\n(a) BLEUVar-10 vs BLEUVar-50\n0.0 0.2 0.4 0.6 0.8 1.0\nFraction of data retained\n30\n40\n50\n60BLEU\nBS\nSP-10\nSP-50 (b) SP-10 vs SP-50\nFigure 5:Uncertainty estimator comparisons for different number of samples. The model is\ntrained for EN to DE tasks with 4.6m training data using 350k steps.\nThe ﬁrst question we hope to answer is the quality of calibration in Transformers models and to\nevaluate the effectiveness of MC Dropout in improving uncertainty estimates.\nThe Transformer was trained on the full EN-DE training set (4.6 million samples) for 350ksteps. We\nevaluate on the newstest2014 test set.\n0.0 0.2 0.4 0.6 0.8 1.0\nFraction of data retained\n30\n40\n50\n60BLEU\nBS\nSP-10\nBLEUVar-10\nFigure 6:BLEU scores for different uncertainty estimators under various retained data rates.\nThe model is trained for EN to DE tasks with 4.6m training data using 350k steps.\nThe results from Figures 5 and 6 suggest that the beam search score provides a well-calibrated\nuncertainty metric on the in-distribution test data. The second observation is that MC Dropout-based\nmethods seem to slightly under-perform beam score in this setting, even when the number of samples\nis increased ﬁvefold. In this setting, our proposed metric (BLEUVar) beneﬁts more from increasing\nthe number of dropout samples relative to sequence probability.\n14\n0.0 0.2 0.4 0.6 0.8 1.0\nFraction of data retained\n30\n40\n50\n60BLEU\nBS\nSP-10\nBLEUVar-10\n(a) 10 samples\n0.0 0.2 0.4 0.6 0.8 1.0\nFraction of data retained\n30\n40\n50\n60BLEU\nBS\nSP-50\nBLEUVar-50 (b) 50 samples\nFigure 7:BLEU scores for different uncertainty estimators under various retained data rates.\nThe model is trained for EN to VI tasks with 133k training data using 350k steps.\nA.2 The Impact of Training Set Size\nThe WMT EN-DE training set is fairly large and one would assume that most test sentences (or very\nsimilar ones) have been observed during training time. Hence we do not expect much epistemic\nuncertainty to exist in this testing scenario, which the experiments seem to conﬁrm. A natural question\nto ask is on the effect of training set size on the calibration of models. We explore this question by\nconsidering the WMT English to Vietnamese (EN-VI) task which has 133ksamples in the training\nset (approx. 2.6% of EN-DE), and down-sampling the EN-DE training set to 50kand 100ksamples.\nThe performance-retention plots in Figure 7 indicate that, while a large training set yields curves that\nseem to suggest beam score is a sufﬁcient uncertainty metric, when a small dataset is used the MC\nDropout-based uncertainty metrics begin to outperform the beam score (note the retention range 0.0\nto 0.2). Moreover, in the low data setting increasing the number of samples drawn from MC dropout\nresults in a signiﬁcant improvement for BLEUVar.\n0.0 0.2 0.4 0.6 0.8 1.0\nFraction of data retained\n10\n15\n20\n25\n30\n35\n40BLEU\nBS\nSP-10\nBLEUVar-10\n(a) 50k training data\n0.0 0.2 0.4 0.6 0.8 1.0\nFraction of data retained\n15\n20\n25\n30\n35\n40BLEU\nBS\nSP-10\nBLEUVar-10 (b) 100k training data\nFigure 8:Uncertainty estimator comparisons for models with different sizes of training set. The\nmodels were trained for EN to DE tasks with 50k and 100k training data using 350k steps.\nThe experiments depicted in Figures 8 and 9 consist of down-sampling the EN-DE training set.\nFigure 8 demonstrates a similar pattern to the above EN-VI experiment when down-sampling the\nEN-DE data to 50k and 100k examples. Again, in the low-data regime BLEUVar substantially\nout-performs beam score and sequence probability. Figure 9 demonstrates the impact of data size\non the distribution of example uncertainty versus performance. We see that low data regimes lead\nto a low-entropy distribution with high uncertainty across the entire test set; as data availability\nis increased, uncertainty decreases, and average model performance increases for all rates of data\nretention.\n15\n0 2000 4000 6000 8000\nUncertainty : BLEUVar-10\n0\n20\n40\n60\n80\n100\nIndividual BLEU\n0\n10\n20\n30\n40\n50\n60\nCount\n(a) 50k training data\n0 2000 4000 6000 8000\nUncertainty : BLEUVar-10\n0\n20\n40\n60\n80\n100\nIndividual BLEU\n0\n10\n20\n30\n40\nCount\n (b) 100k training data\n0 1000 2000 3000 4000 5000 6000 7000 8000\nUncertainty : BLEUVar-10\n0\n20\n40\n60\n80\n100\nIndividual BLEU\n0\n5\n10\n15\n20\n25\nCount\n(c) 4.6m training data\nFigure 9: The density of individual BLEU score versus uncertainty (BLEUVar-10) for all\nsentences in the same test set newstest2014 produced by models trained with various size of\ndata set. The sentences are ordered by their uncertainty from low (left) to high (right) using\nBLEUVar-10. Following the calculation of BLEUVar, since we have 10 samples, the uncertainty\nestimate BLEUVar-10 has the value in range[0, 90]. And we scale it up by ×100, which results\nin the x-axis has the range [0, 9000]. The models were trained for EN to DE tasks with 50k,\n100k and 4.6m training data using 350k steps.\nB Related Work\nOur work might look similar to quality estimation (QE) task in MT [37, 3], but the problem of QE is\nfairly different to what we do in this paper. QE assumes the existence of a ﬁxed translation system\n(e.g., an in-house encoder-decoder attention-based NMT system, as in WMT19’s shared task in\nQuality Estimation). The QE models then have to determine the quality of the system’s output. In\ncontrast, we look at the problem of “introspection” where the system has to decide the the conﬁdence\n(“quality”) of its own output. This conﬁdence can then be used for selective classiﬁcation where\nthe model can reject some uncertain translation. Further, standard approaches in QE might assume\naccess to privileged data (e.g., the NMT translations for the source sentences and their corresponding\nhuman post-edition, as in task 2 in WMT19’QE), which we do not require. In addition, most existing\napproaches for QE require additional model to be trained to estimate the translation quality of a MT\nmodel, while our method does not have such requirement. Therefore, our method is able to provide\n16\nuncertainty estimate simply with the parallel corpus used for training the translation model without\nthe need for additional data and training procedure.\nThe closest to our paper is task 3 in WMT19’QE: a metric to score sentences is sought, which must\ncorrelate to human judgement. We would like to stress that a system’s conﬁdence in its own prediction\ndoes not have to be correlated to human judgement. Indeed, we demonstrate this in Appendix A.2\nwhere a model can indicate that it does not have enough training data, and requires additional data to\nincrease its conﬁdence (the model’s subjective view of its uncertainty does not have to correlate with\nempirical mistakes - Bayesian epistemology [44]).\nIn addition, QE tasks are mainly focus on estimating the in-distribution translation quality, since the\ntest sets are in the same domain as the training sets provided by WMT QE tasks (e.g. both in the\nIT domain for English-German WMT18,19). In contrast, the goal for our uncertainty estimate is\nto identify the out-of-distribution translations, rather then estimating the quality of in-distribution\ntranslation. Therefore, our tasks are fundamentally different to QE.\nThere have been some prior attempts at investigating the similar problem as ours. In particular, Kumar\nand Sarawagi [23] investigated the calibration of various NMT models at the token level. Kumar\nand Sarawagi found that most models are ill-calibrated at the token level, leading to the resulting\nprobability distribution over the vocabulary used during decoding is not a good reference for model\nuncertainty. To correct for this, Kumar and Sarawagi design a recalibration strategy that applies an\nadaptive temperature to the logits, determined by the token identities, attention entropies, and other\nrelevant components. Another study of uncertainty in NMT models comes from Ott et al. [32]; they\nfound models tend to have overly high uncertainty in their output distribution over sequences. Note\nthat both do not consider epistemic uncertainty, not OOD settings. Our work explores this direction\nand offers a new uncertainty estimation technique that empirically out-performs existing methods by\na signiﬁcant margin.\nC Translation Samples\nC.1 In-distribution Certain Samples\nSource sentence(DE) :\nNevada hat bereits ein Pilotprojekt abgeschlossen.\nReference translation(EN) : (only used to compute “BLEU to reference”)\nNevada has already completed a pilot.\nModel predictive-mean translation(EN) : (averaging over predictive probabilities during decoding)\nNevada has already completed a pilot project.\nTranslation “BLEU to reference”: 70.7\nTranslation uncertainty: 0\nTranslations sampled from the model: (5 samples from predictive probabilities during decoding)\n1 Nevada has already completed a pilot project.\n2 Nevada has already completed a pilot project.\n3 Nevada has already completed a pilot project.\n4 Nevada has already completed a pilot project.\n5 Nevada has already completed a pilot project.\nTable 4:(Low uncertainty) In-distribution DE source sentence from the experiment in Figure\n2(a).\n17\nC.2 In-distribution Uncertain Samples\nSource sentence(DE) :\nIm Grunde genommen sind vegane Gerichte für alle da.\nReference translation(EN) : (only used to compute “BLEU to reference”)\nEssentially, vegan dishes are for everyone.\nModel predictive-mean translation(EN) : (averaging over predictive probabilities during decoding)\nBasically vegan dishes are there for everyone.\nTranslation “BLEU to reference”: 34.5\nTranslation uncertainty: 3122\nTranslations sampled from the model: (5 samples from predictive probabilities during decoding)\n1 Basically vegan dishes are for everyone.\n2 Basically, vegan dishes are there for everyone.\n3 Essentially, vegan dishes are available for everyone.\n4 Basically, vegane dishes are there for all.\n5 Basically vegan dishes are there for everyone.\nTable 5:(High uncertainty) In-distribution DE source sentence from the experiment in Figure\n2(a).\nC.3 Out-of-distribution Samples\nSource sentence(NL) :\nDe debiteurenlanden zouden hun concurrentiekracht terugkrijgen; hun schulden zouden in\nreële termen afnemen; de dreiging van staatsbankroeten zou - met de ECB onder hun controle\n- verdwijnen, en hun leenkosten zouden dalen naar een niveau dat vergelijkbaar is met dat van\nhet Verenigd Koninkrijk.\nReference translation(EN) : (only used to compute “BLEU to reference”)\nDebtor countries would regain their competitiveness; their debt would diminish in real terms;\nand, with the ECB under their control, the threat of default would disappear and their borrowing\ncosts would fall to levels comparable to that in the United Kingdom.\nModel predictive-mean translation(EN) : (averaging over predictive probabilities during decoding)\nThe debitenlands were to compete with the rivalrivalrivalrivalrivalrivalrivalrivals of terugkrij-\ngen; they were in debt in the countries of afafafafafafafafafafafafafafafafafafafafafafafafafafaf\nafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafa\nfafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafafaf\nafafafafafafafaf\nTranslation “BLEU to reference”: 1.9\nTranslation uncertainty: 8617\nTranslations sampled from the model: (5 samples from predictive probabilities during decoding)\n1 The debitenlands were the ones to compete in their rivalrivalrivalrivalrivalrivalrivalrival-\nrivalrivalrivalrivals of them; they were debt-denominated in their afafafafafafafafen; the\ntripthirthirthirwent of state bankrbankrbankrbankrbankrbankrbankrbankrbankrbankrbankr-\nbankrbankrbankrbankru - with the ECB in its control - the run - the run - the run - the run - the\nrun - the run - the run - the run - the run-off - the run - the run-run run run run run of the ECB.\n18\n2 In the debdebdebdebdebdebdebdebdebdebdebdebdebdebdebdebdebdebdebdebdebdebdebdebd\nebdebdebdebdebdebdebdebdebits, the debdebdebdebdebdebdebdebdebits were competitive in\nterms of law; those debt owed in debt in debt; the three of state bankrbankrbankrbankrbankrba\nnkrbankrbankrbankrbankrbankrbankrbankrbankrbankrbankrbankrbankrbankrbankrbankrban\nkrbankrbankrbankrbankrbankrbankrbankrbankrbankrbankrbankrbankrbankrbankrbankrban\nkrbankrbankrbankrbankrbankr - with the ECB, in its, in its, in its, in its control - business -\nbusiness - the ECB, in its, in the control - the dispute, the - business - the dispute, the dispute,\nthe - business - the dispute, the sovereign\n3 At the time of its independence, it was a rivalrivalrivalrivalrivalrivalrivalrivalrivalrivalrival-\nrivalrivalrivalrivalrivalrivalrivalrivaleach one; the debts of the poor; the three-three of the\nbankrbankrbankrall - with the ECB in its control of the ones - the ones in question - the parties\nin question, the countries in the future; the three of the bankrbankrbankrbankrbankrbankr-\nbankrbankrbankr ( with the ECB in its control, with the ECB in its control, in the face, the\ndisputes, the ﬁnancial crises, the ﬁnancial crisis, the ﬁnancial crisis, the ﬁnancial crisis, the\nﬁnancial crisis, the ﬁnancial crisis, the ﬁnancial crisis, the ﬁnancial crisis, the ﬁnancial crisis,\nthe ﬁnancial crisis, the ﬁnancial crisis, the ﬁnancial crisis, the ﬁnancial crisis.\n4 De debitenlanden zouden hun concconcurrentierivalrival terugkrijgen; hun levlevlevlevlevlevl\nev levlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevl\nevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevl\nevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevl\nevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevlevl\nevlevlevlevlevlevlevlevlevlevlevlev\n5 The debitenland gambgambgambgambgambgambgambgambgambgambgambgambgambgam\nbgambgamble in their own countries; the gambgambgambgambgambgambgambgambgambga\nmbgambgambgambgambgambgambgambgambgambgambgambgambgambgambgambgamb\ngambgambgambgambgambgambgambgambgambgambgambgambgambgambgambgambga\nmbgambgambgambgambgambgambgambgambgambgambgambgambgambgambgambgamb\ngambgambgambgambgambgambgambgambgambgambgambgambgambgambgambgambga\nmbgambgambgambgambgambgambgambgambgambgambgambgambgambgambgambgamb\ngambgambgambgambgambgambgambgambgambgambgambgambgambgambgambgambga\nmbgambgambgambgambgambgambgambgambgambgambgambgambgambgambgambgamb\ngambgambgambgambgambgambgambgambgambgambgamb\nTable 6:Out-of-distribution NL source sentence from the experiment in Figure 2(c).\n19",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.7182685732841492
    },
    {
      "name": "Computer science",
      "score": 0.6513291001319885
    },
    {
      "name": "Sentence",
      "score": 0.6459923386573792
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6239567995071411
    },
    {
      "name": "German",
      "score": 0.6175621747970581
    },
    {
      "name": "Machine translation",
      "score": 0.6113321185112
    },
    {
      "name": "Inference",
      "score": 0.5709708333015442
    },
    {
      "name": "Bayesian inference",
      "score": 0.5584497451782227
    },
    {
      "name": "Natural language processing",
      "score": 0.5097696185112
    },
    {
      "name": "Measure (data warehouse)",
      "score": 0.48960167169570923
    },
    {
      "name": "Dropout (neural networks)",
      "score": 0.44278520345687866
    },
    {
      "name": "Bayesian probability",
      "score": 0.4366523027420044
    },
    {
      "name": "Machine learning",
      "score": 0.3188120722770691
    },
    {
      "name": "Linguistics",
      "score": 0.1563379466533661
    },
    {
      "name": "Data mining",
      "score": 0.12262594699859619
    },
    {
      "name": "Engineering",
      "score": 0.09088900685310364
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": []
}