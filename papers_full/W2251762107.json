{
  "title": "Bilingual Structured Language Models for Statistical Machine Translation",
  "url": "https://openalex.org/W2251762107",
  "year": 2015,
  "authors": [
    {
      "id": "https://openalex.org/A2250830047",
      "name": "Ekaterina Garmash",
      "affiliations": [
        "University of Amsterdam"
      ]
    },
    {
      "id": "https://openalex.org/A2109806231",
      "name": "Christof Monz",
      "affiliations": [
        "University of Amsterdam"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2041535764",
    "https://openalex.org/W2116316001",
    "https://openalex.org/W4241645538",
    "https://openalex.org/W2121103874",
    "https://openalex.org/W126222424",
    "https://openalex.org/W2251639585",
    "https://openalex.org/W2156985047",
    "https://openalex.org/W2124322414",
    "https://openalex.org/W2166905217",
    "https://openalex.org/W2153653739",
    "https://openalex.org/W4253646471",
    "https://openalex.org/W1838574496",
    "https://openalex.org/W2124807415",
    "https://openalex.org/W2137854946",
    "https://openalex.org/W2142632103",
    "https://openalex.org/W2251843378",
    "https://openalex.org/W2168966090",
    "https://openalex.org/W2132891320",
    "https://openalex.org/W2158388102",
    "https://openalex.org/W2115774663",
    "https://openalex.org/W2016522586",
    "https://openalex.org/W2113541941",
    "https://openalex.org/W2095650036",
    "https://openalex.org/W1843946026",
    "https://openalex.org/W2160382364",
    "https://openalex.org/W2796084947",
    "https://openalex.org/W2018156128",
    "https://openalex.org/W2149709850",
    "https://openalex.org/W1989705153",
    "https://openalex.org/W122999227",
    "https://openalex.org/W2188741930",
    "https://openalex.org/W1978052141",
    "https://openalex.org/W2001064229",
    "https://openalex.org/W2092654472",
    "https://openalex.org/W3166311385",
    "https://openalex.org/W2180952760",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W2989631226",
    "https://openalex.org/W3152059800",
    "https://openalex.org/W2171421863",
    "https://openalex.org/W2595715041"
  ],
  "abstract": "This paper describes a novel target-side syntactic language model for phrase-based statistical machine translation, bilingual structured language model.Our approach represents a new way to adapt structured language models (Chelba and Jelinek, 2000) to statistical machine translation, and a first attempt to adapt them to phrasebased statistical machine translation.We propose a number of variations of the bilingual structured language model and evaluate them in a series of rescoring experiments.Rescoring of 1000-best translation lists produces statistically significant improvements of up to 0.7 BLEU over a strong baseline for Chinese-English, but does not yield improvements for Arabic-English.",
  "full_text": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2398–2408,\nLisbon, Portugal, 17-21 September 2015.c⃝2015 Association for Computational Linguistics.\nBilingual Structured Language Models for Statistical Machine Translation\nEkaterina Garmash and Christof Monz\nInformatics Institute, University of Amsterdam\nScience Park 904, 1098 XH Amsterdam, The Netherlands\n{e.garmash,c.monz}@uva.nl\nAbstract\nThis paper describes a novel target-side\nsyntactic language model for phrase-based\nstatistical machine translation, bilingual\nstructured language model. Our approach\nrepresents a new way to adapt structured\nlanguage models (Chelba and Jelinek,\n2000) to statistical machine translation,\nand a ﬁrst attempt to adapt them to phrase-\nbased statistical machine translation. We\npropose a number of variations of the\nbilingual structured language model and\nevaluate them in a series of rescoring ex-\nperiments. Rescoring of 1000-best transla-\ntion lists produces statistically signiﬁcant\nimprovements of up to 0.7 BLEU over a\nstrong baseline for Chinese-English, but\ndoes not yield improvements for Arabic-\nEnglish.\n1 Introduction\nMany model components of competitive statisti-\ncal machine translation (SMT) systems are based\non rather simplistic deﬁnitions with little linguis-\ntic grounding, which includes the deﬁnitions of\nphrase pairs, lexicalized reordering, and n-gram\nlanguage models. However, earlier work has also\nshown that statistical MT can beneﬁt from ad-\nditional linguistically motivated models. Most\nprominent among the linguistically motivated ap-\nproaches are syntax-based MT systems which\ntake into account the syntactic structure of sen-\ntences through CKY decoding and categorial la-\nbels (Zollmann and Venugopal, 2006; Shen et al.,\n2008). On the other hand, the commonly used\nphrase-based SMT approaches can also reap some\nof the beneﬁts of using syntactic information by\nintegrating linguistic components addressing spe-\nciﬁc phenomena, such as Cherry (2008), Carpuat\net al. (2010), Crego and Yvon (2010), Ge (2010),\nXiang et al. (2011), Lerner and Petrov (2013),\nGarmash and Monz (2014).\nThis paper is a contribution to the existing body\nof work on how syntactically motivated models\nhelp translation performance. We work with the\nphrase-based SMT (PBSMT) (Koehn et al., 2003)\nframework as the baseline system. Our choice is\nmotivated by the fact that PBSMT is a conceptu-\nally simple and therefore ﬂexible framework. It is\ntypically quite straightforward to integrate an ad-\nditional model into the system. Also, PBSMT is\nthe most widely used framework in the SMT re-\nsearch community, which ensures comparability\nof our results to other people’s work on the topic.\nThere is a variety of ways syntax can be used in\na PBSMT model. Typically a syntactic represen-\ntation of a source sentence is used to deﬁne con-\nstraints on the order in which the decoder trans-\nlates it. For example, Cherry (2008) deﬁnes soft\nconstraints based on the notion of syntactic cohe-\nsion (Section 2). Ge (2010) captures reordering\npatterns by deﬁning soft constraints based on the\ncurrently translated word’s POS tag and the words\nstructurally related to it. On the other hand, tar-\nget syntax is more challenging to use in PBSMT,\nsince a target-side syntactic model does not have\naccess to the whole target sentence at decoding.\nPost and Gildea (2008) is one of the few target-\nside syntactic approaches applicable to PBSMT,\nbut it has been shown not to improve translation.\nTheir approach uses a target side parser as a lan-\nguage model: one of the reasons why it fails is\nthat a parser assumes its input to be grammatical\nand chooses the most likely parse for it. What we\nare interested in during translation is how gram-\n2398\nmatical the target sentence actually is.\nIn addition to reordering constraints, source\nsyntax can be used for target-side language mod-\neling. A target side string can be encoded with\nsource-syntactic building blocks and then scored\nas to how well-formed it is. Crego and Yvon\n(2010), Niehues et al. (2011), Garmash and Monz\n(2014) model target sequences as strings of tokens\nbuilt from the target POS tag and the POS tags of\nthe source words related to it through alignment\nand the source parse. In this paper, we deﬁne\na target-side syntactic language model that takes\nstructural constraints from the source sentence, but\nuses the words from the target side (as ‘building\nblocks’). We do it by adapting an existing mono-\nlingual model of Chelba and Jelinek (2000),struc-\ntured language models, to the bilingual setting.\nOur contributions can be summarized as follows:\n•we propose a novel method to adapt monolin-\ngual structured language models (Chelba and\nJelinek, 2000) (Section 3) to a PBSMT sys-\ntem (Section 4), which does not require an\nexternal on-the-ﬂy parser, but only uses the\ngiven source-side syntactic analysis to infer\nstructural relations between target words;\n•building on the existing literature, we pro-\npose a set of deterministic rules that incre-\nmentally build up a parse of a target trans-\nlation hypothesis based on the source parse\n(Section 4);\n•we evaluate our models in a series of rescor-\ning experiments and achieve statistically sig-\nniﬁcant improvements of up to 0.7 BLEU for\nChinese-English (Section 5).\nBefore describing the models, we motivate our\nmethod with a common assumption about cross-\nlingual correspondence (Section 2).\n2 Direct correspondence assumption and\nsyntactic cohesion in SMT\nBefore we apply the syntactic model introduced in\nSection 3 to the bilingual setting (Section 4), we\nﬁrst explain two widely used assumptions about\nsyntactic correspondence across languages.\nWe take adependency treeto be a syntactic rep-\nresentation of a sentence and reason about other\nsyntactic assumptions and models in its terms.\nIn this work, we choose a dependency structure\nover a constituency structure because the former\n0 1 2\n(a)\n0 1 2 (b)\n0 1 2 3 (c)\n0 1 2 3 (d)\nFigure 1: Examples of projective and non-\nprojective parses. (a-b): projective (a) and non-\nprojective (b) parses of the same dependency tree.\n(b) is non-projective because node 1 is not a de-\nscendant of either 0 or 2 (it is the parent of 2). (c-\nd): projective (c) and non-projective (d) parses of\nthe same dependency tree. Node 2 in (d) is placed\nbetween its sibling (node 1) and the child of its\nsibling (node 3), neither of which is its ancestor.\nis more primitive. 1 A dependency parse D is a\ndependency tree analysis of a sentence W, and\nwe will think of it as a relation between words\nof W, such that D(w,v) if w is a parent (head)\nof v (v being a child/modiﬁer). D can be gener-\nalized to D∗which is an relation between words\nthat are connected by a continuous path in a de-\npendency tree (i.e. D∗(w,v) if D(w,v) or if ∃u\ns.t. D(w,u) ∧D∗(u,v)). We assume unlabeled\ndependency trees. Finally, we make a projectivity\nassumption, which is supported by empirical data\nin many languages (Kuhlmann and Nivre, 2006;\nHavelka, 2007), and makes a model computation-\nally less expensive. A dependency parse D of a\nsentence W = w1,...,w n is projective, if for ev-\nery word pair wi,wj ∈W s.t. D(wi,wj) it holds\nthat every wk ∈W s.t. i<k <j or j <k <iis\na descendant of wi, i.e., D∗(wi,wk); see Figure 1.\nMost NLP models that address the interaction\nof two or more languages are based (explicitly or\nimplicitly) on the direct correspondence assump-\ntion (DCA) (Hwa et al., 2002). It states that close\ntranslation equivalents in different languages have\nthe same dependency structure. This is grounded\nlinguistically, as translation equivalence implies\nsemantic equivalence and therefore thematic rela-\ntions are preserved (Hwa et al., 2002). Thus de-\npendency relations are preserved, as they are de-\nﬁned based on thematic relations between words.\nOn the other hand, there is plenty empirical evi-\ndence supporting the violation of DCA under cer-\ntain conditions (Hwa et al., 2002). For instance,\neven semantically very close sentences in differ-\nent languages may have a different number of\n1A dependency parse (a dependency tree analysis of a sen-\ntence) is more primitive because every constituency parse can\nbe formalized as a projective dependency parse with labeled\nrelations, but not vice versa (Osborne, 2008).\n2399\n0 1 2\na b c\n(a)\n0 1 2\na b c (b)\n0 1 2 3\na b c d (c)\n0 1 2 3\na b c d (d)\nFigure 2: Examples of cohesive and uncohesive\ntranslations. (a-b): cohesive (a) and uncohesive\n(b) translations of the same dependency parse. (b)\nis uncohesive because words aand ctranslate the\nsource subtree {(1,2)}, but the target word bdoes\nnot translate this subtree. (c-d): cohesive (c) and\nuncohesive (d) translations. (d) is uncohesive be-\ncause aand ctranslate the source subtree {(0,1)},\nbut bdoes not translate it.\nwords. Syntactic divergence increases if the two\nlanguages are typologically different.\nEven though DCA only holds up to a certain\nlevel of precision, it is widely used in NLP. There\nare models of cross-lingual transfer that deﬁne\nsyntactic structure of one language by condition-\ning it on the structure of semantically equiva-\nlent sentences in another language (Naseem et al.,\n2012). DCA has also been used in SMT. In partic-\nular, syntax-based SMT is built implicitly around\nthis assumption (Wu, 1997; Yamada and Knight,\n2001). In Quirk and Menezes (2006) DCA is\nexplicitly implemented by deﬁning a translation\nmodel in terms of treelet pairs where target-side\ntreelets are produced by projecting source depen-\ndencies via word alignments.\nClosely related to DCA is the notion of syn-\ntactic cohesionof translation (Fox, 2002; Cherry,\n2008). This is a constraint that does not allow for\nnon-projective reordering: Given a source parse\nDS, a translation W is cohesive if all translated\ntarget words wi,wj do not have any word wk be-\ntween them such that there is a source subtree sub\nin DS such that some parts of it are translated by\nwi and wj but not bywk (Figure 2). Cherry (2008)\nand Bach et al. (2009) deﬁne a set of soft con-\nstraints based on the syntactic cohesion assump-\ntion which are applicable to PBSMT decoding.\nThey only require phrase applications, and not\nnecessarily individual target words, to conform to\nthe cohesion principle. For example, if we imag-\nine a situation where a subtree as in Figure 2(b)\nis translated as a whole with one phrase applica-\ntion (and not word by word), then it does not vio-\nlate the cohesion principle, although it is internally\nuncohesive. Both our approach and Cherry (2008)\nimplement the idea of conforming the target trans-\nlation to the source syntactic structure, but in dif-\nferent ways. Approaches like Cherry (2008) de-\nﬁne principles that constrain the decoder in order\nto produce better translations. Our goal is to have\na model that allows for a more direct way of evalu-\nation of how well-formed the target translation is.\nIn Section 5 we compare translation performance\nof the two approaches.\n3 Structured language models\nAs discussed in Sections 1 and 2, we would like to\ntest how much a PBSMT can beneﬁt from an ad-\nditional syntax-based LM. In this section, we de-\nscribe a syntactic language model, structured LM\n(SLM) (Chelba and Jelinek, 2000), that we extend\nto a bilingual setting and apply to SMT in Sec-\ntion 4. SLMs have been applied in SMT before\n(Yamada and Knight, 2001; Yu et al., 2014), but\nas we show in Section 4, we provide a much sim-\npler method to integrate it into the system. While\na SLM is not the only syntactically deﬁned LM,\nit is one of the few that models sentence genera-\ntion sequentially. And due to the way the decoding\nprocedure of PBSMT is deﬁned, it is natural and\nstraightforward to use models whose score can be\ncomputed sequentially. Other syntactic language\nmodels deﬁne sentence generation hierarchically\n(Shen et al., 2008; Sennrich, 2015), which com-\nplicates their integration into a PBSMT system.\nThe linguistic intuition behind SLMs is that the\nstructural children of a word do not essentially\nchange its distributional properties but just provide\nadditional speciﬁcation. In Figure 3(a) the word\npresident has two modiﬁers: the and former and\nit follows yesterday (an adjunct) and precedes met\n(a predicate). This ordering is correct in English.\nIf instead its modiﬁer was a or an entire relative\nclause, it would not make it incorrect.\nTo capture this observation, (Chelba and Je-\nlinek, 2000) propose a language model where each\nword wi of a sentence W is predicted by an or-\ndered subset of the words preceding wi. This con-\nditioning subset is selected based on the syntactic\nproperties of the preceding sequence Wi−1: the\nstrong predictors are kept and the weak ones are\nleft out. The strong predictors are the set of ex-\nposed heads. Given a subsequence Wi−1 and its\nassociated parse Di−1, exposed heads are the roots\nof all the disconnected subtrees inDi−1. Note that\n2400\nthe former\npresident\nthe\npressyesterday\nmet\n(a)\nthe former\npresident metyesterday\n(b)\nthe\narrived\npresident metyesterday\nwho … in London two days before\n(c)\nFigure 3: A fully parsed sentence (a) and its partial\nparse (b) during sequential generation. The par-\ntial parse in (b) has two disconnected subtrees with\nroots yesterday and president. These roots are the\nexposed heads for met. (c) is an alternative sen-\ntence with a similar structure: president is still a\nroot of a subtree, and thus and an exposed head.\na parse Di−1 is not necessarily fully connected and\nthus a word can have multiple conditioning words.\nFor an example, consider again Figure 3(a). In\na left-to-right scenario, when met is generated, a\nregular n-gram LM conditions it on yesterday the\nformer president, while a SLM conditions it on\nyesterday president, since these two words are the\nexposed heads with respect to met (Figure 3(b)).\nThe words the and former are modiﬁers of pres-\nident and they get ﬁltered out. Thus we obtain a\nless speciﬁc conditioning history, which may lead\nto the resulting model being less sparse. Another\npotential beneﬁt is that SLMs can capture long-\ndistance reordering: If president had as its mod-\niﬁer a relative clause (Figure 3(c)) then a simple\nn-gram LM would be conditioned on days before\n(assuming n= 3), while an SLM would condition\nmet on yesterday president.\nSummarizing the ideas of words being con-\nditioned on a structurally deﬁned subset of the\npreceding sentence, Chelba and Jelinek (2000)\nformalize the generation process of W as fol-\nlows:2 Each new word wi is conditioned on a\n2The original model by (Chelba and Jelinek, 2000) is de-\nﬁned in terms of a lexicalized constituency grammar, but as\nsequence of exposed heads Expos(W,D). Then a\ntag ti is predicted, and the parse Di−i of Wi−1\nis extended to Di incorporating wi and ti (where\nWi−1 is the preﬁx of W preceding wi):\np(W,D) =\n|W |∏\ni=1\np(wi|Expos(Wi−1,Di−1))\n·p(ti|wi,Expos(Wi−1,Di−1))\n·p(Di|wi,ti,Expos(Wi−1,Di−1)).\n(1)\nThey use a shift-reduce parser with reduce-left,\nreduce-right, and shift operations.\n4 Bilingual structured language models\nIn this section, we combine the direct correspon-\ndence assumption (Section 2) and SLMs (Sec-\ntion 3), and deﬁne bilingual structured language\nmodels (BiSLMs) for PBSMT. Structured LMs\nhave been successfully applied in SMT before.\nYamada and Knight (2001) use SLMs in a string-\nto-tree SMT system where a derivation of a target-\nside parse tree is part of the decoding algorithm,\nand target syntactic representations are obtained\n‘for free’. Yu et al. (2014) use an on-the-ﬂy shift-\nreduce parser to build an incremental target parse.\nThe approaches sketched above rely on re-\nsources that a standard PBSMT system does not\nhave access to by default. Phrase-based decoders\ndo not provide us with a parse of the target\nsentence, and inferring the parse of a target string\nwith an external parser is computationally expen-\nsive and potentially unreliable (see Section 1).\nOur main insight is that in a bilingual setting one\ndoes not need an additional probabilistic target\nparsing model. We assume that the source parse is\ngiven (precomputed) and that the DCA (Section 2)\nholds, and project the parse deterministically onto\nthe target side via word alignments 3. We obtain\nthe following equation:\np(T|S,DS) =\n|T |∏\ni=1\np(ti|Expos(Ti−1,\nProjP(DS,S,T i−1))),\n(2)\nwhere T is a target sentence, Ti−1 is the sequence\nin T preceding the i-th target word ti, S is a\nwe discussed in Section 2, constituency parses can be trans-\nformed into dependency parses.\n3Phrase-internal word alignments are stored in the phrase\ntable and are available at decoding time, see Section 4.4.\n2401\npujing shuo ta xihuan suoyou de eluosi funv\nputin said he likes all russian women\n(a)\npujing shuo ta xihuan\nputin said he likes\n(b)\npujing shuo ta xihuan suoyou de eluosi funv\nputin said he likes all russian women\n(c)\nFigure 4: Chinese-English sentence pair (a) and\nsets of exposed heads (underlined ) at different\ngeneration (b and c) steps of a bilingual SLM.\nsource sentence, DS is a source dependency parse,\nand ProjP is a function that returns a partial tar-\nget parse DT i−1 by projecting DS onto Ti−1. In\nwords, at each time stepiwe predict the next word\nti conditioned on the exposed heads of the partial\nparse of Ti−1 projected from the source side. We\nlimit Expos to returning the four preceding exposed\nheads.4 Because the function ProjP is determinis-\ntic and because we do not have to predict tags for\nwords, Equation 2 is simpler than Equation 1.\nWe ﬁrst illustrate Equation 2 with an example\nin Figure 4. Since word alignment is monotonic\nin Figure 4(a), it is straightforward to project the\nsource dependencies onto the target side. We aim\nto imitate a monolingual parser in the way we\nbuild up our projected parse: Reduce operations\nshould be invoked whenever both of the subtrees\ninvolved in the operation are complete, i.e., are\nnot expected to have any more modiﬁers (Sec-\ntion 4.2). For example, when the target word likes\nis produced its exposed heads aresaid and he (Fig-\nure 4(b)), since Putin is a modiﬁer of said. Like-\nwise, the exposed heads for women are said likes\nall Russian(Figure 4(c)).\nIn what follows we discuss how to deﬁneProjP.\nCompared to projection approaches like (Quirk\n4As written above, we choose the dependency structures\nover the lexicalized constituency ones because the latter can\nbe mapped to the former. It is thus more likely that a pro-\njected dependency tree is still be a well-formed parse, than a\nprojected constituency tree. We decided to work with struc-\ntural models that are more ﬂexible, but one may also deﬁne\nBiSLM in terms of the more constraining constituency trees\nand see if the such model has better generalization power.\nand Menezes, 2006), we would like our model\nto project a source parse incrementally, allowing\nit to be used in a PBSMT decoder. We think of\nProjP as a function that computes the output in\ntwo stages: ﬁrst, it infers from the source parse the\ndependency relations between target words (Sec-\ntion 4.1), second, it decides how to parse the tar-\nget sequence, i.e. in which order to assign these\ndependencies (Section 4.2). Additionally, in Sec-\ntion 4.3 we propose to use additional labelings of\ntarget words, and in Section 4.4 we describe some\nimportant implementation details.\n4.1 Dependency graph projection\nAdoption of DCA (Section 2) allows to build up a\ntarget dependency tree from a source tree by pro-\njecting the latter through word alignments. The\ndeﬁnition of DCA can be rephrased as requiring\na one-to-one correspondence map between words\nof a sentence pair, allowing one to unambigu-\nously map dependencies: Given a source parse,\nif t1 is the head of t2, then map(t1) is the head\nof map(t2). The correspondence relation that\nwe have in PBSMT is the word alignment align:\nin the most general case, it is a many-to-many\ncorrespondence, and the straightforward projec-\ntion described above can lead to incorrect depen-\ndency structures. To overcome these problems,\nwe describe a simple ordered set of projection\nrules, based on the ones speciﬁed by (Quirk and\nMenezes, 2006) (and we point out if otherwise).\nThe general idea behind this set of rules is to ex-\ntract a one-to-one function align1−1 from source\nwords to target words from align and use it to\nproject source dependencies as described in the\nparagraph above ( R1 below). We then use addi-\ntional rules ( R2-R4 below) for the target words\nthat are not in align1−1. Given a source sen-\ntence S with a parse DS, a target sentence T and\nword alignment align, align1−1 is extracted as fol-\nlows: For all ti ∈T with multiple aligned source\nwords {si1 ,si2 ,...}only align1−1(si1 ) = ti (only\nleftmost source word is kept, the links from the\nrest of the source words are removed 5). For all\nsi ∈Swith aligned target words{ti1 ,ti2 ,...}keep\nthe link only for the leftmost aligned target word:\nalign1−1(si) = ti1 . For example, in Figure 5(b)\nthe link between f0 and e1 is not in align1−1, and\nin Figure 5(c) the link between f1 and e0 is re-\nmoved (and the arc fromf2 to f1 is not projected).\n5This is an ad-hoc solution, other heuristics could be used.\n2402\nf0 f1 f2\ne0 e1 e2\n(a)\nf0 f1\ne0 e1 e3 (b)\nf0 f1 f2\ne0 e1 (c)\nf0 f1\ne0 e1 e2 e3 (d)\nf0\ne0\nf1 f2\ne1\n(e)\nf0 f1 f2\ne0 e1 (f)\nf0 f1\ne0 e1e1 (g)\nFigure 5: Examples for dependency projection\nrules. (a): no alignment links get removed (R1).\n(b): f0 −e1 link is removed from align1−1 (R1).\n(c): f1 −e0 link gets removed (R1). (d): e1 and\ne2 get adjoined to e0 (R2). (e): R3a. (f): R3b.\n(g) demonstrates two versions of R4: the dashed\narrow gets ‘realized’ only if we adjoin unaligned\nwords to the preceding head.\nThe following rules should be applied in order\n(as else-if conditions). Given a source sentence\nS with a parse DS, a target sentence T and word\nalignment align between them, ti ∈T is a head of\ntj ∈T (i.e. DT (ti,tj)):\n(R1) if there are sk,sl ∈ S s.t. DS(sk,sl) and\nalign1−1(sk) = ti and align1−1(sl) = tj; see Fig-\nures 5(a)-5(c);\n(R2) if ∃s∈Ss.t. align1−1(s) = ti and (s,tj) ∈\nalign. This rule deals with one-to-many align-\nments; see Figure 5(d);\n(R3a) if ∃sk s.t. align1−1(sk) = ti and ∃sl s.t.\n(sl,tj) ∈align and and DS(sl,sk), and ti linearly\nprecedes tj. In words: if two target words are in\nalign1−1 but do not get connected via R1, ﬁnd a\nsource word aligned to the second target word that\nmay get them connected; see Figure 5(e);\n(R3b) same as R3a, but in casetj precedes ti (i.e.,\nﬁnd an additional source word aligned to the ﬁrst\ntarget word; see Figure 5(f)).6\n(R4) In case ¬∃s(s,tj) ∈align (tj is unaligned),\nwe consider two strategies: We simplify the rule of\nQuirk and Menezes (2006) (dealing with the same\nsituation) by adjoining it to the immediately pre-\nceding head. We also consider a strategy whereby\nthe word remains unconnected to any word in the\nsentence; see Figure 5(g).\n6R3a and R3b differ from the rules proposed in Quirk and\nMenezes (2006) dealing with the same situation, since we had\nto adapt it to the left-to-right parsing scenario.\nf0 f1 f2\ne0 e1 e2\n(a)\nf0 f1 f2\ne0 e2e1\nf2\ne3 (b)\nFigure 6: (a): The dashed lines are the dependency\narcs that would project through word alignment,\nresulting in a non-projective projective (impossi-\nble under strong source-completeness). (b): The\ndashed lines are the parse produced under weak\nsource-completeness. Under strong completeness\nnone of the words will get connected.\n4.2 BiSLM parsing procedure\nGiven an inference procedure for dependency re-\nlations between target words (Section 4.1), one\ncan specify in which order the corresponding de-\npendency arcs are assigned to the target sentence.\nWe deﬁne an incremental parsing procedure in\nterms of three operations: shift, left-reduce, and\nright-reduce. The operations are applied as soon\nas the sufﬁcient conditions hold: We specify the\nconditions using the following structural proper-\nties. A target subtree is source-complete if all the\ndescendants of align−1\n1−1(root(sub)) (source corre-\nspondent of the root of the current subtree) (Sec-\ntion 4.1) have been translated and reduced. A tar-\nget subtree is complete if it is source-complete and\nall the target words that are its children through\nnon-projected arcs (through R2 or R4 in Sec-\ntion 4.1) have been translated and reduced. The\nbilingual parsing operations and the sufﬁcient con-\nditions for them are deﬁned as follows:\nShift: after the word is produced it is shifted onto\nthe stack as an elementary subtree.\nLeft-reduce: if a disconnected subtree subi\nand a disconnected subtree subi−1 imme-\ndiately preceding it are both complete and\nDT (root(subi),root(subi−1)), adjoin subi−1\nto subi so that root(subi−1) is a modiﬁer of\nroot(subi).\nRight-reduce: analogous to left-reduce, but\nDT (root(subi−1),root(subi)).\nIn the case of non-cohesive translation the re-\nsulting target dependencies are non-projective.\nOur deﬁnition of left- and right-reduce only pro-\nduces projective parses. For a non-cohesive\ntranslation, certain subtrees will never be source-\ncomplete and will never be reduced; see Fig-\nure 6(a). Note that this is not a disadvantage\n2403\nof our model. Cherry (2008) simply assumes\nthat non-cohesive reordering should be penalized,\nand our model is able to learn this pattern. We\nalso consider an alternative to incorporating non-\ncohesive alignments by relaxing the deﬁnition of\ncompleteness for subtrees: A projected subtree\nsubis weakly source-completeif all descendants\nof all source word(s) which are aligned to the root\nof subhave been translated and, only if the deﬁni-\ntion of reduce applies, reduced; see Figure 6(b).\n4.3 Syntactic labeling of tokens\nOne of the problems with SLMs in general is that\nat time steps iand j the sets of exposed heads for\nti and tj can differ in size, which may imply dif-\nferent predictive power. To this end, we add an ad-\nditional detail to our model: Each time a reduction\noccurs, we label the root of the subtree to which\nanother subtree has been adjoined, thus making\nthe conditioning history more speciﬁc. We use the\nfollowing labelings:\nReduction labeling:if a subtree is adjoint to sub\nfrom the left, then label root(sub) with LR. If it is\nadjoint from the right, then label it with RR.\nReduction POS-labeling: same as in simple re-\nduction labeling, but add the POS tag of the root\nof the reduced subtree to the label.\n4.4 Implementation and training\nTo use BiSLM during decoding, one needs access\nto phrase-internal alignments and target POS tags.\nWe store phrase-internal alignments and target-\nside POS annotations of each phrase in the phrase\ntable, based on the most frequent internal align-\nment during training and the most likely target-\nside POS labeling ˆt given the phrase pair: ˆt =\narg max¯t p(¯t|¯e, ¯f). We train BiSLMs on the par-\nallel training data (Section 5.1) and use the Stan-\nford dependency parser (Chang et al., 2009) for\nChinese and and the Stanford constituency parser\n(Green and Manning, 2010) for Arabic 7. POS-\ntagging of the training data is produced with the\nStanford POS-tagger (Toutanova et al., 2003). We\nlearn a 5-gram model using SRILM (Stolcke et al.,\n2011) with modiﬁed Kneser-Ney smoothing.\n5 Experiments\nTo evaluate the effectiveness of BiSLMs for PB-\nSMT, we performed rescoring experiments for\n7We extract dependency parses from its output based on\nCollins (1999)\nArabic-English and Chinese-English. We com-\npare the resulting 1-best translation lists with an\noutput of the baseline system and the baseline aug-\nmented with soft cohesion constraints from Bach\net al. (2009).\nSystem MT06 MT08 MT06+MT08\nbaseline 32.60 25.94 29.56\ncohesion 32.52 25.98 29.54\nTable 1: Chinese-English baseline and compari-\nson model (Cherry, 2008; Bach et al., 2009) re-\nsults.\nSystem MT08 MT09 MT08+MT09\nbaseline 45.84 48.61 47.18\ncohesion constr. 45.61 48.49 47.02\nTable 2: Arabic-English baseline and comparison\nmodel (Cherry, 2008; Bach et al., 2009) results.\n5.1 Experimental setup\nThis section provides information about our base-\nline system. Word-alignment is produced with\nGIZA++ (Och and Ney, 2003). We use an in-\nhouse implementation of a PBSMT system similar\nto Moses (Koehn et al., 2007). Our baseline has\nall standard PBSMT features including language\nmodel, lexical weighting, and lexicalized reorder-\ning. The distortion limit is set to 5. A 5-gram LM\nis trained on the English Gigaword corpus (1.6B\ntokens) using SRILM with modiﬁed Kneser-Ney\nsmoothing and linear interpolation. Information\nabout the training data for the Arabic-English and\nChinese-English systems is in Table 3. 8 Feature\nweights are tuned using pairwise ranking opti-\nmization (Hopkins and May, 2011) on the MT04\nbenchmark (for both language pairs). For testing,\nwe use MT08 and MT09 for Arabic, and MT06\nand MT08 for Chinese. We use case-insensitive\nBLEU (Papineni et al., 2002) as evaluation met-\nric. Approximate randomization (Noreen, 1989;\nRiezler and Maxwell, 2005) is used to detect sta-\ntistically signiﬁcant differences.\n5.2 Baseline and comparison systems\nAs a comparison model, we implemented six fea-\ntures from Cherry (2008) and Bach et al. (2009) 9\nand added them to the log-linear interpolation used\n8The standard LDC corpora were used for training.\n9Exhaustive and non-exhaustive interruption check, ex-\nhaustive and non-exhaustive interruption count, verb- and\nnoun-dominated subtree interruption count.\n2404\nTraining set N. of lines N. of tokens\nSource side of Ar-En set 4,376,320 148M\nTarget side of Ar-En set 4,376,320 146M\nSource side of Ch-En set 2,104,652 20M\nTarget side of Ch-En set 2,104,652 28M\nTable 3: Training data for Arabic-English and\nChinese-English experiments.\nby the baseline system. Since these features are bi-\nnary or count-based, we cannot use them directly\nin rescoring. For that reason we integrated the fea-\ntures into the decoder and tuned the correspond-\ning weights. The results for Chinese-English and\nArabic-English translation experiments are pre-\nsented in Table 1 and 2, respectively. We see that\nadding the cohesion constraints does not improve\nperformance. This ﬁnding is different from, for\nexample, Feng et al. (2010), where they get im-\nprovement for Chinese-English: however, we note\nthat their training set is smaller than ours, and their\nbaseline is weaker as it does not contain lexical-\nized distortion models.\n5.3 Rescoring experiments\nRescoring with BiSLMs is performed as follows:\nFor the test runs of the baseline system we com-\npute the n = 1000 best translation hypotheses\nfor each source sentence and extract their deriva-\ntions (sequence of phrase pair applications). Each\nphrase pair in our implementation is associated\nwith a unique phrase-internal alignment and tar-\nget POS-sequence. We fully reconstruct word-\nalignment for each pair of a source sentence and\nits translation hypothesis. We project a precom-\nputed source parse onto the target side and com-\npute representations of the target sentence to be\ncomputed by a BiSLM. For each hypothesis, we\ntake its BiSLM score and its score assigned by\nthe baseline system and compute the ﬁnal score\nas a weighted sum of the original baseline score\nand a length-normalized BiSLM score 10, where\nthe weight λis empirically set to 0.3:\nλ· scoreBiSLM\nlengthHypothesis\n+ (1 −λ) ·scoreBaseline (3)\n5.3.1 Chinese-English\nOur main focus here is Chinese-English, since it\nhas more instances of longer-distance reordering,\nat which syntax-based models are typically good.\n10Normalization is needed to ensure comparability of\nscores for translation hypotheses of different lengths, since\nlonger translation hypotheses will have lower scores.\nlabeling complete unalign BLEU diff.\n-adjoin\nplain strong + 30.09▲ +0.53\n- 30.20▲ +0.64\nweak + 30.11▲ +0.55\n- 30.22▲ +0.66\nreduce strong + 29.94△ +0.40\n- 30.19▲ +0.63\nweak + 30.09▲ +0.53\n- 30.24▲ +0.68\nreduce-POS strong + 30.09▲ +0.53\n- 30.25▲ +0.69\nweak + 30.05▲ +0.49\n- 30.25▲ +0.69\nTable 4: Rescoring experiments for Chinese\nMT06+08 1000-best translation sets. Unrescored\nBLEU is 29.56. The column labeling contains in-\nformation about the kind of labeling used on the\ntarget side of a BiSLM: just target words, target\nwords with a reduction label, or target words with\na reduction label and a POS of the root of the re-\nduced subtree (Section 4.3). The column com-\nplete indicates whether we use a strong or weak\ndeﬁnition of a complete subtree (Section 4.2). The\ncolumn unalign-adjoin indicates whether we ad-\njoin an unaligned target word to the preceding\nsubtree (Section 4.1). Statistically signiﬁcant im-\nprovements over the baseline are marked ▲ at the\np < .01 level and △ at the p < .05 level. ▼ marks\nsigniﬁcant decrease at the p<. 01 level.\nSLMs by design are good at capturing longer-\ndistance dependencies. We try out several varia-\ntions of BiSLM. First, we test whether to use a\nstrong or weak deﬁnition of a complete subtree\n(Section 4.2). Second, we investigate whether to\nadjoin unaligned target words to a preceding head\n(Section 4.1; unalign-adjoin+/-). Third, we com-\npare several target-side labeling methods (Sec-\ntion 4.3): plain (just target words), reduce ( LR or\nRR) or reduce-POS ( LR POS or RR POS, where\nPOS is the tag of the root of the reduced subtree).\nThe rescoring results are presented in Table 4.\nThe results show statistically signiﬁcant im-\nprovement over the baseline of up to 0.7 BLEU\n(for all of the employed BiSLM variants except\none). The rescoring experiments also demonstrate\nthe tendency of the unalign-adjoin- feature value\nto produce higher scores than unalign-adjoin+.\nBut the other two distinguishing features do not\nhave an effect on BLEU scores. As future work,\nwe are interested in examining if these features\nproduce the same distribution of scores when a\nBiSLM is fully integrated into the decoder.\n2405\nlabeling complete unalign BLEU diff.\n-adjoin\nplain strong + 47.20 -0.02\n- 47.00▼ -0.18\nweak + 47.22 +0.04\n- 46.98▼ -0.20\nreduce strong + 47.15 -0.03\n- 46.99▼ -0.19\nweak + 47.09 -0.09\n- 46.98▼ -0.20\nreduce-POS strong + 47.15 -0.03\n- 46.98▼ -0.20\nweak + 47.17 +0.01\n- 47.00▼ -0.18\nTable 5: Rescoring experiments for Arabic\nMT08+09 n-best translation sets. Unrescored\nBLEU for is 47.18. For notation see Table 4.\n5.3.2 Arabic-English\nWe also rescore the n-best lists for the output of\nthe Arabic-English baseline system and results are\nshown in Table 5. Arabic and English are typolog-\nically very different, but the range of reordering is\nmuch smaller than for Chinese-English. We ex-\npect reordering-related models to have lesser ef-\nfect on Arabic as compared to Chinese (Carpuat\net al., 2010). Experimental results on Arabic-\nEnglish could indicate what kind of translation\naspect beneﬁts from BiSLMs. We see that for\nArabic-English, just as for the cohesion constraint,\nBiSLM have little effect on BLEU scores, or\neven decrease them. This is a weak indication\nthat BiSLMs are better at capturing reordering as-\npects. As for the varying features deﬁning dif-\nferent BiSLM versions, we again see little effect\nof the labeling type or subtree completeness def-\ninition. On the other hand, we see the oppo-\nsite pattern for the unalign-adjoin feature, where\nunalign-adjoin+ is preferred.\nTo gain further insight into the different effect\nof BiSLM on the two language pairs, we evalu-\nated our experimental output against a reordering-\nsensitive metric LRscore (Birch et al., 2010). We\nuse the version of LRscore which is an average of\nthe inverse Kendall’s Tau distance and the Ham-\nming distance. In order to compute alignments for\ntest sets which are needed to compute the score we\nconcatenated the parallel text with an additional\n250K lines of parallel text from the training data to\nensure better generalization of the alignment algo-\nrithm (GIZA++). The LRscores of the baseline are\ncompared to the best performing BiSLM system\nwith respect to BLEU, for each of the language\npair. The results are provided in Tables 6 and 7.\nsystem LRscore MT06+08\nbaseline 0.4736\nBiSLM 0.4907\nTable 6: LRscores (average inverse Kendall’s\nTau distance and Hamming distance) for Chinese-\nEnglish baseline and BiSLM with reduce-labeling,\nweak completeness, unalign-adjoin-.\nsystem LRscore MT08+09\nbaseline 0.6671\nBiSLM 0.6719\nTable 7: LRscores for Arabic-English baseline and\nBiSLM with plain-labeling, weak completeness,\nunalign-adjoin+.\nAs expected, the scores for Chinese-English are\nmuch lower than for Arabic-English, which is con-\nsistent with the observation reordering is more dif-\nﬁcult for Chinese-English. BiSLM yields larger\nimprovements for Chinese-English suggesting that\nthe proposed model helps addressing difﬁcult re-\nordering problems. While there are also small im-\nprovements for Arabic-English the they may be\ntoo small to be detectable by BLEU.\n6 Conclusions\nIn this paper we proposed a novel way to adapt\nstructured language models to phrase-based SMT.\nOur method requires minimal changes to the PB-\nSMT pipeline. We tried a number of variations\nof our model and evaluated them in rescoring ex-\nperiments, resulting in statistically signiﬁcant im-\nprovement for Chinese-English. The model is\nbased on the idea of syntactic transfer (DCA; Sec-\ntion 2) and the positive result indicates its ability\nto capture syntactic patterns across languages. For\nArabic-English, we did not observe any improve-\nments, suggesting that our models indeed mainly\nimprove reordering aspects. Improvements in\nrescoring are a positive indication that our model\nmay be a strong feature during decoding. As fu-\nture work, we will fully integrate our model into a\nPBSMT decoder and evaluate it on other language\npairs with different reordering distributions.\nAcknowledgments\nWe thank the reviewers for their useful com-\nments. This research was funded in part by the\nNetherlands Organization for Scientiﬁc Research\n(NWO) under project numbers 639.022.213 and\n612.001.218.\n2406\nReferences\nNguyen Bach, Stephan V ogel, and Colin Cherry. 2009.\nCohesive constraints in a beam search phrase-based\ndecoder. In Proceedings of the 2009 Annual Con-\nference of the North American Chapter of the As-\nsociation for Computational Linguistics, pages 1–4.\nAssociation for Computational Linguistics.\nAlexandra Birch, Miles Osborne, and Phil Blunsom.\n2010. Metrics for mt evaluation: evaluating reorder-\ning. Machine Translation, 24(1):15–26.\nMarine Carpuat, Yuval Marton, and Nizar Habash.\n2010. Improving Arabic-to-English statistical ma-\nchine translation by reordering post-verbal subjects\nfor alignment. In Proceedings of the ACL 2010 Con-\nference Short Papers, pages 178–183. Association\nfor Computational Linguistics.\nPi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and\nChristopher D. Manning. 2009. Discriminative\nreordering with chinese grammatical relations fea-\ntures. In Proceedings of the Third Workshop on Syn-\ntax and Structure in Statistical Translation, pages\n51–59. Association for Computational Linguistics.\nCiprian Chelba and Frederick Jelinek. 2000. Struc-\ntured language modeling. Computer Speech and\nLanguage, 14(4):283–332.\nColin Cherry. 2008. Cohesive phrase-based decoding\nfor statistical machine translation. In Proceedings\nof Association for Computational Linguistics, pages\n72–80.\nMichael Collins. 1999. Head-Driven Statistical Mod-\nels for Natural Language Parsing. Ph.D. thesis,\nUniversity of Pennsylvania.\nJosep M. Crego and Franc ¸ois Yvon. 2010. Improv-\ning reordering with linguistically informed bilin-\ngual n-grams. In Proceedings of the 23rd Inter-\nnational Conference on Computational Linguistics,\npages 197–205. Association for Computational Lin-\nguistics.\nMinwei Feng, Arne Mauser, and Hermann Ney. 2010.\nA source-side decoding sequence model for statis-\ntical machine translation. In Conference of the As-\nsociation for Machine Translation in the Americas,\nDenver, Colorado, USA.\nHeidi J. Fox. 2002. Phrasal cohesion and statisti-\ncal machine translation. In Proceedings the Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 304–311. Association for Com-\nputational Linguistics.\nEkaterina Garmash and Christof Monz. 2014.\nDependency-based bilingual language models for\nreordering in statistical machine translation. In Pro-\nceedings of the 2014 Conference on Empirical Meth-\nods in Natural Language Processing (EMNLP) ,\npages 1689–1700, Doha, Qatar, October. Associa-\ntion for Computational Linguistics.\nNiyu Ge. 2010. A direct syntax-driven reordering\nmodel for phrase-based machine translation. In\nHuman Language Technologies: The 2010 Annual\nConference of the North American Chapter of the\nAssociation for Computational Linguistics, pages\n849–857. Association for Computational Linguis-\ntics.\nSpence Green and Christopher D. Manning. 2010.\nBetter arabic parsing: Baselines, evaluations, and\nanalysis. In Proceedings of the 23rd International\nConference on Computational Linguistics, pages\n394–402. Association for Computational Linguis-\ntics.\nJiri Havelka. 2007. Beyond projectivity: Multilin-\ngual evaluation of constraints and measures on non-\nprojective structures. In Proceedings of the 45th An-\nnual Meeting of the Association of Computational\nLinguistics, pages 608–615. Association for Com-\nputational Linguistics.\nMark Hopkins and Jonathan May. 2011. Tuning as\nranking. In Proceedings of the Conference on Em-\npirical Methods in Natural Language Processing,\npages 1352–1362. Association for Computational\nLinguistics.\nRebecca Hwa, Philip Resnik, Amy Weinberg, and\nOkan Kolak. 2002. Evaluating translational corre-\nspondence using annotation projection. In Proceed-\nings of the 40th Annual Meeting on Association for\nComputational Linguistics, pages 392–399. Associ-\nation for Computational Linguistics.\nPhilipp Koehn, Franz Josef Och, and Daniel Marcu.\n2003. Statistical phrase-based translation. In Pro-\nceedings of the 2003 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics on Human Language Technology, pages\n48–54. Association for Computational Linguistics.\nPhilipp Koehn, Hieu Hoang, Alexandra Birch, Chris\nCallison-Burch, Marcello Federico, Nicola Bertoldi,\nBrooke Cowan, Wade Shen, Christine Moran,\nRichard Zens, et al. 2007. Moses: Open source\ntoolkit for statistical machine translation. In Pro-\nceedings of the 45th Annual Meeting of the Associ-\nation for Computational Linguistics on Interactive\nPoster and Demonstration Sessions, pages 177–180.\nAssociation for Computational Linguistics.\nMarco Kuhlmann and Joakim Nivre. 2006. Mildly\nnon-projective dependency structures. In Proceed-\nings of the COLING/ACL 2006 Main Conference\nPoster Sessions, pages 507–514, Sydney, Australia,\nJuly. Association for Computational Linguistics.\nUri Lerner and Slav Petrov. 2013. Source-side classi-\nﬁer preordering for machine translation. In Proceed-\nings of the Empirical Methods in Natural Language\nProcessing.\nTahira Naseem, Regina Barzilay, and Amir Globerson.\n2012. Selective sharing for multilingual dependency\n2407\nparsing. In Proceedings of the 50th Annual Meet-\ning of the Association for Computational Linguis-\ntics: Long Papers-Volume 1, pages 629–637. Asso-\nciation for Computational Linguistics.\nJan Niehues, Teresa Herrmann, Stephan V ogel, and\nAlex Waibel. 2011. Wider context by using bilin-\ngual language models in machine translation. In\nProceedings of the Sixth Workshop on Statistical\nMachine Translation, pages 198–206. Association\nfor Computational Linguistics.\nEric W. Noreen. 1989. Computer Intensive Meth-\nods for Testing Hypotheses. An Introduction. Wiley-\nInterscience.\nFranz Josef Och and Hermann Ney. 2003. A sys-\ntematic comparison of various statistical alignment\nmodels. Computational Linguistics, 29(1):19–51.\nTimothy Osborne. 2008. Major constituents and two\ndependency grammar constraints on sharing in coor-\ndination. Linguistics, 46(6):1109–1165.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic eval-\nuation of machine translation. In Proceedings of the\n40th annual meeting of the Association for Compu-\ntational Linguistics, pages 311–318. Association for\nComputational Linguistics.\nMatt Post and Daniel Gildea. 2008. Parsers as lan-\nguage models for statistical machine translation. In\nProceedings of the Eighth Conference of the Asso-\nciation for Machine Translation in the Americas,\npages 172–181. Citeseer.\nChris Quirk and Arul Menezes. 2006. Dependency\ntreelet translation: The convergence of statistical\nand example-based machine translation? Machine\nTranslation, 20:43–65, March.\nStefan Riezler and John T. Maxwell. 2005. On some\npitfalls in automatic evaluation and signiﬁcance test-\ning for MT. In Proceedings of the ACL Workshop on\nIntrinsic and Extrinsic Evaluation Measures for Ma-\nchine Translation and/or Summarization.\nRico Sennrich. 2015. Modelling and optimizing on\nsyntactic n-grams for statistical machine translation.\nTransactions of the Association for Computational\nLinguistics, 3:169–182.\nLibin Shen, Jinxi Xu, and Ralph M. Weischedel. 2008.\nA new string-to-dependency machine translation al-\ngorithm with a target dependency language model.\nIn Proceedings of the Association for Computational\nLinguistics, pages 577–585.\nAndreas Stolcke, Jing Zheng, Wen Wang, and Victor\nAbrash. 2011. Srilm at sixteen: Update and out-\nlook. In Proceedings of IEEE Automatic Speech\nRecognition and Understanding Workshop, page 5.\nKristina Toutanova, Dan Klein, Christopher D. Man-\nning, and Yoram Singer. 2003. Feature-rich part-of-\nspeech tagging with a cyclic dependency network.\nIn Proceedings of the 2003 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics on Human Language Technology,\npages 173–180. Association for Computational Lin-\nguistics.\nDekai Wu. 1997. Stochastic inversion transduction\ngrammars and bilingual parsing of parallel corpora.\nComputational linguistics, 23(3):377–403.\nBing Xiang, Niyu Ge, and Abraham Ittycheriah. 2011.\nImproving reordering for statistical machine trans-\nlation with smoothed priors and syntactic features.\nIn Proceedings of the Fifth Workshop on Syntax,\nSemantics and Structure in Statistical Translation,\npages 61–69. Association for Computational Lin-\nguistics.\nKenji Yamada and Kevin Knight. 2001. A syntax-\nbased statistical translation model. In Proceedings\nof the 39th Annual Meeting on Association for Com-\nputational Linguistics, pages 523–530. Association\nfor Computational Linguistics.\nHeng Yu, Haitao Mi, Liang Huang, and Qun Liu. 2014.\nA structured language model for incremental tree-\nto-string translation. Proceedings of COLING 2014,\nthe 25th International Conference on Computational\nLinguistics, pages 1133–1143.\nAndreas Zollmann and Ashish Venugopal. 2006. Syn-\ntax augmented machine translation via chart parsing.\nIn Proceedings of the Workshop on Statistical Ma-\nchine Translation, pages 138–141. Association for\nComputational Linguistics.\n2408",
  "topic": "Machine translation",
  "concepts": [
    {
      "name": "Machine translation",
      "score": 0.909978985786438
    },
    {
      "name": "Computer science",
      "score": 0.8734754323959351
    },
    {
      "name": "Phrase",
      "score": 0.7088402509689331
    },
    {
      "name": "Natural language processing",
      "score": 0.6972804665565491
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6732535362243652
    },
    {
      "name": "Translation (biology)",
      "score": 0.6232317686080933
    },
    {
      "name": "Example-based machine translation",
      "score": 0.5987899899482727
    },
    {
      "name": "Language model",
      "score": 0.5865688920021057
    },
    {
      "name": "Machine translation software usability",
      "score": 0.5560210347175598
    },
    {
      "name": "Baseline (sea)",
      "score": 0.5034372210502625
    },
    {
      "name": "Bilingual dictionary",
      "score": 0.4634430706501007
    },
    {
      "name": "Evaluation of machine translation",
      "score": 0.44878602027893066
    },
    {
      "name": "Statistical model",
      "score": 0.4478703737258911
    },
    {
      "name": "Messenger RNA",
      "score": 0.0
    },
    {
      "name": "Oceanography",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Geology",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    }
  ]
}