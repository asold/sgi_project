{
  "title": "Concrete flow transformer: predicting fresh concrete properties from concrete flow using vision transformers",
  "url": "https://openalex.org/W4383681986",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2021548294",
      "name": "Max Coenen",
      "affiliations": [
        "Leibniz University Hannover"
      ]
    },
    {
      "id": "https://openalex.org/A2040204727",
      "name": "Christian Vogel",
      "affiliations": [
        "Leibniz University Hannover"
      ]
    },
    {
      "id": "https://openalex.org/A2605541877",
      "name": "Tobias Schack",
      "affiliations": [
        "Leibniz University Hannover"
      ]
    },
    {
      "id": "https://openalex.org/A2082993948",
      "name": "Michael Haist",
      "affiliations": [
        "Leibniz University Hannover"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2607014458",
    "https://openalex.org/W4223468276",
    "https://openalex.org/W2901536639",
    "https://openalex.org/W1947481528",
    "https://openalex.org/W3094502228",
    "https://openalex.org/W1755205674",
    "https://openalex.org/W2342662179",
    "https://openalex.org/W6730267373",
    "https://openalex.org/W3042301565",
    "https://openalex.org/W6666761814",
    "https://openalex.org/W1983364832",
    "https://openalex.org/W6631190155",
    "https://openalex.org/W4281632024",
    "https://openalex.org/W2583815496",
    "https://openalex.org/W2156303437",
    "https://openalex.org/W1522734439",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W3006087551",
    "https://openalex.org/W2613984758",
    "https://openalex.org/W6797876215",
    "https://openalex.org/W6744066916",
    "https://openalex.org/W2069413003",
    "https://openalex.org/W3075642210",
    "https://openalex.org/W6750401302",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W4214589115",
    "https://openalex.org/W2963315828",
    "https://openalex.org/W2508429489",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4283793620",
    "https://openalex.org/W2963351113"
  ],
  "abstract": "This paper presents a novel approach for an automatic and holistic quality assessment of fresh concrete on the construction site. Based on a low-cost and easy-to-mount camera setup, delivering image sequences showing the concrete flow during the discharge process of a mixing truck, we propose the Concrete Flow Transformer, a deep learning approach based on Vision Transformers, for the online prediction of fresh concrete properties. The performance of the proposed approach is evaluated based on a challenging real-world data set, demonstrating highly convincing results for the prediction of both, the consistency and rheological parameters of the fresh concrete.",
  "full_text": "2023 European Conference on Computing in Construction\n40th International CIB W78 Conference\nHeraklion, Crete, Greece\nJuly 10-12, 2023\nCONCRETE FLOW TRANSFORMER: PREDICTING FRESH CONCRETE \nPROPERTIES FROM CONCRETE FLOW USING VISION TRANSFORMERS\nMax Coenen, Christian Vogel, Tobias Schack, Michael Haist\nInstitute of Building Materials Science, Leibniz University Hannover, Germany\nAbstract\nT o improve sustainability, concretes are increasingly pro-\nduced using recipes containing up to a dozen diﬀerent raw\nmaterials. The increasing complexity of the composition\nleads to an increased sensitivity and decreased robustness\nof the concrete, making a reliable quality control of the\nconcrete highly important. Despite that, current quality\ncontrol is mainly conducted based on analogous and em-\npirical tests. This paper presents a novel approach for\nan automatic quality assessment of fresh concrete on the\nconstruction site. Based on a camera sensor setup, de-\nlivering image sequences showing the concrete ﬂow dur-\ning the discharge process of a mixing truck, we propose\nthe Concrete Flow Transformer, a deep learning approach\nbased on Vision Transformers, for the prediction of fresh\nconcrete properties. The performance of the proposed ap-\nproach is evaluated on a challenging real-world data set,\ndemonstrating highly convincing results for the prediction\nof both, the consistency and rheological parameters of the\nfresh concrete.\nIntroduction\nFresh concrete can be characterised by its workability, a\nterm which describes the concrete’s consistency and its\nrheological properties. The workability of concrete is a\nhighly important factor for both, the classical casting of\nconcrete at the construction site as well as for 3D printing.\nIn this context, fresh concrete inheriting unsuitable\nproperties can lead to serious quality and safety relevant\nproblems, like segregation, ﬂow blockage, or substantial\nvoids inside the concrete structure; eﬀects demanding for\na proper quality control of the fresh concrete before its\nincorporation. Moreover, in order to meet sustainability\ngoals, concretes are nowadays increasingly produced\nusing recipes containing up to a dozen diﬀerent raw ma-\nterial components, including e.g. CO 2 reduced cements\nor recycled aggregates. These increasingly complex\nmixtures, however, lead to a pronounced sensitivity of the\nconcrete to ﬂuctuations in the raw material properties,\nand, therefore, to a decreased robustness of the concrete,\nrendering a thorough quality control even more important\ntoday and in the near future.\nIn current practice, quality control is typically conducted\non site based on normative regulated test methods\n(e.g. ﬂow table test and slump test), which, however,\nrely on very simple empirical procedures, delivering\nonly provisional information on the concrete’s con-\nsistency . Rheometer tests on the other hand allow\ndeeper insights into the rheological properties of con-\ncrete, but are typically expensive, time consuming,\nRheology\nConsistency\nImage Sequence\n Vision Transformer\nConcrete \nFlow \nTransformer\nRheology\nConsistency\nPrediction\nFigure 1: High level overview on our approach. Image\nsequences are recorded at the concrete discharge channel of a\nmixing truck. The proposed Concrete Flow T ransformer is used\nto predict the consistency and the rheological properties of the\nfresh concrete.\nand hardly applicable to standard concrete, rendering\nthem unsuitable for an application in construction practice.\nIn order to overcome current limitations and to improve\nconcrete quality control and safety assurance on construc-\ntion sites, we present a novel test procedure for the au-\ntomatic on-site characterisation of fresh concrete during\nthe discharge process of a mixing vehicle (cf. Fig. 1). As\ncontributions of this paper, we propose a computer vision\nbased strategy for a digital characterisation of fresh con-\ncrete based on image sequences showing the concrete ﬂow\nat the mixing trucks’s discharge. Given the recorded video\nframes, we propose Concrete Flow T ransformer , a deep\nlearning approach based on Vision Transformers (ViT), for\nthe prediction of concrete properties like consistency and\nrheological parameters. In this context, we present ﬂow\ntokenisation, a strategy for the generation of patch embed-\ndings serving as input to the ViT , using priorly computed\ndense optical ﬂow information. Finally, we evaluate the\nperformance of our approach on a challenging real-world\ndata set, demonstrating highly promising results.\nW e hope with this paper to initiate and encourage further\nfuture research, bridging the scientiﬁc disciplines of civil\nengineering, building materials, computer vision, and data\nsciences in order to bring forth developments of novel,\ndata-driven methods for an automatic, digital, and im-\nproved quality assurance in construction and civil engi-\nneering.\nState of the art\nDespite the increasing developments in digitisation\nand automation of processes in other manufacturing\nindustries, the quality control of the concrete production\nand construction industry is still based on conventional,\nnon-digital, batch-based and primarily manual methods.\nAlthough of essential importance, the testing of concrete\nproperties on the construction site before casting is based\non very simple and empirical test methods as e.g. the\nﬂow table test (EN 12350-5, 2019) for deriving the\nconcrete’s workability . In this test, the fresh concrete is\nspread on a ﬂow table and the diameter\nδ [mm] of the\nresulting slump cake is used to derive an assessment of\nthe concrete’s consistency class C. In addition to slump\ntesting, rheometer test methods have gained attraction in\ntesting of fresh concrete (Haist et al., 2020) by determining\nthe parameters of a Bingham model (Y ahia et al., 2016)\nwhich is used to describe the rheological properties\nof fresh concrete by the plastic viscosity\nµ [Pa·s] and\nthe yield stress τ 0 [Pa]. However, concrete rheometer\ntest are exclusively batch-based, laborious and the data\ninterpretation is highly challenging. As a consequence,\nincreasing interest has emerged in developing and\nproviding digital and automatic methods for quality con-\ntrol in the concrete production industry (Haist et al., 2022).\nA ﬁrst approach for fresh concrete monitoring has been\nproposed in (Y ang et al., 2020), where the concrete mix\nproportion is determined from single images of fresh\nconcrete using a convolutional neural network (CNN).\nHowever, in practice, not only the mix proportion but\nrather an indication for the concrete’s workability is of\nmain interest. In (Coenen et al., 2022), an approach\nfor the panoptic segmentation of fresh concrete was\npresented, which allows to derive conclusions about the\nsedimentation stability of the concrete, but does not give\nindications about the concrete’s workability . Ponick et al.\n(2022) proposed an approach for predicting the rheology\nof concrete from stereo-images and 3D reconstructions of\nthe concrete’s surface during the mixing procedure. How-\never, in their method, the temporal information, namely\nthe concrete ﬂow, is not considered. Y et, we believe,\nthat the ﬂow behaviour of fresh concrete carries valuable\ninformation on the concrete’s characteristics. In (Ding and\nAn, 2018), an approach for determining the workability\nfrom image sequences acquired during the mixing process\nusing a LSTM deep learning network has been proposed.\nWhile promising results were obtained, processing was\ndone on rather low resolution grey scale images only\nand the approach relied on 2D transformations, ignoring\nthe clearly visible eﬀects perspective distortions. In this\npaper, we follow a similar idea, namely to determine the\nfresh concrete’s characteristics from image sequences\nobserving the concrete ﬂow in an open-channel geometry .\nFrom a methodological point of view, the problem tack-\nled in this paper is closely related to deep learning based\nvideo interpretation and classiﬁcation. Compared to single\nimage interpretation, image sequences contain additional\ntemporal information, like e.g. object motion, which is\nexpected to carry valuable and relevant cues for solving\nthe respective problem. Many approaches apply a CNN\nto each individual video frame in order to leverage the\nstrength of single-image CNNs and aggregate the extracted\ninformation across time in order to capture temporal re-\nlations. Often, a 2D-CNN backbone is applied to extract\nframe-wise feature representations and temporal relation-\nships are modelled e.g. as conditional random ﬁelds (CRF)\n(Sigurdsson et al., 2017), via recurrent modules like long-\nshort term memory cells (Hochreiter and Schmidhuber,\n1997; Donahue et al., 2015), or via the self-attention mech-\nanism within transformer-based architectures (Zhou et al.,\n2018; W ang et al., 2021).\nBy expanding the 2D ﬁlters of a CNN to three dimensions,\nan approach called 3D CNN (Ji et al., 2012), and apply-\ning the 3D ﬁlters along the temporal domain of an image\nsequence in addition to the spatial image domain, single-\nframe CNNs can be generalised to an application to video\ndata. In contrast to 2D CNNs, 3D ﬁlters conceptually allow\nCNNs to model motion because they act as local spatio-\ntemporal ﬁlters, thus generating spatio-temporal feature\nmaps. In this way, 3D CNNs are often applied to sequen-\ntial image data in the literature in order to solve video\ninterpretation problems, cf. for instance (Ji et al., 2012;\nTran et al., 2015; Camgoz et al., 2016).\nAnother strategy that can be found in the literature for\nvideo interpretation is to make use of two-stream convolu-\ntional neural networks (Simonyan and Zisserman, 2014).\nIn this case, the network architecture is based on two sep-\narate recognition streams, a spatial and a temporal stream,\nwhich are then combined by fusion at a later stage of\nthe network. While the spatial stream performs video in-\nterpretation from still video frames, the temporal stream\nuses pre-computed dense optical ﬂow maps as input and\nis trained to generate feature embeddings from the explicit\nmotion information (W ang et al., 2018; Feichtenhofer et al.,\n2016). In this work, we also make use of explicit optical\nﬂow computations, i.e. of explicit per-pixel motion esti-\nmates. In addition to the valuable information the optical\nﬂow carries, it is also invariant to e.g. texture, colour, and\nillumination, making it less prone to overﬁtting eﬀects.\nMethodology\nThe method proposed in this paper is built on the premise\nthat fresh concretes with diﬀerent rheological properties\nexhibit a diﬀerent and distinguishable ﬂow behaviour. This\nhypothesis is founded by ﬁnite-element formulations of\nnon-Newtonian ﬂuid ﬂow, on the basis of which the ﬂow\nbehaviour of Bingham ﬂuid’s (such as concrete) can be de-\nscribed as a function of its rheological parameters, namely\nthe plastic viscosity\nµ and yield stress τ 0 (Whipple, 1997).\nThis paper targets the inverse problem, namely the objec-\ntive of predicting the rheological properties (\nτ 0 and µ ) and\nthe consistency of fresh concrete from observations of its\nﬂow behaviour. More speciﬁcally, we make use of image\nsequences showing the concrete ﬂow during the discharge\nprocess of a mixing vehicle as input data to our approach.\nThe image sequences are acquired using a rigid camera\nsetup installed at the outlet of the mixing vehicle, where\nwe assume the images to be approximately acquired in\nnadir view to the discharge channel, and the image coordi-\nnate axes (x and y) to be approximately axis-parallel to the\nlongitudinal and transversal axes of the channel, resulting\nin the property that the major constituent of the ﬂow move-\nment is observed along one of the respective axes (here:\nthe x-axis).\nFormal problem deﬁnition\nGiven an image sequence I(t) containing the images I(ti )\nacquired according to the setup described above and show-\ning the discharge procedure of fresh concrete at discrete\ntime steps ti ∈ t with t = [t0 ,tn ], the goal is to automatically\nderive the target parameters describing the rheology and\nconsistency of the fresh concrete. For notation, we as-\nsociate each concrete with its state vector s = (\nµ ,τ 0 ,δ ,C)\ncomprising the rheology (Bingham yield stress τ 0 [Pa] and\nplastic viscosity µ [Pa·s]) and the consistency (slump ﬂow\ndiameter δ [mm] and consistency class C). In a ﬁrst step,\nwe compute the dense optical ﬂow O(ti ) for each image\nframe ti , describing the pixelwise movement between the\nrespective image and its subsequent frame. The dense\nﬂow maps are used to generate a sequence of ﬂow tokens\nz(t) which serves as input to a multi-task Vision Trans-\nformer (ViT), that maps the observed concrete ﬂow of the\ntime span t, represented by the ﬂow token sequence, to the\ncorresponding fresh concrete properties s. An overview\non the procedure is shown in Fig. 3 and the approach is\ndescribed in more detail in the following sections.\nDense optical ﬂow\nDense optical ﬂow (cf. Fig. 2) denotes the problem of per-\npixel motion estimation between two consecutive frames\nti and ti+1 of an image sequence, and, thus, implies the\ncomputation of a translation vector ∆ = (∆ x,∆ y) for each\npixel, describing the pixel’s displacement between the two\nframes in the x and y coordinate direction, respectively .\n1.0\n0.0\n-1.0\nFigure 2: Visualisation of an example of the dense optical ﬂow\ncomputation. Left: Original image. Centre: The dense\ndisplacement ﬁeld in the x-coordinate direction (colour coding\ncorresponds to the normalised magnitude of the pixelwise\ndisplacement ∆ x ). Right: The RGB image overlayed with the\ndense displacement ﬁeld.\nIn this paper, we make use of the approach by Farnebäck\n(2003) in order to derive the two-dimensional dense opti-\ncal ﬂow ﬁeld O(ti ) = (Ox (ti ), Oy (ti )) for each image I(ti ),\nwhereas Ox (ti ) and Oy (ti ) contain the displacement of each\npixel in the x and y coordinate direction, respectively . Re-\ngarding the application addressed in this paper, where the\nopen-channel concrete ﬂow is observed, the dense optical\nﬂow map implicitly encodes the velocity\nϑ of the con-\ncrete ﬂow at each pixel position in [px/(ti+1 − ti )], which\ncorresponds to the magnitude of the translation vector ∆ .\nFurthermore, the ﬂow direction of the concrete, namely\nthe angle\nα of the translation vector ∆ , is also implicitly\ncontained. Fig. 2 shows an example of the dense optical\nﬂow map Ox for the concrete ﬂow of a speciﬁc epoch ti .\nRevisiting Vision Transformers (ViT)\nThe original Vision Transformer (ViT) (Dosovitskiy et al.,\n2021) takes a single image as input and extracts n non-\noverlapping image patches xi ∈ Rh× w which are trans-\nformed into 1D tokens zi ∈ Rd of length d using a linear\nprojection E. The sequence of tokens z0 ∈ R(n+1)× d with\nz0 = [zcls,Ez1 ,Ez2 ,...,Ezn ] +p (1)\nthen serves as input to a transformer encoder architec-\nture (V aswani et al., 2017). As is shown in Eq. 1, a\nlearnable classiﬁcation token zcls is prepended to the se-\nquence, whose representation at the ﬁnal layer of the en-\ncoder is used as input embedding for the output layer.\nFurthermore, a learnable position embedding p ∈ Rn× d\nis added to the tokens (cf. Eq. 1) in order to retain po-\nsitional information throughout the permutation invariant\nself-attention operations of the encoder. The tokens are\npassed through the transformer encoder which consists of\na stack of l = 1...L residual layers, each comprising Multi-\nHead Self-Attention (MSA) (V aswani et al., 2017), layer\nnormalisation (LN), and Multi-Layer Perceptron (MLP)\nblocks, producing the intermediate outputs zl with\nyl = MSA(LN(zl− 1 )) +zl− 1 (2)\nzl = MLP(LN(yl )) +yl . (3)\nHere, The MLP blocks consist of two linear projections\nseparated by a GELU non-linearity . MSA is based on\nthe self-attention (SA) mechanism, whose goal is to cap-\nture the interaction and dependencies amongst all entities\n(tokens). T o this end, three learnable weight matrices\nW Q ∈ Rd× dq , W K ∈ Rd× dk , and W V ∈ Rd× dv are deﬁned\n(where dq = dv ) in order to compute Queries Q = zW Q ,\nKeys K = zW K , and V alues V = zW V . The self-attention\nlayer output results to\nSA = softmax\n(\nQ ·KT\n√dq\n)\n·V. (4)\nMSA extends the self-attention mechanism by concatenat-\ning the outputs of h separate SA heads and projecting them\nto the ﬁnal embedding using another learnable weight ma-\ntrix W M , such that\nMSA = Concat(SA1 ,SA2 ,...,SAh ) ·W M . (5)\nFinally, a MLP head is used on top of the transformer\nencoder to produce the prediction output based on the\nﬁnal encoded class token embedding zL\ncls.\nConcrete Flow Transformer\nIn this section, we describe the Concrete Flow T rans-\nformer, a ViT -based approach for the prediction of fresh\nconcrete properties from concrete ﬂow observations. An\noverview on the workﬂow of the proposed approach is\nshown in Fig. 3. In contrast to the description in the\nTransformer Encoder\nMLP\nLinear Projection of Flow Tokens\n*0 1 2 3 4 n\nMLP\nPatch + Position\nEmbedding\n* Extra learnable\n[class] embedding\nImage\nSequence\nOptical\nFlow\nFlow\nTokens\nRheologyConsistency\nClassification\nhead\nRegression\nhead\nFigure 3: Overview on the procedure of the proposed Concrete\nFlow T ransformer . Given an image sequence, the dense optical\nﬂow is computed for each frame. F or each ﬂow map, ﬂow tokens\nare extracted, linearly projected, enriched by position and class\nembeddings, and fed to a multi-task transformer encoder . T wo\nnetwork heads predict the target parameters describing the\nconsistency and rheology of the fresh concrete.\nsection above, the approach presented in this paper does\nnot operate on a single image, but on a sequence of images\nshowing the open channel ﬂow of fresh concrete, instead.\nHowever, the transformer encoder (V aswani et al., 2017),\nwhich forms the basis of ViT (Dosovitskiy et al., 2021),\nis a ﬂexible architecture that can operate on any sequence\nof input tokens z ∈ R(n+1)× d . In this paper, we therefore\npropose ﬂow tokenisation , a strategy for tokenising the\ninput image sequences containing the ﬂow information of\nthe concrete.\nFlow tokenisation: As input, we make use of the dense\noptical ﬂow maps O(t) computed from the image sequence\nI(t) for each epoch ti = t0 ...tn , carrying the motion infor-\nmation representing the concrete ﬂow behaviour over time.\nThe speciﬁc setting treated in this work in form of the im-\nage sequence acquired from the open channel concrete\nﬂow leads to the occurrence of large amounts of redun-\ndant information in the data. This is caused by the fact,\nthat the concrete’s movement mainly takes place along one\ndirection with a motion behaviour (velocity) that is approx-\nimately constant along the direction of movement for an\nindividual time step ti (cf. Fig. 2). W e therefore deﬁne\na location xS on the x-coordinate axis of the optical ﬂow\nmap and extract a vertical proﬁle slice zx (ti ) ∈ Ry× 1 and\nzy (ti ) ∈ Ry× 1 with a width of 1 [px] at this location from\neach of both channels of the dense ﬂow ﬁeld Ox (ti ) and\nOy (ti ). W e linearly project the two-channel proﬁle slices\nin order to receive a ﬂow token zi ∈ Rd with d = 2y for\neach epoch. The tokens of all epochs ti ∈ t with i = 0...n\nare arranged to the sequence z(t) ∈ R(n+1)× d according to\nEq. 1 and serve as input to the transformer encoder. A\nschematic overview of this procedure is shown in Fig. 3.\nW e argue that by slicing the ﬂow ﬁelds in order to gener-\nate the ﬂow tokens, we discard the redundant information\ncontained in the ﬂow data while conserving the relevant\nmotion information. As a result from this, the required\ncomputational complexity is reduced while, at the same\ntime, the learning complexity of the transformer built on\ntop of the ﬂow tokens is simpliﬁed, since in this way, learn-\ning to discern relevant data from redundant information\nbecomes less demanding. Particularly, the proposed way\nof ﬂow tokenisation preserves the following features. Each\ntoken in z(t) carries the information of the concrete’s ﬂow\nvelocity and ﬂow direction at a speciﬁc point in time. As\nestablished in (Whipple, 1997), the velocity is a function\nof a material’s rheological properties and, consequently,\nconstitutes one of the most signiﬁcant cues for the charac-\nterisation of the fresh concrete.\nFurthermore, the token sequence contains the ﬂow data\nover the entire time span t, consequently giving the trans-\nformer access to information on changes in the velocity\nproﬁles over time. These changes correspond to acceler-\nation and deceleration behaviour of the material and can\nbe caused by varying transportation rates of the mixing\nvehicle. W e argue, that velocity changes in the concrete\nﬂow as reaction to variations in the transportation rates\ncarry additional valuable information encoding rheologi-\ncal properties of the material.\nAt last, each token preserves the information of the\nﬂow behaviour along the transversal (y) direction of the\nopen channel. Consequently, each token encodes the\nspatial motion information such as e.g. the current width\nof the concrete ﬂow stream, which implicitly contains\ninformation about the volumetric transportation rate of\nthe concrete.\nPrediction: As outlined before, we aim at learning a ViT\nwhich predicts the fresh concrete properties represented\nby the state vector s from open channel concrete ﬂow ob-\nservations over a time interval t represented by the ﬂow\ntokens z(t). T owards this goal, we employ a transformer\nencoder with a number of L transformer blocks (cf. de-\nscription above), which takes the sequence of n ﬂow tokens\nas input and produces a sequence of feature embeddings\nzL = [zL\ncls, zL\n1 , zL\n2 , ...,zL\nn ] as output of the ﬁnal layer ac-\ncording to Eq. 3. As is depicted in Fig. 3, we employ two\nMLP heads, a regression head and a classiﬁcation head ,\non top of the transformer encoder which predict the target\nparameters from the class token embedding zL\ncls .\nThe regression head is used to predict a number of nReg\nreal-valued parameters. In this work, nReg = 3, where\neach parameter is related to the concrete’s rheology and\nconsistency, namely the slump ﬂow diameter\nδ , the plastic\nviscosity µ , and the yield stress τ 0 . In this paper, we\nconsider these parameters to be normalised in the range\n[0; 1] using the minimum and maximum valid values. In\nthat case, we make use of an MLP head with three output\nvariables, one for each parameter, and by using the sigmoid\nfunction as activation.\nThe classiﬁcation head\ndirectly delivers a prediction of\nthe concrete’s consistency class C. T o this end, the ﬁnal\noutput is produced by an MLP using a softmax activation\nfunction. More speciﬁcally, the classiﬁcation head\nproduces nClass output variables p with ∑ N\nj=1 p j = 1 where\neach variable p j represents the predicted probability for\neach respective consistency class C j . The ﬁnal class being\nconsidered as the predicted class for the input is deﬁned\nbased on the maximum a posteriori criteria, i.e. is chosen\naccording to the class receiving the maximum probability\nby the ViT .\nTraining: Training in this work is performed in a super-\nvised manner. Therefore, the training procedure requires\ntraining samples in the form of the ﬂow token sequences in-\ncluding corresponding reference values for the concrete’s\nproperties. Starting from a random initialisation of the ViT\nparameters, training is done by minimising a loss func-\ntion L . The optimisation is performed iteratively using\nstochastic mini-batch gradient descent (SGD) (Goodfel-\nlow et al., 2016), where in this work the Adam optimiser\n(Kingma and Ba, 2015) is used for weight optimisation.\nThe loss function used in this paper is composed of the\nregression loss LR computed for the output of the regres-\nsion head and the classiﬁcation loss LC computed for the\noutput of the classiﬁcation head, such that L = LR +LC .\nBoth losses quantify the diﬀerence between the concrete\nproperties predicted by the network and the reference prop-\nerties. In case of the regression head, the mean squared\nerror (MSE) is used to calculate the loss while the cate-\ngorical cross-entropy (CE) is used as loss function for the\nclassiﬁcation head.\nExperimental setup\nT est data: The empirical evaluation of the proposed\nmethod is conducted on a self-acquired data set of open-\nchannel concrete ﬂow recorded during the discharge pro-\ncess of a mixing vehicle. For data acquisition a setup as\nshown in Fig. 4, consisting of a semi-circular open chan-\nnel and a camera rig in approximate nadir view, was used.\nImage acquisition was conducted using a frame rate of\n60 [fps]. For the experiments in this paper, we down-scaled\nthe images to a resolution of 380 × 675 [px], corresponding\nto an image scale of approximately 1 [px/mm]. In total, the\nacquired data set consists of recordings of the discharge of\na variety of 18 diﬀerent concretes with strongly varying\ncompositions and properties.\n20°\nFigure 4: The proposed acquisition setup for the open-channel\nconcrete ﬂow at the discharge of a mixing vehicle.\nFor this paper, we created sequence snippets, each of\nwhich has a length of 60 [s] ˆ=3600 frames, extracted\nfrom the original sequence of the 18 concretes between\npoints in time where a representative concrete ﬂow\nwas present and observed during the discharge. In\norder to obtain groundtruth values for the consistency\n(slump ﬂow\nδ and consistency class C) as well as for\nthe rheological parameters (plastic viscosity µ and yield\nstress τ 0 ), reference measurements were conducted based\non samples taken from each of the 18 concretes. In\nthis context, a portable rheometer for fresh concrete, an\neBT - V rheometer (Schleibinger), was used to generate\nrotational-controlled rheological measurements from\nwhich the rheological parameters are derived using the\nBingham model according to (Haist et al., 2020). In order\nto obtain reference values for the consistency, the slump\nﬂow was determined according to EN 206-1 (2001)/DIN\n1045-2 (2008).\nTraining: For the experiments in this work, we make use\nof the ViT -Base architecture as deﬁned in (Dosovitskiy\net al., 2021) as encoder backbone, consisting of L = 12\nlayers and h = 12 MSA heads. Data-wise, we deﬁned\nboth, a spatially and temporally disjunct separation of\ntrain, test, and validation splits from the given sequence\nsnippets. For a spatial separation of the data, we deﬁned\nﬁve equidistant slice locations xS,1 to xS,5 over the x-axis\nrange of the images, from which the ﬂow tokens are\nextracted. Three of the ﬁve splits are used for training and\none is used for validation and testing, respectively . For\na temporal separation, we divided the sequence snippets\ninto four equally sized parts, two of them are used for\ntraining, and two for validation and testing. Provided\nthe data splits as just described, training is done based\non a randomly selected subset of ﬂow tokens extracted\nfrom the data. In this paper, we choose n = 256 for\nthe number of tokens in each sequence presented to the\ntransformer, meaning that only the ﬂow information of\n256/60 ≈ 4[sec] (supposing a frame rate of 60 fps) are fed\nas training information to the network for each sample.\nTraining is done using the Adam optimiser (Kingma and\nBa, 2015), a mini-batch size of 32 and an initial learning\nrate if 10− 4 . T o improve training, the learning rate is\ndecreased by a factor of 10− 1 after 50 epochs with no\nimprovement in the training loss.\nEvaluation strategy: For the empirical evaluation of the\nproposed approach, we apply a sliding window strategy\nusing the same number of ﬂow tokens as used for train-\ning. More speciﬁcally, for each test split of the diﬀerent\nconcrete snippets of length t, we extract a token sequence\nof size n = 256 covering the epochs ti to ti+256 , and in-\ncrementally increase i by 1. Each token sequence is pro-\ncessed individually by the ViT , resulting in a number of\nt − 256 predictions for each of the concrete’s state param-\neters s = (\nµ ,τ 0 ,δ ,C). In order to assess the performance\nof the classiﬁcation head, namely the prediction of the\nconsistency class C, we determine the confusion matrix of\nthe predictions. Furthermore, we compute values for the\noverall accuracy (OA) of the predictions as well as class-\nwise values for recall, precision, and F1-score. For the\nevaluation of the regression branch, i.e. the predictions for\nthe slump ﬂow\nδ as well as for the rheological parameters\nτ 0 and µ , the mean absolute error (MAE) and root mean\nsquared error (RMSE) of the predictions are reported. In\naddition to the mean errors, we also compute the standard\ndeviation of the absolute errors\nσ AE to achieve further\ninsights into the error distribution of the predictions.\nEvaluation\nThis chapter provides the quantitative evaluation of the\nproposed Concrete Flow Transformer for the determina-\ntion of fresh concrete properties based on open-channel\nﬂow observations. W e report the results obtained by the\nclassiﬁcation head and the regression head separately .\nClassiﬁcation head\nFig. 5 shows the confusion matrix containing the results\nof the classiﬁcation head predicting the consistency class\nof the concrete from the ﬂow observations.\nAs is visible from the matrix, the classiﬁcation leads to\nan overall accuracy (OA) of 77.4%, i.e. that many of the\nsliding window token sequences are associated the correct\nclass by the Concrete Flow Transformer. The confusions\nshow a clear pattern in the distribution of erroneous clas-\nsiﬁcations, namely that the vast majority of errors appear\nnext to the main diagonal, i.e. at neighbouring classes. A\npotential explanation for this observation is the fact that the\nconsistency classes are obtained by a discretisation of the\nslump ﬂow into individual consistency ranges, introducing\nclass boundaries to the parameter range of the continuous\nvariable\nδ . As several of concretes consistency classes lie\nvery close to the class boundaries, potentially leading to\nan ambiguous setting of hard-to-distinguish concrete sam-\nples, partly causing the confusions that are observable in\nFigure 5: Confusion matrix for the classiﬁcation head including\nthe results for recall, precision, F1-score and overall accuracy.\nThe values are to be read as percentage of entities belonging to\nreference class (rows) and being classiﬁed as the predicted class\n(columns). The colour coding denotes low values (light green)\nand high values (dark green). Empty entries correspond to\nvalues of 0.0%.\nFig. 5. While the classwise F1-scores range from 68.2%\nto 88.3% for four of the ﬁve classes, the class C0 only\nachieves a F1-score of 54.8%. A reason for this can be the\nunder-representation of this class in the data set leading to\nclass-imbalance eﬀects for the classiﬁcation problem.\nRegression head\nThe regression head predicts the values for slump ﬂow\nδ , the yield stress τ 0 , as well as the viscosity µ . The\nquantitative results of the regression head predictions are\nshown in T ab. 1 The table contains the mean absolute error\n(MAE) of the target parameters, the standard deviation of\nthe mean error\nσ AE and the RMSE.\nT able 1: Quantitative results obtained by the regression head.\nThe MAE, the standard deviations of the absolute errors, as well\nas the RMSE are shown for the individual target parameters.\nParameter MAE σ AE RMSE\nδ [mm] 23.3 34.5 41.6\nτ 0 [Pa] 11.9 12.9 17.5\nµ [Pa·s] 1.9 2.2 2.9\nAs is visible from the table, we achieve highly promis-\ning results with mean absolute errors of only 23.3 [mm],\n11.9 [Pa], and 1.9 [Pa ·s] for the respective target param-\neters, namely the slump ﬂow diameter, yield stress, and\nplastic viscosity . As can be deducted from the relatively\nlarge standard deviations of the MAE, the errors exhibit a\nrelatively broad distribution. In order to get deeper insights\ninto the distribution of the predictions for the individual\nconcrete samples, Fig. 6 shows the average predictions\ntogether with the corresponding standard deviation\nσ for\neach of the target parameters.\nAs is visible from the graphs of all three parameters, most\nof the mean predictions are very close to the reference di-\nagonal, indicating that the prediction performance can be\nimproved by averaging multiple predictions over time. An\nexception is the concrete sample with a plastic viscosity\nand yield stress at the maximum boundaries, and a slump\nﬂow at the minimum boundary of the value range, respec-\ntively . Here the distinctly largest diﬀerence between the\nmean prediction and the reference values and the largest\nReference\nPrediction:\n(a) Results for the slump ﬂow δ .\nReference\nPrediction:\n(b) Results for the viscosity µ .\nReference\nPrediction:\n(c) Results for the yield stress τ 0 .\nFigure 6: Average predictions and the corresponding standard\ndeviations σ of the target parameters δ , τ 0 , and µ for each\nindividual concrete sample contained in the test set.\nstandard deviation of the predictions are observable. W e\nbelieve that this behaviour is caused by what is called\nthe long-tail problem (W ang et al., 2017), which refers\nto the problem of an imbalanced statistical distribution of\nthe examples in the training data where only little data is\navailable for values in the tail of the distribution. This re-\nsults in problems of these approaches w .r.t. their ability to\ngeneralise to barely or never seen examples or situations.\nThis issue is currently being addressed by additional data\nacquisition series.\nConclusion\nW e presented the Concrete Flow T ransformer , a novel\nmethod based on Vision Transformers for an automatic\ncharacterisation of fresh concrete from image sequences\nobserving the open-channel concrete ﬂow during the dis-\ncharge process of a mixing vehicle. In this context, we\nproposed Flow tokenisation as eﬃcient representation of\npatches serving as input to a transformer architecture. W e\nshowed that this representation encodes and preserves all\ninformation relevant for the derivation of the fresh con-\ncrete properties while drastically reducing the amount of\n(redundant) data. W e demonstrated highly promising re-\nsults by applying and evaluating the proposed method to\na challenging real-world data set. In the future, we aim\nat building on research from the ﬁelds of ﬂuid mechanics\nand ﬂow modelling in order to incorporate knowledge from\nthese ﬁelds to the problem of fresh concrete characterisa-\ntion. In particular, we strive at incorporating sophisticated\nﬂow models as prior knowledge to our deep learning based\napproach, a strategy termed (physics) informed machine\nlearning (von Rueden et al., 2021). W e believe in this\nway to further improve the approach and to enhance the\nperformance of the concrete characterisation.\nAcknowledgements\nThe authors acknowledge the funding of the project\nReCyCONtrol (https://www.recycontrol.\nuni-hannover.de/en/) provided by the German\nFederal Ministry of Education and Research (BMBF) un-\nder the grant No. 033R260A and the funding of the project\nOpen Channel Flow provided by the German Research\nFoundation (DFG) under the grant No. 452024049.\nReferences\nCamgoz, N. C., Hadﬁeld, S., Koller, O., and Bowden,\nR. (2016). Using Convolutional 3D Neural Networks\nfor User-independent continuous Gesture Recognition.\nIn International Conference on Pattern Recognition\n(ICPR), pages 49–54.\nCoenen, M., Schack, T ., Beyer, D., Heipke, C., and Haist,\nM. (2022). ConsInstancy: Learning Instance Repre-\nsentations for Semi-Supervised Panoptic Segmentation\nof Concrete Aggregate Particles. Machine Vision and\nApplications, 33(57).\nDIN 1045-2 (2008). Concrete, Reinforced and Prestressed\nConcrete Structures - Part 2: Concrete - Speciﬁcation,\nProperties, Production and Conformity - Application\nRules for DIN EN 206-1.\nDing, Z. and An, X. (2018). Deep Learning Approach for\nEstimating W orkability of Self-Compacting Concrete\nfrom Mixing Image Sequences. Advances in Materials\nScience and Engineering, 2018:1–16.\nDonahue, J., Anne Hendricks, L., Guadarrama, S.,\nRohrbach, M., V enugopalan, S., Saenko, K., and Dar-\nrell, T . (2015). Long- T erm Recurrent Convolutional\nNetworks for Visual Recognition and Description. In\nIEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), pages 2625–2634.\nDosovitskiy, A., Beyer, L., Kolesnikov , A., W eissenborn,\nD., Zhai, X., Unterthiner, T ., Dehghani, M., Minderer,\nM., Heigold, G., Gelly, S., Uszkoreit, J., and Houlsby, N.\n(2021). An Image is W orth 16x16 W ords: Transform-\ners for Image Recognition at Scale. In International\nConference on Learning Representations (ICLR).\nEN 12350-5 (2019). T esting Fresh Concrete - Part 5: Flow\nT able T est. European Committee for Standardization.\nEN 206-1 (2001). Concrete - Part 1: Speciﬁcation, Perfor-\nmance, Production and Conformity .\nFarnebäck, G. (2003). T wo-Frame Motion Estimation\nbased on Polynomial Expansion. In Scandinavian Con-\nference on Image Analysis, pages 363–370.\nFeichtenhofer, C., Pinz, A., and Zisserman, A. (2016).\nConvolutional T wo-Stream Network Fusion for Video\nAction Recognition. In IEEE Conference on Computer\nVision and Pattern Recognition (CVPR), pages 1933–\n1941.\nGoodfellow, I., Bengio, Y ., and Courville, A. (2016). Deep\nLearning. MIT Press, Cambridge, Massachusetts, USA.\nHaist, M., Heipke, C., Beyer, D., Coenen, M., V ogel, C.,\nSchack, T ., Ponick, A., and Langer, A. (2022). Digitiza-\ntion of the Concrete Production Chain using Computer\nVision and Artiﬁcial Intelligence. In Proceedings of the\n6th ﬁb Congress, pages 434–443.\nHaist, M., Link, J., Nicia, D., Leinitz, S., and et al. (2020).\nInterlaboratory Study on rheological Properties of Ce-\nment Pastes and Reference Substances: Comparability\nof Measurements performed with diﬀerent Rheometers\nand Measurement Geometries. Materials and Struc-\ntures, 53(92).\nHochreiter, S. and Schmidhuber, J. (1997). Long Short-\nT erm Memory. Neural Computation, 9(8):1735–1780.\nJi, S., Xu, W ., Y ang, M., and Y u, K. (2012). 3D Convolu-\ntional Neural Networks for Human Action Recognition.\nIEEE Transactions on Pattern Analysis and Machine\nIntelligence (TP AMI), 35(1):221–231.\nKingma, D. and Ba, L. (2015). Adam: A Method for\nStochastic Optimization. In International Conference\non Learning Representations (ICLR).\nPonick, A., Langer, A., Beyer, D., Coenen, M., Haist, M.,\nand Heipke, C. (2022). Image-Based Deep Learning for\nRheology Determination of Bingham Fluids. In Interna-\ntional Archives of the Photogrammetry, Remote Sensing\nand Spatial Information Sciences XLIII-B2-2022, pages\n711–720.\nSigurdsson, G. A., Divvala, S., Farhadi, A., and Gupta,\nA. (2017). Asynchronous T emporal Fields for Action\nRecognition. In IEEE Conference on Computer Vision\nand Pattern Recognition (CVPR), pages 585–594.\nSimonyan, K. and Zisserman, A. (2014). T wo-Stream Con-\nvolutional Networks for Action Recognition in Videos.\nIn Advances in Neural Information Processing Systems\n(NIPS), pages 568–576.\nTran, D., Bourdev , L., Fergus, R., T orresani, L., and Paluri,\nM. (2015). Learning Spatiotemporal Features with 3D\nConvolutional Networks. In IEEE International Confer-\nence on Computer Vision (ICCV), pages 4489–4497.\nV aswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,\nL., Gomez, A. N., Kaiser, L., and Polosukhin, I. (2017).\nAttention is All you Need. In Advances in Neural Infor-\nmation Processing Systems (NIPS), volume 30.\nvon Rueden, L., Mayer, S., Beckh, K., Georgiev , B., Gies-\nselbach, S., Heese, R., Kirsch, B., W alczak, M., Pfrom-\nmer, J., Pick, A., Ramamurthy, R., Garcke, J., Bauck-\nhage, C., and Schuecker, J. (2021). Informed Machine\nLearning - A T axonomy and Survey of Integrating Prior\nKnowledge into Learning Systems. IEEE Transactions\non Knowledge and Data Engineering.\nW ang, L., Xiong, Y ., W ang, Z., Qiao, Y ., Lin, D., T ang, X.,\nand V an Gool, L. (2018). T emporal Segment Networks\nfor Action Recognition in Videos. IEEE Transactions\non Pattern Analysis and Machine Intelligence (TP AMI),\n41(11):2740–2755.\nW ang, X., Zhang, S., Qing, Z., Shao, Y ., Zuo, Z., Gao, C.,\nand Sang, N. (2021). OadTR: Online Action Detection\nwith Transformers. In IEEE International Conference\non Computer Vision (ICCV), pages 7565–7575.\nW ang, Y .-X., Ramanan, D., and Hebert, M. (2017). Learn-\ning to Model the T ail. In Advances in Neural Infor-\nmation Processing Systems (NIPS), volume 30, pages\n7029–7039.\nWhipple, K. X. (1997). Open-Channel Flow of Bingham\nFluids: Applications in Debris-Flow Research. The\nJournal of Geology, 105(2):243–262.\nY ahia, A., Mantellato, S., and Flatt, R. J. (2016). Con-\ncrete Rheology: A Basis for Understanding Chemical\nAdmixtures. In Science and T echnology of Concrete\nAdmixtures, pages 97–127. W oodhead Publishing.\nY ang, H., Jiao, S.-J., and Yin, F.-D. (2020). Multilabel\nImage Classiﬁcation Based Fresh Concrete Mix Propor-\ntion Monitoring Using Improved Convolutional Neural\nNetwork. Sensors, 20(16).\nZhou, L., Zhou, Y ., Corso, J. J., Socher, R., and Xiong,\nC. (2018). End-to-End Dense Video Captioning with\nMasked Transformer. In IEEE Conference on Computer\nVision and Pattern Recognition (CVPR), pages 8739–\n8748.",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.7379733324050903
    },
    {
      "name": "Computer science",
      "score": 0.538651704788208
    },
    {
      "name": "Artificial intelligence",
      "score": 0.35624587535858154
    },
    {
      "name": "Engineering",
      "score": 0.29684531688690186
    },
    {
      "name": "Voltage",
      "score": 0.18474411964416504
    },
    {
      "name": "Electrical engineering",
      "score": 0.12020227313041687
    }
  ]
}