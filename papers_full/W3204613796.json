{
  "title": "Anonymization of German financial documents using neural network-based language models with contextual word representations",
  "url": "https://openalex.org/W3204613796",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2978460324",
      "name": "David Biesner",
      "affiliations": [
        "University of Bonn",
        "Fraunhofer Institute for Intelligent Analysis and Information Systems"
      ]
    },
    {
      "id": "https://openalex.org/A2894634728",
      "name": "Rajkumar Ramamurthy",
      "affiliations": [
        "Fraunhofer Institute for Intelligent Analysis and Information Systems"
      ]
    },
    {
      "id": "https://openalex.org/A2973202078",
      "name": "Robin Stenzel",
      "affiliations": [
        "Fraunhofer Institute for Intelligent Analysis and Information Systems"
      ]
    },
    {
      "id": "https://openalex.org/A2979014553",
      "name": "Max Lubbering",
      "affiliations": [
        "Fraunhofer Institute for Intelligent Analysis and Information Systems"
      ]
    },
    {
      "id": "https://openalex.org/A2046223250",
      "name": "Lars Hillebrand",
      "affiliations": [
        "University of Bonn",
        "Fraunhofer Institute for Intelligent Analysis and Information Systems"
      ]
    },
    {
      "id": "https://openalex.org/A2224434053",
      "name": "Anna Ladi",
      "affiliations": [
        "Fraunhofer Institute for Intelligent Analysis and Information Systems"
      ]
    },
    {
      "id": "https://openalex.org/A2969907972",
      "name": "Maren Pielka",
      "affiliations": [
        "Fraunhofer Institute for Intelligent Analysis and Information Systems"
      ]
    },
    {
      "id": "https://openalex.org/A610571192",
      "name": "Rüdiger Loitz",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A830440161",
      "name": "Christian Bauckhage",
      "affiliations": [
        "Fraunhofer Institute for Intelligent Analysis and Information Systems"
      ]
    },
    {
      "id": "https://openalex.org/A2072919878",
      "name": "Rafet Sifa",
      "affiliations": [
        "Fraunhofer Institute for Intelligent Analysis and Information Systems"
      ]
    },
    {
      "id": "https://openalex.org/A2979014553",
      "name": "Max Lubbering",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2128004504",
    "https://openalex.org/W2169730138",
    "https://openalex.org/W1995228216",
    "https://openalex.org/W2158645702",
    "https://openalex.org/W2152540201",
    "https://openalex.org/W2740614682",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2963250244",
    "https://openalex.org/W2144578941",
    "https://openalex.org/W2972381987",
    "https://openalex.org/W2963626623",
    "https://openalex.org/W6603242443",
    "https://openalex.org/W6702248584",
    "https://openalex.org/W6605614091",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W3104415840",
    "https://openalex.org/W1515847863",
    "https://openalex.org/W2971039193",
    "https://openalex.org/W2973794125"
  ],
  "abstract": "Abstract The automatization and digitalization of business processes have led to an increase in the need for efficient information extraction from business documents. However, financial and legal documents are often not utilized effectively by text processing or machine learning systems, partly due to the presence of sensitive information in these documents, which restrict their usage beyond authorized parties and purposes. To overcome this limitation, we develop an anonymization method for German financial and legal documents using state-of-the-art natural language processing methods based on recurrent neural nets and transformer architectures. We present a web-based application to anonymize financial documents and a large-scale evaluation of different deep learning techniques.",
  "full_text": "International Journal of Data Science and Analytics (2022) 13:151–161\nhttps://doi.org/10.1007/s41060-021-00285-x\nAPPLICATIONS\nAnonymization of German ﬁnancial documents using neural\nnetwork-based language models with contextual word\nrepresentations\nDavid Biesner 1,2 · Rajkumar Ramamurthy 1 · Robin Stenzel 1 · Max Lübbering 1 · Lars Hillebrand 1,2 · Anna Ladi 1 ·\nMaren Pielka 1 · Rüdiger Loitz 3 · Christian Bauckhage 1 · Rafet Sifa 1\nReceived: 1 October 2020 / Accepted: 4 September 2021 / Published online: 2 October 2021\n© The Author(s) 2021\nAbstract\nThe automatization and digitalization of business processes have led to an increase in the need for efﬁcient information\nextraction from business documents. However, ﬁnancial and legal documents are often not utilized effectively by text pro-\ncessing or machine learning systems, partly due to the presence of sensitive information in these documents, which restrict\ntheir usage beyond authorized parties and purposes. To overcome this limitation, we develop an anonymization method for\nGerman ﬁnancial and legal documents using state-of-the-art natural language processing methods based on recurrent neural\nnets and transformer architectures. We present a web-based application to anonymize ﬁnancial documents and a large-scale\nevaluation of different deep learning techniques.\nKeywords Neural nets · Transformers · BERT · RNN · Financial documents · Anonymization · Sequence tagging\n1 Introduction\nThe automatic processing of text documents has become of\nvital importance in several industrial applications. The avail-\nability of digital ﬁnancial and legal documents is increasing\nand companies rely on automated methods for handling\nand analysis, often based on or assisted by machine learn-\ning tools. The development of such tools usually requires\nresearchers and developers to have access to documents\nas part of data exploration or the model training pipeline.\nHowever, such ﬁnancial data typically cannot be processed\nor shared beyond authorized parties due to the prevalence\nof sensitive information regarding speciﬁc individuals and\norganizations, which signiﬁcantly restricts development even\nwithin the organization. One possible solution is to perform\nDavid Biesner and Rajkumar Ramamurthy have contributed equally to\nthis work.\nB David Biesner\ndavid.biesner@iais.fraunhofer.de\n1 Fraunhofer IAIS, Sankt Augustin, Germany\n2 University of Bonn, Bonn, Germany\n3 PriceWaterhouseCoopers GmbH WPG, Frankfurt, Germany\neither pseudo-anonymization or full anonymization of data\nbefore further processing.\nAfter removing names, locations, dates and other entities\nthat make the inference of personal information possible,\none remains with a document that is safe to distribute but\nstill contains the original structure and language, leaving it\nsuitable for analysis, training and prediction.\nEven when anonymization of data is a direct interest to a\nbusiness or even a legal necessity (see Sect. 1.1 for examples),\nmanual anonymization is often unfeasible due to the sheer\namount of classiﬁed documents and the necessity for the\nhuman anonymizers to have authorized access to the original\ndocuments. In this work, we propose a deep learning-based\nframework for automatic anonymization of text documents\nand study its effectiveness on ﬁnancial documents.\n1.1 Legal context\nWhile the principle of anonymization is simple, concrete\napplications must follow narrow legal guidelines which we\nwant to elaborate on for the European and German market.\nWith the introduction of the General Data Protection Reg-\nulation, (GDPR)\n1 personal data can only be further processed\n1 https://gdpr-info.eu/ .\n123\n152 International Journal of Data Science and Analytics (2022) 13:151–161\nif they are compatible with the very strict purposes permitted\nby law for which this data were collected. 2 These purposes\nusually do not include the usage of the collected data for the\ntraining of machine learning tools. In fact, the GDPR does\nnot even mention the processing of “Big Data” or algorithms\nwith a single-word [ 1]. This does not change with the 2019’s\nentry into force of a new regulation of the EU on the free\nﬂow of non-personal data. As the name already suggest, this\nregulation allows the storage and processing of data across\nthe Member States without unjustiﬁed restrictions, as long as\nthe data are not personal. However, the principle of purpose\nlimitation is not applicable once the data are anonymized,\n3\nand therefore, this data can be used for developing digital\nsolutions across Europe.\nFurthermore, if the personal data are no longer necessary\nfor the purpose for which it was collected, the GDPR grants\nthe data subject a “right to be forgotten,” i.e., the right that\nits data are being erased.\n4 In practice, a company that col-\nlects personal data, like every service provider, would need\nto delete their customer contracts at the time of its termi-\nnation date. However, this could contradict legal retention\nperiods, for example, for tax purposes. This may be avoided,\nif the company anonymizes their contracts at the termination\ndate. Considering the amount of the corresponding docu-\nments, manual anonymization is not appropriate under these\ncircumstances.\nHowever, the demand for anonymization of conﬁdential\ndata has always been present, not only since the introduc-\ntion of the GDPR. For instance, publication of judgments\nin the public interest is, at least in Germany, a direct con-\nstitutional task for the judicial power and therefore for\nevery single court.\n5 However, these publications need to be\nanonymized, regardless of the GDPR, to protect the funda-\nmental right to informational self-determination. 6 Until now,\nsuch anonymization is mainly done manually, resulting in a\npublication of only a mere fraction of the judgments that are\nin the public interest.\n1.2 Our contributions\nAll of the examples above have in common that the data with\nthe need for anonymization is usually part of documents like\ncontracts or other reports. Consequently, we address this con-\ncern of data privacy and protection and present a web-based\nanonymization application that anonymizes sensitive infor-\nmation such as names of persons, locations, organizations,\nnumbers, telephone numbers, dates and URLs in a piece of\n2 Art. 17 GDPR.\n3 Recital 26 GDPR.\n4 Art. 5 GDPR.\n5 BV erwG, 26.2.1997 – 6 C 3/96.\n6 Art. 2 Abs. 1 GG in conjunction with Art. 1 Abs. 1 GG.\nFig. 1 General workﬂow for anonymizing a document using named\nentity recognition. First, sensitive entities are identiﬁed using deep\nlearning methods and rule-based post-processing. Then, the identiﬁed\nentities are replaced with appropriate tags to preserve the text structure\nor hidden behind a general anonymized tag\nwriting by the example of ﬁnancial documents. We tackle\nthis using state of the art deep learning and natural language\nprocessing techniques as well as rule-based post-processing.\nA general outline of the workﬂow is shown in Fig. 1.\nOur main contributions in this work are:\n– A method to anonymize 99% of all sensitive entities con-\ntained in German ﬁnancial documents while maintaining\nhigh readability and preserving the structure of the given\ntext\n– Presenting a web-based application and an API to use our\nmethod on various types of documents\n– A quantitative evaluation of multiple state-of-the-art deep\nlearning techniques for anonymization as well as the\nimpact of domain-speciﬁc language models for ﬁnancial\ndocuments.\nNote that a preliminary version of this work was presented\n(unpublished) at an AAAI-20\n7 workshop. This version of\nthe paper includes discussion of a new type of deep-learning\narchitecture (see Sect. 4.1.3) with theory, details on training\nand new experimental results.\n2 Related work\nEarlier systems on anonymization focused primarily on\nmedical records. The ﬁrst anonymization system was devel-\noped by [ 2] used several pattern matching algorithms which\ndetect names, phone numbers, etc. Later in 2006, a chal-\nlenge was hosted to anonymize clinical data which were\nalso made available as public dataset, namely i2b2\n8 for de-\nidentiﬁcation. Several systems were developed as a result of\nthis challenge which tackled the problem using named-entity\nrecognition [ 3,4], rule-based systems [ 5] and hybrid system\n[6] which uses look-up on dictionaries, regular expressions\n7 https://aaai-kdf2020.github.io/.\n8 https://www.i2b2.org/.\n123\nInternational Journal of Data Science and Analytics (2022) 13:151–161 153\nFig. 2 A screenshot of our anonymization tool; the left pane contains\nthe UI controls for uploading the document and other settings such as\nto turn on the anonymization for numbers and to enable masking. To\nthe right of it, there is the document pane and it shows the content of the\ndocument in which sensitive entities are highlighted if the mask option\nis not selected. If the mask option is selected, then the document pane\nshows the same content instead with sensitive entities masked\nand as well as model-based classiﬁers. To the best of our\nknowledge, we present the ﬁrst large scale of evaluation\nof anonymization techniques with respect to ﬁnancial docu-\nments.\n9\n3 Application\n3.1 Web-based application\nA screenshot of the application is shown in Fig. 2.I ti sa\nweb-based application (implemented via the Flask10 frame-\nwork) which allows the user to upload text documents (e.g.,\n.docx, .pdf, .txt, .json) and visualize the anonymized con-\ntent. The interface contains two panes; a left pane with\ncontrols and a right pane where the anonymized document\nis rendered. There are two basic conﬁgurable settings: by\ndefault, names, locations, organizations and other entities are\nanonymized using our deep learning methods. Additionally,\none can enable anonymization of numbers, dates, etc., which\nare detected using regular expressions. The sensitive entities\nare highlighted in different colors based on their types; In\nFig. 2, the names of persons, companies and locations are\nhighlighted in red, green and blue, respectively. Further, the\ntool allows the user to enable masking such that sensitive\nentities are blacked out entirely as shown in the ﬁgure on the\nrightmost pane.\n9 “Prof. Dr. V ogel …Mr. V ogel …vogel@company.com …Munich,\nApril 6th 2017.”\n10 https://pypi.org/project/Flask/ .\nParsing the original document allows for replacement of\ntext within the document format (e.g., .docx implemented\nusing the python-docx11 python library, .xslx using the open-\npyxl12 library) while keeping formatting like text size, fonts\nand layout intact. Once a document is processed, the tool lets\nthe user download an anonymized version of the document\nin the original format (e.g., .docx), in which all relevant enti-\nties are replaced by generic tokens (e.g., <PER>, <ORG>,\n<LOC>,… ) .\nAdditionally, the tool anonymizes .pdf -documents and\napplication of OCR methods ( pytesseract\n13 library) allow\nfor anonymization of scanned .pdf ﬁles.\nAll machine-learning related work was implemented\nusing the pytorch14 framework.\n3.2 API\nSince the main application of this tool is document pre-\nprocessing for further distribution or use in the training of\nmachine learning systems, we desire the anonymization of\nan entire document corpus. These anonymized documents\ncan afterward be handled by developers without clearance\nfor the original data. For this reason, we provide a REST\nAPI and python package for internal usage. This makes it\npossible for an employee with the required clearance for the\noriginal documents and no involvement in the development\n11 https://pypi.org/project/python-docx/ .\n12 https://pypi.org/project/openpyxl/ .\n13 https://pypi.org/project/pytesseract/ .\n14 https://pytorch.org/.\n123\n154 International Journal of Data Science and Analytics (2022) 13:151–161\nraw text\n”Herr Prof. Dr. Vogel ...\n...\nHerr Vogel ...\n...\n(vogel@company.com) ...\n...\n”.7102lirpA.6ned,nehcnu¨M 9\nembedding\n⎛\n⎜⎜⎜\n⎜⎝\n0.47\n0.03\n...\n...\n0.6\n0.9\n⎞\n⎟⎟⎟\n⎟⎠\n...\n⎛\n⎜⎜⎜\n⎜⎝\n− 0.19\n− 0.25\n...\n...\n− 0.48\n0.58\n⎞\n⎟⎟⎟\n⎟⎠\nprobabilities\n⎛\n⎜⎜⎝\n0.85\n0.05\n···\n0.0\n0.1\n⎞\n⎟⎟⎠···\n⎛\n⎜⎜⎝\n0.0\n0.25\n···\n0.45\n0.0\n⎞\n⎟⎟⎠\nlanguage model prediction model\npredictions\n”Herr Prof. Dr. Vogel ...\n...\nHerr Vogel ...\n...\n(vogel@company.com) ...\n...\nnehcnu¨M , den 6. April 2017.”\nLOC 00 0 0\n0\n0 PER\nPER PER PER 0\npost-processed predictions\n”Herr Prof. Dr. Vogel ...\n...\nHerr Vogel ...\n...\n(vogel@company.com) ...\n...\nnehcnu¨M ,d e n 6. April 2017 .”\nLOC 0 DATEDATE DATE\nEMAIL\nPER PER\nPER PER PER PER\nanonymized text\n”<PER> ...\n...\n<PER> ...\n...\n(<EMAIL>) ...\n...\n<LOC>, den <DATE>.”\npost-processing anonymization\nFig. 3 Workﬂow from raw text to ﬁnal anonymized output. We convert\neach token into a numerical vector using a trained language model, use a\nneural net classiﬁer to predict probabilities for each class for each token,\nchoose the class with the highest probability, apply post-processing and\nﬁnally replace named entities with corresponding labels in text, leaving\nwords classiﬁed as 0 intact\nprocess to use the tool to anonymize a corpus of documents\nat once and return the anonymized data. This leaves a read-\nable text without sensitive information that can be further\nanalyzed by different machine learning approaches.\n4 Anonymization as sequence tagging\nWe tackle the problem of anonymization as a sequence\ntagging task [ 7]. Given a document consisting of several\nsentences in which each sentence is a sequence of words\n(tokens), our goal is to assign a suitable label to each token\nindicating if it contains sensitive information or not.\nThe possible labels include\n– 0 (contains non-sensitive information),\n– ORG (contains an organization or part of an organizations\nname),\n– PER (contains a person or part of a persons name),\n– LOC (contains a location or part of a location name),\n– PROD (contains a product name),\n– SEG (contains information about the industry of the com-\npany),\n– URL (contains an URL),\n– TEL (contains a phone number),\n– DATE (contains a date),\n– NUM (contains a number),\n– EMAIL (contains an e-mail address) and\n– OTH (contains any other sensitive information).\nIn particular, we refer to ORG, PER, LOC, PROD, SEG\nand OTH as named entities as it is part of the well-known\nproblem of named entity recognition [ 8] in natural language\nprocessing.\nWe employ a multi-step approach as depicted in Fig. 3.\nStep 1 : Predict the named entities in each document using\nlanguage models and deep learning methods. Step 2: Make\nthese predictions consistent across each document. Step 3:\nPredict the remaining labels using rule-based classiﬁers and\nassign to the respective tokens. Step 4: Replace the text of\ntokens by appropriate tags in order to preserve the sentence\nstructure and semantics.\n4.1 Language models\n4.1.1 Word embeddings and contextual language models\nUnlike traditional string-based methods (e.g., rule-based sys-\ntems using regex), modern deep learning approaches for text\nclassiﬁcation require a two-step approach; ﬁrst, the raw text\nhas to be converted into a numeric representation, usually\na vector of ﬁxed dimension for each word in the text. The\nnumeric representation of a token is then fed into a classiﬁer\nthat outputs probabilities for each class.\n123\nInternational Journal of Data Science and Analytics (2022) 13:151–161 155\nWord representations can be obtained in two forms:\nglobal word embeddings and contextual word embed-\ndings. Global word embeddings provide numeric vectors for\neach word in a vast vocabulary and they are obtained using\na large corpus of language data to capture semantic informa-\ntion of each word. Typically, these embeddings are trained\nto satisfy some distance metric (e.g., Euclidean distance or\ncosine similarity) between semantically similar vectors. For\nexample, the word vector corresponding to ﬁnance would\nbe closer to the vector for banking than to the vector corre-\nsponding to apple. Popular word embedding models include\nword2vec [ 9] and glove [ 10]. The advantage of these mod-\nels lies in their ease of use that they can be distributed as\ntext documents containing words and corresponding vector\nweights. And retrieving an embedding for a certain word sim-\nply requires just a lookup of the corresponding entry in the\nlist of vectors. However, the reliance on exactly one vector\nper word has a major disadvantage that the same word can\nhave multiple meanings depending on context, which cannot\nbe captured by these global embeddings.\nConsider the following two sentences\n– “Herr V ogel ist Geschäftsführer der Test GmbH.”\n15\n– “Der frühe V ogel fängt den Wurm.” 16\nThe word Vogel refers to a bird in one sentence and a\nperson in the other. A global word embedding model would\nretrieve the same vector for both tokens and an anonymiza-\ntion model based on individual word embeddings would\neither anonymize the animal or let the name pass through.\nA prediction model that takes as input a sequence of word\nembeddings, as they appear in the sentence, might be able\nto differentiate the meanings in this context. However in this\nwork, we only consider prediction models based on single-\nword embeddings.\nIn contrast, contextualized language models offer embed-\ndings that include context for each word. Like word embed-\ndings, these models are also pretrained on a large corpus\nof language data, but are based off neural networks them-\nselves that process each sentence to capture the context. In\nthe example mentioned above, the language model would\ncapture the context of the sentence (see sections below for\ndetails on how) and calculate distinct word embeddings for\nboth instances of the word Vogel. An anonymization model\ncould then learn from these contextual word embeddings to\nanonymize the appropriate name. However, this means that\nthe retrieval of word embedding which is part of the predic-\ntion pipeline is not a simple dictionary lookup, but rather a\ndeep learning model itself that can vastly exceed the predic-\ntion model in size and complexity. In our experiments, the\n15 “Mr. V ogel (bird) is CEO of Test GmbH (equiv. LLC).”\n16 “The early bird catches the worm.”\nretrieval of the contextualized word embeddings takes up the\nmajority of the processing power and inference time.\nIn our setting, the most important distinction between clas-\nsic word embeddings and language models is the handling of\nout-of-vocabulary words. Though global word embeddings\noffer vectors for large vocabularies of words (e.g., Glove\nwith up to 400,000 words), there is no guarantee that for\nnames of persons, locations and companies there even exist\nan embedding. While there are several ways, depending on\nthe task, of dealing with these missing embeddings, obtaining\na reasonable embedding for each token naturally is deﬁnitely\npreferable.\nIn contrast, contextualized language models work with a\nvocabulary of either characters or so-called sub-word tokens\n[11]. In either case, the vocabulary contains each character\nthat is needed to construct words in a given sentence. There-\nfore, a contextualized language model is able to embed any\nword, no matter how common or rare.\nThese theoretical considerations hold up in practice,\nwhere architectures based on contextual language models\nseverely outperform traditional approaches based on word\nembeddings. For instance, [ 12] report a F1-score of 76-79%\non the CONLL-2003 task [ 13], compared to 91% reported\nin [ 14] on the same task. In a similar work on German NER\n[15], the use of contextual embeddings [ 14] obtained bet-\nter performance when compared to using only the Fasttext\nword embeddings [ 16]. For these reasons, we do not consider\nclassical word embeddings for our task and refrain from an\nadditional evaluation of these methods on our dataset.\n4.1.2 Recurrent neural net-based language models\nIn our work, we utilize ﬂair [14], which employs a bi-\ndirectional character-based recurrent neural net that traverses\neach sentence in both forward and backward direction, which\nis trained to predict the next character conditioned on the ones\nit saw before. In order to predict the beginning of the next\nword or the next character in a word, it needs information on\nthe sentence context that will be stored in the hidden states of\nthe network layers. The corresponding hidden states of the\nnetwork at the beginning and end of each token together act\nas the numeric vector representation for that token. It con-\ntains both information of the word itself and an encoding of\nthe surrounding words, thereby capturing the context of the\ntoken.\nIn this paper, we evaluate several versions of this language\nmodel that differ both in training data (i.e., what language\ncorpus the model was trained on) and their size, referring to\nthe dimension of the output vector. A smaller language model\noutputs a smaller token vector that stores less information but\ncan process a document signiﬁcantly faster. See Fig. 4 and\nTable 1 for a quantitative evaluation of language models of\ndifferent sizes.\n123\n156 International Journal of Data Science and Analytics (2022) 13:151–161\n4.1.3 Transformer-based language models\nIn recent years, the development of the transformer model\n[17] has led to many breakthroughs in natural language pro-\ncessing. Transformer-based architectures rely almost entirely\non self-attention, which processes the sequence of words as a\nwhole and considers relationships between all pairs of tokens\nin the sentence. This architecture allows for tracking long\ndependencies in text, which may be an issue with recurrent\nneural net-based architectures that lose their “memory” of\nprocessed words rather quickly [ 18].\nOne very popular transformer-based architecture is BERT\n[19]. BERT trains a transformer-based neural net model\nby masking random tokens in a sentence and trying to\nreconstruct them. While recurrent architectures, as described\nabove, receive the entire sentence to one side to reconstruct\nthe next token, BERT receives the entire sentence context\nexcept the tokens that needs to be reconstructed. Addition-\nally, the same model architecture can be trained on many\ntasks like language modeling (i.e., token reconstruction),\ntranslation and token or sequence classiﬁcation. This way\nresearchers are able to train a single model on various datasets\nto improve general language understanding within the model.\nThis type of architecture has led to new state of the art\nresults, for instance in machine translation. However, one\ndrawback of BERT is a reliance on a maximum sequence\nlength of 512, which other models are able to overcome [ 20].\n4.2 Prediction models\nAfter obtaining the token representations using the language\nmodels, the text is fed into the classiﬁer network as an ordered\nlist of numeric vectors, one for each token, which is then sub-\nsequently mapped onto corresponding probabilities for each\nof the 7 named entities ( 0, ORG, PER, LOC, PROD, SEG\nand OTH). During training, the network is trained to predict\nthe expert annotated labels for each token by minimizing the\ncross-entropy loss. Once the network is trained in this fash-\nion, during inference, the label with the highest probability\nis predicted. We consider three different classiﬁers architec-\ntures:\n4.2.1 MLP\nFirst, we consider a simple fully connected network ( multi-\nlayer perceptron) that takes each token representation indi-\nvidually, passes it through several layers and outputs prob-\nabilities for each of the 7 named entities. In this case, the\nprediction for each token is treated independently and relies\nsolely on the contextual representation provided by the lan-\nguage model. This classiﬁer is preferred because of faster\ninference time and easier interpretability of results.\n4.2.2 RNN\nAlthough a simple MLP is sufﬁcient to classify a token since\nthe representation contains the context, it is still beneﬁcial to\nprocess the text using a recurrent neural net which further\nenhances the context and more importantly the required span\nof context can be trained for the given task. For this reason, we\nconsider a bi-directional variant of Long Short Term Memory\n(LSTM)[ 21] which traverses the list of vectors in both direc-\ntions, processing stored context information from previous\ntokens and the current token. The outputs along both direc-\ntions (forward and backward) are concatenated and passed\nthrough a ﬁnal fully connected prediction layer mapping to\nprobabilities for each of the 7 named entities.\n4.2.3 RNN + CRF\nWith MLP and RNN, the prediction of each token is treated\nindependently. In order to incorporate dependencies between\npredicted labels, the fully connected layer from the output\nstates of the RNN to the output layer can be replaced by a\nconditional random ﬁeld (CRF)[ 22] that learns a mapping\nof sequences of representations taking into account the pre-\ndicted labels of consecutive tokens.\n4.3 Post-processing\nAs discussed in Sect. 3.1, we also provide an option in our\napplication to anonymize URLs, dates, numbers and e-mail\naddresses. Since they mostly have regular patterns, we have\nimplemented regular expressions to detect these entities.\nFor the task of anonymization, we want to give higher\npreference to recall than precision, since anonymizing too\nmany words is preferable to missing a word that should be\nanonymized. Due to the context dependence of the applied\nlanguage and prediction models, there might be tokens in the\ngiven text which are predicted as sensitive in one place and\nas not sensitive in other places. To this end, we propose the\napplication of a post-processing step that ensures consistency\nin the predicted labels: a token (e.g., a persons name) that is\npredicted as a named entity once in the document is always\nreplaced by the corresponding label, even if the classiﬁer\npredicted it as non-sensitive in another sentence.\n5 Experiments and results\n5.1 Datasets and models\nIn the following subsections, we describe the speciﬁc\ndatasets, architectures and techniques used for training lan-\nguage models and classiﬁers.\n123\nInternational Journal of Data Science and Analytics (2022) 13:151–161 157\nTable 1 Quantitative evaluation of all described language models and classiﬁers on the NER evaluation dataset of ﬁnancial documents and the\nGermEval dataset\nArchitecture Embedding On ﬁnancial documents On Germeval\nBefore post-processing After post-processing Before post-processing\nPrecision Recall F 1 Precision Recall F 1 Precision Recall F 1\nMLP BANZ1024 0.989 0.485 0.651 0.960 0.682 0.797 0.928 0.076 0.140\nMLP BANZ2048 0.986 0.584 0.734 0.954 0.777 0.856 0.938 0.136 0.238\nMLP BANZ4096 0.986 0.765 0.862 0.938 0.867 0.901 0.923 0.179 0.300\nMLP ﬂairDE 0.967 0.933 0.950 0.905 0.968 0.935 0.669 0.793 0.726\nMLP BERT 0.975 0.617 0.756 0.923 0.793 0.853 0.778 0.193 0.309\nRNN BANZ1024 0.958 0.948 0.953 0.897 0.976 0.935 0.720 0.646 0.681\nRNN BANZ2048 0.963 0.966 0.964 0.907 0.985 0.944 0.778 0.622 0.691\nRNN BANZ4096 0.972 0.969 0.970 0.915 0.986 0.949 0.815 0.638 0.716\nRNN ﬂairDE 0.966 0.968 0.967 0.906 0.988 0.945 0.808 0.848 0.828\nRNN BERT 0.958 0.957 0.957 0.887 0.978 0.930 0.775 0.573 0.659\nRNN_CRF BANZ1024 0.960 0.961 0.960 0.897 0.983 0.938 0.741 0.684 0.711\nRNN_CRF BANZ2048 0.968 0.969 0.968 0.910 0.987 0.947 0.784 0.654 0.713\nRNN_CRF BANZ4096 0.971 0.973 0.972 0.910 0.987 0.947 0.796 0.675 0.731\nRNN_CRF ﬂairDE 0.968 0.970 0.969 0.903 0.990 0.945 0.824 0.840 0.832\nRNN_CRF BERT 0.955 0.950 0.952 0.878 0.975 0.923 0.743 0.582 0.653\nﬂairNER ﬂairDE 0.938 0.779 0.851 0.853 0.897 0.874 0.889 0.755 0.817\nWe provide all metrics on the positive class ( PER, ORG and LOC). The best performance for each metric is marked bold for each column,\nrespectively. Post-processing for these classes only consists of ensuring label consistency. We do not evaluate post-processing for Germeval sinc e\nits structure (independent sentences) does not ﬁt our post-processing methods\n5.1.1 Language model corpus\nAs discussed in the previous section, in order to obtain\ncontextual representations for tokens, we consider differ-\nent language models. The baseline model that we use is a\npre-trained language model provided by the ﬂair framework\nwhich is trained on a large general corpus of German sen-\ntences consisting of 500 million words. We refer the embed-\nding obtained using this model as ﬂairDE. The language\ncorpus used in the training of this embedding might cause\nlicensing issues, e.g., the Wikipedia corpus is distributed\nunder GNU Free Documentation License and Creative Com-\nmons Attribution-Share-Alike 3.0 License , which prohibit\ncommercial use without adapting the same license to the\nproject. Additionally, a language model trained on data that\nis similar to the ﬁnancial text might provide an advantage\nover a language model trained on general language data and\na custom language model allows for tuning the embedding\nsize in order to optimize runtime. We therefore train language\nmodels on a corpus of language data from Bundesanzeiger\n17\n(BANZ), consisting of 19,000 German ﬁnancial documents\n(200 million words).\n17 https://www.bundesanzeiger.de/ebanzwww/wexsservlet.\n5.1.2 Document corpus\nWe train our deep learning classiﬁer models using a corpus of\n407 published German ﬁnancial documents, annotated man-\nually by domain experts. We split the dataset into 305 training\nand 102 validation documents. Once a model is trained, we\nprovide a ﬁnal evaluation dataset consisting of 45 thoroughly\nannotated documents. This evaluation dataset contains a total\nof 189k tokens, 17k (9.1%) of which belong to one of the\nclasses ORG, LOC and PER. In order to provide results\ncomparable to other NER and anonymization projects, we\nadditionally evaluate all trained models on the GermEval\n2014 NER Shared Task corpus [ 23], consisting of 29k sen-\ntences annotated for NER with a total of approximately 590k\ntokens, 8.4% of which are named entities.\n5.1.3 RNN-based language models\nTo train and use a language model on our data, we employ\nthe framework provided by the ﬂair python-package.\n18 It\nimplements a bidirectional LSTM on a character level. We\ntrain language models on the BANZ-corpus with 1024, 2048\nand 4096 dimensions. These are denoted by BANZ1024,\n18 https://github.com/zalandoresearch/ﬂair .\n123\n158 International Journal of Data Science and Analytics (2022) 13:151–161\nFig. 4 Inﬂuence of language model on precision, recall, F 1-score\nand inference time on evaluation documents. Precision and recall are\nreported without post-processing. Inference time measured in seconds\nper document (10 pages). We see that for the RNN-based architectures,\nthe choice of language model makes little difference in anonymiza-\ntion performance. However, a smaller language model reduces the time\nit takes to process one document signiﬁcantly. Note that there are no\nmajor differences in processing time between classiﬁer architectures,\nthe language model is the main contributor to processing time\nBANZ2048, BANZ4096, respectively. We train for 100 epochs\nusing the default parameters suggested by the package.\n5.1.4 BERT language models\nThe used BERT model consists of a model pretrained on\ngeneral German language data 19 that we ﬁne-tuned (i.e., con-\ntinued to train) on the BANZ data corpus described above.\nThe model provides embeddings of dimension 3072.\n5.1.5 Classiﬁers\nThe RNN classiﬁer as suggested by [ 14] is a one-layer BiL-\nSTM with a hidden representation of 256 dimensions. We use\nthe framework provided by the ﬂair package to train RNN-\nbased NER classiﬁers on the NER training dataset. We train\nfor 100 epochs using the default parameters suggested by\nthe package. Each MLP model consists of one intermediate\nhidden layer, mapping the input onto a lower-dimensional\n19 https://deepset.ai/german-bert .\nrepresentation. This hidden representation is then mapped\nonto the 7-dimensional output vector. The number of neu-\nrons in the intermediate hidden layer are 500, 500, 1000,\ndepending on the input dimension 1024, 2048 and 4096,\nrespectively. We train the MLP classiﬁer for 100 epochs,\nusing a batch size of 100 tokens. As optimizer, we use\nAdadelta with a learning rate of 0.1 and weight decay of\n1e–5.\nFurther, to provide a baseline evaluation we consider a pre-\ntrained classiﬁer for named entity recognition that has been\ntrained on general language and named entity recognition\ndata and has never seen our BANZ corpus or any annotated\nﬁnancial documents. For this, we apply the pre-trained NER\nmodel provided by the ﬂair package, which is a RNN+CRF\nclassiﬁer trained on the CoNLL-2003 German NER dataset\n[13] and a general corpus language model. We denote this\nclassiﬁer as ﬂairNER.\n123\nInternational Journal of Data Science and Analytics (2022) 13:151–161 159\n5.2 Results and analysis\nIn this section, we present quantitative results on the per-\nformance of the described language models and classiﬁers.\nFor our task of anonymization, it is desired to have a good\nbinary classiﬁcation performance, i.e., we tolerate a PER\nentity being tagged as an ORG entity and at the same time, we\nconsider a PER entity tagged as 0 as a mis-classiﬁcation and\nvice versa. For this reason, before evaluation all predicted\nand annotated tags are re-mapped onto two classes only, the\nnegative class 0 indicating they are not sensitive entities and\nthe positive class 1 indicating such tokens to be anonymized.\nFurther, we are mostly interested in the performance on the\npositive class and therefore provide its metrics (precision,\nrecall and F\n1-score) only. Due to the lack of reliable avail-\nable data for SEG, PROD and OTH, we do not consider them\nduring this evaluation.\nTable 1 presents the complete experimental results with\ndifferent classiﬁer architectures and language models. The\nevaluation on ﬁnancial documents suggests that the RNN+CRF\nachieves the best performance, at over 97% recall without\npost-processing and around 99% after post-processing, with-\nout compromising precision of over 90%.\nThis results in a near complete anonymization of the\nentire document with very little unnecessarily anonymized\nwords. Using domain-speciﬁc language model gives slight\nimprovements over general language models for RNN-based\nclassiﬁers. On the other-hand, the general corpus was bene-\nﬁcial while using a MLP classiﬁer.\nFigure 4 captures the inﬂuence of language model on the\nperformance metrics. From the runtime and recall plots, we\ncan observe that even with the smaller domain-speciﬁc lan-\nguage models, the RNN classiﬁers are able to out-perform\nthe general language model, while reducing the runtimes\nof the anonymization process by over 50%. We further see\nthat the RNN-based prediction models achieve comparable\nresults for the larger RNN-based language models and the\ntransformer-based BERT. Depending on application a slight\ndrop in recall when employing a smaller language model\n(e.g., going from BANZ4096 to BANZ2048) can be toler-\nated, considering it greatly improves on the inference time\nper document.\nIn order to evaluate the generalizability of our classiﬁers,\nwe evaluate our models on GermEval dataset. For this evalu-\nation, we do not apply any post-processing since it contains\nonly sentences obtained from different sources and they do\nnot follow any document structure. The results suggest that\nthe RNN classiﬁers using a general language model performs\nbetter than one trained only on ﬁnancial documents, which\nis expected since the sentences in GermEval correspond to\nsentences from a variety of sources. Nevertheless, the perfor-\nmance is comparable to the current state-of-the-art for NER.\nFurther, the pre-trained NER classiﬁer, trained on a general\nlanguage German NER corpus, only yields a recall of 84%\nand 93% on the ﬁnancial documents, without and with post-\nprocessing, respectively.\n6 Discussion and future work\nIn this work, we focus on the anonymization of ﬁnancial\ndocuments and mention the use case for court records and\nlegal documents in general. Another example for a pos-\nsible application is healthcare. The ongoing battle with\nthe corona pandemic showed how beneﬁcial it is when\nhospitals and researchers work together and share their ﬁnd-\nings and information. At the same time, patient data often\ncontains sensitive information prohibiting a fast exchange\nwithout prior anonymization. Therefore, an expansion of our\napproach to this ﬁeld can enable and speed-up the data trans-\nfer and increase the amount of available data.\nIn order to apply this work to a new group of documents,\none can use the following approach. As there are many sim-\nilarities between entities of different domains, the presented\nmodels will likely work well even with no adaption. As\nseen in Table 1, a model pre-trained on general text data\nalready performs decently at almost 90% anonymization per-\nformance. The next step to further increase the performance\nand recognize new patterns will be to train a domain spe-\nciﬁc language model and if available, ﬁne-tune the model on\nannotated data of that ﬁeld. We expect the post-processing\nsteps described in Sect. 4.3 to also improve anonymization in\nmost other domains, domain-speciﬁc post-processing steps\nmight have to be developed.\nIn the experiments, we consider BERT as a contextual-\nized language model that provides word embeddings which\nare passed as inputs to the separate prediction model. To\nfurther improve the language model, we plan on integrating\nnamed entities directly into the pre-training. Yamada et al.\n[24] show that treating words and entities as independent\ntokens during the masking task and within the self-attention\nmechanism can lead to better performances on named entity\nrecognition tasks. Furthermore, we intend to explore trans-\nformers and self-attention as an end-to-end model for named\nentity recognition.\nAnother limiting factor for our method that inspires further\nresearch is the quality of annotations. Often, mistakes in the\nannotation lead to worse models by internalizing annotation\nmistakes during training. Additionally, Manning [ 25] demon-\nstrates that the agreement between annotators can be another\nconstraint. In the future, we intend to reduce the effect of\nboth cases by identifying suspicious samples during training\na ss h o w nb y[26].\n123\n160 International Journal of Data Science and Analytics (2022) 13:151–161\n7 Conclusion\nWe presented a method to reliably anonymize the names\nof persons, locations and organizations using state-of-the-\nart deep learning techniques, as well as URLs, telephone\nnumbers, dates and other numbers using classical rule-based\napproaches in ﬁnancial documents. For internal use, this\nmethod can be applied to a single document or entire doc-\nument corpora using a web-based application and a REST\nAPI. This allows for pre-processing of documents that can\nthen be used by developers and researchers to train and eval-\nuate further models for machine learning on ﬁnancial data\n(e.g., [ 27]).\nA quantitative evaluation of language models and text\nclassiﬁers shows that domain-speciﬁc training of language\nmodels improves classiﬁcation performance and smaller\nlanguage models signiﬁcantly improve runtime while main-\ntaining anonymization performance. As future work, we\nwould like to incorporate methods to anonymize additional\nidentifying information (e.g., the segments the organization\noperates in) as well as analyze the impact of anonymized data\nas inputs for the training of machine learning algorithms over\nthe original text.\nSupplementary Information The online version contains supplemen-\ntary material available at https://doi.org/10.1007/s41060-021-00285-\nx.\nFunding Open Access funding enabled and organized by Projekt\nDEAL. Part of the authors from Fraunhofer IAIS were supported in\nparts by the Fraunhofer Research Center for Machine Learning (RCML)\nwithin the Fraunhofer Cluster of Excellence Cognitive Internet Tech-\nnologies (CCIT) and by the Competence Center for Machine Learning\nRhine Ruhr (ML2R) which is funded by the Federal Ministry of Educa-\ntion and Research of Germany (Grant No. 01|S18038B). We gratefully\nacknowledge this support.\nData availability Data for language modeling training is available at\nhttps://www.bundesanzeiger.de/. Annotated data for prediction model\ntraining is not publicly available.\nCode Availability Code is not publicly available.\nDeclarations\nConﬂict of interest None.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing, adap-\ntation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indi-\ncate if changes were made. The images or other third party material\nin this article are included in the article’s Creative Commons licence,\nunless indicated otherwise in a credit line to the material. If material\nis not included in the article’s Creative Commons licence and your\nintended use is not permitted by statutory regulation or exceeds the\npermitted use, you will need to obtain permission directly from the copy-\nright holder. To view a copy of this licence, visit http://creativecomm\nons.org/licenses/by/4.0/.\nReferences\n1. Gola, P ., Eichler, C., Franck, L., et al.: Datenschutz-\ngrundverordnung: Ds-gvo (2017). Art. 6, paragraph 255\n2. Sweeney, L.: Replacing Personally-Identifying Information in\nMedical Records, the Scrub System. (1996)\n3. Wellner, B., Huyck, M., Mardis, S., et al.: Rapidly retargetable\napproaches to de-identiﬁcation in medical records. J. Am. Med.\nInf. Assoc. 14(5), 564 (2007)\n4. Gardner, J., Xiong, L.: HIDE: an integrated system for health infor-\nmation de-identiﬁcation. In: Proc. on. International Symposium on\nComputer-Based Medical Systems (2008), pp. 254–259\n5. Neamatullah, I., Douglass, M.M., Li-wei, H.L., et al.: Automated\nde-identiﬁcation of free-text medical records. BMC Med. Inf.\nDecis. Mak. 8(1), 32 (2008)\n6. Ferrández, O., South, B., Shen, S., et al.: BoB, a best-of-breed auto-\nmated text de-identiﬁcation system for VHA clinical documents.\nJ. Am. Med. Inf. Assoc. 20(1), 77 (2012)\n7. Nguyen, N., Guo, Y .: Comparisons of sequence labeling algorithms\nand extensions. In: Proceedings of the 24th International Confer-\nence on Machine Learning 227, 681–688 (2007)\n8. Li, J., Sun, A., Han, J., Li, C.: A Survey on Deep Learning for\nNamed Entity Recognition (2018)\n9. Mikolov, T., Chen, K., Corrado, G.S., Dean, J.: Efﬁcient Estimation\nof Word Representations in V ector Space (2013)\n10. Pennington, J., Socher, R., Manning, C.D.: GloV e: Global vectors\nfor word representation. In: Proc. of Empirical Methods in Natural\nLanguage Processing (2014), pp. 1532–1543\n11. Kudo, T., Richardson, J.: Sentencepiece: A simple and language\nindependent subword tokenizer and detokenizer for neural text pro-\ncessing (2018)\n12. Ghannay, S., Favre, B., Estève, Y ., Camelin, N.: Word Embeddings\nEvaluation and Combination. Tech. rep. https://code.google.com/\np/word2vec/\n13. Tjong Kim Sang, E.F., De Meulder, F.: Introduction to the CoNLL-\n2003 shared task: language-independent named entity recognition.\nIn: Daelemans, W., Osborne, M. (eds.) Proc. of CoNLL, pp. 142–\n147 (2003)\n14. Akbik, A., Blythe, D., V ollgraf, R.: Contextual string embed-\ndings for sequence labeling. In: Proc. of Int. Con. on Computa-\ntional Linguistics (2018), pp. 1638–1649. https://www.aclweb.org/\nanthology/C18-1139\n15. Ramamurthy, R., Stenzel, R., Sifa, R., Ladi, A., Bauckhage, C.:\nEcho state networks for named entity recognition. In: Proc. of.\nInternational Conference on Artiﬁcial Neural Networks (2019)\n16. Joulin, A., Grave, E., Bojanowski, P ., Mikolov, T.: Bag of Tricks\nfor Efﬁcient Text Classiﬁcation. arXiv preprint arXiv:1607.01759\n(2016)\n17. V aswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L.,\nGomez, A.N., Kaiser, L., Polosukhin, I.: Attention Is All Y ou Need,\nCoRR. arXiv preprint arXiv:1706.03762\n18. Bai, S., Kolter, J.Z., Koltun, V .: An Empirical Evaluation of Generic\nConvolutional and Recurrent Networks for Sequence Modeling,\nCoRR. arXiv preprint arXiv:1803.01271\n19. Devlin, J., Chang, M., Lee, K., Toutanova, K.: BERT: Pre-training\nof Deep Bidirectional Transformers for Language Understanding,\nCoRR. arXiv preprint arXiv:1810.04805.\n20. Dai, Z., Yang, Z., Yang, Y ., Carbonell, J.G., Le, Q.V ., Salakhutdi-\nnov, R.: Transformer-XL: Attentive Language Models Beyond a\nFixed-Length Context, CoRR. arXiv preprint arXiv:1901.02860.\n123\nInternational Journal of Data Science and Analytics (2022) 13:151–161 161\n21. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural\nComput. 9, 1735 (1997)\n22. Lafferty, J.D., McCallum, A., Pereira, F.C.N.: Conditional random\nﬁelds: probabilistic models for segmenting and labeling sequence\ndata. In: Proc. of Int. Conf. on Machine Learning (2001), ICML\n’01, pp. 282–289\n23. Benikova, D., Biemann, C., Kisselew, M., Padó, S.: GermEval\nNamed Entity Recognition: Companion paper, pp. 104–112. In:\nProc. of the KONVENS GermEval Shared Task on Named Entity\nRecognition, Hildesheim, Germany (2014)\n24. Yamada, I., Asai, A., Shindo, H., Takeda, H., Matsumoto, Y .:\nLUKE: Deep Contextualized Entity Representations with Entity-\nAware Self-Attention. arXiv preprint arXiv:2010.01057 (2020)\n25. Manning, C.D.: Part-of-speech tagging from 97 to 100%: is it time\nfor some linguistics?. In: International Conference on Intelligent\nText Processing and Computational Linguistics (Springer, 2011),\npp. 171–189\n26. Wang, Z., Shang, J., Liu, L. Lu, L., Liu, J., Han, J.: Crossweigh:\nTraining Named Entity Tagger from Imperfect Annotations. arXiv\npreprint arXiv:1909.01441 (2019)\n27. Sifa, R., Lübbering, M., Nütten, U., Bauckhage, C., Warning, U.,\nFürst, B., Khameneh, T., Thom, D., Huseynov, I., Kahlert, R.,\nSchlums, J., Ladi, A., Ismail, H., Kliem, B., Loitz, R., Pielka, M.,\nRamamurthy, R., Hillebrand, L., Kirsch, B., Bell, T.: Towards auto-\nmated auditing with machine learning. Proc. ACM Symp. Doc.\nEng. 2019, 1–4 (2019)\nPublisher’s Note Springer Nature remains neutral with regard to juris-\ndictional claims in published maps and institutional afﬁliations.\n123",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7810580730438232
    },
    {
      "name": "German",
      "score": 0.7780909538269043
    },
    {
      "name": "Transformer",
      "score": 0.7140305638313293
    },
    {
      "name": "Artificial neural network",
      "score": 0.5917285084724426
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5432223081588745
    },
    {
      "name": "Natural language processing",
      "score": 0.527675211429596
    },
    {
      "name": "Information extraction",
      "score": 0.5059584975242615
    },
    {
      "name": "Word embedding",
      "score": 0.469635009765625
    },
    {
      "name": "Machine learning",
      "score": 0.3649340271949768
    },
    {
      "name": "Information retrieval",
      "score": 0.3325836658477783
    },
    {
      "name": "World Wide Web",
      "score": 0.3247755765914917
    },
    {
      "name": "Engineering",
      "score": 0.08974692225456238
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Embedding",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "History",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210144576",
      "name": "Fraunhofer Institute for Intelligent Analysis and Information Systems",
      "country": "DE"
    }
  ]
}