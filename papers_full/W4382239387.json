{
  "title": "Multi-Aspect Explainable Inductive Relation Prediction by Sentence Transformer",
  "url": "https://openalex.org/W4382239387",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2314890506",
      "name": "Zhixiang Su",
      "affiliations": [
        "Nanyang Technological University",
        "Shandong University"
      ]
    },
    {
      "id": "https://openalex.org/A2107274244",
      "name": "Di Wang",
      "affiliations": [
        "Nanyang Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A2154137932",
      "name": "Chunyan Miao",
      "affiliations": [
        "Shandong University",
        "Nanyang Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A2155397016",
      "name": "Li-Zhen Cui",
      "affiliations": [
        "Shandong University"
      ]
    },
    {
      "id": "https://openalex.org/A2314890506",
      "name": "Zhixiang Su",
      "affiliations": [
        "Nanyang Technological University",
        "Optech (Canada)"
      ]
    },
    {
      "id": "https://openalex.org/A2107274244",
      "name": "Di Wang",
      "affiliations": [
        "BC Research (Canada)",
        "Optech (Canada)"
      ]
    },
    {
      "id": "https://openalex.org/A2154137932",
      "name": "Chunyan Miao",
      "affiliations": [
        "Optech (Canada)",
        "Nanyang Technological University",
        "BC Research (Canada)"
      ]
    },
    {
      "id": "https://openalex.org/A2155397016",
      "name": "Li-Zhen Cui",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2127795553",
    "https://openalex.org/W6784868539",
    "https://openalex.org/W6740216407",
    "https://openalex.org/W4412342001",
    "https://openalex.org/W6672750507",
    "https://openalex.org/W2250342289",
    "https://openalex.org/W3003265726",
    "https://openalex.org/W1756422141",
    "https://openalex.org/W2184957013",
    "https://openalex.org/W3006053005",
    "https://openalex.org/W2283196293",
    "https://openalex.org/W2950813464",
    "https://openalex.org/W6791739708",
    "https://openalex.org/W2769099080",
    "https://openalex.org/W3034239155",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2995448904",
    "https://openalex.org/W2962936385",
    "https://openalex.org/W4311565391",
    "https://openalex.org/W2604314403",
    "https://openalex.org/W2087588854",
    "https://openalex.org/W2728059831",
    "https://openalex.org/W2962886429",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W2972167903",
    "https://openalex.org/W3103296573",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W3096932862"
  ],
  "abstract": "Recent studies on knowledge graphs (KGs) show that path-based methods empowered by pre-trained language models perform well in the provision of inductive and explainable relation predictions. In this paper, we introduce the concepts of relation path coverage and relation path confidence to filter out unreliable paths prior to model training to elevate the model performance. Moreover, we propose Knowledge Reasoning Sentence Transformer (KRST) to predict inductive relations in KGs. KRST is designed to encode the extracted reliable paths in KGs, allowing us to properly cluster paths and provide multi-aspect explanations. We conduct extensive experiments on three real-world datasets. The experimental results show that compared to SOTA models, KRST achieves the best performance in most transductive and inductive test cases (4 of 6), and in 11 of 12 few-shot test cases.",
  "full_text": "Multi-Aspect Explainable Inductive Relation Prediction by Sentence Transformer\nZhixiang Su1,2,3, Di Wang3,4*, Chunyan Miao1,2,3,4, Lizhen Cui2,5\n1School of Computer Science and Engineering, Nanyang Technological University (NTU), Singapore\n2SDU-NTU Centre for Artiticial Intelligence Research (C-FAIR), Shandong University (SDU), China\n3Joint NTU-WeBank Research Centre on Fintech, NTU, Singapore\n4Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly (LILY), NTU, Singapore\n5School of Software, SDU, China\n{zhixiang002, wangdi, ascymiao}@ntu.edu.sg, clz@sdu.edu.cn\nAbstract\nRecent studies on knowledge graphs (KGs) show that path-\nbased methods empowered by pre-trained language models\nperform well in the provision of inductive and explainable re-\nlation predictions. In this paper, we introduce the concepts\nof relation path coverage and relation path confidence to fil-\nter out unreliable paths prior to model training to elevate the\nmodel performance. Moreover, we propose Knowledge Rea-\nsoning Sentence Transformer (KRST) to predict inductive re-\nlations in KGs. KRST is designed to encode the extracted\nreliable paths in KGs, allowing us to properly cluster paths\nand provide multi-aspect explanations. We conduct extensive\nexperiments on three real-world datasets. The experimental\nresults show that compared to SOTA models, KRST achieves\nthe best performance in most transductive and inductive test\ncases (4 of 6), and in 11 of 12 few-shot test cases.\nIntroduction\nAs an important tool for providing side information for ques-\ntion answering and recommendation systems (Ji et al. 2021),\nknowledge graph (KG) has been widely studied. A KG is\ntypically expressed in terms of triplets G = {(hi, ri, ti)|i =\n1, 2, 3, .., m}, which contains entities hi, ti ∈ EG and re-\nlations ri ∈ RG. Because of the incompleteness of KGs in\npractice, knowledge graph completion (KGC) is needed to\nimprove the quality of KGs. One of the most important KGC\ntasks is relation prediction. Given the target triplet (h, r, t),\na relation prediction query is usually set by masking the en-\ntity h or t in the given triplet and letting the model predict\nthe masked entity based on the other entity and the relation\ntype.\nEmbedding-based methods are probably the most com-\nmonly applied SOTA models. With a fixed set of entities and\nrelations, embedding-based methods perform fairly well in\nKGC tasks. However, most existing embedding-based meth-\nods are not explainable and cannot deal with inductive sit-\nuations, making them not suitable for modeling real-world\ndynamic KGs, wherein new entities and relations may be\nadded all the time. Inductive relation prediction requires the\nmodel to handle unseen entities unavailable in the training\ngraph.\n*Corresponding Author\nCopyright © 2023, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n !\"#$%& '()(&*+$,&-##-*\n.-##()\n'/(##*'0#1$-)%\n2-)30)/4$#/*5(!\"6(\"-\n2-)%0!*5(!\"6(\"-\n7)-(/80)9%\n2)016,:$0!*;0/<(!=\n>&-*?%#(!1\n'-(!*@-(!\n2)016,:$0!*;0/<(!=\n2-)30)/\n4$#/*5(!\"6(\"-\n2-)%0!*5(!\"6(\"-\nA,:0)\n2)03-%%$0!\nA#=%0!*\nB(!!$\"(! 4-/(#-\n.-!1-)\n.-!1-)2)03-%%$0!\nC(:&)=!*\nA!!*@$\"-#0D7$)-,:0) .-!1-)2)03-%%$0!\nFigure 1: An example of KG.\nGNN-based methods take advantage of the KG’s graph\nconnectivity, thus, are capable of predicting new entities\nwith a sufficient number of known neighboring entities. Re-\ncent GNN-based method GRAIL (Teru, Denis, and Hamil-\nton 2020) is shown to be capable of conducting inductive re-\nlation predictions. Nonetheless, extracting explainable rules\nis left for further exploration in GRAIL. So far, no evidence\nshows that GRAIL is explainable.\nDifferent from GNN-based methods, path-based methods\ntake advantage of the graph connectivity by analyzing paths\nbetween the head and tail entities. When we focus only on\nthe relations in one path, they can be formulated as a Horn\nrule (Horn 1951) for knowledge reasoning. Therefore, in\npath-based methods, new entities can be easily modeled by\napplying the summarized rules. For example, w.r.t Figure 1,\nfor triplet (Small Soldiers, Film Language,English) and the\ncorresponding path\nSmall Soldiers Perform-1\n− − − − − →Sarah Person Language− − − − − − − − − − →English, (1)\nwe can summarize that\n(y, Perform, x) ∧ (y, PersonLanguage, z) → (x, FilmLanguage, z). (2)\nSuch rule-based operations make path-based methods in-\nductive and highly explainable. BERTRL (Zha, Chen, and\nYan 2022), which employs the pre-trained language model\nBERT for scoring, is one typical model of such type. Using\ncontextual descriptions of entities and relations, BERTRL\nThe Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23)\n6533\ncan deal with inductive cases and provide single-path expla-\nnations, achieving the best SOTA results in the literature.\nTo further improve the relation prediction performance\nand strive for better explainability, in this paper, we propose\nKnowledge Reasoning Sentence Transformer (KRST) ,\nwhich is a novel path-based model built upon the sentence\ntransformer. The key innovations of KRST are as follows:\nPath extraction. Although paths between head and tail enti-\nties can be easily extracted, most of the extracted paths may\nbe unreliable. Moreover, unreliable short paths with words\nalso appearing in the target triplets are usually preferred by\nthe pre-trained language model. To assess the reliability of\npaths and only use reliable ones for model training, we pro-\npose the concepts of relation path coverage and relation path\nconfidence (see Definitions 4 and 5, respectively).\nPre-trained language model. Compared with the com-\nmonly applied BERT for sequence classification model, the\nsentence transformer adopting cosine similarity achieves\na higher performance in multiple tasks (Reimers and\nGurevych 2019). Therefore, we adopt sentence transformer\nin KRST to encode triplets and paths into embeddings,\nwhich allows us to explicitly compare between embeddings\nand cluster paths w.r.t various aspects.\nLoss function. In KRST, we compare the similarity between\npaths and triplets using the cosine similarity score. In the\ncase of negative triplets, negative scores are not necessarily\nclose to −1. Nevertheless, commonly applied binary classi-\nfication loss functions (e.g., cross-entropy) often make the\nmodel over-confident by requiring the prediction result to be\nclose to either 1 or −1. Therefore, we use cosine embedding\nloss instead, aiming to better elevate the model performance.\nOur key contributions in this paper are as follows:\n(i) We propose two novel path extraction metrics named\nrelation path coverage and relation path confidence, and a\nnovel path-based model named KRST. To the best of our\nknowledge, KRST is the first sentence transformer model\nfor knowledge graph path encoding.\n(ii) We develop a comprehensive approach for relation\nprediction explanation, which enables the provision of ex-\nplanations from multiple paths and multiple perspectives.\n(iii) We assess the performance of KRST on three trans-\nductive and inductive datasets: WN18RR, FB15k-237, and\nNELL-995. KRST obtains significantly better results than\nSOTA models in majority cases (15 of 18).\nRelated Work\nEmbedding-based methods: Such methods (e.g., Com-\nplEx (Trouillon et al. 2017), ConvE (Dettmers et al. 2018),\nand TuckER (Balaevi, Allen, and Hospedales 2019)) gener-\nate embeddings for entities and relations in the latent space.\nScore functions are proposed for training and evaluating\nwithin triplets. The most representative embedding-based\nmethods are the translation methods (e.g., TransE (Bordes\net al. 2013), TransH (Wang et al. 2014), TransR (Lin et al.\n2015), and TransD (Ji et al. 2015)). The key idea behind\nthe translation models is to treat the process of finding valid\ntriplets as the translation operation of entities through rela-\ntionships, define the corresponding score function, and then\nminimize the loss function to learn the representation of en-\ntities and relationships (Chen et al. 2020).\nGNN-based methods: Such methods (e.g.,\nCompGCN (Vashishth et al. 2019) and R-\nGCN (Schlichtkrull et al. 2018)) pass messages between a\nnode and its neighbors. These approaches take advantage\nof the graph connectivity. They are able to deal with\na particular inductive situation where the new entity is\nsurrounded by entities already known. GRAIL (Teru,\nDenis, and Hamilton 2020) is proposed to handle KGs with\nentirely new entities. However, GRAIL is not explainable\nas the author stated in (Teru, Denis, and Hamilton 2020).\nChallenged by the number of reachable entities that grows\nexponentially with the search depth, when given a dense\nKG, GNN-based methods may not well capture the correct\nlong path information and hence may not perform well in\nrelation prediction tasks.\nPath-based methods: Such methods aim to find one (or\nmultiple) logical reasoning path(s) between the query head\nand tail entities. PRA (Lao, Mitchell, and Cohen 2011) and\nAMIE (Gal ´arraga et al. 2013) generate Horn rules (Horn\n1951), which have a broader definition than paths. However,\ndue to noises in real-world KGs, their performance is limited\nbecause they are only applicable for exact matches. Deep-\nPath (Xiong, Hoang, and Wang 2017) and MINERV A (Das\net al. 2017) learn to generate paths by reinforcement learn-\ning, whereby positive rewards are given when having suc-\ncessful target arrivals. These approaches can be applied to\nnew entities and are naturally explainable. Nevertheless,\nthey are also challenged by the exponentially growing reach-\nable entities, which leads to sparse rewards.\nMethods with pre-trained language model:With the great\nsuccess achieved in various NLP tasks, pre-trained language\nmodels (PLMs) (e.g., BERT (Devlin et al. 2018), GPT (Rad-\nford et al. 2018) and XLNet (Yang et al. 2019)) show\ngreat potential in dealing with contextual descriptions. KG-\nBERT (Yao, Mao, and Luo 2019) extends embedding-based\nmethods by fine-tuning BERT. Using contextual descrip-\ntions for entities and relations, BERT model is able to under-\nstand a triplet and output a classification label. KG-BERT\nworks well in inductive settings but is not explainable be-\ncause of the incomprehensible embeddings. Different from\nKG-BERT, BERTRL (Zha, Chen, and Yan 2022) incorpo-\nrates path-based methods with BERT. Specifically, BERTRL\nconverts triplets and the corresponding paths into sentences,\nand fine-tunes the pre-trained BERT for sequence classifi-\ncation. Because BERTRL uses all paths (shorter than L) as\ninputs without filtering, its performance may be limited. Re-\ncently, sentence transformer models is shown to outperform\nBERT on common STS and transfer learning tasks (Reimers\nand Gurevych 2019). In addition, BERT for sequence clas-\nsification requires two sentences to input together and make\nan implicit comparison, while sentence transformer encodes\nsentences separately, allowing more flexible comparisons\namong sentences. In this paper, we adopt sentence trans-\nformer to provide a multi-aspect explanation.\n6534\nPreliminary\nWe start this section by introducing the commonly applied\nlogical reasoning path. Then we introduce the definition and\ncommon settings for inductive relation prediction.\nDefinition 1 (Logical Reasoning Path). Given a KG G =\n{(hi, ri, ti)|i = 1, 2, 3, .., m}, hi, ti ∈ EG and ri ∈ RG,\none possible logical reasoning path p(h, r, t) and the corre-\nsponding relation path Rp(h, r, t) are defined as follows:\np(h, r, t) =h\nr1\n− →e1\nr2\n− →e2\nr3\n− →...\nrn−1\n− − − →en−1\nrn\n− →t, (3)\nRp(h, r, t) = (r1, r2, ..., rn−1, rn), (4)\nwhere (h, r1, e1), ...,(en−1, rn, t)∈ G − {(h, r, t)}.\nFrom the perspective of knowledge graph reasoning, the\nrelation prediction task can be viewed as a logical induc-\ntion problem to identify the inductive and explainable log-\nical reasoning paths. Because logical reasoning paths are\nsequential in nature, we can easily convert them into sen-\ntences. However, a large proportion of paths are either illog-\nical or entity-dependent in real-world KGs, which cannot be\napplied to inductive relation prediction (see Definition 2). To\naddress this problem, we define relation path coverage and\nrelation path confidence to filter out unreliable or meaning-\nless paths (see Definitions 4 and 5, respectively).\nDefinition 2 (Inductive Relation Prediction). Given a\ntraining graph Gtrain(EGtrain , RGtrain ), a testing graph\nGtest(EGtest , RGtest ) and a query triplet (hq, rq, tq), a relation\nprediction is inductive if:\n• EGtrain ∩ EGtest = ∅,\n• RGtest ⊆ RGtrain , rq ∈ RGtrain .\nWith the emergence of real-world ever-evolving KGs,\ndealing with new relations and entities is a necessity. We fo-\ncus on the inductive setting introduced by GRAIL (Teru, De-\nnis, and Hamilton 2020), which contains a training graph, a\ntesting graph, and a series of query triplets. Only the training\ngraph is visible during training. Because both GNN-based\nmethods and path-based methods make use of the graph con-\nnectivity, the test graph is only applied to extract neighbors\nor paths w.r.t query triplets during testing, respectively.\nMethodology\nOur proposed architecture comprises three steps for relation\nprediction, with the intuition that a triplet and its correspond-\ning reliable paths should have similar semantics when con-\nverted to sentences. Specifically, KRST 1) filters unreliable\nlogical reasoning paths extracted for model training, 2) con-\nverts paths and triplets into sentences by sentence formation,\nand 3) measures semantic similarity scores and makes rela-\ntion predictions based on them.\nPath Extraction with Filtering\nFollowing the idea of knowledge reasoning, a logical rea-\nsoning path is determined by its support evidence w.r.t the\ntarget triplet. To train the model with both positive and\nnegative samples, we extract logical reasoning paths from\nKGs for both positive and negative target triplets. However,\nmany extracted paths are unreliable. For example, for pos-\nitive triplet (Sarah, Profession,Actor) and negative triplet\n(Sarah, Profession,Director), we can both extract paths\nwith the same relation path (Gender, Gender-1, Profession)\nas follows:\nSarah Gender− − − − →Female Gender-1\n− − − − − →Kathryn Profession− − − − − − →Actor, (5)\nSarah Gender− − − − →Female Gender-1\n− − − − − →Alyson Profession− − − − − − →Director. (6)\nPaths (5) and (6) are similar and contribute little to dis-\ntinguish the profession. Therefore, we consider paths with\nrelation path (Gender, Gender-1, Profession) to be unreli-\nable. Although the unreliable paths should be excluded from\nmodel training, because they are similar to the target triplet,\nthey may be given a high similarity score and hence mistak-\nenly considered as reliable. For example, another path for\ntriplet (Sarah, Profession,Actor) is as follows:\nSarah\nPerform\n− − − − →SmallSoldiers\nCompany-1\n− − − − − →DreamWorks\nCompany\n− − − − →TheIsland\nPerform-1\n− − − − − →Sean\nProfession\n− − − − − →Actor.\n(7)\nThis path is relatively more reliable than Path (5) because\nit involves the person in the same company for prediction.\nHowever, after being converted to sentences, Path (5) is as-\nsumed to be more similar by PLMs (shorter and contains\nwords in target triplet). Because (Sarah, Profession,Actor)\nis a positive triplet, model training reinforces this bias, lead-\ning to an even higher score for Path (5) after using it for\ntraining. These unreliable paths significantly limit the model\nperformance. To exclude unreliable extracted paths from\ntraining, we perform path filtering. How we identify unre-\nliable logical reasoning paths are introduced as follows.\nDefinition 3 (Relation Path Support). Given a triplet\n(h, r, t) and a relation path Rp′ = (r\n′\n1, r\n′\n2, ..., r\n′\nm−1, r\n′\nm),\nthe support of Rp′ is defined as follows:\nsuppRp′ (h, r, t) = #p(h, r, t), Rp(h, r, t) =Rp′ , (8)\nwhere #p(h, r, t) denotes the number of logical reasoning\npaths on G w.r.t(h, r, t).\nRelation path support suppRp′ (h, r, t) measures the num-\nber of paths containing the same relations with Rp′ between\nh and t. With a larger support score, Rp′ is more common\namong paths between h and t. However, relation path sup-\nport represents an unbounded value. Entity pairs with better\nconnectivity usually have a larger support number. To fur-\nther assess the ratio of the support, we define relation path\ncoverage and relation path confidence, respectively.\nDefinition 4 (Relation Path Coverage). Given a triplet\n(h, r, t) and a relation path Rp′ , the head and tail relation\npath coverage of Rp′ is defined as follows:\ncoverh\nRp′ (h, r, t) =\nsuppRp′ (h, r, t)\n#p(h, r, t\n′\n), |p(h, r, t\n′\n)| = |Rp′ |, (9)\ncovert\nRp′ (h, r, t) =\nsuppRp′ (h, r, t)\n#p(h\n′\n, r, t), |p(h\n′\n, r, t)| = |Rp′ |, (10)\nwhere | · |denotes the length of the path.\n6535\nIn (9) and (10), the number of paths starting from h or\nending at t with length |Rp′ | is adopted as the denominator,\nrespectively.\nDefinition 5 (Relation Path Confidence). Given a triplet\n(h, r, t), the head and tail relation path confidence of a rela-\ntion path Rp′ is defined as follows:\nconfh\nRp′ (h, r, t) =\nsuppRp′ (h, r, t)\nP\nt′∈EG−{h} suppRp′ (h, r, t′), (11)\nconft\nRp′ (h, r, t) =\nsuppRp′ (h, r, t)\nP\nh′∈EG−{t} suppRp′ (h′, r, t). (12)\nIn (11) and (12), the total number of all reachable enti-\nties starting from h or ending at t w.r.t relation path Rp′ is\nadopted as the denominator, respectively.\nRelation path coverage measures the ratio over all paths\nwith the same source (or destination) and length, while re-\nlation path confidence measures the ratio over all entities\nthat satisfy the target relation paths. To show the effective-\nness of relation path confidence, we refer back to Paths (5)\nand (7). The relation path confidence score for Path (7) is\nmuch larger than Path (5). Because in the relation path of\n(Gender, Gender-1, Profession), Gender-1 can lead to mul-\ntiple people with various professions. Therefore, the num-\nber of paths satisfying the relation path of Path (5) is sig-\nnificantly more than that of Path (7), leading to a relatively\nsmaller relation path confidence score for Path (5).\nFor path extraction, we adopt the breadth-first search, with\nthe maximum search depth L and the maximum number of\npaths per triplet M. These parameters are set to avoid the\ngeneration of an unnecessarily large number of paths. Also,\npaths with excessive length are highly likely illogical. In\naddition, to ensure a sufficient number of paths per triplet\nare generated for effective model training, we synchronously\nperform path filtering and path extraction (see Algorithm 1).\nSentence Formation\nTo leverage the pre-trained parameters of the sentence trans-\nformer, KRST converts paths and triplets into sentences. Our\nkey considerations are as follows:\nEntity description selection. Both long (more than 20\nwords on average) and short entity descriptions in text\nare available in various datasets. Long descriptions usually\nmake the sentence description imbalance between entities\nand relations when being modeled by PLMs, hence, they\nare less effective under inductive situations. In addition, sen-\ntences converted using long descriptions usually exceed the\nmaximum sequence length of the PLM, which need to be\ntruncated as incomplete. Therefore, only short descriptions\nare applied to KRST.\nInverse relation. To provide KRST with sequential order\nfor positional encoding, entities’ and relations’ order in the\npaths should be preserved after being converted into sen-\ntences. A straightforward way is to place the descriptions\nfollowing the entities’ and relations’ order in paths. How-\never, inverse relations (e.g., Gender-1 in Path (5)) occur in\nAlgorithm 1: Path Extraction\nInput: KG G, query triplet (h, r, t), filter threshold α, filter\nfunction f(), max search depth L, max number of paths M\nOutput: List of extracted pathsP\n1: // Initialize search queue and state list\n2: q = Queue(); visited = List(); prev = List()\n3: q.push((h, 0))\n4: visited[h] =True\n5: // Breadth-first search\n6: while q is not empty do\n7: u, l= q.pop()\n8: // Check whether search depth exceeds L\n9: if l >= L then\n10: continue\n11: // Give priority to less frequent relations\n12: for v in G[u] sorted by frequency G[u][v][‘relation’]\ndo\n13: if v == t then\n14: if u == h&&G[u][v][‘relation’] ==r then\n15: continue\n16: p =generatePath(prev, h, t)\n17: if f(p) ≥ α then\n18: P.add(p)\n19: else if visited[v] == 0then\n20: q.push((v, l+ 1)); visited(v) = 1; prev(v) =u\n// Early break when generated path is enough\n21: if |P| > Mthen\n22: break\n23: if |P| > Mthen\n24: break\n25: return P\nthe paths and their descriptions are not available. Empiri-\ncally, a systematic description in KG usually starts with de-\nscriptions related to the head entity and ends with descrip-\ntions related to the tail entity. Thus, we choose to use the\ninverse order of words in the sequential relation for inverse\nrelations. Moreover, by doing so, we preserve the similar-\nity between relations and inverse ones, making it easier for\nthe model to understand symmetric relations (e.g., friend,\nspouse, and teammate).\nDescription concatenation. To obtain a complete sentence,\nwe need to concatenate descriptions of entities and rela-\ntions in the path. A natural language pattern makes the sen-\ntence closer to human expressions. An example w.r.t triplet\n(Sarah, Profession,Actor) is shown as follows:\nQuestion:\nSarah Michelle Gellaris the person professionof what?\nIs the correct answer Actor?\nHowever, our preliminary results show that formulating\ncomplete sentences does not yield better performance than\nsimply combining entities and relations together using semi-\ncolons as follows:\nSarah Michelle Gellar; person profession; Actor\nThis is because the latter approach better preserves the se-\nquential order and relative positions in the paths in PLMs.\n6536\n !\"#$%&'()'\n*$#+,#-!\".-\"/\n0-1&,2\n0-1&,!\n   \n'3$4#/1, +5/66$!\"\n0-1&, +5/66$!\",2\n0-1&, +5/66$!\",!\n   \n7893/,2\n7893/,!    :\"\"3/\"-1/6,\n7893/\n7/!1/!8/,*93+-1$9!\n;<7'\n=9%$!/,7$+$#-3$1>\nFigure 2: Overall architecture of relation prediction in KRST.\nTherefore, we choose to use semicolons for description\nconcatenation. For example, the corresponding sentence of\nPath (5) is formulated as follows:\nSarah Michelle Gellar; person gender; Female;\ngender person; Alyson Hannigan; person profession; Actor\nKRST Prediction\nAfter sentence formation, KRST is able to generate em-\nbeddings and make relation predictions. Figure 2 shows the\noverall model architecture.\nFor each positive query triplet, multiple reliable logi-\ncal reasoning paths are extracted correspondingly. After be-\ning formatted into sentences, triplets and the corresponding\npaths have similar semantics, which are measured by the co-\nsine similarity:\ncos(s1, s2) = s1 · s2\n||s1||2 · ||s2||2\n, (13)\nwhere s1 and s2 are the corresponding sentence embeddings.\nKRST extracts at most |M| paths per triplet and converts\npaths and triplets into embeddings. The similarity score be-\ntween each path and the corresponding triplet is computed\nand the path with the highest score is deemed as most rea-\nsonable for relation prediction. Therefore, we use the highest\nscore among all paths as the score for each triplet:\nscore(h, r, t) = max\np∈P\n{cos(s((h, r, t)), s(p))}, (14)\nwhere P denotes the corresponding path set w.r.t triplet\n(h, r, t), and s(·) denotes the embedding function (i.e.,\nKRST) for triplets and paths.\nDuring training, negative triplets are processed with the\nlabel of -1. As aforementioned, commonly applied binary\nloss functions (e.g., cross-entropy and hinge) require the\nnegative scores to be close to -1 (or 0). This is not appro-\npriate in our scenario because the unmatched pair of triplet\nand path are not necessarily perpendicular to each other. To\nrelax the penalty for loss, we use the cosine embedding loss\nfunction:\nL(s1, s2, y) =\n\u001a1 − cos(s1, s2), y = 1,\nmax(0, cos(s1, s2) − margin), y = −1,\n(15)\nwhere margin ∈ (−1, 1) and y ∈ {1,−1} denotes the label.\nEquation 15 makes the positive score to be close to 1, max-\nimizing similar semantics. On the other hand, the negative\nscore is only constrained to be smaller than margin.\nExperiments\nWe evaluate the performance of KRST in three different\nsettings: transductive, inductive, and few-shot. Then, we\ndemonstrate multi-aspect comprehensive explanations by\nclustering the embeddings of paths generated by KRST. We\nimplement KRST1 with a SOTA sentence transformer (all-\nmpnet-base-v22) on a Tesla V100 GPU with 16GB RAM.\nFollowing the evaluation tasks conducted in (Teru, Denis,\nand Hamilton 2020) and (Zha, Chen, and Yan 2022), in this\npaper, we measure the rank and hit rate of one positive triplet\namong 49 negative triplets. We only randomly generate neg-\native triplets and use them for training and validation. For\na fair comparison, we use the negative triplets provided by\n(Zha, Chen, and Yan 2022) for testing.\nDatasets\nTo evaluate the transductive and inductive performance of\nKRST, we use all three datasets adopted in (Zha, Chen,\nand Yan 2022), which were introduced by (Teru, Denis,\nand Hamilton 2020)3. These datasets are commonly adopted\nby various inductive approaches and they are the respective\nsubsets of WN18RR, FB15k-237, and NELL-995. In the in-\nductive setting, training entities have no overlap with testing\nentities.\nFor few-shot evaluation, we use the corresponding few-\nshot transductive and few-shot inductive datasets given in\n(Zha, Chen, and Yan 2022).\nTransductive and Inductive Relation Prediction\nIn transductive cases, we extract paths in the training graph\nfor all training, validation, and testing triplets. However, in\ninductive cases, paths for testing triplets are not available\nfrom the training graph, because entities used for testing\ndo not appear in the training graph (see Definition 2). In-\nstead, we use the inductive graphs given in (Teru, Denis, and\nHamilton 2020) for path extraction.\nWe benchmark the performance of KRST against SOTA\ninductive methods, SOTA embedding-based methods, and\nSOTA reinforcement learning methods. Table 1 shows the\nresults of transductive and inductive relation prediction.\nCompared with SOTA methods, KRST methods achieve the\n1github.com/ZhixiangSu/KRST\n2huggingface.co/sentence-transformers/all-mpnet-base-v2\n3github.com/kkteru/grail\n6537\nTransductive Inductive\nWN18RR FB15k-237 NELL-995 WN18RR FB15k-237 NELL-995\nMRR RuleN 0.669 0.674 0.736 0.780 0.462 0.710\nGRAIL 0.676 0.597 0.727 0.799 0.469 0.675\nMINERV A 0.656 0.572 0.592 - - -\nTuckER 0.646 0.682 0.800 - - -\nKG-BERT - - - 0.547 0.500 0.419\nBERTRL 0.683 0.695 0.781 0.792 0.605 0.808\nKRST (No filter) 0.881 0.671 0.730 0.883 0.713 0.753\nKRST (Coverage) 0.897 0.709 0.803 0.902 0.704 0.696\nKRST (Confidence) 0.899 0.720 0.800 0.890 0.716 0.769\nHit@1 RuleN 0.646 0.603 0.636 0.745 0.415 0.638\nGRAIL 0.644 0.494 0.615 0.769 0.390 0.554\nMINERV A 0.632 0.534 0.553 - - -\nTuckER 0.600 0.615 0.729 - - -\nKG-BERT - - - 0.436 0.341 0.244\nBERTRL 0.655 0.620 0.686 0.755 0.541 0.715\nKRST (No filter) 0.807 0.576 0.618 0.803 0.602 0.633\nKRST (Coverage) 0.831 0.624 0.692 0.835 0.573 0.554\nKRST (Confidence) 0.835 0.639 0.694 0.809 0.600 0.649\nTable 1: Transductive and inductive relation prediction results\nTransductive Inductive\nWN18RR FB15k-237 NELL-995 WN18RR FB15k-237 NELL-995\n1000 2000 1000 2000 1000 2000 1000 2000 1000 2000 1000 2000\nMRR RuleN 0.567 0.625 0.434 0.577 0.453 0.609 0.681 0.773 0.236 0.383 0.334 0.495\nGRAIL 0.588 0.673 0.375 0.453 0.292 0.436 0.652 0.799 0.380 0.432 0.458 0.462\nMINERV A 0.125 0.268 0.198 0.364 0.182 0.322 - - - - - -\nTuckER 0.258 0.448 0.457 0.601 0.436 0.577 - - - - - -\nKG-BERT - - - - - - 0.471 0.525 0.431 0.460 0.406 0.406\nBERTRL 0.662 0.673 0.618 0.667 0.648 0.693 0.765 0.777 0.526 0.565 0.736 0.744\nKRST (Confidence) 0.871 0.882 0.696 0.701 0.743 0.781 0.886 0.878 0.679 0.680 0.745 0.738\nHit@1 RuleN 0.548 0.605 0.374 0.508 0.365 0.501 0.649 0.737 0.207 0.344 0.282 0.418\nGRAIL 0.489 0.633 0.267 0.352 0.198 0.342 0.516 0.769 0.273 0.351 0.295 0.298\nMINERV A 0.106 0.248 0.170 0.324 0.152 0.284 - - - - - -\nTuckER 0.230 0.415 0.407 0.529 0.392 0.520 - - - - - -\nKG-BERT - - - - - - 0.364 0.404 0.288 0.317 0.236 0.236\nBERTRL 0.621 0.637 0.517 0.583 0.526 0.582 0.713 0.731 0.441 0.493 0.622 0.628\nKRST (Confidence) 0.790 0.810 0.611 0.602 0.628 0.678 0.811 0.793 0.537 0.524 0.637 0.629\nTable 2: Few-shot transductive and inductive relation prediction results\nbest performance under MRR (5 of 6) and Hit@1 (4 of 6)\nmetrics. Specifically, KRST methods achieve significant im-\nprovement in the transductive case of WN18RR (+0.216 for\nMRR and +18.0% for Hit@1), inductive case of WN18RR\n(+0.103 for MRR and +6.6% for Hit@1) and inductive case\nof FB15k-237 (+0.111 for MRR and +5.9% for Hit@1).\nAmong KRST methods, the majority of the best results\nare achieved by KRST with relation path confidence (8 of\n12). Only in 1 of 12 cases, KRST with no filter performs the\nbest. So we empirically show that filtering (especially re-\nlation path confidence) elevates model performance. As for\nthe relatively inferior performance of relation path coverage,\nthis is because long paths usually lead to exponentially in-\ncreasing numbers of reachable entities, making the relation\npath coverage prefer shorter paths. However, short paths are\nnot necessarily reliable. Therefore, the performance is lim-\nited by unreliable paths unfiltered by relation path coverage.\nFew-shot Relation Prediction\nIn the few-shot settings, wherein only subsets of the en-\ntire datasets are given for training, we conduct similar path\nextractions as done for the entire datasets. Specifically, for\ntransductive cases, training, validation, and testing paths are\nall extracted from the entire training graph. For inductive\ncases, paths for inductive training are extracted from the en-\ntire training graph, while paths for inductive validation and\ninductive testing are both extracted from the inductive graph.\nBecause KRST with relation path confidence achieves the\nbest performance on the entire datasets, we apply it for all\nfew-shot settings. As shown in Table 2, KRST with rela-\ntion path confidence outperforms SOTA methods in 11 of 12\ncases. The average transductive and inductive improvement\nfor MRR and Hit@1 is 0.119 and 0.082 (+3.1% and +5.0%),\nrespectively. In addition, the performance gap between few-\n6538\n(a) Clusters for triplet (Atlantic\nCity, Film Genre, Drama).\n(b) Clusters for triplet (California,\nLocation Contain, Carlsbad).\n(c) Clusters for triplet (Kelsey,\nPerson Language, English).\nFigure 3: Clustering result for a multi-aspect explanation.\n  !\" #\n$%&'()*+ \n$%\n&'()*+#\n$%&'()*+,\n$%&'()*+-\n !\"#$!%&'(%!)\n*+!,\"%-'.+$/+01\n2/#3#\n 4#/5'67/801\n*9:((  4#/5'67/8 ;#<%$<'=>\"\" :%\"3'.+$/+ 2/#3#\n:%\"3'.+$/+\n?>@%&#\"\n*+!,\"%-'.+$/+01\n2/#3#\n*73%$#!+':7/01 =>/!'\nA#$&#@!+/\n 4#/5'*73%$++ = :B *73%$#!+5':7/  C7>!'\nD&E3%5!\n:%\"3'(7>$!/)\n:/#$&+ BE+'(\"+#/%$<\n*+!,\"%-'.+$/+01\n2/#3#\n:%\"3'A#$<>#<+\nF$<\"%@E 6++5@ 2/#3#\n*73%$#!+5':7/01\n= :B *73%$#!+5':7/ =#C+\" *+!,\"%-'.+$/+01\n2/#3#\n2/#3#\nG*7'H#!EI\n*+!,\"%-'.+$/+01\nH/7</#3'.+$/+H/7</#3'A#$<>#<+01\n;+\"+#@+';+<%7$01\n*+!,\"%-'.+$/+\n(7#\"'?%$+/J@'2#><E!+/\nFigure 4: Paths clustered by similarity scores for a multi-aspect explanation of triplet (Atlantic City, Film Genre, Drama).\nshot-1000 and few-shot-2000 samples is small (smaller than\n0.015 for MRR in 5 of 6 cases). These results illustrate the\nstrong generalization capability of KRST, which requires a\nlesser amount of samples to achieve on-par performance.\nMulti-Aspect Explanation\nAs afore-introduced, KRST is able to provide a multi-aspect\nexplanation of the relation prediction results. This is because\nKRST generates an embedding for each path, allowing us\nto quantifiably analyze the relations among paths. Although\npaths are supposed to be similar to the given query triplet,\nthey are not necessarily similar to each other. By grouping\nthem into different clusters, we could provide a multi-aspect\ncomprehensive explanation.\nFigure 3 visualizes the clustering results on the reduced\ndimensions after applying Linear Discriminant Analysis\n(LDA) for three different triplets. Clusters are generated\nusing the K-Means algorithm. As shown in Figures 3(a)\nand 4, KRST successfully provides a multi-aspect explana-\ntion for triplet (AtlanticCity, FilmGenre,Drama) based on\nthe similarity score (pre-processed after min-max scaling).\nThe paths grouped into each cluster are shown in Figure 4\nand presented using the same color in Figure 3(a). As shown,\nthe only path in Cluster 3 illustrates the explanation provided\nby the external knowledge from Netflix thatAtlanticCity is a\nDrama available on Netflix. This explanation is straightfor-\nward and convincing, and is considered to be the most reli-\nable (score of 1.0). For paths in Clusters 2, explanations are\nprovided using similar films with the same attributes (e.g.,\nlanguage and country), which is similar to the human ana-\nlogical reasoning. Cluster 0 explains the target triplet us-\ning the knowledge of awards won or nominated regarding\nAtlanticCity in three paths, which is a distinctive piece of\nside information. KRST considers Clusters 2 and 0 as rel-\natively less convincing and assigns relatively lower scores\n(0.837 and 0.593 on average, respectively). We also input\nan empty path for comparison, which individually consti-\ntutes Cluster 1. KRST correctly gives it the lowest similarity\nscore. In summary, based on Figure 4, we can easily per-\nceive different explanations in the corresponding aspects of\nNetflix platform, similar films, and awards.\nConclusion\nIn this paper, we propose a novel architecture named KRST\nwhich outperforms SOTA models in most transductive and\ninductive relation prediction tasks (15 of 18). In addition, we\nperform clustering on KRST generated embeddings and pro-\nvide a comprehensive multi-aspect explanation. Nonethe-\nless, KRST is a model based on BERT, which requires rela-\ntively large memory usage and computational resources. Go-\ning forward, we plan to solve this computational intensive\nissue by proposing a more parameter-efficient model.\n6539\nAcknowledgements\nThis research is supported, in part, by the Joint SDU-NTU\nCentre for Artificial Intelligence Research (C-FAIR), Shan-\ndong University, China and by the Joint NTU-WeBank\nResearch Centre on Fintech (Award No: NWJ-2020-010),\nNanyang Technological University, Singapore. This re-\nsearch is also supported, in part, by the National Research\nFoundation, Prime Minister’s Office, Singapore under its\nNRF Investigatorship Programme (NRFI Award No. NRF-\nNRFI05-2019-0002). Any opinions, findings and conclu-\nsions or recommendations expressed in this material are\nthose of the authors and do not reflect the views of Na-\ntional Research Foundation, Singapore. This work is also\nsupported, in part, by the National Key R&D Program of\nChina No.2021YFF0900800; NSFC No.91846205; Shan-\ndong Provincial Key Research and Development Program\n(Major Scientific and Technological Innovation Project)\n(NO.2021CXGC010108).\nReferences\nBalaevi, I.; Allen, C.; and Hospedales, T. M. 2019. Tucker:\nTensor factorization for knowledge graph completion.arXiv\npreprint arXiv:1901.09590.\nBordes, A.; Usunier, N.; Garcia-Duran, A.; Weston, J.; and\nYakhnenko, O. 2013. Translating embeddings for modeling\nmulti-relational data. In Proceedings of Advances in Neural\nInformation Processing Systems, 27872795.\nChen, Z.; Wang, Y .; Zhao, B.; Cheng, J.; Zhao, X.; and\nDuan, Z. 2020. Knowledge graph completion: A review.\nIEEE Access, 8: 192435–192456.\nDas, R.; Dhuliawala, S.; Zaheer, M.; Vilnis, L.; Durugkar, I.;\nKrishnamurthy, A.; Smola, A.; and McCallum, A. 2017. Go\nfor a walk and arrive at the answer: Reasoning over paths\nin knowledge bases using reinforcement learning. arXiv\npreprint arXiv:1711.05851.\nDettmers, T.; Minervini, P.; Stenetorp, P.; and Riedel, S.\n2018. Convolutional 2d knowledge graph embeddings. In\nProceedings of the AAAI Conference on Artificial Intelli-\ngence, 1811–1819.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2018.\nBert: Pre-training of deep bidirectional transformers for lan-\nguage understanding. arXiv preprint arXiv:1810.04805.\nGal´arraga, L. A.; Teflioudi, C.; Hose, K.; and Suchanek, F.\n2013. AMIE: association rule mining under incomplete ev-\nidence in ontological knowledge bases. In Proceedings of\nthe International Conference on World Wide Web, 413–422.\nHorn, A. 1951. On sentences which are true of direct unions\nof algebras1. The Journal of Symbolic Logic, 14–21.\nJi, G.; He, S.; Xu, L.; Liu, K.; and Zhao, J. 2015. Knowledge\ngraph embedding via dynamic mapping matrix. In Proceed-\nings of the Annual Meeting of the Association for Computa-\ntional Linguistics and the International Joint Conference on\nNatural Language Processing, 687–696.\nJi, S.; Pan, S.; Cambria, E.; Marttinen, P.; and Philip, S. Y .\n2021. A survey on knowledge graphs: Representation, ac-\nquisition, and applications. IEEE Transactions on Neural\nNetworks and Learning Systems, 494–514.\nLao, N.; Mitchell, T.; and Cohen, W. 2011. Random walk in-\nference and learning in a large scale knowledge base. InPro-\nceedings of the Conference on Empirical Methods in Natural\nLanguage Processing, 529–539.\nLin, Y .; Liu, Z.; Sun, M.; Liu, Y .; and Zhu, X. 2015. Learn-\ning entity and relation embeddings for knowledge graph\ncompletion. In Proceedings of AAAI Conference on Arti-\nficial Intelligence, 2181–2187.\nRadford, A.; Narasimhan, K.; Salimans, T.; and Sutskever, I.\n2018. Improving language understanding by generative pre-\ntraining. https://openai.com/blog/language-unsupervised/.\nAccessed 2023-03-17.\nReimers, N.; and Gurevych, I. 2019. Sentence-BERT:\nSentence embeddings using siamese bert-networks. arXiv\npreprint arXiv:1908.10084.\nSchlichtkrull, M.; Kipf, T. N.; Bloem, P.; Berg, R. v. d.;\nTitov, I.; and Welling, M. 2018. Modeling relational data\nwith graph convolutional networks. In Proceedings of Euro-\npean Semantic Web Conference, 593–607.\nTeru, K.; Denis, E.; and Hamilton, W. 2020. Inductive rela-\ntion prediction by subgraph reasoning. InProceedings of In-\nternational Conference on Machine Learning, 9448–9457.\nTrouillon, T.; Dance, C. R.; Welbl, J.; Riedel, S.; Gaussier,\n.; and Bouchard, G. 2017. Knowledge graph comple-\ntion via complex tensor factorization. arXiv preprint\narXiv:1702.06879.\nVashishth, S.; Sanyal, S.; Nitin, V .; and Talukdar, P.\n2019. Composition-based multi-relational graph convolu-\ntional networks. arXiv preprint arXiv:1911.03082.\nWang, Z.; Zhang, J.; Feng, J.; and Chen, Z. 2014. Knowl-\nedge graph embedding by translating on hyperplanes. In\nProceedings of the AAAI Conference on Artificial Intelli-\ngence, 1112–1119.\nXiong, W.; Hoang, T.; and Wang, W. Y . 2017. DeepPath: A\nreinforcement learning method for knowledge graph reason-\ning. arXiv preprint arXiv:1707.06690.\nYang, Z.; Dai, Z.; Yang, Y .; Carbonell, J.; Salakhutdinov,\nR. R.; and Le, Q. V . 2019. XLNet: Generalized autoregres-\nsive pretraining for language understanding. In Proceed-\nings of Advances in Neural Information Processing Systems,\n57535763.\nYao, L.; Mao, C.; and Luo, Y . 2019. KG-BERT:\nBERT for knowledge graph completion. arXiv preprint\narXiv:1909.03193.\nZha, H.; Chen, Z.; and Yan, X. 2022. Inductive relation pre-\ndiction by BERT. In Proceedings of the AAAI Conference\non Artificial Intelligence, 5923–5931.\n6540",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7146716117858887
    },
    {
      "name": "Relation (database)",
      "score": 0.7041299343109131
    },
    {
      "name": "Transformer",
      "score": 0.6934311985969543
    },
    {
      "name": "ENCODE",
      "score": 0.6190296411514282
    },
    {
      "name": "Sentence",
      "score": 0.5995426177978516
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5671581029891968
    },
    {
      "name": "Path (computing)",
      "score": 0.5463980436325073
    },
    {
      "name": "Inductive reasoning",
      "score": 0.5311374068260193
    },
    {
      "name": "Machine learning",
      "score": 0.4157390296459198
    },
    {
      "name": "Natural language processing",
      "score": 0.4057421088218689
    },
    {
      "name": "Data mining",
      "score": 0.2181946337223053
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I154099455",
      "name": "Shandong University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I172675005",
      "name": "Nanyang Technological University",
      "country": "SG"
    }
  ],
  "cited_by": 9
}