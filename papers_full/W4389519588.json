{
  "title": "MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations",
  "url": "https://openalex.org/W4389519588",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2989693568",
      "name": "Arkil Patel",
      "affiliations": [
        "University of Oxford",
        "McGill University"
      ]
    },
    {
      "id": "https://openalex.org/A2887141342",
      "name": "Satwik Bhattamishra",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2169793708",
      "name": "Siva Reddy",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2509101809",
      "name": "Dzmitry Bahdanau",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2897513296",
    "https://openalex.org/W4287755175",
    "https://openalex.org/W4385573248",
    "https://openalex.org/W3127593076",
    "https://openalex.org/W2971079754",
    "https://openalex.org/W4288331674",
    "https://openalex.org/W3100268441",
    "https://openalex.org/W3035331128",
    "https://openalex.org/W2890431379",
    "https://openalex.org/W4301259831",
    "https://openalex.org/W3175473034",
    "https://openalex.org/W2133564696",
    "https://openalex.org/W1699946128",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4287332702",
    "https://openalex.org/W2564823089",
    "https://openalex.org/W4385570730",
    "https://openalex.org/W3098135552",
    "https://openalex.org/W4285221130",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3105184673",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W3177023643",
    "https://openalex.org/W3177813494",
    "https://openalex.org/W4385572634",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2885851150",
    "https://openalex.org/W4386566858",
    "https://openalex.org/W3177474387",
    "https://openalex.org/W2092239795",
    "https://openalex.org/W1514897281",
    "https://openalex.org/W2996346899",
    "https://openalex.org/W4226053975",
    "https://openalex.org/W3104739822",
    "https://openalex.org/W4295312788",
    "https://openalex.org/W2962847482",
    "https://openalex.org/W4298187912",
    "https://openalex.org/W4385572825",
    "https://openalex.org/W4287113019",
    "https://openalex.org/W3102020135",
    "https://openalex.org/W3105725479",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W4285131076",
    "https://openalex.org/W2996132992",
    "https://openalex.org/W4253001367",
    "https://openalex.org/W4375869868",
    "https://openalex.org/W2950170241",
    "https://openalex.org/W3174896143",
    "https://openalex.org/W4376167329",
    "https://openalex.org/W2765159719",
    "https://openalex.org/W3170978252",
    "https://openalex.org/W4322718191"
  ],
  "abstract": "Humans possess a remarkable ability to assign novel interpretations to linguistic expressions, enabling them to learn new words and understand community-specific connotations. However, Large Language Models (LLMs) have a knowledge cutoff and are costly to finetune repeatedly. Therefore, it is crucial for LLMs to learn novel interpretations in-context. In this paper, we systematically analyse the ability of LLMs to acquire novel interpretations using in-context learning. To facilitate our study, we introduce MAGNIFICo, an evaluation suite implemented within a text-to-SQL semantic parsing framework that incorporates diverse tokens and prompt settings to simulate real-world complexity. Experimental results on MAGNIFICo demonstrate that LLMs exhibit a surprisingly robust capacity for comprehending novel interpretations from natural language descriptions as well as from discussions within long conversations. Nevertheless, our findings also highlight the need for further improvements, particularly when interpreting unfamiliar words or when composing multiple novel interpretations simultaneously in the same example. Additionally, our analysis uncovers the semantic predispositions in LLMs and reveals the impact of recency bias for information presented in long contexts.",
  "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 2167–2189\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nMAGNIFIC O: Evaluating the In-Context Learning Ability of Large\nLanguage Models to Generalize to Novel Interpretations\nArkil PatelkSatwik BhattamishranSiva ReddykqrDzmitry Bahdanaukqb\nkMila and McGill University qServiceNow Research nUniversity of Oxford\nrFacebook CIFAR AI Chair bCanada CIFAR AI Chair\n{arkil.patel, siva.reddy, bahdanau}@mila.quebec satwik.bmishra@cs.ox.ac.uk\nAbstract\nHumans possess a remarkable ability to assign\nnovel interpretations to linguistic expressions,\nenabling them to learn new words and under-\nstand community-specific connotations. How-\never, Large Language Models (LLMs) have a\nknowledge cutoff and are costly to finetune re-\npeatedly. Therefore, it is crucial for LLMs to\nlearn novel interpretations in-context. In this\npaper, we systematically analyse the ability of\nLLMs to acquire novel interpretations using in-\ncontext learning. To facilitate our study, we in-\ntroduce MAGNIFIC O, an evaluation suite im-\nplemented within a text-to-SQL semantic pars-\ning framework that incorporates diverse tokens\nand prompt settings to simulate real-world com-\nplexity. Experimental results on MAGNIFIC O\ndemonstrate that LLMs exhibit a surprisingly\nrobust capacity for comprehending novel inter-\npretations from natural language descriptions\nas well as from discussions within long conver-\nsations. Nevertheless, our findings also high-\nlight the need for further improvements, partic-\nularly when interpreting unfamiliar words or\nwhen composing multiple novel interpretations\nsimultaneously in the same example. Addition-\nally, our analysis uncovers the semantic predis-\npositions in LLMs and reveals the impact of\nrecency bias for information presented in long\ncontexts.\n1 Introduction\nHumans can assign new interpretations to words or\nphrases in a language and consequently use them\ncompositionally in utterances. For instance, the\nword ‘zoom’ is increasingly used to refer to a vir-\ntual calling service in the context of the COVID-19\npandemic. Similarly, as our society progresses,\nnew words such as ‘ binge-watching’ and ‘ selfie’\nkeep getting coined frequently and become a part\nof our daily usage. Moreover, in regular conversa-\ntions, people might assign custom interpretations\nto words or phrases (e.g., see the interpretation of\n‘underpaid’ in Figure 2). The question of whether\nNovel \ninterpretation\nSQL Output\n“P la y er  who has \nr ec eiv ed a y ello w  car d”\nH o w  man y  pla y er s  ha v e \nmor e than 1000 hour s o f  tr aining?\nwith a y ello w  car d\nbase form\nplausible form\nforeign form\nadversarial form\nH o w  man y   pla y er s ha v e mor e than \n1000 hour s o f  tr aining?\ngiwzle\nH o w  man y   pla y er s ha v e mor e than \n1000 hour s o f  tr aining?\nmeek\nH o w  man y   pla y er s ha v e mor e \nthan 1000 hour s o f  tr aining?\naggr essiv e\nSELECT COUNT(*) FROM player WHERE \nhs > 1000 AND ycard = ‘yes’ MODEL\nFigure 1: An example from MAGNIFIC O illustrating\na novel interpretation denoted by plausible, foreign, and\nadversarial forms. The corresponding base example is\nalso provided.\nlanguage models are similarly capable of assign-\ning novel interpretations to words and phrases is\ntherefore interesting and requires investigation.\nThe task of learning novel interpretations has\npredominantly been studied from the perspective\nof finetuning a model, particularly the word em-\nbeddings, to acquire novel words during training\n(Lampinen and McClelland, 2017; Pham et al.,\n2018; Schick and Schütze, 2019). Prior studies\non compositional generalization (Lake and Baroni,\n2018; Kim and Linzen, 2020) also attempt to eval-\nuate novel word learning using specially crafted\ntrain-test splits in which certain combinations of\nwords are systematically held out from the test\nset. In recent years, however, contemporary Large\nLanguage Models (LLMs) have brought about a\nparadigm shift away from the classical train-test\nsetup with their incredible capacity to learn new\ntasks in-context (Brown et al., 2020). With this\nstudy, we seek to understand how well can LLMs\nacquire novel interpretations in-context. Compared\nto previous setups, in-context learning (ICL) is also\nmore practical since it is difficult to train models\nevery time a new interpretation is encountered.\n2167\nFind the unique job ids from the \nemployee's job history when \n is more than 3 and start \ndate was after 1st January 1994.\ntenure\nSELECT DISTINCT \njob_id FROM \njob_history WHERE \n > 3 AND \nstart_date > \n'1994-01-01'\nend_date - \nstart_date\nThe word  refers to the \nduration of employment as \nmeasured in years. It is \ncalculated by taking the \ndif ference between the end date \nand the start date.\n‘tenure’\nI think many of the instructors in the \ndepartment are . underpaid\nWho are the  instructors in \nthe Computer Science department?\nunderpaid\nW ell, I consider someone to be \n if they \n.\nunderpaid earn less than \n100,000\nReally? How do you determine if \nsomeone is ? underpaid\nSELECT name FROM instructor \nWHERE dept_name = ‘Comp. \nSci.’ AND ; salary < 100000\nWhich major has  number of students? runner-up\nSELECT major FROM ( SELECT major ,  CO U NT (*)  AS \nt_prop FROM student G RO UP  BY  major \n)  AS t_tab  \nt_tab.t_prop \nORDER  BY  \nCOUNT(*)  DESC  LIMIT  2 ORDER  BY\nLIMIT  1\nWhich ad v isor has  number of students? runner-up\nSELECT ad v isor FROM ( SELECT ad v isor ,  CO U NT (*)  AS t_prop \nFROM student G RO UP  BY  ad v isor \n)  AS t_tab  t_tab.t_prop \nORDER  BY  COUNT(*)  DESC  \nLIMIT  2 ORDER  BY LIMIT  1\nShow the account id with  number of transactions. runner-up\nSELECT account_id FROM ( SELECT account_id ,  CO U NT (*)  AS \nt_prop FROM f inancia l _transactions G RO UP  BY  account_id \n)  AS t_tab  \nt_tab.t_prop \nORDER  BY  COUNT(*)  DESC  LIMIT  2 ORDER  BY\nLIMIT  1\nNatur al L an gua ge \nDescr iption F e w - Sh ot E x amples Dialogue\nFigure 2: We consider several scenarios of how a novel interpretation can be introduced in the prompt. Left: A\nnatural language description of the novel interpretation ‘tenure’ is provided with the question. Centre: Few-shot\nexamples illustrating usage of the novel interpretation ‘runner-up’ are provided with the question. Right: Dialogue\ncontext describing the novel interpretation ‘underpaid’ is provided with the question.\nIn this work, we systematically analyse the abil-\nity of LLMs to in-context learn novel interpreta-\ntions. We summarize our contributions below.\nEvaluation Suite. To facilitate our analysis,\nwe create an evaluation suite, MAGNIFIC O:\nMeasuring Adaptability and Generalization to\nNovel Interpretations For In-Context Learning.\nEach example in MAGNIFIC O is a text-to-SQL\nsemantic parsing problem that requires models to\nunderstand one or more novel interpretations used\nin the input text to generate the correct SQL query.\nTo simulate real-world diversity and complexity,\nwe experiment with different ways of introducing\nnew interpretations to the model (see Figure 2).\nCapabilities of LLMs.We extensively experi-\nment with 11 LLMs to understand their ability for\nlearning novel interpretations in-context. Experi-\nments on MAGNIFIC O reveal that LLMs show\na high degree of capability in learning novel in-\nterpretations even from a brief natural language\ndescription of the interpretation or from a long-\nform conversation. For larger LMs, learning from\na description is competitive to providing explicit\nfew-shot examples.\nChallenges for LLMs. We find that LLMs\nseverely fail at learning multiple novel interpre-\ntations simultaneously. Moreover, we observed\nthat LLMs find it more challenging to learn inter-\npretations for unfamiliar words. Our analysis also\nshows that LLMs have a recency bias and might\nfind it difficult to learn interpretations presented\nearlier in the context.\n2 Related Work\nWord Learning. Previous works (Wang et al.,\n2017; Herbelot and Vecchi, 2016; Lampinen and\nMcClelland, 2017; Pham et al., 2018; Schick and\nSchütze, 2019) have developed task- or model-\nspecific approaches for learning the embeddings\nof novel words. However, these methods cannot\nbe applied in diverse scenarios with contemporary\nLarge Language Models (LLMs). In this work, we\ntake a more practical approach by evaluating how\nwell do LLMs understand novel interpretations of\nwords and phrases in-context on top of a grounded\nNLP task, text-to-SQL semantic parsing.\nThere are a limited number of works that analyse\nthe novel word learning abilities of LLMs. Haley\n(2020) and Thrush et al. (2020) analysed novel\nword learning with BERT (Devlin et al., 2019) us-\ning synthetic tests. However, it is unclear how their\nfindings relate to autoregressive LLMs. Brown et al.\n(2020) qualitatively tested GPT-3’s ability to use a\nnovel word in a sentence after seeing its definition.\nEisenschlos et al. (2023) analyse the in-context\nword learning abilities of LLMs using a synthetic\nco-reference resolution task. In this paper, however,\nwe work on a more practical task and take a broader\nview of the problem by studying the acquisition of\nnovel interpretations, which can arise even from\n2168\nCATEGORY INTERPRETATION EXAMPLES\nBasic Operations Minimum Input: What are the name, latitude, and city of the station with the baseline latitude?\nOutput: SELECT name, lat, city FROM station ORDER BY lat LIMIT 1\nSubquery-based Operations Most-frequent\nInput: Display the sex and first name of students with the prevalent major.\nOutput: SELECT Sex, Fname FROM Student WHERE Major IN (SELECT Major FROM\nStudent GROUP BY Major ORDER BY COUNT(*) DESC LIMIT 1)\nValue-based Filtering 4 credit courses Input: List the names of all heavy courses ordered by their titles and credits.\nOutput: SELECT title FROM course WHERE credits = 4 ORDER BY title, credits\nColumn Operations Concatenation of last and\nfirst name\nInput: How many students are there with ‘gE’ in alias?\nOutput: SELECT COUNT(*) FROM student WHERE lname || fname LIKE ‘%gE%’\nTable 1: Examples of novel interpretations in MAGNIFIC O. Illustrated examples use a plausible English form.\nexisting words and phrases in the vocabulary. We\nalso study compositional generalization of multiple\nnovel interpretations simultaneously.\nCompositional Generalization.Recent works\n(Lake and Baroni, 2018; Kim and Linzen, 2020;\nKeysers et al., 2020) proposed benchmarks with\na systematic difference between the train and test\nsets: novel combinations of certain words are held\nout from the train set. However, such evaluation\nsetups are susceptible to fairness issues (Sikarwar\net al., 2022) arising from the dependence on a train\nset. Moreover, model-independent factors in the\ntrain set can influence generalization performance\n(Patel et al., 2022). Our evaluation framework is set\nwithin the paradigm of in-context learning (ICL),\nwhich does not require the creation of an explicit\ntrain set. Note that even in ICL settings, LLMs\nhave saturated existing compositional generaliza-\ntion benchmarks (Drozdov et al., 2023). More re-\ncently, An et al. (2023) proposed a new benchmark,\nCOFE, for in-context compositional generalization.\nHowever, their focus was on understanding the fac-\ntors affecting better selection of in-context exam-\nples for compositional generalization. Moreover,\nthe examples in COFE are based on another syn-\nthetic benchmark, while we focus on more realistic\nsettings using a grounded text-to-SQL task.\nKnowledge-intensive text-to-SQL.Works on\nknowledge-intensive text-to-SQL (Li et al., 2023a;\nLee et al., 2021; Zhao et al., 2022; Dou et al., 2022)\nhave some similarities with our work in that they as-\nsign schema-specific external knowledge to words\nor phrases in the input query. However, our in-\nterpretations are much more dynamic and do not\nhave pre-defined formal definitions. Moreover, the\nfocus of these works is on domain generalization\nfor text-to-SQL semantic parsing. We only use\ntext-to-SQL as a testbed since it allows us to more\nformally ground meanings of interpretations and\nhas real-world applicability.\n3 MAGNIFIC O\nWe choose the text-to-SQL task to test LLMs’ abil-\nity to handle novel interpretations because of its rel-\nevance to real-world applications. Moreover, con-\ntemporary LLMs already achieve good zero/few-\nshot in-context performance on the task. We cre-\nate MAGNIFIC O by modifying and re-tasking\nexamples from an existing text-to-SQL benchmark,\nSpider (Yu et al., 2018). Below, we describe the\nprocedure in detail.\n3.1 Novel Interpretations\nWe define a set of 24 interpretations that are ei-\nther already being used or can be introduced in the\nexamples of Spider:\n⋆ Basic operations: Standard column operations\nfrequently used in SQL queries.\n⋆ Subquery-based operations: Complex opera-\ntions using nested subqueries.\n⋆ Value-based filtering: Particular subset of val-\nues for specific columns.\n⋆ Column operations: Operations performed\nover specific columns.\nTable 1 provides examples of some of the inter-\npretations that we defined. We will refer to the\nword or phrase used to denote the novel interpreta-\ntion on the source side of the example as its form.\nWe defined 18 interpretations denoted by a sin-\ngle word form and 6 interpretations denoted by a\nphrase form (see Figure 3 for an illustration). The\nfull list of all interpretations can be found in Tables\n4 and 5 in the Appendix. For the 18 interpretations\ndenoted by a single word, we experiment with three\ntypes of forms that vary in their pre-existing seman-\ntic meaning: (1) plausible forms are words that can\n2169\nP hr ase f orm\nM ultiple no v el in t erpr e ta tions\nList the names o f   who ne v er  \nt ook an y  appoin tmen t.\nboar d-c ertified and lic ensed P h y sicians\nSELECT name FROM physician EXCEPT SELECT t2.name FROM \nappointment AS t1 JOIN physicianAS t2 ON t1.physician \n= t2.employeeid WHERE position NOT IN (’Staff \nInternist’)\nW hich is the  departmen t with the  major? pur e-scienc e pr e v alen t\nSELECT dept_name FROM student  major  \nmajor FROM student \n  major \n)\nWHERE IN (SELECT\nGROUP BY ORDER BY COUNT(*) DESC \nLIMIT 1\nWHERE dept_name IN ('Physics', \n'Biology')\nFigure 3: Illustrations of examples with phrase form\nand multiple novel interpretations in MAGNIFIC O.\nreasonably be expected to represent the novel in-\nterpretation in realistic scenarios, (2) foreign forms\nare novel words without any pre-defined meaning\nthat are generated using a random permutation of\nEnglish characters, and (3) adversarial forms are\nwords with an existing meaning that is contrary\nto the intent expressed by the novel interpretation.\nFigure 1 illustrates the three types of forms in an\nexample from MAGNIFIC O.\n3.2 Generating Data\nWe create MAGNIFIC O examples by modifying\nexamples in the Spider dataset such that understand-\ning a novel interpretation1 used in the input is nec-\nessary to successfully generate the corresponding\nSQL query. We will refer to the original examples\nfrom Spider as seed examples. For each interpre-\ntation, we generate data using one or more of the\nfollowing methods:\n(1) Regex-based pattern matching.Some inter-\npretations such as ‘the minimum value’ (see Table\n1) already have examples existing in Spider. For\nsuch interpretations, we find the relevant seed ex-\namples using regex-based pattern matching, either\non the source side by conditioning on the presence\nof certain keywords such as minimum or lowest or\non the target side by conditioning on operations\nsuch as min(). We then modify the seed examples\nto include the form of the interpretation in the input\nand inculcate the corresponding logic in the target\nSQL query using specific rules, if required. An\nillustration of this process is shown in Figure 4.\n(2) LLM-assisted constrained paraphrasing.\nFor many interpretations, it is not possible to manu-\nally devise rules for modifying the natural language\n1We experiment with different types of prompt contexts\nfor explaining the novel interpretation, detailed in §4.\nShow ids for all employees who \ndon't have a certificate.\nSELECT eid FROM employee \nEXCEPT SELECT eid FROM \ncertificate\nExample fr om S pider\nShow ids for all  employees \nwho don't have a certificate.\noverpaid SELECT eid FROM employee \n EXCEPT \nSELECT eid FROM certificate\nWHERE salary > 30000\nExample in MA GNIFIC o\nFigure 4: Illustration of the ‘Regex-based pattern match-\ning’ procedure used for creating examples in MAG-\nNIFIC O.\nqueries of the seed example to include the corre-\nsponding form in a suitable manner. In such cases,\nwe prompt GPT-4 (OpenAI, 2023) with the query\nof the seed example and instruct it to paraphrase\nthe query so as to include the form of the novel in-\nterpretation. We then manually examine the model-\ngenerated paraphrase for grammatical correctness\nand consistency of intended meaning. Similar to\nthe previous method, we modify the target SQL\nquery using hand-crafted rules, if required.\n(3) Synchronous Context-Free Grammar.\nFor many interpretations, there are either none or\nvery few examples already existing in Spider. It is\nalso difficult to find such examples automatically\nbased on regex patterns. In such cases, if we\nhave obtained a limited number of examples from\nSpider, we extract an SCFG representing those\nexamples by abstracting away specific column\nand table names and data values similar to the\nmethod used by Yu et al. (2021). If there are\nnot enough examples in Spider, we define an\nSCFG ourselves that represents the interpretation.\nWe then automatically generate examples from\nthe SCFG by filling it with randomly sampled\ncolumn and table names and values from the set of\ndatabases in Spider. We only keep the examples for\nwhich the generated SQL query correctly executes\nand does not give a NULL output. An illustration of\nthis process is provided in Figure 5.\nMultiple novel interpretations in same example.\nFrom the data created using the procedures\nabove, we select pairs of examples that have\ndifferent novel interpretations but use the same\ndatabase schema. We devise a set of rules using\nwhich, given such a pair, we can automatically\ncreate a new example that requires understanding\nboth novel interpretations (one from each of the\nexamples in the pair) simultaneously. Figure\n3 illustrates such an example. We created a\n2170\nShow  for all  with \n more than average.\nnames aircrafts\ndistances\nSELECT  FROM  \nWHERE distance > (SELECT \nAVG( ) FROM )\nname aircraft\naircraftdistance\nExample fr om S pider\nI n tr oduc e N o v el I n t erpr e ta tion\nShow  for all  with \n more than average.\ncolumn0 table0\ncolumn1\nSELECT  FROM  \nWHERE  > (SELECT \nAVG( ) FROM )\ncolumn0 table0\ntable0\ncolumn1\ncolumn1\nExtr act SCF G\nShow  for all  with \n grades.\nnames students\nsatisfactory\nSELECT  FROM  WHERE \n > (SELECT AVG( ) \nFROM )\nname student\nstudent\ngrade grade\nExample in MA GNIFIC o\n,\nShow column0 for all table0 with \n column1.satisfactory\nSELECT column0 FROM table0 \nWHERE column1 > (SELECT \nAVG(column1) FROM table0),\nFigure 5: Illustration of the ‘Synchronous Context-\nFree Grammar’ procedure used for creating examples\nin MAGNIFIC O.\ntotal of 376 such examples spanning 24 unique\ncombinations of interpretations. We manually\nreviewed each example to ensure correctness.\nGenerating Conversations. We generate\nlong-form dialogues for a subset of examples\nin MAGNIFIC O. For each database schema\nused in these examples, we prompt GPT-42 to\ngenerate a long conversation between two users\nof that database. We instruct GPT-4 to introduce\nthe corresponding novel interpretation and its\ndescription in a manner that makes it blend\nnaturally into the flow of the conversation at the\nbeginning. We generated a total of 125 unique\ndialogues, each at least 2000 tokens long. We\nmanually reviewed all generated dialogues to\nensure correctness.\nBase Examples. We are only interested in\nmeasuring the ability of models to generalize\nto novel interpretations and not how well they\nperform on the text-to-SQL semantic parsing task.\nHence, for every example in MAGNIFIC O with a\nnovel interpretation, we also maintain an example\nthat does not include any novel interpretation form\nand instead directly states the interpretation as\npart of the input query. These examples serve as\na comparative reference point for our evaluation.\nWe refer to these examples as base examples and\nmeasure the performance of all models across all\n2Prompt provided in Figure 19 in the Appendix.\nTYPE UNIQUE\nTEMPLATES\nTYPES OF\nFORMS\nNUM OF\nEXAMPLES\nSingle-word 1150 base, adversarial,\nplausible, foreign 4600\nPhrase 279 base, plausible 558\nMultiple novel\ninterpretations 94 base, adversarial,\nplausible, foreign 376\nTOTAL 1523 5534\nTable 2: Dataset statistics for MAGNIFIC O.\nprompt types on them. An illustration of a base\nexample is shown in Figure 1.\nSummary. Overall, we created 1523 unique exam-\nples across 24 interpretations. The forms of inter-\npretations in these examples can be automatically\nreplaced to generate more data at scale. Dataset\nstatistics for MAGNIFIC O are provided in Table 2.\nAdditional details on creating MAGNIFIC O are\nprovided in Appendix B. Note that each example in\nMAGNIFIC O was manually reviewed by at least\none of the authors to ensure correctness.\n4 Experimental Setup\nIn this section, we will discuss the setup for our\nexperiments on MAGNIFIC O.3\nModels. We experiment with OpenAI\nGPT-3.5-Turbo (v0301) (Brown et al., 2020;\nOuyang et al., 2022), StarCoder (Li et al.,\n2023b), LLaMA-7B,13B,30B (Touvron et al.,\n2023a), Alpaca-7B (Taori et al., 2023),\nMPT-7B4, MPT-7B-Instruct, RedPajama-7B5,\nRedPajama-7B-Instruct, and RWKV-14B (Bo,\n2021). We additionally experimented with GPT-4\n(OpenAI, 2023) and LLaMA-2 (Touvron et al.,\n2023b), results for which are provided in Appendix\nC.4. For all models, we decode greedily for a\nmaximum of 128 tokens. To take stock of the basic\ntext-to-SQL semantic parsing capabilities of these\nmodels, we show their execution accuracies over\nthe base examples in MAGNIFIC O averaged over\nall interpretations in Figure 6. Some of the results\nfor RWKV-14B and the RedPajama-7B models can\nbe found in Appendix C.\nPrompt. All our experiments are in the in-context\nlearning experimental setup. Our prompt structure\n3We make our code and data available at\nhttps://github.com/McGill-NLP/MAGNIFICo.\n4https://www.mosaicml.com/blog/mpt-7b\n5https://www.together.xyz/blog/redpajama-models-v1\n2171\nLLaMA-7B Alpaca MPT-7B MPT-7B-Inst LLaMA-30B StarCoder GPT-3.5-Turbo\nModels\n0\n10\n20\n30\n40\n50\n60\n70\n80Execution Accuracy (%)\nExecution Accuracy on Base Examples\nDirect\nFew-shot\nFigure 6: Average execution accuracy ( ↑) of all mod-\nels on base examples in MAGNIFIC O across various\nprompt settings.\nlargely follows the Create Table + Select 3 prompt\nformat from Rajkumar et al. (2022) which resulted\nin the best performance on Spider with OpenAI\nCodex (Chen et al., 2021). This format provides\nthe CREATE TABLE commands for each table in the\nschema and displays the values for the top three\nrows for each table. We experiment with three\ndifferent prompt settings: (1) ‘Direct’ is exactly\nthe zero-shot Create Table + Select 3setting which\nincludes no information about how to interpret the\nform of the novel interpretation, (2) ‘Description’\nadditionally includes a brief, one-line natural\nlanguage description of the novel interpretation(s),\nand (3) ‘Few-shot’ includes 5 input-output\nexamples6 of the novel interpretation instead\nof the description. We hold out 5 examples for\neach interpretation from the test sets to maintain\nconsistency in testing across various experimental\nsettings. For experiments with a dialogue in the\ncontext, the dialogue is prepended to the Create\nTable + Select 3 prompt. Examples for each type\nof prompt are provided in Appendix E.\nMetric. We use a metric called Relative Perfor-\nmance to measure the generalization ability of mod-\nels towards acquiring novel interpretations. Our\nmetric provides a measure that is relative to the per-\nformance of the model on the corresponding base\nexamples:\nRelative Performance = min\n( EXNI\nEXbase , 1\n)\n×100\nwhere EXNI is the execution accuracy 7 on the\nexamples with novel interpretations from MAG-\nNIFIC O and EXbase is the execution accuracy on\n6For multiple novel interpretations in the same example,\nwe include 3 support examples for each novel interpretation.\n7Measure of equivalence between output obtained from ex-\necuting the generated SQL query and the ground truth output.\nDirect Description Few-Shot\nPrompt Setting\n0\n20\n40\n60\n80\n100Relative Performance (%)\nRelative Performance - Plausible\nLLaMA-7B Alpaca MPT-7B MPT-7B-Instruct StarCoder LLaMA-30B GPT-3.5-Turbo\nFigure 7: Relative performance ( ↑) of all models on\nMAGNIFIC O across various prompt settings when the\nTOKEN is a plausible English word.\nthe corresponding base examples. 8 Hence, the\nhigher the Relative Performance, the lower the\nmodel’s drop in performance on examples with\nnovel interpretation(s) (relative to base examples),\nand consequently, the higher its ability to learn\nnovel interpretations.\n5 Results and Discussion\n5.1 Impact of Description and Few-shot\nExamples\nQuestion: How well can LLMs learn novel interpre-\ntations when the interpretation is simply described\nin an English sentence? And how does it compare\nagainst the case when we provide few-shot exam-\nples of usage of that interpretation?\nWe compare providing a natural language de-\nscription of the novel interpretation (‘Description’\nprompt type) against providing examples of us-\nage of the novel interpretation (‘Few-shot’ prompt\ntype). Figure 7 provides the results when the form\nused to represent the novel interpretation is a plau-\nsible English word. The results for foreign and\nadversarial forms can be found in Figures 16 and\n17 in the Appendix.\nMost LLMs exhibit a surprisingly high capabil-\nity to understand and generalize to novel interpreta-\ntions from simply the natural language descriptions.\nThis capability seems to increase with model size\nas GPT-3.5-Turbo and LLaMA-30B outperform all\nother models while the smallest model, LLaMA-7B,\nstruggles to generalize from just the description. It\nis also interesting to see the benefit of instruction\nfinetuning (Wang et al., 2023) in learning novel in-\nterpretations in-context just from natural language\ndescriptions: the instruction-finetuned models out-\nperform their corresponding base models, often by\n8We only consider interpretations for which the execution\naccuracy on base examples is at least 5%.\n2172\nPlausible Foreign Adversarial\nPre-existing Semantic Interpretation\n40\n50\n60\n70\n80\n90\n100Average Relative Performance (%)\nEffect of pre-existing semantic interpretation\nLLaMA-7B\nAlpaca\nMPT-7B\nMPT-7B-Instruct\nRedPajama-7B\nRedPajama-7B-Instruct\nLLaMA-30B\nStarCoder\nGPT-3.5-T urbo\nFigure 8: Relative performance ( ↑) of all models across\nforms of different types.\nlarge margins. All models generalize well when a\nfew examples of usage of the novel interpretation\nare provided.\n5.2 Impact of Pre-existing Semantic\nInterpretation\nQuestion: How much does the existing semantic\ninterpretation of the form denoting the novel inter-\npretation influence the generalization capability of\nLLMs?\nAs mentioned in §3.1, we experiment with three\ntypes of form. We plot the relative performance\naveraged over the ‘Description’ and ‘Few-shot’\nprompt types9 in Figure 8.\nWe see a trend of decrease in generalization abil-\nity when the pre-existing semantic interpretation of\nthe form steers farther from the intended meaning\nof the novel interpretation. This shows that LLMs\nhave strong semantic priors that may require tar-\ngeted approaches to be overcome. Moreover, the\nfact that LLMs can easily understand novel inter-\npretations when presented in a familiar form (as\nopposed to completely foreign words) is an inter-\nesting finding for potential applications requiring\nacquisition of novel interpretations in the wild (e.g.,\nconversational agents).\n5.3 Acquiring Novel Interpretations From\nLong Form Dialogue\nWe envision a real-life scenario requiring compo-\nsitional generalization: acquiring novel interpreta-\ntions introduced in a long form conversation. This\nmay arise in situations such as having a conver-\nsation with an AI personal assistant or when we\nwant to condition the outputs of an AI system based\n9We average over the prompt types to improve readability\nof the figure. The complete figure can be seen in Figure 18 in\nthe Appendix.\nStarCoder GPT-3.5-Turbo\nPrompt Plausible Foreign Plausible Foreign\nDescription 79.40 80.74 91.46 85.95\nDialogue 68.91 80.55 84.87 87.63\nTable 3: Relative performance ( ↑) of StarCoder and\nGPT-3.5-Turbo on examples in MAGNIFIC O when\nthe description of the novel interpretation is provided in\na long form dialogue.\non a dialogue history between multiple users. An\nexample is provided in Figure 2.\nQuestion: How well can LLMs learn a novel in-\nterpretation from its description mentioned briefly\nwithin a long-form dialogue?\nWe select 8 interpretations, covering a total of\n583 examples from MAGNIFIC O, encompassing\nall four categories. We generate long conversa-\ntion contexts for each of these examples as de-\nscribed in §3.2. An example of the prompt struc-\nture is provided in Figure 22. We experiment with\nStarCoder and GPT-3.5-Turbo since they are ca-\npable of processing more than 2000 tokens of text\nin-context. The results are provided in Table 3. For\nease of comparison, we also state the results with\nthe ‘Description’ prompt-type for the 8 interpreta-\ntions considered.\nFor both models, using a foreign form to repre-\nsent the novel interpretation does not result in much\nperformance difference when the description of the\nnovel interpretation is blended inside a long form\ndialogue instead of directly stating it. However,\nwhen the form is a plausible english word, we see\na clear decrease in generalization ability for both\nmodels. The decrease is much more significant for\nStarCoder compared to GPT-3.5-Turbo. This in-\ndicates that LLMs may find it difficult to associate\na case-specific interpretation with tokens that they\nare already familiar with when used in long conver-\nsations. It is possible that the models do not pay\nmuch attention to that aspect of the conversation as\nit might seem more ‘normal’ compared to the case\nwhere a foreign form is used.\n5.4 Impact of Position of Description in\nContext Window\nQuestion: How sensitive are LLMs to the location\nin the context window that the novel interpretation\nis described in?\nWe experiment with placing the description at\nthe beginning, middle, or the end of the prompt\n2173\nStart Middle End\nPosition of Description\nStarCoder\nGPT-3.5-TurboModel\n74.24 93.37 100.0\n90.92 91.17 100.0\nPlausible\nStart Middle End\nPosition of Description\n51.32 78.32 100.0\n84.54 79.35 100.0\nForeign\nSensitivity to location of description directly stated\n(a)\nStart Middle End\nPosition of Description\nStarCoder\nGPT-3.5-TurboModel\n89.04 86.08 100.0\n90.8 100.67 100.0\nPlausible\nStart Middle End\nPosition of Description\n81.58 91.56 100.0\n81.78 84.33 100.0\nForeign\nSensitivity to location of description in dialogue\n(b)\nFigure 9: Relative performance ( ↑) of StarCoder and\nGPT-3.5-Turbo on MAGNIFIC O across different lo-\ncations of the description of the novel interpretation in\nthe prompt when the description is directly stated (top)\nand when the description is mentioned in a dialogue\n(bottom). The numbers are relative to the performance\nfor the end position.\nwhen using the‘Description’ prompt type. We also\nexperiment with the ‘Dialogue’ setting by placing\nthe turns of conversation describing the novel in-\nterpretation at the beginning, middle, or the end\nof the dialogue. The results for both experiments\nare provided in Figure 9. Note that we measure\nperformance relative to the performance when the\nnovel interpretation is described in the end so as to\nbetter characterize recency bias.\nWe observe a clear trend of recency bias in\nboth LLMs, where the generalization increases\nwhen the interpretation is described nearer to\nthe end of the context window. StarCoder suf-\nfers much more variation in performance com-\npared to GPT-3.5-Turbo. The difference in per-\nformance between start and end positions for\nGPT-3.5-Turbo, while comparatively small, is still\nsignificant enough to indicate a stronger preference\nfor information presented later in the context.\n5.5 Composing Multiple Novel Interpretations\nQuestion: Are LLMs able to simultaneously learn\nmultiple novel interpretations used compositionally\nin the same example?\nWe evaluate models on a total of 376 exam-\nples that require simultaneously understanding two\nnovel interpretations (see Figure 3 for an example).\nThe results for all models across all three types of\nform of interpretations using the ‘Description’ and\nPlausible Foreign Adversarial\nPre-existing Semantic Interpretation\n0\n10\n20\n30\n40\n50\n60\n70Relative Performance (%)\nMultiple novel interpretations learned simultaneously\nDescription Few-Shot\nLLaMA-7B Alpaca LLaMA-30B StarCoder GPT-3.5-T urbo\nFigure 10: Relative performance ( ↑) of all models\nacross all settings when there are multiple novel in-\nterpretations in the same example.\n‘Few-shot’ prompt types are provided in Figure 10.\nWe notice that all models struggle at learning\nmultiple novel interpretations in the same example\ncompared to learning just one novel interpretation.\nGPT-3.5-Turbo is the best performing model, sig-\nnificantly outperforming StarCoder while the rest\nof the models show nearly trivial performance. The\ndifference in performance between ‘description’\nand ‘few-shot’ prompt types for foreign form sug-\ngests that models have a comparatively harder time\ncomposing interpretations when they are presented\nindividually in separate examples in the prompt.\n5.6 Learning Novel Interpretations of Phrases\nQuestion: Are LLMs able to learn novel interpreta-\ntions when they are denoted by more than a single\nword?\nWe defined 6 interpretations denoted by phrases\nof plausible English words in MAGNIFIC O,\namounting to a total of 279 examples (see Figure\n3 for an example). The results of evaluation over\nthese examples are provided in Figure 11.\nWe notice that LLaMA, StarCoder, and\nGPT-3.5-Turbo models show a surprisingly high\nability to learn the novel interpretation from just\nthe description. It is even more surprising to see\nboth MPT-7B models struggle since they compar-\natively excelled for single-word form interpreta-\ntions (see Figure 7). This shows that the task of\nlearning novel interpretations denoted by multi-\nword phrases is not simply an extension of learning\nsingle-word form interpretations, but a separate\ntask that presents its own set of challenges. Lastly,\nit is interesting to see that contrary to expectations,\nStarCoder outperforms GPT-3.5-Turbo in both\nprompt settings.\n2174\nDirect Description Few-Shot\nPrompt Setting\n0\n20\n40\n60\n80\n100Relative Performance (%)\nRelative Performance - Plausible\nLLaMA-7B Alpaca MPT-7B MPT-7B-Instruct StarCoder LLaMA-30B GPT-3.5-Turbo\nFigure 11: Relative performance ( ↑) of all models on\nMAGNIFIC O across various prompt settings when the\nnovel interpretation is a phrase composed of multiple\nEnglish words.\n6 Final Remarks\nWe studied the ability of LLMs to interpret new\nwords and phrases in-context using their descrip-\ntion or a few demonstrations. We also extended this\nstudy to a realistic scenario: understanding user-\ndefined interpretations from long form dialogue.\nOur results indicate that current LLMs can, to an\nextent, acquire novel interpretations from diverse\nforms of context. However, interpreting unfamiliar\nwords or multiple novel words simultaneously still\nposes a significant challenge for existing LLMs.\nThese tasks can serve as a measure to evaluate\nthe compositional generalization abilities of future\nLLMs in practical settings.\nIt is interesting to note that instruction fine-\ntuning leads to significant improvements in learn-\ning from descriptions across three different LLM\nfamilies. Considering that instruction fine-tuning\ndoesn’t involve acquiring novel semantics, it could\nbe useful to understand why it has this impact.\nIn the past few years, several works (Lake and\nBaroni, 2018; Kim and Linzen, 2020) showed that\nsequence models were limited in their ability to\ngeneralize to novel words on semantic parsing tasks\nbased on a few examples in the training set. Many\nspecialised methods and approaches (Liu et al.,\n2021; Chen et al., 2020) were designed to address\nthis problem. It is therefore fascinating to see that\ncontemporary general LLMs are able to generalize\nto novel words from not only processing a few ex-\namples in-context, but also from natural language\ndescriptions and conversations. While a large part\nof the compositional generalization challenge still\nremains unsolved, we feel it is important to high-\nlight this paradigm shift. We hope our work paves\nthe way for further studies of practical setups that\nrequire LLMs to generalize compositionally.\nAcknowledgments\nWe would like to thank Navin Goyal for initial dis-\ncussions related to the idea behind this work. We\nalso thank the anonymous reviewers, and our col-\nleagues at Mila and McGill University for helpful\ndiscussions and for providing valuable feedback.\nArkil is also supported by the Canada Graduate\nScholarship – Master’s (CGS-M) funded by the\nNatural Sciences and Engineering Research Coun-\ncil of Canada (NSERC).\nLimitations\nWe created our evaluation suiteMAGNIFIC O over\na single task, text-to-SQL semantic parsing. While\nsemantic parsing is a fundamental task in language\nprocessing with general applicability, it would be\nuseful to verify the findings across other tasks and\ndomains. In the future, we aim to incorporate more\ntasks from diverse domains such as classification\nto better support our claims.\nThe execution accuracies over base examples in\nMAGNIFIC O are low for smaller models. This\nresults in a higher variance in the results of small\nmodels. While we enforce a threshold of minimum\n5% accuracy on the base examples for each inter-\npretation to be included in the results, in the future,\nwe shall also include experiments over a task that\nis more easily solvable by smaller models.\nThe number of data points for some of our ex-\nperimental settings (such as multiple novel inter-\npretations) is not large. However, note that our\nstudy was exploratory in nature and our main focus\nwas on analysing the in-context learning abilities\nof LLMs for acquiring novel interpretations rather\nthan proposing a general benchmark for evaluat-\ning LLMs. Our findings revealed that LLMs face\nmore difficulty when there are multiple novel in-\nterpretations in the same example. This motivates\nus to look more closely at this particular setting\nin the future and potentially create a challenging\nbenchmark.\nEthics Statement\nWe have extensively discussed the limitations of\nour work in the previous section. We use an exist-\ning dataset, Spider (Yu et al., 2018), which is pub-\nlicly available and commonly used in NLP research.\nWe generate additional data by modifying the ex-\namples in Spider in a rule-based manner. Since we\nfocus on a text-to-SQL semantic parsing task, there\n2175\nare minimal risks and biases associated with our\ndata and we believe that it does not require ethical\nconsideration. We also employed Large Language\nModels to automatically generate data, and each\nexample of the generated data went through man-\nual verification, ensuring that it does not pose any\nsignificant risk. We have discussed the experimen-\ntal details in Appendix A. The research presented\nin this paper focuses on analysing the in-context\nlearning abilities of LLMs targeted towards inter-\npreting novel interpretations and we believe that\nour work does not raise any ethical concerns.\nReferences\nEkin Akyurek and Jacob Andreas. 2021. Lexicon learn-\ning for few shot sequence modeling. In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 4934–4946, Online.\nAssociation for Computational Linguistics.\nShengnan An, Zeqi Lin, Qiang Fu, Bei Chen, Nan-\nning Zheng, Jian-Guang Lou, and Dongmei Zhang.\n2023. How do in-context examples affect compo-\nsitional generalization? In Proceedings of the 61st\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 11027–\n11052, Toronto, Canada. Association for Computa-\ntional Linguistics.\nJacob Andreas. 2020. Good-enough compositional data\naugmentation. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 7556–7566, Online. Association for\nComputational Linguistics.\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-\ngio. 2015. Neural machine translation by jointly\nlearning to align and translate. In 3rd International\nConference on Learning Representations, ICLR 2015,\nSan Diego, CA, USA, May 7-9, 2015, Conference\nTrack Proceedings.\nPENG Bo. 2021. Blinkdl/rwkv-lm: 0.01.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nPaco Calvo and John Symons. 2014. The architecture\nof cognition: Rethinking Fodor and Pylyshyn’s sys-\ntematicity challenge. MIT Press.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming\nYuan, Henrique Ponde de Oliveira Pinto, Jared Ka-\nplan, Harri Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, et al. 2021. Evaluating large\nlanguage models trained on code. arXiv preprint\narXiv:2107.03374.\nXinyun Chen, Chen Liang, Adams Wei Yu, Dawn Song,\nand Denny Zhou. 2020. Compositional generaliza-\ntion via neural-symbolic stack machines. In Ad-\nvances in Neural Information Processing Systems ,\nvolume 33, pages 1690–1701. Curran Associates,\nInc.\nMaxime Chevalier-Boisvert, Dzmitry Bahdanau, Salem\nLahlou, Lucas Willems, Chitwan Saharia, Thien Huu\nNguyen, and Yoshua Bengio. 2019. BabyAI: First\nsteps towards grounded language learning with a hu-\nman in the loop. In International Conference on\nLearning Representations.\nHenry Conklin, Bailin Wang, Kenny Smith, and Ivan\nTitov. 2021. Meta-learning to compositionally gen-\neralize. In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Papers),\npages 3322–3335, Online. Association for Computa-\ntional Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nLongxu Dou, Yan Gao, Xuqi Liu, Mingyang Pan,\nDingzirui Wang, Wanxiang Che, Dechen Zhan, Min-\nYen Kan, and Jian-Guang Lou. 2022. Towards\nknowledge-intensive text-to-SQL semantic parsing\nwith formulaic knowledge. In Proceedings of the\n2022 Conference on Empirical Methods in Natu-\nral Language Processing , pages 5240–5253, Abu\nDhabi, United Arab Emirates. Association for Com-\nputational Linguistics.\nAndrew Drozdov, Nathanael Schärli, Ekin Akyürek,\nNathan Scales, Xinying Song, Xinyun Chen, Olivier\nBousquet, and Denny Zhou. 2023. Compositional\nsemantic parsing with large language models. In\nThe Eleventh International Conference on Learning\nRepresentations.\nJulian Martin Eisenschlos, Jeremy R. Cole, Fangyu Liu,\nand William W. Cohen. 2023. WinoDict: Probing\nlanguage models for in-context word acquisition. In\nProceedings of the 17th Conference of the European\nChapter of the Association for Computational Lin-\nguistics, pages 94–102, Dubrovnik, Croatia. Associa-\ntion for Computational Linguistics.\nJerry A Fodor and Ernest Lepore. 2002. The composi-\ntionality papers. Oxford University Press.\n2176\nJerry A Fodor and Zenon W Pylyshyn. 1988. Connec-\ntionism and cognitive architecture: A critical analysis.\nCognition, 28(1-2):3–71.\nJonathan Gordon, David Lopez-Paz, Marco Baroni, and\nDiane Bouchacourt. 2020. Permutation equivariant\nmodels for compositional generalization in language.\nIn International Conference on Learning Representa-\ntions.\nDemi Guo, Yoon Kim, and Alexander Rush. 2020.\nSequence-level mixed sample data augmentation. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 5547–5552, Online. Association for Computa-\ntional Linguistics.\nRobert F Hadley. 1994. Systematicity in connectionist\nlanguage learning. Mind & Language, 9(3):247–272.\nColeman Haley. 2020. This is a BERT. now there are\nseveral of them. can they generalize to novel words?\nIn Proceedings of the Third BlackboxNLP Workshop\non Analyzing and Interpreting Neural Networks for\nNLP, pages 333–341, Online. Association for Com-\nputational Linguistics.\nAurélie Herbelot and Eva Maria Vecchi. 2016. Many\nspeakers, many worlds. Linguistic Issues in Lan-\nguage Technology, 13.\nFelix Hill, Olivier Tieleman, Tamara von Glehn,\nNathaniel Wong, Hamza Merzic, and Stephen Clark.\n2021. Grounded language learning fast and slow. In\nInternational Conference on Learning Representa-\ntions.\nDaniel Keysers, Nathanael Schärli, Nathan Scales,\nHylke Buisman, Daniel Furrer, Sergii Kashubin,\nNikola Momchev, Danila Sinopalnikov, Lukasz\nStafiniak, Tibor Tihon, Dmitry Tsarkov, Xiao Wang,\nMarc van Zee, and Olivier Bousquet. 2020. Measur-\ning compositional generalization: A comprehensive\nmethod on realistic data. In International Conference\non Learning Representations.\nNajoung Kim and Tal Linzen. 2020. COGS: A compo-\nsitional generalization challenge based on semantic\ninterpretation. In Proceedings of the 2020 Confer-\nence on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 9087–9105, Online. As-\nsociation for Computational Linguistics.\nBrenden Lake and Marco Baroni. 2018. Generalization\nwithout systematicity: On the compositional skills\nof sequence-to-sequence recurrent networks. In Pro-\nceedings of the 35th International Conference on\nMachine Learning, volume 80 of Proceedings of Ma-\nchine Learning Research, pages 2873–2882. PMLR.\nBrenden M Lake. 2019. Compositional generalization\nthrough meta sequence-to-sequence learning. In Ad-\nvances in Neural Information Processing Systems ,\nvolume 32. Curran Associates, Inc.\nAndrew K Lampinen and James L McClelland. 2017.\nOne-shot and few-shot learning of word embeddings.\narXiv preprint arXiv:1710.10280.\nAngeliki Lazaridou, Adhiguna Kuncoro, Elena Gri-\nbovskaya, Devang Agrawal, Adam Liska, Tayfun\nTerzi, Mai Gimenez, Cyprien de Masson d’Autume,\nTomáš Koˇciský, Sebastian Ruder, Dani Yogatama,\nKris Cao, Susannah Young, and Phil Blunsom. 2021.\nMind the gap: Assessing temporal generalization\nin neural language models. In Advances in Neural\nInformation Processing Systems.\nChia-Hsuan Lee, Oleksandr Polozov, and Matthew\nRichardson. 2021. KaggleDBQA: Realistic evalu-\nation of text-to-SQL parsers. In Proceedings of the\n59th Annual Meeting of the Association for Compu-\ntational Linguistics and the 11th International Joint\nConference on Natural Language Processing (Vol-\nume 1: Long Papers), pages 2261–2273, Online. As-\nsociation for Computational Linguistics.\nJinyang Li, Binyuan Hui, Ge Qu, Binhua Li, Jiaxi\nYang, Bowen Li, Bailin Wang, Bowen Qin, Rongyu\nCao, Ruiying Geng, et al. 2023a. Can llm already\nserve as a database interface? a big bench for large-\nscale database grounded text-to-sqls. arXiv preprint\narXiv:2305.03111.\nRaymond Li, Loubna Ben Allal, Yangtian Zi, Niklas\nMuennighoff, Denis Kocetkov, Chenghao Mou, Marc\nMarone, Christopher Akiki, Jia Li, Jenny Chim,\nQian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo,\nThomas Wang, Olivier Dehaene, Mishig Davaadorj,\nJoel Lamy-Poirier, João Monteiro, Oleh Shliazhko,\nNicolas Gontier, Nicholas Meade, Armel Zebaze,\nMing-Ho Yee, Logesh Kumar Umapathi, Jian Zhu,\nBenjamin Lipkin, Muhtasham Oblokulov, Zhiruo\nWang, Rudra Murthy, Jason Stillerman, Siva Sankalp\nPatel, Dmitry Abulkhanov, Marco Zocca, Manan Dey,\nZhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya,\nWenhao Yu, Swayam Singh, Sasha Luccioni, Paulo\nVillegas, Maxim Kunakov, Fedor Zhdanov, Manuel\nRomero, Tony Lee, Nadav Timor, Jennifer Ding,\nClaire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri\nDao, Mayank Mishra, Alex Gu, Jennifer Robinson,\nCarolyn Jane Anderson, Brendan Dolan-Gavitt, Dan-\nish Contractor, Siva Reddy, Daniel Fried, Dzmitry\nBahdanau, Yacine Jernite, Carlos Muñoz Ferrandis,\nSean Hughes, Thomas Wolf, Arjun Guha, Leandro\nvon Werra, and Harm de Vries. 2023b. Starcoder:\nmay the source be with you!\nYuanpeng Li, Liang Zhao, Jianyu Wang, and Joel Hest-\nness. 2019. Compositional generalization for primi-\ntive substitutions. In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 4293–4302, Hong Kong, China. Association\nfor Computational Linguistics.\nChenyao Liu, Shengnan An, Zeqi Lin, Qian Liu, Bei\nChen, Jian-Guang Lou, Lijie Wen, Nanning Zheng,\n2177\nand Dongmei Zhang. 2021. Learning algebraic re-\ncombination for compositional generalization. In\nFindings of the Association for Computational Lin-\nguistics: ACL-IJCNLP 2021, pages 1129–1144, On-\nline. Association for Computational Linguistics.\nQian Liu, Shengnan An, Jian-Guang Lou, Bei Chen,\nZeqi Lin, Yan Gao, Bin Zhou, Nanning Zheng,\nand Dongmei Zhang. 2020. Compositional gener-\nalization by learning analytical expressions. In Ad-\nvances in Neural Information Processing Systems ,\nvolume 33, pages 11416–11427. Curran Associates,\nInc.\nGary F Marcus. 2003. The algebraic mind: Integrating\nconnectionism and cognitive science. MIT press.\nOpenAI. 2023. Gpt-4 technical report.\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-\nroll L. Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, John\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,\nMaddie Simens, Amanda Askell, Peter Welinder,\nPaul Christiano, Jan Leike, and Ryan Lowe. 2022.\nTraining language models to follow instructions with\nhuman feedback.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, Alban Desmaison, Andreas Kopf, Edward\nYang, Zachary DeVito, Martin Raison, Alykhan Te-\njani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\nJunjie Bai, and Soumith Chintala. 2019. Pytorch: An\nimperative style, high-performance deep learning li-\nbrary. In Advances in Neural Information Processing\nSystems, volume 32. Curran Associates, Inc.\nArkil Patel, Satwik Bhattamishra, Phil Blunsom, and\nNavin Goyal. 2022. Revisiting the compositional\ngeneralization abilities of neural sequence models.\nIn Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n2: Short Papers) , pages 424–434, Dublin, Ireland.\nAssociation for Computational Linguistics.\nNgoc-Quan Pham, Jan Niehues, and Alex Waibel.\n2018. Towards one-shot learning for rare-word\ntranslation with external experts. arXiv preprint\narXiv:1809.03182.\nNitarshan Rajkumar, Raymond Li, and Dzmitry Bah-\ndanau. 2022. Evaluating the text-to-sql capabilities\nof large language models.\nTimo Schick and Hinrich Schütze. 2019. Learning se-\nmantic representations for novel words: Leveraging\nboth form and context. In Proceedings of the AAAI\nConference on Artificial Intelligence , volume 33,\npages 6965–6973.\nAnkur Sikarwar, Arkil Patel, and Navin Goyal. 2022.\nWhen can transformers ground and compose: In-\nsights from compositional generalization bench-\nmarks. In Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Processing,\npages 648–669, Abu Dhabi, United Arab Emirates.\nAssociation for Computational Linguistics.\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\nDubois, Xuechen Li, Carlos Guestrin, Percy Liang,\nand Tatsunori B Hashimoto. 2023. Alpaca: A\nstrong, replicable instruction-following model. Stan-\nford Center for Research on Foundation Models.\nhttps://crfm. stanford. edu/2023/03/13/alpaca. html.\nTristan Thrush, Ethan Wilcox, and Roger Levy. 2020.\nInvestigating novel verb learning in BERT: Selec-\ntional preference classes and alternation-based syn-\ntactic generalization. In Proceedings of the Third\nBlackboxNLP Workshop on Analyzing and Interpret-\ning Neural Networks for NLP, pages 265–275, On-\nline. Association for Computational Linguistics.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurelien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023a. Llama: Open\nand efficient foundation language models.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\nBhosale, Dan Bikel, Lukas Blecher, Cristian Canton\nFerrer, Moya Chen, Guillem Cucurull, David Esiobu,\nJude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\nCynthia Gao, Vedanuj Goswami, Naman Goyal, An-\nthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\nIsabel Kloumann, Artem Korenev, Punit Singh Koura,\nMarie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-\nana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-\ntinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-\nbog, Yixin Nie, Andrew Poulton, Jeremy Reizen-\nstein, Rashi Rungta, Kalyan Saladi, Alan Schelten,\nRuan Silva, Eric Michael Smith, Ranjan Subrama-\nnian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-\nlor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\nZheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\nMelanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez, Robert Stojnic, Sergey Edunov, and Thomas\nScialom. 2023b. Llama 2: Open foundation and\nfine-tuned chat models.\nMaria Tsimpoukelli, Jacob Menick, Serkan Cabi,\nS. M. Ali Eslami, Oriol Vinyals, and Felix Hill. 2021.\nMultimodal few-shot learning with frozen language\nmodels. In Advances in Neural Information Process-\ning Systems.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. Advances in neural information processing\nsystems, 30.\nSu Wang, Stephen Roller, and Katrin Erk. 2017. Distri-\nbutional modeling on a diet: One-shot word learning\nfrom text only.\n2178\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa\nLiu, Noah A. Smith, Daniel Khashabi, and Hannaneh\nHajishirzi. 2023. Self-instruct: Aligning language\nmodels with self-generated instructions.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38–45, Online. Association\nfor Computational Linguistics.\nHitomi Yanaka, Koji Mineshima, and Kentaro Inui.\n2021. SyGNS: A systematic generalization testbed\nbased on natural language semantics. In Findings of\nthe Association for Computational Linguistics: ACL-\nIJCNLP 2021, pages 103–119, Online. Association\nfor Computational Linguistics.\nTao Yu, Chien-Sheng Wu, Xi Victoria Lin, bailin\nwang, Yi Chern Tan, Xinyi Yang, Dragomir Radev,\nrichard socher, and Caiming Xiong. 2021. Gra{pp}a:\nGrammar-augmented pre-training for table semantic\nparsing. In International Conference on Learning\nRepresentations.\nTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga,\nDongxu Wang, Zifan Li, James Ma, Irene Li, Qingn-\ning Yao, Shanelle Roman, Zilin Zhang, and Dragomir\nRadev. 2018. Spider: A large-scale human-labeled\ndataset for complex and cross-domain semantic pars-\ning and text-to-SQL task. In Proceedings of the 2018\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 3911–3921, Brussels, Bel-\ngium. Association for Computational Linguistics.\nChen Zhao, Yu Su, Adam Pauls, and Emmanouil An-\ntonios Platanios. 2022. Bridging the generalization\ngap in text-to-SQL parsing with schema expansion.\nIn Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 5568–5578, Dublin, Ireland.\nAssociation for Computational Linguistics.\nRuiqi Zhong, Tao Yu, and Dan Klein. 2020. Semantic\nevaluation for text-to-SQL with distilled test suites.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 396–411, Online. Association for Computa-\ntional Linguistics.\n2179\nA Implementation Details\nExperiments using GPT-3.5-Turbo and GPT-4\nwere performed using the OpenAI API10. All other\nexperiments were done on a single NVIDIA A100\nGPU with 80 GB memory. Our code is imple-\nmented in PyTorch (Paszke et al., 2019) and makes\nuse of the HuggingFace Transformers library (Wolf\net al., 2020).\nB Additional Information on\nMAGNIFIC O\nWe provide examples for each of the 18 single-\nword form and 6 phrase form interpretations in\nMAGNIFIC O in Table 4 and Table 5 respectively.\nB.1 Populating Tables with Edge Cases\nThe metric for evaluating the generated SQL\nqueries in text2SQL benchmarks is execution accu-\nracy, which compares the output of the execution\nof the generated query with the ground truth. Since\nwe are introducing new interpretations in existing\ndatabases, it is possible that the output of the cor-\nresponding SQL query is trivial, like printing all\nvalues in the Table. Apart from this, it is possible\nthat an incorrect SQL query leads to the ground-\ntruth output because there are no edge case values\npresent in the Table. To handle such cases, we au-\ntomatically populate the tables by inserting new\nvalues that act as edge cases (Zhong et al., 2020).\nC Additional Experimental Results\nC.1 Performance on Base Examples\nThe performance of models on base examples in\nMAGNIFIC O can be seen in Figure 12. We found\nthe base text-to-SQL performance of RWKV-14B to\nbe extremely low and hence do not experiment with\nit in other settings.\nC.2 Impact of Description and Few-Shot\nExamples\nFigure 7, Figure 16 and Figure 17 illustrate the\nimpact of providing description and few-shot ex-\namples of the novel interpretation when the novel\ninterpretation is represented by a plausible, foreign\nor an adversarial form respectively for all models.\n10https://platform.openai.com/\nRWKV RedPajama-7B RedPajama-7B-Instruct LLaMA-13B\nModels\n0\n5\n10\n15\n20\n25\n30\n35\n40Execution Accuracy (%)\nExecution Accuracy on Base Examples\nDirect\nFew-shot\nFigure 12: Average execution accuracy (↑) of models on\nbase examples in MAGNIFIC O across various prompt\nsettings.\nLLaMA-2-7B LLaMA-2-13B LLaMA-2-70B GPT-4\nModels\n0\n10\n20\n30\n40\n50\n60\n70\n80Execution Accuracy (%)\nExecution Accuracy on Base Examples\nDirect\nFew-shot\nFigure 13: Average execution accuracy ( ↑) of LLaMA-2\nand GPT-4 models on base examples in MAGNIFIC O\nacross various prompt settings.\nC.3 Impact of Pre-existing Semantic\nInterpretation\nFigure 18 provides the results for all models across\nall experimental settings.\nC.4 Results for LLaMA-2 and GPT-4\nThe performance of LLaMA-2 and GPT-4 models\non base examples in MAGNIFIC O can be seen\nin Figure Figure 13. Their performance across all\nexperimental settings can be seen in Figure 14.\nD Additional Related Works\nWord Acquisition\nLazaridou et al. (2021) analyse the temporal\ngeneralization capabilities of LLMs and showed\nthat the perplexity increases when modelling text\ncontaining new words. There is also some related\nwork in the domain of grounded language learning.\nChevalier-Boisvert et al. (2019) focus on learning\na synthetic language which is a subset of English.\nHowever, they do not carry out any systematic\nevaluation focused on word learning. Hill et al.\n(2021) propose an approach for fast-mapping, i.e.,\n2180\nthe ability to bind a novel non-sense word to an\nobject in their RL framework. However, their\nframework and approach are specifically designed\nto cater to word learning, while we wish to evaluate\nthe word learning abilities of general NLP models\nacross various NLP tasks. Tsimpoukelli et al.\n(2021) focus on using frozen pretrained models for\nlearning words that only act as names of objects\nin images. We wish to study word learning at a\nbroader level, by considering more complex types\nof words and interpretations.\nCompositional Generalization\nMany works in the past (Fodor and Pylyshyn, 1988;\nHadley, 1994; Fodor and Lepore, 2002; Marcus,\n2003; Calvo and Symons, 2014) have argued that\nartificial neural networks are incapable of exhibit-\ning systematic compositionality. However, recent\nsuccesses of neural models (Bahdanau et al., 2015;\nVaswani et al., 2017; Devlin et al., 2019) across\nvarious NLP tasks have revived this debate with a\nfocus on investigating the presence and extent of\ncompositional biases in models.\nLake and Baroni (2018) investigated the com-\npositional generalization abilities of contemporary\nneural sequence models such as RNNs and LSTMs\nbased on their performance on a synthetic bench-\nmark called ‘SCAN’. Their conclusions were con-\nsistent with past work in that they found neural\nsequence models generalize poorly when tested\non systematically held-out novel combinations of\nwords and phrases. Follow-up work by Kim and\nLinzen (2020) reached similar conclusions using\ntheir semantic parsing benchmark, ‘COGS’.\nWhile novel word learning has not been explic-\nitly studied in previous compositional generaliza-\ntion literature, some of the experiments carried out\nby Lake and Baroni (2018) and Kim and Linzen\n(2020) do implicitly assess the abilities of models to\none-shot acquire a novel word. However, the words\nused in these experiments are of a primitive nature\nand have a context-independent direct mapping in\nthe output space (for e.g., in SCAN, models simply\nneed to learn to map the input word ‘jump’ to its\ncorresponding output token ‘JUMP’). In our work,\nwe broaden the scope to also understand how well\nmodels acquire more functional words, i.e., words\nthat act over other words in a context-dependent\nmanner to generate the output (for e.g., consider\nthe interpretation ‘most-frequent’ represented by\nthe form prevalant in Table 1. The output looks\nPlausible Foreign Adversarial\nPre-existing Semantic Interpretation\n0\n20\n40\n60\n80\n100\nRelative Performance (%)\nEffect of pre-existing semantic interpretation\nDirect Description Few-Shot\nLLaMA-2-7B LLaMA-2-13B LLaMA-2-70B GPT-4\nFigure 14: Relative performance ( ↑) of LLaMA-2 and\nGPT-4 models across forms of different types for all\nprompt settings.\nvery different for inputs like, ‘Find the prevalant\nage of students’ or, ‘What is the number of students\nthat do not have the prevalant last name?’).\nThere have been many compositional gener-\nalization benchmarks proposed in recent years\n(Keysers et al., 2020; Yanaka et al., 2021), almost\nall of them illustrating deficiencies of neural\nmodels at generalizing compositionally. Many\napproaches have also been proposed to solve\ncompositional generalization benchmarks (Li et al.,\n2019; Lake, 2019; Gordon et al., 2020; Chen et al.,\n2020; Andreas, 2020; Liu et al., 2020; Guo et al.,\n2020; Akyurek and Andreas, 2021; Conklin et al.,\n2021; Liu et al., 2021). However, most of these\napproaches are task-specific and cannot be gener-\nally applied for language processing. Moreover,\nLLMs achieve a very high level of performance\non compositional generalization benchmarks\nbased on just a few examples in-context (Drozdov\net al., 2023). In this work, we seek to analyse\nthe compositional generalization capabilities\nof LLMs more realistically, by grounding our\nevaluation to possible use case scenarios, for e.g.\ngenerating SQL queries for user inputs that require\nunderstanding novel interpretations from a long\nconversation context.\nE Example Prompts\nFigure 19 shows an example of a prompt used to\ngenerate a long form dialogue using GPT-4. Fig-\nures 20, 21, and 22 show examples for the‘Descrip-\ntion’, ‘Few-shot’, and ‘Dialogue’ prompt types\nrespectively.\n2181\nDirect Description Few-Shot\nPrompt Setting\n0\n20\n40\n60\n80\n100Relative Performance (%)\nRelative Performance - Plausible\nLLaMA-7B\nAlpaca\nMPT-7B\nMPT-7B-Instruct\nRedPajama\nRedPajama-Instruct\nLLaMA-13B\nStarCoder\nLLaMA-30B\nGPT-3.5-Turbo\nFigure 15: Relative performance ( ↑) of all models on MAGNIFIC O across various prompt settings when the TOKEN\nis a plausible word.\nDirect Description Few-Shot\nPrompt Setting\n0\n20\n40\n60\n80\n100Relative Performance (%)\nRelative Performance - Foreign\nLLaMA-7B\nAlpaca\nMPT-7B\nMPT-7B-Instruct\nRedPajama\nRedPajama-Instruct\nLLaMA-13B\nStarCoder\nLLaMA-30B\nGPT-3.5-Turbo\nFigure 16: Relative performance ( ↑) of all models on MAGNIFIC O across various prompt settings when the TOKEN\nis a foreign word.\n2182\nCATEGORY INTERPRETATION EXAMPLES\nBasic Operations\nMinimum Input: What are the name, latitude, and city of the station with the baseline latitude?\nOutput: SELECT name, lat, city FROM station ORDER BY lat LIMIT 1\nMaximum Input: Which film has the coveted rental rate? And what is the rate?\nOutput: SELECT title, rental_rate FROM film ORDER BY rental_rate DESC LIMIT 1\nAverage\nInput: What is the representative price for flights from LA to honolulu?\nOutput: SELECT AVG(price) FROM flight WHERE origin = ‘Los Angeles’ AND destination\n= ‘honolulu’\nSum Input: What is the accumulated employee number for each office of professors?\nOutput: SELECT prof_office, SUM(emp_num) FROM professor GROUP BY prof_office\nCount Input: Show the magnitude of unique transaction types.\nOutput: SELECT COUNT(DISTINCT transaction_type) FROM financial_transactions\nSubquery-based Operations\nMost-frequent\nInput: Display the sex and first name of students with the prevalent major.\nOutput: SELECT Sex , Fname FROM Student WHERE Major IN (SELECT Major FROM Student\nGROUP BY Major ORDER BY COUNT(*) DESC LIMIT 1)\nSecond-maximum\nInput: Which major has runner-up number of students?\nOutput: SELECT major FROM (SELECT major , COUNT(*) AS t_prop FROM student GROUP\nBY major ORDER BY COUNT(*) DESC LIMIT 2 AS t_tab ORDER BY t_tab.t_prop LIMIT 1\nAbove-average Input: What are the name of players who got satisfactory points?\nOutput: SELECT name FROM player WHERE points > (SELECT AVG(points) FROM player)\nValue not present\nInput: How many customers are absent from having an account?\nOutput: SELECT COUNT(*) FROM customers WHERE customer_id NOT IN (SELECT customer_id\nFROM accounts)\nMore than max\n(conditionally)\nInput: Which songs dominate those with a rating below 6 in terms of resolution?\nOutput: SELECT f_id FROM song WHERE resolution > (SELECT MAX(resolution) FROM song\nWHERE rating < 6)\nValue-conditioned\n4 credit courses Input: List the names of all heavy courses ordered by their titles and credits.\nOutput: SELECT title FROM course WHERE credits = 4 ORDER BY title, credits\nSalary more than\n30000\nInput: Display information on those overpaid employees who joined after 1st April, 1995.\nOutput: SELECT * FROM employees WHERE salary > 30000 AND hire_date > ‘1995-04-01’\nPhysics and Biology\ndepartments\nInput: What are the addresses of pure-science subject departments? |\nOutput: SELECT dept_address FROM department WHERE dept_name IN (‘Physics’,\n‘Biology’)\nYellow card Input: How many aggressive players have more than 1000 hours of training?\nOutput: SELECT COUNT(*) FROM player WHERE hs > 1000 AND ycard = ‘yes’\nMountain View and\nPalo Alto cities\nInput: How many trips did not end in tech-towns?\nOutput: SELECT COUNT(*) FROM trip AS t1 JOIN station AS t2 ON t1.end_station_id =\nt2.id WHERE t2.city NOT IN (‘Mountain View’, ‘Palo Alto’)\nColumn Operations\nConcatenation of last\nand first name\nInput: How many students are there with ‘gE’ in alias?\nOutput: SELECT COUNT(*) FROM student WHERE lname || fname LIKE ‘%gE%’\nSubtraction of end\nand start dates\nInput: What are the unique job ids in job history when tenure is more than 4.\nOutput: SELECT DISTINCT job_id FROM job_history WHERE end_date - start_date > 4\nProduct of Course\nand Prerequisite IDs\nInput: How many courses have prerequisite with requirement-id less than 100000?\nOutput: SELECT COUNT(*) FROM course WHERE course_id IN (SELECT course_id FROM\nprereq WHERE course_id * prereq_id < 100000)\nTable 4: Examples of all single-word novel interpretations used in MAGNIFIC O. Illustrated examples use a\nplausible English form.\n2183\nINTERPRETATION EXAMPLES\nNumber of characters less than 8 Input: Find the average unit price for a track. Display outputs only if the name is within system length constraints.\nOutput: SELECT AVG(unitprice) FROM track WHERE LENGTH(Name) < 8\nValue greater than the difference of the\naverage and the standard deviation\nInput: Find the campuses whose campus fee is in first order outlier range.\nOutput: SELECT campus FROM csu_fees WHERE campusfee > (SELECT AVG(campusfee) -\nSTDEV(campusfee) FROM csu_fees)\nValue less than average Input: What are the name of rooms that have a cost lying in the community-mandated spectrum.\nOutput: SELECT roomname FROM rooms WHERE baseprice < ( SELECT AVG(baseprice) FROM rooms)\nHire date in July or August 1987\nInput: Get the details of employees who manage a department. Show outputs only for those employees that were\nhired during the months of union labour strike.\nOutput: SELECT DISTINCT * FROM employees AS t1 JOIN departments AS t2 ON t1.departmen_id\n= t2.department_id WHERE hire_date >= ’1987-07-01’ AND hire_date < ’1987-09-01’ AND\nt1.employee_id = t2.manager_id\nPhysicians that are not an intern\nInput: List the name of board-certified and licensed physicians who never took any appointment.\nOutput: SELECT name FROM physician EXCEPT SELECT t2.name FROM appointment AS t1 JOIN physician\nAS t2 ON t1.physician = t2.employeeid WHERE position NOT IN (’Staff Internist’)\nNumber of docks greater than 19 Input: How many biking association compliant stations are in Mountain View?\nOutput: SELECT COUNT(*) FROM station WHERE dock_count >= 19 AND city = ‘Mountain View’\nTable 5: Examples of all novel interpretations represented by a phrase of English words used in MAGNIFIC O.\nDirect Description Few-Shot\nPrompt Setting\n0\n20\n40\n60\n80\n100Relative Performance (%)\nRelative Performance - Adversarial\nLLaMA-7B\nAlpaca\nMPT-7B\nMPT-7B-Instruct\nRedPajama\nRedPajama-Instruct\nLLaMA-13B\nStarCoder\nLLaMA-30B\nGPT-3.5-Turbo\nFigure 17: Relative performance ( ↑) of all models on MAGNIFIC O across various prompt settings when the TOKEN\nis a adversarial word.\n2184\nPlausible Foreign Adversarial\nPre-existing Semantic Interpretation\n0\n20\n40\n60\n80\n100\nRelative Performance (%)\nEffect of pre-existing semantic interpretation\nDirect Description Few-Shot\nLLaMA-7B\nAlpaca\nMPT-7B\nMPT-7B-Instruct\nRedPajama-7B\nRedPajama-7B-Instruct\nLLaMA-13B\nLLaMA-30B\nStarCoder\nGPT-3.5-Turbo\nFigure 18: Relative performance ( ↑) of all models across forms of different types for all prompt settings.\n2185\nSystem Prompt:\nYou are DialogueGPT - a tool to generate realistic long-form multi-turn dialogues based on the\nsituation provided.\nUser Prompt:\nYou are given a database schema. Examples of the data in each of the tables is provided:\nCREATE TABLE IF NOT EXISTS `departments` (\n`DEPARTMENT_ID` decimal(4,0) NOT NULL DEFAULT '0',\n`DEPARTMENT_NAME` varchar(30) NOT NULL,\n`MANAGER_ID` decimal(6,0) DEFAULT NULL,\n`LOCATION_ID` decimal(4,0) DEFAULT NULL,\nPRIMARY KEY (`DEPARTMENT_ID`)\n)\n/*\n3 example rows:\nSELECT * FROM `departments` LIMIT 3;\nDEPARTMENT_ID DEPARTMENT_NAME MANAGER_ID LOCATION_ID\n10 Administration 200 1700\n20 Marketing 201 1800\n30 Purchasing 114 1700\n*/\n.\n.\n.\n/*\nCREATE TABLE IF NOT EXISTS `jobs` (\n`JOB_ID` varchar(10) NOT NULL DEFAULT '',\n`JOB_TITLE` varchar(35) NOT NULL,\n`MIN_SALARY` decimal(6,0) DEFAULT NULL,\n`MAX_SALARY` decimal(6,0) DEFAULT NULL,\nPRIMARY KEY (`JOB_ID`)\n)\n/*\n3 example rows:\nSELECT * FROM `jobs` LIMIT 3;\nJOB_ID JOB_TITLE MIN_SALARY MAX_SALARY\nAD_PRES President 20000 40000\nAD_VP Administration Vice President 15000 30000\nAD_ASST Administration Assistant 3000 6000\n*/\nGenerate a 20-turn dialogue between two users of this database. Somewhere near the start of the\nconversation, user1 says that based on the schema, some people are overpaid. In response to user2\nasking what user1 means when they say someone is overpaid, user1 will casually mention that according\nto them, anyone that earns a salary more than 30,000 is overpaid. The rest of the conversation should\nmake no mention of overpaid. The conversation should not include SQL queries.\nFigure 19: Prompt used for generating long form dialogues using GPT-4.\n2186\nCREATE TABLE IF NOT EXISTS `departments` (\n`DEPARTMENT_ID` decimal(4,0) NOT NULL DEFAULT '0',\n`DEPARTMENT_NAME` varchar(30) NOT NULL,\n`MANAGER_ID` decimal(6,0) DEFAULT NULL,\n`LOCATION_ID` decimal(4,0) DEFAULT NULL,\nPRIMARY KEY (`DEPARTMENT_ID`)\n)\n/*\n3 example rows:\nSELECT * FROM `departments` LIMIT 3;\nDEPARTMENT_ID DEPARTMENT_NAME MANAGER_ID LOCATION_ID\n10 Administration 200 1700\n20 Marketing 201 1800\n30 Purchasing 114 1700\n*/\n.\n.\n.\n/*\nCREATE TABLE IF NOT EXISTS `jobs` (\n`JOB_ID` varchar(10) NOT NULL DEFAULT '',\n`JOB_TITLE` varchar(35) NOT NULL,\n`MIN_SALARY` decimal(6,0) DEFAULT NULL,\n`MAX_SALARY` decimal(6,0) DEFAULT NULL,\nPRIMARY KEY (`JOB_ID`)\n)\n/*\n3 example rows:\nSELECT * FROM `jobs` LIMIT 3;\nJOB_ID JOB_TITLE MIN_SALARY MAX_SALARY\nAD_PRES President 20000 40000\nAD_VP Administration Vice President 15000 30000\nAD_ASST Administration Assistant 3000 6000\n*/\n-- Using valid SQLite, answer the following questions for the tables provided above.\n-- The word ’overpay’ refers to those with salary more than 30000.\n-- what is all the information about overpaid employees hired before April 2, 1995?\nSELECT\nFigure 20: Example prompt for Create Table + Select 3where the prompt contains a description of the novel\ninterpretation.\n2187\nCREATE TABLE IF NOT EXISTS `regions` (\n`REGION_ID` decimal(5,0) NOT NULL,\n`REGION_NAME` varchar(25) DEFAULT NULL,\nPRIMARY KEY (`REGION_ID`)\n)\n/*\n.\n.\n.\ncreate table prereq\n(course_id varchar(8),\nprereq_id varchar(8),\nprimary key (course_id, prereq_id),\nforeign key (course_id) references course (course_id)\non delete cascade,\nforeign key (prereq_id) references course (course_id)\n)\n/*\n3 example rows:\nSELECT * FROM prereq LIMIT 3;\ncourse_id prereq_id\n376 130\n760 169\n403 345\n*/\n-- Using valid SQLite, answer the following questions for the tables provided above.\n-- on what dates were overpaid employees without the letter m in their first names hired?\nselect hire_date from employees where salary > 30000 and first_name not like '%m%'\n-- give the distinct department ids of departments in which a manager is in charge of one or more\noverpaid employees?\nselect distinct department_id from employees where salary > 30000 group by department_id , manager_id\nhaving count(employee_id) >= 1\n-- find the names of all overpaid instructors in comp. sci. department .\nselect name from instructor where dept_name = 'Comp. Sci.' and salary > 30000\n-- what is all the information about overpaid employees hired before April 2, 1995?\nSELECT\nFigure 21: Example prompt with few-shot examples for the novel interpretation represented by the plausible form\n‘overpaid’ followed by the query input.\n2188\nUser1: Hey, I've been working with this database schema and I wanted to discuss some of the tables\nand their relationships.\nUser2: Sure, I'm familiar with the schema. What do you want to know?\nUser1: I noticed there's a table for employees with a salary column. Which employees would you\nconsider to be overpaid ?\nUser2: Well, that's subjective and depends on various factors. But for the sake of this conversation,\nlet's say anyone earning a salary more than 30,000 is\noverpaid. What do you want to discuss in relation to the schema?\n...\n/* conversation containing 2000 words */\n...\nUser2: The benefits_enrollment table has a foreign key EMPLOYEE_ID, indicating which employee the\nbenefit enrollment is associated with. It also has columns for the benefit name, enrollment date,\nand status.\nUser1: Suppose you are given the following schema:\nCREATE TABLE IF NOT EXISTS `regions` (\n`REGION_ID` decimal(5,0) NOT NULL,\n`REGION_NAME` varchar(25) DEFAULT NULL,\nPRIMARY KEY (`REGION_ID`)\n)\n/*\n3 example rows:\nSELECT * FROM `regions` LIMIT 3;\nREGION_ID REGION_NAME\n1 Europe\\r\n2 Americas\\r\n3 Asia\\r\n*/\n.\n.\n.\n/*\n3 example rows:\nSELECT * FROM `locations` LIMIT 3;\nLOCATION_ID STREET_ADDRESS POSTAL_CODE CITY STATE_PROVINCE COUNTRY_ID\n1000 1297 Via Cola di Rie 989 Roma IT\n1100 93091 Calle della Testa 10934 Venice IT\n1200 2017 Shinjuku-ku 1689 Tokyo Tokyo Prefecture JP\n*/\nUsing valid SQLite, answer the following question with the corresponding SQL query:\nwhat is all the information about overpaid employees hired before April 2, 1995?\nUser2: SELECT\nFigure 22: Example prompt which involves a long form dialogue containing the description of the novel interpreta-\ntion. Note that the truncated section of the dialogue has over 2000 words.\n2189",
  "topic": "Context (archaeology)",
  "concepts": [
    {
      "name": "Context (archaeology)",
      "score": 0.6523914933204651
    },
    {
      "name": "Computer science",
      "score": 0.6496447920799255
    },
    {
      "name": "Parsing",
      "score": 0.5877885222434998
    },
    {
      "name": "Natural language processing",
      "score": 0.5471920967102051
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5158109068870544
    },
    {
      "name": "Suite",
      "score": 0.4923149347305298
    },
    {
      "name": "Natural language",
      "score": 0.4324640929698944
    },
    {
      "name": "Cognitive science",
      "score": 0.38535186648368835
    },
    {
      "name": "Linguistics",
      "score": 0.3457236886024475
    },
    {
      "name": "Cognitive psychology",
      "score": 0.32832205295562744
    },
    {
      "name": "Psychology",
      "score": 0.291287899017334
    },
    {
      "name": "History",
      "score": 0.08130985498428345
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    }
  ]
}