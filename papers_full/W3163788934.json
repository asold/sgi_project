{
  "title": "Quality assessment tools used in systematic reviews of in vitro studies: A systematic review",
  "url": "https://openalex.org/W3163788934",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2110566906",
      "name": "Linh Tran",
      "affiliations": [
        "Duy Tan University"
      ]
    },
    {
      "id": "https://openalex.org/A2752565208",
      "name": "Dao Ngoc Hien Tam",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A2733722895",
      "name": "Abdelrahman Elshafay",
      "affiliations": [
        "Al-Azhar University"
      ]
    },
    {
      "id": "https://openalex.org/A2130650091",
      "name": "Thao Dang",
      "affiliations": [
        "The University of Texas of the Permian Basin",
        "Texas Tech University"
      ]
    },
    {
      "id": "https://openalex.org/A2146577085",
      "name": "Kenji Hirayama",
      "affiliations": [
        "Nagasaki University"
      ]
    },
    {
      "id": "https://openalex.org/A2116696034",
      "name": "Nguyen Tien Huy",
      "affiliations": [
        "Nagasaki University"
      ]
    },
    {
      "id": "https://openalex.org/A2110566906",
      "name": "Linh Tran",
      "affiliations": [
        "Duy Tan University"
      ]
    },
    {
      "id": "https://openalex.org/A2752565208",
      "name": "Dao Ngoc Hien Tam",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2733722895",
      "name": "Abdelrahman Elshafay",
      "affiliations": [
        "Al-Azhar University"
      ]
    },
    {
      "id": "https://openalex.org/A2130650091",
      "name": "Thao Dang",
      "affiliations": [
        "The University of Texas of the Permian Basin",
        "Texas Tech University"
      ]
    },
    {
      "id": "https://openalex.org/A2146577085",
      "name": "Kenji Hirayama",
      "affiliations": [
        "Nagasaki University"
      ]
    },
    {
      "id": "https://openalex.org/A2116696034",
      "name": "Nguyen Tien Huy",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2255222715",
    "https://openalex.org/W2018152980",
    "https://openalex.org/W2117192229",
    "https://openalex.org/W2326601293",
    "https://openalex.org/W2085057176",
    "https://openalex.org/W2140030055",
    "https://openalex.org/W2171425715",
    "https://openalex.org/W2099067203",
    "https://openalex.org/W1805646557",
    "https://openalex.org/W2161763362",
    "https://openalex.org/W2576440140",
    "https://openalex.org/W2965664886",
    "https://openalex.org/W2938752336",
    "https://openalex.org/W2268078935",
    "https://openalex.org/W2321195649",
    "https://openalex.org/W2765565489",
    "https://openalex.org/W1507069233",
    "https://openalex.org/W1594735141",
    "https://openalex.org/W2033454688",
    "https://openalex.org/W1246403004",
    "https://openalex.org/W2141710589",
    "https://openalex.org/W2268721851",
    "https://openalex.org/W2142358242",
    "https://openalex.org/W2753586189",
    "https://openalex.org/W2747598858",
    "https://openalex.org/W2774398092",
    "https://openalex.org/W2795822327",
    "https://openalex.org/W2899511705",
    "https://openalex.org/W1555546429",
    "https://openalex.org/W2984018323",
    "https://openalex.org/W3007672022",
    "https://openalex.org/W2947905979",
    "https://openalex.org/W2883676175",
    "https://openalex.org/W2996659261",
    "https://openalex.org/W2948988368",
    "https://openalex.org/W2947286399",
    "https://openalex.org/W2901747740",
    "https://openalex.org/W2889509689",
    "https://openalex.org/W2609623533",
    "https://openalex.org/W3017866168",
    "https://openalex.org/W2807781193",
    "https://openalex.org/W2034761114",
    "https://openalex.org/W2079712252",
    "https://openalex.org/W2104675861",
    "https://openalex.org/W2142198188",
    "https://openalex.org/W1175437893",
    "https://openalex.org/W1598602811",
    "https://openalex.org/W2160660775",
    "https://openalex.org/W1564188094",
    "https://openalex.org/W2094016944",
    "https://openalex.org/W857941592",
    "https://openalex.org/W3048909697",
    "https://openalex.org/W3049415974",
    "https://openalex.org/W2024950964",
    "https://openalex.org/W2073644162",
    "https://openalex.org/W2346262725",
    "https://openalex.org/W3036868013",
    "https://openalex.org/W2790819078",
    "https://openalex.org/W2955705005",
    "https://openalex.org/W2921569956",
    "https://openalex.org/W3000215288",
    "https://openalex.org/W2782135529",
    "https://openalex.org/W2105267366",
    "https://openalex.org/W2042298892",
    "https://openalex.org/W1839216342",
    "https://openalex.org/W2336350945",
    "https://openalex.org/W2519804936",
    "https://openalex.org/W2201702490",
    "https://openalex.org/W2065511420",
    "https://openalex.org/W2332831464",
    "https://openalex.org/W2213318554",
    "https://openalex.org/W1745059608",
    "https://openalex.org/W2079364627",
    "https://openalex.org/W2962776046",
    "https://openalex.org/W3022903699",
    "https://openalex.org/W2473559982",
    "https://openalex.org/W2987188646",
    "https://openalex.org/W2074126933",
    "https://openalex.org/W4231547689",
    "https://openalex.org/W2792461787",
    "https://openalex.org/W2158079075",
    "https://openalex.org/W2588681363",
    "https://openalex.org/W4287862395"
  ],
  "abstract": "Abstract Background Systematic reviews (SRs) and meta-analyses (MAs) are commonly conducted to evaluate and summarize medical literature. This is especially useful in assessing in vitro studies for consistency. Our study aims to systematically review all available quality assessment (QA) tools employed on in vitro SRs/MAs. Method A search on four databases, including PubMed, Scopus, Virtual Health Library and Web of Science, was conducted from 2006 to 2020. The available SRs/MAs of in vitro studies were evaluated. DARE tool was applied to assess the risk of bias of included articles. Our protocol was developed and uploaded to ResearchGate in June 2016. Results Our findings reported an increasing trend in publication of in vitro SRs/MAs from 2007 to 2020. Among the 244 included SRs/MAs, 126 articles (51.6%) had conducted the QA procedure. Overall, 51 QA tools were identified; 26 of them (51%) were developed by the authors specifically, whereas 25 (49%) were pre-constructed tools. SRs/MAs in dentistry frequently had their own QA tool developed by the authors, while SRs/MAs in other topics applied various QA tools. Many pre-structured tools in these in vitro SRs/MAs were modified from QA tools of in vivo or clinical trials, therefore, they had various criteria. Conclusion Many different QA tools currently exist in the literature; however, none cover all critical aspects of in vitro SRs/MAs. There is a need for a comprehensive guideline to ensure the quality of SR/MA due to their precise nature.",
  "full_text": "RESEARCH ARTICLE Open Access\nQuality assessment tools used in systematic\nreviews of in vitro studies: A systematic\nreview\nLinh Tran 1,2† , Dao Ngoc Hien Tam 3,4† , Abdelrahman Elshafay 4,5, Thao Dang 4,6, Kenji Hirayama 7 and\nNguyen Tien Huy 8*\nAbstract\nBackground: Systematic reviews (SRs) and meta-analyses (MAs) are commonly conducted to evaluate and\nsummarize medical literature. This is especially useful in assessing in vitro studies for consistency. Our study aims to\nsystematically review all available quality assessment (QA) tools employed on in vitro SRs/MAs.\nMethod: A search on four databases, including PubMed, Scopus, Virtual Health Library and Web of Science, was\nconducted from 2006 to 2020. The available SRs/MAs of in vitro studies were evaluated. DARE tool was applied to\nassess the risk of bias of included articles. Our protocol was developed and uploaded to ResearchGate in June 2016.\nResults: Our findings reported an increasing trend in publication of in vitro SRs/MAs from 2007 to 2020. Among\nthe 244 included SRs/MAs, 126 articles (51.6%) had conducted the QA procedure. Overall, 51 QA tools were\nidentified; 26 of them (51%) were developed by the authors specifically, whereas 25 (49%) were pre-constructed\ntools. SRs/MAs in dentistry frequently had their own QA tool developed by the authors, while SRs/MAs in other\ntopics applied various QA tools. Many pre-structured tools in these in vitro SRs/MAs were modified from QA tools\nof in vivo or clinical trials, therefore, they had various criteria.\nConclusion: Many different QA tools currently exist in the literature; however, none cover all critical aspects of\nin vitro SRs/MAs. There is a need for a comprehensive guideline to ensure the quality of SR/MA due to their precise\nnature.\nKeywords: Quality assessment tool, Systematic review, Meta-analysis, In vitro study\nBackground\nEvidence-based medicine (EBM) is a reliable and accurate\napproach based on existing evidence in healthcare-related\nresearches [1]. Systematic reviews (SRs) and meta-analyses\n(MAs) are crucial methods of EBM that assess the findings\nof different work in the medical literature on related\ntopics. The data and conclusions of each work synthesized\nto present a comprehensive summary and conclusion\nbased on the findings [ 2, 3]. The primary medical value\nbehind conducting such studies is to improve healthcare\ndelivery and outcomes in the clinical setting. Researchers\ncan utilize these tools to summarize clinical research with\na non-biased approach to even the most controversial\ntopics [ 4, 5]. For in vitro studies, being able to translate\nand keep track of numerous research projects that address\nthe same topic increases transparency and addresses the\nsignificance of clinical translation. They eventually en-\nhance the safety and efficacy of the treatments in clinical\npractice [ 6, 7]. Current discrepancy between SRs/MAs on\n© The Author(s). 2021 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,\nwhich permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give\nappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if\nchanges were made. The images or other third party material in this article are included in the article's Creative Commons\nlicence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons\nlicence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain\npermission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\nThe Creative Commons Public Domain Dedication waiver ( http://creativecommons.org/publicdomain/zero/1.0/) applies to the\ndata made available in this article, unless otherwise stated in a credit line to the data.\n* Correspondence: tienhuy@nagasaki-u.ac.jp\n† Linh Tran and Dao Ngoc Hien Tam contributed equally to this work.\n8School of Tropical Medicine and Global Health, Nagasaki University, 1 – 12– 4\nSakamoto, Nagasaki 852-8523, Japan\nFull list of author information is available at the end of the article\nTran et al. BMC Medical Research Methodology          (2021) 21:101 \nhttps://doi.org/10.1186/s12874-021-01295-w\npreclinical studies and SRs/MAs on clinical studies sug-\ngest a potential gap in the assessment and evaluation of\npreclinical evidence. This may lead to inadequate transla-\ntion to clinical evidence [ 6, 8]. Therefore, further research\nis justified to address any possible shortfalls in the meth-\nodology of performing such study types.\nThe precise nature of scientific discoveries combined\nwith the increasing influx of research papers highlight\nthe importance of QA tool for all published articles. The\ndevelopment of QA tools investigates to improve the\nquality of scientific reports by addressing unethical and\nmisconducted research studies [ 9– 11]. There are several\nmethods to assess the quality of SRs/MAs, including As-\nsessment of Multiple Systematic Reviews (AMSTAR)\nand Critical Appraisal Skills Programme (CASP). The\nmajority of SRs/MAs uses one of many available ap-\nproaches. However, the content and weights of different\ntools are variable and inconsistent, which raises the\nquestion on either an universally accepted one should be\ndeveloped. ToxRTool and Oral Health Assessment Tool\n(OHAT) are two examples of the National Health and\nMedical Research Council ’s recommendation for SRs/\nMAs of in vitro studies [ 12]. Both tools cover different\naspects of risk of bias, providing researchers with a par-\ntial guide while conducting or assessing these studies.\nGiven the importance of in vitro SRs/MAs to the ad-\nvancement of research through the comprehensive im-\nplementation, its results support the experimental and\nclinical settings. Further investigations are required to\nbridge any potential inadequacies in the methods of syn-\nthesizing preclinical evidence. The selection of high-\nquality QA tools for SRs/MAs on preclinical studies can\nimprove research quality by significantly addressing its\nmethodology. Therefore, our study aimed to evaluate all\nQA tools used in SRs/MAs of in vitro studies.\nMethods\nProtocol registration\nOur study followed the steps recommended in the Pre-\nferred Reporting Items for Systematic reviews and Meta-\nAnalyses (PRISMA) checklist (Table S 1)[ 13, 14]. The\nprotocol was published in ResearchGate in June 2016\n(DOI: https://doi.org/10.13140/RG.2.1.1515.9925). These\nworks relate to in vitro studies; they could not be pub-\nlished on the International Prospective Register of Sys-\ntematic Reviews (PROSPERO).\nSearch strategy\nOur conducted search contained two phases. The first\nphase was performed to identify the SRs/MAs of in vitro\nstudies in October 2016 using four electronic databases,\ncomposed of PubMed, Web of Science (ISI), Virtual\nHealth Library (VHL), and Scopus. This search would be\nlater updated in September 2020. The entire search\nstrategy for these databases was provided in Table S 2.\nNo restriction was applied inside the publication date\nrange from 2006 to 2020. This procedure was also based\non previously performed search [ 15].\nThe second phase was conducted to identify potential\ntools using the Google search engine ( www.google.com)\n[16]. The automatic Google filter was switched off, and\nthe first 300 links of each search term were screened for\nrelevant tools. In addition, the bibliographic references\nof the first 300 links of Google search and eventually in-\ncluded their respective publications were searched to\nfind additional tools unidentified by the search of the\ndatabase. The search strategy was described in Table S 2.\nWe used this search model as described before in Nolger\net al. [ 17]. Also, several webpages were used to search\nand identify the relevant QA tools (Table S 2).\nSelection criteria\nThe inclusion criteria of our studies were; 1- The SRs and/\nor MAs must be purely in vitro research, 2- Search was\nranged from 2006 to 2020 for publication year, 3- Original\nin vitro study was defined as a technique that was con-\nducted in a controlled condition outside the living organism\nwithout being implanted again into the living body or or-\nganism. The exclusion criteria were; 1- All SRs and/or MAs\nthat involved in vivo studies, 2- Combined in vivo and\nin vitro studies. After dupli cate removal using Endnote X7\nprogram (Thompson Reuter, USA ), the titles and abstracts\nwere screened by two reviewers (DNHT and TD) inde-\npendently, followed by the inclu sion and exclusion criteria.\nAfterward, full-texts of the selected articles were divided\ninto several clusters, and each one was evaluated by another\ntwo reviewers (TD and AE) working independently. Results\nwere then gathered, and in the case of inconsistency, a final\ndecision was resolved following discussion with the super-\nvisor (NTH). We included all QA tools that were used in\nthe included articles. For the s econd phase, all potential QA\ntools were included if addressed or proposed in any in vitro\nstudies.\nData extraction\nTwo independent reviewers (DNHT and TD) extracted\nthe data from included articles into a specifically de-\nsigned template using the same method in the screening\nphase. The removed items including the name of au-\nthors, year and region of publication, the involvement of\na methodologist or statistician, whether a meta-analysis\nwas conducted, and whether the risk of bias assessment\nwas undertaken. To extract the QA tool used in each in-\ncluded study, we followed the name of this tool and\nsearched for its original paper for the subsequent extrac-\ntion of QA tools. The QA tools included in our study\nwere all tools which the authors applied for included ar-\nticles in their respective SRs/MAs.\nTran et al. BMC Medical Research Methodology          (2021) 21:101 Page 2 of 13\nIn each confirmed relevant tool, we collected the fol-\nlowing components: type of the tool (scale, checklist, or\nitem), number of items and main contents of its tool,\nthe scoring system, description of formulation, whether\nthe tool was developed for generic purpose in SRs/MAs,\nsingle-use in a specific SR/MA (in a particular type of\nin vitro studies), and whether the tools were developed\nby the authors themselves or pre-structured tools. Re-\nviewers resolved any dissimilarity via discussion. If a de-\ncision could not be achieved, the supervisor (NTH) was\nconsulted to reach a consensus.\nQuality assessment (QA)\nThe QA on the included publications was carried out\nutilizing the Database of Abstract of Reviews of Effects\n(DARE) tool [ 18]. Five criteria consist of: (i) was inclu-\nsion/exclusion criteria reported; (ii) was the search ad-\nequate; (iii) was the quality of the included studies\nassessed; (iv) are sufficient details about the individual\nincluded studies present and (v) were the included stud-\nies synthesized. The interpretation for fulfilling a “yes,”\n“partial,” and “no” score was described in Figure S 1. The\nDARE tool has been used in a tertiary study to evaluate\nthe included SRs/MAs [ 19]. Two independent reviewers\n(LT and TD) performed the QA process, and any dis-\npute was fixed via discussion. If a decision could not be\nobtained, supervisor (NTH) consulted to reach the con-\nsensus. Further analysis was calculated using a Kappa\ncoefficient to determine the inter-agreement between\nthe examiners in each process.\nResults\nSearch results\nThe first phase retrieved 11,757 initial reports from four\nelectronic databases, including PubMed, ISI, Scopus, and\nVHL, as shown in Fig. 1. After duplicate removal, the\ntitles and abstracts of 11,640 publications were screened.\nFrom this, only 343 studies were included for full-text\nscreening, with 244 articles reaching final eligibility. The\nlist of 99 excluded reports with exclusion reasoning was\nprovided in Table S 3. The publication date of all in-\ncluded SRs/MAs ranged from 2007 to 2020. The second\nphase search retrieved 3000 links in the Google search\nengine. We screened the first 300 links for each one of\nten search terms used. We included 32 links for full-text\nscreening, of which 29 were deemed irrelevant links and\nwere excluded. This left three tools eligible for inclusion\nin phase two in our study.\nCharacteristics of included in vitro SRs/MAs\nAmong 244 in vitro SRs/MAs included in the analysis,\n150 articles (60.7%) employed the guidelines for SRs/\nMAs. Of these, 146 articles used the PRISMA checklist\nthough only a single study followed Quality of Reporting\nof Meta-analyses (QUOROM) checklist, and only one\nstudy followed Strengthening the Reporting of Observa-\ntional Studies in Epidemiology (STROBE), and Oral\nHealth Assessment Tool (OHAT) (Table 1). Only 100\narticles that followed guidelines for SR/MA reported\ntheir QA results. The list of 244 included articles using\nQA tools in vitro SRs/MAs was found in Table S 4.\nAmong 244 included studies, 126 articles (51.6%) per-\nformed QA. Only 26 of 126 articles developed their QA\ntools while conducting their reviews, meanwhile 100 ar-\nticles employed the available tools. Also, 34 studies\nfollowed the QA checklist, which was previously devel-\noped by other authors. The others assessed the risks of\nbias following pre-structured QA tools.\nRegarding the distribution of the included studies\nbased on the continent, Europe had the most significant\nrepresentation with 99 (40.7%) studies meanwhile 65\n(26.6%), 14 (5.7%), 27 (11.1%), 31 (12.7%) were from\nFig. 1 Flow diagram of the search strategy of in vitro SRs/MAs\nTran et al. BMC Medical Research Methodology          (2021) 21:101 Page 3 of 13\nTable 1 Principal characteristics of included articles using QA tools in vitro SRs/MAs\nCharacteristics Categorization All studies ( N =\n244)\nYear of publication 2007 – 2014 24 (9.8%)\n2015– 2020 220 (90.2%)\nRegion Europe 99 (40.6%)\nSouth-America 64 (26.2%)\nAsia 33 (13.5%)\nMiddle East 26 (10.7%)\nNorth America 14 (5.7%)\nAustralia 5 (2%)\nAfrica 3 (1.2%)\nStudy topic Dentistry 125 (51.2%)\nBioactivity 53 (21.7%)\nBiology 31 (12.7%)\nMethodology 13 (5.3%)\nMaterials 9 (3.7%)\nPharmacology 5 (2%)\nDiagnosis 4 (1.6%)\nToxicity 4 (1.6%)\nReporting QA used PRISMA 143 (58.6%)\nN 93 (38.1%)\nPRISMA and AMSTAR 3 (1.3%)\nCochrane Handbook for Systematic Reviews of Interventions 2 (0.8%)\nSTROBE 1 (0.4%)\nQUOROM 1 (0.4%)\nOHAT 1 (0.4%)\nQA used Y 126 (51.6%)\nN 118 (48.4%)\nConducting meta-\nanalysis\nY 71 (29.1%)\nN 173 (70.9%)\nQA tool used NR 120 (49.2%)\nFollowing previous description of Onofre et al. 29 (11.9%)\nDeveloped by authors 28 (11.5%)\nCochrane Risk of Bias tool 12 (4.9%)\nCONSORT 8 (3.3%)\nToxRTool 5 (2%)\nOHAT 4 (1.6%)\nJoanna Briggs Institute Clinical Appraisal Checklist 4 (1.6%)\nMINORS 4 (1.6%)\nQUADAS-2 4 (1.6%)\nGRADE 3 (1.2%)\nNOS 3 (1.2%)\nFollowing previous description of Onofre et al. and Montagner et al. 2 (0.8%)\nSTROBE 2 (0.8%)\nFollowing the previous description of Bader et al 1 (0.4%)\nTran et al. BMC Medical Research Methodology          (2021) 21:101 Page 4 of 13\nSouth-America, North America, Middle East, and Asia,\nrespectively. Three studies (1.2%) were from Africa, and\nfive studies from (2%) Australia. Table S 3 provided the\ncharacteristics of all included SRs/MAs.\nThe publication trend of in vitro SRs/MAs slowly en-\nhanced from 2007 to 2014 and then rapidly increased in\nthe following years until 2020. There were 126 of 244 in-\ncluded articles (51.6%) that conducted methodological\nQA. Although no SR/MA assessed QA in 2007 and\n2008, the prevalent studies performing QA among in-\ncluded in vitro SRs/MAs steadily increased during the\nsearch period.\nQA results of included studies using the DARE tool\nWhile utilizing the DARE tool to evaluate 244 included\nstudies, five criteria were presented in Table 2 along\nwith the Kappa ’s index and the level of agreement. The\ninclusion and exclusion criteria have been reported in\n220 of included studies (90.2%), while 22 studies were\nevaluated with partially reporting (9%), and two papers\ndid not report this criterion (0.8%). Search coverage was\nwritten in 122 of the included studies (50%), while 115\nstudies reported partially (47.1%), and seven studies did\nnot report that criterion (2.9%). Among 244 included\nstudies, tools of QA were reported in 126 studies\n(51.6%); meanwhile, three articles partially performed\nQA (1.2%), and 115 studies did not assess the QA of\ntheir studies (47.2%). Study description and study syn-\nthesis criteria have been evaluated, and the level of\nagreement was critical for both. The QA result of five\nDARE assessment criteria was provided in Fig. 2 and\nTable S 4.\nSummary of QA tools\nWe identified 51 different available QA tools. Of these,\n48 tools from the first phase were retrieved from within\nincluded studies and three tools from the second phase\nfound by Google engine, including IVD (in vitro diagno-\nsis), artificial rumen system, and OHAT. We found that\n26 used tools (51%) in the first phases developed by the\nauthors [ 20– 45], while other 22 tools were pre-\nstructured and included 19 studies from the first phases\nTable 1 Principal characteristics of included articles using QA tools in vitro SRs/MAs (Continued)\nCharacteristics Categorization All studies ( N =\n244)\nFollowing previous description of Sackett et al 1 (0.4%)\nJADAD 1 (0.4%)\nSciRAP method 1 (0.4%)\nCASP and MINORS 1 (0.4%)\nTimmer’s Analysis Tool 1 (0.4%)\nARRIVE 1 (0.4%)\nQUADAS 1 (0.4%)\nModifying Quality Assessment Tool for Studies with Diverse Designs (QATSDD) 1 (0.4%)\nReferencing CRH and the EBM Evidence Pyramid 1 (0.4%)\nNature Publication Quality Improvement Project (NPQIP) study 1 (0.4%)\nStandard Quality Assessment Criteria for Evaluating Primary Research Papers from a Variety of\nFields\n1 (0.4%)\nFollowing previous description of Samuel et al. 1 (0.4%)\nSYCLE 1 (0.4%)\nWorld Cancer Research Fund/ University of Bristol for cell line 1 (0.4%)\nCRIS guidelines 1 (0.4%)\nFollowing Joanna Briggs Institute Clinical Appraisal Checklist for Experimental Studies 1 (0.4%)\nPRISMA 1 (0.4%)\nDowns and Black 1 (0.4%)\nAbbreviations: N: No; NR: Not Report; Y: Yes; PRIMA: Preferred Reporting Items for Systematic Reviews and Meta-Analyses; AMSTAR: Assessment of Mult iple\nSystematic Reviews; QUOROM: Quality of Reporting of Meta-analyses; QATSDD: Quality Assessment Tool for Studies with Diverse Designs;\nThe summary statistics are absolute count (%) for categorical variables\nTable 2 Agreement between reviewers of QA of the included\nstudies using DARE assessment criteria\nItems Kappa ’ index Level of Agreement\nInclusion and exclusion 0.94 Almost perfect\nSearch coverage 0.95 Almost perfect\nAssessment of quality 1.00 Almost perfect\nStudy description 0.89 Strong\nSynthesis of study 0.88 Strong\nTran et al. BMC Medical Research Methodology          (2021) 21:101 Page 5 of 13\nand three tools from the second phase accounted for the\nremaining 49%. Among 26 QA tools developed by the\nauthors, 20 tools (76.9%), specialized in dentistry studies\nwhereas two tools (7.7%) applied in the methodology,\ntwo tools (7.7%) applied in bioactivity studies, and two\ntools (7.7%) involved in the biology studies. Among tools\ndeveloped by the authors, 17 tools (65.38%) [ 20, 21, 23,\n26– 34, 39, 40, 42, 44, 45] mentioned items, which could\nbe used only in specific fields (mainly on dentistry) while\nnine tools (34.62%) [ 22, 24, 25, 35– 38, 41, 43] contrib-\nuted the criteria for general reviews, as shown in Table 3.\nTools used for a specific study often contained unique\nfactors directly relating to the test materials and out-\ncomes in the reviews. Examples of this include teeth free\nof caries, the specimen preparation, specimen dimen-\nsion, enamel antagonist, the specimen shape, concentra-\ntion of enzymes, storage condition of the sample, or the\nused devices. The authors also highly concern on the\nbias of method, which could affect the reliability of out-\ncomes, namely calculating sample size, the\nrandomization of samples, the blinding of the examiner,\nand the appropriate form of statistical analysis. Instead,\ntools used for general SRs/MAs evaluated the reliability\nof methodology to report results generally [ 43] or con-\nsisted of items assessing each step of study (objective, se-\nquence generation, blinding, selection bias, detection\nbias, performance bias, report bias). The majority of\nthese tools (11 tools, 42.3%) were contributed as simple\nchecklists. These tools only had questions and required\nthe answers of “yes”, “no” or “not report. ” The overall\nbias could be decided by the number of “yes” or “no” an-\nswers. Seven checklists with judgment (26.9%) among\ntools developed by the authors contained multiple items,\nwhich required the authors to provide their assessment\nin details and compared them between studies. Finally,\neight scale tools (30.8%) rated the quality of each item\nwith varied levels by giving points to them; for instance,\nreported answer = 1 point, not reported answer = 0\npoints. There were also tool in quality ratings of each\ndomain with different levels (0 – 4 points). The summary\nFig. 2 QA results of the included studies using DARE assessment criteria\nTable 3 Summary results comparing the identified tools by type\nTool characteristics Developed by the authors\n(number, %)\nPre-structured tools\n(number, %)\nPurpose\nItems used in specific fields 17, 65.38% [ 20, 21, 23, 26– 34, 39, 40, 42, 44, 45] 5, 20% [ 46– 49]\nItems used for general systematic reviews 9, 34.62% [ 22, 24, 25, 35– 38, 41, 43] 20, 80% [ 50– 57]\nCharacteristics\nSimple checklist 11, 42.3% [ 22, 24– 27, 29, 31, 33, 39, 45] 4, 16% [ 52, 55, 56]\nChecklist with judgment 7, 26.9% [ 20, 35, 36, 41– 43, 45] 7, 28% [ 46, 47, 49– 51, 53, 54]\nScale 8, 30.8% [ 23, 28, 30, 32, 34, 37, 40, 44] 14, 56% [ 48, 57]\nTotal (number, 100%) 26, 100% 25, 100%\nTran et al. BMC Medical Research Methodology          (2021) 21:101 Page 6 of 13\nscore of each study determined as high, low or unclear\nrisk of bias correspondingly.\nIn contrast, for 25 pre-structured tools, there were ap-\nproximately 20 tools (80%) used for general SRs/MAs.\nThe exceptions were QA for IVD [ 46], a tool for in vitro\nstudies using artificial rumen [ 47], which specialized in\nstudies on cell lines, and two tools for the evaluation of\ntoxicological/ecotoxicological data [ 48, 49]. In general,\nthere were four simple checklists, six checklists with\njudgment with 15 scales respectively (Table 3). IVD and\nartificial rumen tools are checklists with conclusions.\nThe assessments entirely required the examiners to give\ntheir checking based on available criteria. Tool for IVDs\nsuggested validations relating to their technical charac-\nteristics, namely technical specification actable for regis-\ntry purposes, their format for technical file,\nmanufacturers, their proper distribution, and cost-\neffectiveness.\nSimilarly, the validation established for experiments\nwith artificial rumen focused on specific criteria via the\nassessment of microorganisms, dividing protozoa, incu-\nbation periods, the digestion, and the interaction be-\ntween chemicals used. Meanwhile, the tool specializing\nin cell lines (World Cancer Research Fund, University of\nBristol) also highlighted the cell line characteristics, re-\npetitive numbers of experiments, and the reporting se-\nlection of outcomes. The first tool in toxicological/\necotoxicological information was developed by Klimisch\net al. [ 49]. The criteria entirely focused on factors affect-\ning the results, namely the test substances (their purity/\norigin/composition, their concentration/doses) or test\nsystems (their suitability, the physical and chemical char-\nacteristics of the medium, negative/positive controls)\nand method to measure the results (appropriate statistic\nmethod). These authors suggested four levels of quality,\nincluding reliable with and without restriction, not reli-\nable and not assignable, accordingly. However, this ap-\nproach did not have specific guidance for the quality\nevaluation. In 2009, Schneider et al. [ 48] developed a\nmore detailed tool named ToxRTool based on Klimisch\net al. [ 49] ‘s suggestion to address this flaw. The ToxR-\nTool for in vitro SRs/MAs included 18 questions evalu-\nating the test substances, test system, study design\ndescription, study results documentation, and plausibility\nof study design and data. For each criterion reported,\nthe study gets one point. The summary score will ini-\ntially determine its level of quality. However, Schneider\net al. [ 48] indicated some critical criteria would down-\ngrade the overall level if the study did not report it. The\nevaluators will give their decision after considering both\nthe summary score and the answer to critical questions.\nFor 20 pre-structured tools for general reviews, they\nemphasized the bias based on the detection or selection\nof samples, the balance of baseline characteristics, the\ncomplete outcome reported, and the sequence gener-\nation. Two of these tools (EBM Evidence Pyramid and\nGRADE tool) were wrongly used as assessment tools of\nmethodological quality or risk of bias. Mainly, Xiao et al.\n[58] used EBM Evidence Pyramid to evaluate the meth-\nodological quality, while Pavan et al. [ 59] used GRADE\ntool to assess the risk of bias of their included studies.\nHowever, we still had them as exceptional cases of QA\ntools applied by other authors of SRs/MAs in our re-\nsearch. Among these 20 pre-structured tools, the QA\ntool referring to CRH and the EBM Evidence Pyramid\n[50] might be classified as the most straightforward\nchecklist. This tool has four levels and defines the grades\nof quality based on the study design (SRs/MAs of\nin vitro studies = A) and baseline characteristics (com-\nparable baseline = B, unknown baseline = C, no similar\nbaseline = D). However, it is inappropriate to evaluate\nthe methodology of a SR/MA only based on the baseline\ncharacteristics. The GRADE tool [ 51] is a tool to grade\nthe quality of evidence (strong to low quality), which\nconsists of six other domains (study design, inconsist-\nency, indirectness, limitations, imprecision, and publica-\ntion bias) to adjust (downward or upward) this initial\nassessment of quality. Therefore, the GRADE tool in-\nstructs the authors on defining the critical outcomes and\nevaluating the quality of such results rather than asses-\nsing the study ’s risk of bias.\nFor the remained 18 tools, although there were both\nchecklists with available questions needing yes/no an-\nswers and lists with domains needs requiring assessor ’s\nopinions, these questions are divided into these domains:\nrationale of the study, samples, randomization, blinding,\nprocedures, reported outcomes, discussion evaluation\nand other bias (Table 4). The criteria were highly varied.\nThe most popular criterion, which needs to be consid-\nered as the appropriate analysis, was mentioned in\nCochrane Collaboration [ 60], Joanna Briggs Institute\nClinical Appraisal Checklist for Experimental Studies\n[61], Timmer ’s Analysis Tool [ 52], and OHAT [ 53].\nOther pricipal criteria are description of data collection,\nthe blinding of samples and investigators/assessors, ap-\npropriate method, reporting of all outcomes mentioned\nin the method, and reporting of missing data. These cri-\nteria were mentioned by three tools in Table 4. The less\nhighlighted criteria include the reasonable sample size,\nthe appropriate method of data collection, the represen-\ntative samples, the balanced baseline characteristic be-\ntween intervention groups, the detailed sample data, the\nrandomization of allocation sequence, the assurance that\nsamples received the proper procedure, the appropriate\ncontrol/reference standards, and the adjusted con-\nfounders. Finally, the criteria rated by only one tool are\nthe rationale of the study, the description of the sample\ncollection tool, the description of controls/reference\nTran et al. BMC Medical Research Methodology          (2021) 21:101 Page 7 of 13\nTable 4 The criteria rated by five tools (Cochrane collaboration, Joanna Briggs Institute Clinical appraisal checklist for experimental\nstudies, QUADAS tool, Timmer ’s analysis tool, OHAT)\nCriteria Cochrane\nCollaboration\nJoanna Briggs Institute Clinical Appraisal\nChecklist for Experimental Studies\nQUADAS\ntool\nTimmer’s\nAnalysis\nTool\nOHAT\nRationale\nof study\nRationale of study – + –– –\nSample\nReasonable sample size – ++ –\nDescription of data collection – ++ + –\nAppropriate method of data\ncollection\n– + – + –\nSample collection tool – + –– –\nRepresentative/ appropriate samples –– ++ –\nThe balanced baseline characteristics\nbetween intervention groups\n+ –– – +\nDetailed sample data – + – + –\nDescription of control/reference\nstandard\n–– + ––\nAppropriate control/reference –– – + –\nRandomization\nRandomization of allocation\nsequence\n+ –– + –\nAdequate randomization –– – – +\nBlinding\nAllocation sequence + –– – –\nSample/Participants + –– ++\nInvestigators/Assessors + –– ++\nProcedure\nFull description of procedures – + –– –\nSamples received proper procedure + – + ––\nIdentical procedure between group –– – – +\nChoice of appropriate method –– ++ +\nAppropriate control/reference\nstandard\n–– + ––\nThe ability for replication –– + ––\nAppropriate analysis + + + +\nJustification of method analysis + –– –\nIdentical analysis between group + –– – –\nAdjust confounders –– – ++\nReporting outcomes\nComplete reported results + –– ++\nComplete data + –– – –\nNo selection of reported results + –– – –\nIntermediate results reported –– + ––\nMissing data reported + – ++ –\nClinical practice reflection –– + ––\n+ This is a criterion of the tool\n- This is not required\nTran et al. BMC Medical Research Methodology          (2021) 21:101 Page 8 of 13\nstandards, the adequate randomization, the blinding of\nallocation sequence, the full description of procedures,\nthe identical approach between groups, the description\nof control/reference standard, the replication, the justifi-\ncation of method analysis, the similar research between\ngroups, the report of complete data, no selection of re-\nported results, report of intermediate results and the re-\nquirement of the reflection in a clinical trial.\nDiscussion\nThe publication trend of in vitro SRs/MAs has been re-\ncently increasing [ 62]. This was demonstrated by the\nnumber of SRs/MAs found in our study along with the\nrecent surge of novel QA tools for in vitro studies [ 48,\n53]. QA highly plays a critical role in every SR/MA to\njudge the methodology and reliability, reduce the risk of\nbias, and strengthen the evidence and recommendations\ntaken from such reviews [ 63]. However, the percentage\nof papers, which reported QA procedures in our SRs/\nMAs, was associated with an increasing trend to 42% in\n2016. This was relatively low compared to other areas,\nsuch as in randomized clinical trials, the Cochrane tool\nwas reported as widely used in 100% Cochrane reviews\n[64].\nIn our study, a total of 51 tools has been identified\nfrom two phases, in which, 48 tools were used by au-\nthors of the included studies and three tools were found\nvia Google engine. There were 26 articles, which used in\nthe authors ’ methodological assessment, and other tools\nwere pre-structured. Almost every study used a different\nQA tool, which imposed several challenges that might\nrestrict the process of consistent, reliable, and integral\nappraisal of SRs/MAs. Most QA tools in SRs/MAs of\ndentistry topic were developed by the authors. These\ntools were mainly methodological QA that primarily fo-\ncused on materials and standard procedures in dentistry.\nAlso, the majority of dentistry SRs/MAs followed by the\ncriteria previously proposed by Onofre et al. This im-\nplied that the criteria for assessing the methodology in\ndental procedures were standards and could be applied\nwidely in different SRs/MAs. Only few dental SRs/MAs\nfollowed QA process as the instructed in pre-structured\ntools such as Cochrane or CASP and MINORS [ 65– 69].\nRegarding SRs/MAs relating to toxicology and diagno-\nsis, there was a consistent manner among applied tools\nsince these QA tools specialized in each specific topic.\nFor instance, ToxRTool was applied in toxicological\nstudies and QUADAS-2 used in diagnosis studies. We\nalso recommend these tools in SRs/MAs of these par-\nticular topics because the criteria mainly cover the es-\nsential aspects from the included studies. Other SRs/\nMAs of other subjects (biology, bioactivity, and mate-\nrials) assessed the quality of included studies primarily\nby pre-structured tools. However, they considered a\nvariety of selected QA tools used. Both methodological\nand reporting QA tools were applied. The authors had\nto modify these tools for their in vitro SRs/MAs since\nthese tools were initially applied for in vivo studies\n(SYCLE tool) or clinical trials (MINORS, CONSORT\nchecklist, Cochrane risk of bias tool). This resulted in\nseveral inappropriate criteria, which were only applicable\nin clinical trials or in vivo studies, which were included\nin assessing quality. Only few SRs/MAs developed their\nown criteria for these assessments [ 23, 70, 71]. As a re-\nsult, this variety of QA tools poses a difficulty for re-\nsearchers to select which tool is more suitable to apply.\nAlso, the inconsistency of items covered by each tool\nwill affect the review process, especially when a specific\ntool dismisses items that reflect the essential informa-\ntions on the study under-assessment. This mostly oc-\ncurred in methodological QA tools since no current tool\ncovers all methodological aspects for all topics. There-\nfore, this emphasizes the importance of reaching a con-\nsensus among researchers regarding QA tools for\nin vitro SRs/MAs comprehensively. Possibly there were\nseveral inappropriate criteria included in a tool and lack-\ning of several critical criteria, there is a need for consen-\nsus of essential aspects that should be included in QA\ntool of in vitro SRs/MAs as well as the removal of un-\nnecessary criteria.\nGiven the lack of a standard QA tool for in vitro stud-\nies, several authors tend to develop a checklist that suits\nthe needs of their project. Passos et al. [ 20], Altmann\net al. [ 21], and Goldbach et al. [ 25] have developed dif-\nferent sets of QA tools that are either generic or serve\nspecific purposes. Sarkis-Onofre et al. [ 26, 72– 77] also\ndeveloped several scales for single use in a particular\ncontext. This tool was used by other in vitro studies of\nthe same topic in our sample and consisted of seven\nitems. The most commonly used items among seven\nstudies including sample size calculation and\nrandomization of ceramic specimen/teeth, indicated a\nspecific field of in vitro research. A highlight of tool de-\nveloped by authors in conducting their study is their\ntechnical characteristics. These assessment help the au-\nthors evaluate the exact level of quality of included stud-\nies by relevant factors that affect the reliability of these\nstudies (including the used devices, the appropriate\nmedium, or specimens). However, the tools missed non-\ntechnical factors causing bias, such as the integrity of\ndata reported or the appropriate analysis method. Three\nother tools [ 22, 24, 25], which were developed by au-\nthors but covered different aspects of a study, appeared\nto comprehensively evaluate their included studies ran-\nging from report/performance/selection/detection cri-\nteria. However, the guidance for using these tools was\nnot clarified in these reviews, as they only rated these\ncriteria based on their own research question leading to\nTran et al. BMC Medical Research Methodology          (2021) 21:101 Page 9 of 13\nthe limitations if other reviews aimed to use their ap-\nproaches. The specificity of these tools limits their use\non a broader scale, and the variant nature facilitates a re-\nsearcher to disregard specific tools in literature\nsearching.\nToxRTool, which was known as criteria for reporting\nand evaluating ecotoxicity data, and other standardized\ntools were developed to provide more detailed and\ntransparent evaluation systems [ 78– 80]. ToxRTool has\nbecome widely used in toxicological research, and there\nare similar tools adapted from it [ 81]. However, the\nconsistency of ToxRTool has some limitations and re-\nquires some refinements [ 82]. In fact, ToxRTool aimed\nto evaluate the toxicological data. Therefore, there are\nmany questions relating to the test substance and test\nsystems that might not be important for other in vitro\nstudies, for instance, the pureness and source of the test\nsubstance.\nMoreover, the lack of positive control would reduce\npoints of the quality of a study. However, not all in vitro\nstudies have their positive control. This decision de-\npends on the research questions and the purposes of the\nstudy. Several other crucial factors for general in vitro\nstudies were neglected in this tool, such as the descrip-\ntion of sample collection or the suitable sample size. For\nthese reasons, ToxRTool might be the best choice for\ntoxicological studies. Nevertheless, if we used it for re-\nviews of in vitro studies in other fields, it could not as-\nsess the appropriate levels of quality for included\nstudies.\nAmongst pre-structured tools for general reviews in-\ncluded in our study, EBM Evidence Pyramid and\nGRADE tool were wrongly applied to assess the method-\nology and risk of bias. We do not recommend other au-\nthors to use these tools in their SRs/MAs in the future.\nOn the other hand, it seems that no tool covers almost\nthe essential criteria, such as sample size, the procedure\nof sample collection, negative/positive controls,\nrandomization, blinding, analysis, data complete, and\nmissing data. For instance, the justification of sample\nsize, the full description of experimental procedures, and\nthe appropriate positive/negative controls were only in-\ncluded for assessment in limited tools.\nSimilarly, the report of missing data and the comple-\ntion of data report are also important since they relate\nto the reporting bias leading to the inaccurate reflection\nof in vitro results in clinical trials. But these criteria are\nonly mentioned in one tool. In contrast, for in vitro\nstudies, the blinding of the sample (participant) is un-\nnecessary since this kind of sample could not cause re-\nport bias. However, this criterion is requested to report\nin many tools due to the modification of QA tools of\nin vivo studies or clinical trials. This gap leads to the fact\nthat whether the authors use any tools for their reviews,\nthe assessment might not reflect the proper level of\nquality of included studies. This depends on authors ’\nperspective to determine which tool is more relevant to\ntheir research questions. Frequently, the authors should\ncombine several tools to get the most suitable one for\ntheir study. But this could not be applied widely if no\ndetailed guidance is developed. Three tools mentioned\nthe randomization, in which, Cochrane Collaboration\nand Timmer ’s Analysis Tool suggested the\nrandomization of allocation sequence meanwhile OHAT\nrecomended assessing whether the randomization was\nadequate. This is a challenge for in vitro reviews since\nthe randomization is difficult to apply for in vitro mate-\nrials. Unfortunately, no in vitro review in our study clari-\nfied how they determined the randomization in their\nincluded studies. We do not deny the critical role of\nrandomization to reduce the selection bias and reduce\nthe wrong results caused by different characteristics of\nsamples. However, we suggest that additional QA tools\nfor in vitro studies should focus on criteria to assure the\nidentical attributes in studied samples. This finding is\neasier than the contribution to the method of\nrandomization. Finally, we agree that a QA tool for\nin vitro studies should include the blinding of investiga-\ntors and assessors. This can reduce the bias caused by\nthe ability to predict the results of the researchers.\nOur study had certain limitations. Despite low prob-\nability, we applied the restrictions to our search during\n14 years, excluding in vivo studies and combined studies.\nIn addition, 300 links screening from Google search en-\ngine might result in a missed tool or guideline. Also, we\nincluded all tools applied by the authors in their SRs/\nMAs that led to forming some inappropriate QA tools\n(GRADE tool and EBM Evidence Pyramid). However, we\ndiscussed this problem and did not recommend it in\nother SRs/MAs of in vitro studies.\nConclusions\nMultiple different QA tools are currently available\nthroughout the literature. However, none could cover all\ncritical aspects of in vitro SRs/MAs. Thus, a comprehen-\nsive guide should be developed to addresses all signifi-\ncant concerns and aspects of this field. This would have\nthe possibility to increase the transparency and reprodu-\ncibility of scientific work, boosting the reliability and val-\nidity of available in vitro findings. This study serves as\nan initial step towards achieving these targets by sum-\nmarizing the QA tools that are readily utilized through-\nout the literature while pointing out potential\nimprovements to be adopted in the future.\nAbbreviations\nAMSTAR: Assessment of Multiple Systematic Reviews; CASP: Critical Appraisal\nSkills Programme; CRD: Center for Reviews and Dissemination;\nDARE: Database of Abstract of Reviews of Effects; EBM: Evidence-based\nTran et al. BMC Medical Research Methodology          (2021) 21:101 Page 10 of 13\nmedicine; IVD: In vitro diagnosis; JBI: Joanna Briggs Institute; MA: Meta-\nanalyses; NICE: National Institute for Clinical Excellence; PRISMA: Preferred\nreporting items for systematic reviews and meta-analyses; QA: Quality\nassessment; QUOROM: Quality of Reporting of Meta-analyses; SIGN: Scottish\nIntercollegiate Guidelines Network; SR: Systematic reviews; VHL: Virtual Health\nLibrary\nSupplementary Information\nThe online version contains supplementary material available at https://doi.\norg/10.1186/s12874-021-01295-w.\nAdditional file 1: Table S1. PRISMA checklist.\nAdditional file 2: Table S2. Detailed search strategy for each database\nsearch.\nAdditional file 3: Table S3. List of excluded studies.\nAdditional file 4: Table S4. List of included articles using QA tools in\nin vitro SRs/MAs.\nAdditional file 5: Table S5. Detailed result of DARE assessment criteria\nof included studies.\nAdditional file 6: Figure S1. The interpretation for fulfilling a “yes”,\n“partial” and “no” score.\nAcknowledgments\nWe would like to thank Mohamed Omar El-Badry, Faculty of Medicine, Al-\nAzhar University, Cairo, 11884, Egypt; Ashraf Ismail Sayed, Faculty of Medicine,\nAl-Azhar University, Assuit, Egypt; Ahmed Magdey Sayed, Faculty of Phar-\nmacy, Al-Azhar University, Cairo, Egypt; Salma Y Fala, Faculty of Medicine,\nSuez Canal University, Ismailia, Egypt; Thi Nguyen Minh, Department of Radi-\nology, Go Vap hospital, Ho Chi Minh, 70000, Viet Nam; Maha Elbadawy, Min-\nistry of Health, Egypt; Mohamed Tamer Elhady, Department of Pediatrics,\nZagazig University Hospitals, Faculty of Medicine, Sharkia, 44511, Egypt for\ntheir initial contribution to the study. We also thank Thuan Tieu, Faculty of\nHealth Sciences, McMaster University, Hamilton, Canada, for checking English\nfor the manuscript. We would like to thank Dr. Joseph Varney (American Uni-\nversity of Caribbean School of Medicine, Cupecoy, Sint Maarten), a native\nEnglish speaker, for proofreading the manuscript.\nAuthors’ contributions\nNTH proposed the idea of this study and is the supervisor. LT organized\ntasks. All authors involved in screening papers and decided their inclusion/\nexclusion wrote the manuscript and made tables/Figures. LT, DNHT validated\ndata and revised the manuscript under the supervision of KH and NHT. All\nauthors approved the final version.\nFunding\nNot applicable.\nAvailability of data and materials\nThe corresponding authors will provide the datasets in this study by\nreasonable request.\nDeclarations\nEthics approval and consent to participate\nNot applicable.\nConsent for publication\nNot applicable.\nCompeting interests\nNot applicable.\nAuthor details\n1Institute of Fundamental and Applied Sciences, Duy Tan University, Ho Chi\nMinh City 700000, Vietnam. 2Faculty of Natural Sciences, Duy Tan University,\nDa Nang City 550000, Vietnam. 3Asia Shine Trading & Service CO. LTD., Ho\nChi Minh City, Vietnam. 4Online Research Club, Nagasaki, Japan. 5Faculty of\nMedicine, Al-Azhar University, Cairo 11884, Egypt. 6Department of Internal\nMedicine, Texas Tech University Health Science Center at the Permian Basin,\nOdessa, TX, USA. 7Department of Immunogenetics, Institute of Tropical\nMedicine (NEKKEN), Graduate School of Biomedical Sciences, Nagasaki\nUniversity, 1-12-4 Sakamoto, Nagasaki 852-8523, Japan. 8School of Tropical\nMedicine and Global Health, Nagasaki University, 1 – 12– 4 Sakamoto, Nagasaki\n852-8523, Japan.\nReceived: 2 June 2020 Accepted: 26 April 2021\nReferences\n1. Manchikanti L. Evidence-based medicine, systematic reviews, and guidelines\nin interventional pain management, part I: introduction and general\nconsiderations. Pain Physician. 2008;11(2):161 – 86.\n2. Lau J, Ioannidis JP, Schmid CH. Summing up evidence: one answer is not\nalways enough. Lancet. 1998;351(9096):123 – 7. https://doi.org/10.1016/S014\n0-6736(97)08468-7.\n3. Oxman AD, Schnemann HJ, Fretheim A. Improving the use of research\nevidence in guideline development: 8. Synthesis and presentation of\nevidence. Health Res Policy Syst. 2006;4(20). https://doi.org/10.1186/1478-4\n505-4-20.\n4. Swennen MH, van der Heijden GJ, Boeije HR, van Rheenen N, Verheul FJ,\nvan der Graaf Y, et al. Doctors' perceptions and use of evidence-based\nmedicine: a systematic review and thematic synthesis of qualitative studies.\nAcad Med. 2013;88(9):1384 – 96. https://doi.org/10.1097/ACM.0b013e3182\n9ed3cc.\n5. Gallagher EJ. Systematic reviews: a logical methodological extension of\nevidence-based medicine. Acad Emerg Med. 1999;6(12):1255 – 60. https://doi.\norg/10.1111/j.1553-2712.1999.tb00142.x.\n6. Ritskes-Hoitinga M, Leenaars M, Avey M, Rovers M, Scholten R. Systematic\nreviews of preclinical animal studies can make significant contributions to\nhealth care and more transparent translational medicine. Cochrane\nDatabase Syst Rev. 2014;3:ED000078.\n7. Sena ES, Currie GL, McCann SK, Macleod MR, Howells DW. Systematic\nreviews and meta-analysis of preclinical studies: why perform them and\nhow to appraise them critically. J Cereb Blood Flow Metab. 2014;34(5):737 –\n42. https://doi.org/10.1038/jcbfm.2014.28.\n8. Howells DW, Sena ES, Macleod MR. Bringing rigour to translational\nmedicine. Nat Rev Neurol. 2014;10(1):37 – 43. https://doi.org/10.1038/\nnrneurol.2013.232.\n9. Brouwers MC, Johnston ME, Charette ML, Hanna SE, Jadad AR, Browman GP.\nEvaluating the role of quality assessment of primary studies in systematic\nreviews of cancer practice guidelines. BMC Med Res Methodol. 2005;5(1):8.\nhttps://doi.org/10.1186/1471-2288-5-8.\n10. Shamliyan T, Kane RL, Jansen S. Quality of systematic reviews of\nobservational nontherapeutic studies. Prev Chronic Dis. 2010;7(6): A133.\nPMID: 20950540; PMCID: PMC2995597.\n11. Wong WC, Cheung CS, Hart GJ. Development of a quality assessment tool\nfor systematic reviews of observational studies (QATSO) of HIV prevalence in\nmen having sex with men and associated risk behaviours. Emerg Themes\nEpidemiol 2008;5(23). https://doi.org/10.1186/1742-7622-5-23.\n12. National Health and Medical Research Council. Assessing risk of bias.\nAvailable from: https://www.nhmrc.gov.au/guidelinesforguidelines/\ndevelop/assessing-risk-bias. Accessed 20 Aug 2020.\n13. Liberati A, Altman DG, Tetzlaff J, Mulrow C, Gotzsche PC, Ioannidis JP, et al.\nThe PRISMA statement for reporting systematic reviews and meta-analyses\nof studies that evaluate health care interventions: explanation and\nelaboration. J Clin Epidemiol. 2009;62(10):e1 – 34. https://doi.org/10.1016/j.\njclinepi.2009.06.006.\n14. Tawfik GM, Dila KAS, Mohamed MYF, Tam DNH, Kien ND, Ahmed AM, et al.\nA step by step guide for conducting a systematic review and meta-analysis\nwith simulation data. Tropical Med Health. 2019;47(1):46. https://doi.org/1\n0.1186/s41182-019-0165-6.\n15. Elshafay A, Omran ES, Abdelkhalek M, El-Badry MO, Eisa HG, Fala SY, et al.\nReporting quality in systematic reviews of in vitro studies: a systematic\nreview. Curr Med Res Opin. 2019;35(9):1631 – 41. https://doi.org/10.1080/03\n007995.2019.1607270.\n16. Madelain V, Nguyen TH, Olivo A, de Lamballerie X, Guedj J, Taburet AM,\net al. Ebola virus infection: review of the pharmacokinetic and\nPharmacodynamic properties of drugs considered for testing in human\nTran et al. BMC Medical Research Methodology          (2021) 21:101 Page 11 of 13\nefficacy trials. Clin Pharmacokinet. 2016;55(8):907 – 23. https://doi.org/10.1\n007/s40262-015-0364-1.\n17. Nogler M, Wimmer C, Mayr E, Öfner D. The efficacy of using search Engines\nin Procuring Information about Orthopaedic Foot and Ankle Problems from\nthe world wide web. Foot Ankle Int. 1999;20(5):322 – 5. https://doi.org/10.11\n77/107110079902000511.\n18. Database of Abstracts of Reviews of Effects (DARE): Quality-assessed\nReviews. York (UK): Centre for Reviews and Dissemination (UK); 1995\nAvailable from: https://www.ncbi.nlm.nih.gov/books/NBK285222/. Accessed\n20 Aug 2020.\n19. Budgen D, Brereton P, Drummond S, Williams N. Reporting systematic\nreviews: some lessons from a tertiary study. Inf Softw Technol. 2018;95:62 –\n74. https://doi.org/10.1016/j.infsof.2017.10.017.\n20. Passos SP, Torrealba Y, Major P, Linke B, Flores-Mir C, Nychka JA. In vitro\nwear behavior of zirconia opposing enamel: a systematic review. J\nProsthodont. 2014;23(8):593 – 601. https://doi.org/10.1111/jopr.12167.\n21. Altmann AS, Collares FM, Leitune VC, Samuel SM. The effect of antimicrobial\nagents on bond strength of orthodontic adhesives: a meta-analysis of\nin vitro studies. Orthod Craniofac Res. 2016;19(1):1 – 9. https://doi.org/1\n0.1111/ocr.12100.\n22. Louropoulou A, Slot DE, Van der Weijden F. Influence of mechanical\ninstruments on the biocompatibility of titanium dental implants surfaces: a\nsystematic review. Clin Oral Implants Res. 2015;26(7):841 – 50. https://doi.\norg/10.1111/clr.12365.\n23. Arilla FV, Yeung M, Bell K, Rahnemai-Azar AA, Rothrauff BB, Fu FH, et al.\nExperimental Execution of the Simulated Pivot-Shift Test: A Systematic\nReview of Techniques. Arthroscopy. 2015;31(12):2445 – 54 e2.\n24. Ehsani S, Mandich MA, El-Bialy TH, Flores-Mir C. Frictional resistance in self-\nligating orthodontic brackets and conventionally ligated brackets. A\nsystematic review. Angle Orthod. 2009;79(3):592 – 601. https://doi.org/10.231\n9/060208-288.1.\n25. Golbach LA, Portelli LA, Savelkoul HF, Terwel SR, Kuster N, de Vries RB, et al.\nCalcium homeostasis and low-frequency magnetic and electric field\nexposure: A systematic review and meta-analysis of in vitro studies. Environ\nInt. 2016;92 – 93:695– 706.\n26. Sarkis-Onofre R, Skupien JA, Cenci MS, Moraes RR, Pereira-Cenci T. The role\nof resin cement on bond strength of glass-fiber posts luted into root canals:\na systematic review and meta-analysis of in vitro studies. Oper Dent. 2014;\n39(1):E31– 44. https://doi.org/10.2341/13-070-LIT.\n27. Mo żyńska JM, Lipski M, Nowicka A. Tooth discoloration induced by different\ncalcium silicate-based cements: A systematic review of in vitro studies. J\nEndod. 2017;43(10):1593 – 601. https://doi.org/10.1016/j.joen.2017.04.002.\n28. Reis AF, Vestphal M, Amaral RC, Rodrigues JA, Roulet JF, Roscoe MG.\nEfficiency of polymerization of bulk-fill composite resins: a systematic\nreview. Braz Oral Res. 2017;31(suppl 1):e59. https://doi.org/10.1590/1807-31\n07BOR-2017.vol31.0059.\n29. Ferrúa CP, Centeno EG, Rosa LC, Amaral CC, Severo RF, Sarkis-Onofre R, et al.\nHow has dental pulp stem cells isolation been conducted? A scoping\nreview. Braz Oral Res. 2017;31:e87.\n30. Marchionatti AM, Aurélio IL, May LG. Does veneering technique affect the\nflexural strength or load-to-failure of bilayer Y-TZP? A systematic review and\nmeta-analysis. J Prosthet Dent. 2018;119(6):916 – 24. https://doi.org/10.1016/j.\nprosdent.2017.11.013.\n31. Martins FV, Vasques WF, Fonseca EM. Evaluation of the efficiency of fluoride-\nreleasing adhesives for preventing secondary caries in-vitro: a systematic\nreview and meta-analysis. Eur Arch Paediatr Dent. 2019;20(1):1 – 8. https://doi.\norg/10.1007/s40368-018-0388-y.\n32. Elkaffas AA, Eltoukhy RI, Elnegoly SA, Mahmoud SH. The effect of preheating\nresin composites on surface hardness: a systematic review and meta-analysis.\nRestor Dent Endod. 2019;44(4):e41. https://doi.org/10.5395/rde.2019.44.e41.\n33. Pourhajibagher M, Sodagar A, Bahador A. An in vitro evaluation of the effects\nof nanoparticles on shear bond strength and antimicrobial properties of\northodontic adhesives: A systematic review and meta-analysis study. Int\nOrthod. 2020;18(2):203– 13. https://doi.org/10.1016/j.ortho.2020.01.011.\n34. AlFawaz YF, Alonaizan FA. Efficacy of phototherapy in the adhesive bonding\nof different dental posts to root dentin: A systematic review. Photodiagn\nPhotodyn Ther. 2019;27:111 – 6. https://doi.org/10.1016/j.pdpdt.2019.05.024.\n35. Samiei M, Shirazi S, Azar FP, Fathifar Z, Ghojazadeh M, Alipour M. The Effect\nof Different Mixing Methods on the Properties of Calcium-enriched Mixture\nCement: A Systematic Review of in Vitro Studies. Iran Endod J. 2019;14(4):\n240– 6.\n36. Kuik K, De Ruiter MH, De Lange J, Hoekema A. Fixation methods in sagittal\nsplit ramus osteotomy: a systematic review on in vitro biomechanical\nassessments. Int J Oral Maxillofac Surg. 2019;48(1):56 – 70. https://doi.org/10.1\n016/j.ijom.2018.06.013.\n37. Parikh M, Kishan KV, Solanki NP, Parikh M, Savaliya K, Bindu VH, et al. Efficacy\nof removal of calcium hydroxide medicament from root canals by\nEndoactivator and Endovac irrigation techniques: A systematic review of\nin vitro studies. Contemp Clin Dent. 2019;10(1):135 – 42. https://doi.org/10.41\n03/ccd.ccd_335_18.\n38. Silveira FM, de Pauli Paglioni M, Marques MM, Santos-Silva AR, Migliorati CA,\nArany P, et al. Examining tumor modulating effects of photobiomodulation\ntherapy on head and neck squamous cell carcinomas. Photochem\nPhotobiol Sci. 2019;18(7):1621 – 37. https://doi.org/10.1039/C9PP00120D.\n39. Ajay R, Suma K, Ali SA. Monomer modifications of Denture Base acrylic resin:\nA systematic review and meta-analysis. J Pharm Bioallied Sci. 2019;11(Suppl\n2):S112– S25. https://doi.org/10.4103/JPBS.JPBS_34_19.\n40. Özcan M, Höhn J, de Araújo GM, Moura DD, Souza R. Influence of testing\nparameters on the load-bearing capacity of prosthetic materials used for\nfixed dental prosthesis: A systematic review and meta-analysis. Braz Dental\nSci. 2018;21(4):470 – 90.\n41. Khaledi A, Meskini M. A systematic review of the effects of Satureja\nkhuzestanica Jamzad and Zataria multiflora Boiss against Pseudomonas\naeruginosa. Iran J Med Sci. 2020;45(2):83.\n42. Zhao S, Arnold M, Ma S, Abel R, Cobb J, Hansen U, et al. Standardizing\ncompression testing for measuring the stiffness of human bone. Bone Joint\nRes. 2018;7(8):524 – 38.\n43. Hindy A, Farahmand F, sadat Tabatabaei F. In vitro biological outcome of laser\napplication for modification or processing of titanium dental implants. Lasers\nMed Sci. 2017;32(5):1197– 206. https://doi.org/10.1007/s10103-017-2217-7.\n44. Wehner C, Lettner S, Moritz A, Andrukhov O, Rausch-Fan X. Effect of\nbisphosphonate treatment of titanium surfaces on alkaline phosphatase\nactivity in osteoblasts: a systematic review and meta-analysis. BMC Oral\nHealth. 2020;20:1 – 13.\n45. Tan MC, Chai Z, Sun C, Hu B, Gao X, Chen Y, et al. Comparative evaluation\nof the vertical fracture resistance of endodontically treated roots filled with\nGutta-percha and Resilon: a meta-analysis of in vitro studies. BMC Oral\nHealth. 2018;18(1):107. https://doi.org/10.1186/s12903-018-0571-x.\n46. Mirab Samiee S, Rahnomaye Farzami M, Aliasgharpour M, Rafie M,\nEntekhabie B, Sabzavie F. An overview of a new approach in evaluation,\nverification and validity of in vitro diagnosis (IVDs) performance in Iran. Iran\nJ Public Health. 2013;42(1):107 – 9.\n47. Warner ACI. Criteria for establishing the validity of in vitro studies with\nrumen micro-organisms in so-called artificial rumen systems. Microbiology.\n1956;14:733– 48.\n48. Schneider K, Schwarz M, Burkholder I, Kopp-Schneider A, Edler L, Kinsner-\nOvaskainen A, et al. \"ToxRTool\", a new tool to assess the reliability of\ntoxicological data. Toxicol Lett. 2009;189(2):138 – 44. https://doi.org/10.1016/j.\ntoxlet.2009.05.013.\n49. Klimisch HJ, Andreae M, Tillmann U. A systematic approach for evaluating\nthe quality of experimental toxicological and ecotoxicological data. Regul\nToxicol Pharmacol. 1997;25(1):1 – 5. https://doi.org/10.1006/rtph.1996.1076.\n50. SDM C. EBM Evidence Pyramid. 2001; Available from: http://library.downsta\nte.edu/ebmdos/2100.htm. Accessed 20 Aug 2020.\n51. Guyatt G, Oxman AD, Akl EA, Kunz R, Vist G, Brozek J, et al. GRADE\nguidelines: 1. Introduction-GRADE evidence profiles and summary of\nfindings tables. J Clin Epidemiol. 2011;64(4):383 – 94. https://doi.org/10.1016/j.\njclinepi.2010.04.026.\n52. Timmer A, Sutherland LR, Hilsden RJ. Development and evaluation of a\nquality score for abstracts. BMC Med Res Methodol. 2003;3:2. https://doi.\norg/10.1186/1471-2288-3-2.\n53. Tsouh Fokou PV, Nyarko AK, Appiah-Opong R, Tchokouaha Yamthe LR,\nAddo P, Asante IK, et al. Ethnopharmacological reports on anti-Buruli ulcer\nmedicinal plants in three west African countries. J Ethnopharmacol. 2015;\n172:297– 311. https://doi.org/10.1016/j.jep.2015.06.024.\n54. J.P.T. Higgins SGE. Cochrane Handbook for Systematic Reviews of\nInterventions. 1 ed. Chichester, England, Hoboken: Wiley-Blackwell; 2008.\n55. Aminoshariae A, Kulild J. Master apical file size - smaller or larger: a\nsystematic review of microbial reduction. Int Endod J. 2015;48(11):1007 – 22.\nhttps://doi.org/10.1111/iej.12410.\n56. Group DTAW. Available from: http://srdta.cochrane.org. Accessed 20 Aug\n2020.\nTran et al. BMC Medical Research Methodology          (2021) 21:101 Page 12 of 13\n57. Sirriyeh R, Lawton R, Gardner P, Armitage G. Reviewing studies with diverse\ndesigns: the development and evaluation of a new tool. J Eval Clin Pract.\n2012;18(4):746– 52. https://doi.org/10.1111/j.1365-2753.2011.01662.x.\n58. Xiao Z, Li C, Shan J, Luo L, Feng L, Lu J, et al. Mechanisms of renal cell\napoptosis induced by cyclosporine A: a systematic review of in vitro studies.\nAm J Nephrol. 2011;33(6):558 – 66. https://doi.org/10.1159/000328584.\n59. Pavan LM, Rêgo DF, Elias ST, De Luca CG, Guerra EN. In vitro anti-tumor\neffects of statins on head and neck squamous cell carcinoma: A systematic\nreview. PLoS One. 2015;10(6):e0130476. https://doi.org/10.1371/journal.pone.\n0130476.\n60. Maina S, Misinzo G, Bakari G, Kim HY. Human, Animal and Plant Health\nBenefits of Glucosinolates and Strategies for Enhanced Bioactivity: A\nSystematic Review. Molecules. 2020;25(16):3682. https://doi.org/10.3390/\nmolecules25163682.\n61. Nazeam J, Mohammed EZ, Raafat M, Houssein M, Elkafoury A, Hamdy D,\net al. Based on principles and insights of COVID-19 epidemiology, genome\nsequencing, and pathogenesis: retrospective analysis of Sinigrin and Prolixin\n(RX) (Fluphenazine) provides off-label drug candidates. SLAS Discovery.\n2020;25(10):1123– 40. https://doi.org/10.1177/2472555220950236.\n62. Hooijmans C, Ritskes-Hoitinga M. Progress in using systematic reviews of\nanimal studies to improve translational research. PLoS Med. 2013;10(7):\ne1001482. https://doi.org/10.1371/journal.pmed.1001482.\n63. Shea BJ, Hamel C, Wells GA, Bouter LM, Kristjansson E, Grimshaw J, et al.\nAMSTAR is a reliable and valid measurement tool to assess the\nmethodological quality of systematic reviews. J Clin Epidemiol. 2009;62(10):\n1013– 20. https://doi.org/10.1016/j.jclinepi.2008.10.009.\n64. Jørgensen L, Paludan-Müller AS, Laursen DR, Savovi ć J, Boutron I, Sterne JA,\net al. Evaluation of the Cochrane tool for assessing risk of bias in\nrandomized clinical trials: overview of published comments and analysis of\nuser practice in Cochrane and non-Cochrane reviews. Syst Rev. 2016;5(1):80.\nhttps://doi.org/10.1186/s13643-016-0259-8.\n65. Baumgartner S, Koletsi D, Verna C, Eliades T. The effect of enamel\nsandblasting on enhancing bond strength of orthodontic brackets: A\nsystematic review and meta-analysis. J Adhes Dent. 2017;19(6):463 – 73.\n66. Kulkarni S, Meer M, George R. The effect of photobiomodulation on human\ndental pulp-derived stem cells: systematic review. Lasers Med Sci. 2020;\n35(9):1889– 97. https://doi.org/10.1007/s10103-020-03071-6.\n67. Dumbryte I, Vebriene J, Linkeviciene L, Malinauskas M. Enamel microcracks\nin the form of tooth damage during orthodontic debonding: a systematic\nreview and meta-analysis of in vitro studies. Eur J Orthod. 2018;40(6):636 – 48.\nhttps://doi.org/10.1093/ejo/cjx102.\n68. Iliadi A, Koletsi D, Eliades T. Forces and moments generated by aligner-type\nappliances for orthodontic tooth movement: A systematic review and meta-\nanalysis. Orthod Craniofac Res. 2019;22(4):248 – 58. https://doi.org/10.1111/\nocr.12333.\n69. Mello CC, Lemos CA, de Luna Gomes JM, Verri FR, Pellizzer EP. CAD/CAM vs\nconventional technique for fabrication of implant-supported frameworks: A\nsystematic review and meta-analysis of in vitro studies. Int J Prosthodont.\n2019;32(2):182– 92. https://doi.org/10.11607/ijp.5616.\n70. Silveira RG, Ferrúa CP, do Amaral CC, Garcia TF, de Souza KB, Nedel F.\nMicroRNAs expressed in neuronal differentiation and their associated\npathways: Systematic review and bioinformatics analysis. Brain Res Bull.\n2020;157:140– 8.\n71. García-Sanz V, Paredes-Gallardo V, Mendoza-Yero O, Carbonell-Leal M,\nAlbaladejo A, Montiel-Company JM, et al. The effects of lasers on bond\nstrength to ceramic materials: A systematic review and meta-analysis. PLoS\nOne. 2018;13(1):e0190736. https://doi.org/10.1371/journal.pone.0190736.\n72. Lenzi TL, Gimenez T, Tedesco TK, Mendes FM, Rocha RO, Raggio DP.\nAdhesive systems for restoring primary teeth: a systematic review and\nmeta-analysis of in vitro studies. Int J Paediatr Dent. 2016;26(5):364 – 75.\nhttps://doi.org/10.1111/ipd.12210.\n73. Rosa WL, Piva E, Silva AF. Bond strength of universal adhesives: A systematic\nreview and meta-analysis. J Dent. 2015;43(7):765 – 76. https://doi.org/10.1016/\nj.jdent.2015.04.003.\n74. Moraes AP, Sarkis-Onofre R, Moraes RR, Cenci MS, Soares CJ, Pereira-Cenci T.\nCan Silanization increase the retention of glass-fiber posts? A systematic\nreview and meta-analysis of in vitro studies. Oper Dent. 2015;40(6):567 – 80.\nhttps://doi.org/10.2341/14-330-O.\n75. Aurélio IL, Marchionatti AM, Montagner AF, May LG, Soares FZ. Does air\nparticle abrasion affect the flexural strength and phase transformation of Y-\nTZP? A systematic review and meta-analysis. Dent Mater. 2016;32(6):827 – 45.\nhttps://doi.org/10.1016/j.dental.2016.03.021.\n76. AlShwaimi E, Bogari D, Ajaj R, Al-Shahrani S, Almas K, Majeed A. In vitro\nantimicrobial effectiveness of root canal sealers against enterococcus\nfaecalis: A systematic review. J Endod. 2016;42(11):1588 – 97. https://doi.org/1\n0.1016/j.joen.2016.08.001.\n77. Pereira GK, Venturini AB, Silvestri T, Dapieve KS, Montagner AF, Soares FZ,\net al. Low-temperature degradation of Y-TZP ceramics: A systematic review\nand meta-analysis. J Mech Behav Biomed Mater. 2015;55:151 – 63. https://doi.\norg/10.1016/j.jmbbm.2015.10.017.\n78. Money CD, Tomenson JA, Penman MG, Boogaard PJ, Jeffrey LR. A\nsystematic approach for evaluating and scoring human data. Regul Toxicol\nPharmacol. 2013;66(2):241 – 7. https://doi.org/10.1016/j.yrtph.2013.03.011.\n79. Samuel GO, Hoffmann S, Wright RA, Lalu MM, Patlewicz G, Becker RA, et al.\nGuidance on assessing the methodological and reporting quality of\ntoxicologically relevant studies: A scoping review. Environ Int. 2016;92 – 93:\n630– 46.\n80. Lynch HN, Goodman JE, Tabony JA, Rhomberg LR. Systematic comparison\nof study quality criteria. Regul Toxicol Pharmacol. 2016;76:187 – 98. https://\ndoi.org/10.1016/j.yrtph.2015.12.017.\n81. Koch MS, DeSesso JM, Williams AL, Michalek S, Hammond B. Adaptation of\nthe ToxRTool to assess the reliability of toxicology studies conducted with\ngenetically modified crops and implications for future safety testing. Crit\nRev Food Sci Nutr. 2016;56(3):512 – 26. https://doi.org/10.1080/10408398.2\n013.788994.\n82. Segal D, Makris SL, Kraft AD, Bale AS, Fox J, Gilbert M, et al. Evaluation of the\nToxRTool's ability to rate the reliability of toxicological data for human\nhealth hazard assessments. Regul Toxicol Pharmacol. 2015;72(1):94 – 101.\nhttps://doi.org/10.1016/j.yrtph.2015.03.005.\nPublisher’sN o t e\nSpringer Nature remains neutral with regard to jurisdictional claims in\npublished maps and institutional affiliations.\nTran et al. BMC Medical Research Methodology          (2021) 21:101 Page 13 of 13",
  "topic": "Systematic review",
  "concepts": [
    {
      "name": "Systematic review",
      "score": 0.6538533568382263
    },
    {
      "name": "Medical physics",
      "score": 0.5394571423530579
    },
    {
      "name": "Protocol (science)",
      "score": 0.5321319103240967
    },
    {
      "name": "Guideline",
      "score": 0.5203618407249451
    },
    {
      "name": "Scopus",
      "score": 0.5137077569961548
    },
    {
      "name": "Quality assessment",
      "score": 0.4572780132293701
    },
    {
      "name": "Medicine",
      "score": 0.4559831917285919
    },
    {
      "name": "Computer science",
      "score": 0.44490909576416016
    },
    {
      "name": "MEDLINE",
      "score": 0.44377321004867554
    },
    {
      "name": "Pathology",
      "score": 0.17036038637161255
    },
    {
      "name": "External quality assessment",
      "score": 0.1617991328239441
    },
    {
      "name": "Alternative medicine",
      "score": 0.14899802207946777
    },
    {
      "name": "Biology",
      "score": 0.07636439800262451
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I170238339",
      "name": "Duy Tan University",
      "country": "VN"
    },
    {
      "id": "https://openalex.org/I43777268",
      "name": "Nagasaki University",
      "country": "JP"
    }
  ]
}