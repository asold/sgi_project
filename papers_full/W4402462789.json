{
    "title": "Artificial intelligence derived large language model in decision-making process in uveitis",
    "url": "https://openalex.org/W4402462789",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2007339463",
            "name": "Inès Schumacher",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5107154633",
            "name": "Virginie Manuela Marie Bühler",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2578157448",
            "name": "Damian Jaggi",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2551381938",
            "name": "Janice Roth",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4400606821",
        "https://openalex.org/W4386861318",
        "https://openalex.org/W4388791629",
        "https://openalex.org/W4387613884",
        "https://openalex.org/W4378713739",
        "https://openalex.org/W2139499737",
        "https://openalex.org/W2005165933",
        "https://openalex.org/W4386867830",
        "https://openalex.org/W4392092394",
        "https://openalex.org/W4385725044",
        "https://openalex.org/W4322622443",
        "https://openalex.org/W4390743733",
        "https://openalex.org/W4388796860"
    ],
    "abstract": "Abstract Background Uveitis is the ophthalmic subfield dealing with a broad range of intraocular inflammatory diseases. With the raising importance of LLM such as ChatGPT and their potential use in the medical field, this research explores the strengths and weaknesses of its applicability in the subfield of uveitis. Methods A series of highly clinically relevant questions were asked three consecutive times (attempts 1, 2 and 3) of the LLM regarding current uveitis cases. The answers were classified on whether they were accurate and sufficient, partially accurate and sufficient or inaccurate and insufficient. Statistical analysis included descriptive analysis, normality distribution, non-parametric test and reliability tests. References were checked for their correctness in different medical databases. Results The data showed non-normal distribution. Data between subgroups (attempts 1, 2 and 3) was comparable (Kruskal-Wallis H test, p -value = 0.7338). There was a moderate agreement between attempt 1 and attempt 2 (Cohen’s kappa, ĸ = 0.5172) as well as between attempt 2 and attempt 3 (Cohen’s kappa, ĸ = 0.4913). There was a fair agreement between attempt 1 and attempt 3 (Cohen’s kappa, ĸ = 0.3647). The average agreement was moderate (Cohen’s kappa, ĸ = 0.4577). Between the three attempts together, there was a moderate agreement (Fleiss’ kappa, ĸ = 0.4534). A total of 52 references were generated by the LLM. 22 references (42.3%) were found to be accurate and correctly cited. Another 22 references (42.3%) could not be located in any of the searched databases. The remaining 8 references (15.4%) were found to exist, but were either misinterpreted or incorrectly cited by the LLM. Conclusion Our results demonstrate the significant potential of LLMs in uveitis. However, their implementation requires rigorous training and comprehensive testing for specific medical tasks. We also found out that the references made by ChatGPT 4.o were in most cases incorrect. LLMs are likely to become invaluable tools in shaping the future of ophthalmology, enhancing clinical decision-making and patient care.",
    "full_text": null
}