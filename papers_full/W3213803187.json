{
    "title": "An improved Vision Transformer-based method for classifying surface defects in hot-rolled strip steel",
    "url": "https://openalex.org/W3213803187",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A5071804110",
            "name": "Xinglong Feng",
            "affiliations": [
                "Northeastern University"
            ]
        },
        {
            "id": "https://openalex.org/A5063319414",
            "name": "Xianwen Gao",
            "affiliations": [
                "Northeastern University"
            ]
        },
        {
            "id": "https://openalex.org/A5037665763",
            "name": "Ling Luo",
            "affiliations": [
                null
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2979325939",
        "https://openalex.org/W2425802132",
        "https://openalex.org/W2945708832",
        "https://openalex.org/W2337601638",
        "https://openalex.org/W3038274881",
        "https://openalex.org/W3153037112"
    ],
    "abstract": "Abstract A new Vision Transformer(ViT) model is proposed for the classification of surface defects in hot rolled strip, optimizing the poor learning ability of the original Vision Transformer model on smaller datasets. Firstly, each module of ViT and its characteristics are analyzed; Secondly, inspired by the deep learning model VGGNet, the multilayer fully connected layer in VGGNet is introduced into the ViT model to increase its learning capability; Finally, by performing on the X-SDD hot-rolled steel strip surface defect dataset. The effect of the improved algorithm is verified by comparison experiments on the X-SDD hot-rolled strip steel surface defect dataset. The test results show that the improved algorithm achieves better results than the original model in terms of accuracy, recall, F1 score, etc. Among them, the accuracy of the improved algorithm on the test set is 5.64% higher than ViT-Base and 2.64% higher than ViT-Huge; the accuracy is 4.68% and 1.36% higher than both of them, respectively.",
    "full_text": null
}