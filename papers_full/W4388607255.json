{
    "title": "ChatGPT: Where Is a Silver Lining? Exploring the realm of GPT and large language models",
    "url": "https://openalex.org/W4388607255",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2619855722",
            "name": "Elena Tikhonova",
            "affiliations": [
                "National Research University Higher School of Economics",
                "Peoples' Friendship University of Russia"
            ]
        },
        {
            "id": "https://openalex.org/A2762627233",
            "name": "Lilia Raitskaya",
            "affiliations": [
                "Moscow State Institute of International Relations"
            ]
        },
        {
            "id": "https://openalex.org/A2619855722",
            "name": "Elena Tikhonova",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2762627233",
            "name": "Lilia Raitskaya",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4385303098",
        "https://openalex.org/W4366783381",
        "https://openalex.org/W4385455730",
        "https://openalex.org/W4366422585",
        "https://openalex.org/W4377041488",
        "https://openalex.org/W4221015229",
        "https://openalex.org/W4322766815",
        "https://openalex.org/W4365511589",
        "https://openalex.org/W4379056517",
        "https://openalex.org/W4297832101",
        "https://openalex.org/W4366417850",
        "https://openalex.org/W4379385961",
        "https://openalex.org/W4313479734",
        "https://openalex.org/W4320495408",
        "https://openalex.org/W4323848232",
        "https://openalex.org/W4380291613",
        "https://openalex.org/W4321605350",
        "https://openalex.org/W4366834247",
        "https://openalex.org/W4317910584",
        "https://openalex.org/W4366989878",
        "https://openalex.org/W4367852612",
        "https://openalex.org/W4385633461",
        "https://openalex.org/W4317390716",
        "https://openalex.org/W4366489368",
        "https://openalex.org/W3154770621",
        "https://openalex.org/W4365484674",
        "https://openalex.org/W4318263917",
        "https://openalex.org/W4315783110",
        "https://openalex.org/W4317853296",
        "https://openalex.org/W4360989442",
        "https://openalex.org/W4313582009"
    ],
    "abstract": "Introduction: the JLE editors analyse the scope and depth of the subject area of ChatGPT and related topics based on the Scopus database. The Scopus statistics prove a skyrocketing rise in the number of publications in the field in question during 2023. The major alarming themes cover authorship and integrity related to AI-assisted writing, threats to educational practices, medicine, and malevolent uses of ChatGPT. Keywords Explained: the key terminology is defined, including generative pre-trained transformers (GPT); ChatGPT; artificial intelligence (AI); AI chatbots; natural language processing (NLP); large language models; Open AI; large language model (LLM). International Research on ChatGPT: as of September 24 2023, the Scopus database has indexed 1,935 publications, with “ChatGPT” in the title, abstract, or keywords. A skyrocketing rise in the number of research has been reported since the early days of 2023. 1,925 indexed publications out of 1,935 were published in 2023. Most of them came from the USA, India, the UK, and China. The number of documents indexed in the Scopus database as well as PubMed, arXiv and others are exponentially rising. ChatGPT in Education: the academic community has been actively discussing the challenges education will face in the era of ChatGPT in the context of the fundamental threats posed to the educational system. The latter include assessment procedures, information accuracy, and skill devaluation. As many complex technologies, generative pre-trained transformers are ambivalent in nature, providing a great potential for learning and education at large, including new approaches based on critical thinking and awareness of the pros and cons of AI. ChatGPT in Science: great prospects for text generation and improvements in language quality adjoin to dubious authorship and potentially inconsistent and erroneous parts in the AI-produced texts. Publishers and journals are working out new publishing policies, including publishing ethics towards AI-assisted or AI-improved submissions. Conclusion: JLE is planning to revise its editorial policy to address the new challenges from AI technologies. JLE editors welcome new submissions of research articles and reviews as well as special issues on ChatGPT and related themes, with potential applications of chatbots in education, innovative approaches to writing assignments, facilitating personalized learning, academic integrity issues related to AI-supported writing, etc. in focus.",
    "full_text": "JLE  |  Vol. 9  |  No. 3  |  2023\n5\nJOURNAL OF LANGUAGE & EDUCATION\n| Editorial\nChatGPT: Where Is a Silver Lining? \nExploring the realm of GPT and Large \nLanguage Models\nElena Tikhonova \n1, 2\n, Lilia Raitskaya\n 3\n1 National Research University Higher School of Economics\n2 Peoples’ Friendship University of Russia (RUDN University)\n3 Moscow State Institute of International Relations (MGIMO University)\nABSTRACT\nIntroduction: the JLE editors analyse the scope and depth of the subject area of ChatGPT and \nrelated topics based on the Scopus database. The Scopus statistics prove a skyrocketing rise \nin the number of publications in the field in question during 2023. The major alarming themes \ncover authorship and integrity related to AI-assisted writing, threats to educational practices, \nmedicine, and malevolent uses of ChatGPT.\nKeywords Explained: the key terminology is defined, including generative pre-trained \ntransformers (GPT); ChatGPT; artificial intelligence (AI); AI chatbots; natural language processing \n(NLP); large language models; Open AI; large language model (LLM).\nInternational Research on ChatGPT: as of September 24 2023, the Scopus database has \nindexed 1,935 publications, with “ChatGPT” in the title, abstract, or keywords. A skyrocketing \nrise in the number of research has been reported since the early days of 2023. 1,925 indexed \npublications out of 1,935 were published in 2023. Most of them came from the USA, India, the UK, \nand China. The number of documents indexed in the Scopus database as well as PubMed,  arXiv \nand others are exponentially rising.\nChatGPT in Education:  the academic community has been actively discussing the challenges \neducation will face in the era of ChatGPT in the context of the fundamental threats posed to \nthe educational system. The latter include assessment procedures, information accuracy, and \nskill devaluation. As many complex technologies, generative pre-trained transformers are \nambivalent in nature, providing a great potential for learning and education at large, including \nnew approaches based on critical thinking and awareness of the pros and cons of AI.\nChatGPT in Science: great prospects for text generation and improvements in language \nquality adjoin to dubious authorship and potentially inconsistent and erroneous parts in the \nAI-produced texts. Publishers and journals are working out new publishing policies, including \npublishing ethics towards AI-assisted or AI-improved submissions.\nConclusion: JLE is planning to revise its editorial policy to address the new challenges from AI \ntechnologies. JLE editors welcome new submissions of research articles and reviews as well \nas special issues on ChatGPT and related themes, with potential applications of chatbots in \neducation, innovative approaches to writing assignments, facilitating personalized learning, \nacademic integrity issues related to AI-supported writing, etc. in focus.\nKEYWORDS\ngenerative pre-trained transformers (GPT), ChatGPT, artificial intelligence (AI), AI chatbots, \nnatural language processing (NLP), large language model (LLM)\n1  Grammarly. https://www.grammarly.com\nINTRODUCTION\nThe world witnesses that AI-generat-\ned writings are spreading across vari-\nous fields. AI assistants have been used \nfor the recent years across education \nand science. The most popular and ef-\nficient AI tools encompass Grammarly 1,  \nCitation: Tikhonova E., & Raitskaya \nL. (2023). ChatGPT: Where Is a Silver \nLining? Exploring the realm of GPT \nand large language models. Journal \nof Language and Education, 9(3), 5-11.  \nhttps://doi.org/10.17323/jle.2023.18119\nCorrespondence: \nElena Tikhonova, \netihonova@hse.ru\nReceived: September 01, 2023\nAccepted: September 15, 2023\nPublished: September 30, 2023\nhttps://doi.org/10.17323/jle.2023.18119\nElena Tikhonova, Lilia Raitskaya\n6\nJLE  |  Vol. 9  |  No. 3  |  2023\n| Editorial\nJasper AI 2, JenniAI 3, Hemingway Editor 4, QdouillBot 5, and \nothers. Their use improves writing, checks for errors, cor-\nrects spelling. Some of them assist with citations (e.g. Quill -\nBot), others check for plagiarism (e.g. Grammarly). All AI \ntools of the kind do not produce text. Their usefulness is \nobvious. In November 2022, an advanced technology of \ngenerative artificial intelligence was launched by OpenAI, \nan American California-based laboratory, showing great \nperformance and spreading at lightning speed. ChatGPT \nreached one million users only within five days as compared \nwith 300 days for Facebook, 75 days for Instagram to reach \nthe same audience (Firat, 2023, p. 58).\nThe popularity of ChatGPT can be easily explained. Writing \nforms an integral and important part of education and work \nelsewhere. Educational systems of assessment are essen-\ntially based on writing. Professional requirements wide-\nly imply good-to-perfect writing skills and skills of writing \ncommunication. For instance, in the USA, 872 occupations \nrelate to writing skills (Steele, 2023). Authors, journalists, \nand researchers are frontrunners in writing. They ought to \npossess most elaborate writing skills. Not surprisingly, the \nspheres they are engaged in are likely to be influenced most \nby rapidly developing large language model (LLM) chatbots. \nThe recent ubiquity of the advanced AI technologies repli-\ncating human language patterns has led to a discussion of \ntheir pros and cons. The challenges, or rather threats and \nadvantages, are considered to have some potential impli-\ncations for education and various professional fields. The \nperceptions of the brand-new technologies range from neg-\native or even alarming to positive and enthusiastic. \nEven before the arrival of ChatGPT 4.0, its previous version \nwas successfully applied in medical education and practice. \nChatGPT is good at “interpreting clinical information” (Ho, \nKoussayer, & Sujka, 2023), giving full and correct answers \nto all questions that students of medicine may get at an ex-\namination, diagnosing complicated cases, and consulting \non treatments. In the same vein, journals on medicine and \nnursing became the frontrunners who introduced a new \nstand on ChatGPT’s participation in writing research. \nSome of medical journals stick to an editorial policy allowing \nAI-generated text incorporation but subject to a statement \nof the way ChatGPT was used. Authors are required to indi-\ncate where and how this technology was applied. The sec-\ntions of the submissions covering this information may vary, \nbut most sources single out the methods section or the ac-\nknowledgements section as the most appropriate. But all \nagree that it may be any section but for the information on \nthe authors. \n2 Jasper AI. (https://www.jasper.ai/)\n3 JenniAI. (https://jenni.ai/)\n4 Hemingway Editor. (https://hemingwayapp.com)\n5 QdouillBot. (https://quillbot.com)\nSome researchers assume that artificial intelligence chatbot \nmay pose a threat to the very pillars of education, including \nassessment of students’ educational outcomes (Rudolph et \nal., 2023), accuracy and credibility of information, skills de-\nvaluation (Steel, 2023). The technologies may bring ethical \nthreats and academic integrity concerns, wider exposure to \nmisinformation and fake news in the media (Tewari et al., \n2021). Different malevolent uses are likely to influence oth-\ner human activities (Alasadi, & Baiz, 2023; Fyfe, 2023; Firat, \n2023; Illia et al., 2023; Yeo, 2023; Lund, & Wang, 2023).\nThe JLE editors in their review aim to consider the scope of \nthe emerging field and outline some implications of the \ntechnology for scholarly publishing and education as well \nas the most essential directions of research.\nKeywords Explained\nGenerative pre-trained transformer (GPT) is a large language \nmodel serving as a framework for generative artificial intelli-\ngence. Such transformers are pre-trained on big sets of text. \nThey generate human-like texts.\nChatGPT is an AI-powered language model developed by \nOpenAI (Los Angeles, California). On November 30 2023, \nOpen AI launched ChatGPT that opened new opportunities \nfor text production. At present, ChatGPT3.5 and ChatGPT4 \n(or ChatGPT Plus) are available on the market. The former \nwas freely released as a research preview. ChatGPT4 is dis-\ntributed to paid subscribers. \nArtificial intelligence (AI) may be defined as the intelligence of \nsoftware, mainly high-profile applications such as advanced \nweb search engines, natural language understanding, gen-\nerative tools, recommendation platforms, driverless cars, \nstrategic games. AI became an academic field and discipline \nin 1956.\nAI chatbots represent a software application initially called \nchatterbots, mimicking human conversation. AI chatbots \nare based on text or voice interactions.\nNatural language processing (NLP) is a subfield of computer \nscience and linguistics. It aims to enable computers to under-\nstand and generate human languages based on natural lan-\nguage datasets in the form of corpora (both text and speech).\nOpen AI is an American artificial intelligence laborato-\nry founded in 2015. In 2020, Open AI presented GPT3, a \nlarge language model trained on big datasets. In late 2022, \nGPT3.5 chatbot was launched. In March 2023, GPT4 entered \nthe market.\nChatGPT: Where Is a Silver Lining?\nJLE  |  Vol. 9  |  No. 3  |  2023\n7\n| Editorial\nLarge language model (LLM) is a model of natural language \nprocessing that uses big data to be trained to generate hu-\nman texts. The model is based on billions of parameters that \nhelp it to mimic human languages.\nInternational Research on ChatGPT \nWe searched the Scopus database for the key word \n“ChatGPT” and found 1,935 indexed documents on Septem-\nber 24, 2023. Almost all publications (n=1,925) came out in \n2023. The prevailing publication type is the “article” (n=827). \nThere are quite many letters (n=350), editorials (n=204), and \nnotes (n=164). Conference papers account for 211 papers. \n123 reviews were published during 2023. The most prolific \nauthors include A.Kleebayoon (n=35), V.Wiwanitkit (n=29), \nand P.P.Ray (n=22). The most highly cited publication in the \narea is headlined “ChatGPT is fun, but not an author” and \nhas 233 citations as of September 24, 2023 (Thorp, 2023). \nMost publications came from the USA (n=611), India (n=192), \nthe UK (n=161), and China (n=154) (see Fig.2). Medicine \n(n=797), Computer Science (n=493), and Social Sciences \n(n=472) top the breakdown by subject area (Figure1). \nTo analyse the speed at which the field had been rising, we \ncompared the readings of the above search and the one \nmade as of April 1, 2023 (Liu et al., 2023). The latter brought \n194 papers mentioning ChatGPT on arXiv. A search on the \nkeyword “ChatGPT” identified 186 articles in the PubMed as \nof April 3, 2023, as compared with only 36 publications on \nFebruary 23 2023 (Misra & Chadwar, 2023). We expect that \nmuch more research articles and other publications will add \nto the field in the near future.\nThe most cited article in our search dwell upon the issues \nof authorship (Thorp, 2023). Other popular directions of \nresearch cover priorities related to ChatGPT for research-\ners (Stokel-Walker, 2023), challenges and implications of \nChatGPT in research (Qasem, 2023), practice and policy, \nChatGPT performance in the US medical licensing examina-\ntion and its implications for medical education, the quality \nof writing (articles, abstracts, essays, etc.) by ChatGPT, po-\ntential for education (Crompton, & Burke, 2023; Ivakhnenko, \n& Nikolskiy, 2023; Fuchs, 2023; Kikalishvili, 2023; Su, & Yang, \n2023; Rudolph, Tan, & Tan, 2023), ethical challenges for pub-\nlishing, ChatGPT and assessment in education (Rudolph, & \nTan, 2023), AI-based bot impact on libraries (Lund, & Wang, \n2023), ChatGPT in journalism, the future of education, a new \nacademic reality (Lund et al., 2023), academic integrity (Per-\nkins, 2023), science communication (Schäfer, 2023), etc.\nChatGPT in Education \nChatGPT makes educators, teachers, faculty, professors, \nand lectures revise traditional educational practices. As-\nsessment is an essential part of education at all educational \nlevels as it gives feedback and outlines the educational out-\ncomes. Traditionally, writing is a predominant way of evalu-\nation. As it takes time, it is often applied out of class (writing \nessays, reports, and other tasks). An easy access to ChatGPT \nand similar technologies may tempt students to outsource \ntheir tasks to AI tools (Steele, 2023). Two important educa-\ntional failures are likely to follow: wrong assessment and \ndevaluation of skills. \nGPT bots may lure students into accumulating the infor-\nmation they need, ignoring other more reliable sources. \nReliability can be easily sacrificed in favour of availability of \ninformation via ChatGPT. Educators will have to work out \ntasks based on critical thinking for students to evaluate any i \nnformation they get. Traditional writing forms of assess-\nment may be limited to digital-free class (Kikalishvili, 2023). \nFigure 1\nScopus-Indexed Research on ChatGPT: Breakdown by Subject Area\nNote. Source: Scopus Database as of September 15 2023.\nElena Tikhonova, Lilia Raitskaya\n8\nJLE  |  Vol. 9  |  No. 3  |  2023\n| Editorial\nAs previous threats to education (for instance, a calculator \nsome forty years ago), ChatGPT may prove boon.  A simi-\nlar paradox (Steele, 2023) will cause major revisions in the \nmeasurements of knowledge and skills. A new AI-supported \nworkplace will require employees with adequate skills. The \nlatter are to be reevaluated to meet the emerging demands. \nGiven mental awareness and critical perception of informa-\ntion, any new technologies may be adapted for educational \npurposes and turned into supporting tools. Alarming rheto-\nric of educators is largely caused by prudence and conserv-\nativeness of education as a social institution. But Covid-19 \npandemic and the related pedagogy of emergency have in-\ncreased the adaptivity of educational systems. Today, they \nare more or less prepared for the sweeping changes asso-\nciated with AI.\nJLE board members and editors are looking forward to new \nresearch submissions that will shed light on the looming \neducational landscape where AI plays on educators’ and \nstudents’ side. The research agenda covers “further explo-\nration of the ethical implications of AI for education, the \ndevelopment of strategies to manage privacy concerns, \nand the investigation of how educational institutions can \nbest prepare for the integration of AI technologies” (Firat, \n2023, p.57). The recently published literature reviews and re-\nsearch outline some potential lines of research that we also \nsee as promising and essential for the academic community \nat large. They embrace potential applications of chatbots in \neducation, including innovative methods and writing assign-\nments, shifting the focus on skills and competencies (Firat, \n2023); facilitating personalized learning and consequent-\nly academic achievements, engagement, and self-efficacy \n(Fuchs, 2023); academic integrity issues related to online ex-\naminations (Huber et al., 2023; Fyfe, 2023); ChatGPT mediat-\ning role in assessment practices (Farazouli et al., 2023), etc.\nChatGPT in Science \nThe academic community is stirred by consequences of po-\ntential uses of ChatGPT-generated content (Tang, 2023). As \nthe texts produced by AI may successfully follow language \npatterns typical of the academic writing style and mimic re-\nsearch articles, there is a growing concern that unscrupu -\nlous researchers may be tempted to generate partially or \nmore extensively texts, using ChatGPT, and deceitfully pass \noff AI-created texts as their writings. They may incorporate \nincomplete, inconsistent, or fallible pieces of the LLM-based \ntexts into their submission (Tools such as ChatCPT, 2023). \nNo doubt, the technologies are advantageous for non-na-\ntive English-speaking authors or even native speakers as \nthey may avoid weaknesses in their submissions related to \nthe language quality. But can such a text be totally attribut-\ned to the researcher? The plagiarism detecting tools can tell \nthe ChatGPT-generated texts from human writings, though \nChatGPT-produced texts are considered as original or new-\nly produced. Special tools detecting AI-generated content \nare already available with more work in progress (Misra & \nChandwar, 2023). The way AI presence is found is connected \nto regular patterns and algorithms any AI-generated text is \nbased on. Researchers may select to play around with the \nChatGPT’s help throughout the writing, or only in some \nchunks of the article.\nAuthorship of such texts as submissions is raising doubts \n(Hufton, 2023). Academics and researchers express worries \nas AI does not bear any responsibility for the produced in-\nformation (Tang, 2023). In late 2022 and early 2023,  several \npreprints and publications were released, with ChatGPT in-\ndicated as a co-author. It led to a heated discussion of AI’s \nauthorship. In the wake of ChatGPT launch, Springer Nature \nwas nearly the first to develop new technologies spotting \nLLM-generated output. The publishers also supported those \nresearchers who disapprove of “citing the bot as an author” \nFigure 2\nScopus-Indexed Research on ChatGPT:  Breakdown by Country or Territory\nNote. Source: Scopus Database as of September 24 2023.\nChatGPT: Where Is a Silver Lining?\nJLE  |  Vol. 9  |  No. 3  |  2023\n9\n| Editorial\n(Tollefson, 2023). The debate is still on the rise on the role \nof the AI tools in producing scientific literature. LLM tools \ncannot be accepted as a credited author as “any attribution \nof authorship is connected to responsibility” (Tools such as \nChatCPT, 2023) that sounds senseless if applied to AI.\nMany journals are revising their editorial policy regarding \ntheir authors’ use of AI in their submissions. They tend to \ndisallow crediting ChatGPT or other artificial intelligence \nlanguage models as a co-author. In early 2023, a few pre-\nprints and submissions, mainly in medicine, turned out to \ncontain information on AI authorship 6. It launched a dis-\ncussion on the possibility of AI authorship.  Consequently, \nmedical journals pioneered the revision of roles of authors \nand contributors, specifying the disclosure procedure of ar-\ntificial intelligence-assisted technology in the production of \nany submission.7 Elsevier was among those publishers who \npioneered new policies related to AI-assisted tools. Elsevier \nin their journals expects their authors to make a statement \non the use of AI-assisted tools. In other publishing houses \nor journals, researchers should seek permission from their \npublisher or editor in case they use AI in any part of their \nsubmission (but for the information on the authors that \nis generally prohibited) or specify the sections where they \nused AI. \nElsevier’s Practices\nIn February 2023, updates on the use of artificial intelligence \ntools in the submissions were introduced into Elsevier’s au-\nthorship policy (Hufton, 2023). According to Elsevier policies \nand guidelines, authors, editors, and reviewers are to follow \nPublishing Ethics where the use of generative AI and AI-as-\nsisted technologies (ChatGPT, NovelAI, Jasper AI, Rytr AI, \nDALL-E, etc.) in scientific writing, in the journal peer-review \nand editorial process is described8. \nFor Elsevier authors: The policy regarding AI-based tech-\nnologies exclusively refers to the writing process barring \nthe research process. Authors may improve readability and \nlanguage of their submission without reservations. Gener-\nal oversight and editing are the author’s responsibility. If \nAI is applied, the author is to make a statement. “Authors \nshould not list AI and AI-assisted technologies as an author \nor co-author, nor cite AI as an author.” 9\nFor Elsevier editors and reviewers: As any submitted man-\nuscript is confidential, no part of it may be uploaded into \na generative AI tool. The latter may infringe the author’s \n6 King, M.R., & ChatGPT. (2023). A conversation on artificial intelligence, Chatbots, and plagiarism in higher education. Cellular and Mo-\nlecular Bioengineering, 16, 1–2. https://doi.org/10.1007/s12195-022-00754-8\n7 International Committee of Medical Journal Editors. Defining the Role of Authors and Contributors. Artificial Intelligence-Assisted Tech-\nnology. https://www.icmje.org/recommendations/browse/roles-and-responsibilities/defining-the-role-of-authors-and-contributors.\nhtml (accessed September 19, 2023).\n8 Elsevier. Publishing Ethics. https://beta.elsevier.com/about/policies-and-standards/publishing-ethics?trial=true\n9 Ibid., The use of generative AI and AI-assisted technologies in scientific writing.\nconfidentiality and data privacy rights. As correspondence \nwith authors contains personal data, editors cannot upload \nit into a generative AI tool either. Reviewers should not use \nAI-assisted tools in the scientific review as peer review is \nbased on critical thinking that is missing from such tools. \nMoreover, generative AI technologies may produce incor-\nrect or biased conclusions. \nThe academic community is unanimous that any content \nproduced by AI tools should be “screened and edited for ac-\ncuracy and appropriateness before dissemination” (Misra & \nChadwar, 2023). JLE editors cannot but share the stance of \nElsevier and other publishers on the AI-related publishing \nethics.\nCONCLUSION\nChatGPT has been changing the realities in education, aca-\ndemia, media, and communication. At present, it is impos-\nsible to foresee the speed, depth, and scope of transforma -\ntions. New and unexpected implications of ChatGPT may \narise soon. It is high time for journals to revise their notions \nrelated to authorship, integrity, and use of AI at large in re-\nsearch and scholarly writing. Following this editorial, JLE is \nplanning to include a provision regulating AI-supported and \nAI-generated writing in the JLE guidelines for authors and \nreviewers. \nAs this new emerging field of study is rising fast, JLE editors \nwelcome any initiatives on special issues, new submissions \nof research articles and reviews on ChatGPT and associated \nthemes. \nAUTHORS CONTRIBUTIONS\nElena Tikhonova: Conceptualization, Data curation, Formal \nanalysis, Investigation, Methodology, Resources,  Software,  \nValidation, Visualization, Writing – original draft, Writing – \nreview & editing, other contribution.\nLilia Raitskaya: Conceptualization, Data curation, Formal \nanalysis, Investigation, Methodology, Resources, Software,  \nValidation, Visualization, Writing – original draft, Writing – \nreview & editing, other contribution.\nElena Tikhonova, Lilia Raitskaya\n10\nJLE  |  Vol. 9  |  No. 3  |  2023\n| Editorial\nREFERENCES\nAlasadi, E.A., & Baiz, C.R. (2023). Generative AI in education and research: Opportunities, concerns, and solutions. Journal of \nChemical Education, 100(8), 2965-2971. https://doi.org/10.1021/acs.jchemed.3c00323\nCrompton, H., Burke, D. (2023). Artificial intelligence in higher education: the state of the field. International Journal of Educa-\ntional Technology in Higher Education, 20(1), 22. https://doi.org/10.1186/s41239-023-00392-8\nFarazouli, A., Cerratto-Pargman, T., Bolander-Laksov, K., & McGrath, C. (2023): Hello GPT! Goodbye home examination? An \nexploratory study of AIchatbots impact on university teachers’ assessment practices. Assessment & Evaluation in Higher \nEducation. https://doi.org/10.1080/02602938.2023.2241676\nFirat, M. (2023). What ChatGPT means for universities: Perceptions of scholars and students. Journal of Applied Learning and \nTeaching, 6(1), 57-63. https://doi.org/10.37074/jalt.2023.6.1.22\nFuchs, K. (2023). Exploring the opportunities and challenges of NLP models in higher education: is ChatGPT a blessing or a \ncurse? Frontiers in Education, 8, 1166682. https://doi.org/10.3389/feduc.2023.1166682\nFyfe, P. (2023). How to cheat on your final paper: Assigning AI for student writing. AI and Society, 38(4), 1395-1405. https://doi.\norg/10.1007/s00146-022-01397-z\nHuber, E., Harris, L., Wright, S., White, A., Raduescu, C., Zeivots, S., Cram, A. & Brodzeli, A. (2023). Towards a framework for de-\nsigning and evaluating online assessments in business education. Assessment & Evaluation in Higher Education. https://doi.\norg/10.1080/02602938.2023.2183487\nHufton, A.L. (2023). No artificial intelligence authors, for now. Patterns, 4,  14, 2023. https://doi.org/10.1016/j.patter.2023.100731 \nHo, W.L.J., Koussayer, B. & Sujka, J. (2023). ChatGPT: Friend or foe in medical writing? An example of how ChatGPT can be  \nutilized in writing case reports. Surgery in Practice and Science, 14, 100185. https://doi.org/10.1016/j.sipas.2023.100185\nIllia, L., Colleoni, E., & Zyglidopoulos, S. (2023). Ethical implications of text generation in the age of artificial intelligence.  \nBusiness Ethics, Environment and Responsibility, 32(1), 201-210. https://doi.org/10.1111/beer.12479\nIvakhnenko, E. N., Nikolskiy, V. S. (2023). ChatGPT in higher education and science: A threat or a valuable resource? Vysshee \nobrazovanie v Rossii = Higher Education in Russia, 32(4), 9-22. https://doi.org/10.31992/0869-3617-2023-32-4-9-22 \nKikalishvili, S. (2023). Unlocking the potential of GPT-3 in education: Opportunities, limitations, and recommendations for ef-\nfective integration. Interactive Learning Environments. https://doi.org/10.1080/10494820.2023.2220401\nKing, M. R., & ChatGPT. (2023). A conversation on artificial intelligence, chatbots, and plagiarism in higher education. Cellular \nand Molecular Bioengineering, 16, 1–2. https://doi.org/10.1007/s12195-022-00754-8\nLund, B.D., & Wang, T. (2023). Chatting about ChatGPT: How may AI and GPT impact academia and libraries? Library Hi Tech \nNews, 40(3), 26-29. https://doi.org/10.1108/LHTN-01-2023-0009\nLund, B.D., Wang, T., Mannuru, N.R., Nie, B., Shimray, S., & Wang, Z. (2023). ChatGPT and a new academic reality: Artificial \nIntelligence-written research papers and the ethics of the large language models in scholarly publishing. Journal of the \nAssociation for Information Science and Technology, 74(5), 570-581. https://doi.org/10.1002/asi.24750\nMisra, D.P., & Chandwar, K. (2023). ChatGPT, artificial intelligence and scientific writing: What authors, peer reviewers and \neditors should know? Journal of the Royal College of Physicians of Edinburgh, 1-4. http://doi.org/10.1177/14782715231181023\nPerkins, M. (2023). Academic Integrity considerations of AI Large Language Models in the post-pandemic era: ChatGPT and \nbeyond. Journal of University Teaching and Learning Practice, 20(2), 7. https://doi.org/10.53761/1.20.02.07\nQasem, F. (2023). ChatGPT in scientific and academic research: Future fears and reassurances. Library Hi Tech News, 40(3), 30-\n32. https://doi.org/10.1108/LHTN-03-2023-0043\nRudolph, J., Tan, S., & Tan, S. (2023). ChatGPT: Bullshit spewer or the end of traditional assessments in higher education? Jour-\nnal of Applied Learning and Teaching, 6(1), 342-363. https://doi.org/10.37074/jalt.2023.6.1.9\nRudolph, J., Tan, S., & Tan, S. (2023). War of the chatbots: Bard, Bing Chat, ChatGPT, Ernie and beyond. The new AI gold \nrush and its impact on higher education. Journal of Applied Learning and Teaching, 6(1), 364-389. https://doi.org/10.37074/\njalt.2023.6.1.23\nSchäfer, M.S. (2023). The Notorious GPT: Science communication in the age of artificial intelligence. Journal of Science Commu-\nnication, 22(2), Y02. https://doi.org/10.22323/2.22020402\nSteele, J.L. (2023). To GPT or not GPT? Empowering our students to learn with AI. Computers and Education: Artificial Intelligence, \n5, 100160. https://doi.org/10.1016/j.caeai.2023.100160\nStokel-Walker, C. (2023). ChatGPT listed as author on research papers: Many scientists disapprove. Nature, 613 (7945), 620-621. \nhttps://doi.org/10.1038/d41586-023-00107-z\nChatGPT: Where Is a Silver Lining?\nJLE  |  Vol. 9  |  No. 3  |  2023\n11\n| Editorial\nSu, J., & Yang, W. (2023). Unlocking the power of ChatGPT: A framework for applying generative AI in education. ECNU Review \nof Education, 6(3), 355-366. https://doi.org/10.1177/20965311231168423\nTewari, S., Zabounidis, R., Kothari, A., Bailey, R., & Alm, C.O. (2021). Perceptions of human and machine-generated articles.  \nDigital Threats: Research and Practice, 2(2), 12. https://doi.org/10.1145/3428158 \nTang, G. (2023). Academic journals cannot simply require authors to declare that they used ChatGPT. Irish Journal of Medical \nScience (1971 -). https://doi.org/10.1007/s11845-023-03374-x\nThorp, H.H. (2023). ChatGPT is fun, but not an author. Science, 379(6630), 313. http://doi.org/10.1126/science.adg7879\nTollefson, J. (2023). The plan to “Trump-proof” US science against meddling. Nature, 613(7945), 621-622. http://10.1038/d41586-\n022-03307-1\nTools such as ChatGPT threaten transparent science; here are our ground rules for their use. (2023). Nature, 613(7945), 612. \nhttps://doi.org/10.1038/d41586-023-00191\nYeo, M.A. (2023). Academic integrity in the age of Artificial Intelligence (AI) authoring apps. TESOL Journal, 14(3), e716.  \nhttps://doi.org/10.1002/tesj.716"
}