{
  "title": "Personalized Transformer for Explainable Recommendation",
  "url": "https://openalex.org/W3175536494",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2098784551",
      "name": "Lei Li",
      "affiliations": [
        "Hong Kong Baptist University"
      ]
    },
    {
      "id": "https://openalex.org/A2112127489",
      "name": "Yongfeng Zhang",
      "affiliations": [
        "Rutgers, The State University of New Jersey"
      ]
    },
    {
      "id": "https://openalex.org/A1971984624",
      "name": "Li Chen",
      "affiliations": [
        "Hong Kong Baptist University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W4237284205",
    "https://openalex.org/W3035523484",
    "https://openalex.org/W3094497946",
    "https://openalex.org/W3022328511",
    "https://openalex.org/W1994389483",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3101366597",
    "https://openalex.org/W3099726771",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W1815076433",
    "https://openalex.org/W2964961855",
    "https://openalex.org/W3110460992",
    "https://openalex.org/W3102172133",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2740167620",
    "https://openalex.org/W2997892440",
    "https://openalex.org/W2593222764",
    "https://openalex.org/W2157331557",
    "https://openalex.org/W3033351949",
    "https://openalex.org/W3024683329",
    "https://openalex.org/W3172887316",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W3154587251",
    "https://openalex.org/W4205334834",
    "https://openalex.org/W2971196067",
    "https://openalex.org/W3034328025",
    "https://openalex.org/W2801992635",
    "https://openalex.org/W3080122044",
    "https://openalex.org/W2152184085",
    "https://openalex.org/W1994616650",
    "https://openalex.org/W2739992143",
    "https://openalex.org/W3093531652",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3093532296",
    "https://openalex.org/W2100171245",
    "https://openalex.org/W2971274815",
    "https://openalex.org/W2898076813",
    "https://openalex.org/W2904002921",
    "https://openalex.org/W3121002673",
    "https://openalex.org/W2963045354",
    "https://openalex.org/W2137245235",
    "https://openalex.org/W2945260553",
    "https://openalex.org/W2967299966"
  ],
  "abstract": "Lei Li, Yongfeng Zhang, Li Chen. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021.",
  "full_text": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natural Language Processing, pages 4947‚Äì4957\nAugust 1‚Äì6, 2021. ¬©2021 Association for Computational Linguistics\n4947\nPersonalized Transformer for Explainable Recommendation\nLei Li1 Yongfeng Zhang2 Li Chen1\n1Hong Kong Baptist University, Hong Kong, China\n2Rutgers University, New Brunswick, USA\n1{csleili,lichen}@comp.hkbu.edu.hk\n2yongfeng.zhang@rutgers.edu\nAbstract\nPersonalization of natural language generation\nplays a vital role in a large spectrum of tasks,\nsuch as explainable recommendation, review\nsummarization and dialog systems. In these\ntasks, user and item IDs are important identi-\nÔ¨Åers for personalization. Transformer, which\nis demonstrated with strong language model-\ning capability, however, is not personalized\nand fails to make use of the user and item\nIDs since the ID tokens are not even in the\nsame semantic space as the words. To address\nthis problem, we present a PErsonalized Trans-\nformer for Explainable Recommendation (PE-\nTER1), on which we design a simple and ef-\nfective learning objective that utilizes the IDs\nto predict the words in the target explanation,\nso as to endow the IDs with linguistic mean-\nings and to achieve personalized Transformer.\nBesides generating explanations, PETER can\nalso make recommendations, which makes it a\nuniÔ¨Åed model for the whole recommendation-\nexplanation pipeline. Extensive experiments\nshow that our small unpretrained model outper-\nforms Ô¨Åne-tuned BERT on the generation task,\nin terms of both effectiveness and efÔ¨Åciency,\nwhich highlights the importance and the nice\nutility of our design.\n1 Introduction\nRecent years have witnessed the successful appli-\ncation of natural language generation. Many of the\napplications in fact require certain degree of per-\nsonalization, such as explainable recommendation\n(Zhang et al., 2014; Li et al., 2020c; Zhang and\nChen, 2020), review generation (Dong et al., 2017),\nreview summarization (Li et al., 2019), and conver-\nsational systems (Zhang et al., 2018; Chen et al.,\n2020). In these tasks, user and item IDs that distin-\nguish one user/item from the others are crucial to\n1https://github.com/lileipisces/PETER\npersonalization. For example, in recommender sys-\ntems, different users may care about different item\nfeatures (e.g., style vs. quality), and different items\nmay have different characteristics (e.g.,fashionable\nvs. comfortable). The goal of explainable recom-\nmendation (Zhang and Chen, 2020) is to provide an\nexplanation to a user for a recommended item, so\nas to justify how the recommendation might match\nhis/her interests. That is, given a pair of user ID and\nitem ID, the system needs to generate an explana-\ntion, such as ‚Äúthe style of the jacket is fashionable‚Äù\n(see the last column of Table 4 for more examples).\nTransformer (Vaswani et al., 2017), whose\nstrong language modeling ability has been demon-\nstrated on a variety of tasks (Radford et al., 2018;\nDevlin et al., 2019; Brown et al., 2020), however, is\nrelatively under-explored for personalized natural\nlanguage generation. Since IDs and words are in\nvery different semantic spaces, it would be prob-\nlematic to directly put them together for attention\nlearning, because by doing so, the IDs are treated\nas words, but the IDs appear far less frequently\nthan the words. For example, a paragraph of re-\nview (and thus hundreds of words) on e-commerce\nplatform only corresponds to a single pair of user\nID and item ID. As such, the IDs may be regarded\nas out-of-vocabulary tokens, to which the model\nis insensitive. As shown in Fig. 1(a), when gener-\nating an explanation for a user-item pair, standard\nTransformer relies heavily on the special <bos>\ntoken instead of the user or the item. This would\nresult in identical explanations over different user-\nitem pairs (see USR score in Table 2), deviating\nfrom our personalization goal.\nTo address this problem, we bridge IDs and\nwords by designing an elegant task called context\nprediction, which maps IDs onto words to be gen-\nerated by the explanation task. This in some way\nresembles one‚Äôs drafting-polishing process, where\nby predicting some words the context prediction\n4948\n[User]\n[Item]\n<bos>\nthe\nhotel\nis\nlocated\nin\nthe\nheart\nof\nthe\ncity\nand\nthe\ncity\ncentre\nis\nSource\n[User]\n[Item]\nthe\nhotel\nis\nlocated\nin\nthe\nheart\nof\nthe\ncity\nand\nthe\ncity\ncentre\nis\n<eos>\nTarget\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n(a) Standard Transformer model, where the user and the\nitem have no contribution to each generation step.\n[User]\n[Item]\n<bos>\nthe\npool\narea\nis\nnice\nand\nthe\ngym\nis\nvery\nwell\nequipped\nSource\n[Rating]\n[Context]\nthe\npool\narea\nis\nnice\nand\nthe\ngym\nis\nvery\nwell\nequipped\n<eos>\nTarget\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n(b) Our PETER model, where the user and item IDs play\nsigniÔ¨Åcant roles in the generation steps.\nFigure 1: Attention visualization of two models when generating an explanation for the same user-item pair (see\nthe Ô¨Årst two columns). They are both from the last attention layer, so the target sequences are offset by one position\nfor better illustration. The larger the attention weights, the lighter the cells.\ntask does the job of drafting. Then, the explana-\ntion generation task polishes these words so as to\nform a readable sentence. Meanwhile, we demon-\nstrate that conducting recommendation task on the\nsame model is also feasible, so we name it PETER,\nwhich stands for PErsonalized Transformer for Ex-\nplainable Recommendation. As we can see in Fig.\n1(b), when PETER generates an explanation for the\nsame user-item pair, it can utilize the information\nof both the user and the item, which illustrates the\neffectiveness of our context prediction task.\nIn addition, PETER is Ô¨Çexible to incorporate\nitem features that can help to guide its generation.\nThis can be very useful when, for instance, a user\nproactively asks the system to explain certain fea-\nture(s) of a recommendation (Li et al., 2020c), e.g.,\nprice. Then, we would expect the model to gen-\nerate a targeted explanation, such as ‚Äúgreat jacket,\nespecially for the price ‚Äù. PETER is a small un-\npretrained Transformer with only 2 layers, yet it\noutperforms a Ô¨Åne-tuned BERT (Ni et al., 2019)\non most metrics by a large margin, and takes less\ntime to train, as shown in our experiments. This\nmanifests the superiority of our model.\nIn summary, our key contributions are:\n‚Ä¢We propose PETER that makes recommenda-\ntion and generates explanation simultaneously\nbased on user and item IDs for explainable rec-\nommendation. To the best of our knowledge,\nwe are the Ô¨Årst to enable Transformer with\npersonalized natural language generation.\n‚Ä¢We evaluate the generated explanations on\nnot only text quality metrics (such as BLEU\nand ROUGE), but also metrics that particu-\nlarly focus on explainability from the angle\nof item features. Extensive experiments show\nthat our model can outperform state-of-the-art\nbaselines on large datasets.\n‚Ä¢Our solution sheds light on a broader scope\nof Ô¨Åelds that also need personalization (e.g.,\npersonalized conversational systems). In ad-\ndition, it points out a way for Transformer to\ndeal with heterogeneous inputs, e.g., text and\nimages in multimodal artiÔ¨Åcial intelligence.\n2 Related Work\nExplainable recommendation (Zhang et al.,\n2014; Zhang and Chen, 2020) has been studied\nfrom two major perspectives: human-computer\ninteraction and machine learning. The former\n(Gedikli et al., 2014; Chen and Wang, 2017; Chen\net al., 2019b) investigates how people perceive dif-\nferent styles of explanations, while the latter pro-\nvides explanations by designing new explainable\nrecommendation algorithms, to which our work is\nmore related. There exist various types of explana-\ntion styles, such as pre-deÔ¨Åned templates (Zhang\net al., 2014; Li et al., 2020a), ranked sentences\n(Chen et al., 2019d; Li et al., 2021), image visu-\nalizations (Chen et al., 2019c), knowledge graph\npaths (Ai et al., 2018; Xian et al., 2019; Fu et al.,\n2020; Xian et al., 2020), reasoning rules (Shi et al.,\n4949\n2020; Chen et al., 2021; Zhu et al., 2021), etc.,\namong which, recently, generated natural language\nexplanations (Ni et al., 2019; Li et al., 2020c) have\nreceived much attention, mainly owing to the ad-\nvancement of natural language generation technol-\nogy and the availability of textual data on recom-\nmendation platforms such as e-commerce. How-\never, previous works mostly rely on recurrent neu-\nral networks (RNN), e.g., LSTM (Hochreiter and\nSchmidhuber, 1997) and GRU (Cho et al., 2014),\nleaving the potentially more effective Transformer\nunder-explored, which motivates this work.\nTransformer (Vaswani et al., 2017) was Ô¨Årst\nbrought to machine translation with the architec-\nture of encoder-decoder. Later works (Liu et al.,\n2018; Devlin et al., 2019) show that it remains\neffective, even when the encoder or the decoder\nis removed, reducing nearly half of the parame-\nters. Under the paradigm of pre-training plus Ô¨Åne-\ntuning, Transformer‚Äôs effectiveness has been con-\nÔ¨Årmed on a wide range of tasks, including both nat-\nural language understanding and generation (Rad-\nford et al., 2018; Devlin et al., 2019; Dong et al.,\n2019). Particularly, it is able to perform novel tasks,\ne.g., arithmetic, after scaling up both the model\nand the training data (Radford et al., 2019; Brown\net al., 2020). However, it may not be friendly to re-\nsearchers who do not possess large amounts of com-\nputing resources. Instead, our work explores small\nunpretrained models, as they are computationally\ncheaper and more Ô¨Çexible when being adapted to\nnew applications, e.g., personalized generation.\nPersonalized generation usually involves the\nIDs of users and items. Previous approaches typi-\ncally adopt multi-layer perceptron (MLP) to encode\nthe IDs into a context vector, from which RNN\ncan decode a word sequence. This strategy can be\nfound in many applications, such as review gener-\nation (Dong et al., 2017), tip generation (Li et al.,\n2017) and explanation generation (Li et al., 2020c).\nHowever, it does not Ô¨Åt Transformer that relies en-\ntirely on self-attention. Probably because a proper\nsolution to deal with heterogeneous inputs (i.e., IDs\nand words) is yet to be found, previous works with\nTransformer for personalized generation replace\nIDs with text segments, such as persona attributes\n(Zheng et al., 2020), movie titles (Zhou et al., 2020)\nand item features (Ni et al., 2019), which are in the\nsame semantic space as the word sequence to be\ngenerated. In comparison, our solution is to design\nan effective task that can give the IDs linguistic\nTransformer with ùêøLayers\nTransformer with ùêøLayers\nLinear Layer\n∆∏ùëüùë¢,ùëñ ∆∏ùëí1 ∆∏ùëí2 < ‡∑ûùëíùëúùë†>\nùë¢ ùëñ <ùëèùëúùë†> ∆∏ùëí2∆∏ùëí1ùëì2ùëì1\nùê¨ùêø,1 ùê¨ùêø,2 ùê¨ùêø,5 ùê¨ùêø,6 ùê¨ùêø,7ùê¨ùêø,3 ùê¨ùêø,4\nUser Item\nFeatures (opt.) Explanation\nRating\nPrediction\nContext Prediction\nExplanation Generation\nMLP\n«Åùëí1«Åùëí2 < ‡∑¶ùëíùëúùë†>\nFigure 2: Our proposed model PETER that contains\nthree tasks. The input features are optional.\nmeanings, thus connecting IDs with words.\n3 Problem Formulation\nThe goal of our explanation task is to generate a\nnatural language sentence ÀÜEu,i for a pair of user\nuand item ito justify why iis recommended to\nu. Meanwhile, our model PETER can also make\nrecommendations by estimating a rating ÀÜru,i that\npredicts u‚Äôs preference towards i. At the testing\nstage, only user uand item iare used as inputs for\nproducing both explanation and recommendation.\nWhen item features Fu,i are available, our model\nis Ô¨Çexible to incorporate them by simply concate-\nnating them at the beginning of the explanation. In\nthis case, the features are also needed in the testing\nstage. In the following, we will discuss both cases.\n4 Methodology\nIn this section, we present the details of our model\nPETER. First, we show how to encode different\ntypes of tokens in a sequence. Then, we brieÔ¨Çy\nreview Transformer and introduce our revised at-\ntention masking matrix. At last, we formulate the\nthree tasks, i.e., explanation generation, context pre-\ndiction and recommendation, and integrate them\ninto a multi-task learning framework.\n4.1 Input Representation\nWe Ô¨Årst introduce our way to encode heterogeneous\ninputs into vector representations. As shown in Fig.\n2, the input to our model is a sequence, consisting\n4950\nSource\nTarget\nùë¢ ùëñ ùëì1 ùëì2 <ùëèùëúùë†> ∆∏ùëí1 ∆∏ùëí2\nùë¢\nùëñ\n<ùëèùëúùë†>\n∆∏ùëí1\n∆∏ùëí2\nAllow to attend Prevent from attending\nùëì1\nùëì2\nFigure 3: The attention masking used in our model that\nwe call PETER masking. The orange box highlights its\ndifference from the Left-to-Right masking.\nof user ID u, item ID i, features Fu,i, and expla-\nnation Eu,i. The user and the item serve for the\npurpose of personalization, i.e., aiming to make\nthe generated explanation reÔ¨Çect both the user‚Äôs\ninterests and the item‚Äôs attributes. The features can\nguide the model to talk about certain topics. For in-\nstance, a conversational recommender system may\nexplain a recommendation‚Äôs specialty to the user\nwith the goal of knowing more about his/her pref-\nerence (Chen et al., 2020). Since the features are\nnot always available, in our experiments we test\nboth cases (with and without them). When they are\navailable, the input sequence can be represented as\nS = [ u,i,f 1,¬∑¬∑¬∑ ,f|Fu,i|,e1,¬∑¬∑¬∑ ,e|Eu,i|], where\nf1,¬∑¬∑¬∑ ,f|Fu,i|are the features and e1,¬∑¬∑¬∑ ,e|Eu,i|\nare the explanation‚Äôs word sequence.|Fu,i|denotes\nthe number of features and |Eu,i|is the number of\nwords in the explanation.\nClearly there are three types of tokens in the\nsequence S, i.e., users, items, and words (includ-\ning features), for which we prepare three sets of\nrandomly initialized token embeddings U, I and\nV respectively, besides the positional embeddings\nP that encode the position of each token in the\nsequence. Notice that, we do not add users and\nitems to the vocabulary V, given that it costs more\ntime to predict a word out of the huge amount of\nIDs (for example, millions of users and items in\ne-commerce). After performing embedding look-\nup, we can obtain the sequence‚Äôs token represen-\ntation [u,i,f1,¬∑¬∑¬∑ ,f|Fu,i|,e1,¬∑¬∑¬∑ ,e|Eu,i|] and its\npositional representation [p1,¬∑¬∑¬∑ ,p|S|], where |S|\nis the length of the sequence. The input repre-\nsentation of the sequence is the addition of the\ncorresponding token representation and positional\nrepresentation, denoted as S0 = [s0,1,¬∑¬∑¬∑ ,s0,|S|].\n4.2 Transformer and Attention Masking\nTo enable the three tasks, we show how to modify\nthe attention masking mechanism in Transformer\n(Vaswani et al., 2017). Transformer consists ofL\nidentical layers, each of which is composed of two\nsub-layers: multi-head self-attention and position-\nwise feed-forward network. The l-th layer encodes\nthe previous layer‚Äôs output Sl‚àí1 into Sl, where\nl ‚àà[1,L]. In the multi-head self-attention sub-\nlayer, the computation of each attention head is\nalso identical, and among the H heads of the l-th\nlayer, the h-th head Al,h is computed as follows:\nAl,h = softmax(\nQl,hK‚ä§\nl,h‚àö\nd\n+ M)Vl,h\nQl,h = Sl‚àí1WQ\nl,h,Kl,h = Sl‚àí1WK\nl,h,\nVl,h = Sl‚àí1WV\nl,h\nM =\n{\n0, Allow to attend\n‚àí‚àû, Prevent from attending\n(1)\nwhere Sl‚àí1 ‚ààR|S|√ód is the (l‚àí1)-th layer‚Äôs out-\nput, WQ\nl,h,WK\nl,h,WV\nl,h ‚ààRd√ód\nH are projection ma-\ntrices, ddenotes the dimension of embeddings, and\nM ‚ààR|S|√ó|S|is the attention masking matrix.\nEach element in M controls whether a token in\nthe sequence can attend to another. For example,\nin the unidirectional left-to-right language model\n(Radford et al., 2018), the lower triangular part of\nM is set to 0 and the remaining part ‚àí‚àû, so as to\nallow each token to attend to past tokens (includ-\ning itself), but prevent it from attending to future\ntokens. We call it Left-to-Right Masking. As our\nmodel is not limited to the left-to-right explanation\ngeneration task, we modify the masking mecha-\nnism to accommodate the other two tasks (i.e., con-\ntext prediction and recommendation). As shown in\nFig. 3, the Ô¨Årst two tokens uand iin the sequence\ncan attend to each other, because both context pre-\ndiction and recommendation tasks need them. To\necho our model, we name it PETER Masking.\n4.3 Explanation and Recommendation\nIn the following, we perform the three tasks, af-\nter obtaining the sequence‚Äôs Ô¨Ånal representation\nSL = [ sL,1,¬∑¬∑¬∑ ,sL,|S|] from Transformer. The\nkey challenge lies in the personalization of expla-\nnation generation task, for which we design the\ncontext prediction task. For both tasks, we apply a\nlinear layer to the Ô¨Ånal representation of each token\nto map it into a |V|-sized vector. As an example,\n4951\nafter passing through this layer, sL,t becomes ct:\nct = softmax(WvsL,t + bv) (2)\nwhere Wv ‚ààR|V|√ód and bv ‚ààR|V|are weight pa-\nrameters. The vector ct represents the probability\ndistribution over the vocabulary V, from which a\nword ewith probability ce\nt can be sampled.\nExplanation Generation: We adopt the Neg-\native Log-Likelihood (NLL) as the explanation\ntask‚Äôs loss function, and compute the mean of user-\nitem pairs in the training set:\nLe = 1\n|T|\n‚àë\n(u,i)‚ààT\n1\n|Eu,i|\n|Eu,i|‚àë\nt=1\n‚àílog cet\n2+|Fu,i|+t\n(3)\nwhere T denotes the training set. The probability\ncet\nt is offset by 2 + |Fu,i|positions because the\nexplanation is placed at the end of the sequence,\nand |Fu,i|= 0 when the features are unavailable.\nAt the testing stage, along with u, i, and Fu,i (if\navailable), we feed the model a special begin-of-\nsequence token <bos>. From its resulting proba-\nbility distribution c<bos>, the model can predict a\nword. For simplicity, among the many decoding\nmethods, we opt for greedy decoding that samples\nthe word with the largest probability. Then we can\nconcatenate this predicted word at the end of the\nsequence to form a new input sequence for gener-\nating another word. We do this repeatedly until the\nmodel produces a special end-of-sequence token\n<eos>, or the generated explanation ÀÜEu,i reaches\na pre-deÔ¨Åned length.\nContext Prediction: As discussed earlier, when\nthere is only one task of explanation generation,\nTransformer fails to make use of user ID and item\nID, resulting in identical sentences. To address this\nissue, we design this task to map the IDs onto the\nwords in the explanation, so as to build a connec-\ntion between them. Since the Ô¨Årst two positions (u\nand i) of the sequence are allowed to attend to each\nother, both of their Ô¨Ånal representations absorb the\ninformation of the user and the item. Thus, we\ncan use either of them to perform this task. Here,\nwe use the 2nd one for better illustration in Fig. 2.\nAgain, we adopt NLL as the loss function:\nLc = 1\n|T|\n‚àë\n(u,i)‚ààT\n1\n|Eu,i|\n|Eu,i|‚àë\nt=1\n‚àílog cet\n2 (4)\nwhere the difference from Eq. (3) is that all pre-\ndicted words are from the 2nd position, which is\nwhy they are not sequentially ordered (see Fig. 2).\nRating Prediction: Recommendation can be\nseen as a prediction problem (Chen et al., 2021)\nwhere the goal is to predict a score ÀÜru,i based on\nthe IDs of user u and item i. As both u and i\nin the sequence can attend to each other, their Ô¨Å-\nnal representations capture the interaction between\nthem. Next, we map the 1st representationsL,1 into\na scalar (because the 2nd one is used for context\nprediction). To this end, we employ multi-layer per-\nceptron (MLP) with one hidden layer as follows:\nÀÜru,i = wrœÉ(WrsL,1 + br) + br (5)\nwhere Wr ‚ààRd√ód, br ‚ààRd, wr ‚ààR1√ód and\nbr ‚ààR are weight parameters, and œÉ(¬∑) is the sig-\nmoid function. Therefore, it can be seen that it is\nfeasible to do both recommendation and explana-\ntion on Transformer. As recommendation is not the\nkey focus of this paper, we leave its improvement\nin the future work. For this task, we use Mean\nSquare Error (MSE) as the loss function:\nLr = 1\n|T|\n‚àë\n(u,i)‚ààT\n(ru,i ‚àíÀÜru,i)2 (6)\nwhere ru,i is the ground-truth rating.\nMulti-task Learning: At last, we integrate the\nthree tasks into a multi-task learning framework\nwhose objective function is deÔ¨Åned as:\nJ= min\nŒò\n(ŒªeLe + ŒªcLc + ŒªrLr) (7)\nwhere Œò denotes all the trainable parameters in\nthe model, and Œªe, Œªc and Œªr are regularization\nweights that balance the learning of different tasks.\nIn this way, the model can be trained efÔ¨Åciently in\nan end-to-end manner.\n5 Experimental Setup\n5.1 Datasets\nFor experimentation, we adopt three publicly avail-\nable explainable recommendation datasets, and\ntheir data splits (Li et al., 2020c). During the\nsplitting process, each dataset is randomly divided\ninto training, validation and testing sets with ra-\ntio 8:1:1 for 5 times, and the training set holds at\nleast one record for each user and each item. The\nthree datasets are respectively from TripAdvisor\n4952\nYelp Amazon TripAdvisor\n#users 27,147 7,506 9,765\n#items 20,266 7,360 6,280\n#records 1,293,247 441,783 320,023\n#features 7,340 5,399 5,069\n#records / user 47.64 58.86 32.77\n#records / item 63.81 60.02 50.96\n#words / exp 12.32 14.14 13.01\n* exp denotes explanation.\nTable 1: Statistics of the three datasets.\n(hotel), Amazon (movies & TV) and Yelp (restau-\nrant). Each record in the datasets is comprised of a\nuser ID, an item ID, a rating, an explanation, and a\nfeature. The explanations are sentences extracted\nfrom user reviews. Each explanation contains at\nleast one item feature, e.g.,bedroom, which ensures\nthe explanation quality. Statistics of the datasets\nare shown in Table 1. We can see that Yelp is much\nlarger than the other two in terms of size, making\nit closer to the real-world situation where there are\nmillions of users and items.\n5.2 Evaluation Metrics\nTo evaluate the recommendation performance, we\nadopt two commonly used metrics: Root Mean\nSquare Error (RMSE) and Mean Absolute Error\n(MAE). As to explanation performance, we mea-\nsure the generated explanations from two main per-\nspectives: text quality and explainability. For the\nformer, we adopt BLEU (Papineni et al., 2002) in\nmachine translation and ROUGE (Lin, 2004) in\ntext summarization, and report BLEU-1 and BLEU-\n4, and Precision, Recall and F1 of ROUGE-1 and\nROUGE-2. Though being widely used, BLUE and\nROUGE are not Ô¨Çawless. For example, it is dif-\nÔ¨Åcult for them to detect the problem of identical\nsentences generated by Transformer. These iden-\ntical sentences might not be used as explanations,\nbecause they are less likely to well explain the spe-\ncial property of different recommendations. To\nquantitatively measure how severe the problem is,\nwe adopt USR that computes the Unique Sentence\nRatio of generated sentences (Li et al., 2020c).\nText quality, however, is not equal to explain-\nbility. In the case of explainable recommendation,\nusers may value more an explanation that justi-\nÔ¨Åes a recommendation‚Äôs advantages on certain fea-\ntures (Li et al., 2020c; Chen et al., 2019a). To this\nend, we adopt the other three metrics proposed by\n(Li et al., 2020c): Feature Matching Ratio (FMR),\nFeature Coverage Ratio (FCR) and Feature Diver-\nsity (DIV). FMR measures whether a generated\nexplanation contains the feature in the ground-truth.\nFCR is computed as the number of distinct features\ncontained in all the generated explanations, divided\nby the total number of features in the whole dataset.\nDIV measures the intersection of features between\nany two generated explanations.\nFor RMSE, MAE and DIV , the lower, the better,\nwhile it is opposite for the rest of metrics.\n5.3 Compared Methods\nWe introduce baselines, Ô¨Årst for explanation and\nthen for recommendation. For the former, we di-\nvide the baselines into two groups, depending on\nwhether the feature is used or not.\nThe following models leverage only user and\nitem IDs to generate explanations (without feature).\nWe denote our model without feature as PETER.\n‚Ä¢Transformer (Vaswani et al., 2017) performs\nthe explanation generation task by treating\nuser and item IDs as words. We also tested\nencoder-decoder Transformer, where the en-\ncoder encodes the IDs for the decoder to de-\ncode, but its results turned out to be the same,\nso we do not report it.\n‚Ä¢NRT (Li et al., 2017) can predict a rating and\ngenerate a tip simultaneously based on user\nand item IDs. We take the explanations in\nthe datasets as tips. Moreover, we found that\nthe model‚Äôs problem of generating identical\nsentences (as reported in Li et al., 2020c) is\ncaused by the L2 regularization in its original\ndesign. For fair comparison, we removed it.\n‚Ä¢Att2Seq (Dong et al., 2017) is a review gener-\nation approach and we take the explanations\nas reviews. This model has an attention mod-\nule, but we found that it makes the generated\ncontent unreadable in the task. To be fair, we\nremoved it as well.\nWhen features are used, we denote our model as\nPETER+, and compare it with two recent models:\n‚Ä¢ACMLM (Ni et al., 2019) is a Ô¨Åne-tuned\nBERT (Devlin et al., 2019), where an atten-\ntion layer is introduced to encode the features\nfrom both the user and the item. By predict-\ning masked tokens, this model can produce\ndiverse sentences.\n‚Ä¢NETE (Li et al., 2020c) is a tailored GRU\n(Cho et al., 2014) that incorporates a given\n4953\nExplainability Text Quality\nFMR‚Üë FCR‚Üë DIV‚Üì USR‚Üë B1‚Üë B4‚Üë R1-P‚Üë R1-R‚Üë R1-F‚Üë R2-P‚Üë R2-R‚Üë R2-F‚Üë\nYelp\nTransformer 0.06 0.06 2.46 0.01 7.39 0.42 19.18 10.29 12.56 1.71 0.92 1.09\nNRT 0.07 0.11 2.37 0.12 11.66 0.65 17.69 12.11 13.55 1.76 1.22 1.33\nAtt2Seq 0.07 0.12 2.41 0.13 10.29 0.58 18.73 11.28 13.29 1.85 1.14 1.31\nPETER 0.08** 0.19** 1.54** 0.13 10.77 0.73** 18.54 12.20 13.77 ** 2.02** 1.38** 1.49**\nACMLM 0.05 0.31 0.95 0.95 7.01 0.24 7.89 7.54 6.82 0.44 0.48 0.39\nNETE 0.80 0.27 1.48 0.52 19.31 2.69 33.98 22.51 25.56 8.93 5.54 6.33\nPETER+ 0.86** 0.38** 1.08 0.34 20.80** 3.43** 35.44** 26.12** 27.95** 10.65** 7.44** 7.94**\nAmazon\nTransformer 0.10 0.01 3.26 0.00 9.71 0.59 19.68 11.94 14.11 2.10 1.39 1.55\nNRT 0.12 0.07 2.93 0.17 12.93 0.96 21.03 13.57 15.56 2.71 1.84 2.05\nAtt2Seq 0.12 0.20 2.74 0.33 12.56 0.95 20.79 13.31 15.35 2.62 1.78 1.99\nPETER 0.12** 0.21 1.75 ** 0.29 12.77 1.17** 19.81 13.80 15.23 2.80 2.08 ** 2.20**\nACMLM 0.10 0.31 2.07 0.96 9.52 0.22 11.65 10.39 9.69 0.71 0.81 0.64\nNETE 0.71 0.19 1.93 0.57 18.76 2.46 33.87 21.43 24.81 7.58 4.77 5.46\nPETER+ 0.77** 0.31** 1.20** 0.46 19.75** 3.06** 34.71** 23.99** 26.35** 9.04** 6.23** 6.71**\nTripAdvisor\nTransformer 0.04 0.00 10.00 0.00 12.79 0.71 16.52 16.38 15.88 2.22 2.63 2.34\nNRT 0.06 0.09 4.27 0.08 15.05 0.99 18.22 14.39 15.40 2.29 1.98 2.01\nAtt2Seq 0.06 0.15 4.32 0.17 15.27 1.03 18.97 14.72 15.92 2.40 2.03 2.09\nPETER 0.07** 0.13 2.95** 0.08 15.96** 1.11* 19.07 16.09 16.48** 2.33 2.17 2.09\nACMLM 0.07 0.41 0.78 0.94 3.45 0.02 4.86 3.82 3.72 0.18 0.20 0.16\nNETE 0.78 0.27 2.22 0.57 22.39 3.66 35.68 24.86 27.71 10.20 6.98 7.66\nPETER+ 0.89** 0.35 1.61 0.25 24.32** 4.55** 37.48** 29.21** 30.49** 11.92** 8.98** 9.24**\nTable 2: Performance comparison of the generation methods in terms of Explainability and Text Quality on three\ndatasets. The methods are divided into two groups according to whether features are used or not. B1 and B4 stand\nfor BLEU-1 and BLEU-4. R1-P, R1-R, R1-F, R2-P, R2-R and R2-F denote Precision, Recall and F1 of ROUGE-1\nand ROUGE-2. BLEU and ROUGE are percentage values (% symbol omitted for table clarity), while the others\nare absolute values. The best performing values are boldfaced, and the second best underlined. ** and * indicate\nthe statistical signiÔ¨Åcance over the second best baseline respectively forp< 0.01 and p< 0.05 via Student‚Äôs t-test.\nfeature into the decoding process to generate\ntemplate-like explanations. It can also make\nrecommendations.\nFor recommendation, besides NRT and NETE,\nwe include another two traditional methods:\n‚Ä¢PMF (Mnih and Salakhutdinov, 2007) is\na standard probabilistic matrix factorization\nmethod that characterizes users and items by\nlatent factors.\n‚Ä¢SVD++ (Koren, 2008) leverages a user‚Äôs in-\nteracted items to enhance the latent factors.\n5.4 Implementation Details\nWe train each model on the training set, tune the\nhyper-parameters on the validation set, and report\nthe performance on the testing set. The results are\naveraged on the 5 data splits. We adopt the codes of\nACMLM and NETE, and implement all the other\nmethods. For NRT, Att2Seq, NETE and our PE-\nTER and PETER+, we set the size of vocabulary\nto 20,000 by keeping the most frequent words. We\ndo not apply this to Transformer, otherwise users\nTime Epochs Time/Epoch\nACMLM 97.0 3 32.3\nPETER+ 57.7 25 2.3\nTable 3: EfÔ¨Åciency comparison of two Transformer-\nbased models in terms of training minutes on the Tri-\npAdvisor dataset, tested on NVIDIA Tesla P40.\nand items (regarded as words) may be Ô¨Åltered out.\nWe set both the number of context words and the\nlength of explanations to 15, because the mean\nlength of explanations is approximately 13 (see Ta-\nble 1). ACMLM adopts sub-words, so we do not\napply the above two steps to it. We reuse the other\ndefault settings of the baselines.\nFor Transformer, PETER and PETER+, we set\nthe embedding size dto 512 and the dimension of\nfeed-forward network to 2,048, following (Vaswani\net al., 2017), but the number of layers Land atten-\ntion heads H are both 2. For our models PETER\nand PETER+, we set the regularization weights Œªe,\nŒªc and Œªr to 1.0, 1.0 and 0.1, respectively. We\noptimize the model via stochastic gradient descent\n(Robbins and Monro, 1951), and apply gradient\nclipping (Pascanu et al., 2013) with a threshold of\n4954\nTop-15 Context Words Explanation\nGround-truth the rooms are spacious and the bathroom has a large tub\nPETER <eos> the and a pool was with nice is very were to good in of the pool area is nice and the gym is very well equipped <eos>\nPETER+ <eos> the and a was pool with to nice good very were is of in the rooms were clean and comfortable <eos>\nGround-truth beautiful lobby and nice bar\nPETER <eos> the and a was were separate bathroom with shower large very had in is the bathroom was large and the shower was great <eos>\nPETER+ <eos> the and a was bathroom shower with large in separate were room very is the lobby was very nice and the rooms were very comfortable <eos>\nTable 4: Context words and explanations on two different cases as generated by our PETER and PETER+ on Tri-\npAdvisor dataset. The boldfaced words in the ground-truth are the key features. Generated features are underlined.\n1.0. The batch size is set to 128, and the learning\nrate 1.0. At each epoch, we save the model if it\nachieves the lowest loss on the validation set, but\nwhen there is no improvement, we decrease the\nlearning rate by a factor of 0.25. When the latter\nhappens for 5 times, we stop training and load the\nsaved model for prediction.\n6 Results and Analysis\n6.1 Quantitative Analysis on Explanations\nIn Table 2, we compare the performance of expla-\nnation generation methods in two groups. We Ô¨Årst\nanalyze models that make use of item features (i.e.,\nACMLM, NETE and PETER+). Our PETER+ con-\nsistently and signiÔ¨Åcantly outperforms ACMLM\nand NETE on the three datasets in terms of text\nquality (BLEU and ROUGE). This shows the ef-\nfectiveness of our model in generating high-quality\nsentences. Notice that Li et al. (2020b) conducted\na user survey and reported that NETE‚Äôs explana-\ntions were perceived useful by most participants. It\nsuggests that our model‚Äôs explanations with better\nquality could also be very useful to real users.\nAgain, in terms of text quality, the performance\ngap between PETER+ and ACMLM (a Ô¨Åne-tuned\nBERT) is extremely large, because the latter‚Äôs gen-\neration is achieved by predicting masked tokens,\nwhich is quite different from word-by-word gener-\nation. This may explain why ACMLM produces\ndiverse sentences (high USR), which, however, is\nless meaningful when text quality cannot be guaran-\nteed. Furthermore, PETER+ beats both ACMLM\nand NETE on the explainability metric FMR that\ncares about whether a generated explanation men-\ntions the feature in the ground-truth. This is quite\nuseful in real-world applications when the system\nis asked to explain a particular feature. Regarding\nthe other two explainability metrics FCR and DIV ,\nPETER+ is also very competitive. ACMLM gains\nbetter performance on some cases, because at the\ntraining stage it is exposed to more features (from\nboth the user and the item), which is unfair to both\nPETER+ and NETE.\nNext, we discuss the results of the models that\nYelp Amazon TripAdvisor\nR‚Üì M‚Üì R‚Üì M‚Üì R‚Üì M‚Üì\nPMF 1.09 0.88 1.03 0.81 0.87 0.70\nSVD++ 1.01 0.78 0.96 0.72 0.80 0.61\nNRT 1.01 0.78 0.95 0.70 0.79 0.61\nNETE 1.01 0.79 0.96 0.73 0.79 0.60\nPETER 1.01 0.78 0.95 0.71 0.81 0.63\nTable 5: Recommendation performance comparison in\nterms of RMSE (R for short) and MAE (denoted as M).\nThe best performing values are boldfaced.\nonly leverage user and item IDs for generation. As\nit can be seen, Transformer generates identical ex-\nplanations on each dataset, resulting in nearly 0\nscore on Unique Sentence Ratio (USR). Owing\nto the context prediction task, our PETER suc-\ncessfully addresses this issue, producing diverse\n(comparable USR) and high-quality (best BLEU-\n4) sentences. In particular, on the largest dataset\nYelp, it achieves the best performance on most of\nthe metrics. This again demonstrates the effective-\nness of our model. On Amazon and TripAdvisor,\nNRT and Att2Seq are very competitive, because\nwe Ô¨Åxed their generation issues (see Section 5.3).\nIn addition, the two datasets are small and thus the\ntraining samples are limited, so our model may un-\nderÔ¨Åt, which is why it does not always reach the\nbest performance.\nBesides explanation performance, we also inves-\ntigate the efÔ¨Åciency of different Transformer-based\nmodels. On the same machine (NVIDIA Tesla P40)\nand dataset (TripAdvisor), we compare the train-\ning minutes of ACMLM and our PETER+ in Table\n3. Compared with ACMLM, our model takes less\ntime to train (2.3 minutes per epoch), since it has\nonly 2 layers and thus less parameters. But because\nit is unpretrained and learned from scratch, it needs\nmore training epochs.\n6.2 Qualitative Case Study on Explanations\nIn Table 4, we present two examples generated by\nPETER and PETER+ on the TripAdvisor dataset.\nWe can see that PETER generates distinct context\nwords and explanations for different user-item pairs.\nThis conÔ¨Årms that our proposed solution can in-\ndeed endow the user and item IDs with linguis-\n4955\nExplainability Text Quality Recommendation\nFMR FCR DIV USR BLEU-1 BLEU-4 RMSE MAE\nDisable Lc 0.06 ‚Üì 0.03 ‚Üì 5.75 ‚Üì 0.01 ‚Üì 15.37 ‚Üì 0.86 ‚Üì 0.80 ‚Üë 0.61 ‚Üë\nDisable Lr 0.07 0.14 ‚Üë 2.90 ‚Üë 0.10 ‚Üë 16.16 ‚Üë 1.15 ‚Üë 3.23 ‚Üì 3.10 ‚Üì\nLeft-to-Right Masking 0.07 0.15 ‚Üë 2.68 ‚Üë 0.12 ‚Üë 15.73 ‚Üì 1.11 0.87 ‚Üì 0.68 ‚Üì\nPETER 0.07 0.13 2.95 0.08 15.96 1.11 0.81 0.63\nTable 6: Ablation study on the smallest dataset TripAdvisor. Arrows ‚Üëand ‚Üìrespectively denote the performance\nincrease and decrease compared with PETER.\ntic meanings, as well as achieving certain degree\nof personalization for natural language generation.\nAmong the commonly used context words, e.g.,\nthe, there are some important features (underlined),\naccording to which the model then generates an ex-\nplanation that talks about them. Admittedly, there\nis still much room for improvement of the context\nprediction task, so as to more accurately predict the\nfeatures in the ground-truth (e.g., rooms vs. pool\nin the Ô¨Årst example). One alternative is to leverage\nthe features to guide the model‚Äôs generation. This\nexplains why PETER+ is able to generate an ex-\nplanation that talks about rooms rather than pool,\nmaking it semantically closer to the ground-truth.\nIt thus demonstrates our model‚Äôs Ô¨Çexibility in in-\ncorporating these features.\n6.3 Recommendation Performance\nTable 5 presents the performance comparison\nof different recommendation methods. On the\nlargest dataset Yelp with approximately 1.3 million\nrecords, our model PETER performs as good as the\nthree competitive baselines (i.e., SVD++, NRT and\nNETE), which shows the rationale of our recom-\nmendation module. Since our model PETER has\nmore parameters to learn, it may underÔ¨Åt on small\ndatasets. This explains why it does not always per-\nform the best on TripAdvisor and Amazon. When\nmore training data are available to Transformer,\nusually the performance will become better, as evi-\ndenced by GPT-2 (Radford et al., 2019) and GPT-3\n(Brown et al., 2020). Thus, we can expect our\nmodel to perform well in real-world applications,\nwhere the training data are bigger than the testing\ndatasets, e.g., billion-scale users in Amazon.\n6.4 Ablation Study\nIn Table 6, we provide an ablation study conducted\non the TripAdvisor dataset. After disabling the\ncontext prediction task Lc by setting Œªc = 0, the\nperformances of both explainability and text qual-\nity drop dramatically, and the unique sentence ratio\n(USR) is nearly approaching Transformer‚Äôs (see\nTable 2). It hence conÔ¨Årms this task‚Äôs effectiveness.\nAs Lc is highly correlated with the recommenda-\ntion task Lr via the user and item IDs (see Section\n4.3), the removal of Lc leads to slight improve-\nment on recommendation performance. We can\nalso observe a reversed phenomenon when we dis-\nable Lr. When PETER masking is replaced by the\nLeft-to-Right masking that prevents the model from\naccessing the item information, the recommenda-\ntion performance drops sharply. Overall, PETER\nreaches an optimal situation, where its explainabil-\nity, text quality and recommendation performance\nare all reasonably good.\n7 Conclusion\nWe propose a simple and effective solution to ad-\ndress the personalized generation problem of Trans-\nformer, unleashing its language modeling power\nto generate explanations for recommender systems.\nExtensive experiments show that the solution is\nboth effective and efÔ¨Åcient. It opens up a new way\nof exploiting Transformer by designing good tasks\ninstead of scaling up model size. There are various\napplications of personalized generation for which\nTransformer is still less explored. Our next step\nis to adopt our solution for personalized question\nanswering systems and personalized conversational\nagents. We also plan to incorporate item images\ninto the model, so as to generate visual explanations\nfor recommendations, since ‚Äúa picture is worth a\nthousand words‚Äù. Another meaningful extension\nis to adapt the model to cross-lingual explanation\ngeneration, because international platforms, e.g.,\nAmazon, may serve users who speak different lan-\nguages.\nAcknowledgments\nThis work was partially supported by HKBU\nIRCMS/19-20/D05, RGC/HKBU12201620, and\nNSF IIS-1910154 and IIS-2007907. Any opin-\nions, Ô¨Åndings, conclusions or recommendations\nexpressed in this material are those of the authors\nand do not necessarily reÔ¨Çect those of the sponsors.\n4956\nReferences\nQingyao Ai, Vahid Azizi, Xu Chen, and Yongfeng\nZhang. 2018. Learning heterogeneous knowledge\nbase embeddings for explainable recommendation.\nAlgorithms, 11(9):137.\nTom B Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. In Advances in neural information process-\ning systems.\nHanxiong Chen, Xu Chen, Shaoyun Shi, and Yongfeng\nZhang. 2019a. Generate natural language explana-\ntions for recommendation. In Proceedings of SI-\nGIR‚Äô19 Workshop on ExplainAble Recommendation\nand Search. ACM.\nHanxiong Chen, Shaoyun Shi, Yunqi Li, and Yongfeng\nZhang. 2021. Neural collaborative reasoning. In\nProceedings of The Web Conference 2021.\nLi Chen and Feng Wang. 2017. Explaining recom-\nmendations based on feature sentiments in product\nreviews. In Proceedings of the 22nd International\nConference on Intelligent User Interfaces, pages 17‚Äì\n28.\nLi Chen, Dongning Yan, and Feng Wang. 2019b. User\nevaluations on sentiment-based recommendation ex-\nplanations. ACM Transactions on Interactive Intelli-\ngent Systems (TiiS), 9(4):1‚Äì38.\nXu Chen, Hanxiong Chen, Hongteng Xu, Yongfeng\nZhang, Yixin Cao, Zheng Qin, and Hongyuan Zha.\n2019c. Personalized fashion recommendation with\nvisual explanations based on multimodal attention\nnetwork: Towards visually explainable recommen-\ndation. In Proceedings of the 42nd International\nACM SIGIR Conference on Research and Develop-\nment in Information Retrieval, pages 765‚Äì774.\nXu Chen, Yongfeng Zhang, and Zheng Qin. 2019d. Dy-\nnamic explainable recommendation based on neural\nattentive models. In Proceedings of the AAAI Con-\nference on ArtiÔ¨Åcial Intelligence , volume 33, pages\n53‚Äì60.\nZhongxia Chen, Xiting Wang, Xing Xie, Mehul\nParsana, Akshay Soni, Xiang Ao, and Enhong Chen.\n2020. Towards explainable conversational recom-\nmendation. In Proceedings of the Twenty-Ninth\nInternational Joint Conference on ArtiÔ¨Åcial Intelli-\ngence.\nKyunghyun Cho, Bart Van Merri ¬®enboer, Caglar Gul-\ncehre, Dzmitry Bahdanau, Fethi Bougares, Holger\nSchwenk, and Yoshua Bengio. 2014. Learning\nphrase representations using rnn encoder-decoder\nfor statistical machine translation. In Proceedings of\nthe 2014 conference on empirical methods in natural\nlanguage processing (EMNLP), pages 1724‚Äì1734.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. In 2019 Annual Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics.\nLi Dong, Shaohan Huang, Furu Wei, Mirella Lapata,\nMing Zhou, and Ke Xu. 2017. Learning to generate\nproduct reviews from attributes. In Proceedings of\nthe 15th Conference of the European Chapter of the\nAssociation for Computational Linguistics: Volume\n1, Long Papers, pages 623‚Äì632.\nLi Dong, Nan Yang, Wenhui Wang, Furu Wei, Xi-\naodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou,\nand Hsiao-Wuen Hon. 2019. UniÔ¨Åed language\nmodel pre-training for natural language understand-\ning and generation. In Advances in Neural Informa-\ntion Processing Systems, pages 13063‚Äì13075.\nZuohui Fu, Yikun Xian, Ruoyuan Gao, Jieyu Zhao,\nQiaoying Huang, Yingqiang Ge, Shuyuan Xu, Shi-\njie Geng, Chirag Shah, Yongfeng Zhang, et al.\n2020. Fairness-aware explainable recommendation\nover knowledge graphs. In Proceedings of the 43rd\nInternational ACM SIGIR Conference on Research\nand Development in Information Retrieval.\nFatih Gedikli, Dietmar Jannach, and Mouzhi Ge. 2014.\nHow should i explain? a comparison of different\nexplanation types for recommender systems. In-\nternational Journal of Human-Computer Studies ,\n72(4):367‚Äì382.\nSepp Hochreiter and J ¬®urgen Schmidhuber. 1997.\nLong short-term memory. Neural computation ,\n9(8):1735‚Äì1780.\nYehuda Koren. 2008. Factorization meets the neighbor-\nhood: a multifaceted collaborative Ô¨Åltering model.\nIn Proceedings of the 14th ACM SIGKDD interna-\ntional conference on Knowledge discovery and data\nmining, pages 426‚Äì434.\nJunjie Li, Haoran Li, and Chengqing Zong. 2019. To-\nwards personalized review summarization via user-\naware sequence network. In Proceedings of the\nAAAI Conference on ArtiÔ¨Åcial Intelligence , vol-\nume 33, pages 6690‚Äì6697.\nLei Li, Li Chen, and Ruihai Dong. 2020a. Caesar:\ncontext-aware explanation based on supervised at-\ntention for service recommendations. Journal of In-\ntelligent Information Systems, pages 1‚Äì24.\nLei Li, Li Chen, and Yongfeng Zhang. 2020b. To-\nwards controllable explanation generation for recom-\nmender systems via neural template. In Compan-\nion Proceedings of the Web Conference 2020, pages\n198‚Äì202.\nLei Li, Yongfeng Zhang, and Li Chen. 2020c. Gen-\nerate neural template explanations for recommenda-\ntion. In Proceedings of the 29th ACM International\nConference on Information & Knowledge Manage-\nment, pages 755‚Äì764.\n4957\nLei Li, Yongfeng Zhang, and Li Chen. 2021. Extra:\nExplanation ranking datasets for explainable recom-\nmendation. In Proceedings of the 44th International\nACM SIGIR conference on Research and Develop-\nment in Information Retrieval.\nPiji Li, Zihao Wang, Zhaochun Ren, Lidong Bing, and\nWai Lam. 2017. Neural rating regression with ab-\nstractive tips generation for recommendation. In\nProceedings of the 40th International ACM SIGIR\nconference on Research and Development in Infor-\nmation Retrieval, pages 345‚Äì354.\nChin-Yew Lin. 2004. Rouge: A package for automatic\nevaluation of summaries. In Text summarization\nbranches out, pages 74‚Äì81.\nPeter J Liu, Mohammad Saleh, Etienne Pot, Ben\nGoodrich, Ryan Sepassi, Lukasz Kaiser, and Noam\nShazeer. 2018. Generating wikipedia by summariz-\ning long sequences. In The Sixth International Con-\nference on Learning Representations.\nAndriy Mnih and Russ R Salakhutdinov. 2007. Proba-\nbilistic matrix factorization. In Advances in neural\ninformation processing systems, pages 1257‚Äì1264.\nJianmo Ni, Jiacheng Li, and Julian McAuley. 2019.\nJustifying recommendations using distantly-labeled\nreviews and Ô¨Åne-grained aspects. In Proceedings of\nthe 2019 Conference on Empirical Methods in Nat-\nural Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 188‚Äì197.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic eval-\nuation of machine translation. In Proceedings of the\n40th annual meeting of the Association for Compu-\ntational Linguistics, pages 311‚Äì318.\nRazvan Pascanu, Tomas Mikolov, and Yoshua Bengio.\n2013. On the difÔ¨Åculty of training recurrent neural\nnetworks. In International conference on machine\nlearning, pages 1310‚Äì1318.\nAlec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nHerbert Robbins and Sutton Monro. 1951. A stochastic\napproximation method. The annals of mathematical\nstatistics, pages 400‚Äì407.\nShaoyun Shi, Hanxiong Chen, Weizhi Ma, Jiaxin Mao,\nMin Zhang, and Yongfeng Zhang. 2020. Neural\nlogic reasoning. In Proceedings of the 29th ACM\nInternational Conference on Information & Knowl-\nedge Management, pages 1365‚Äì1374.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in neural information pro-\ncessing systems, pages 5998‚Äì6008.\nYikun Xian, Zuohui Fu, S Muthukrishnan, Gerard\nDe Melo, and Yongfeng Zhang. 2019. Reinforce-\nment knowledge graph reasoning for explainable\nrecommendation. In Proceedings of the 42nd Inter-\nnational ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval , pages 285‚Äì\n294.\nYikun Xian, Zuohui Fu, Handong Zhao, Yingqiang Ge,\nXu Chen, Qiaoying Huang, Shijie Geng, Zhou Qin,\nGerard De Melo, Shan Muthukrishnan, et al. 2020.\nCafe: Coarse-to-Ô¨Åne neural symbolic reasoning for\nexplainable recommendation. In Proceedings of the\n29th ACM International Conference on Information\n& Knowledge Management, pages 1645‚Äì1654.\nYongfeng Zhang and Xu Chen. 2020. Explainable\nrecommendation: A survey and new perspectives.\nFoundations and Trends R‚Éùin Information Retrieval,\n14(1):1‚Äì101.\nYongfeng Zhang, Xu Chen, Qingyao Ai, Liu Yang,\nand W Bruce Croft. 2018. Towards conversational\nsearch and recommendation: System ask, user re-\nspond. In Proceedings of the 27th ACM Interna-\ntional Conference on Information and Knowledge\nManagement, pages 177‚Äì186.\nYongfeng Zhang, Guokun Lai, Min Zhang, Yi Zhang,\nYiqun Liu, and Shaoping Ma. 2014. Explicit fac-\ntor models for explainable recommendation based\non phrase-level sentiment analysis. In Proceedings\nof the 37th international ACM SIGIR conference on\nResearch & development in information retrieval ,\npages 83‚Äì92.\nYinhe Zheng, Rongsheng Zhang, Minlie Huang, and\nXiaoxi Mao. 2020. A pre-training based personal-\nized dialogue generation model with persona-sparse\ndata. In Proceedings of the AAAI Conference on Ar-\ntiÔ¨Åcial Intelligence, pages 9693‚Äì9700.\nKun Zhou, Wayne Xin Zhao, Shuqing Bian, Yuan-\nhang Zhou, Ji-Rong Wen, and Jingsong Yu. 2020.\nImproving conversational recommender systems via\nknowledge graph based semantic fusion. In Pro-\nceedings of the 26th ACM SIGKDD International\nConference on Knowledge Discovery & Data Min-\ning, pages 1006‚Äì1014.\nYaxin Zhu, Yikun Xian, Zuohui Fu, Gerard de Melo,\nand Yongfeng Zhang. 2021. Faithfully explainable\nrecommendation via neural logic reasoning. In 2021\nAnnual Conference of the North American Chapter\nof the Association for Computational Linguistics.",
  "topic": "Zh√†ng",
  "concepts": [
    {
      "name": "Zh√†ng",
      "score": 0.6343982219696045
    },
    {
      "name": "Computer science",
      "score": 0.624670147895813
    },
    {
      "name": "Chen",
      "score": 0.601801335811615
    },
    {
      "name": "Transformer",
      "score": 0.5542963743209839
    },
    {
      "name": "Joint (building)",
      "score": 0.44783878326416016
    },
    {
      "name": "Volume (thermodynamics)",
      "score": 0.42863112688064575
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3724118173122406
    },
    {
      "name": "Natural language processing",
      "score": 0.36068034172058105
    },
    {
      "name": "Engineering",
      "score": 0.19848838448524475
    },
    {
      "name": "Electrical engineering",
      "score": 0.13821673393249512
    },
    {
      "name": "History",
      "score": 0.11724212765693665
    },
    {
      "name": "Geology",
      "score": 0.07980218529701233
    },
    {
      "name": "China",
      "score": 0.07686135172843933
    },
    {
      "name": "Civil engineering",
      "score": 0.07621029019355774
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I141568987",
      "name": "Hong Kong Baptist University",
      "country": "HK"
    },
    {
      "id": "https://openalex.org/I102322142",
      "name": "Rutgers, The State University of New Jersey",
      "country": "US"
    }
  ],
  "cited_by": 104
}