{
  "title": "Impact of large language model (ChatGPT) in healthcare: an umbrella review and evidence synthesis",
  "url": "https://openalex.org/W4410178347",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2111317264",
      "name": "Usman Iqbal",
      "affiliations": [
        "Bond University",
        "Gold Coast Health",
        "Gold Coast Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2790087495",
      "name": "Afifa Tanweer",
      "affiliations": [
        "University of Management and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2572715367",
      "name": "Annisa Ristya Rahmanti",
      "affiliations": [
        "Middlesex University",
        "Universitas Gadjah Mada"
      ]
    },
    {
      "id": "https://openalex.org/A1990797816",
      "name": "David Greenfield",
      "affiliations": [
        "UNSW Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A5037904618",
      "name": "Leon Tsung‐Ju Lee",
      "affiliations": [
        "Taipei Medical University Hospital",
        "Taipei Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2682987909",
      "name": "Yu-Chuan (Jack) Li",
      "affiliations": [
        "Taipei Medical University",
        "Taipei Municipal YangMing Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2111317264",
      "name": "Usman Iqbal",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2790087495",
      "name": "Afifa Tanweer",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2572715367",
      "name": "Annisa Ristya Rahmanti",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1990797816",
      "name": "David Greenfield",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5037904618",
      "name": "Leon Tsung‐Ju Lee",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2682987909",
      "name": "Yu-Chuan (Jack) Li",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4384282605",
    "https://openalex.org/W4389117636",
    "https://openalex.org/W4388615529",
    "https://openalex.org/W4387818199",
    "https://openalex.org/W4385845074",
    "https://openalex.org/W4388896357",
    "https://openalex.org/W4317914418",
    "https://openalex.org/W4380371861",
    "https://openalex.org/W4386845850",
    "https://openalex.org/W2205558186",
    "https://openalex.org/W4366498198",
    "https://openalex.org/W4390240044",
    "https://openalex.org/W3113541070",
    "https://openalex.org/W4386023761",
    "https://openalex.org/W4391069573",
    "https://openalex.org/W4389565446",
    "https://openalex.org/W4385838574",
    "https://openalex.org/W4378574344",
    "https://openalex.org/W4379376212",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W3155461783",
    "https://openalex.org/W4386173035",
    "https://openalex.org/W2756578555",
    "https://openalex.org/W3080762062",
    "https://openalex.org/W4391047581",
    "https://openalex.org/W4380480792",
    "https://openalex.org/W4389574959",
    "https://openalex.org/W4390587679",
    "https://openalex.org/W4390674638",
    "https://openalex.org/W4393994738",
    "https://openalex.org/W4389898530",
    "https://openalex.org/W4389917881",
    "https://openalex.org/W4321442932",
    "https://openalex.org/W4388860503",
    "https://openalex.org/W4390443812"
  ],
  "abstract": null,
  "full_text": "Iqbal et al. \nJournal of Biomedical Science           (2025) 32:45  \nhttps://doi.org/10.1186/s12929-025-01131-z\nRESEARCH Open Access\n© The Author(s) 2025. Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory \nregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this \nlicence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/. The Creative Commons Public Domain Dedication waiver (http:// creat iveco \nmmons. org/ publi cdoma in/ zero/1. 0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\nImpact of large language model (ChatGPT) \nin healthcare: an umbrella review and evidence \nsynthesis\nUsman Iqbal1,2, Afifa Tanweer3, Annisa Ristya Rahmanti4,5, David Greenfield6, Leon Tsung‑Ju Lee7,8,9 and \nYu‑Chuan Jack Li10,11,12*   \nAbstract \nBackground The emergence of Artificial Intelligence (AI), particularly Chat Generative Pre‑Trained Transformer \n(ChatGPT), a Large Language Model (LLM), in healthcare promises to reshape patient care, clinical decision‑making, \nand medical education. This review aims to synthesise research findings to consolidate the implications of ChatGPT \nintegration in healthcare and identify research gaps.\nMain body The umbrella review was conducted following Preferred Reporting Items for Systematic Reviews \nand Meta‑Analyses (PRISMA) guidelines. The Cochrane Library, PubMed, Scopus, Web of Science, and Google Scholar \nwere searched from inception until February 2024. Due to the heterogeneity of the included studies, no quantitative \nanalysis was performed. Instead, information was extracted, summarised, synthesised, and presented in a narrative \nform. Two reviewers undertook title, abstract, and full text screening independently. The methodological quality \nand overall rating of the included reviews were assessed using the A Measurement Tool to Assess systematic Reviews \n(AMSTAR‑2) checklist. The review examined 17 studies, comprising 15 systematic reviews and 2 meta‑analyses, \non ChatGPT in healthcare, revealing diverse focuses. The AMSTAR‑2 assessment identified 5 moderate and 12 low‑\nquality reviews, with deficiencies like study design justification and funding source reporting. The most reported \ntheme that emerged was ChatGPT’s use in disease diagnosis or clinical decision‑making. While 82.4% of studies \nfocused on its general usage, 17.6% explored unique topics like its role in medical examinations and conducting \nsystematic reviews. Among these, 52.9% targeted general healthcare, with 41.2% focusing on specific domains \nlike radiology, neurosurgery, gastroenterology, public health dentistry, and ophthalmology. ChatGPT’s use for manu‑\nscript review or writing was mentioned in 17.6% of reviews. Promising applications include enhancing patient care \nand clinical decision‑making, though ethical, legal, and accuracy concerns require cautious integration.\nConclusion We summarise the identified areas in reviews regarding ChatGPT’s transformative impact in health‑\ncare, highlighting patient care, decision‑making, and medical education. Emphasising the importance of ethical \nregulations and the involvement of policymakers, we urge further investigation to ensure the reliability of ChatGPT \nand to promote trust in healthcare and research.\nKeywords ChatGPT; Large language models (LLMs), Generative AI, Healthcare; Medical research; Medical education; \nPatient care, Consumer health, Reviews, Evidence synthesis\n*Correspondence:\nYu‑Chuan Jack Li\njack@tmu.edu.tw\nFull list of author information is available at the end of the article\nPage 2 of 19Iqbal et al. Journal of Biomedical Science           (2025) 32:45 \nBackground\nRecent advancements in Artificial Intelligence (AI) have \nbrought transformative changes across various indus -\ntries, including healthcare [16]. AI-powered tools and \ntechnologies offer the potential to revolutionise health -\ncare delivery, improving patient outcomes, and enhanc -\ning clinical decision-making processes. Among these \ntechnologies, ChatGPT (Chat Generative Pre-trained \nTransformer), a Large Language Model (LLM), devel -\noped by OpenAI, has received significant attention \nwithin the healthcare sector [12]. As a state-of-the-art \nNatural Language Processing (NLP) model trained on a \nvast corpus of text data, ChatGPT can generate human-\nlike responses to text inputs. Operating on deep learn -\ning principles and employing a transformer architecture, \nChatGPT surpasses traditional rule-based chatbots by \nnot relying on predefined rules or templates for generat -\ning responses [23]. Instead, it leverages its extensive pre-\ntrained knowledge to understand and respond to queries \nin a contextually relevant manner.\nChatGPT is a promising tool for a wide range of diverse \nand multifaceted applications in consumer health [23]. \nOne of the primary areas of promise is in healthcare edu -\ncation. With its ability to generate informative and educa-\ntional content, ChatGPT can serve as a valuable resource \nfor medical students, healthcare professionals, and edu -\ncators [25]. It can assist in the creation of educational \nmaterials, answer clinical queries, and facilitate interac -\ntive learning experiences. Additionally, ChatGPT can aid \nmedical research by generating human-like text, offering \nfundamental guidance, and elucidating complex con -\ncepts [1]. In clinical practice, ChatGPT has the potential \nto streamline clinical documentation, patient communi -\ncation, and decision support tasks, thus improving the \nworkflow efficiency. By automating routine administra -\ntive tasks and providing real-time assistance, ChatGPT \ncan help reduce the burden on healthcare professionals \nand enhance the quality of patient care [14]. Moreover, \nChatGPT holds promise in diagnostic assistance and \ndecision support. Its ability to process and analyze medi -\ncal data, including patient histories, symptoms, and diag -\nnostic tests, enables it to provide valuable insights and \nrecommendations to healthcare providers. In fields such \nas radiology and pathology, ChatGPT can assist in image \ninterpretation, differential diagnosis, and treatment plan-\nning, potentially improving diagnostic accuracy and \npatient outcomes [21]. Furthermore, it can offer sec -\nond opinions on dermatological treatments, which may \nbecome increasingly reliable as it continues to optimize \n[33].\nDespite its potential benefits, integrating ChatGPT into \nhealthcare practice poses risks, challenges and limita -\ntions. Addressing risks associated with ethical concerns \nregarding patient privacy, data security, and algorithmic \nbias is crucial for ensuring its safe and responsible use. \nMoreover, verifying the accuracy, reliability, and trust -\nworthiness of ChatGPT-generated content requires fur -\nther investigation [34].\nTranslating promises into reality is always a significant \nstep. The potential uses and benefits of ChatGPT for con-\nsumer health have emerged but are not yet fully realised. \nFurther work is necessary to understand for what and \nhow ChatGPT is being used. Similarly, understanding \nthe risks, challenges and limitations of ChatGPT in con -\nsumer health can help ensure its appropriate and effective \nuse. Given these considerations, conducting an umbrella \nreview of systematic reviews on ChatGPT in consumer \nhealth is imperative. This study aims to provide a com -\nprehensive overview through synthesis and evaluation, \nincluding evidence gap synthesis, discerns implications \nfor integration, and highlight areas for further research \nand development.\nMethods\nAn umbrella review synthesises existing systematic \nreviews and meta-analyses on a topic, offering a compre -\nhensive overview of evidence from multiple studies. It \nprovides a broader perspective, enhancing research depth \nand reliability. Thus, it is ideal for exploring ChatGPT’s \napplications and impacts in healthcare. This umbrella \nreview was conducted according to the Preferred Report-\ning Items for Systematic Reviews and Meta-Analysis \nProtocols guidelines (PRISMA) [26]. The checklist rec -\nommended by Choi et al. [8] was followed for conduct -\ning and reporting this umbrella review. The protocol was \nregistered with the International Prospective Register \nof Systematic Reviews (PROSPERO) under registration \nnumber CRD42024510926.\nSearch strategy and eligibility criteria\nThe search strategy for included reviews was conducted \nacross five electronic databases: (i) Cochrane Library (the \nCochrane Database of Systematic Reviews); (ii) PubMed; \n(iii) Web of Science (all databases); (iv) Scopus; and (v) \nGoogle Scholar. The review period was up until February \n3, 2024, without restrictions on language or publication \nyear.\nTo capture a wide-ranging collection of reviews cover -\ning ChatGPT’s role in consumer health, we performed a \ncomprehensive searching strategy across the database \nby using a combination of keywords and Boolean opera -\ntors. For Google Scholar, specific filters for ’review arti -\ncles’ and sorting by relevance were applied, followed by \na targeted search query to refine the results further. The \ndetailed search strategy can be found in Additional file 1.\nPage 3 of 19\nIqbal et al. Journal of Biomedical Science           (2025) 32:45 \n \nThe inclusion criteria were: (i) peer-reviewed System -\natic Reviews (SR) and Systematic Reviews with Meta-\nAnalysis (SRMA); (ii) focusing on ChatGPT within the \nscope of consumer health, specifically highlighting areas \nsuch as patient education, health information seeking, \ndigital health interventions, health literacy, and various \nforms of electronic health services. While prioritising \nSR and SRMA, the scope extends to any study following \nPRISMA guidelines, thereby ensuring a broad yet rigor -\nous collection of literature on ChatGPT’s impact on con -\nsumer health informatics. Studies were excluded if they: \n(i) were not SR or SRMA; (ii) lacked relevance to Chat -\nGPT in consumer health; (iii) were not entirely in Eng -\nlish; or (iv) were only available as abstracts without full \ntexts.\nFor study selection, two reviewers (AT and ARR) inde -\npendently performed the literature search across the \nselected databases, then screened titles and abstracts to \neliminate duplicates, and read the full texts of all papers \nto identify relevant systematic reviews. Any disagree -\nments were resolved by a consensus with a third reviewer \n(UI).\nAssessment of methodological quality\nThe methodological quality of the included reviews was \nappraised using A MeaSurement Tool to Assess system -\natic Reviews (AMSTAR-2) guideline, a comprehensive \nframework to determine the thoroughness and reliability \nof the reviews [28]. Quality levels were categorised into \nhigh, moderate, low, or critically low, based on the pres -\nence of critical flaws and non-critical weaknesses. The \nAMSTAR-2 appraisal was initially performed by a single \nreviewer (ARR) and then verified by another (AT), with \nboth agreeing on the evaluation outcomes without any \ndisagreement.\nData extraction and evidence synthesis\nThe selected articles were manually reviewed, and per -\ntinent information was extracted, synthesised, and \nsummarised in tabular format. We did not perform quan-\ntitative analysis in this review given the heterogeneity of \nincluded articles and because the meta-analysis had not \nbeen performed in most of the articles. The findings were \nsynthesised into main and sub-themes, analysing the \nmost common outcomes and methodological quality of \nthe systematic reviews.\nResults\nA preliminary search with the key term “ChatGPT” \nyielded no results in the Cochrane Library. Subsequently, \na search was conducted on PubMed using keyword \n“ChatGPT” with the filter set to “Systematic Reviews” \nwithout any restriction for date, yielding 21 records. \nIn addition, after applying the filter of “review articles” \nand “sort by relevance” , we inserted a predefined search \nquery in the search tab of Google Scholar, producing \n433 results. As Google Scholar gives very broad search \nresults, we utilised the methodology described by Hadda-\nway et al. [11] and included the first 50 records for further \nscreening. Out of these, 15 titles were deemed relevant to \nthe objectives of this umbrella review. Searches in Sco -\npus and Web of Science, following predefined criteria, \nyielded 23 and 5 records, respectively. After removing \nthe duplicates, 74 unique titles were screened by titles \nand abstracts, leading to the exclusion of 54 studies for \nbeing irrelevant to the study objective (40) or not being \nsystematic reviews (14), out of which 20 were deemed \neligible for full-text analysis. Three articles were further \nexcluded during full-text study for not solely focusing \non ChatGPT [19], being a preprint (not peer-reviewed) \n[9], and primarily emphasising practical query interac -\ntions with ChatGPT, rather than providing a comprehen-\nsive analysis of systematic review results [7]. Therefore, \n17 articles were included in the final group for analysis \nand synthesis, as illustrated in the PRISMA flow diagram \n(Fig. 1). Of these, 15 comprised systematic reviews, with \nan additional 2 being meta-analyses. The distribution of \npublication years underscores the topic’s emerging rele -\nvance, with 13 articles published in 2023 and 4 in 2024 to \nFebruary, indicating a notable surge in ChatGPT-related \nresearch during this period.\nThe methodological quality assessment using \nAMSTAR-2, as summarised in Table  1, indicated that 5 \nout of 17 reviews (29.4%) were of moderate quality, while \nthe remaining 12 out of 17 reviews (70.6%) had low qual -\nity. Notably, the most frequently lacking quality indica -\ntor was the explanation or justification of the selection \nof study designs for inclusion in the review (item number \n3). Furthermore, deficiencies were observed in report -\ning the sources of funding (item number 10), addressing \nthe risk of bias when discussing results (item number \n13), and explaining or discussing observed heterogeneity \n(item number 14), indicating areas needing improvement \nin future reviews.\nTables 2 and 3 present a summary of the methodology \naims and key findings of the included articles, offering a \ncomprehensive overview of how ChatGPT is being inte -\ngrated and evaluated within healthcare settings. These \nreviews exhibited considerable heterogeneity in terms \nof their fields and objectives. The majority (82.35% or \n14 out of 17) of the reviews focused on elucidating the \nusage, advantages, and limitations of ChatGPT across \nvarious domains within healthcare. The remaining \nthree reviews explored unique topics, including the \nrole of ChatGPT in multiple-choice question-based \nmedical examinations [17], medical research [24], and \nPage 4 of 19Iqbal et al. Journal of Biomedical Science           (2025) 32:45 \nperformance in systematic review tasks [27]. While a \nmajority (52.94% or 9 out of 17) of the reviews concen -\ntrated on general healthcare practices, a total of seven \nreviews delved into specific domains such as radiology \n[4, 31], neurosurgery [3 ],Roman, Al-Sharif, & Gharyani, \n2023), gastroenterology [15], public health dentistry \n[32] and ophthalmology [35]. Quantitative analysis of \npooled findings was conducted in two studies. It was \nnoted that 3 out of the 17 systematic reviews (17.65%) \nincorporated ChatGPT to aid in reviewing [10, 27] or \nwriting manuscripts [20], acknowledging the contribu -\ntion in their acknowledgements section.\nTable  4 outlines the references of articles report -\ning each theme and sub theme of ChatGPT within the \ncontext of healthcare. According to the included arti -\ncles, the role of ChatGPT in healthcare from both the \npatient and caregiver perspectives, emerged as the most \nfrequently studied theme (studied in 16 out of 17 arti -\ncles) [2 –5, 15, 18, 20], Muftić, Kadunić, Mušinbegović, \n& Almisreb, 2023; [22, 24],Salam, 2023; [27, 31, 32, 35, \n36]. The education of patients—in terms of general \ninformation gathering about disease—was explored in \n11 studies [2 –5, 18, 20, 22, 24, 25, 35, 36].\nAdditional File 2, Table  S1 shows the comparison of \nvarious versions of ChatGPT used in the included arti -\ncles. Eight studies out of 17 mentioned the impact of dif -\nferent versions of ChatGPT on tasks they can perform \neffectively [2, 4, 15, 17, 18, 27, 31, 35]. ChatGPT 3.5 was \nFig. 1 PRISMA flow diagram representing the inclusion of systematic reviews and meta‑analysis\nPage 5 of 19\nIqbal et al. Journal of Biomedical Science           (2025) 32:45 \n \nfound to be less precise and needed human verification \nbut its accuracy depends on the quality of training data. \nIt easily integrates into clinical workflows and is a prom -\nising educational tool. ChatGPT 4.0 was able to handle \ncomplex tasks such as radiology [31] but was less reliable \nin less complex tasks [4]. However, gastroenterology self-\nassessment could not be done by both versions in a satis -\nfactory manner [15].\nDiscussion\nThis umbrella review synthesised 17 existing systematic \nreviews and meta-analyses investigating the applications, \nstrengths, limitations, and future directions of using \nChatGPT in healthcare. The evidence suggests that Chat-\nGPT has diverse applications, which explored enhancing \npatient care [10], conducting and reporting systematic \nreviews [27], advancing healthcare education [25], aug -\nmenting clinical decision-making [31], and providing \npreparatory materials for medical examinations [17]. \nSeveral studies suggested that ChatGPT can be employed \nas a valuable tool in clinical practice, assisting clini -\ncians with patient inquiries, writing medical notes and \ndischarge summaries, and making informed decisions \nabout treatment plans. Additionally, it has the potential \nto serve as a personalised learning tool, encouraging crit -\nical thinking and problem-based learning among medical \nprofessionals [18, 36].\nChatGPT has demonstrated remarkable capabilities \nin generating human-like text and conducting natural \nlanguage processing for text organisation and summari -\nsation. It can expedite processes such as collecting ques -\ntionnaire responses or conducting interviews, enhancing \nthe effectiveness and efficiency of epidemiological \nresearch. Furthermore, ChatGPT supports researchers \nin locating essential information, developing hypotheses, \nand analysing data [24]. In healthcare education, Chat -\nGPT serves as a preparatory tool for medical examina -\ntions, where it correctly answers most multiple-choice \nquestions, suggesting its potential utility in evaluating \nmedical knowledge [17]. Specialized applications, such as \naiding in surgical planning, image recognition, diagnosis, \nand patient care in neurosurgery [3, 33] and supporting \ndentistry practices [32], further highlight its transforma -\ntive potential. However, it is important to note that \nTable 1 Risk of Bias analysis of included systematic reviews using AMSTAR‑2 [28]\nThe AMSTAR-2 guideline assesses 16 criteria, including: (i) research questions and inclusion criteria based on the PICO framework; (ii) a pre-defined methodological \nprotocol; (iii) the rationale for including specific study designs; (iv) a comprehensive literature search strategy; (v) duplication in study selection; (vi) duplication in data \nextraction; (vii) justification for excluded studies; (viii) a detailed description of included studies; (ix) risk of bias assessment; (x) funding source reporting for included \nstudies; (xi) use of appropriate meta-analysis statistical methods; (xii) assessment of risk of bias impact on results; (xiii) consideration of risk of bias in outcomes \ninterpretation; (xiv) a satisfactory explanation on observed heterogeneity; (xv) an adequate investigation of publication bias; and (xvi) reporting of potential sources \nof conflict of interest\nPage 6 of 19Iqbal et al. Journal of Biomedical Science           (2025) 32:45 \nTable 2 Summary of methodologies of included systematic reviews and systematic reviews with meta‑analysis (n = 17)\nAuthor, year Country \n(corresponding \nauthor’s \naffiliation)\nSearch Strategy \n(databases, \nsearch terms and \ntimeline)\nRoB* assessment \nperformed (Y/N)\nNumber and \ntype of studies \nincluded\nMeta-\nanalysis \nperformed \n(Y/N)\nVersion of \nChatGPT studied\nUtilization \nof ChatGPT \n(in writeup/ \nconducting \nsystematic \nsearch)\nAcknowledgement \nof ChatGPT by \nauthors\nFunding \ninformation\n[10] Lucknow, India Embase, Scopus, \nPubMed, Google \nScholar\nSearch term: \nChatGPT\nData till 24th\nMay 2023\nNo 118 articles\n(original articles,\nreviews, edito‑\nrial/ commentar‑\nies, and letter \nto the editor)\nNo Not mentioned ChatGPT was used \nfor analysis \nof records \nand manuscript \nwriting\nChatPDF was used \nto generate\nYes Authors declare \nno financial support\n[27] Leipzing, Germany PubMed search\nMESH terms were \ndeveloped by Chat‑\nGPT and refined \nby human authors\nJanuary, 2020 \nonwards (NLP \ninstead of ChatGPT \nonly)\nNo 5 (main concern \nwas to evaluate \nthe effectiveness \nand reliability \nof ChatGPT \nin conduct‑\ning review \ncompared \nwith human \nauthors)\nNo 3.5 (Legacy) \nand 4.0\nAll tasks of sys‑\ntematic review \naugmented \nby ChatGPT\nYes No information \nin the article\n[25] Amman, Jordan PubMed/MED‑\nLINE and Google \nScholar Search term: \nChatGPT\nYear: 2022–2023\nNo 60 (article, \nreview, commu‑\nnication, edito‑\nrial, opinion)\nNo Not mentioned No No Authors declare \nno financial support\n[18] Essen, Germany Pubmed\nSearch term: \nChatGPT\nTill March, 2023\nNo 58 (all types \nbut the writeup \ndone for origi‑\nnal articles \nand opinion/\neditorial pieces \nseparately)\nNo Version released \nin Nov., 2022\nNo No Medical Fac‑\nulty of German \nRheinisch‑West‑\nfälische Technische \nHochschule Aachen \nUniversity as part \nof the Clinician \nScientist\nProgram\nPage 7 of 19\nIqbal et al. Journal of Biomedical Science           (2025) 32:45 \n \nTable 2 (continued)\nAuthor, year Country \n(corresponding \nauthor’s \naffiliation)\nSearch Strategy \n(databases, \nsearch terms and \ntimeline)\nRoB* assessment \nperformed (Y/N)\nNumber and \ntype of studies \nincluded\nMeta-\nanalysis \nperformed \n(Y/N)\nVersion of \nChatGPT studied\nUtilization \nof ChatGPT \n(in writeup/ \nconducting \nsystematic \nsearch)\nAcknowledgement \nof ChatGPT by \nauthors\nFunding \ninformation\n[36] Basra, Iraq Taylor\nand Francis, Google \nScholar, Scopus, \nWeb of Science, \nElsevier, Springer, \nMDPI, IEEE Xplore \ndigital and Wiley\nKeywords:\nChatGPT with vari‑\nous keywords \nfor healthcare \nand medicine \nbetween November \n2022 and August \n2023\nNo 82 (All types) No (although \nthe title sug‑\ngests so)\nNot mentioned No No Funding by The \nDeanship of Scien‑\ntific Research at King \nKhalid University, \nKSA\n[31] Dublin, Ireland PubMed, EMBASE \nand Web of Science\nKeyword \nnot described\nSearch till 18 June \n2023\nNo 6 (prospective) No version 3.0 to 4.0 No No Authors declare \nthat open access \nfunding provided \nby IReL\n[2] Rajnandgaon, \nIndia\nPubMed, Google \nScholar, Scopus, \nEMBASE, Cochrane\nLibrary, and UpTo‑\nDate\nKey terms:\nChatGPT and Medi‑\ncal Informatics \nwhich were \ncombined using \nBoolean operators \n“AND” and “OR” \nwith “dental” , “spe‑\ncialty” , “accuracy” , \n“query” , “response” \nand “meta‑\nanalysis” . Articles \npublished in 2023 \nonly\nYes 11 descriptive \nstudies\nYes 3.5 No No No information \nin the article\nPage 8 of 19Iqbal et al. Journal of Biomedical Science           (2025) 32:45 \nTable 2 (continued)\nAuthor, year Country \n(corresponding \nauthor’s \naffiliation)\nSearch Strategy \n(databases, \nsearch terms and \ntimeline)\nRoB* assessment \nperformed (Y/N)\nNumber and \ntype of studies \nincluded\nMeta-\nanalysis \nperformed \n(Y/N)\nVersion of \nChatGPT studied\nUtilization \nof ChatGPT \n(in writeup/ \nconducting \nsystematic \nsearch)\nAcknowledgement \nof ChatGPT by \nauthors\nFunding \ninformation\n[3] Zenica, Bosnia \nand Herzegovina\nPubmed, Embase, \nScopus\nKeywords:(ChatGPT \nOR OpenAI) \nAND (neurosurgery \nOR\nspinal surgery) till\n12th of August, \n2023\nNo 13 (all types) No Not mentioned No No Authors declare \nno financial support\n[17] Quebec, Canada PubMed, Scopus \nand Web of Science\nKeyterm: ChatGPT \ntill\n2nd June 2023\nNo 19 peer‑\nreviewed articles\nyes 3.5 No No Authors declare \nno financial support\n[20] Sarajevo, Bosnia \nand Herzegovina\nGoogle Scholar \nand PubMed\nKeyword: “ChatGPT \napplications \nin medicine”\nTill April 15, 2023\nNo 31‑ any type \nof published\nscientific \nresearch or pre‑\nprints\nNo Not mentioned Yes (Paraphrasing \nand writeup)\nYes No information \nin the article\n[15] Tel Aviv,\nIsrael\nPubmed\nKey words: MESH \nterms related \nto ‘ChatGPT’ , \nand ‘Gastroenterol‑\nogy’\nYes 6 No Heterogenous No No Authors declare \nno financial support\n[32] Rosemont, USA Pubmed, Embase, \nOvid, Global Health, \nPsycINFO, Web \nof Science\nUsing search \nphrases related \nto chatGPT \nand public health \ndentistry Between: \nMarch 31, 2018, \nand March 31, 2023\nNo 39 No Not mentioned No No Authors declare \nno financial support\nPage 9 of 19\nIqbal et al. Journal of Biomedical Science           (2025) 32:45 \n \nTable 2 (continued)\nAuthor, year Country \n(corresponding \nauthor’s \naffiliation)\nSearch Strategy \n(databases, \nsearch terms and \ntimeline)\nRoB* assessment \nperformed (Y/N)\nNumber and \ntype of studies \nincluded\nMeta-\nanalysis \nperformed \n(Y/N)\nVersion of \nChatGPT studied\nUtilization \nof ChatGPT \n(in writeup/ \nconducting \nsystematic \nsearch)\nAcknowledgement \nof ChatGPT by \nauthors\nFunding \ninformation\n[22] Abu Dhabi, UAE PubMed, Google \nScholar, and Embase\nMESH terms \nfor \"neurosurgery\" \nAND \"ChatGPT\"\nTill June 30, 2023\nNo 22 ‑All types \n(peer reviewed \nand gray litera‑\nture search)\nNo Not specified No No Authors declare \nno financial support\n[4] Cleveland, Ohio, \nUSA\nMEDLINE, EMBASE\nusing the search \nterms: ChatGPT, \nimaging, radiology, \nLLM, large language \nmodels, BARD \nfrom November \n2022 to August 15, \n2023,\nYes 51 (23 original \nresearch articles \nand 28 non‑\noriginal research \narticles)\nNo ChatGPT version 3, \n3.5 and 4\nNo No Authors declare \nno financial support\n[5] Bucharest, Roma‑\nnia\nProQuest, Scopus, \nand the Web of Sci‑\nence with search \nterms includ‑\ning \"generative arti‑\nficial intelligence‑\nbased diagnostic \nalgorithms,\" \"disease \nrisk detection,\" \n\"personalized \nand targeted health‑\ncare procedures,\" \nand \"patient care \nsafety and quality.\" \nthroughout April \n2023\nYes 32 (28 original \nresearch articles \nand 4 review \narticles)\nNo Not specified No No The paper is an out‑\nput of the project \nNFP313010BWN6 \n“The implementa‑\ntion\nframework \nand business model \nof the Internet \nof Things, Industry \n4.0 and smart trans‑\nport.” The funder \nhad no role in study \ndesign, data collec‑\ntion analysis, and\ninterpretation, \ndecision to submit \nthe manuscript \nfor publication, \nor the preparation \nand writing of this \npaper\nPage 10 of 19Iqbal et al. Journal of Biomedical Science           (2025) 32:45 \nTable 2 (continued)\nAuthor, year Country \n(corresponding \nauthor’s \naffiliation)\nSearch Strategy \n(databases, \nsearch terms and \ntimeline)\nRoB* assessment \nperformed (Y/N)\nNumber and \ntype of studies \nincluded\nMeta-\nanalysis \nperformed \n(Y/N)\nVersion of \nChatGPT studied\nUtilization \nof ChatGPT \n(in writeup/ \nconducting \nsystematic \nsearch)\nAcknowledgement \nof ChatGPT by \nauthors\nFunding \ninformation\n[35] Singapore PubMed, Europe \nPMC, Scopus, \nand Web of Science\nkeywords related \nto ChatGPT \nand LLMs (“large \nlanguage model” , \n“natural language \nprocessing” , \n“generative artificial \nintelligence” , \n“ChatGPT” , “chatbot” , \n“GPT‑3.5” , “GPT‑\n4.0”) with those \nspecific to the field \nof ophthalmology \n(“ophthalmol‑\nogy” , “ophthalmic” , \n“ophthalmologist” , \n“ophthalmological” , \n“ocular” , “optical” , \n“eye” , “retina” , “vision \nscience” , “vision \nresearch”). pub‑\nlished between 1 \nJanuary 2022 and 31 \nJuly 2023\nNo 32 (24 original \nresearch articles \nand 8 commen‑\ntaries)\nNo ChatGPT 3.5 & 4.0 No No National Medical \nResearch Council of\nSingapore\nPage 11 of 19\nIqbal et al. Journal of Biomedical Science           (2025) 32:45 \n \nTable 2 (continued)\nAuthor, year Country \n(corresponding \nauthor’s \naffiliation)\nSearch Strategy \n(databases, \nsearch terms and \ntimeline)\nRoB* assessment \nperformed (Y/N)\nNumber and \ntype of studies \nincluded\nMeta-\nanalysis \nperformed \n(Y/N)\nVersion of \nChatGPT studied\nUtilization \nof ChatGPT \n(in writeup/ \nconducting \nsystematic \nsearch)\nAcknowledgement \nof ChatGPT by \nauthors\nFunding \ninformation\n[24] Cleveland, USA Google Scholar, \nWeb of Science, \nPubMed, and Med‑\nline\nusing search \nterms “ChatGPT” \nAND “Chatbot” \nAND “Medical \nResearch”\nsearched on January \n21, 2023, at 9:26 PM \nEST to identify\narticles published \nbetween 2022 \nand 2023\nNo 6 (2 literature \nreview articles, \n1 case study, \n1 editorial, 1 \nperspective, 1 \nnot specific)\nNo Not specified No No No information \nin the article\n* RoB = Risk of Bias\nPage 12 of 19Iqbal et al. Journal of Biomedical Science           (2025) 32:45 \nTable 3 Objectives and key findings of the included systematic reviews and systematic reviews with meta‑analysis (n = 17)\nAuthor, Year Field of study Objectives related to \nChatGPT\nPros of using ChatGPT Cons/ Challenges of using \nChatGPT\nFuture directions \nsuggested by author \n(evidence gap)\nFindings of Meta—Analysis\n[10] Patient care and medical \nresearch\nTo explore the capacity \nof ChatGPT in enhancing \npatient care and its contribu‑\ntion to medical research \nand medical writing\nChatGPT can help with han‑\ndling patient inquiries, \ndocumenting notes, making \ndecisions, enrolling in trials, \nmanaging data, providing \ndecision support, assisting \nwith research, and educat‑\ning patients\nThe provided solutions often \nfall short and present con‑\nflicting information, leading \nto concerns about their \noriginality, privacy, accuracy, \nbias, and legality. Content \ngenerated by ChatGPT \nraises issues related to bias \nand potential plagiarism\nLongitudinal studies \non the role of ChatGPT \nin healthcare and medical \neducation and research \nas well as comparison \nof ChatGPT with other AI \ntools\nN/A\n[27] Support of ChatGPT \nin conducting a medical \nsystematic review\nTo evaluate human \nresearchers’ performance \nversus ChatGPT in systematic \nreview tasks (inter‑ and int‑\nrarater reliability, sensitivity, \nspecificity, accuracy, preci‑\nsion, chance hit rate)\nA substantial level of agree‑\nment between ChatGPT \nand human researchers \nin extracting informa‑\ntion for systematic review \nexcept for reporting study \ndesign, clinical task, and clin‑\nical implementation\nThe limitations of ChatGPT \nrender augmented sys‑\ntematic reviews inefficient \nfor experienced researchers. \nEthical implications of using \nChatGPT in medical scien‑\ntific writing\nRange of application \nof ChatGPT and other \ntransformer based models \nin healthcare should be \nincreased\nN/A\n[25] Healthcare education, prac‑\ntice and research\nTo explore the effec‑\ntiveness of ChatGPT \nin healthcare Education, \nresearch, and practice, \nwhile also emphasizing its \npotential drawbacks\nResearch: Review and writ‑\ning, data analysis, code \ngeneration, saving Time \nfor tasks requiring human \nintelligence\nPractice: drug discovery \nand development, workflow \noptimization, cost reduction, \ndocumentation, person‑\nalized medicine, health \nliteracy\nEducation: personalized \nlearning, critical thinking \nand problem‑based learning\nEthical concerns, copyright \nissues, transparency chal‑\nlenges, and legal consid‑\nerations, along with the \npotential for bias, Plagiarism, \nlack of originality, inaccurate \ncontent leading to halluci‑\nnation, limited knowledge, \nincorrect citations, cyberse‑\ncurity risks, and the threat \nof infodemics\nPotential areas to be \nexplored include the appli‑\ncation of AI in reviewing \nand editing tasks (for \njournals) and incorpora‑\ntion of Emotional support \nin patient care involving \nthe use of ChatGPT. Role \nof ChatGPT in refining com‑\nmunication skills is also an \narea of importance\nN/A\n[18] Treatment decisions (for \nprofessionals and public)\nTo explore the usage and pit‑\nfalls of ChatGPT in healthcare\nThe question‑and‑answer \n(QA) design of ChatGPT’s \ninterface facilitates integra‑\ntion into the current clinical \nworkflow\nUnsuitable for direct \nclinical deployment as it \nis not designed for clinical \napplications\nFuture development \nof ‘ChatGPT medical profes‑\nsional version’ , specific \naccording to medical \nspecialities\nN/A\nPage 13 of 19\nIqbal et al. Journal of Biomedical Science           (2025) 32:45 \n \nTable 3 (continued)\nAuthor, Year Field of study Objectives related to \nChatGPT\nPros of using ChatGPT Cons/ Challenges of using \nChatGPT\nFuture directions \nsuggested by author \n(evidence gap)\nFindings of Meta—Analysis\n[36] Healthcare practice To investigate the various \napplications, potential \nbenefits and risks, ethical \nissues of ChatGPT in health‑\ncare and recommendations \nfor its adoption in medicine \nand cellular imaging\n1. Disseminates critical infor‑\nmation about pandemics \nand infectious diseases\n2. virtual assistant \nfor orthognathic surgery \nconsultations\n3. addresses inquiries related \nto dental practice\n4. simplifies complex medi‑\ncal concepts\n5. differential diagnoses \nbased on patient history\n6. analysis of\nmedical images and cellular \nimaging\n7. expedited research \nprocesses through quick \nliterature review\n1.Inability to understand \nspecialized medical termi‑\nnology\n2. Can augment \nbut not replace human \njudgment in clinical settings\n3. In case of inaccurate \nclinical advice, account‑\nability (legal and ethical \nregulatory frameworks) have \nnot yet been devised\n4. Balancing automation \nwith the human touch\nWork should be done \nfor dynamic and real \ntime learning of ChatGPT \nfor obtaining updated \ninformation in medicine \nand health care\nN/A\n[31] Radiology Evaluating the current appli‑\ncations and future\ndirections of ChatGPT \nin the field of radiology\nDemonstrates substantial \npotential to augment \ndecision‑making and opti‑\nmizing workflow\nConcerns regarding radio‑\nlogic image processing, ethi‑\ncal and legal implications, \npotential self‑diagnosis \nand self‑management \nby patients\nThe image processing \npotential of ChatGPT 4.0 \nneeds to be validated \nfurther\nN/A\n[2] Medical and dental research To evaluate the reliability \nand accuracy of ChatGPT \nin medical and dental \nresearch\nMeta‑analysis shows \nthat the accuracy of\nChatGPT in providing cor‑\nrect responses was sig‑\nnificantly higher compared \nto the total responses \nto queries related to medi‑\ncal examination, systematic \nreviews, clinical reasoning, \ndiagnostic imaging, liver \ndiseases, and COVID‑19\nvaccination\nTransparency, ethical \nconcern, erroneous content, \nvariation in population, data \nreproducibility\nThe studies on ChatGPT \nhave small data points \ntested (small sample \nsize) which poses threat \nto extrapolation of findings. \nTherefore, larger datasets \n(including concepts, queries, \nprompts etc.) should be \ntested using ChatGPT \nto improve the generaliz‑\nability of the study results\nThe meta‑analysis showed \nan odds ratio (OR) of 2.25 \nand a relative risk (RR) of 1.47\nwith a 95% confidence \ninterval (CI), indicating \nthat the accuracy of ChatGPT \nin providing correct responses \nwas significantly higher com‑\npared to the total responses \nfor queries\n[3] Neurosurgery To examine the potential \nbenefits and limitations \nof ChatGPT in neurosurgical \npractice and education\nPersonalized treatment \nplans, supporting surgical \nplanning and navigation, \nand enhancing large data \nprocessing efficiency \nand accuracy\nQuestion format limita‑\ntions, validation challenges, \nand algorithmic bias \nalong with ethical issues \nrelated to its usage\nIncorporating longitudinal \npatient data into predic‑\ntive models can enhance \noutcome prediction\nN/A\nPage 14 of 19Iqbal et al. Journal of Biomedical Science           (2025) 32:45 \nTable 3 (continued)\nAuthor, Year Field of study Objectives related to \nChatGPT\nPros of using ChatGPT Cons/ Challenges of using \nChatGPT\nFuture directions \nsuggested by author \n(evidence gap)\nFindings of Meta—Analysis\n[17] Medical examinations To assess the performance \nin medical examinations \nwith\nmultiple‑choice questions\nChatGPT correctly answered \nthe majority of multiple‑\nchoice questions in medical \nexaminations with a passing \ngrade\nPreparations for medical \nexaminations using ChatGPT \nshould be done with cau‑\ntion\nDevelopment of training \ndata set specific for medical \neducation\nExploring the role of Future \nAI chatbots in medical \nexamination preparation\nOverall performance \nof ChatGPT ranged from 40% \nin the biomedical admission \ntest to 100% in a diabetes \nknowledge questionnaire. \nThe mean performance \nof ChatGPT was 61.1% (95% CI \n56.1%–66.0%\n[20] Medicine and healthcare To explore the\npotential of ChatGPT \nin medicine\nStreamline and simplify\ncomplex tasks, improve \npatient care, enhance clini‑\ncal decision making,\nand facilitate communica‑\ntion among healthcare \nprofessionals\nPrivacy, ethical considera‑\ntions, tokenization, sensitiv‑\nity of wording of prompt, \nlack of capacity to handle \nimage based questions\nInvolvement of medical \npractitioners in training \nChatGPT\nN/A\n[15] Gastroenterology To assess the applications, \nbenefits and limitations \nof ChatGPT in the field \nof gastroenterology\nIt can provide recommenda‑\ntions, enhance communi‑\ncation between patients \nand caregivers, and prompt \nvaluable research inquiries\nObstacles in decoding \nintricate medical questions, \nyielded\ninconsistent responses \nat times, and exhibited limi‑\ntations in generating novel \ncontent\nThe model of ChatGPT used \nin research influences its \noutcomes, so a comparable \nversion should be used\nResearch on prompt selec‑\ntion for ChatGPT is lacking \nwhich can drastically change \nthe outcome/ response\nN/A\n[32] Public health dentistry To find out applications \nand drawbacks of Chat‑\nGPT in public dental \nhealth schooling, writing \nfor academic use, research \nand clinical practice in public \ndental health\nHelps scholars \nwith the authoring of scien‑\ntific research and\ndental studies\nScientists can focus and allo‑\ncate more time on experi‑\nmentation by delegating \nsome tasks to ChatGPT\nPrejudice in the training \ndata, undervaluing human \nskills, possible fraud, legal \nand reproducibility concerns\nInclusion of more homog‑\nenous studies in terms \nof quality in order \nto improve the generaliz‑\nability of systematic review \nfindings\nN/A\n[22] Neurosurgery To explore the potential \nbenefits and limitations \nof ChatGPT in the field \nof neurosurgery\nAccuracy and efficiency \nof neurosurgical procedures, \nas well as diagnosis, treat‑\nment, and patient outcomes\n1. Need for large datasets\n2. Potential for errors \nin the output\nTo provide extensive \ndatabase necessary to train \nChatGPT without breaching \npatient confidentiality\nN/A\n[4] Radiology To conduct a qualitative \nand quantitative analysis \nof ChatGPT literature in radi‑\nology, assessing its scope \nand impact\nEnhances patient educa‑\ntion, protocol selection, \nand differential diagnosis \ngeneration\nImproves radiology report \nstructuring and examination \npreparation\n1. Inconsistency in perfor‑\nmance and information \naccuracy\n2. Challenges in fully \nintegrating AI into clinical \nradiology workflows\nResearch on factually incor‑\nrect information/ hallucina‑\ntions generated from Chat‑\nGPT is needed\nN/A\nPage 15 of 19\nIqbal et al. Journal of Biomedical Science           (2025) 32:45 \n \nTable 3 (continued)\nAuthor, Year Field of study Objectives related to \nChatGPT\nPros of using ChatGPT Cons/ Challenges of using \nChatGPT\nFuture directions \nsuggested by author \n(evidence gap)\nFindings of Meta—Analysis\n[5] Disease risk detection, \npersonalized healthcare \nprocedures, and enhanc‑\ning patient care safety \nand quality\nTo explore the efficacy \nof ChatGPT and generative \nAI tools in medical diagnos‑\ntics, treatment recommen‑\ndations, and improving \nhealthcare practices\n1. Enhances diagnostic accu‑\nracy and surgical planning\n2. Reduces administrative \ntasks, improving physician \nefficiency\n3. Supports evidence‑based \ndecision‑making and clinical \neducation\n1. Potential inaccuracies \nin clinical letter generation\n2. Requires regulation \nand careful integration \ninto clinical workflows\n3. Risk of misinterpreting \ntreatment guidelines affect‑\ning patient care\nPredictive analytics \nto observe how well can \nChatGPT assess the real‑time \ndata streams\nN/A\n[35] Ophthalmology To evaluate the effectiveness \nand potential of ChatGPT \nin improving ophthalmologi‑\ncal care, specifically in diag‑\nnosis, patient interaction, \nand educational roles\n1. Offers rapid, accessible \ninformation and support \nfor clinical decisions\n2. Enhances patient educa‑\ntion through simplified \nexplanations of conditions \nand treatments\n1. Potential inaccuracies \nin medical advice or diag‑\nnostic information\n2. Ethical concerns \naround patient data privacy \nand the reliability of AI‑\ngenerated advice\nExplore the effectiveness \nof ChatGPT in a diverse \nlinguistic landscape\nN/A\n[24] Medical research To evaluate ChatGPT’s \napplication and effective‑\nness in medical research, \nincluding treatment, diag‑\nnosis, medication provision, \nand more\nOffers potential ben‑\nefits in drug development, \nmedical report improve‑\nment, providing treatment \nand medical information, \nliterature review writing, \nresearch conduction, data \nanalysis, and personalized \nmedicine\nConcerns about ChatGPT’s \naccuracy, originality, aca‑\ndemic integrity, and ethical \nissues like privacy and secu‑\nrity in medical research\nOvercome issues pertain‑\ning to academic integrity, \nprivacy, and ethics\nN/A\nPage 16 of 19Iqbal et al. Journal of Biomedical Science           (2025) 32:45 \nChatGPT cannot replace the holistic care provided by a \ndentist, as decision-making in dentistry is multidiscipli -\nnary and involves patient care beyond diagnosis [32].\nAdministrative efficiency is another domain where \nChatGPT shows promise. Its robust linguistic capa -\nbilities make it highly suitable for handling intricate \nadministrative tasks, which can significantly aid in busy \nhealthcare settings. Tasks such as managing medical \nrecords, generating discharge summaries, formatting \nexamination reports and drafting referral letters are \nefficiently managed by AI through initial information \nstructuring and organisation. Subsequent review and \nconfirmation by healthcare professionals facilitate the \nrapid organisation of clinical data, alleviating both time \nand manpower burdens. This contributes to improving \nthe healthcare environment and the quality of patient \ncare [3, 10, 25, 27, 36].\nWhile AI holds the potential to assume numer -\nous responsibilities currently undertaken by human \nphysicians, such as diagnosis and medication prescrip -\ntion, several limitations must be considered. Studies \nhave raised concerns regarding ChatGPT’s potential \nfor bias, plagiarism, lack of originality, and ethical and \nlegal dilemmas [2 , 22, 25]. It frequently produces erro -\nneous or inconsistent content, including inaccurate \ncitations and fabrications, which constrain its reliability \nin clinical and academic contexts [5 , 15]. Furthermore, \nChatGPT has difficulty interpreting specialised medi -\ncal terminology, integrating into clinical workflows \nand addressing complex medical inquiries [4 , 31, 32]. \nThese limitations can lead to a loss of human critical \nthinking and involvement, as excessive reliance on AI \ncould reduce the exercise of essential cognitive skills, \npotentially hindering professional growth and societal \nadvancement [30, 36].\nIn terms of scientific writing, ChatGPT’s linguis -\ntic capabilities can assist authors in generating ideas, \nsummarising text, editing language, and proofreading \nTable 4 Major themes and sub themes derived from systematic reviews for the umbrella review evidence synthesis\n* Article serial number is as per Table 1\nEach circle indicates one study Low quality review \nModerate quality review \nThemes Sub-Theme References (article number) in \nwhich this theme was reported*\nFrequency of articles \nreporting the respective \ntheme\nQuality \nof studies \nassessment\nHealth services (1) Diagnosis and clinical decision mak‑\ning (1a)\n1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, \n15, 16, 17\n16\nTreatment options (1b) 1, 3, 4, 5, 8, 11, 12, 13, 15, 16, 17 11\nReduce burden on health care profes‑\nsionals (1c)\n5, 8, 12, 13, 15 5\nHealth records (1d) 1, 2, 3, 5, 8, 12, 16, 17 8\nPatient education (1e) 3, 4, 5, 7, 8, 10, 13, 14, 15, 16, 17 11\nConsumers/Patients (2) Self‑diagnosis/management of dis‑\nease (2a)\n5, 11, 12, 15 16, 17 6\nResearch (3) Conducting systematic review (3a) 2, 7 2\nResearch ideas generation (3b) 11 1\nCollecting and summarising evidence \n(3c)\n1, 2, 3, 6, 7, 12, 17 7\nReporting of evidence (scientific \nwriting) (3d)\n1 2, 3, 6, 8, 12, 13, 14, 16 9\nHelps researchers’ direct attention \non parts of research requiring intel‑\nlect (3e)\n3, 4, 12, 17 4\nData analysis (3f ) 17 1\nMedical education (4) Conducting Assessments (4a) 6, 9, 11, 14, 16, 5\nLearning (4b) 1, 3, 4, 5, 7, 9, 10 7\nIntegration of AI into curriculum (3c) 12 1\nPage 17 of 19\nIqbal et al. Journal of Biomedical Science           (2025) 32:45 \n \ndocuments. However, it is important to note that under \nthe current International Committee of Medical Jour -\nnal Editors (ICMJE)/Committee on Publication Ethics \n(COPE) guidelines, ChatGPT is not eligible for author -\nship in scientific publications unless these guidelines \nare updated [25]. Moreover, several ethical concerns, \nincluding copyright issues, transparency, and the risk \nof spreading misinformation, have been raised regard -\ning its use in scientific writing [2, 25]. Given these con -\ncerns, it is essential to investigate the research domain \nfrom the viewpoints of editors, reviewers and journals \nto develop appropriate policies. Further research is also \nneeded on educational policy formulation and the inte -\ngration of ChatGPT into teaching methods and curricu -\nlum development [37]. Exploring the intersecting realms \nof research and education offers another avenue for \nexploration.\nWhile acknowledging the potential significance of \nChatGPT in healthcare, the reviewed studies highlight \nseveral challenges. ChatGPT’s integration into healthcare \nsystems requires collaboration between AI developers, \nhealthcare professionals and policymakers to maxim -\nise its transformative impact. Since the effectiveness of \nChatGPT’s outputs depends on the quality and diver -\nsity of its training data [6], it is crucial to ensure that it \nincorporates a broad range of clinical information that \naccurately reflects the target patient population [31]. This \nmay involve developing specialised ChatGPT models tai -\nlored to specific patient groups or healthcare domains to \nensure the relevance and efficacy of its outputs.\nTo ensure responsible deployment, robust validation \nmechanisms, including expert review and clinical test -\ning are necessary to address issues like AI hallucination, \nmisinformation and bias. In addition, clear privacy reg -\nulations and transparent data usage policies are essen -\ntial to protect user data and build trust in AI-generated \nresponses. Establishing ethical frameworks, certification \nstandards, and promoting digital literacy through educa -\ntional initiatives will empower users to understand Chat -\nGPT’s limitations and use it responsibly [13, 38].\nWith patients increasingly gaining access to Chat -\nGPT, concerns may arise regarding self-diagnosis and \nthe potential for cyberchondria [29]. While empowering \npatients with information can enhance autonomy and \nengagement in their healthcare, it also raises concerns \nabout the accuracy and interpretation of medical data. \nSelf-diagnosis based solely on ChatGPT’s outputs could \nlead to misinterpretation or oversight of critical details, \npotentially compromising patient safety. Therefore, it is \ncrucial to establish guidelines and educational resources \nto support patients in using ChatGPT as a supplemen -\ntary tool rather than a substitute for professional medical \nadvice and diagnosis.\nThis umbrella review demonstrates both strengths and \nlimitations of ChatGPT. We conducted it by relying on \nexisting systematic reviews and meta-analyses, ensuring \nmethodological rigour through adherence to PRISMA \nguidelines and the use of the AMSTAR-2 tool for qual -\nity assessment. Our stringent criteria for study inclusion \naimed to analyse high-quality, relevant research, while \nmeticulous search strategies and transparent selection \ncriteria minimised biases. Despite efforts to standard -\nise methodologies and terminologies, integrating and \nreconciling inconsistencies across studies posed chal -\nlenges. While our review provided a comprehensive \noverview, it lacked detailed insights into specific health -\ncare contexts, emphasising the need for further primary \nresearch. Moreover, Generative AI is a dynamic field \nthat undergoes regular updates, making comparisons \nbetween different versions of ChatGPT valuable for \nfuture researchers important. Newer versions generally \ndemonstrate enhanced natural language processing capa-\nbilities, which can significantly benefit healthcare appli -\ncations. However, concerns regarding the reliability of \nnewer versions, such as ChatGPT 4.0, which performed \npoorly in handling simpler queries compared to its pre -\ndecessor, highlight the need for further investigation into \nthese advancements (Additional File 2). Addressing these \nlimitations will enhance the robustness and applicabil -\nity of our findings for evidence-based decision-making \nin healthcare practice. Moreover, longitudinal studies \nare necessary to examine the broader, long-term impact \nof ChatGPT on healthcare systems, patient outcomes, \nworkflow efficiency, and provider-patient dynamics. \nCombining these approaches will ensure a holistic under-\nstanding of ChatGPT’s role in advancing healthcare while \naddressing its limitations.\nConclusions\nThe ChatGPT’s integration into healthcare as a reli -\nable educational, research and clinical augmentation \ntool shows immense promise however, its success relies \non the establishment of robust regulations and control \nmechanisms to ensure ethical deployment.\nChatGPT’s version 3.5 was found to be more reliable in \ncertain circumstances while complex tasks can be han -\ndled well by the ChatGPT version 4.0. Prioritising ethical \nconsiderations is essential to harness AI’s potential while \npreserving trust and integrity in healthcare and research \npractices. Acknowledging and addressing challenges such \nas ethical concerns, bias and the potential for overreli -\nance is crucial.\nThrough collaborative efforts among stakeholders, \nChatGPT can significantly enhance healthcare deliv -\nery, research innovation and patient outcomes, marking \nPage 18 of 19Iqbal et al. Journal of Biomedical Science           (2025) 32:45 \na step forward in ethically responsible use of AI in the \nhealthcare field.\nAbbreviations\nAMSTAR‑2  A MeaSurement Tool to Assess systematic Reviews\nChatGPT  Chat Generative Pre‑trained Transformer\nSR  Systematic reviews\nSRMA  Systematic reviews with meta‑analysis\nICMJE  International Committee of Medical Journal Editors\nCOPE  Committee on Publication Ethics\nPRISMA  Preferred Reporting Items for Systematic Reviews and \nMeta‑Analysis\nSupplementary Information\nThe online version contains supplementary material available at https:// doi. \norg/ 10. 1186/ s12929‑ 025‑ 01131‑z.\nAdditional file 1.\nAdditional file 2.\nAcknowledgements\nDuring the preparation of this work, the authors used ChatGPT for language \nediting. After using this tool, the authors reviewed and edited the content as \nneeded and took full responsibility for the content of the publication.\nAuthor contributions\nUI and YCJL designed the study concepts. AT and ARR were responsible for \nconducting the article search, selection, summarization, and synthesis of the \neligible articles suitable for inclusion. UI, AT, and ARR prepared the first draft \nof the article. UI, LTJL, DG, and YCJL contributed significantly to revising and \nproviding a critical review of the manuscript. All authors read and approved \nthe final version of the manuscript.\nFunding\nNo funding has been obtained for this study.\nAvailability of data and materials\nNot applicable.\nDeclarations\nEthics approval and consent to participate\nNot applicable.\nConsent for publication\nNot applicable.\nCompeting interests\nThe authors declare that they have no competing interests.\nAuthor details\n1 Institute for Evidence‑Based Healthcare, Faculty of Health Sciences & \nMedicine, Bond University, Gold Coast, Australia. 2 Evidence‑Based Practice \nProfessorial Unit, Gold Coast Hospital & Health Service (GCHHS), Gold Coast, \nQLD, Australia. 3 Department of Nutrition & Dietetics, School of Health Sci‑\nences, University of Management and Technology, Lahore, Pakistan. 4 Depart‑\nment of Health Policy and Management, Faculty of Medicine, Public Health \nand Nursing, Universitas Gadjah Mada, Yogyakarta, Indonesia. 5 Department \nof Computer Science, Faculty of Science and Technology, Middlesex Univer‑\nsity, London, UK. 6 School of Population Health, Faculty of Medicine and Health, \nUniversity of New South Wales (UNSW), Sydney, Australia. 7 Graduate Institute \nof Clinical Medicine, Taipei Medical University, Taipei, Taiwan. 8 Department \nof Dermatology, Taipei Medical University Hospital, Taipei Medical University, \nTaipei, Taiwan. 9 Department of Dermatology, School of Medicine, College \nof Medicine, Taipei Medical University, Taipei, Taiwan. 10 Graduate Institute \nof Biomedical Informatics, College of Medical Science and Technology, Taipei \nMedical University, Taipei, Taiwan. 11 Department of Dermatology, Taipei \nMunicipal Wanfang Hospital, Taipei Medical University, Taipei, Taiwan. 12 Inter‑\nnational Center for Health Information Technology, Taipei Medical University, \nTaipei, Taiwan. \nReceived: 10 August 2024   Accepted: 4 March 2025\nReferences\n 1. Ashraf H, Ashfaq H. The role of ChatGPT in medical research: progress \nand limitations. Ann Biomed Eng. 2023. https:// doi. org/ 10. 1007/ \ns10439‑ 023‑ 03311‑0.\n 2. Bagde H, Dhopte A, Alam MK, Basri R. A systematic review and meta‑\nanalysis on ChatGPT and its utilization in medical and dental research. \nHeliyon. 2023;9(12): e23050. https:// doi. org/ 10. 1016/j. heliy on. 2023. \ne23050.\n 3. Bečulić H, Begagić E, Skomorac R, Mašović A, Selimović E, Pojskić M. \n2024. ChatGPT’s contributions to the evolution of neurosurgical practice \nand education: A systematic review of benefits, concerns and limita‑\ntions. Medicinski Glasnik Ljekarske Komore Zenicko‑Dobojskog Kantona. \nhttps:// doi. org/ 10. 17392/ 1661‑ 23\n 4. Bera K, O’Connor G, Jiang S, Tirumani SH, Ramaiya N. Analysis of ChatGPT \npublications in radiology: literature so far. Curr Probl Diagn Radiol. \n2024;53(2):215–25. https:// doi. org/ 10. 1067/j. cprad iol. 2023. 10. 013.\n 5. Bugaj M, Kliestik T, Lăzăroiu G. Generative artificial intelligence‑based \ndiagnostic algorithms in disease risk detection, in personalized and \ntargeted healthcare procedures, and in patient care safety and quality. \nContemp Read Law Soc Justice. 2023;15(1):9–26.\n 6. Cao Y, Li S, Liu Y, Yan Z, Dai Y, Yu PS, Sun L. 2023. A comprehensive survey \nof AI‑generated content (AIGC): a history of generative AI from GAN to \nChatGPT (arXiv: 2303. 04226). arXiv. http:// arxiv. org/ abs/ 2303. 04226\n 7. Cazzato G, Capuzzolo M, Parente P , Arezzo F, Loizzi V, Macorano E, Mar‑\nzullo A, Cormio G, Ingravallo G. Chat GPT in diagnostic human pathology: \nwill it be useful to pathologists? A preliminary review with ‘query session’ \nand future perspectives. AI. 2023;4(4):1010–22. https:// doi. org/ 10. 3390/ \nai404 0051.\n 8. Choi GJ, Kang H. Introduction to umbrella reviews as a useful evidence‑\nbased practice. J Lipid Atherosclerosis. 2023;12(1):3.\n 9. Gabashvili I. 2023. ChatGPT in dermatology: a comprehensive systematic \nreview. medRxiv, 2023–06.\n 10. Garg RK, Urs VL, Agarwal AA, Chaudhary SK, Paliwal V, Kar SK. Exploring \nthe role of ChatGPT in patient care (diagnosis and treatment) and medi‑\ncal research: a systematic review. Health Promot Perspect. 2023;13(3):183.\n 11. Haddaway NR, Collins AM, Coughlin D, Kirk S. The role of Google Scholar \nin evidence reviews and its applicability to grey literature searching. PLoS \nONE. 2015;10(9): e0138237.\n 12. Harry A. The future of medicine: harnessing the power of AI for revolu‑\ntionizing healthcare. Int J Multidis Sci Arts. 2023;2(1):36–47.\n 13. Hastings J. Preventing harm from non‑conscious bias in medical genera‑\ntive AI. Lancet Digit Health. 2024;6(1):e2–3. https:// doi. org/ 10. 1016/ \nS2589‑ 7500(23) 00246‑ 7[publi shedO nline First: 2023/ 12/ 21].\n 14. Javaid M, Haleem A, Singh RP . ChatGPT for healthcare services: an emerg‑\ning stage for an innovative perspective. BenchCouncil Trans Benchmarks \nStandards Evaluat. 2023;3(1): 100105.\n 15. Klang E, Sourosh A, Nadkarni GN, Sharif K, Lahat A. Evaluating the role \nof ChatGPT in gastroenterology: a comprehensive systematic review \nof applications, benefits, and limitations. Ther Adv Gastroenterol. \n2023;16:17562848231218618. https:// doi. org/ 10. 1177/ 17562 84823 12186 \n18.\n 16. Lee D, Yoon SN. Application of artificial intelligence‑based technologies \nin the healthcare industry: opportunities and challenges. Int J Environ Res \nPublic Health. 2021;18(1):271.\n 17. Levin G, Horesh N, Brezinov Y, Meyer R. Performance of ChatGPT in medi‑\ncal examinations: a systematic review and a meta‑analysis. Int J Obstet \nGynaecol. 2024;131(3):378–80. https:// doi. org/ 10. 1111/ 1471‑ 0528. 17641.\n 18. Li J, Dada A, Puladi B, Kleesiek J, Egger J. ChatGPT in healthcare: a \ntaxonomy and systematic review. Comput Methods Programs Biomed. \n2024;245: 108013. https:// doi. org/ 10. 1016/j. cmpb. 2024. 108013.\nPage 19 of 19\nIqbal et al. Journal of Biomedical Science           (2025) 32:45 \n \n 19. Mitsea E, Drigas A, Skianis C. Digitally assisted mindfulness in training self‑\nregulation skills for sustainable mental health: a systematic review. Behav \nSci. 2023;13(12):1008.\n 20. Muftić F, Kadunić M, Mušinbegović A, Abd Almisreb A. Exploring medical \nbreakthroughs: a systematic review of ChatGPT applications in health‑\ncare. Southeast Eur J Soft Comput. 2023;12(1):13–41.\n 21. Rao A, Kim J, Kamineni M, Pang M, Lie W, Succi MD. Evaluating ChatGPT \nas an adjunct for radiologic decision‑making. medRxiv. 2023;16:2023–02.\n 22. Roman A, Al‑Sharif L, Al Gharyani M. The expanding role of ChatGPT \n(chat‑generative pre‑trained transformer) in neurosurgery: a systematic \nreview of literature and conceptual framework. Cureus. 2023. https:// doi. \norg/ 10. 7759/ cureus. 43502.\n 23. Roumeliotis KI, Tselikas ND. ChatGPT and open‑AI models: a preliminary \nreview. Future Internet. 2023;15(6):192.\n 24. Ruksakulpiwat S, Kumar A, Ajibade A. Using ChatGPT in medical research: \ncurrent status and future directions. J Multidiscip Healthc. 2023;16:1513–\n20. https:// doi. org/ 10. 2147/ JMDH. S4134 70.\n 25. Sallam M. ChatGPT utility in healthcare education, research, and practice: \nsystematic review on the promising perspectives and valid concerns. \nHealthcare. 2023;11(6):887. https:// doi. org/ 10. 3390/ healt hcare 11060 887.\n 26. Sarkis‑Onofre R, Catalá‑López F, Aromataris E, Lockwood C. How to prop‑\nerly use the PRISMA statement. Syst Rev. 2021;10(1):117. https:// doi. org/ \n10. 1186/ s13643‑ 021‑ 01671‑z.\n 27. Schopow N, Osterhoff G, Baur D. Applications of the natural language \nprocessing tool ChatGPT in clinical practice: comparative study and \naugmented systematic review. JMIR Med Inform. 2023;11: e48933.\n 28. Shea BJ, Reeves BC, Wells G, Thuku M, Hamel C, Moran J, Moher D, \nTugwell P , Welch V, Kristjansson E. AMSTAR 2: a critical appraisal tool for \nsystematic reviews that include randomised or non‑randomised studies \nof healthcare interventions, or both. Bmj. 2017. https:// doi. org/ 10. 1136/ \nbmj. j4008.\n 29. Starcevic V, Berle D, Arnáez S. Recent insights into cyberchon‑\ndria. Curr Psychiatry Rep. 2020;22(11):56. https:// doi. org/ 10. 1007/ \ns11920‑ 020‑ 01179‑8.\n 30. Swaminathan A, Rathnasabapathy M. Role of creativity in problem \nsolving–a review. Rev Int Geograph Educ Online. 2021;11(8):2.\n 31. Temperley HC, O’Sullivan NJ, Mac Curtain BM, Corr A, Meaney JF, Kelly \nME, Brennan I. Current applications and future potential of C hat GPT in \nradiology: a systematic review. J Med Imaging Radiat Oncol. 2024;1754–\n9485:13621. https:// doi. org/ 10. 1111/ 1754‑ 9485. 13621.\n 32. Tiwari A, Kumar A, Jain S, Dhull KS, Sajjanar A, Puthenkandathil R, Paiwal K, \nSingh R. Implications of ChatGPT in public health dentistry: a systematic \nreview. Cureus. 2023. https:// doi. org/ 10. 7759/ cureus. 40367.\n 33. Iqbal U, Lee LT, Rahmanti AR, Celi LA, Li YJ. Can large language models \nprovide secondary reliable opinion on treatment options for dermato‑\nlogical diseases? J Am Med Inform Assoc. 2024;31(6):1341–7. https:// doi. \norg/ 10. 1093/ jamia/ ocae0 67. PMID: 38578 616; PMCID: PMC11 105123.\n 34. Wang C, Liu S, Yang H, Guo J, Wu Y, Liu J. Ethical considerations of using \nChatGPT in health care. J Med Int Res. 2023;25: e48009.\n 35. Wong M, Lim ZW, Pushpanathan K, Cheung CY, Wang YX, Chen D, Tham \nYC. Review of emerging trends and projection of future developments \nin large language models research in ophthalmology. Br J Ophthalmol. \n2023. https:// doi. org/ 10. 1136/ bjo‑ 2023‑ 324734.\n 36. Younis HA, Eisa TAE, Nasser M, Sahib TM, Noor AA, Alyasiri OM, Salisu S, \nHayder IM, Younis HA. A systematic review and meta‑analysis of artificial \nintelligence tools in medicine and healthcare: applications, considera‑\ntions, limitations. Motiv Challenges Diagn. 2024;14(1):109. https:// doi. org/ \n10. 3390/ diagn ostic s1401 0109.\n 37. Yu H. The application and challenges of ChatGPT in educational trans‑\nformation: new demands for teachers’ roles. Heliyon. 2024;10(2): e24289. \nhttps:// doi. org/ 10. 1016/j. heliy on. 2024. e24289.\n 38. Zack T, Lehman E, Suzgun M, et al. Assessing the potential of GPT‑4 to \nperpetuate racial and gender biases in health care: a model evaluation \nstudy. Lancet Digit Health. 2024;6(1):e12–22. https:// doi. org/ 10. 1016/ \nS2589‑ 7500(23) 00225‑ X[publi shedO nline First: 2023/ 12/ 21].\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in pub‑\nlished maps and institutional affiliations.",
  "topic": "Systematic review",
  "concepts": [
    {
      "name": "Systematic review",
      "score": 0.7412320971488953
    },
    {
      "name": "Health care",
      "score": 0.6568648815155029
    },
    {
      "name": "Checklist",
      "score": 0.5857735276222229
    },
    {
      "name": "Scopus",
      "score": 0.5214430689811707
    },
    {
      "name": "Cochrane Library",
      "score": 0.5050902962684631
    },
    {
      "name": "Medical education",
      "score": 0.48043394088745117
    },
    {
      "name": "MEDLINE",
      "score": 0.46690303087234497
    },
    {
      "name": "Medicine",
      "score": 0.46606189012527466
    },
    {
      "name": "Alternative medicine",
      "score": 0.37490469217300415
    },
    {
      "name": "Psychology",
      "score": 0.36565861105918884
    },
    {
      "name": "Family medicine",
      "score": 0.34157437086105347
    },
    {
      "name": "Pathology",
      "score": 0.21107786893844604
    },
    {
      "name": "Political science",
      "score": 0.1477643847465515
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Cognitive psychology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I120125038",
      "name": "Bond University",
      "country": "AU"
    },
    {
      "id": "https://openalex.org/I2800155786",
      "name": "Gold Coast Hospital",
      "country": "AU"
    },
    {
      "id": "https://openalex.org/I87482320",
      "name": "University of Management and Technology",
      "country": "PK"
    },
    {
      "id": "https://openalex.org/I60488453",
      "name": "Middlesex University",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I165230279",
      "name": "Universitas Gadjah Mada",
      "country": "ID"
    },
    {
      "id": "https://openalex.org/I31746571",
      "name": "UNSW Sydney",
      "country": "AU"
    },
    {
      "id": "https://openalex.org/I47519274",
      "name": "Taipei Medical University",
      "country": "TW"
    },
    {
      "id": "https://openalex.org/I2802331550",
      "name": "Taipei Medical University Hospital",
      "country": "TW"
    }
  ]
}