{
  "title": "The application of Large Language Models to the phenotype-based prioritization of causative genes in rare disease patients",
  "url": "https://openalex.org/W4409906005",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A4321044203",
      "name": "Şenay Kafkas",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2903627423",
      "name": "Marwa Abdelhakim",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A4228952421",
      "name": "Azza Althagafi",
      "affiliations": [
        "Taif University",
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2974395003",
      "name": "Sumyyah Toonsi",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2944111709",
      "name": "Malak AlGhamdi",
      "affiliations": [
        "King Saud Medical City",
        "King Saud University"
      ]
    },
    {
      "id": "https://openalex.org/A2101704118",
      "name": "Paul N. Schofield",
      "affiliations": [
        "University of Cambridge"
      ]
    },
    {
      "id": "https://openalex.org/A196825606",
      "name": "Robert Hoehndorf",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A4321044203",
      "name": "Şenay Kafkas",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2903627423",
      "name": "Marwa Abdelhakim",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4228952421",
      "name": "Azza Althagafi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2974395003",
      "name": "Sumyyah Toonsi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2944111709",
      "name": "Malak AlGhamdi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2101704118",
      "name": "Paul N. Schofield",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A196825606",
      "name": "Robert Hoehndorf",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2973267506",
    "https://openalex.org/W4382631903",
    "https://openalex.org/W4318542795",
    "https://openalex.org/W3180381598",
    "https://openalex.org/W4225139333",
    "https://openalex.org/W4206627019",
    "https://openalex.org/W3106811464",
    "https://openalex.org/W3092613928",
    "https://openalex.org/W2605099106",
    "https://openalex.org/W2588397446",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W3138406745",
    "https://openalex.org/W2990435446",
    "https://openalex.org/W2901527454",
    "https://openalex.org/W3043427624",
    "https://openalex.org/W2246559112",
    "https://openalex.org/W2104622981",
    "https://openalex.org/W2127006085",
    "https://openalex.org/W2059313072",
    "https://openalex.org/W4379468930",
    "https://openalex.org/W4367626167",
    "https://openalex.org/W4365460657",
    "https://openalex.org/W2049185824",
    "https://openalex.org/W1919257374",
    "https://openalex.org/W3032034316",
    "https://openalex.org/W2096791516",
    "https://openalex.org/W2951101345",
    "https://openalex.org/W2103017472",
    "https://openalex.org/W4220684441",
    "https://openalex.org/W2319307509",
    "https://openalex.org/W4220711281",
    "https://openalex.org/W3213759078",
    "https://openalex.org/W1994645009",
    "https://openalex.org/W1997720284",
    "https://openalex.org/W4220749237",
    "https://openalex.org/W4380993239",
    "https://openalex.org/W4385848430",
    "https://openalex.org/W4307180312"
  ],
  "abstract": "Abstract Computational methods for identifying gene–disease associations can use both genomic and phenotypic information to prioritize genes and variants that may be associated with genetic diseases. Phenotype-based methods commonly rely on comparing phenotypes observed in a patient with databases of genotype-to-phenotype associations using measures of semantic similarity. They are constrained by the quality and completeness of these resources as well as the quality and completeness of patient phenotype annotation. Genotype-to-phenotype associations used by these methods are largely derived from the literature and coded using phenotype ontologies. Large Language Models (LLMs) have been trained on large amounts of text and data and have shown their potential to answer complex questions across multiple domains. Here, we evaluate the effectiveness of LLMs in prioritizing disease-associated genes compared to existing bioinformatics methods. We show that LLMs can prioritize disease-associated genes as well, or better than, dedicated bioinformatics methods relying on pre-defined phenotype similarity, when gene sets range from 5 to 100 candidates. We apply our approach to a cohort of undiagnosed patients with rare diseases and show that LLMs can be used to provide diagnostic support that helps in identifying plausible candidate genes. Our results show that LLMs may offer an alternative to traditional bioinformatics methods to prioritize disease-associated genes based on disease phenotypes. They may, therefore, potentially enhance diagnostic accuracy and simplify the process for rare genetic diseases.",
  "full_text": "The application of Large Language \nModels to the phenotype-based \nprioritization of causative genes in \nrare disease patients\nŞenay Kafkas1,2, Marwa Abdelhakim1,3, Azza Althagafi1,4, Sumyyah Toonsi1,2,3,5, \nMalak Alghamdi6, Paul N. Schofield7 & Robert Hoehndorf1,2,3,5\nComputational methods for identifying gene–disease associations can use both genomic and \nphenotypic information to prioritize genes and variants that may be associated with genetic \ndiseases. Phenotype-based methods commonly rely on comparing phenotypes observed in a patient \nwith databases of genotype-to-phenotype associations using measures of semantic similarity. \nThey are constrained by the quality and completeness of these resources as well as the quality \nand completeness of patient phenotype annotation. Genotype-to-phenotype associations used by \nthese methods are largely derived from the literature and coded using phenotype ontologies. Large \nLanguage Models (LLMs) have been trained on large amounts of text and data and have shown their \npotential to answer complex questions across multiple domains. Here, we evaluate the effectiveness of \nLLMs in prioritizing disease-associated genes compared to existing bioinformatics methods. We show \nthat LLMs can prioritize disease-associated genes as well, or better than, dedicated bioinformatics \nmethods relying on pre-defined phenotype similarity, when gene sets range from 5 to 100 candidates. \nWe apply our approach to a cohort of undiagnosed patients with rare diseases and show that LLMs can \nbe used to provide diagnostic support that helps in identifying plausible candidate genes. Our results \nshow that LLMs may offer an alternative to traditional bioinformatics methods to prioritize disease-\nassociated genes based on disease phenotypes. They may, therefore, potentially enhance diagnostic \naccuracy and simplify the process for rare genetic diseases.\nKeywords  Gene prioritization, Rare diseases, Diagnosis support, Phenotypes, Large language models\nAlthough rare diseases individually affect a small number of people in the population, together they present a \nsignificant burden on global public health, affecting millions worldwide1. The diagnosis of rare diseases presents \nunique challenges due to their low prevalence and diverse clinical presentation in patients with the same \nunderlying genetic lesions. Consequently, patients often endure a diagnostic odyssey, involving numerous tests \nand investigations over many years, before receiving a definitive diagnosis.\nMost rare diseases have a genetic basis, typically involving variation in one or a few genes2. Next-generation \nsequencing (NGS) has revolutionized the diagnostic process for these diseases by enabling identification of \ngenetic variants in individuals which are associated with the disorder. However, despite the advances in NGS \napproaches, achieving a molecular diagnosis remains elusive for about half of all patients3.\nSeveral methods are commonly employed to reduce the number of candidate variants to consider, including \nthe mode of inheritance, the frequency of observing the variant within different populations, and the impact \n1Computer, Electrical and Mathematical Sciences & Engineering Division, King Abdullah University of Science \nand Technology, 23955 Thuwal, Saudi Arabia. 2SDAIA-KAUST Center of Excellence in Data Science and Artificial \nIntelligence, King Abdullah University of Science and Technology, 23955 Thuwal, Saudi Arabia. 3KAUST Center of \nExcellence for Smart Health (KCSH), King Abdullah University of Science and Technology, 23955 Thuwal, Saudi \nArabia. 4Computer Science Department, College of Computers and Information Technology, Taif University, \n26571 Taif, Saudi Arabia. 5KAUST Center of Excellence for Generative AI, King Abdullah University of Science \nand Technology, 23955 Thuwal, Saudi Arabia. 6Medical Genetic Division, Department of Pediatrics, College \nof Medicine, King Saud University, 11461 Riyadh, Saudi Arabia. 7Department of Physiology, Development \n& Neuroscience, University of Cambridge, Cambridge CB2 3EG, UK. email: senay.kafkas@kaust.edu.sa;  \nrobert.hoehndorf@kaust.edu.sa\nOPEN\nScientific Reports |        (2025) 15:15093 1| https://doi.org/10.1038/s41598-025-99539-y\nwww.nature.com/scientificreports\n\na variant has on the molecular function of a gene product. However, even after these filters have been applied, \nthere are still often tens to hundreds of candidate variants left in that individual’s genotype that need to be \nconsidered and evaluated4. Diverse strategies have been developed for prediction of variant pathogenicity. These \nmethods include rule-based methods and machine learning algorithms 5. However, accurately determining the \ncausative variant in an individual, amidst the complexity of genetic data and phenotypic variability, remains a \nformidable task.\nPhenotype-based methods for prioritizing genes or genotypes typically compare the phenotypes observed \nin a patient with the phenotypes in a genotype-to-phenotype database 6 and rank genes or genotypes based on \nwhether they are likely to cause the phenotypes observed in a patient. These methods rely on resources such \nas the Human Phenotype Ontology (HPO) 7 and semantic similarity measures to assess the relevance of the \nobserved phenotypes8. Although phenotype ontologies are manually curated and make excellent use of domain \nexpertise, they are unavoidably incomplete and the structure reflects human decisions with consequences for the \napplication of formal semantics9; genotype-to-phenotype databases are created from the literature or large-scale \nexperiments and may be incomplete or noisy 7; and, although a large number of semantic similarity measures \nhave been developed, they have different biases which make them a challenge to apply consistently10.\nIn recent years, Large Language Models (LLMs) trained on large text corpora have emerged as powerful tools \nfor natural language understanding and generation11. These models can potentially overcome the limitations of \nformal phenotype similarity-based methods by leveraging their vast knowledge and the semantic understanding \nimplicit in their training data. Consequently, they may also be able to estimate semantic similarity as well as, \nor better than, ontology-dependent similarity measures. By incorporating LLMs into diagnostic workflows, we \naim to improve the prioritization of disease–causing variants and enhance the genetic diagnostic yield for rare \ndisease.\nIn our study, we evaluated three LLMs, GPT-3.5-turbo (model gpt-3.5-turbo-1106)12, GPT-4 (model gpt-4-\n1106-preview)13, and Falcon180B14, for ranking genes based on clinically observed phenotypes. We integrated \nthese LLMs into diagnostic pipelines for analysing WE or WG sequencing data.\nWe evaluate LLMs using three synthetic datasets and one dataset of undiagnosed genetic disease patients. \nThrough direct comparison with state-of-the-art methods, we demonstrate LLMs’ ability to enhance phenotype-\nbased gene ranking. Moreover interactions with LLMs can provide explanations for ranking decisions and refine \nresults, potentially serving as valuable diagnostic aids. However, we also observed several cases of “hallucinations” \nand other biases, highlighting the need for further refinement before considering possible application to clinical \ndecision making. Despite these challenges, the potential of LLMs to improve rare disease diagnosis and facilitate \nthe application of precision medicine is promising, provided that their limitations are carefully addressed.\nMaterials and methods\nDatasets used\nWe used three benchmark datasets to conduct our experiments. The first dataset, GPCards  15, is a manually \ncurated dataset of genotype–phenotype associations. We randomly selected 50 variants from distinct genes \nalong with their corresponding clinical phenotypes from GPCards. The phenotypes in GPCards are represented \nas natural language terms and do not rely on a structured vocabulary or ontology. We use the GPCards dataset \nto develop prompts and assess the performance of the LLMs on different prompts.\nThe second dataset is the October 2023 release of ClinVar 16 a publicly accessible database detailing genomic \nvariations and their connections to disease. We focused particularly on the new variants included in ClinVar \nbetween July 2, 2023, and October 7, 2023. From this subset of data, we randomly selected 100 variants, each \nfrom a different gene, associated with diseases in Online Mendelian Inheritance in Man (OMIM)  17, which are \nconsidered either “pathogenic” or “likely-pathogenic” in ClinVar. We identified the phenotypes corresponding \nto OMIM disease using the HPO database   7 accessed on 8 October, 2023. We used time-based ClinVar data, \nincorporating only variants published after the LLM cut-off training date, to evaluate the potential impact of the \ntraining data on LLMs. This approach ensured that the variant-phenotype relationships in the dataset were novel \nand had not been seen by the LLMs or Exomiser during their training phases. ClinVar, however, has certain \nlimitations. Phenotype information is often missing and must be inferred from OMIM identifiers, which, unlike \nGPCards/PAVS18 datasets, do not fully reflect real-world scenarios.\nThe third dataset is the Phenotype-Associated Variants in Saudi Arabia (PAVS) database18, a public database of \ngenotype–phenotype relations identified in Saudi individuals. PAVS combines a collection of clinically validated \npathogenic variants with manually curated variants specific to the Saudi population, each accompanied by its \nassociated phenotypes mapped to HPO codes. We used the PAVS dataset to compare LLMs with ontology-\nbased gene prioritization methods. PAVS provides direct phenotype annotations and broader variant-phenotype \ncoverage, closely corresponding to clinical phenotype observations, unlike phenotypes in OMIM or the HPO \ndatabase which collect consensus phenotypes across multiple cases. This makes PAVS advantageous over ClinVar \nfor this specific task. We randomly selected 500 variants each from a distinct gene along with their associated \nphenotypes from PAVS.\nFor each of the benchmark sets, we generated a set of pairs ( G, P) of a list of genes G =( G1, ..., Gn) and \na set of phenotypes P =( P1, ..., Pm). The phenotypes are identical to the phenotypes from the benchmark \nsets (which contain genotype–phenotype relations); the list of genes G contains the causative gene (i.e., the \ngenotype mapped to the underlying gene) and a set of genes randomly chosen either from all human genes or \nfrom all genes with a genotype in the benchmark set. We vary the size of the gene set G by randomly choosing \ndifferent numbers of genes to add; the cardinality of G ranges from 5 to 100 (cardinalities 5, 25, 50, 75, 100). Our \nselection of 5 to 100 genes for the experiments aligns with findings from previous studies. A notable reduction \nin candidate variants is often observed after filtering variants based on pedigree or Trio data 19. Specifically, \nusing exomes and filtering variants by minor allele frequency (MAF), mode of inheritance, family structure, and \nScientific Reports |        (2025) 15:15093 2| https://doi.org/10.1038/s41598-025-99539-y\nwww.nature.com/scientificreports/\nfunctional impact leaves a range of 1.1 to 68.9 candidate variants to be prioritised in each patient, depending on \nthe mode of inheritance4.\nBaseline methods\nWe evaluated several state-of-the-art methods for phenotype-based gene prioritization, all implemented in \nthe Exomiser (version 12.1.0) 20 system. We use three main methods as baseline: ExomeWalker 21, PHIVE 22, \nand PhenIX23, as well as their weighted combination (labeled “Exomiser score”). Exomiser uses phenotypes \nin the form of HPO terms as input and, because it is designed for ranking variants in whole exome or whole \ngenome sequencing, it outputs a ranked list of variants from the list that the user provides. We generate a random \nvariant in each randomly picked gene as input and ignore all variant-related scores produced by Exomiser in \nour evaluation. Exomiser algorithms vary mainly in the background knowledge they use 20. PhenIX ranks \ngenes solely based on human phenotypes 23, omitting scores for non-human disease genes. PHIVE integrates \ninput phenotypes with mouse model phenotypes and orthology 22. ExomeWalker incorporates protein-protein \ninteraction networks21, generating a final score via logistic regression.\nWe utilized the default settings to execute the tools on the generated synthetic datasets from PAVS and \nClinVar, inputting the acquired HPO codes for each variant. We assessed the gene scores for each prediction \nmethod, excluding variant scores, since our focus is on gene prioritization.\nLarge Language Models used\nWe used three LLMs as part of this study, GPT-3.5-Turbo11 and GPT-413 and the Falcon180B model24. GPT-3.5-\nTurbo is an instruction-following LLM with 20 billion parameters, trained on data up to January 2022. GPT-4 \nis a multi-modal instruction-following model; the model is commercially available as a black-box model and \nno technical details are publicly known. We used GPT-4 trained with data up to April 2023. Falcon 180B is an \nLLM that is publicly available. Falcon 180B was trained on 3.5 trillion tokens primarily consisting of data from \nthe RefinedWeb dataset24. We utilized Falcon 180B-Chat, a model with 180 billion parameters, trained up to \nNovember 2022. We accessed GPT-3.5-Turbo and GPT-4 via the OpenAI API. Falcon 180B-Chat was run using \neight A100 80GB GPUs, following release notes, with the model set to return only high-confidence tokens by \nsetting do_sample to false.\nPrompt engineering\nAs part of our interaction with the LLMs, we designed structured prompts to engage with the LLMs through \ntheir API. We followed the GPT best practice guidelines25 to design our prompts. We wrote clear instructions by \nfollowing the suggested tactics (e.g., ask the model to adopt a persona, use delimiters to clearly indicate distinct \nparts of the input, specify the output format) and evaluated each prompt on our benchmarking datasets.\nWe show the experimental prompts in Table 1 and provide examples in the supplements (Supplementary \nTable S1). We adhere to ethical guidelines to ensure the confidentiality and anonymity of patient information \nin our interactions with the LLMs. Prompts Q1, Q2, and Q3 are zero-shot 26, while Q4 constitutes a one-shot, \nchain-of-thought prompt26,27 instructing the LLM specifically on how to perform the gene ranking. In Q1, we \ninstruct the LLM to rank the provided gene list. In Q2, additional patient-related information, including sex and \nmode of inheritance, is provided. In Q3, the LLM is prompted to rank genes based on their function, expression \nsite, and relevant animal models if there is insufficient information about the gene itself available. Lastly, Q4, a \none-shot, chain-of-thought prompt precisely instructs the LLM on the ranking process and the required output \nformat. This prompt provides the LLM with a “reasoning” strategy about how it should identify relevant genes \nin the presence or absence of different types of information. This chain-of-thought prompt that we designed \nis inspired by the different types of data that phenotype-based gene- and variant-prioritization methods like \nExomiser20 use.\nTo identify the prompt to use, we assessed GPT-3.5-turbo’s performance on GPCards using a selection of \nnine randomly chosen genes and one causative gene retrieved from GPCards. Table 2 shows the performance \nID Type Prompt\nQ1 Zero-shot A patient presented with these clinical symptoms: [phenotypes]. Rank these genes according to their association with the \nsymptoms of the patient: [genes]\nQ2 Zero-shot A [male/female] patient who is suspected of having a [mode of inheritance/genetic] disease, presented with these clinical \nsymptoms: [phenotypes]. Rank these genes according to their association with the symptoms of the patient:[genes]\nQ3 Zero-shot\nA [male/female] patient who is suspected of having a [mode of inheritance/genetic] disease, presented with these clinical \nsymptoms: [phenotypes]. Rank these genes according to their association with the symptoms of the patient: [genes]. In the case \nof insufficient information, still try to rank these genes by using function, site of expression or information from animal models\nQ4 One-shot, chain-of-thought\nRole: Y ou are an automated ranking system. Y ou take a set of patient signs and symptoms (phenotypes) as input, as well as a set \nof genes in which a likely pathogenic variant has been identified using a bioinformatics system. Y ou return a ranked list of genes \naccording to the likelihood of the damaging variant in the gene causing the phenotypes of the patient. To do the ranking, first \nidentify if there is any knowledge about mutations in the gene causing the same or similar phenotypes as observed in the patient. \nUse information about disease and phenotypes, animal models, gene functions, and anatomical site of expression. Automatically \nrank all genes on the last rank if no evidence exists, and rank all other genes based on the likelihood of causing the phenotypes. \nY our ranked list should include only the user provided genes and not any other gene. Example: A [male/female] patient who is \nsuspected of having a [mode of inheritance/genetic] disease, presented with these clinical symptoms: [phenotypes]. Rank these \ngenes according to their association with the symptoms of the patient: [genes]. Assistant: “Ranked List:” 1. Gene1 2. Gene2 \n3. Gene3 ... A [male/female] patient who is suspected of having a [mode of inheritance/genetic] disease, presented with these \nclinical symptoms: [phenotypes]. Rank these genes according to their association with the symptoms of the patient:[genes]\nTable 1. Prompts Crafted.\n \nScientific Reports |        (2025) 15:15093 3| https://doi.org/10.1038/s41598-025-99539-y\nwww.nature.com/scientificreports/\nresults of the different queries, including several combinations and variations of the queries. Q2 +Q3 denotes \nthe utilization of Q3 when Q2 fails, i.e., when the LLM does not rank a given set of genes based on Q2. The \nsymbol Q2−sign indicates substituting “symptoms” with “signs and symptoms” , whereas Q2−pheno represents \nreplacing “symptoms” with “phenotypes” in Q2. Q2-full gene names represents using full gene names instead of \ntheir symbols in Q2.\nAnalysis of noisy phenotypes\nTo assess the robustness of our LLM-based approach against noise in gene prioritization, we conducted \nexperiments by systematically altering the phenotypes in patient profiles. For this purpose, we mapped \nphenotypes from GPCards to HPO using a dictionary of class names and synonyms available in HPO (using \nHPO version 2019-11-08, following GPCard’s HPO release). For each phenotype, we retrieved its direct parents \nand direct children in HPO.\nTo introduce controlled modifications, we applied four different alteration scenarios. (1) Phenotype removal: \nin this experiment, randomly selected phenotypes were removed from the patient’s profile. (2) Phenotype \naddition: randomly selected HPO terms that were not already present in the patient’s profile were added to \nthe phenotypes. (3) Phenotype generalization: randomly selected phenotypes from the patient’s profile were \nreplaced with one of their direct parent terms. (4) Phenotype specialization: randomly selected phenotypes of \nthe patient were replaced with one of their direct child terms.\nFor all scenarios, modifications were applied at predefined proportions (10%, 25%, 50%, or 75%). If a patient \nhad only a single phenotype, no alterations were applied (we identified only one patient profile out of 50 in \nGPCards with such characteristics). When calculating the number of phenotypes to modify, we used the floor \nvalue to determine the number of alterations.\nRare disease cohort\nWe applied GPT-4 to 32 families presenting at King Khalid University Hospital (KKUH) in Riyadh. Each family \nconsisted of at least one individual with suspected genetic disease and multiple unaffected family members \nwho provided blood samples at KKUH where DNA was extracted from blood. Using the extracted DNA, we \nconstructed DNA libraries using a QIAGEN QIAseq FX DNA Library kit and sequenced each individual using \nan Illumina NovaSeq 6000 with an average coverage of 30x for each genome.\nWe used the bcbio-nextgen toolkit 28 and standard workflows to align the genomes to the GRCh38 human \nreference genome, to call variants using the GATK Haplotype caller 29, and genotype individuals. After variant \ncalling and genotyping, we filtered common variants (minor allele frequency less than 1%) using gnomAD \n(version 2.1.1)30 and the 1,000 genomes project all population frequencies31. We then used the suspected mode \nof inheritance assigned by the clinical geneticist at KKUH based on the observed pattern of inheritance within \nthe family and filtered variants by family pedigree using the SliVar4 software. We further removed variants not \nconsidered pathologically “impactful” by using the SliVar tool, i.e., excluding synonymous and intronic variants4.\nWe carried out expert assessment of the plausibility of the ChatGPT suggested variants, looking primarily for \nconsistency with existing knowledge and reasonable mechanistic coherence (discussed further in Section 3.3). \nOur expert assessment of plausibility includes: knowledge of gene function, pathway involvement, experimental \nfindings on whole animal and cellular systems, and phenotypic similarity ( e.g. closely clinically related aspects \nof developmental delay) amongst other factors. We include reported phenotypes associated with other variants \nin the same gene, phenotypes caused by members of the same pathway or gene family members, and those that \nmay be reasonably inferred from mechanistic knowledge.\nIn the light of the expert assessment of the biological and clinical plausibility of candidates, we examined the \nexplanations given by GPT-4 using four criteria, scoring out of 5 for each criterion. Truthfulness; the explanation \ngiven using objectively identifiably correct assertions, such as “gene A is a member of gene family X and is involved \nin Biological process Y” . Informativeness; the explanation gives insight into the causative link between alteration \nof gene function and phenotype, for example through a previously characterised mechanism. Completeness; \nthe explanation providing a complete rationale for the generation of all the phenotypes seen in the patient as a \nconsequence of the suggested mechanism. Relevance; that the explanation is relevant to the candidate gene and \nthe phenotypes reported and does not, for example, use an explanation that involves a completely different gene \nor set of phenotypes to those input in the prompt.\nHits (%) Q1 Q2 Q2−sign Q2−pheno Q2-full gene names Q3 Q2+Q3 Q4\nHits@1 74 76 76 76 30 62 80 80\nHits@5 92 94 94 94 64 78 98 98\nHits@10 92 94 94 94 100 82 100 100\nTable 2. Evaluation of GPT-3.5-turbo with various prompts on GPCards. The numbers indicate the percentage \nof the causative gene hits at ranks 1, 5, and 10. The notation Q2+Q3 denotes the utilization of Q3 when Q2 \nfails. The symbol Q2−sign indicates substituting “symptoms” with “signs and symptoms” , whereas Q2−pheno \nrepresents replacing “symptoms” with “phenotypes” in Q2. Q2-full gene names represent using full gene names \ninstead of their symbols in Q2.\n \nScientific Reports |        (2025) 15:15093 4| https://doi.org/10.1038/s41598-025-99539-y\nwww.nature.com/scientificreports/\nEvaluation procedure\nWe applied LLMs to the problem of ranking genes based on a set of phenotypes associated with a Mendelian \ndisorder. The input is a set of genes and a set of phenotypes, and the output is a ranked list of genes, with the gene \nmost likely to be causative of the observed phenotypes ranked first. This evaluation reflects the use case where \nvariants are already filtered by different evidence types or machine learning tools predicting pathogenicity, and \nthe remaining variants have to be ranked based on whether the gene products they affect are likely involved in \ncausing the observed set of phenotypes. In this ranking, only a few genes or gene products need to be considered.\nWe designed prompts in which we asked the LLM to rank a set of genes based on their likelihood of being \ninvolved in a set of phenotypes. The phenotypes we used in the prompts are taken from the phenotypes in the \ndatasets, and one gene in the list of genes is the gene associated with the set of phenotypes in the given dataset; \nthe other genes are randomly chosen from all human genes. We evaluated the ranked list of genes generated by \nthe LLMs as output, and determined where the positive gene (from the genotype-to-phenotype information in \nthe datasets) is ranked.\nThe LLM provides a ranked list of genes, often with explanatory sentences. We disregarded explanations and \nassessed the LLMs’ performance in ranking the “correct” genes.\nThe evaluation metrics used in this study are described in Supplementary Materials.\nResults\nLLMs accurately rank candidate genes\nWe first applied LLMs on a dataset of genotype–phenotype relations derived from GPCards. Initially, we \nexperimented with a set of “zero-shot” and “chain-of-thought prompts”26 (see Materials and Methods) by using \nGPT-3.5 to optimize the prompts.\nTable 2 presents the results obtained with different prompts using a gene size of 10 on GPCards. Q4 (one shot, \nchain-of-thought) and Q2+Q3 (zero-shot) outperform other query formats. However, results may not achieve \nthe accuracy 100% at Hits@10 due to hallucinations, such as the causative gene being absent from the LLM list \nreturned. To assess LLMs’ gene ranking performance with an increasing number of discriminated genes, we \nexpanded the random genes added to the causative one from 4 to 99. One-shot chain-of-thought prompting \nshows potential improvement over zero-shot prompting, with GPT-4 outperforming all tested LLMs (see Table \n3 and Supplementary Table S2 for other LLMs).\nWe repeated the experiment on GPCards five times (see Supplementary Table S3) to determine the stability \nof the results, and find that the ranking results in the GPCards dataset are stable across multiple repetitions. \nAcross these repetitions, one-shot prompting consistently outperformed other approaches, especially for larger \ngene lists (50, 75, and 100 genes). Notably, one-shot prompting also showed more reproducible results for gene \nranking where we found the mean (M) and standard deviation (SD) for the largest gene set size (100) as M=0.90, \nSize Metric\nGP-Cards ClinVar PAVS\nGPT-4 GPT-4\nExomiser\nGPT-4\nExomiserZero shot One shot Zero shot One shot Zero shot One shot\n5\nHits@1 (%) 98.00 94.00 93.00 97.00 89.00 93.00 94.80 97.60\nHits@10 (%) 100 100 100 100 100 100 100 100\nROC AUC 0.998 0.990 0.991 0.991 0.967 0.989 0.991 0.927\nAUPR 0.985 0.949 0.944 0.972 0.889 0.943 0.956 0.771\n25\nHits@1 (%) 78.00 78.00 82.00 85.00 84.00 75.40 77.80 65.60\nHits@10 (%) 98.00 98.00 94.00 97.00 91.00 97.80 99.00 82.60\nROC AUC 0.961 0.964 0.964 0.982 0.938 0.970 0.979 0.880\nAUPR 0.770 0.756 0.802 0.856 0.799 0.753 0.784 0.618\n50\nHits@1 (%) 76.00 70.00 81.00 87.00 84.00 66.40 68.40 57.20\nHits@10 (%) 94.00 94.00 96.00 97.00 91.00 91.00 95.20 80.20\nROC AUC 0.962 0.961 0.971 0.977 0.936 0.949 0.973 0.875\nAUPR 0.723 0.680 0.806 0.786 0.789 0.639 0.677 0.540\n75\nHits@1 (%) 62.00 72.00 71.00 74.00 82.00 59.80 61.80 51.60\nHits@10 (%) 86.00 94.00 82.00 96.00 86.00 83.40 91.40 79.40\nROC AUC 0.919 0.981 0.925 0.980 0.932 0.992 0.960 0.872\nAUPR 0.576 0.681 0.663 0.742 0.771 0.553 0.595 0.483\n100\nHits@1 (%) 60.00 60.00 68.00 70.00 82.00 56.40 57.80 58.60\nHits@10 (%) 86.00 82.00 81.00 89.00 85.00 77.20 84.80 78.40\nROC AUC 0.928 0.927 0.911 0.929 0.930 0.895 0.937 0.870\nAUPR 0.343 0.559 0.622 0.668 0.766 0.500 0.539 0.445\nTable 3. Performance comparison across different Gene Set Sizes and Cohorts. Exomiser and the other \nmethods are not applicable to GPCards since the phenotypes are represented in free-text without assigned \nHuman Phenotype Ontology terms.\n \nScientific Reports |        (2025) 15:15093 5| https://doi.org/10.1038/s41598-025-99539-y\nwww.nature.com/scientificreports/\nSD=0.03 for zero-shot and M=0.94, SD=0.01 for one-shot on GPCards (for full results, refer to Supplementary \nTable S3).\nFurthermore, we investigated the robustness of GPT-4 against noise in the datasets. To this end, we conducted \nexperiments with GPCards, randomly removing, adding and replacing (with their parent or child classes) 10%, \n25%, 50%, or 75% of the phenotypes for each patient with 25 genes. Our results showed that GPT-4 remained \nrobust to noise until a significant proportion (75%) of the phenotypes was removed or added, while replacing \nthe phenotypes with their parent or child classes had minimal impact on performance (see Supplementary Table \nS4).\nLLMs improve on ontology-based ranking methods\nWhile our results on the GPCards dataset show that LLMs can rank genes based on a set of phenotypes specified \nin natural language, the majority of phenotype-based gene- or variant-prioritization methods rely on input \nspecified in a formal language based on phenotype ontologies 6,20. The use of an ontology removes ambiguity \nin phenotype descriptions and enables access to background knowledge contained in phenotype ontologies 9. \nTo compare the use of LLMs with established ontology-based ranking methods, we followed the same setup in \nranking a set of genes and identifying the causative genes given a set of phenotypes, and we compared LLMs with \nthe ontology-based tool Exomiser. Exomiser implements multiple different algorithms for prioritizing candidate \ngenes based on different sources of information; it uses human phenotypes in the PhenIX algorithm 23, mouse \nmodel phenotypes in PHIVE 22, human and other model organisms phenotypes in hiPHIVE 22, and protein–\nprotein interaction networks in ExomeWalker21.\nWe used two databases of genotype–phenotype associations for our evaluation and comparison. The first \nis ClinVar, which is used widely to benchmark variant- and gene-prioritization methods. ClinVar contains \nassociations of variants with diseases (specified using their OMIM identifiers); the OMIM diseases can then be \nmapped to their phenotypes using the HPO database7. For evaluation, we used only variants that have been added \nafter the knowledge cut-off date (2 July 2023 – 7 October 2023) for GPT-4. While ClinVar is a comprehensive \ndataset of genotype–phenotype relations, it does not associate variants with phenotypes observed clinically but \nrather with the disorder. Therefore, we also used the PAVS database, a database of phenotype-associated variants \nin Saudi Arabia, which contains clinically-reported phenotypes and the associated variants. For both sets of \nvariants, we followed a similar procedure as for our previous evaluation: we input the gene affected by the variant \ntogether with 4, 24, 49, 74, or 99 randomly chosen genes and asked the LLMs to rank the list of genes given the \nphenotypes. As GPT-4 was the best-performing model, we only evaluated GPT-4 on this task. Furthermore, \nsince Exomiser outperformed all compared methods, we reported Exomiser’s performance and included all \nother methods’ performance in the supplementary tables.\nTable 3 shows results for ranking genes based on ClinVar variants and phenotypes. GPT-4 with a one-\nshot chain-of-thought query outperformed a zero-shot query. It ranked genes better than the best performing \nbaseline method (Exomiser, refer to Supplementary Table S5 for other methods) when fewer than 25 genes are \nincluded, but its performance decreased compared to Exomiser when ranking more than 25 genes.\nIn the case of ClinVar, we used the HPO phenotypes as input for ranking; these phenotypes are identical \nto the phenotypes associated with the causative gene in the database used by Exomiser, and this may bias the \nresults. To address this, we evaluated genotypes from the PAVS database in Table 3. GPT-4 outperformed all \nother methods in ranking genes (see Supplementary Table S6 for other baseline methods) in the PAVS dataset, \nindicating its robustness to noisy phenotype descriptions compared to methods relying on semantic similarity \nand explicit genotype-to-phenotype databases.\nLLMs reveal candidate genes for undiagnosed cases\nWe evaluated LLM-based gene ranking using 32 families with undiagnosed genetic diseases (See Supplementary \nTable S7). All were seen at King Khalid University Hospital (KKUH) in Riyadh, Saudi Arabia. Whole genome \nsequencing was conducted for affected individuals and family members (see Methods). Data for these families \nis not publicly available, presenting a challenging “unseen” test case for LLM utility in rare genetic diseases. \nVariants were filtered by pedigree, mode of inheritance, and allele frequency, retaining rare and potentially \nimpactful variants (see Methods). After filtering, affected individuals had between 1 to 215 candidate variants \neach (mean 51.90) affecting 1 to 161 genes (mean 37.97).\nWe used the genes with a potentially impactful variant after all filtering steps as the list of genes to rank, and \nthe phenotypes observed clinically for each family as phenotypes. We used either the zero-shot or single-shot \nchain-of-thought prompt evaluated earlier. Based on our performance evaluation, we applied only GPT-4 to this \ncohort.\nAll 32 families underwent a detailed analysis to assess the biological and clinical plausibility of the top five \ncandidate gene predictions. We assessed whether the top candidate from either the zero or few shot approaches \nhad, in the opinion of two experts, a likelihood or possibility of being the causative gene (see Section 2.4). \nThis assessment, while expert, is inevitably subjective in the absence of direct experimentation, e.g. generating \nmice or cells carrying the mutant allele, direct 3D molecular structural determination of the mutant protein, or \nexperimental in vitro functional assay. Our criteria broadly overlap with those suggested by Strande at al.32 but \ngiven the heterogeneity of evidence available across the candidates, only a semi-quantitative approach is possible.\nFor example, we took into account existing evidence that the gene had already been associated with a \nclosely-related phenotypic description presented in the case in a genotype-to-phenotype database; evidence for \nloss or gain of function of a gene giving rise to at least two of the phenotypes or phenotype domains seen in \nthe family (for example delay in speech acquisition was regarded as an example of developmental delay and \ntherefore closely related); concordance of gene function or process, as described either by Gene Ontology 33 or \nin the literature, with the phenotypic description; phenotypic concordance with loss or gain of function of an \nScientific Reports |        (2025) 15:15093 6| https://doi.org/10.1038/s41598-025-99539-y\nwww.nature.com/scientificreports/\northolog in an experimental model; functional or etiological relationship between the phenotype of the patient \nand a gene–phenotype (e.g., vermis hypoplasia was regarded as closely associated with seizures/epilepsy or \nother neurodevelopmental disorders as the two are closely linked). Given the large variation in the severity and \nspectrum of disease manifestations in many rare diseases34, it is doubly important to assess biological plausibility \nrather than scoring precise and complete phenotype matches.\nWe evaluated the top five genes for each of the 32 families. All families had ranked candidate genes except one \nwhere GPT-4 failed to rank. Of these, 16 cases received at least one gene with a plausibility score of 4 or 5, and \n23 genes were deemed plausible by expert evaluation out of a total of 155 scored.\nExplanations, hallucinations, and reproducibility\nOne of the advantages of LLMs in variant- and gene-prioritization is that they can not only perform the ranking \nof genes but can also provide explanations for the ranks assigned. However, due to the statistical nature of LLMs, \nthey may also provide output that is factually incorrect, irrelevant, or inconsistent; we collectively refer to these \noutputs as “hallucinations” .\nThe first type of hallucination we observed was when the ranked list of genes included genes that were not \nspecified as input, omitted genes that were provided as input, or contained duplicates (see Table 4). All LLMs that \nwe evaluated often omitted genes (up to 56% cases), not ranking all input genes.\nLess frequently, LLMs also added new genes to the list to rank. Overall, we found that GPT-4 was more \nreliable than the other LLMs we evaluated, with the lowest number of hallucinations (both removing or adding \ngenes from the list to rank), and that prompts where phenotypes use structured, ontology-based input instead of \nfree-text were less prone to hallucinations than free-text input (Table 4).\nWe observed a second type of hallucination in the explanations that LLMs are generated for ranking certain \ngenes. Hallucinations included those that gave an inappropriate response, ones that gave an irrelevant response, \nand the ones that seemed true and were convincing, but had no basis in fact. The latter poses the most significant \nconcern as it can be challenging to identify and typically requires expert review of available sources and literature.\nWe manually reviewed the quality of the explanation given by the LLM for its choices of the top five gene \ncandidates for 32 families from our rare disease cohort. In some cases, the LLM gave a single global explanation \nwhich was often very general and factually correct but uninformative. In other cases, specific reasons were given \nfor each gene.\nWe assessed the explanations provided in terms of their truthfulness, informativeness, completeness, and \nrelevance. Truthfulness was assessed by whether the statement was factually true and could be substantiated \nwith facts or reasonable inferences from facts. Informativeness was assessed on how much useful, relevant, or \nnovel information was conveyed by the explanation. Completeness describes whether the explanation provides a \nrationale for all aspects of the patient phenotypes. Relevance was assessed by the degree to which the explanation \nfor gene association was biologically or clinically relevant to the phenotypes. A summary of results is available \nas Supplementary Table S7. We show that most explanations were factually correct (Truthfulness: mean: 3.8, SD: \n1.9), although usually uninformative (Informativeness: mean: 2.2, SD: 1.6) and incomplete (Completeness: mean \n1.8, SD: 1.4), and often not relevant to the phenotypes observed (Relevance: mean 2.1, SD: 1.8). We also ranked \nplausibility for the gene being causative of the phenotypes; overall, across the top five genes, plausibility had a \nmean of 1.6 (SD: 1.7). However, if we only consider the highest-scoring gene among the five genes we evaluated, \nthe mean plausibility is 3.7 (SD: 1.2), and for 15 families out of 32, we identified at least one candidate scoring \nwith a plausibility of 4 or 5.\nWhile most explanations were truthful, there are some where we have been unable to identify evidence for \nthe truth of the statements made. For example, in one family where the affected individual has a wide range of \nphenotypes, GPR107 is the second-ranked candidate gene and we are provided with the following explanation: \n“GPR107: This gene encodes a protein that is a member of the G protein-coupled receptor superfamily. This \nprotein has been shown to be a receptor for glucose, and is widely expressed in the central nervous system. While \nnot directly linked to the symptoms, it could potentially be involved due to its role in glucose metabolism. ” It \nis true that GPR107 is a G protein-coupled receptor, and it may be involved in glucose metabolism through its \naction on glucagon physiology via its binding to neuronostatin 35. However, we have been unable to find any \nevidence that it binds glucose. Therefore, while the overall assertion is largely true, the LLM has hallucinated \nModel and prompt\nGPCards PAVS ClinVar\nMissing Extra Missing Extra Missing Extra\nGPT-4—zero shot 42.00 00.80 14.48 01.84 15.40 01.60\nGPT-4—one shot 14.80 03.60 24.72 03.68 25.00 02.80\nGPT-3.5 turbo—zero shot 56.80 00.80 – – – –\nGPT-3.5 turbo—one shot 46.40 30.40 – – – –\nFalcon 180B—zero shot 44.00 06.80 – – – –\nFalcon 180B—one shot 12.00 30.80 – – – –\nTable 4. Hallucination results. Missing indicates, the ranked list of genes missing one/more input genes. Extra \nindicates the ranked list of genes contains one/more genes that are not provided in the input list. The values \nare percentages obtained by using the results of all the prompts regardless of the gene size (5,25,50,75,100). We \nhave 500, 250, and 2500 prompts for ClinVar, GPCards, and PAVS respectively.\n \nScientific Reports |        (2025) 15:15093 7| https://doi.org/10.1038/s41598-025-99539-y\nwww.nature.com/scientificreports/\npart of its explanation: GPR107 does not bind glucose. Furthermore, while there is a wide range of phenotypes \nreported, there is no clear common linkage to glucose metabolism and we consider this to be another type of \nhallucination, i.e., generation of an irrelevant response.\nWe observed a similar hallucination in another family where the affected individual has astigmatism, Legg-\nPerthes36, intellectual disability, and short stature. The explanation given for the top suggestion (SMPD3) is: \n“This gene is associated with Legg-Perthes disease, a condition that affects the hip joint in children and can \nlead to short stature. ” While it is true that, in principle, a hip disorder can lead to short stature, there is no \ndiscoverable link between SMPD3 and Legg-Perthes disease, and the disorder is primarily associated with \nCol2A1 ( OMIM:150600   37 ). It is, however, true that loss of function of the mouse ortholog gives rise to \ndisproportionate dwarfism 38, which is in principle a match. However, there are no behavioural or ocular \nphenotypes in these mice.The LLM has made a partial connection with the gene and the phenotypes, but the \nassertion that it is known to be involved in Legg-Perthes disease is hallucinatory. In a third type of hallucination, \nGPT-4 invented a syndrome, “TOR3A syndrome” with associated phenotypes bearing some relation to those \nof the patient. We can find no reference in the literature to “TOR3A syndrome” but TOR1A is associated with \ntorsion dystonia39; OMIM: 128100. GPT-4 seems to have associated the phenotype of one gene with another \nclosely related in name and function. We have seen this problem several times. For example, MYH4 and MYH14, \nwhere MYH14 is associated with autosomal deafness (OMIM: 600652) which is part of the patient phenotype, \nbut MYH4, the given candidate, has no association with deafness that we can discover.\nComparison of GPT-4 and Exomiser results on KKUH families\nWe compared the performance of GPT-4 and Exomiser in gene prioritization across 32 families, focusing \non the top 5 candidate genes when available from each tool. Supplementary Table S8 presents the integrated \nanalysis, including plausibility scores for the top five genes suggested by Exomiser and GPT-4. Overlapping \ngenes between the two methods are highlighted for clarity. Additionally, Supplementary Table S9 provides a \ncomparative summary of the performance of GPT-4 and Exomiser across all families. In total, we analyzed \n142 and 156 genes from GPT-4 and Exomiser respectively. Among these top rankings, 42 genes (16.27% of the \ncombined predictions) were suggested by both tools.\nWhen evaluating gene plausibility, GPT-4 identified 23 plausible genes across 16 families, while Exomiser \nidentified 18 plausible genes across 11 families, with 10 families overlapping between the two methods. Of \nthese 10 families, seven had overlapping genes predicted by both tools, with a total of 10 overlapping plausible \ngenes identified (32.26%): three families had two overlapping plausible genes each, and four families had one \noverlapping plausible gene. The remaining seven families each had a single plausible gene identified by one of the \ntools: six by GPT-4 and one by Exomiser. We further compared the tools based on the five solved cases where the \ncausative genes were known. GPT-4 demonstrated superior performance by identifying all five causative genes \n(100% success rate) within its top 5 predictions. In contrast, Exomiser identified two of the five causative genes \n(40% success rate) in its top 5 predictions.\nOur comparative analysis reveals that while both tools can effectively prioritize candidate genes, GPT-4 \nshowed higher accuracy in ranking both plausible and causative genes within its top 5 predictions. The modest \noverlap in predictions (16.27% overall, 32.26% in plausible genes) suggests they employ different approaches to \ngene prioritization, potentially making them complementary in clinical genetic analysis.\nDiscussion\nWe studied the use of LLMs for the task of gene prioritization based on phenotypes, a task that has traditionally \nbeen thought to rely on structured background knowledge. Our results demonstrate that LLMs can perform as \nwell or better than custom-built tools for this task. Notably, our time-based ClinVar experiment revealed that \nthe lack of provenance and original training data has no impact on LLM performance (See Supplementary Table \nS5). Phenotype-based methods for ranking candidate genes consist of two main components: a knowledge-base \nof genotype-to-phenotype relations, and a similarity measure6. Often, they also contain structured background \nknowledge about how phenotypes are related, usually in the form on a phenotype ontology 9. They also use a \nsimilarity measure based on the background knowledge, thereby making it a semantic similarity measure 8. To \nperform better than phenotype-based gene prioritization methods, LLMs need to be able to replace these two \nmain components. LLMs obtain their background knowledge from information covering structured datasets, \nontologies, and literature; the content of genotype-to-phenotype databases will therefore be included at least to \nlarge parts as training data or extracted from the literature (for example in the form of clinical case report 40). \nLLMs also seem to be able to compute similarity between phenotypes as well or better than the custom-built \nsimilarity measures in Exomiser, demonstrated in particular when using clinical phenotype descriptions as input \nto the ranking model (Table 3).\nLLMs can accept various types of input, including arbitrary text, as demonstrated in one dataset not reliant on \nthe HPO vocabulary. While Exomiser’s baseline methods use HPO codes, we solely employed natural language \nlabels for LLM input in our experiments. Although the biomedical community has created valuable phenotype \nontologies like the HPO to aid gene prioritization, our findings suggest that structured phenotypes may not be \nessential and could even hinder success. This could be due to incomplete ontology information leading to errors \nor limitations in expressing information compared to natural language input for LLMs. While our observations \nfocus on one aspect of phenotype ontologies, future considerations should weigh the benefits of ontologies \nagainst the capabilities of advanced LLMs for various tasks.\nOur experiments also show that LLMs go beyond gene prioritization systems in that they can provide \nexplanations for their results. Furthermore, LLMs also have the potential to refine and update ranking results \ninteractively.\nScientific Reports |        (2025) 15:15093 8| https://doi.org/10.1038/s41598-025-99539-y\nwww.nature.com/scientificreports/\nThe best use of LLMs may therefore be not as a simply ranking system but rather as an interactive diagnostic \nassistant. We also attempted to estimate how robust LLMs are to noise, and find that they tolerate different \ntypes of noise, including omitting phenotypes, adding unrelated phenotypes, and using more generic or more \nspecialized phenotypes. Using the GPCards dataset, we also evaluated how stable results are when queries \nare repeated, and find that results generally remain the same with only small differences in repeated queries. \nHowever, for both the ClinVar and PAVS datasets, our analysis is based on single queries, i.e., we did not repeat \nthe queries with different random gene sets, due to the larger size of the datasets compared to GPCards. We \ntherefore cannot determine how stable the results are when performed multiple times. Furthermore, future work \nstill needs to address “hallucinations” as well as ways to quantify uncertainty; knowledge graphs and ontologies \nmay provide ways to solve the problem of hallucination41,42 by providing structured knowledge.\nOne potential limitation of our study is that the language models we assessed were trained on text (i.e. \nliterature articles) containing variants found in our testing set. This issue also extends to the Exomiser tool, \nwhich relies on reported gene phenotypes. To address this, we only evaluated variants post the GPT-4 cut-off  \ndate. For future studies, a prospective approach utilizing language models for genetic disease diagnosis should \nbe considered. This study could explore other types of genomic variants, such as non-coding and structural \nvariants, along with methods for incorporating structured background knowledge to enhance learning.\nData availability\nPrimary or derived data from the families that were sequenced and analyzed is available only for researchers \nwith access approved by the responsible IRB. Any requests for data access should be addressed to the Institu -\ntional Bioethics Committee at King Abdullah University of Science and Technology and the Institutional Review \nBoard (IRB) at King Saud University. All other data and code used in this study are available at  h t t p s :  / / g i t h  u b . c o \nm  / b i o - o  n t o l o  g y - r e s  e a r c h -  g r o u p /  L L M _ G e n e P r i o r i t i z a t i o n.\nReceived: 25 June 2024; Accepted: 21 April 2025\nReferences\n 1. Nguengang Wakap, S. et al. Estimating cumulative point prevalence of rare diseases: Analysis of the orphanet database. Eur. J. \nHum. Genet. 28, 165–173. https://doi.org/10.1038/s41431-019-0508-0 (2019).\n 2. Stark, Z. & Scott, R. H. Genomic newborn screening for rare diseases. Nat. Rev. Genet. 24, 755–766.  h t t p s : / / d o i . o r g / 1 0 . 1 0 3 8 / s 4 1 5 7 \n6 - 0 2 3 - 0 0 6 2 1 - w     (2023).\n 3. Wojcik, M. H. et al. Beyond the exome: What’s next in diagnostic testing for mendelian conditions. Am. J. Hum. Genet.  110, \n1229–1248. https://doi.org/10.1016/j.ajhg.2023.06.009 (2023).\n 4. Pedersen, B. S. et al. Effective variant filtering and expected candidate variant yield in studies of rare human disease. npj Genomic \nMed. https://doi.org/10.1038/s41525-021-00227-3 (2021).\n 5. Spielmann, M. & Kircher, M. Computational and experimental methods for classifying variants of unknown clinical significance. \nCold Spring Harb. Mol. Case Stud. https://doi.org/10.1101/mcs.a006196 (2022).\n 6. Yuan, X. et al. Evaluation of phenotype-driven gene prioritization methods for mendelian diseases. Brief. Bioinform.  h t t p s : / / d o i . o r \ng / 1 0 . 1 0 9 3 / b i b / b b a c 0 1 9     (2022).\n 7. Köhler, S. et al. The human phenotype ontology in 2021. Nucleic Acids Res. 49, D1207–D1217.  h t t p s : / / d o i . o r g / 1 0 . 1 0 9 3 / n a r / g k a a 1 0 \n4 3     (2020).\n 8. Kulmanov, M., Smaili, F . Z., Gao, X. & Hoehndorf, R. Semantic similarity and machine learning with ontologies. Brief. Bioinform. \nhttps://doi.org/10.1093/bib/bbaa199 (2020).\n 9. Gkoutos, G. V ., Schofield, P . N. & Hoehndorf, R. The anatomy of phenotype ontologies: Principles, properties and applications. \nBrief. Bioinform. 19, 1008–1021 (2018).\n 10. Kulmanov, M. & Hoehndorf, R. Evaluating the effect of annotation size on measures of semantic similarity. J. Biomed. Semant. \nhttps://doi.org/10.1186/s13326-017-0119-z (2017).\n 11. Brown, T. et al. Language models are few-shot learners. Adv. Neural. Inf. Process. Syst. 33, 1877–1901 (2020).\n 12. OpenAI. Gpt-3.5-turbo: Generative pre-trained transformer 3.5-turbo. https://platform.openai.com/docs/models/gpt-3-5 \nAccessed 21 Oct 2023 (2023).\n 13. OpenAI. Gpt-4 technical report. Tech. Rep., arXiv arXiv:submit/4812508 (2023).\n 14. Technology Innovative Institute, . Falcon180b. https://falconllm.tii.ae/. Accessed 21 Oct 2023 (2023).\n 15. Li, B. et al. Gpcards: An integrated database of genotype-phenotype correlations in human genetic diseases. Comput. Struct. \nBiotechnol. J. 19, 1603–1611. https://doi.org/10.1016/j.csbj.2021.03.011 (2021).\n 16. Landrum, M. J. et al. Clinvar: Improvements to accessing data. Nucleic Acids Res. 48, D835–D844 (2020).\n 17. Amberger, J. S., Bocchini, C. A., Scott, A. F . & Hamosh, A. Omim.org: Leveraging knowledge across phenotype-gene relationships. \nNucl. Acids Res. 47, D1038–D1043 (2019).\n 18. Syed, A. R., Abdelhakim, M., Althagafi, A. & Hoehndorf, R. PAVS - phenotype associated variants in saudi arabia.  h t t p : / / p a v s . p h e \nn o m e b r o w s e r . n e t /     . Accessed 21 Oct (2023).\n 19. Alfares, A. et al. What is the right sequencing approach? Solo vs extended family analysis in consanguineous populations. BMC \nMed. Genomics https://doi.org/10.1186/s12920-020-00743-8 (2020).\n 20. Smedley, D. et al. Next-generation diagnostics and disease-gene discovery with the exomiser. Nat. Protoc. 10, 2004–2015 (2015).\n 21. Smedley, D. et al. Walking the interactome for candidate prioritization in exome sequencing studies of mendelian diseases. \nBioinformatics 30, 3215–3222 (2014).\n 22. Robinson, P . N. et al. Improved exome prioritization of disease genes through cross-species phenotype comparison. Genome Res. \n24, 340–348 (2014).\n 23. Zemojtel, T. et al. Effective diagnosis of genetic disease by computational phenotype analysis of the disease-associated genome. Sci. \nTransl. Med. https://doi.org/10.1126/scitranslmed.3009262 (2014).\n 24. Penedo, G. et al. The refinedweb dataset for falcon llm: Outperforming curated corpora with web data, and web data only,  h t t p s : / / \nd o i . o r g / 1 0 . 4 8 5 5 0 / A R X I V . 2 3 0 6 . 0 1 1 1 6     (2023).\n 25. OpenAI. Gpt best practices.  h t t p s :   /  / p l a t f o r  m . o p e n a  i  . c  o m /  d o  c s /  g u i  d e s  /  g p t -   b e s t - p r a c t i c e s Accessed 21 Oct 2023 (2023).\n 26. Wang, J. et al. Prompt engineering for healthcare: Methodologies and applications. arXiv  h t t p s : / / d o i . o r g / 1 0 . 4 8 5 5 0 / A R X I V . 2 3 0 4 . 1 4 \n6 7 0     (2023).\n 27. Lai, V . D. et al. Chatgpt beyond english: Towards a comprehensive evaluation of large language models in multilingual learning, \nhttps://doi.org/10.48550/ARXIV .2304.05613 (2023).\nScientific Reports |        (2025) 15:15093 9| https://doi.org/10.1038/s41598-025-99539-y\nwww.nature.com/scientificreports/\n 28. Guimera, R. V . bcbio-nextgen: Automated, distributed next-gen sequencing pipeline. EMBnet. J. 17, 30 (2011).\n 29. Auwera, G. A. et al. From FastQ data to high-confidence variant calls: The genome analysis toolkit best practices pipeline. Curr. \nProtocols Bioinform. https://doi.org/10.1002/0471250953.bi1110s43 (2013).\n 30. Collins, R. L. et al. A structural variation reference for medical and population genetics. Nature 581, 444–451.  h t t p s : / / d o i . o r g / 1 0 . 1 \n0 3 8 / s 4 1 5 8 6 - 0 2 0 - 2 2 8 7 - 8     (2020).\n 31. Consortium et al. An integrated map of genetic variation from 1,092 human genomes. Nature 491, 56 (2012).\n 32. Strande, N. T. et al. Evaluating the clinical validity of gene-disease associations: An evidence-based framework developed by the \nclinical genome resource. Am. J. Hum. Genet. 100, 895–906. https://doi.org/10.1016/j.ajhg.2017.04.015 (2017).\n 33. Ashburner, M. et al. Gene ontology: Tool for the unification of biology. Nat. Genet. 25, 25–29. https://doi.org/10.1038/75556 \n(2000).\n 34. McNeill, A. Good genotype-phenotype relationships in rare disease are hard to find. Eur. J. Hum. Genet. 30, 251–251.  h t t p s : / / d o i . \no r g / 1 0 . 1 0 3 8 / s 4 1 4 3 1 - 0 2 2 - 0 1 0 6 2 - 5     (2022).\n 35. Elrick, M. M. et al. Neuronostatin acts via GPR107 to increase cAMP-independent PKA phosphorylation and proglucagon mRNA \naccumulation in pancreatic alpha-cells. Am. J. Physiol.-Regul. Integr. Compar. Physiol. 310, R143–R155.  h t t p s : / / d o i . o r g / 1 0 . 1 1 5 2 / a j \np r e g u . 0 0 3 6 9 . 2 0 1 4     (2016).\n 36. Rodríguez-Olivas, A. O., Hernández-Zamora, E. & Reyes-Maldonado, E. Legg-calvé-perthes disease overview. Orphanet J. Rare \nDis. https://doi.org/10.1186/s13023-022-02275-z (2022).\n 37. Asadollahi, S., Neamatzadeh, H., Namiranian, N. & Sobhan, M. R. Genetics of legg-calve-perthes disease: A review study. J. Pediatr. \nRev. 9, 301–308 https://doi.org/10.32598/jpr.9.4.964.1 (2021).\n 38. Stoffel, W . et al. Neutral sphingomyelinase (SMPD3) deficiency causes a novel form of chondrodysplasia and dwarfism that is \nrescued by col2a1-driven smpd3 transgene expression. Am. J. Pathol. 171, 153–161. https://doi.org/10.2353/ajpath.2007.061285 \n(2007).\n 39. Ozelius, L. J. et al. The early-onset torsion dystonia gene (DYT1) encodes an ATP-binding protein. Nat. Genet. 17, 40–48.  h t t p s : / / \nd o i . o r g / 1 0 . 1 0 3 8 / n g 0 9 9 7 - 4 0     (1997).\n 40. Fujiwara, T., Shin, J. & Y amaguchi, A. Advances in the development of PubCaseFinder, including the new application programming \ninterface and matching algorithm. Hum. Mutat. https://doi.org/10.1002/humu.24341 (2022).\n 41. Pan, S. et al. Unifying large language models and knowledge graphs: A roadmap. ArXivabs/2306.08302 (2023).\n 42. Pan, J. Z. et al. Large language models and knowledge graphs: Opportunities and challenges. Trans. Graph Data Knowl. 1, 2:1-2:38. \nhttps://doi.org/10.4230/TGDK.1.1.2 (2023).\nAcknowledgements\nWe thank the KAUST Supercomputing Laboratory for their support. P .N.S acknowledges support from the Alan \nTuring Institute.\nAuthor contributions\nŞ.K. designed prompts, conducted GPT experiments, evaluated results, and contributed to the initial manuscript \ndraft. M. Abdelhakim prepared libraries for KSU samples, analyzed gene prioritization results, and participated \nin manual analysis. A.A. executed experiments with other tools, generated VCF files, and contributed to the \nstudy. S.T. conducted Falcon180B-Chat experiments and helped prepare evaluation scripts. P .N.S. participated in \nexpert evaluation of results, analysis of explanations, and manuscript drafting. M. Alghamdi provided samples, \nclinical data, and pedigrees. R.H. conceived the study, contributed to the prompt design, and participated in \nmanuscript drafting. All authors reviewed and approved the final manuscript version.\nFunding\nThis work was supported by funding from King Abdullah University of Science and Technology (KAUST) \nOffice of Sponsored Research (OSR) under several award numbers: URF/1/4355-01-01, URF/1/4675-01-01, \nURF/1/4697-01-01, URF/1/5041-01-01, REI/1/5334-01-01, FCC/1/1976-46-01, and FCC/1/1976-34-01. Addi -\ntionally, support was provided by the SDAIA-KAUST Center of Excellence in Data Science and Artificial Intelli-\ngence (SDAIA-KAUST AI). We acknowledge funding from King Abdullah University of Science and Technology \n(KAUST) – KAUST Center of Excellence for Smart Health (KCSH), under award number 5932, and by funding \nfrom King Abdullah University of Science and Technology (KAUST) – Center of Excellence for Generative AI, \nunder award number 5940.\nDeclarations\nCompliance with guidelines\nAll methods were carried out per the guidelines and regulations laid out by the institutional bioethics \ncommittees, the Declaration of Helsinki, and applicable laws and regulations governing research involving \nhuman subjects.\nConsent to participate\nInformed consent was obtained from all participants or their legal guardians.\nConsent for publication\nInformed consent was obtained from all participants or their legal guardians.\nEthical approval\nThis study was approved by the Institutional Bioethics Committee (IBEC) at King Abdullah University of \nScience and Technology under approval numbers 18IBEC10 and 22IBEC069, and the Institutional Review \nBoard (IRB) at King Saud University under approval number 18/0093/IRB.\nScientific Reports |        (2025) 15:15093 10| https://doi.org/10.1038/s41598-025-99539-y\nwww.nature.com/scientificreports/\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary Information The online version contains supplementary material available at  h t t p s : / / d o i . o r g / 1 \n0 . 1 0 3 8 / s 4 1 5 9 8 - 0 2 5 - 9 9 5 3 9 - y     .  \nCorrespondence and requests for materials should be addressed to Ş.K. or R.H.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give \nappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and \nindicate if changes were made. The images or other third party material in this article are included in the article’s \nCreative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included \nin the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or \nexceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy \nof this licence, visit http://creativecommons.org/licenses/by/4.0/.\n© The Author(s) 2025 \nScientific Reports |        (2025) 15:15093 11| https://doi.org/10.1038/s41598-025-99539-y\nwww.nature.com/scientificreports/",
  "topic": "Phenotype",
  "concepts": [
    {
      "name": "Phenotype",
      "score": 0.676213264465332
    },
    {
      "name": "Disease",
      "score": 0.6348199248313904
    },
    {
      "name": "Gene",
      "score": 0.5212224721908569
    },
    {
      "name": "Genotype-phenotype distinction",
      "score": 0.47508588433265686
    },
    {
      "name": "Prioritization",
      "score": 0.47079578042030334
    },
    {
      "name": "Bioinformatics",
      "score": 0.38891810178756714
    },
    {
      "name": "Computational biology",
      "score": 0.36815744638442993
    },
    {
      "name": "Genetics",
      "score": 0.34273606538772583
    },
    {
      "name": "Biology",
      "score": 0.33650392293930054
    },
    {
      "name": "Medicine",
      "score": 0.2851487398147583
    },
    {
      "name": "Pathology",
      "score": 0.12511548399925232
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Management science",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I71920554",
      "name": "King Abdullah University of Science and Technology",
      "country": "SA"
    },
    {
      "id": "https://openalex.org/I179331831",
      "name": "Taif University",
      "country": "SA"
    },
    {
      "id": "https://openalex.org/I28022161",
      "name": "King Saud University",
      "country": "SA"
    },
    {
      "id": "https://openalex.org/I241749",
      "name": "University of Cambridge",
      "country": "GB"
    }
  ],
  "cited_by": 3
}