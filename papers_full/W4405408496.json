{
    "title": "The Impact of Temperature on Extracting Information From Clinical Trial Publications Using Large Language Models",
    "url": "https://openalex.org/W4405408496",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2163710154",
            "name": "Paul Windisch",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2979755547",
            "name": "Fabio Dennstädt",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4224503866",
            "name": "Carole Koechli",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1986935804",
            "name": "Christina Schröder",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2034485990",
            "name": "Daniel M. Aebersold",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2056450758",
            "name": "Robert Forster",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A679931317",
            "name": "Daniel R. Zwahlen",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2100053037",
        "https://openalex.org/W2970771982",
        "https://openalex.org/W3133622905",
        "https://openalex.org/W3087185831",
        "https://openalex.org/W4375870255",
        "https://openalex.org/W6606378520",
        "https://openalex.org/W4396624257",
        "https://openalex.org/W4391709332",
        "https://openalex.org/W4400931359",
        "https://openalex.org/W4400345189",
        "https://openalex.org/W4403790812",
        "https://openalex.org/W4401208776",
        "https://openalex.org/W4288407534"
    ],
    "abstract": "Introduction The application of natural language processing (NLP) for extracting data from biomedical research has gained momentum with the advent of large language models (LLMs). However, the effect of different LLM parameters, such as temperature settings, on biomedical text mining remains underexplored and a consensus on what settings can be considered \"safe\" is missing. This study evaluates the impact of temperature settings on LLM performance for a named entity recognition and a classification task in clinical trial publications. Methods Two datasets were analyzed using GPT-4o and GPT-4o-mini models at nine different temperature settings (0.00-2.00). The models were used to extract the number of randomized participants and classify abstracts as randomized controlled trials (RCTs) and/or as oncology-related. Different performance metrics were calculated for each temperature setting and task. Results Both models provided correctly formatted predictions for more than 98.7% of abstracts across temperatures from 0.00 to 1.50. While the number of correctly formatted predictions started to decrease afterward with the most notable drop between temperatures 1.75 and 2.00, the other performance metrics remained largely stable. Conclusion Temperature settings at or below 1.50 yielded consistent performance across text-mining tasks, with performance declines at higher settings. These findings are aligned with research on different temperature settings for other tasks, suggesting stable performance within a controlled temperature range across various NLP applications.",
    "full_text": "Review began\n 12/09/2024 \nReview ended\n 12/13/2024 \nPublished\n 12/15/2024\n© Copyright \n2024\nWindisch et al. This is an open access\narticle distributed under the terms of the\nCreative Commons Attribution License CC-\nBY 4.0., which permits unrestricted use,\ndistribution, and reproduction in any\nmedium, provided the original author and\nsource are credited.\nDOI:\n 10.7759/cureus.75748\nThe Impact of Temperature on Extracting\nInformation From Clinical Trial Publications\nUsing Large Language Models\nPaul Windisch \n \n, \nFabio Dennstädt \n, \nCarole Koechli \n, \nChristina Schröder \n \n, \nDaniel M. Aebersold \n,\nRobert Förster \n \n, \nDaniel R. Zwahlen \n1.\n Department of Radiation Oncology, Cantonal Hospital Winterthur, Winterthur, CHE \n2.\n Department of Radiation\nOncology, Bern University Hospital, University of Bern, Bern, CHE\nCorresponding author: \nPaul Windisch, \npaulwindisch93@gmail.com\nAbstract\nIntroduction\nThe application of natural language processing (NLP) for extracting data from biomedical research has\ngained momentum with the advent of large language models (LLMs). However, the effect of different LLM\nparameters, such as temperature settings, on biomedical text mining remains underexplored and a\nconsensus on what settings can be considered “safe” is missing. This study evaluates the impact of\ntemperature settings on LLM performance for a named entity recognition and a classification task in clinical\ntrial publications.\nMethods\nTwo datasets were analyzed using GPT-4o and GPT-4o-mini models at nine different temperature settings\n(0.00-2.00). The models were used to extract the number of randomized participants and classify abstracts as\nrandomized controlled trials (RCTs) and/or as oncology-related. Different performance metrics were\ncalculated for each temperature setting and task.\nResults\nBoth models provided correctly formatted predictions for more than 98.7% of abstracts across temperatures\nfrom 0.00 to 1.50. While the number of correctly formatted predictions started to decrease afterward with\nthe most notable drop between temperatures 1.75 and 2.00, the other performance metrics remained largely\nstable.\nConclusion\nTemperature settings at or below 1.50 yielded consistent performance across text-mining tasks, with\nperformance declines at higher settings. These findings are aligned with research on different temperature\nsettings for other tasks, suggesting stable performance within a controlled temperature range across various\nNLP applications.\nCategories:\n Other, Healthcare Technology\nKeywords:\n large language models, natural language processing, temperature, text mining, transformer\nIntroduction\nUsing natural language processing (NLP) to extract data from biomedical research publications has garnered\nincreasing interest, particularly with the advent of more powerful architectures, most notably large language\nmodels (LLMs) \n[1-3]\n. The task itself has been of interest for a long time as the ability to automatically extract\nand structure information, e.g., according to PICO (patient, intervention, control, outcome) characteristics,\ncould improve various processes such as screening the literature for relevant publications, assessing\nadherence to reporting guidelines, and ultimately automating the process of evidence synthesis \n[4,5]\n.\nWhile the capability of LLMs for several of these text-mining tasks has been demonstrated previously, there\nis still relatively little information on the impact that different parameters or prompts might have \n[6,7]\n. A\nnotable parameter of LLMs is the temperature of its softmax function that turns the \"raw\" outputs (i.e., the\nlogits) into probabilities for the next token (i.e., the likeliest next part of a word). A high temperature leads\nto a flat probability distribution for the prediction of the next token, which makes the model more likely to\nchoose less conventional options \n[8]\n. This may increase the creativity of the output but also make the\nbehavior less predictive while increasing the risk of incoherent output. With a low-temperature setting, the\nmodel will choose only the most likely next token thus leading to a more predictive, coherent output with\nlimited creativity. Although anecdotal reports suggest decreasing performance for certain tasks at higher\n1,\n2\n2\n1\n1,\n2\n2\n1,\n2\n1\n \nOpen Access Original Article\nHow to cite this article\nWindisch P, Dennstädt F, Koechli C, et al. (December 15, 2024) The Impact of Temperature on Extracting Information From Clinical Trial\nPublications Using Large Language Models. Cureus 16(12): e75748. \nDOI 10.7759/cureus.75748\ntemperatures, some publications report consistent performance across a broad temperature range, such as in\nanswering multiple-choice questions or predicting clinical outcomes like in-hospital mortality from\nelectronic health records \n[9,10]\n. Thus, there is no consensus on what temperature range can be considered\n“safe,” i.e., which range is unlikely to result in decreasing performance.\nThe purpose of this project was to evaluate the impact of temperature settings on text-mining tasks for\nclinical trial publications, specifically to determine whether performance remains consistent across a wide\nrange of temperatures, as demonstrated for other tasks, and to identify the threshold beyond which\nperformance begins to decline \n[9,10]\n. As most text-mining tasks generally fall into the categories of either\nnamed-entity recognition or classification, we used two dedicated datasets for these tasks.\nMaterials And Methods\nTwo datasets that had been annotated as part of previous projects by the author group were used to create\ntasks for the evaluation of two LLMs, namely Generative Pretrained Transformer 4 Omni (GPT-4o, OpenAI,\nSan Francisco, United States) and GPT-4o mini at nine different temperature settings (0.00, 0.25, 0.50, 0.75,\n1.00, 1.25, 1.50, 1.75, 2.00) \n[11-14]\n. The respective versions that were used were the latest versions available,\nnamely gpt-4o-2024-05-13 and gpt-4o-mini-2024-07-18.\nThe first task was to extract the number of people who underwent randomization from the abstract of a\npublication reporting on a randomized clinical trial (RCT). To this end, a random sample of 996 RCTs from\nseven major journals (\nBritish Medical Journal, JAMA, JAMA Oncology, Journal of Clinical Oncology, Lancet,\nLancet Oncology, New England Journal of Medicine\n) published between 2010 and 2022 were labeled. The\nabstracts were retrieved as a txt file from PubMed and parsed using regular expressions (i.e., expressions that\nmatch certain patterns in text). For each trial, the number of randomized trial participants was retrieved by\nlooking at the abstract, followed by the full publication if the number could not be determined with certainty\nfrom the abstract. Two physician annotators carried out the annotation independently, and conflicts were\nresolved by discussing the differences afterward. \nThe LLMs were called via the application programming interface (API) with the aforementioned\ntemperatures and max_tokens set to 10 to stop the LLM in case of hallucinations associated with producing\nlarge amounts of incoherent output. All other API parameters were left at their default, which can be found\nin the documentation \n[15]\n. The system prompt was the following: “You will be provided with the abstract of\nan RCT. Your task will be to extract the number of people who underwent randomization. If this number is\nnot explicitly mentioned, you may use other numerical information (e.g. the number of total participants or\nadding up the number of patients in each arm). Please return only the number as a single integer. If no\ninformation is available, please return null.\"\nThe user prompt was the respective abstract. The raw responses were stored and afterward, each raw\nresponse was converted into an integer unless the conversion failed, e.g., due to the raw response being\nequal to “null” or due to non-numerical hallucinations.\nThe results were evaluated against the ground truth created by the human annotators. The percentage of\ncorrectly formatted, numerical predictions was calculated as well as performance metrics like the mean\nabsolute percentage error (MAPE) and the proportion of predictions that fell within a certain percentage of\nthe ground truth.\nThe second task was to classify an abstract regarding whether or not it was reported on an RCT and/or an\noncology topic. To this end, a random sample of 900 publications from the aforementioned seven major\njournals published between 2010 and 2022 were annotated. Publications that described RCTs received the\nlabel “RCT.” Publications that covered oncological topics received the label “ONCOLOGY.” Trials that\nfulfilled both criteria were assigned both labels. Trials that were neither RCTs nor covered oncology topics\nwere assigned no label. The two labels were chosen as each label poses different requirements to the LLM:\nFor the oncology label, the model does not need a deep contextual understanding but can rather make a\nprediction based on the presence of certain words that are associated with oncology publications, such as\n“cancer” or words related to staging and antineoplastic therapies. In order to assign the RCT label, the model\ncan not simply rely on the presence of words and phrases like “randomized” or “primary endpoint” as these\nmight also be present in other articles such as meta-analyses of RCTs. \nAnnotation was based on the title and abstract, which were also retrieved as a txt file from PubMed and\nparsed using regular expressions. Due to the relatively simple annotation process, annotation was carried\nout by a single physician annotator. The API call to the LLMs used the same settings as those for the first\ntask. The user prompt was again the abstract. The system prompt was the following: \"You will be provided\nwith the abstract of a medical publication. Your task will be to determine if the abstract reports on a RCT. If\nthe abstract reports on a systematic review or meta-analysis of RCTs or a commentary/editorial, return false.\nIn addition, you will be asked to determine if the abstract focuses on an oncology topic which includes all\npapers dealing with the prevention, diagnosis or treatment of solid or hematologic cancers. Your response\nshould be a list of two boolean values (True or False), the first indicating if the paper is an RCT and the\n \n2024 Windisch et al. Cureus 16(12): e75748. DOI 10.7759/cureus.75748\n2\n of \n9\nsecond indicating if the paper is oncology-related. The list should be enclosed in brackets and separated by a\ncomma, e.g. [True, False].\"\nThe raw responses were stored and afterward, the two boolean values were extracted unless the extraction\nfailed due to incorrect formatting. The results were evaluated against the ground truth by computing the\nproportion of correctly formatted predictions (i.e., a single integer or a list of two booleans in brackets\nseparated by a comma) as well as the confusion matrices for each label and several performance metrics\n(accuracy, precision, recall, and F1 score).\nAll programming was performed in Python (version 3.11.5) using, among others, the pandas (version 2.1.0)\nand openai (version 1.40.3) packages. This article was previously posted to the medRxiv preprint server on\nOctober 23, 2024.\nResults\nThe median number of people who underwent randomization was 668 with an interquartile range (IQR of\n300-1836) and a histogram of the respective number of people who underwent randomization in each trial is\npresented in Figure \n1A\n. The percentage of trials with correctly formatted numerical predictions made by\nGPT-4o was almost constant between temperatures 0.00 and 1.50, ranging from 98.7% to 99.0%. The first\nnoticeable drop occurred at temperature 1.75 with 95.6% with a further drop to 89.2% at temperature 2.00.\nThe same pattern could be seen with GPT-4o mini where temperatures between 0.00 and 1.50 resulted in\ntrials with correctly formatted numerical predictions between 99.0% and 99.1% and drops at 1.75 as well as\n2.00 (97.5% and 90.2%, respectively). A scatterplot of the predictions of the LLMs compared to the ground\ntruth is presented in Figure \n1B\n. The complete performance metrics are presented in Table \n1\n.\nFIGURE\n 1: Predicting or extracting the number of randomized trial\nparticipants\nA) Histogram of the trials and the respective number of randomized participants. B) Scatterplots where each dot\nrepresents a trial with its x-coordinate representing how many people were randomized and the y-coordinate\nrepresenting what GPT-4o (left) or GPT-4o mini (right) predicted in terms of how many people were randomized at\ntemperature 1.00. To ensure better visualization of the range that most trials fall into, only trials and predictions\nwith less than 10,000 randomized participants are displayed.\n \n2024 Windisch et al. Cureus 16(12): e75748. DOI 10.7759/cureus.75748\n3\n of \n9\nTemperature\nPredicted trials,\n%\nMAPE,\n%\nPredictions within 10% from ground\ntruth, %\nPredictions within 1% from ground\ntruth, %\nGPT-4o\n0.00\n98.7\n1.7\n96.9\n94.1\n0.25\n98.8\n1.8\n97.0\n94.0\n0.50\n98.7\n1.5\n97.3\n94.3\n0.75\n99.0\n2.3\n96.5\n93.6\n1.00\n98.8\n2.0\n96.5\n93.7\n1.25\n98.7\n1.7\n96.6\n93.7\n1.50\n98.7\n3.8\n96.2\n93.4\n1.75\n95.6\n1.8\n96.7\n94.2\n2.00\n89.2\n1.0\n98.0\n95.3\nGPT-4o mini\n0.00\n99.1\n1.5\n96.8\n92.7\n0.25\n99.1\n1.5\n96.8\n92.7\n0.50\n99.0\n1.3\n97.0\n93.1\n0.75\n99.1\n1.4\n96.9\n92.7\n1.00\n99.1\n1.4\n96.7\n92.9\n1.25\n99.1\n1.3\n97.0\n93.1\n1.50\n99.1\n1.5\n96.7\n92.8\n1.75\n97.5\n1.6\n96.4\n92.4\n2.00\n90.2\n1.6\n96.7\n92.9\nTABLE\n 1: Performance of GPT-4o and GPT-4o mini when asked to extract the number of patients\nwho were randomized from the abstract of a publication reporting on an RCT\n“Predicted trials” indicates the percentage of trials for which a correctly formatted, numerical prediction was returned.\nRCT, randomized controlled trial; MAPE, mean absolute percentage error\nWhen analyzing only the correctly formatted predictions, the performance in terms of MAPE and the\nproportion of predictions within a certain margin of error did not show a major drop beyond a certain\ntemperature. On the contrary, for GPT-4o, a temperature of 2.00 resulted in the lowest MAPE and the highest\nproportion of predictions within 10% and 1% of the ground truth.\nA confusion matrix on the distribution of RCTs and oncology trials is presented in Figure \n2A\n. 46.8% of trials\nwere RCTs and 26.9% covered an oncology topic. The predictions of the LLMs compared to the ground truth\nfor each label are presented in the confusion matrices in Figure \n2B\n. The performance metrics are presented\nin Table \n2\n (RCT) and Table \n3\n (oncology). The classification task resulted in trials with correctly formatted\npredictions in 100% of abstracts with both models and labels for temperatures at or below 1.25. The biggest\ndrop occurred again between temperatures 1.75 (98.9% for GPT-4o and 97.7% for GPT-4o mini) and 2.00\n(93.3% for GPT-4o and 92.4% for GPT-4o mini) for both labels. The F1 scores for the label RCT ranged from\n0.956 to 0.960 for GPT-4o and 0.914 to 0.921 for GPT-4o mini. The F1 scores for the label oncology ranged\nfrom 0.965 to 0.977 for GPT-4o and 0.964 to 0.972 for GPT-4o mini.\n \n2024 Windisch et al. Cureus 16(12): e75748. DOI 10.7759/cureus.75748\n4\n of \n9\nFIGURE\n 2: Trial classification\nConfusion matrix regarding whether or not the abstract of a publication reports on an RCT and whether or not it\nreports on an oncology topic. B) Confusion matrices for the predictions of GPT-4o (left) or GPT-4o mini (right) at a\ntemperature of 1.00 regarding whether or not the abstract of a publication reports on an RCT (top) and whether or\nnot it reports on an oncology topic (bottom).\nRCT, randomized controlled trial\n \n2024 Windisch et al. Cureus 16(12): e75748. DOI 10.7759/cureus.75748\n5\n of \n9\nTemperature\nPredicted trials, %\nAccuracy\nPrecision\nRecall\nF1 score\nGPT-4o\n0.00\n100.0\n0.957\n0.915\n1.000\n0.956\n0.25\n100.0\n0.959\n0.919\n1.000\n0.958\n0.50\n100.0\n0.957\n0.915\n1.000\n0.956\n0.75\n100.0\n0.958\n0.917\n1.000\n0.957\n1.00\n100.0\n0.960\n0.921\n1.000\n0.959\n1.25\n100.0\n0.960\n0.921\n1.000\n0.959\n1.50\n99.9\n0.961\n0.923\n1.000\n0.960\n1.75\n98.9\n0.960\n0.921\n1.000\n0.959\n2.00\n93.3\n0.957\n0.916\n1.000\n0.956\nGPT-4o mini\n0.00\n100.0\n0.915\n0.847\n1.000\n0.917\n0.25\n100.0\n0.918\n0.851\n1.000\n0.919\n0.50\n100.0\n0.915\n0.847\n1.000\n0.917\n0.75\n100.0\n0.919\n0.852\n1.000\n0.920\n1.00\n100.0\n0.920\n0.854\n1.000\n0.921\n1.25\n100.0\n0.917\n0.849\n1.000\n0.918\n1.50\n99.6\n0.918\n0.852\n1.000\n0.920\n1.75\n97.7\n0.916\n0.849\n1.000\n0.918\n2.00\n92.4\n0.911\n0.842\n1.000\n0.914\nTABLE\n 2: Performance of GPT-4o and GPT-4o mini when asked to predict if an abstract of a\npublication reported on an RCT\n“Predicted trials” indicates the percentage of trials for which a correctly formatted prediction was returned.\nRCT, randomized controlled trial\n \n2024 Windisch et al. Cureus 16(12): e75748. DOI 10.7759/cureus.75748\n6\n of \n9\nTemperature\nPredicted trials, %\nAccuracy\nPrecision\nRecall\nF1 score\nGPT-4o\n0.00\n100.0\n0.983\n0.967\n0.971\n0.969\n0.25\n100.0\n0.982\n0.963\n0.971\n0.967\n0.50\n100.0\n0.984\n0.967\n0.975\n0.971\n0.75\n100.0\n0.983\n0.963\n0.975\n0.969\n1.00\n100.0\n0.982\n0.963\n0.971\n0.967\n1.25\n100.0\n0.983\n0.963\n0.975\n0.969\n1.50\n99.9\n0.981\n0.963\n0.967\n0.965\n1.75\n98.9\n0.988\n0.967\n0.988\n0.977\n2.00\n93.3\n0.985\n0.970\n0.974\n0.972\nGPT-4o mini\n0.00\n100.0\n0.983\n0.952\n0.988\n0.970\n0.25\n100.0\n0.983\n0.952\n0.988\n0.970\n0.50\n100.0\n0.984\n0.956\n0.988\n0.972\n0.75\n100.0\n0.982\n0.945\n0.992\n0.968\n1.00\n100.0\n0.984\n0.956\n0.988\n0.972\n1.25\n100.0\n0.984\n0.956\n0.988\n0.972\n1.50\n99.6\n0.980\n0.937\n0.992\n0.964\n1.75\n97.7\n0.981\n0.940\n0.992\n0.965\n2.00\n92.4\n0.983\n0.953\n0.987\n0.970\nTABLE\n 3: Performance of GPT-4o and GPT-4o mini when asked to predict if an abstract of a\npublication reported on an oncology topic\n“Predicted trials” indicates the percentage of trials for which a correctly formatted prediction was returned.\nDiscussion\nIn this study, temperatures at or below 1.50 yielded comparable results and the most pronounced drop in\nperformance occurred between temperatures 1.75 and 2.00. Notably, the drop in performance only occurred\nwith regard to the proportion of correctly formatted predictions while the error metrics of the correctly\nformatted predictions remained constant and in some cases even improved. A possible explanation for this\nseemingly counterintuitive improvement could be that abstracts in which the number of people randomized\nis not explicitly stated, requiring the model to infer it from the available information, are more likely to\ntrigger hallucinations. Thus, more difficult abstracts end up with incorrectly formatted predictions, which\nresults in better performance when looking only at the correctly formatted predictions. These findings\nregarding text mining are largely consistent with Patel and colleagues who saw a consistent performance of\nvarious LLMs (GPT-4, GPT-3.5, and Llama-3-70b) for various clinical tasks across a temperature range from\n0.2 to 1.0 as well as Renze and colleagues who saw consistent results for an even wider array of LLMs\nbetween temperatures of 0.0 to 1.0 \n[9,10]\n. If a hallucination occurred, it consisted of nonsensical output that\nsometimes also contained the desired prediction, usually at the beginning (e.g. “849 Duits.BOTTOM XTrella\nBrent\n涩\n \nуру\n instituto.zaxxer” or ”[True, False]ynamicsCookingocious_student yhtä”).\nA second insight of this observation is that specifying a desired output format via the prompt could facilitate\nthe detection of hallucinations. This raises the question of whether forcing the LLM to adhere to a specific\noutput format, such as using features like Structured Outputs or JSON mode, could eliminate this behavior\nand result in more incorrect predictions being correctly formatted. This topic warrants further research. \nAnother interesting observation is the difference in performance between GPT-4o and GPT-4o-mini when\n \n2024 Windisch et al. Cureus 16(12): e75748. DOI 10.7759/cureus.75748\n7\n of \n9\npredicting whether an abstract reports on an RCT, whereas their performance was similar when predicting\nwhether the abstract pertains to an oncology topic. A possible explanation for this is that determining if an\nabstract pertains to an oncology topic is a simpler task, as it mainly requires recognizing which words in the\nabstract are associated with oncology. To determine if an abstract reports on an RCT, one cannot only rely\non the terminology but has to understand the context. As an example, the phrase “randomized controlled\ntrial” can occur in an abstract reporting on an RCT, but also in a systematic review that includes RCTs.\nTherefore, it seems plausible that the more powerful model, i.e., GPT-4o, performs better at this task.\nThis study is limited by the fact that only OpenAI models were used to analyze the different temperature\nsettings. However, the evaluation studies of different temperature settings for other tasks such as those\nmentioned previously indicate that the findings are likely to generalize to other architectures \n[9,10]\n.\nFurthermore, other factors influencing the output of the LLM, such as the choice of model, additional model\nparameters, or different prompts, were not investigated \n[16]\n. The specific setting of these factors can\ninfluence each other as well as the output and, in turn, the performance and should be investigated in the\nfuture. While it seems unlikely that changes in these factors would yield substantially different results, one\nshould be aware of this fact when interpreting this study and likely do at least a focused evaluation of\ndifferent parameters for the task that one is trying to accomplish.\nAs a potential outlook, one could try to create more robust text-mining workflows by sending the same or\nslightly varied prompts to models with different temperature settings in the seemingly safe range of\ntemperatures from 0.00 to 1.50. If all models are in agreement, the prediction is considered correct. If there\nis a disagreement, a manual review is triggered. This workflow could also be implemented to reduce costs if,\ne.g., three predictions from small, cheaper models at different temperatures are requested and a more\nexpensive model is only used if there is a disagreement.\nConclusions\nIn conclusion, temperature settings at or below 1.50 seem to result in comparable performance for extracting\ninformation from medical publications. These findings are aligned with research on different temperature\nsettings for other tasks, suggesting that a safe temperature range may be consistent across a variety of\napplications. A focused evaluation of different parameters for the task that one is trying to accomplish when\nusing an LLM is recommended considering the uncertainty regarding the relationship between different\nparameters.\nAdditional Information\nAuthor Contributions\nAll authors have reviewed the final version to be published and agreed to be accountable for all aspects of the\nwork.\nConcept and design:\n  \nPaul Windisch\nAcquisition, analysis, or interpretation of data:\n  \nPaul Windisch, Fabio Dennstädt, Carole Koechli,\nChristina Schröder, Daniel M. Aebersold, Robert Förster, Daniel R. Zwahlen\nDrafting of the manuscript:\n  \nPaul Windisch\nCritical review of the manuscript for important intellectual content:\n  \nFabio Dennstädt, Carole Koechli,\nChristina Schröder, Daniel M. Aebersold, Robert Förster, Daniel R. Zwahlen\nDisclosures\nHuman subjects:\n All authors have confirmed that this study did not involve human participants or tissue.\nAnimal subjects:\n All authors have confirmed that this study did not involve animal subjects or tissue.\nConflicts of interest:\n In compliance with the ICMJE uniform disclosure form, all authors declare the\nfollowing: \nPayment/services info:\n All authors have declared that no financial support was received from\nany organization for the submitted work. \nFinancial relationships:\n All authors have declared that they have\nno financial relationships at present or within the previous three years with any organizations that might\nhave an interest in the submitted work. \nOther relationships:\n All authors have declared that there are no\nother relationships or activities that could appear to have influenced the submitted work.\nAcknowledgements\nRobert Förster and Daniel R. Zwahlen contributed equally to the work and should be considered co-last\nauthors. All data and code used for the analysis have been uploaded to https://github.com/windisch-\npaul/temperature. The dataset has also been submitted to Dryad.\nReferences\n \n2024 Windisch et al. Cureus 16(12): e75748. DOI 10.7759/cureus.75748\n8\n of \n9\n1\n. \nVaswani A, Shazeer NM, Parmar N, et al.: \nAttention is all you need\n. Adv Neural Inf Process Syst. 2017,\n5998:6008. \n10.48550/arXiv.1706.03762\n2\n. \nWallace BC, Small K, Brodley CE, Lau J, Trikalinos TA: \nDeploying an interactive machine learning system in\nan evidence-based practice center: abstrackr\n. Proceedings of the 2nd ACM SIGHIT International Health\nInformatics Symposium. 2012, 819-24. \n10.1145/2110363.2110464\n3\n. \nBeltagy I, Lo K, Cohan A: \nSciBERT: a pretrained language model for scientific text\n. arXiv. 2019,\narXiv:1903.10676. \n10.48550/arXiv.1903.10676\n4\n. \nKilicoglu H, Rosemblat G, Hoang L, et al.: \nToward assessing clinical trial publications for reporting\ntransparency\n. J Biomed Inform. 2021, 116:103717. \n10.1016/j.jbi.2021.103717\n5\n. \nMarshall IJ, Nye B, Kuiper J, et al.: \nTrialstreamer: a living, automatically updated database of clinical trial\nreports\n. J Am Med Inform Assoc. 2020, 27:1903-12. \n10.1093/jamia/ocaa163\n6\n. \nWadhwa S, DeYoung J, Nye B, Amir S, Wallace BC: \nJointly extracting interventions, outcomes, and findings\nfrom RCT reports with LLMs\n. arXiv. 2023, arXiv:2305.0364. \n10.48550/arXiv.2305.03642\n7\n. \nYun HS, Pogrebitskiy D, Marshall IJ, Wallace BC: \nAutomatically extracting numerical results from RCTs with\nLLMs\n. Machine Learning for Healthcare (MLHC), Toronto, Canada; 2024.\nhttps://par.nsf.gov/biblio/10523780\n.\n8\n. \nPeeperkorn M, Kouwenhoven T, Brown D, Jordanous A: \nIs temperature the creativity parameter of large\nlanguage models?\n. arXiv. 2024, arXiv:2405.00492. \n10.48550/arXiv.2405.00492\n9\n. \nRenze M, Guven E: \nThe effect of sampling temperature on problem solving in Large Language Models\n. arXiv.\n2024, arXiv:2402.05201. \n10.48550/arXiv.2402.05201\n10\n. \nPatel D, Timsina P, Raut G, et al.: \nExploring temperature effects on large language models across various\nclinical tasks\n. medRxiv. 2024, 2024-07. \n10.1101/2024.07.22.24310824\n11\n. \nMedical publications with information as to whether a publication reports a randomized controlled trial\nand/or if it covers an oncology topic\n. (2024). Accessed: December 15, 2024:\nhttp://10.5061/DRYAD.GB5MKKX00\n.\n12\n. \nRandomized controlled clinical trials with tagged information regarding the number of participants\n. (2024).\nAccessed: December 15, 2024: \nhttp://10.5061/DRYAD.G1JWSTR0B\n.\n13\n. \nWindisch P, Dennstädt F, Koechli C, Förster R, Schröder C, Aebersold DM, Zwahlen DR: \nA pipeline for the\nautomatic identification of randomized controlled oncology trials and assignment of tumor entities using\nnatural language processing\n. medRxiv. 2024, \n10.1101/2024.07.01.24309767\n14\n. \nWindisch P, Dennstädt F, Koechli C, Förster R, Schröder C, Aebersold DM, Zwahlen DR: \nPredicting the\nsample size of randomized controlled trials using natural language processing\n. JAMIA Open. 2024,\n7:ooae116. \n10.1093/jamiaopen/ooae116\n15\n. \nOpenAI Platform\n. (2024). Accessed: December 13, 2024: \nhttps://platform.openai.com/docs/api-\nreference/chat/create.\n.\n16\n. \nMizrahi M, Kaplan G, Malkin D, Dror R, Shahaf D, Stanovsky G: \nState of what art? A call for multi-prompt\nLLM evaluation\n. Trans Assoc Comput Linguist. 2024, 12:933-49. \n10.1162/tacl_a_00681\n \n2024 Windisch et al. Cureus 16(12): e75748. DOI 10.7759/cureus.75748\n9\n of \n9"
}