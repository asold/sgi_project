{
  "title": "A Task-Oriented Dialogue Architecture via Transformer Neural Language Models and Symbolic Injection",
  "url": "https://openalex.org/W3184152240",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A5018578941",
      "name": "Oscar J. Romero",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    },
    {
      "id": "https://openalex.org/A5024767859",
      "name": "Antian Wang",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    },
    {
      "id": "https://openalex.org/A5068413510",
      "name": "John Zimmerman",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    },
    {
      "id": "https://openalex.org/A5108044002",
      "name": "Aaron Steinfeld",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    },
    {
      "id": "https://openalex.org/A5027233041",
      "name": "Anthony Tomasic",
      "affiliations": [
        "Carnegie Mellon University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3102266550",
    "https://openalex.org/W3100715140",
    "https://openalex.org/W2251235149",
    "https://openalex.org/W3034533785",
    "https://openalex.org/W2051768896",
    "https://openalex.org/W3004786215",
    "https://openalex.org/W2963009325",
    "https://openalex.org/W2805406810",
    "https://openalex.org/W4287795696",
    "https://openalex.org/W2988647680",
    "https://openalex.org/W3005231694",
    "https://openalex.org/W3121541553",
    "https://openalex.org/W1948566616",
    "https://openalex.org/W4288624561",
    "https://openalex.org/W2117043847",
    "https://openalex.org/W2127838323",
    "https://openalex.org/W2962831269",
    "https://openalex.org/W3112180926",
    "https://openalex.org/W3024509506",
    "https://openalex.org/W2963789888",
    "https://openalex.org/W3021016503"
  ],
  "abstract": "Recently, transformer language models have been applied to build both task- and non-task-oriented dialogue systems. Although transformers perform well on most of the NLP tasks, they perform poorly on context retrieval and symbolic reasoning. Our work aims to address this limitation by embedding the model in an operational loop that blends both natural language generation and symbolic injection. We evaluated our system on the multi-domain DSTC8 data set and reported joint goal accuracy of 75.8% (ranked among the first half positions), intent accuracy of 97.4% (which is higher than the reported literature), and a 15% improvement for success rate compared to a baseline with no symbolic injection. These promising results suggest that transformer language models can not only generate proper system responses but also symbolic representations that can further be used to enhance the overall quality of the dialogue management as well as serving as scaffolding for complex conversational reasoning.",
  "full_text": "Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 438–444\nJuly 29–31, 2021. ©2021 Association for Computational Linguistics\n438\nA Task-Oriented Dialogue Architecture via Transformer Neural\nLanguage Models and Symbolic Injection\nOscar J. Romero, Antian Wang, John Zimmerman, Aaron Steinfeld, Anthony Tomasic\nCarnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA, 15213, USA\n{oscarr, antianw, johnz, as7s, tomasic}@andrew.cmu.edu\nAbstract\nRecently, transformer language models have\nbeen applied to build both task- and non-task-\noriented dialogue systems. Although trans-\nformers perform well on most of the NLP\ntasks, they perform poorly on context retrieval\nand symbolic reasoning. Our work aims to ad-\ndress this limitation by embedding the model\nin an operational loop that blends both natural\nlanguage generation and symbolic injection.\nWe evaluated our system on the multi-domain\nDSTC8 data set and reported joint goal accu-\nracy of 75.8% (ranked among the ﬁrst half po-\nsitions), intent accuracy of 97.4% (which is\nhigher than the reported literature), and a 15%\nimprovement for success rate compared to a\nbaseline with no symbolic injection. These\npromising results suggest that transformer lan-\nguage models can not only generate proper\nsystem responses but also symbolic represen-\ntations that can further be used to enhance the\noverall quality of the dialogue management as\nwell as serving as scaffolding for complex con-\nversational reasoning.\n1 Introduction\nBuilding task-oriented dialogue systems using a\nconventional pipeline approach, where modules\nare optimized separately, increases the ﬁne control\nfor dialogue management, but it does not necessar-\nily improve overall performance (Madotto et al.,\n2018; Liu and Lane, 2018). In contrast, end-to-end\nneural models employ a straightforward training\napproach to generating system responses; however,\nthis approach is impractical for goal-oriented di-\nalogues where the system needs to interact with\nexternal systems or generate an explanation that\nsupports its decisions (Ham et al., 2020).\nRecently, the use of transformer models for\nbuilding end-to-end dialogue systems has attracted\nconsiderable attention (Budzianowski and Vuli ´c,\n2019; Yang et al., 2020); however, as far as we\nknow, current approaches operate solely at the text\n(word) level. We extend this approach to utilize\ntransformer model’s versatility to generate more\ncomplex constructs such as symbol representations.\nIn this paper, we propose a hybrid approach. We\nﬁrst apply a ﬁne-tuned, end-to-end transformer\nmodel for multi-domain task-oriented dialogue.\nThen, during inference, we decouple the execution\ninto expert modules that collaboratively process the\ncontent of a common knowledge base (resembling\nthe blackboard architecture (Erman et al., 1980)).\nIn our experiments, we empirically demonstrate\nthat the transformer model can be ﬁne-tuned to gen-\nerate not only text from a given input but also sym-\nbolic representations (e.g., utterances →dialogue\nstates), manipulate those symbolic representations\nto generate new ones (e.g., dialogue states →sys-\ntem actions), and generate natural language from\nsymbols (e.g., system actions→system response).\nThis work led us to a new generic reasoning\narchitecture that leverages the ability of a trans-\nformer model to effectively manipulate representa-\ntions that are mixtures of natural and symbolic lan-\nguage. The result is a simple architecture that uses\na uniform representation to blend together dialogue\naspects of interpretation, language understanding\nand generation, and behavior.\n2 Method\nArchitecture: Our system resembles a blackboard\narchitecture (Erman et al., 1980) (Figure 1) with\na central memory blackboard and seven modules\nthat implement different steps of the dialogue.\nBlackboard: It provides a global memory where\npieces of knowledge (history, user’s intents and\ngoals, system actions, etc.) are continuously up-\ndated by modules to maintain the dialogue context.\nForget: This module shortens sequence inputs\nthat surpass the maximum limit of tokens that a\ntransformer model can process at a time (in our\ncase, 1,024 tokens for GPT-2). Additional input\ntokens beyond this limit are truncated, potentially\n439\nBlackboard\n(Dialogue Context)\nWord-level DST (GPT-2) Dialogue\nHistory\nDialogue Interface\nuser\nutterance\nForget\nService \nCall\nService \nResults\nSystem\nResponse\nSystem\nActions\nHistory\nDST\nSlot-Values Validator\nPOL (GPT-2)\nService Executor\nBuses\nHotel\nFlights\nTrain\nShared Ride\nEvents…\nService \nCall\nHistory Modified \nslot values\nValidatorSlot values\nHistory\nDST\nServ. \nResults\nSystem\nActions\nDecoder\nNLG (GPT-2)\nHistory\nDST\nResults\nSys acts\nSystem\nResponse\nDecoder\nDecoder\nHistory\nHistory\nDST \nServ Call\nHistory, DSTDST\nServ. Call Serv. Results\nSys actions\nHist, DST\nRes, Sys act\nDelexicalized\nSys Resp.\nsys\nutterance\nHist, DST, Ser Res.\nDST\nFigure 1: Dialogue System Architecture. Arrows illustrate retrieving/updating information from/to the blackboard.\nBoxes labeled GPT-2 (DST, POL, NLG) represent the same neural module which is invoked multiple times using\ndifferent aggregated inputs. Dotted boxes contain symbols and double-line boxes contain natural language.\ndiscarding relevant symbols needed for dialogue\nprocessing. Instead, this module discards only the\noldest (non-symbolic) elements in dialogue history\nto keep the input token size within the limit. A\nmore sophisticated component that is more selec-\ntive in discarding irrelevant information, chunking\ninformation, etc., is left as future work.\nWord-level Dialogue State Tracking (DST): The\ntransformer model takes the dialogue history as in-\nput and generates a symbolic dialogue state as out-\nput. Since the dialogue state’s symbols (i.e., intent,\nservice, and slot values) can be directly mapped\ninto a service call, the model also outputs a call\nsignature when all the required slots are met. Then,\ngenerated symbols are injected into the blackboard.\nSlot-Values Validator: It checks whether the dia-\nlogue state’s symbols were correctly predicted and,\nif so, they are injected back into the blackboard.\nService Executor: given a generated service call,\nthe service executor queries the database and pub-\nlishes the results on the blackboard.\nDialogue Policy (POL): Based on the current\ncontext, this module uses the transformer model\nto generate the next system actions (symbolic con-\nstructs that contain acts, slots, and values).\nNatural Language Generation (NLG): Taking\nthe current context as input, this module uses the\ntransformer model to generate a natural language\nsystem response.\nFinally, we implemented a control component\nthat orchestrates modules’ activation, allowing\nthem to manipulate back and forth the content of\nthe blackboard (a mixture of multi-domain, multi-\nintent symbols and natural language – see Alg. 1).\nFine-tuning: During training, we ﬁne-tuned a pre-\ntrained GPT-2 transformer model using 16,548\ndialogues from the DSTC8 dataset described in\nsection 3. To this purpose, we ﬁrst pre-processed\nthe data by encoding dialogue annotations into se-\nquences of symbolic representation segments (for\nconvenience, we used a Prolog-like syntax), inter-\nmixed with natural language. Then, we encoded a\nset of 9 special tokens, added them to our vocab-\nulary for delimiters and segment indicators, and\nconcatenated the segments as follows:\n<bos><usr>...<sys>...<usr>...<dst>...\n<svc>...<svr>...<sac>...<sut>...<eos>\nWhere <bos> and <eos> demarcate the begin-\nning and end of an example; <usr> and <sys>\nrepresent the history of both user and system utter-\nances; <dst> is the symbolic segment for the dia-\nlogue state tracker; <svc> and <svr> correspond to\nthe service call and service result segments, respec-\ntively; <sac> are the system actions; and <sut>\nis the system utterance. Then, the forget module\ntruncated each example as we describe before.\nAlthough we ﬁne-tuned the neural model end-\nto-end, during the test phase, we broke down the\ngeneration process into 3 main steps resembling the\nexecution of a pipelined dialogue system (except\nthat inputs to each module are composite structures\nof symbols and natural language that are assembled\nincrementally), as we described above (i.e., DST,\nPOL, and NLG). This architectural breakdown al-\nlowed us to add new experts that intercept each\nmodule’s outputs, manipulate the corresponding\nsymbols, and inject the updates into the context\nmaintained by the blackboard.\n440\nExample: consider the following snippet of a dia-\nlogue from the DSTC8 data set (in json format):\n\"turns\": [\n{\n\"speaker\": \"USER\",\n\"utterance\": \"I need to take a bus from\nLas Vegas to San Francisco\",\n\"user_acts\": ...\n...\n\"state\": {\n\"active_intent\": \"FindBus\",\n\"requested_slots\": [],\n\"slot_values\": {\n\"from_location\": [\n\"Las Vegas\"\n]\n...\n}}\n},\n{\n\"speaker\": \"SYSTEM\",\n\"utterance\": \"sure, I found 3 buses.\nOne departs tomorrow at 10am...\",\n\"sys_acts\": ...\n...\n\"service_call\": {\n\"method\": \"FindBus\",\n\"parameters\": {\n\"from_location\": \"Las Vegas\",\n...\n}\n},\n\"service_results\": [\n{\n\"category\": \"direct\",\n\"departure_date\": \"2019-03-13\",\n...\n}]}\n...\n]\nWhile user/system utterances do not require any\nchange before being encoded as part of the ﬁne-\ntuning data set (e.g., <usr>I need to take...),\nannotations for dialogue state, service calls and\nresults, and system actions are encoded as Prolog-\nlike compound terms (atoms followed by a comma-\nseparated list of argument terms with variable arity).\nFor instance, the dialogue state contains argument\nterms for the type of service, user’s intent, and the\nslot values provided by the user:\n<dst>\nhas(\nstate,[\nservice(Buses),\nintent(FindBus),\nslot_values(\nfrom_location,[‘‘Las Vegas’’],\n...\n)])\nLikewise, the symbolic representation of the\nservice call contains argument terms that corre-\nspond to mappings between active intent and ser-\nvice method, and slot values and call parameters:\n<svc>\ncall(\nBuses, [\nmethod(FindBus),\nparameters(\nfrom_location,[‘‘Las Vegas’’],\n...\n)])\nThe service results are encoded as a list of com-\npound terms, as follows:\n<svr>\nresults([\nidx1(slots,[\ncategory(‘‘direct’’),\n...\n]),\nidx2(slots,[\n...]\n])\nFinally, the system action contains argument\nterms for the the type of dialogue act, the slots,\nand their corresponding values:\n<sac>\naction(\nact(INFORM),\nslot(departure_time),\nvalue(10am)])\n...)\n3 Experiment Framework\nWe used the open-source implementation of GPT-\n2-small transformer model1 with values for Adam\nlearning rate (5.75e-5), epsilon for Adam optimizer\n(1e-8), and batch size (4). To generate more coher-\nent text as proposed by Welleck et al. (2020), we\nset parameters top-p nucleus sampling (0.95) and\ntop-k sampling (50) using grid search.\nWe utilized the Schema-Guided data set pro-\nposed at the Dialogue System Technology Chal-\nlenge DSTC8-Task42. We chose this data set due\nto: 1) its rich annotations across the whole dia-\nlogue pipeline; 2) its size that exceeds the existing\ndialogue corpora in scale (with over 20K multi-\ndomain, task-oriented dialogues spanning 45 APIs\nover 20 domains); and 3) it contains a signiﬁcant\namount of dialogues for the transportation domain3.\nIn this work, we only tested dialogues containing\ndomains/services shown during training although\nunseen slot values were allowed (the evaluation of\nunseen domains is left as future work).\n1https://github.com/huggingface/transformers\n2github.com/google-research-datasets/dstc8-schema-\nguided-dialogue\n3Our long-term goal is to explore the limits of the proposed\nhybrid approach in the context of mitigating accessibility barri-\ners when accessing transportation information, e.g., (National\nCouncil on Disability, 2015; Steinfeld et al., 2017)\n441\nSince the DSTC8 challenge does not provide\nSQL scripts or equivalent, we reverse-engineered\nthe database results from the data set and imple-\nmented our own services database.\nWe carried out automatic evaluation of our sys-\ntem on 2,361 dialogues using diverse metrics. For\nDST, we used the metrics provided with the data\nset, measuring: average goal accuracy(accuracy\nof predicting the value of a slot correctly), joint\ngoal accuracy(average accuracy of predicting all\nslot assignments for a turn correctly), active intent\naccuracy (a fraction of user turns for which the\nintent was rightly predicted), and requested slot F1\n(the macro-averaged F1 score for requested slots\nover all eligible user turns). In addition, we ex-\ntended these metrics to measure system actions in\na similar way: service call accuracy, joint param-\neter accuracy, and joint system action accuracy.\nAlso, we used success ratefor system performance,\nand BLEU for ﬂuency of the generated response.\nHuman evaluation is left as future work.\nFinally, post hoc, we ran an error analysis that\nlet us identify the kind of error that affected system\nperformance the most, allowing us to build a simple\nheuristic-based expert that focused on measuring\nparticular kinds of modeling errors to identify areas\nfor improving overall performance.\n4 Results\nWe ran 3 different experiments as follows:\nExpo: in order to ensure a fair comparison between\nthe results reported in Rastogi et al. (2020) and our\nsystem’s performance results, this experiment uses\nthe ground truth values (oracle) of both user and\nsystem utterances. This experiment uses DSTC8\nmetrics and data, so our results can be compared\ndirectly to published results (26 approaches).\nExpg: history is composed of gold user utterances\nand system utterances generated by our system. As\nopposed to the oracle experiment above, this ex-\nperiment captures cascading errors that propagate\nfrom earlier steps to later steps in a dialogue.\nExpv: a heuristic-based slot-value validator is\nadded to Expo to improve performance. For illus-\ntrative purposes only, this experiment measured the\nimpact of mitigating the most critical errors (from\nerror analysis) by manipulating symbols generated\nby GPT-2 (Expg). These results precisely identify\nweaknesses in the current model.\nDST Evaluation Results: overall, when compared\nto the seen-services results reported in Rastogi et al.\nApproach JGA AGA IA RSF1\nTeam 9 0.924 0.979 0.957 0.993\nTeam 10 0.920 0.978 0.956 0.847\nExpv 0.917 0.956 0.974 0.985\nTeam 8 0.910 0.970 N.A. 0.847\nTeam 14 0.900 0.960 0.957 0.996\nTeam 5 0.893 0.966 0.959 0.992\nExpo 0.758 0.939 0.974 0.985\nExpg 0.639 0.892 0.935 0.974\nBaseline 0.412 0.677 0.950 0.995\nTable 1: Overall results of DST evaluation. JGA: joint\ngoal accuracy, AGA: average goal accuracy, IA: intent\naccuracy, and RSF1: requested slot F1 score. Due to\nspace constraints, we only include the top-5 results re-\nported in Rastogi et al. (2020).\n(2020), our system outperformed other models on\nintent accuracy (see Table 1). Correctly predicting\nthe intent demonstrates the ability of our system\nto track user’s intentions and effectively detect do-\nmain switches. In addition, if we consider the 26\nteams who participated in DSTC8-T4, our system\nranks among the ﬁrst half positions in Expo and the\nﬁrst 2/3 positions in Expg. Finally, Expv made an\nimprovement in JGA of 21% and 43% over Expo\nand Expg, respectively. Details of the heuristic-\nbased module are described in the next section.\nError Analysis: from all the reported metrics,\nwe focused on the results obtained for the Joint\nGoal Accuracy (JGA) for two reasons: 1) JGA is\nthe primary evaluation metric used for ranking ap-\nproaches submitted to DSTC8-Task4; and 2) this\nmetric got the lowest scores for Exp o and Expg\namong all the evaluation metrics (see Table 1).\nFrom the error analysis, we found 3 main kinds\nof errors that affect JGA: 1) slot names were cor-\nrectly predicted but slot values were not (10.5%\nof errors); 2) slot names that appeared in the gold\nDST but were not predicted by the system (29.1%);\nand 3) slot names that were predicted but did not\nappear in the gold DST (60.4%).\nGiven its signiﬁcant presence, we focus on the\nthird kind of error. The main causes for this error\nto occur are: 1) the slot value is predicted but not\nmentioned by either the user or the system in the di-\nalogue history (over-ﬁtting); and 2) the slot value is\nmentioned/offered by the system but not accepted\nby the user (e.g., the system says “There is a direct\nbus that departs at 9:50 am and costs $36.”, where\nthe slot trip_fare was unsolicited by the user, and\nthen the user says “hmm any buses departing in the\n442\nAppr. SCA JPA JSA SR BLEU\nExpv 0.927 0.891 0.786 82.21% 2.14\nExpo 0.927 0.828 0.786 80.45% 2.05\nExpg 0.873 0.703 0.748 71.25% 1.63\nTable 2: Overall results of the System Actions evalu-\nation. SCA: service call accuracy, JPA: joint service\ncall’s parameter accuracy, JSA: joint system action ac-\ncuracy, and SR: success rate.\nafternoon?” only conﬁrming departure_time).\nWe implemented a heuristic-basedslot-value val-\nidator to mitigate the error above. First, we ex-\ntracted and classiﬁed all the slot values from the\ntraining data set and store them in a dictionary.\nThen, a set of heuristic rules based on fuzzy string\nmatching determine whether a slot value is present\nin the dialogue history by calculating its similarity\nwith the values in the dictionary, ﬁxing the ﬁrst\ncause of the error. Next, if the slot value is men-\ntioned only by the system, the value is retained\nonly if the system offered the value at any prior\nturn (i.e., sys_act: ‘‘OFFER’’) and the user ac-\ncepted the offered slot value in the next turn (i.e.,\nuser_act: ‘‘SELECT’’ | ‘‘AFFIRM’’).\nSystem Actions and Performance Results: From\nTable 2, Exp o mainly improved JPA, SR, and\nBLEU over Expg by 18%, 13%, and 26%, respec-\ntively. Clearly, some down-stream error propaga-\ntion occurs. On the other hand, Exp v slightly im-\nproved JPA (8%) over Expo due to ﬁxing some of\nthe DST issues also improved the quality of predict-\ning service parameters. Finally, although BLEU\nscores are low (due to there was available only one\nsingle reference value per turn), they are paired\nwith high success rates – in fact, a manual inspec-\ntion of system utterances indicates an overall high\nquality of language generation (see Figure 2).\n5 Related Work\nIn comparison with traditional pipelined dialogue\narchitectures (Chen et al., 2017; Bohus and Rud-\nnicky, 2009) where NLU (Lee et al., 2019),\nDST (Williams et al., 2013), and POL/NLG (Wen\net al., 2015) modules are optimized separately; our\narchitecture is simpler and less prone to cascading\nfailures due to the folding of multiple NLP tasks\ninto a single transformer model and the exposure\nof symbolic representation directly to the model.\nMore recently, pre-trained language models simi-\nlar to GPT-2 have been used for building end-to-end\ndialogue systems. Our approach is similar in nature\nto the work proposed by (Hosseini-Asl et al., 2020;\nPeng et al., 2020) in that we use a single causal\nlanguage model to generate all outputs given a dia-\nlogue context. However, unlike these approaches,\nour model not only encodes DST and database re-\nsults (which shows a labeling cost reduction) but\nalso encodes dialogue policy and service call tem-\nplates, allowing the system to be able to monitor\nerrors and manipulate symbolic representations at\ndifferent stages of turn processing.\nSimilar to other transformer dialog sys-\ntems (Wolf et al., 2019; Ramadan et al., 2018),\nour model learns from text; however, our model\nalso learns and generates complex structures that\nintermix natural and symbolic language. In par-\nticular, the work described by Budzianowski and\nVuli´c (2019) and Yang et al. (2020) encodes both\nbelief state and knowledge base constructs into\nsimple text representations and generates text-only\noutputs. In contrast, our approach encodes, manipu-\nlates, and generates more sophisticated knowledge\nrepresentations, roughly ﬁrst-order logic constant\nterms that are implicitly learned and which could\nbe used to communicate with external sources and\nexpert components such as a symbolic reasoner.\nDialogue systems have many similarities to con-\nversational workﬂow systems. The Virtual Informa-\ntion Ofﬁcer (Tomasic et al., 2007) required more\nthan thirty individual models performing task clas-\nsiﬁcation, entity resolution, and information extrac-\ntion. Moreover, (Romero et al., 2019) discuss the\nchallenges found when directly translating natural\nlanguage inputs into symbolic API calls in a service\ncomposition system. Both systems would beneﬁt\nfrom the architecture and method presented here.\n6 Conclusions\nIn this paper, we empirically demonstrated that sev-\neral capabilities of transformer language models\ncan be leveraged to construct a new dialogue archi-\ntecture that is more ﬂexible and simpler (resulting\nin much lower engineering costs) and extensible\n(allowing symbolic injection and manipulation),\nwhile retaining reasonable performance.\n7 Acknowledgements\nThe contents of this paper were developed un-\nder grants from the National Institute on Disabil-\nity, Independent Living, and Rehabilitation Re-\nsearch (NIDILRR grant numbers 90DPGE0003\nand 90REGE0007).\n443\nReferences\nDan Bohus and Alexander I. Rudnicky. 2009. The\nravenclaw dialog management framework: Archi-\ntecture and systems. Comput. Speech Lang. ,\n23(3):332–361.\nPaweł Budzianowski and Ivan Vuli´c. 2019. Hello, It’s\nGPT-2-How Can I Help You? Towards the Use of\nPretrained Language Models for Task-Oriented Di-\nalogue Systems. In Proceedings of the 3rd Work-\nshop on Neural Generation and Translation, pages\n15–22.\nHongshen Chen, Xiaorui Liu, Dawei Yin, and Jiliang\nTang. 2017. A survey on dialogue systems: Re-\ncent advances and new frontiers. SIGKDD Explor.\nNewsl., 19(2):25–35.\nLee D Erman, Frederick Hayes-Roth, Victor R Lesser,\nand D Raj Reddy. 1980. The Hearsay-II speech-\nunderstanding system: Integrating knowledge to re-\nsolve uncertainty. ACM Computing Surveys (CSUR),\n12(2):213–253.\nDonghoon Ham, Jeong-Gwan Lee, Youngsoo Jang,\nand Kee-Eung Kim. 2020. End-to-end neural\npipeline for goal-oriented dialogue systems using\nGPT-2. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 583–592. Association for Computational Lin-\nguistics.\nEhsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu,\nSemih Yavuz, and Richard Socher. 2020. A simple\nlanguage model for task-oriented dialogue. In Ad-\nvances in Neural Information Processing Systems,\nvolume 33, pages 20179–20191. Curran Associates,\nInc.\nHwaran Lee, Jinsik Lee, and Tae-Yoon Kim. 2019.\nSUMBT: Slot-utterance matching for universal and\nscalable belief tracking. In Proceedings of the 57th\nAnnual Meeting of the Association for Computa-\ntional Linguistics, pages 5478–5483, Florence, Italy.\nAssociation for Computational Linguistics.\nBing Liu and Ian Lane. 2018. End-to-end learning of\ntask-oriented dialogs. In Proceedings of the 2018\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Student\nResearch Workshop, pages 67–73, New Orleans,\nLouisiana, USA. Association for Computational Lin-\nguistics.\nAndrea Madotto, Chien-Sheng Wu, and Pascale Fung.\n2018. Mem2seq: Effectively incorporating knowl-\nedge bases into end-to-end task-oriented dialog sys-\ntems. CoRR, abs/1804.08217.\nNational Council on Disability. 2015. Transportation\nupdate: Where we’ve gone and what we’ve learned.\nBaolin Peng, Chunyuan Li, Jinchao Li, Shahin\nShayandeh, Lars Liden, and Jianfeng Gao. 2020.\nSOLOIST: few-shot task-oriented dialog with A\nsingle pre-trained auto-regressive model. CoRR,\nabs/2005.05298.\nOsman Ramadan, Paweł Budzianowski, and Milica Ga-\nsic. 2018. Large-scale multi-domain belief track-\ning with knowledge sharing. In Proceedings of the\n56th Annual Meeting of the Association for Compu-\ntational Linguistics, volume 2, pages 432–437.\nAbhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara,\nRaghav Gupta, and Pranav Khaitan. 2020. Schema-\nGuided Dialogue State Tracking Task at DSTC8.\narXiv preprint arXiv:2002.01359.\nOscar J. Romero, A. Dangi, and S. A. Akoju. 2019.\nNLSC: Unrestricted Natural Language-Based Ser-\nvice Composition through Sentence Embeddings. In\n2019 IEEE International Conference on Services\nComputing (SCC), pages 126–135.\nAaron Steinfeld, Jordana L Maisel, and Edward Stein-\nfeld. 2017. Accessible Public Transportation: De-\nsigning Service for Riders with Disabilities. Rout-\nledge.\nAnthony Tomasic, Isaac Simmons, and John Zimmer-\nman. 2007. Learning information intent via observa-\ntion. In Proceedings of the 16th international con-\nference on World Wide Web, pages 51–60.\nSean Welleck, Ilia Kulikov, Jaedeok Kim,\nRichard Yuanzhe Pang, and Kyunghyun Cho.\n2020. Consistency of a recurrent language model\nwith respect to incomplete decoding. arXiv preprint\narXiv:2002.02492.\nTsung-Hsien Wen, Milica Ga ˇsi´c, Nikola Mrk ˇsi´c, Pei-\nHao Su, David Vandyke, and Steve Young. 2015.\nSemantically conditioned LSTM-based natural lan-\nguage generation for spoken dialogue systems. In\nProceedings of the 2015 Conference on Empirical\nMethods in Natural Language Processing, pages\n1711–1721, Lisbon, Portugal. Association for Com-\nputational Linguistics.\nJason Williams, Antoine Raux, Deepak Ramachandran,\nand Alan Black. 2013. The dialog state tracking\nchallenge. In Proceedings of the SIGDIAL 2013\nConference, pages 404–413, Metz, France. Associ-\nation for Computational Linguistics.\nThomas Wolf, Victor Sanh, Julien Chaumond, and\nClement Delangue. 2019. Transfertransfo: A\ntransfer learning approach for neural network\nbased conversational agents. arXiv preprint\narXiv:1901.08149.\nYunyi Yang, Yunhao Li, and Xiaojun Quan. 2020.\nUbar: Towards fully end-to-end task-oriented\ndialog systems with gpt-2. arXiv preprint\narXiv:2012.03539.\n444\nAlgorithm 1Main Flow of Control\ndialogue control():\nInput: signal = start\n1: while signal != end do\n2: usr utt ←get user input().\n3: sys utt ←process response(usr utt).\n4: return sys utt.\n5: end while\nprocess response():\nInput: usr utt\nOutput: sys utt\n1: bb ←update blackboard(usr utt).\n2: dst, serv call ←exec gpt2(“DST”, bb).\n3: bb ←update blackboard(dst, serv call).\n4: dst ←validate slots(bb).\n5: bb ←update blackboard(dst).\n6: results ←exec serv call(serv call).\n7: bb ←update blackboard(results).\n8: sys acts ←exec gpt2(“POL”,bb).\n9: bb ←update blackboard(sys acts).\n10: sys utt ←exec gpt2(“NLG”, bb).\n11: bb ←update blackboard(sys utt).\n12: return sys utt.\nexec gpt2():\nInput: id, bb# bb: blackboard\nOutput: outputs\n1: if id = “DST” then\n2: input ←encode(bb.hist).\n3: else ifid = “POL”then\n4: input ← encode(bb.hist, bb.dst,\nbb.results).\n5: else ifid = “NLG” then\n6: input ← encode(bb.hist, bb.dst,\nbb.results, bb.sys acts).\n7: end if\n8: if length of input >max token length then\n9: input ←forget(input). # truncation\n10: end if\n11: outputs ←predict gpt2(input).\n12: return outputs\nupdate blackboard():\nInput: updates\nOutput: blackboard\n1: for element in updates do\n2: update(blackboard, element).\n3: end for\n4: return blackboard\nTurnSpeakerUtterance1user (gold):I am in a plan to visit some nice and attractive places for which I need your help. Please search some nice places in LA.2 sys (gen):Do you have any particular categoryin your mind to search for and which is your selective city to search for the attractions?sys (gold):I found 10 places those are most attractive places. Among them Angels Flight Railway is the best one and which is also a Historical Landmark. Hope you like it.3user (gold):I need to check whether this place is a Child-friendly place and there will be no entrance fee for this place. Please check it for me.4 sys (gen):Found an attraction which is Autry Museum of the American West which is a good Museum and I think this is the nice place to check for child-friendly attractions Do you help me to find any other attractions?sys (gold):I have checked and found that this is not the suitable place for children and alsoentry fees will be enablethere?     5user (gold):That is okay. In need to go there with four persons for which I need a bus. Please search for me.6 sys (gen):Shall I search it for the date March 4th?\nsys (gold):Let me know your planned leaving date, so that check accordingly.    7user (gold):search for the bus on 13th of this month.\n8 sys (gen):Where are you leaving from?\nsys (gold):AlsoI need the information about your leaving place.    \n9user (gold):I have planned to leave from Sacramento.\n10sys (gen):I found a bus leaving at 2:40pm that costs $45 with 0 transfers.sys (gold):A bus with 0 transfers which leaves at 2:40 pm and it costs $45. What is your opinion?    11user (gold):Let me know the leaving station.\n12sys (gen):The bus departs from Sacramento Valley Station\nsys (gold):It is Sacramento Valley Station.\n13user (gold):Destination station name is what?\n14sys (gen):It is the Union Station which is the destination station of your bussys (gold):It is Union Station, was that information enough?\n15user (gold):Yes, but I need to search for some other buses.\n16sys (gen):Yes, What about a bus departs at 5 pm with 0 transfers under cost $54?sys (gold):What about a bus leaves at 5 pm with 0 transfers under cost $54?17user (gold):Yes, that is the one I want, please make a booking.\n18sys (gen):Need your confirmation to book tickets for 4 persons in the bus leaving from Sacramento to Los Angeles on March 13th at 5 pmsys (gold):Please confirm to book 4 tickets in a bus leaving from Sacramento to Los Angeles on March 13th at 5 pm.19user (gold):This looks okay, can you check about the origin station?20sys (gen):The bus station you will leave from is Sacramento Valley Stationsys (gold):It is Sacramento Valley Station from where the bus will leaveand your tickets are booked as per your information.21user (gold):Thank you for your help.\n22sys (gen):Have a good day\nsys (gold):Have a great day\nFigure 2: Sample of a multi-domain dialogue. For each\ngold user utterance, we provide both the gold system\nutterance and the utterance generated by our system.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7867299318313599
    },
    {
      "name": "Transformer",
      "score": 0.7526131868362427
    },
    {
      "name": "Language model",
      "score": 0.6627007722854614
    },
    {
      "name": "Embedding",
      "score": 0.5204651355743408
    },
    {
      "name": "Natural language",
      "score": 0.5090352892875671
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5048380494117737
    },
    {
      "name": "Natural language processing",
      "score": 0.4749208390712738
    },
    {
      "name": "Architecture",
      "score": 0.4690297842025757
    },
    {
      "name": "Question answering",
      "score": 0.4259251356124878
    },
    {
      "name": "Machine learning",
      "score": 0.32407328486442566
    },
    {
      "name": "Engineering",
      "score": 0.08430728316307068
    },
    {
      "name": "Art",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Visual arts",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I74973139",
      "name": "Carnegie Mellon University",
      "country": "US"
    }
  ]
}