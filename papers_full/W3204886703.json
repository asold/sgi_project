{
    "title": "DeepA2: A Modular Framework for Deep Argument Analysis with Pretrained Neural Text2Text Language Models",
    "url": "https://openalex.org/W3204886703",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2102566054",
            "name": "Gregor Betz",
            "affiliations": [
                "Karlsruhe Institute of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2122050085",
            "name": "Kyle Richardson",
            "affiliations": [
                "Allen Institute"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3167607673",
        "https://openalex.org/W2998696444",
        "https://openalex.org/W2997020034",
        "https://openalex.org/W4205870266",
        "https://openalex.org/W2055650961",
        "https://openalex.org/W3102762626",
        "https://openalex.org/W2395678543",
        "https://openalex.org/W3034830866",
        "https://openalex.org/W3034999214",
        "https://openalex.org/W3115201256",
        "https://openalex.org/W2788292930",
        "https://openalex.org/W2997093078",
        "https://openalex.org/W3156012351",
        "https://openalex.org/W2739419429",
        "https://openalex.org/W1844574851",
        "https://openalex.org/W3006188107",
        "https://openalex.org/W2501224128",
        "https://openalex.org/W3016254928",
        "https://openalex.org/W3201027158",
        "https://openalex.org/W3090866633",
        "https://openalex.org/W2954033554",
        "https://openalex.org/W3177437287",
        "https://openalex.org/W1977975169",
        "https://openalex.org/W4247993381",
        "https://openalex.org/W2407749025",
        "https://openalex.org/W4238826000",
        "https://openalex.org/W3098824823",
        "https://openalex.org/W3035252911",
        "https://openalex.org/W3156111306",
        "https://openalex.org/W2979826702",
        "https://openalex.org/W2469525363",
        "https://openalex.org/W2952781527",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W4231366308",
        "https://openalex.org/W3035554416",
        "https://openalex.org/W3155040511",
        "https://openalex.org/W3196886373",
        "https://openalex.org/W3084470717",
        "https://openalex.org/W4322614701",
        "https://openalex.org/W2963095307",
        "https://openalex.org/W2982399380",
        "https://openalex.org/W3111372685",
        "https://openalex.org/W3173805051",
        "https://openalex.org/W3142819137",
        "https://openalex.org/W3028986228",
        "https://openalex.org/W2758824081",
        "https://openalex.org/W2954422080",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2980459205",
        "https://openalex.org/W3101035550",
        "https://openalex.org/W3034995113",
        "https://openalex.org/W1489439638",
        "https://openalex.org/W3035428952",
        "https://openalex.org/W2480222317",
        "https://openalex.org/W2979666134",
        "https://openalex.org/W3105516974",
        "https://openalex.org/W1508829520",
        "https://openalex.org/W1564062619"
    ],
    "abstract": "In this paper, we present and implement a multi-dimensional, modular framework for performing deep argument analysis (DeepA2) using current pre-trained language models (PTLMs). ArgumentAnalyst – a T5 model [Raffel et al. 2020] set up and trained within DeepA2 – reconstructs argumentative texts, which advance an informal argumentation, as valid arguments: It inserts, e.g., missing premises and conclusions, formalizes inferences, and coherently links the logical reconstruction to the source text. We create a synthetic corpus for deep argument analysis, and evaluate ArgumentAnalyst on this new dataset as well as on existing data, specifically EntailmentBank [Dalvi et al. 2021]. Our empirical findings vindicate the overall framework and highlight the advantages of a modular design, in particular its ability to emulate established heuristics (such as hermeneutic cycles), to explore the model’s uncertainty, to cope with the plurality of correct solutions (underdetermination), and to exploit higher-order evidence.",
    "full_text": "Proceedings of the 11th Joint Conference on Lexical and Computational Semantics, pages 12 - 27\nJuly 14-15, 2022 ©2022 Association for Computational Linguistics\nDeepA2: A Modular Framework for Deep Argument Analysis\nwith Pretrained Neural Text2Text Language Models\nGregor Betz\nKarlsruhe Institute of Technology\nKarlsruhe, Germany\ngregor.betz@kit.edu\nKyle Richardson\nAllen Institute for AI\nSeattle, W A, USA\nkyler@allenai.org\nAbstract\nIn this paper, we present and implement a multi-\ndimensional, modular framework for perform-\ning deep argument analysis (DeepA2) using\ncurrent pre-trained language models (PTLMs).\nArgumentAnalyst – a T5 model (Raffel et al.,\n2020) set up and trained within DeepA2 – re-\nconstructs argumentative texts, which advance\nan informal argumentation, as valid arguments:\nIt inserts, e.g., missing premises and conclu-\nsions, formalizes inferences, and coherently\nlinks the logical reconstruction to the source\ntext. We create a synthetic corpus for deep\nargument analysis, and evaluate ArgumentAna-\nlyst on this new dataset as well as on exist-\ning data, specifically EntailmentBank (Dalvi\net al., 2021). Our empirical findings vindicate\nthe overall framework and highlight the advan-\ntages of a modular design, in particular its abil-\nity to emulate established heuristics (such as\nhermeneutic cycles), to explore the model’s un-\ncertainty, to cope with the plurality of correct\nsolutions (underdetermination), and to exploit\nhigher-order evidence.\n[\n Demo] [\n Model] [\n Datasets]\n1 Introduction\nArgumentative text analysis is an interpretation\nmethod for clarifying arguments (Fisher, 2004).\nBeing studied in argumentation theory, logic, or\nepistemology, it is widely taught and applied as\na key critical thinking skill in, e.g., law (Alexy,\n1989), the humanities (Bruce and Barbone, 2011),\nsocial sciences (Fairclough and Fairclough, 2012),\npolicy advice (Hansson and Hirsch-Hadorn, 2016),\nor public debate (Beck et al., 2019). This paper\npresents a computational approach for deep argu-\nment analysis , i.e., for reconstructing natural-\nlanguage arguments from a given text, as in the\nfollowing example (adapted from Siegel, 2018):\nsource text ; reconstructed argument\nIt is unethical to destroy hu-\nman embryos. The most ba-\nsic argument supporting this\nclaim just stresses that it is\nwrong to intentionally kill in-\nnocent human beings.\n(P1) It is impermissible to\nkill innocent human beings.\n(P2) The human embryo is an\ninnocent human being.\n(C) THUS : It is impermissi-\nble to kill the human embryo.\nThe literature on argument reconstruction (cf.\nFeldman, 1998; Scholz, 2000; Lau, 2011; Bowell\nand Kemp, 2014; Brun, 2014; Brun and Betz, 2016)\ncharacterizes deep argument analysis as:\n• a complex task involving a variety of sub-\ntasks, such as identifying reasons and conclu-\nsions in a text, formalizing sentences, check-\ning validity of an inference, logical streamlin-\ning, or explicating implicit premises.\n• a non-conservative, creative task that goes\nbeyond mere text annotation and essentially\ngenerates a new, more transparent text.\n• an iterative process through which recon-\nstructions are built and revised step-by-step,\nand the solution space is gradually explored.\n• a hermeneutical task, guided by the principle\nof charity, which urges one to come up with\nan interpretation (reconstruction) as strong\nand plausible as possible.\n• assuming a normative background theory\nabout what constitutes a strong and plausible\nargument in the first place.\n• being affected by severe underdetermina-\ntion, both in terms of the process and the final\noutcome; in particular, there typically exist\nrival, yet equally legitimate reconstructions of\none and the same text.\nGiven these special characteristics, deep argu-\nment analysis poses many challenges for machine\nmodels of natural language understanding. In this\npaper, we introduce a novel modular modeling ap-\nproach for analysing complex argumentation that\nbuilds on recent pre-trained text2text transformers\n(Raffel et al., 2020). Our approach – DeepA2 (il-\nlustrated in Figure 1) – works by systematically\n12\ndecomposing a complex reconstruction problem to\nsmaller text2text sub-tasks (see Section 3), which\nallows for emulating the types of interpretation\nstrategies and heuristics studied in argument theory.\nReferring to the different components of a com-\nprehensive argumentative analysis, we may also\ndefine tailor-made metrics for assessing argument\nreconstructions. To demonstrate the benefits of\nour approach, we construct a new argumentation\ndataset (AAAC) that exhibits several complex inter-\npretive dimensions, show how to map other existing\ndatasets into our framework (Section 4), and train\nand evaluate our main model, referred to as Argu-\nmentAnalyst, within DeepA2 (Section 5).\nOur empirical results show:\n1. ArgumentAnalyst generates – out-of-domain –\nsemantically meaningful argument reconstructions,\n70% of which are logically valid. By pooling alter-\nnative reconstructions, virtually every source text\nin the synthetic dataset can be reconstructed as a\nvalid argument.\n2. Modular generation chains which emulate\niterative reconstruction strategies are highly suc-\ncessful: they yield, in particular, a more coherent\ninterpretation of an argumentative text, exploit the\ntext more thoroughly, and generally outperform\none-step generation as soon as problems become\ndifficult.\n3. ArgumentAnalyst outperforms Entailmen-\ntWriter (Dalvi et al., 2021) on difficult Entailment-\nBank problems with respect to telling apart relevant\npremises from distractors.\n4. ArgumentAnalyst generates reliable higher-\norder evidence (Christensen, 2010) which can be\nused for diagnosing logical fallacies – despite the\nfact that ArgumentAnalyst is maximally charitable\nand is trained to reconstruct any input whatsoever\nas a logically valid argument, even if the input\nargument, taken at face value, is painstakingly fal-\nlacious.\nIn concluding this paper, we sum-up and in-\nterpret these findings as general vindication of\nDeepA2’s modular, multi-angular design (Sec-\ntion 6).\n2 Related Work\nTaking transformers as soft reasoners , recent\nwork, pioneered by Clark et al. (2020), has shown\nthat pre-trained language models (PTLMs) possess\nbasic deductive and abductive reasoning capabili-\nties on diverse domains (Banerjee and Baral, 2020;\nBetz et al., 2021; Bostrom et al., 2021), but are\nequally prone to fallacies and biases (Kassner and\nSchütze, 2020; Talmor et al., 2020). Besides draw-\ning the correct conclusion, transformers are able\nto generate correct reasoning chains that justify\nan answer, which in turn further increases answer\naccuracy (Saha et al., 2020; Tafjord et al., 2020;\nGontier et al., 2020; Saha et al., 2021; Dalvi et al.,\n2021).\nNeural semantic parsing uses sequence mod-\nels to formalize natural language sentences (Ka-\nmath and Das, 2019). Shin et al. (2021) show that\nPTLMs are zero-shot parsers, and that intermediate\nsteps which rephrase and streamline the original in-\nput before parsing it to a formal language improve\naccuracy.\nArgument mining is an active research field\nthat studies computational methods for retriev-\ning argumentative components from a text corpus\n(Wachsmuth et al., 2017; Moens, 2018; Potthast\net al., 2019; Lawrence and Reed, 2020). Recently,\nwork in this field has started to use PTLMs: Ein-\nDor et al. (2020) and Gretz et al. (2020) succeed\nin retrieving relevant pro- or con-arguments for a\ngiven topic from a large corpus with a fine-tuned\nBERT model (Devlin et al., 2019). Using BERT,\nBar-Haim et al. (2020) map argumentative texts\nto key points that succinctly summarize the argu-\nment’s gist. Akiki and Potthast (2020) explore\nabstractive argument retrieval by means of text gen-\neration with GPT2 (Radford et al., 2019). Similarly,\nSyed et al. (2021) deploy BART (Lewis et al., 2019)\nto generate conclusions of argumentative texts on a\nchallenging corpus compiled from Reddit and vari-\nous online debate corpora. Rodrigues et al. (2020),\nrevisiting the argument comprehension task (Haber-\nnal et al., 2014, 2018), demonstrate that identifying\nimplicit premises – and deep argument analysis a\nfortiori – remains a hard, unsolved task. Recently,\nChakrabarty et al. (2021) have shown that augment-\ning training data with discourse-aware common-\nsense knowledge improves the plausibility of au-\ntomatically identified implicit premises. Such a\nknowledge-driven perspective is orthogonal to, and\nmay eventually complement the logical approach\nadopted in this paper.\n3 Framework\n3.1 Problem Definition\nDeep argument analysis of a given text seeks to\nanswer the following central question: Can we\n13\nconjectures: source:\nSocrates is mortal because\nevery human is.\nargdown: source: Socrates\nis mortal because every human\nis. conjectures: Socrates is\nmortal\nformalize: premises:\nSocrates is human | If someone\nis human, then they are mortal\nArgument-\nAnalyst\n(1) Socrates is human.\n(2) If someone is human, then\nthey are mortal.\n---\n(3) Socrates is mortal.\nSocrates is mortal\nF a | (x): F x -> G x\nFigure 1: Example text-to-text tasks for deep argument analysis, defined by DeepA2.\nmake sense of the text as a presentation of a rational\nargument? And if so, what exactly is the argument;\nand how precisely is it related to the text?\nIn carrying out a deep argument analysis, one\nexplicates, rephrases and rebuilds – even repairs\n– the text’s argument in one’s own words. That\nis why deep argument analysis is also referred to\nas rational reconstruction (cf. Leitgeb and Carus,\n2021). The reconstructed argument forms, together\nwith details about its logical properties and about\nits relation to the source text, a comprehensive ar-\ngumentative analysis of a text. The latter can be\nseen as an interpretative hypothesis that is abduc-\ntively inferred from a source text by means of an\ninference to the best explanation. Here is another\nexample that illustrates how far a reconstruction\nmay deviate from the original text that presents the\nargument (adapted from Brun and Betz, 2016):\nsource text ; reconstructed argument\nSo, the researcher’s central\ndilemma exists in an espe-\ncially acute form in psychol-\nogy: either the animal is not\nlike us, in which case there\nis no reason for performing\nthe experiment; or else the\nanimal is like us, in which\ncase we ought not to perform\non the animal an experiment\nthat would be considered out-\nrageous if performed on one\nof us.\n(P1) If the animal is not like\nus, it is wrong to perform the\nexperiment.\n(P2) If the animal is like us,\nit is wrong to perform the ex-\nperiment.\n(C) THUS (with classical di-\nlemma): It is wrong to per-\nform the experiment.\nA compelling argumentative analysis yields (i) a\nrational argument that is (ii) closely related to the\nsource text. Deep argument analysis is, accordingly,\nguided by a dual goal (cf. Brun and Betz, 2016).\nAn argument reconstruction should both be\n(i) systematically correct, i.e., the reconstructed\nargument itself is, e.g., transparent, deduc-\ntively valid, non-circular, or doesn’t contain\nirrelevant premises; and\n(ii) exegetically adequate, i.e., the reconstructed\nargument accounts for the original text, be-\ncause, e.g., its premises merely reformulate\nparts of the text, or because its overall inferen-\ntial structure can be traced within the source\ntext.\nThe fact that there typically exists – regarding a\nspecific text – a trade-off between these two goals\nis one major reason for the underdetermination of\ndeep argument analysis and the plurality of legiti-\nmate reconstructions of a given text (cf. Brun and\nBetz, 2016).\nAgainst this background, we may finally define\nthe problem of\nDeep artificial argument analysis: Describe,\nanalyse and implement an effective computa-\ntional system for deep argument analysis!\n3.2 Multi-angular Data\nThe DeepA2 framework is built upon a multi-\nangular data structure (Tafjord and Clark, 2021)\nwhose dimensions represent the essential compo-\nnents of a comprehensive argumentative analysis\n(see Section 3.1). Structured argumentative data is\nrendered as plain text (cf. V oigt, 2014). The differ-\nent data dimensions, which are related as shown in\nFigure 2, are (with an illustrating example):\nargument source text (S)\nIt is unethical to destroy human embryos. The basic\nargument supporting this claim just stresses that it is\nwrong to intentionally kill innocent human beings.\nverbatim reason statements in source text (R)\nit is wrong to intentionally kill innocent human beings\n(ref: (1))\nverbatim conjectures in the source text (J)\nIt is unethical to destroy human embryos (ref: (3))\nargument reconstruction (A)\n(1) It is impermissible to kill innocent human beings.\n(2) The human embryo is an innocent human being.\n– with hypothetical syllogism from (1) (2) –\n(3) It is impermissible to kill the human embryo.\n14\nS\nR\nquotes\nreasons in\nJ\nquotes con-\njectures in\nA\nreconstructs\nargument in\nrefers to\nrefers to\nP\nquotes\npremises\nC\nquotes\nconcl.\nFformalizes\nOformalizes\nK\nprovideskeys for\nprovideskeys for\nFigure 2: Relationships between dimensions of the\nmulti-angular argumentative data.\npremises of the reconstructed argument (P)\nIt is impermissible to kill innocent human beings |The\nhuman embryo is an innocent human being\nfinal conclusion of reconstr. argument (C)\nIt is impermissible to kill the human embryo\nformalizations of premises (F)\n(x): F x →G x |(x): H x →F x\nformalization of conclusion (O)\n(x): H x →G x\nkeys for the formalizations’ constants (K)\nF: innocent human being |G: must not be killed |H:\nhuman embryo\nEach record in a DeepA2 dataset contains a\nsource text plus a legitimate comprehensive argu-\nmentative analysis, which is, given underdetermi-\nnation, not necessarily the only compelling recon-\nstruction of the text; moreover, a dataset may con-\ntain different records with one and the same source\ntext analysed in several ways. So, for example, an\nalternative, equally legitimate argument reconstruc-\ntion of the above source text (S) may read:\nargument reconstruction (A)\n(1) If it is wrong to kill innocent human beings, then it\nis wrong to kill a human embryo.\n(2) It is wrong to kill innocent human beings.\n– with modus ponens from (1) (2) –\n(3) It is wrong to kill a human embryo.\nBeyond this structural and functional character-\nization, DeepA2 is agnostic about the nature and\norigin of the argumentative data. Synthetically gen-\nerated, automatically retrieved, manually created\ndatasets as well as translations of other databases\nare all compatible with the framework and can be\nused side by side.\n3.3 Generative Modes and Chains\nGiven DeepA2’s multi-dimensional data structure\ndescribed in the previous section, a generative\nmode maps data from some input dimensions to\na target dimension. For example, the mode S;A\ntakes a source text (S) as input and outputs an argu-\nment reconstruction (A), the mode RJ ;A recon-\nstructs the argument (A) given the verbatim reasons\n(R) and conjectures ( J). All in all, we define and\ninvestigate 21 different generative modes (see Ap-\npendix B). Every mode represents a task on which\na text-to-text model can be trained.\nBy taking some mode’s output as another mode’s\ninput, modes can be concatenated into generative\nchains. For example, the output of modes S;R\nand S;J (reasons and conjectures from source)\ncan be fed into mode RJ ;A to reconstruct an\nargument. Such generative chains allow us to em-\nulate different strategies (heuristics) for analysing\na given argumentative text (see Appendix C for\ntechnical details).\nThree generative chains which model distinct\ninterpretative strategies, taking a source text (S) as\nsole input, are:\nstraight\nS;A S;R S;J\nhermeneutic cycle\nS;A SA ;R SA ;J RJ ;A\nlogical streamlining\nS;A A;P A;C C;O CO ;K\nOK ;C PC ;A SA ;R SA ;J\nWhile the chain straight, where no output ever\nserves as input to another mode, represents a simple\nbaseline, hermeneutic cycle and logical streamlin-\ning mimic prominent, equally-named methods in ar-\ngument analysis (cf. Bowell and Kemp, 2014; Brun\nand Betz, 2016). One goes through a hermeneutic\ncycle, generally speaking, if one revisits a text in\nview of its previous interpretation, as, for example,\nin steps SA ;R SA ;J , where the source text (S)\nis re-interpreted (identifying reason statements and\nconjectures) given the previously reconstructed ar-\ngument (A), so as to subsequently re-reconstruct the\nargument itself (step RJ ;A ). To logically stream-\nline a reconstruction means to rephrase its con-\nclusion or premises in order to make their logico-\nsemantic structure more transparent. Such seman-\ntic clarification can be emulated by (i) formalizing\na statement (e.g., A;C C;O CO ;K ) and (ii)\nusing the keys (K) to retrieve the original statement\nfrom the generated logical formulas (such as in\nOK ;C ), from which the argument can be re-built\n(step PC ;A ).\nFor evaluation, we append to each generative\nchain the following sub-chain that formalizes the\nreconstructed argument:\nformalization\nA;P A;C P;F CPF ;O PFCO ;K\n15\nA generative chain can be construed as hy-\npergraph on the dimensions of DeepA2’s multi-\nangular datasets, with each of its modes represent-\ning a directed hyper-edge. Summing up the num-\nber of input dimensions (except S) over all modes\nyields a simple graph centrality measure, which\ngauges a chain’s sophistication. Thus, straight,\nhermeneutic cycle and logical streamlining display\na sophistication of 0, 4, and 11, respectively.\n3.4 Metrics\nAs discussed in Section 3.1, an argument recon-\nstruction should both be sound and make sense\nof the text to-be-interpreted. In line with the dual\ngoal of argument analysis, we propose metrics both\nfor the systematic correctness and for the exegetic\nadequacy of a given analysis. The following met-\nrics measure the degree to which a given generated\nargument is systematically correct:\nSYS-PP 1 if the argument is not a petitio principii\n(i.e., if no premise is identical with its final\nconclusion), 0 otherwise;\nSYS-RP 1 if the argument has no redundant\npremises (i.e., if no premise occurs more than\nonce), 0 otherwise;\nSYS-RC 1 if the argument has noredundant conclu-\nsions (i.e., if no conclusion – intermediary or\nfinal – occurs more than once), 0 otherwise;\nSYS-US 1 if all statements in the argument other\nthan the final conclusion are explicitly used in\nan inference, 0 otherwise;\nSYS-SCH ratio of sub-arguments which correctly\ninstantiate the explicitly stated inference\nscheme (e.g., hypothetical syllogism);\nSYS-V AL 1 if the argument is globally valid (i.e., if\nthe final conclusion deductively follows from\nthe premises), 0 otherwise;\nAll six systematic metrics can be computed au-\ntomatically (SYS-SCH tries to parse the argument\nbased on the inference schemes and templates used\nto construct the synthetic dataset in the first place;\nSYS-V ALpasses the model-generated formalizations\nof premises and conclusion to a symbolic theorem\nprover (De Moura and Bjørner, 2008); and the re-\nmaining metrics check for string identity).\nWhereas systematic metrics apply primarily to\nthe generated argument (A), a reconstruction’s in-\nterpretative adequacy will also depend on how rea-\nsons (R) and conjectures ( J) coherently link the\nargument’s components to the original text. As a\nfirst set of exegetic metrics, we thus propose\nEXE-MEQ 1 if the reasons and conjectures are\nmutually exclusive verbatim quotes from the\nsource text, 0 otherwise;\nEXE-RSS semantic similiarity (BLEURT, see Sel-\nlam et al., 2020) of each reason statement and\nits counterpart premise in the reconstructed\nargument (if such exists, -1 otherwise);\nEXE-JSS semantic similiarity (seeEXE-RSS) of each\nconjecture statement and its counterpart in\nthe reconstructed argument (if such exists, -1\notherwise).\nEach source text presents (more or less faithfully)\nan underlying target argument, which in turn marks\nsome of the text’s statements as ‘target’ reasons,\nothers as ‘target’ conjectures. The following two\nmetrics assess the degree to which a comprehen-\nsive argumentative analysis correctly predicts (R,\nJ) those target reasons and conjectures.\nEXE-PPR predictive performance (F1-score) for\nidentifying (target) reason statements in the\nsource text;\nEXE-PPJ predictive performance (F1-score) for\nidentifying (target) conjecture statements in\nthe source text.\nAn argument’s final conclusion may be implicit or\nexplicit in a given text. The ability to fully exploit\na text can be measured by verifying whether the re-\nconstructed argument’s final conclusion is implicit\n(= prediction) if and only if the target argument’s\none is.\nEXE-TE text exploitation, as measured by ability\n(F1-score) to reconstruct arguments with ex-\nplicit final conclusions (prediction) if and only\nif the target final conclusions are explicit.\n3.5 Models\nAny text-to-text language model is compatible with\nthe proposed DeepA2 framework. We refer to mod-\nels used within the framework as ArgumentAna-\nlyst. In this study, we train and evaluate the trans-\nformer model T5 (Raffel et al., 2020) with 770M\nparameters as implemented by (Wolf et al., 2020).\n3.6 Limitations\nIn the DeepA2 framework, arguments are recon-\nstructed from relatively short and isolated texts,\ndisregarding both the broader context of the argu-\nment and domain-specific background knowledge.\nThis limits the framework, as presented here, in\n16\nimportant ways: Implicit premises that are expli-\ncated in an argument reconstruction can neither\nbe checked for plausibility nor for agreement with\nthe author’s broader convictions. In addition, the\nframework cannot assess an argument’s dialectic\nfunction in a wider debate. It seems worthwhile to\nexplore according extensions of the framework in\nfuture research.\n4 Datasets\nFor the experiments reported below, we syntheti-\ncally create two artificial argument analysis corpora\nthat comply with the DeepA2 framework (see also\nAppendix A): AAAC01 and AAAC02. In addition,\nwe translate the synthetic RuleTaker (Clark et al.,\n2020) and the manually compiled EntailmentBank\n(Dalvi et al., 2021) datasets into our framework.\nIn argument analysis, one proceedsfrom a source\ntext to its reconstruction. Creating the synthetic\ncorpora, we reverse-engineer this process:\nStep 1. We sample, first of all, a possibly com-\nplex argument ( A) from a set of valid inference\nschemes. In doing so, we use a multi-step templat-\ning strategy (inspired by Betz et al., 2021) to trans-\nlate symbolic forms into natural language schemes\n(which were generated by local domain experts)\nand to substitute natural language terms for place-\nholders. Premises ( P), conclusion ( C) and their\nformalization (F, O, K) are side-products of such a\nconstruction of an argument.\nStep 2. Given the fully explicit argument (A), we\ncompose a text (S) that presents the argument in a\nmore or less transparent and faithful way. Such text\ncreation involves: rendering the argument tree as\na linear story, leaving out premises or conclusions\n(implicit premises and conclusions), inserting ir-\nrelevant material (distractors), using templates that\nobfuscate the logical form of a sentence, limiting\nthe use of premise and conclusion indicators (such\nas “therefore”), applying rule-based and automatic\nparaphrasing. In composing the argumentative text\n(S), we may record its reasons (R) and conjectures\n(J).\nGiven the synthetic and controlled nature of our\ndataset, which involved eliciting rule templates\nfrom a group of local domain experts, all data is\nassumed to be correct by construction. As an addi-\ntional check of correctness on the logic of our exam-\nples, we ran a symbolic theorem prover (De Moura\nand Bjørner, 2008) over the argument formaliza-\ntions to verify their validity. To ensure the fluency\nof the underlying language templates, all templates\nwere hand verified by the authors.\nOur two datasets AAAC01 and AAAC02 differ in\nthe following ways:\n1. predicates and names are sampled from dif-\nferent, disjunct domains (texts are about, e.g.,\nallergies and family relations versus, e.g., bad-\nminton and cooking) to test a model’s robust-\nness to lexical diversity (Rozen et al., 2019);\n2. similarly, AAAC01 applies automatic para-\nphrasing (Alisetti, 2021) to the final source\ntext whereas AAAC02 doesn’t;\n3. AAAC02 allows for imprecise renditions of log-\nical formulas, while AAAC01 sticks to plain\nformulations to test robustness to variations in\ndescription of rules.\nEach dataset contains diverse texts and argu-\nments. Broadly speaking, data records may dif-\nfer in terms of properties of the argument (step\n1 above) and properties of the argument’s presen-\ntation (step 2). Along these two dimensions, we\ndefine five homogeneous subsets of the data:\nsimple inference: arguments with a single infer-\nence step that neither involves negation nor\ncompositional predicates;\ncomplex inference: arguments with four infer-\nence steps that heavily rely on syntactically\nintricate schemes (e.g., transposition, or de\nMorgan);\nplain presentation: all premises and conclusions\nare explicit in the source text which, in addi-\ntion, contains no distractors;\nmutilated presentation: at least two premises\nand one conclusion are implicit, while the text\ncontains two distractors and explicitly states\nthe final conclusion;\nC&M: the argument’s inference is complex, plus\nthe text contains at least two distractors.\nThe RuleTaker and EntailmentBank datasets con-\ntain multi-hop inference trees (A). To import these\ninto the DeepA2 framework, we create source texts\n(S) for the given arguments by means of simple\ntemplates (such as “{theory} All this entails: {hy-\npothesis}”) and record reasons (R) and conjectures\n(J) on the fly. Unlike AAAC and EntailmentBank,\nRuleTaker (as updated in Tafjord et al., 2020) con-\ntains an equal share of arguments for which (i)\nthe conclusion follows from the premises, (ii) the\nconclusion contradicts the premises, (iii) the con-\nclusion is independent of the premises.\n17\n5 Experiments and Results\nAs first and main experiment we train our\nbase model (see Section 3.5) on the AAAC01 cor-\npus, and evaluate the resulting ArgumentAnalyst\nmodel out-of-domain on AAAC02. ArgumentAna-\nlyst undergoes multi-task training on 21 genera-\ntive modes, which are interpreted as sequence-to-\nsequence tasks (the training set-up is further de-\nscribed in Appendix B).\nThe evaluation of ArgumentAnalyst on AAAC02\nproceeds in two steps: (1.) prediction: produces\noutput in accordance with 16 different generative\nchains (Appendix C); (2.) metrics application:\nassesses the quality of the generated output by\nmeans of the systematic and exegetic metrics of\nthe DeepA2 framework (see Section 3.4).\nTable 1 reports the ability of ArgumentAnalyst\nto generate systematically correct and exegetically\nadequate argument reconstructions. We obtain sim-\nilar global results with the three chains straight,\nhermeneutic cycle, and logical streamlining, whose\ngenerated reconstructions mainly differ in terms\nof internal coherence (EXE-RSS, EXE-JSS) and text\nexploitation (EXE-TE). However, the different gen-\nerative chains complement each other, as shown by\npooling, which does not only outperform individual\nchains, but nearly attains oracle performance.\nMoreover, ArgumentAnalyst produces much bet-\nter reconstructions of simple inferences and plain\npresentations – compared to complex inferences\nand mutilated presentations, i.e., difficult problems\n(cf. Table 5 in App. D). In addition, within one\nand the same subset, substantial differences show\nup between the three generative chains. Globally\nspeaking, hermeneutic cycle outperforms the other\ntwo chains for difficult problems.\nIs ArgumentAnalyst capable of reliable self-\nevaluation? We have validated the logic metric\n(SYS-V AL), which passes on a self-generated formal-\nization of the reconstructed argument to a theorem\nprover, in three ways: First of all, ArgumentAna-\nlyst correctly recognizes target arguments as valid\n(with accuracy 92.7%), which has been verified\nby running the formalization subchain on target\ndata. Secondly, virtually every generated argument\nwith all-correct scheme instantiations (i.e., SYS-\nSCH = 1) is also – and correctly – recognized as\nlogically valid. Thirdly, a manual analysis (human-\nin-the-loop) of 100 generated arguments with in-\ncorrect scheme instantiation (i.e., SYS-SCH < 1)\nreveals a high rate of false negatives: roughly one\nhalf of all inferences that are not automatically\nidentified as an instantiation of the given scheme\nactually do correctly instantiate it. The accordingly\nadjusted global ratio of correct scheme instanti-\nations (Table 1) equals roughly 0.65 (rather than\n0.31–0.33), which is consistent with the ratio of\nlogically valid arguments being 0.72–0.73.\nDo reconstructed arguments exhibit basic seman-\ntic flaws? Regarding the full dataset, Argument-\nAnalyst produces nearly flawless argument re-\nconstructions, committing basic errors (petitio,\nredundancy, unused statements) only very rarely\n(Table 1). And even for very difficult problems,\ntwo thirds of all generated arguments display no\nbasic flaw whatsoever (Table 5,SYS-PP & SYS-RP &\nSYS-RC & SYS-US).\nAre reconstructed arguments logically valid?\nRoughly 70% of all arguments generated by one of\nthe three chains are logically valid (Table 1). More\nimportantly, though, for virtually every source\ntext in the dataset, there is at least one chain\n(out of 16) which reconstructs the text as a valid\nargument (pooling). Given that logical validity\ncan be automatically assessed, the pooled system\nmay thus guarantee to yield a valid reconstruc-\ntion. Concerning different problem types (Table 5),\nhermeneutic cycle clearly outperforms the other\nchains as soon as the problem gets difficult. Ad-\nditional analysis shows that ArgumentAnalyst can\nalso cope with underdetermination, as 68% of all\ngenerated arguments whose final conclusion differs\n(BLEU ≤ .8) from the target argument’s one – i.e.,\narguments that are not reconstructed as expected\ngiven the target data – are still logically valid.\nAre the generated interpretations internally coher-\nent? The generative chain hermeneutic cycle yields\ncomprehensive argument reconstructions where\npremises (P) and conclusions ( C) fit much better\nto detected reasons ( R) and conjectures ( J) than\nstraight or logical streamlining (EXE-RSS, EXE-JSS).\nThis holds globally (Table 1), as well as for easy,\nand for difficult problems (Table 5). Note that the\noracle baseline for metrics EXE-RSS, EXE-JSS is well\nbelow 1, which reflects the fact that source texts\nmay present arguments in highly mutilated ways;\nit is nearly attained by pooling the 16 different\ngenerative chains (Table 1).\nCan ArgumentAnalyst detect reasons and conjec-\ntures, and fully exploit the text? The evaluation\ndemonstrates that reason/conjecture detection on\nAAAC02 is a relatively easy task (EXE-PPR, EXE-PPJ).\n18\nsystematic metrics (SYS-*) exegetic metrics (EXE-*)\nchain PP RP RC US SCH V AL MEQ RSS JSS PPR PPJ TE\nstraight .95 .97 .96 .96 .33 .73 .80 -.08 -.10 .93 .93 .63\nherm. cy. .95 .98 .95 .93 .31 .72 .82 .16 .12 .93 .92 .71\nlogic. str. .95 .97 .96 .95 .32 .72 .82 .11 .00 .93 .92 .69\npooling 1.0 1.0 1.0 1.0 .73 1.0 1.0 .26 .29 .96 .96 .97\noracle 1.0 1.0 1.0 1.0 1.0 1.0 1.0 .30 .37 1.0 1.0 1.0\nTable 1: Performance of ArgumentAnalyst on the AAAC02 data as measured by systematic and exegetic metrics.\nRows display results for three illustrative generative chains (straight, hermeneutic cycle, logical streamlining), for\nthe item-wise best performing generative chain out of all 16 chains (pooling), and for oracle performance (oracle),\nwhich one obtains by applying the metrics to the target data itself.\nArgAnEB ArgAnAAAC,EB EntWr\nsteps straight herm.\ncycle\nstraight herm.\ncycle\n1 .863 .866 .816 .871 .951\n2 .798 .815 .813 .826 .886\n3 .812 .815 .826 .806 .858\n4 .757 .791 .820 .822 .838\n≥5 .795 .811 .786 .773 .742\nany .819 .830 .816 .834 .879\nTable 2: Predictive performance of ArgumentAnalyst\n(ArgAnEB, ArgAnAAAC,EB) and EntailmentWriter ( En-\ntWr) for identifying reason statements in an input text\n(metric SYS-PPR) on the EntailmentBank task2 dataset.\nIn contrast, fully exploiting a text (i.e., generating\nan argument with implicit final conclusion if and\nonly if the underlying target argument has an im-\nplicit final conclusion, EXE-TE) is seemingly more\nchallenging (Table 1). Again, hermeneutic cycle\nachieves best text exploitation, performing, how-\never, clearly below oracle baseline – which may\nsimply reflect the degree of underdetermination in\nthe AAAC02 corpus.\nIn a second experiment we train two models\non the imported EntailmentBank (task1 and task2)\ndataset (see Section 4), namely: (1.) our base\nmodel (T5), which yields ArgumentAnalystEB; (2.)\nthe ArgumentAnalyst model pretrained on AAAC02\n(resulting in an intermediary pre-training set-up\nsimilar to Phang et al., 2018; Geva et al., 2020),\nwhich yields ArgumentAnalystAAAC,EB.\nSince the EntailmentBank data doesn’t contain\nformalizations, we can only train on 14 modes,\nwhich are interpreted as sequence-to-sequence\ntasks (see Appendix B). We evaluate the models\non task2 of EntailmentBank only, which contains\nproblems with a relatively large number of distrac-\ntors, and proceed in two steps as before: prediction\n(with 11 different generative chains) and metrics\napplication. Dalvi et al. (2021) report the ability of\nEntailmentWriter (a fine-tuned T5-11b model) to\ncorrectly distinguish relevant premises of an argu-\nment from distractors in terms of a F1-score, which\ncorresponds to our metric EXE-PPR. That’s why the\nsole focus in this second experiment is on EXE-PPR.\nTable 2 describes the ability of ArgumentAna-\nlyst models to correctly tell apart relevant premises\nfrom mere distractors in the EntailmentBank task2\ndataset for two generative chains (straight, which\ndirectly outputs reason statements, and hermeneu-\ntic cycle, which tries to reconstruct the argument\nfirst and uses both source text and argument to\nidentify reasons), and compares this with the per-\nformance of EntailmentWriter (scores from Dalvi\net al., 2021). The results, shown separately for ar-\nguments with a specific number of inference steps,\nlet us draw three conclusions:\nFirst, ArgumentAnalyst outperforms Entailmen-\ntWriter on difficult problems with more than 4 in-\nference steps / sub-arguments.\nSecond, using the sophisticated chain hermeneu-\ntic cycle improves predictive performance com-\npared to the simple straight chain.\nThird, the chain hermeneutic cycle (unlike\nstraight) generally benefits from intermediary pre-\ntraining on AAAC – caveat: not so for arguments\nwith more than 4 steps. This latter observation\nmight be due to the fact that the AAAC02 corpus, by\nconstruction, doesn’t contain arguments with more\nthan 4 steps, so that pre-training biases the model\ntowards shorter arguments.\nIn a third experiment we explore the following\nhypothesis:\nInformative higher-order evidence. The degree\nto which ArgumentAnalyst struggles in recon-\nstructing a given argument (presented in the\nsource text) as logically valid is a reliable in-\n19\ndicator for whether the original argument is\nfallacious or not.\nTo test this hypothesis, we apply ArgumentAnalyst\n(trained on AAAC02, see above) to the RuleTaker\ndata as imported into the DeepA2 framework (see\nSection 4): ArgumentAnalyst produces – by means\nof 13 generative chains – comprehensive recon-\nstructions, to which the systematic and exegetic\nmetrics are applied. RuleTaker contains an equal\nshare of arguments whose conclusions follow from\n(label=valid), contradict (label=contradiction), or\nare independent of (label=neutral) the correspond-\ning premises. Now, informative higher-order ev-\nidence would allow us to correctly predict these\nlabels. And this is exactly what we observe: First,\nif reconstructions of one and the same source text\nwhich are independently generated with different\nchains agree (disagree), then the original argument\ntends to be valid (invalid). Second, by training\nsimple classifiers on our argumentative metrics and\nfurther properties of the reconstructions, we ro-\nbustly achieve a predictive accuracy 10% above\nthe random baseline. While this is far below the\nSOTA results of tailor-made RuleTaker (Clark et al.,\n2020) and ProofWriter (Tafjord et al., 2020) mod-\nels on this data, our findings nonetheless confirm\nthe above hypothesis.\n6 Conclusion\nIn this paper, we have presented and implemented\na multi-angular, modular framework for deep ar-\ngument analysis (DeepA2). It allows for defining\na large variety of generative modes by combining\ndifferent dimensions of the data. These modes, in\nturn, can be concatenated into complex generative\nchains. ArgumentAnalyst – a text-to-text model\nset up and trained within the DeepA2 framework –\nyields plausible reconstructions of argumentative\ntexts. Our empirical findings vindicate the overall\nframework and highlight the followingadvantages\nof a multi-angular, modular design in general:\nFirst of all, modular chains may emulate estab-\nlished, well-proven, typically piece-meal, schol-\narly techniques for text analysis (heuristics), which\nhence may provide normative, methodological\nguidance in setting up NLP systems. Secondly,\nby defining and implementing different modular\nchains, and investigating the plurality of gener-\nated solutions, one can systematically explore the\nsystem’s uncertainty as well as the tasks’s un-\nderdetermination. Thirdly, monitoring the sys-\ntem during modular computation yields diagnosti-\ncally useful information (e.g., intermediary results)\nwhich not only describes the model’s performance\non the given problem, but which additionally al-\nlows us – as higher-order evidence – to character-\nize (e.g., classify) the original problem in the first\nplace. Fourthly, breaking down a complex task into\nsub-tasks with intermediary results that can be fur-\nther processed and re-combined helps to overcome\ninput size limitations of neural language models.\nFifthly, modular generation with meaningful modes\nallows users to follow the system, comprehend gen-\nerated solutions, verify sub-steps and detect errors\n– the NLP system becomes a transparent, explain-\nable AI (Miller, 2019). Finally, modular NLP sys-\ntems as described by DeepA2 may be connected\nto a user-interface which promises fine-grained\ninteractive control of modular generations and\nseamless cognitive cooperation of AI and human\nexperts in analysing texts.\nAcknowledgments\nWe’re indebted to Christian V oigt for his critical\nand constructive feedback throughout the DeepA2\nproject.\nReferences\nChristopher Akiki and Martin Potthast. 2020. Exploring\nargument retrieval with transformers notebook for the\ntouche lab on argument retrieval at clef 2020.\nRobert Alexy. 1989. A theory of legal argumentation:\nthe theory of rational discourse as theory of legal\njustification. Clarendon Press, Oxford.\nSai Vamsi Alisetti. 2021. Paraphrase generator with t5.\nhttps://github.com/Vamsi995/Paraphrase-Generator.\nPratyay Banerjee and Chitta Baral. 2020. Self-\nsupervised knowledge triplet learning for zero-shot\nquestion answering. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 151–162.\nRoy Bar-Haim, Lilach Eden, Roni Friedman, Yoav Kan-\ntor, Dan Lahav, and N. Slonim. 2020. From argu-\nments to key points: Towards automatic argument\nsummarization. In ACL.\nJordan Beck, Bikalpa Neupane, and John M. Carroll.\n2019. Managing conflict in online debate communi-\nties. First Monday, 24(7).\nGregor Betz, Christian V oigt, and Kyle Richardson.\n2021. Critical thinking for language models. In\nProceedings of the 14th International Conference on\nComputational Semantics (IWCS) . Association for\nComputational Linguistics.\n20\nKaj Bostrom, Xinyu Zhao, Swarat Chaudhuri, and Greg\nDurrett. 2021. Flexible operations for natural lan-\nguage deduction. ArXiv, abs/2104.08825.\nTracey Bowell and Gary Kemp. 2014.Critical Thinking:\nA Concise Guide , 4th edition edition. Routledge,\nLondon.\nMichael Bruce and Steven Barbone. 2011. Just the\narguments: 100 of the most important arguments in\nWestern philosophy. Wiley-Blackwell, Chichester,\nWest Sussex, U.K.\nGeorg Brun. 2014. Reconstructing arguments: Formal-\nization and reflective equilibrium. Logical Analysis\nand History of Philosophy, 17:94–129.\nGeorg Brun and Gregor Betz. 2016. Analysing practical\nargumentation. In Sven Ove Hansson and Gertrude\nHirsch-Hadorn, editors, The Argumentative Turn in\nPolicy Analysis. Reasoning about Uncertainty, pages\n39–77. Springer, Cham.\nTuhin Chakrabarty, Aadit Trivedi, and Smaranda\nMuresan. 2021. Implicit premise generation with\ndiscourse-aware commonsense knowledge models.\nIn EMNLP.\nDavid Christensen. 2010. Higher-order evidence. Phi-\nlosophy and Phenomenological Research, 81(1):185–\n215.\nPeter Clark, Oyvind Tafjord, and Kyle Richardson. 2020.\nTransformers as soft reasoners over language. In Pro-\nceedings of the Twenty-Ninth International Joint Con-\nference on Artificial Intelligence (IJCAI-20), pages\n3882–3890.\nBhavana Dalvi, Peter Jansen, Oyvind Tafjord, Zhengnan\nXie, Hannah Smith, Leighanna Pipatanangkura, and\nPeter Clark. 2021. Explaining answers with entail-\nment trees. arXiv preprint arXiv:2104.08661.\nLeonardo De Moura and Nikolaj Bjørner. 2008. Z3:\nAn efficient smt solver. In International conference\non Tools and Algorithms for the Construction and\nAnalysis of Systems, pages 337–340. Springer.\nJ. Devlin, Ming-Wei Chang, Kenton Lee, and Kristina\nToutanova. 2019. Bert: Pre-training of deep bidirec-\ntional transformers for language understanding. In\nNAACL-HLT.\nL. Ein-Dor, Eyal Shnarch, Lena Dankin, Alon Halfon,\nBenjamin Sznajder, Ariel Gera, Carlos Alzate, Mar-\ntin Gleize, Leshem Choshen, Yufang Hou, Yonatan\nBilu, R. Aharonov, and N. Slonim. 2020. Corpus\nwide argument mining - a working solution. ArXiv,\nabs/1911.10763.\nIsabela Fairclough and Norman Fairclough. 2012. Polit-\nical Discourse Analysis. Routledge, London.\nRichard Feldman. 1998. Reason and Argument, 2nd\nedition. Pearson, Prentice hall.\nAlec Fisher. 2004. The Logic of Real Arguments, 2nd\ned edition. Cambridge University Press, New York.\nMor Geva, Ankit Gupta, and Jonathan Berant. 2020.\nInjecting numerical reasoning skills into language\nmodels. In ACL.\nNicolas Gontier, Koustuv Sinha, Siva Reddy, and\nChristopher Pal. 2020. Measuring systematic gener-\nalization in neural proof generation with transform-\ners.\nShai Gretz, Roni Friedman, Edo Cohen-Karlik, Assaf\nToledo, Dan Lahav, R. Aharonov, and N. Slonim.\n2020. A large-scale dataset for argument qual-\nity ranking: Construction and analysis. ArXiv,\nabs/1911.11408.\nIvan Habernal, Judith Eckle-Kohler, and Iryna\nGurevych. 2014. Argumentation mining on the web\nfrom information seeking perspective. In Elena\nCabrio, Serena Villata, and Adam Wyner, editors,\nArgNLP 2014. Frontiers and Connections between\nArgumentation Theory and Natural Language Pro-\ncessing. Proceedings of the Workshop on Frontiers\nand Connections between Argumentation Theory and\nNatural Language Processing. CEUR-WS.org.\nIvan Habernal, Henning Wachsmuth, Iryna Gurevych,\nand Benno Stein. 2018. The argument reasoning\ncomprehension task: Identification and reconstruc-\ntion of implicit warrants. In NAACL-HLT.\nSven Ove Hansson and Gertrude Hirsch-Hadorn, editors.\n2016. The Argumentative Turn in Policy Analysis.\nReasoning about Uncertainty. Springer, Cham.\nAishwarya Kamath and R. Das. 2019. A survey on\nsemantic parsing. ArXiv, abs/1812.00978.\nNora Kassner and Hinrich Schütze. 2020. Negated and\nmisprimed probes for pretrained language models:\nBirds can talk, but cannot fly. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 7811–7818, Online. Asso-\nciation for Computational Linguistics.\nJoe Y . F. Lau. 2011.An Introduction to Critical Think-\ning and Creativity: Think More, Think Better. Wiley,\nHoboken, N.J.\nJohn Lawrence and Chris Reed. 2020. Argument\nMining: A Survey. Computational Linguistics ,\n45(4):765–818.\nHannes Leitgeb and André Carus. 2021. Rudolf Car-\nnap. Supplement D: Methodology. In Edward N.\nZalta, editor, The Stanford Encyclopedia of Philos-\nophy, Summer 2021 edition. Metaphysics Research\nLab, Stanford University.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVes Stoyanov, and Luke Zettlemoyer. 2019. Bart: De-\nnoising sequence-to-sequence pre-training for natural\nlanguage generation, translation, and comprehension.\n21\nTim Miller. 2019. Explanation in artificial intelligence:\nInsights from the social sciences. Artif. Intell., 267:1–\n38.\nMarie-Francine Moens. 2018. Argumentation mining:\nHow can a machine acquire common sense and world\nknowledge? Argument & Computation, 9:1–14.\nJason Phang, Thibault Févry, and Samuel R. Bowman.\n2018. Sentence encoders on stilts: Supplementary\ntraining on intermediate labeled-data tasks. CoRR,\nabs/1811.01088.\nMartin Potthast, Lukas Gienapp, F. Euchner, Nick\nHeilenkötter, Nicolas Weidmann, Henning\nWachsmuth, Benno Stein, and Matthias Hagen. 2019.\nArgument search: Assessing argument relevance.\nProceedings of the 42nd International ACM SIGIR\nConference on Research and Development in\nInformation Retrieval.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Lan-\nguage models are unsupervised multitask learners.\nPreprint.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. Journal of Machine Learning Research, 21:1–\n67.\nJ. Rodrigues, Ruben Branco, J. Silva, and A. Branco.\n2020. Reproduction and revival of the argument\nreasoning comprehension task. In LREC.\nOhad Rozen, Vered Shwartz, Roee Aharoni, and Ido\nDagan. 2019. Diversify your datasets: Analyzing\ngeneralization via controlled variance in adversarial\ndatasets.\nSwarnadeep Saha, Sayan Ghosh, Shashank Srivastava,\nand Mohit Bansal. 2020. Prover: Proof generation\nfor interpretable reasoning over rules. InProceedings\nof the 2020 Conference on Empirical Methods in\nNatural Language Processing, EMNLP 2020, Online,\nNovember 16-20, 2020, pages 122–136. Association\nfor Computational Linguistics.\nSwarnadeep Saha, Prateek Yadav, and M. Bansal. 2021.\nmultiprover: Generating multiple proofs for im-\nproved interpretability in rule reasoning. ArXiv,\nabs/2106.01354.\nOliver R. Scholz. 2000. Was es heißt, eine argumen-\ntation zu verstehen? - zur konstitutiven rolle von\npräsumtionen. In Geert-Lueke Lueken, editor, For-\nmen der Argumentation, pages 161–176. Leipziger\nUniversitätsverlag, Leipzig.\nThibault Sellam, Dipanjan Das, and Ankur P Parikh.\n2020. Bleurt: Learning robust metrics for text gener-\nation. arXiv preprint arXiv:2004.04696.\nRichard Shin, C. H. Lin, Sam Thomson, Charles Chen,\nSubhro Roy, Emmanouil Antonios Platanios, Adam\nPauls, D. Klein, J. Eisner, and Benjamin Van Durme.\n2021. Constrained language models yield few-shot\nsemantic parsers. ArXiv, abs/2104.08768.\nAndrew Siegel. 2018. Ethics of Stem Cell Research.\nIn Edward N. Zalta, editor, The Stanford Encyclope-\ndia of Philosophy, Winter 2018 edition. Metaphysics\nResearch Lab, Stanford University.\nShahbaz Syed, Khalid Al-Khatib, Milad Alshomary,\nHenning Wachsmuth, and Martin Potthast. 2021.\nGenerating informative conclusions for argumenta-\ntive texts. In FINDINGS.\nOyvind Tafjord and Peter Clark. 2021. General-purpose\nquestion-answering with macaw.\nOyvind Tafjord, Bhavana Dalvi Mishra, and Peter\nClark. 2020. Proofwriter: Generating implications,\nproofs, and abductive statements over natural lan-\nguage. arXiv preprint arXiv:2012.13048.\nAlon Talmor, Yanai Elazar, Yoav Goldberg, and\nJonathan Berant. 2020. olmpics - on what language\nmodel pre-training captures. Trans. Assoc. Comput.\nLinguistics, 8:743–758.\nChristian V oigt. 2014. Argdown and the stacked ma-\nsonry layout: Two user interfaces for non-expert\nusers. In Computational Models of Argument, pages\n483–484, Amsterdam et al. IOS Press.\nHenning Wachsmuth, Martin Potthast, Khalid Al Khatib,\nYamen Ajjour, Jana Puschmann, Jiani Qu, Jonas\nDorsch, Viorel Morari, Janek Bevendorff, and Benno\nStein. 2017. Building an argument search engine for\nthe web. In ArgMining@EMNLP.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,\nJoe Davison, Sam Shleifer, Patrick von Platen, Clara\nMa, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le\nScao, Sylvain Gugger, Mariama Drame, Quentin\nLhoest, and Alexander M. Rush. 2020. Transform-\ners: State-of-the-art natural language processing. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38–45, Online. Association\nfor Computational Linguistics.\nA Synthetic Argument Data\nThe AAAC datasets used in this study are pub-\nlicly available via Huggingface’s Hub – https:\n//huggingface.co/datasets/debatelab/aaac\n– where the construction of the datasets is\ndocumented meticulously.\nA synthetically generated AAAC record, which\nnicely illustrates the underdetermination of argu-\nment reconstruction, with two implicit premises,\n22\none distracting statement and a simple (one-step)\nargument (formatted as presented to the model):\nsource: It is not the case that Tracy\nis not an admirer of Fullerton and Tracy\nhas seen La Habra. Plus, if someone\nloves Chico, then they haven’t visited\nMonterey, owing to the fact that loving\nLaguna Beach is sufficient for not\nhaving visited Monterey.\nreasons: loving Laguna Beach is\nsufficient for not having visited\nMonterey (ref: (2))\nconjectures: if someone loves Chico,\nthen they haven’t visited Monterey (ref:\n(4))\nargdown:\n(1) If someone is an admirer of Chico,\nthen they are an admirer of Laguna Beach\nor a visitor of Stockton.\n(2) If someone admires Laguna Beach,\nthen they haven’t visited Monterey.\n(3) If someone has visited Stockton,\nthen they haven’t visited Monterey.\n-\nwith generalized dilemma (neg variant)\nfrom (1) (2) (3)\n-\n(4) If someone admires Chico, then they\nhaven’t visited Monterey.\npremises: If someone is an admirer\nof Chico, then they are an admirer of\nLaguna Beach or a visitor of Stockton.\n(ref: (1)) | If someone admires Laguna\nBeach, then they haven’t visited\nMonterey. (ref: (2)) | If someone\nhas visited Stockton, then they haven’t\nvisited Monterey. (ref: (3))\nconclusion: If someone admires Chico,\nthen they haven’t visited Monterey.\n(ref: (4))\npremises_form: (x): Fx -> (G x v H x)\n(ref: (1)) | (x): G x -> not I x (ref:\n(2)) | (x): H x -> not I x (ref: (3))\nconclusion_form: (x): F x -> not I x\n(ref: (4))\nkeys: F: admirer of Chico | G: admirer\nof Laguna Beach | H: visitor of Stockton\n| I: visitor of Monterey\nB Training Set-up\nBy interpreting a generative mode as a sequence-\nto-sequence task, we may translate a multi-angular\nDeepA2 dataset (e.g., AAAC01) into a multi-task\nsequence-to-sequence format, on which a sequence-\nto-sequence model can be trained. For each record\nin the multi-angular DeepA2 dataset, we randomly\nsample 14 modes in accordance with the weights\nprovided in Table 3 and add, for each mode, a corre-\nsponding sequence-to-sequence record to the train-\ning data. This results, for AAAC01, in a sequence-to-\nsequence training dataset with 14 ×16.000 records.\nOur models (base model T5-large with 770M\nparameters, and pretrained ArgumentAnalyst) are\nmode w1w2 mode w1w2 mode w1w2\nS;A 1. 1. S;R 1. 1. P;F .7 –\nSR ;A 1. 1. SJ ;R 1. 1. PCO ;F .7 –\nSJ ;A 1. 1. SA ;R 1. 1. C;O .7 –\nSRJ ;A 1. 1. S;J 1. 1. CPF ;O .7 –\nRJ ;A 1. 1. SR ;J 1. 1. PF ;K .7 –\nPC ;A 1. 1. SA ;J 1. 1. CO ;K .7 –\nA;P .2 .2 A;C .2 .2 PFCO ;K .7 –\nFK ;P .7 – OK ;C .7 –\nTable 3: 21 generative modes with corresponding\nweights in AAAC (w1) and EntailmentBank (w2) train-\ning data.\ntrained with batch-size 2 and learning rate 0.00001.\nFor AAAC01, eval loss starts to increase at epoch 8;\nwith EntailmentBank data, eval loss increases from\nepoch 2 onwards.\nC Iterative Prediction with Generative\nChains\nGenerative chains are implemented with a dynamic\ndictionary (9 keys, corresp. to the dimensions of\nDeepA2 data), which is initialized with the source\ntext, provides input for the generative modes, and is\nupdated after each generative step with the mode’s\ngenerated output. Output is generated with beam\nsearch decoding and beam width 2.\nTable 4 displays all generative chains we resort\nto in this study, all of which are used in the first\nexperiment. The second experiment makes use of\nchains 1–11. The third experiment deploys chains\n1–13.\nD Additional Results\nTable 5 assesses ArgumentAnalyst’s reconstruc-\ntions on specific subsets of the AAAC02 dataset (de-\nfined in Section 4) for three representative genera-\ntive chains.\nTable 6 details the performance of Argument-\nAnalyst on the entire AAAC02 dataset as measured\nby tailor-made argumentative metrics. Table 7\nshows the corresponding performance on out-of\n-sample eval data AAAC01.\nDistinguishing four mutually exclusive subsets\nof AAAC02, Tables 8–11 detail the the quality of\nArgumentAnalyst’s reconstruction for easy and\ndifficult problems. Tables 12–15 present the\ncorresponding out-of-sample performance on the\nequally partitioned AAAC01 dataset (eval split).\n23\n# mode sequence len. soph.\n1 S;A S;R S;J 3 0\n2 S;J S;R SJ ;A 3 1\n3 S;J S;R SR ;A 3 1\n4 S;J S;R RJ ;A 3 2\n5 S;J SJ ;R RJ ;A 3 3\n6 S;J SJ ;R SRJ ;A 3 3\n7 S;R SR ;J RJ ;A 3 3\n8 S;R SR ;J SRJ ;A 3 3\n9 S;A SA ;R SA ;J RJ ;A 4 4\n10 S;A SA ;R SA ;J SRJ ;A 4 4\n11 S;A SA ;R SA ;J SRJ ;A\nSA ;R SA ;J SRJ ;A\n7 8\n12 S;A A;P A;C P;F\nPF ;K FK ;P PC ;A\nSA ;R SA ;J\n9 11\n13 S;A A;P A;C C;O\nCO ;K OK ;C PC ;A\nSA ;R SA ;J\n9 11\n14 S;A A;P A;C C;O\nCO ;K OK ;C PC ;A A;P\nA;C P;F PF ;K FK ;P\nPC ;A SA ;R SA ;J\n15 20\n15 S;A A;P A;C P;F\nCPF ;O PFCO ;K FK ;P\nOK ;C PC ;A SA ;R\nSA ;J\n11 18\n16 S;A A;P A;C P;F\nCPF ;O PCO ;F PFCO ;K\nFK ;P OK ;C PC ;A\nSA ;R SA ;J\n12 21\nTable 4: 16 generative chains (without final formal-\nization sub-sequences) evaluated in this study. The\nillustrative chains highlighted in the main paper are\n#1 (straight), #9 (hermeneutic cycle), and #13 (logical\nstreamlining).\ninference presentation\nsimple compl. plain mutil. C&M\nchain N=1274 N=180 N=330 N=114 N=70\nSYS-PP & SYS-RP & SYS-RC & SYS-US\nstraight .95 .72 .98 .61 .69\nherm. c. .94 .68 .96 .67 .61\nlog. str. .95 .68 .98 .64 .61\nSYS-V AL\nstraight .84 .48 .88 .40 .34\nherm. c. .83 .56 .84 .49 .50\nlog. str. .82 .47 .86 .46 .37\nEXE-RSS\nstraight .03 -.25 .05 -.31 -.30\nherm. c. .20 .08 .15 .08 .11\nlog. str. .17 -.01 .13 .01 -.06\nEXE-JSS\nstraight .06 -.32 .10 -.37 -.37\nherm. c. .23 -.06 .21 -.03 -.21\nlog. str. .13 -.26 .07 -.26 -.40\nTable 5: Performance of ArgumentAnalyst on specific\nsubsets (columns) of the AAAC02 data as measured by\nselected systematic and exegetic metrics (sub-tables).\nRows display results for three illustrative generative\nchains (straight, hermeneutic cycle, logical streamlin-\ning).\n24\nsystematic metrics (SYS-*) exegetic metrics (EXE-*)\nchain PP RP RC US SCH V AL MEQ RSS JSS PPR PPJ TE\n#1 0.95 0.97 0.96 0.96 0.33 0.73 0.80 -0.08 -0.10 0.93 0.93 0.63\n#2 0.95 0.97 0.94 0.94 0.33 0.71 0.80 -0.09 0.04 0.93 0.93 0.67\n#3 0.95 0.98 0.95 0.93 0.31 0.70 0.80 0.10 -0.11 0.93 0.93 0.62\n#4 0.94 0.97 0.94 0.92 0.30 0.70 0.80 0.12 -0.00 0.93 0.93 0.66\n#5 0.94 0.97 0.95 0.91 0.30 0.70 0.83 0.13 0.05 0.94 0.93 0.69\n#6 0.94 0.97 0.95 0.93 0.31 0.70 0.83 0.10 0.03 0.94 0.93 0.67\n#7 0.93 0.97 0.95 0.92 0.29 0.70 0.83 0.13 0.05 0.93 0.92 0.68\n#8 0.94 0.97 0.95 0.93 0.30 0.69 0.83 0.10 0.02 0.93 0.92 0.67\n#9 0.95 0.98 0.95 0.93 0.31 0.72 0.82 0.16 0.12 0.93 0.92 0.71\n#10 0.96 0.98 0.96 0.94 0.32 0.71 0.82 0.14 0.09 0.93 0.92 0.69\n#11 0.96 0.98 0.96 0.93 0.32 0.71 0.82 0.15 0.11 0.93 0.92 0.71\n#12 0.93 0.95 0.94 0.94 0.32 0.71 0.81 -0.17 -0.08 0.93 0.92 0.68\n#13 0.95 0.97 0.96 0.95 0.32 0.72 0.82 0.11 -0.00 0.93 0.92 0.69\n#14 0.93 0.95 0.94 0.94 0.32 0.70 0.81 -0.18 -0.14 0.93 0.92 0.66\n#15 0.92 0.96 0.94 0.95 0.33 0.71 0.81 -0.20 -0.19 0.93 0.92 0.65\n#16 0.92 0.96 0.94 0.94 0.33 0.72 0.81 -0.20 -0.19 0.93 0.92 0.65\nTable 6: Performance of ArgumentAnalyst for systematic and exegetic metrics on the entire OOD eval data\n(AAAC02). Rows display mean results for each of the 16 generative chains.\nsystematic metrics (SYS-*) exegetic metrics (EXE-*)\nchain PP RP RC US SCH V AL MEQ RSS JSS PPR PPJ TE\n#1 0.97 0.98 0.97 0.98 0.61 0.87 0.78 0.08 0.13 0.95 0.95 0.64\n#2 0.97 0.98 0.96 0.97 0.60 0.87 0.78 0.09 0.24 0.95 0.95 0.68\n#3 0.96 0.98 0.96 0.97 0.58 0.86 0.78 0.26 0.12 0.95 0.95 0.64\n#4 0.95 0.98 0.95 0.96 0.57 0.85 0.78 0.26 0.20 0.95 0.95 0.67\n#5 0.96 0.98 0.95 0.96 0.57 0.84 0.80 0.27 0.27 0.96 0.95 0.70\n#6 0.97 0.98 0.96 0.96 0.58 0.84 0.80 0.26 0.24 0.96 0.95 0.69\n#7 0.95 0.98 0.96 0.96 0.57 0.86 0.79 0.27 0.26 0.95 0.94 0.71\n#8 0.96 0.98 0.96 0.96 0.57 0.85 0.79 0.26 0.25 0.95 0.94 0.70\n#9 0.97 0.99 0.97 0.97 0.59 0.88 0.79 0.31 0.36 0.96 0.95 0.78\n#10 0.97 0.99 0.97 0.97 0.60 0.87 0.79 0.30 0.34 0.96 0.95 0.77\n#11 0.97 0.99 0.97 0.97 0.60 0.87 0.79 0.31 0.35 0.96 0.95 0.77\n#12 0.95 0.97 0.95 0.96 0.54 0.84 0.79 0.17 0.25 0.96 0.94 0.75\n#13 0.97 0.99 0.97 0.97 0.61 0.87 0.79 0.29 0.32 0.96 0.95 0.76\n#14 0.95 0.97 0.95 0.96 0.54 0.84 0.79 0.16 0.24 0.96 0.94 0.74\n#15 0.94 0.97 0.95 0.96 0.54 0.85 0.79 0.15 0.18 0.96 0.95 0.73\n#16 0.94 0.97 0.95 0.95 0.54 0.85 0.79 0.15 0.19 0.96 0.95 0.73\nTable 7: Performance of ArgumentAnalyst for systematic and exegetic metrics on the entire OOS eval data (AAAC01).\nRows display mean results for each of the 16 generative chains.\n25\ninference presentation\nchain simple complex plain mutilat. C&M\nSYS-PP & SYS-RP & SYS-RC & SYS-US\n#1 0.95 0.72 0.98 0.61 0.69\n#2 0.93 0.66 0.96 0.59 0.60\n#3 0.92 0.69 0.96 0.68 0.73\n#4 0.92 0.66 0.95 0.69 0.60\n#5 0.92 0.68 0.95 0.59 0.61\n#6 0.93 0.66 0.97 0.68 0.59\n#7 0.92 0.67 0.96 0.62 0.64\n#8 0.92 0.66 0.95 0.64 0.66\n#9 0.94 0.68 0.96 0.67 0.61\n#10 0.94 0.73 0.98 0.68 0.77\n#11 0.94 0.69 0.98 0.66 0.73\n#12 0.93 0.60 0.95 0.57 0.50\n#13 0.95 0.68 0.98 0.64 0.61\n#14 0.92 0.57 0.93 0.58 0.49\n#15 0.92 0.66 0.95 0.59 0.56\n#16 0.92 0.64 0.95 0.56 0.60\nTable 8: Performance of ArgumentAnalyst for selected\nsystematic metric (SYS-PP & SYS-RP & SYS-RC & SYS-US) on\nspecific subsets (columns) of the OOD eval data.\ninference presentation\nchain simple complex plain mutilat. C&M\nSYS-V AL\n#1 0.84 0.48 0.88 0.40 0.34\n#2 0.82 0.54 0.84 0.47 0.46\n#3 0.82 0.44 0.87 0.39 0.36\n#4 0.81 0.48 0.83 0.44 0.43\n#5 0.82 0.44 0.85 0.45 0.37\n#6 0.81 0.46 0.85 0.42 0.41\n#7 0.83 0.44 0.82 0.46 0.49\n#8 0.80 0.44 0.83 0.40 0.40\n#9 0.83 0.56 0.84 0.49 0.50\n#10 0.82 0.50 0.85 0.46 0.43\n#11 0.82 0.48 0.84 0.46 0.41\n#12 0.81 0.47 0.84 0.42 0.37\n#13 0.82 0.47 0.86 0.46 0.37\n#14 0.80 0.48 0.82 0.41 0.40\n#15 0.82 0.45 0.84 0.50 0.33\n#16 0.83 0.52 0.85 0.46 0.43\nTable 9: Performance of ArgumentAnalyst for se-\nlected systematic metric ( SYS-V AL) on specific subsets\n(columns) of the OOD eval data.\ninference presentation\nchain simple complex plain mutilat. C&M\nEXE-RSS\n#1 0.03 -0.25 0.05 -0.31 -0.30\n#2 0.02 -0.27 0.07 -0.33 -0.31\n#3 0.15 -0.03 0.12 -0.01 -0.06\n#4 0.16 0.01 0.12 -0.01 0.04\n#5 0.18 0.04 0.13 0.04 0.06\n#6 0.17 -0.04 0.12 -0.02 -0.09\n#7 0.18 0.05 0.14 0.03 0.08\n#8 0.16 -0.02 0.12 -0.02 -0.07\n#9 0.20 0.08 0.15 0.08 0.11\n#10 0.19 0.04 0.15 0.05 -0.01\n#11 0.21 0.04 0.15 0.07 -0.03\n#12 -0.14 -0.20 -0.12 -0.23 -0.25\n#13 0.17 -0.01 0.13 0.01 -0.06\n#14 -0.17 -0.22 -0.16 -0.23 -0.26\n#15 -0.19 -0.23 -0.24 -0.24 -0.23\n#16 -0.19 -0.23 -0.24 -0.25 -0.24\nTable 10: Performance of ArgumentAnalyst for selected\nexegetic metrics (EXE-RSS) on specific subsets (columns)\nof the OOD eval data.\ninference presentation\nchain simple complex plain mutilat. C&M\nEXE-JSS\n#1 0.06 -0.32 0.10 -0.37 -0.37\n#2 0.16 -0.17 0.19 -0.12 -0.26\n#3 0.02 -0.32 0.03 -0.42 -0.33\n#4 0.12 -0.17 0.13 -0.14 -0.19\n#5 0.15 -0.11 0.15 -0.08 -0.18\n#6 0.16 -0.14 0.15 -0.22 -0.22\n#7 0.16 -0.11 0.16 -0.10 -0.18\n#8 0.15 -0.18 0.14 -0.19 -0.27\n#9 0.23 -0.06 0.21 -0.03 -0.21\n#10 0.23 -0.12 0.21 -0.15 -0.27\n#11 0.25 -0.13 0.20 -0.11 -0.27\n#12 0.06 -0.36 0.04 -0.28 -0.47\n#13 0.13 -0.26 0.07 -0.26 -0.40\n#14 -0.02 -0.39 -0.07 -0.31 -0.48\n#15 -0.08 -0.41 -0.16 -0.36 -0.49\n#16 -0.08 -0.37 -0.15 -0.35 -0.45\nTable 11: Performance of ArgumentAnalyst for selected\nexegetic metric (EXE-JSS) on specific subsets (columns)\nof the OOD eval data.\n26\ninference presentation\nchain simple complex plain mutilat. C&M\nSYS-PP & SYS-RP & SYS-RC & SYS-US\n#1 0.98 0.78 1.00 0.75 0.76\n#2 0.97 0.77 0.99 0.70 0.73\n#3 0.95 0.79 0.96 0.77 0.74\n#4 0.95 0.76 0.96 0.69 0.73\n#5 0.97 0.75 0.98 0.66 0.74\n#6 0.96 0.77 0.98 0.73 0.78\n#7 0.96 0.73 0.96 0.71 0.72\n#8 0.97 0.75 0.97 0.73 0.74\n#9 0.98 0.80 0.99 0.80 0.70\n#10 0.98 0.78 0.99 0.80 0.73\n#11 0.98 0.78 0.99 0.80 0.71\n#12 0.97 0.71 0.97 0.70 0.67\n#13 0.98 0.81 0.99 0.76 0.78\n#14 0.96 0.73 0.96 0.70 0.69\n#15 0.97 0.72 0.96 0.70 0.68\n#16 0.97 0.72 0.96 0.68 0.68\nTable 12: Performance of ArgumentAnalyst for selected\nsystematic metric (SYS-PP & SYS-RP & SYS-RC & SYS-US) on\nspecific subsets (columns) of the OOS eval data.\ninference presentation\nchain simple complex plain mutilat. C&M\nSYS-V AL\n#1 0.97 0.68 0.96 0.74 0.74\n#2 0.97 0.68 0.97 0.73 0.71\n#3 0.94 0.70 0.94 0.72 0.71\n#4 0.95 0.65 0.94 0.68 0.71\n#5 0.96 0.59 0.95 0.65 0.62\n#6 0.95 0.62 0.96 0.69 0.63\n#7 0.94 0.66 0.94 0.66 0.71\n#8 0.95 0.67 0.95 0.69 0.69\n#9 0.97 0.65 0.97 0.72 0.69\n#10 0.97 0.67 0.97 0.68 0.72\n#11 0.97 0.70 0.97 0.68 0.74\n#12 0.95 0.63 0.95 0.72 0.70\n#13 0.97 0.68 0.95 0.73 0.73\n#14 0.95 0.63 0.94 0.72 0.69\n#15 0.95 0.65 0.94 0.75 0.71\n#16 0.95 0.65 0.95 0.73 0.71\nTable 13: Performance of ArgumentAnalyst for se-\nlected systematic metric ( SYS-V AL) on specific subsets\n(columns) of the OOS eval data.\ninference presentation\nchain simple complex plain mutilat. C&M\nEXE-RSS\n#1 0.19 -0.16 0.11 -0.07 -0.18\n#2 0.21 -0.13 0.10 -0.05 -0.15\n#3 0.30 0.11 0.17 0.22 0.06\n#4 0.29 0.16 0.16 0.24 0.16\n#5 0.32 0.18 0.19 0.23 0.18\n#6 0.31 0.11 0.18 0.19 0.07\n#7 0.30 0.15 0.17 0.25 0.16\n#8 0.30 0.12 0.17 0.24 0.08\n#9 0.33 0.23 0.19 0.30 0.23\n#10 0.33 0.20 0.19 0.27 0.16\n#11 0.33 0.21 0.19 0.28 0.16\n#12 0.20 0.06 0.11 0.16 0.04\n#13 0.33 0.12 0.19 0.26 0.07\n#14 0.20 0.06 0.10 0.16 0.03\n#15 0.18 0.04 0.07 0.14 0.00\n#16 0.18 0.04 0.07 0.11 0.02\nTable 14: Performance of ArgumentAnalyst for selected\nexegetic metrics (EXE-RSS) on specific subsets (columns)\nof the OOS eval data.\ninference presentation\nchain simple complex plain mutilat. C&M\nEXE-JSS\n#1 0.35 -0.14 0.36 -0.09 -0.13\n#2 0.40 0.02 0.39 0.10 0.02\n#3 0.30 -0.15 0.29 -0.08 -0.15\n#4 0.36 0.03 0.33 0.08 -0.02\n#5 0.41 0.15 0.39 0.17 0.11\n#6 0.40 0.04 0.38 0.10 -0.01\n#7 0.39 0.12 0.37 0.15 0.06\n#8 0.39 0.08 0.38 0.10 -0.02\n#9 0.47 0.16 0.42 0.31 0.13\n#10 0.47 0.11 0.42 0.26 0.02\n#11 0.47 0.11 0.42 0.26 0.02\n#12 0.40 -0.01 0.35 0.14 -0.08\n#13 0.45 0.03 0.36 0.21 -0.01\n#14 0.38 -0.00 0.30 0.15 -0.05\n#15 0.30 -0.04 0.22 0.07 -0.07\n#16 0.30 -0.03 0.22 0.11 -0.06\nTable 15: Performance of ArgumentAnalyst for selected\nexegetic metric (EXE-JSS) on specific subsets (columns)\nof the OOS eval data.\n27"
}