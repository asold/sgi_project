{
  "title": "Large Language Models’ Clinical Decision-Making on When to Perform a Kidney Biopsy: Comparative Study",
  "url": "https://openalex.org/W4410959289",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5077584150",
      "name": "Michael Toal",
      "affiliations": [
        null,
        "Queen's University Belfast",
        "Royal Victoria Hospital",
        "University of Ulster"
      ]
    },
    {
      "id": "https://openalex.org/A5101518603",
      "name": "Christopher Hill",
      "affiliations": [
        null,
        "Belfast City Hospital",
        "University of Ulster"
      ]
    },
    {
      "id": "https://openalex.org/A5012532898",
      "name": "Michael Quinn",
      "affiliations": [
        null,
        "Queen's University Belfast",
        "Royal Victoria Hospital",
        "University of Ulster"
      ]
    },
    {
      "id": "https://openalex.org/A5016414995",
      "name": "Ciarán O’Neill",
      "affiliations": [
        null,
        "Queen's University Belfast",
        "Royal Victoria Hospital",
        "University of Ulster"
      ]
    },
    {
      "id": "https://openalex.org/A5090093329",
      "name": "Alexander P. Maxwell",
      "affiliations": [
        null,
        "Queen's University Belfast",
        "Royal Victoria Hospital",
        "University of Ulster"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4377011132",
    "https://openalex.org/W4400324908",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4388836341",
    "https://openalex.org/W4403782233",
    "https://openalex.org/W4401653419",
    "https://openalex.org/W4386222752",
    "https://openalex.org/W4367310920",
    "https://openalex.org/W4392739577",
    "https://openalex.org/W2972214324",
    "https://openalex.org/W4403195667",
    "https://openalex.org/W4389917881",
    "https://openalex.org/W4392362609",
    "https://openalex.org/W4389204852",
    "https://openalex.org/W4399120295",
    "https://openalex.org/W2093073362",
    "https://openalex.org/W3190099424",
    "https://openalex.org/W4397293584",
    "https://openalex.org/W4394873790",
    "https://openalex.org/W4392850382",
    "https://openalex.org/W4392504747",
    "https://openalex.org/W4399923676",
    "https://openalex.org/W4405632956",
    "https://openalex.org/W2158515517",
    "https://openalex.org/W4392597393",
    "https://openalex.org/W4378472917",
    "https://openalex.org/W4389312580",
    "https://openalex.org/W4318261797",
    "https://openalex.org/W4408165783",
    "https://openalex.org/W4393287322",
    "https://openalex.org/W4392632345"
  ],
  "abstract": "Abstract Background Artificial intelligence (AI) and large language models (LLMs) are increasing in sophistication and are being integrated into many disciplines. The potential for LLMs to augment clinical decision-making is an evolving area of research. Objective This study compared the responses of over 1000 kidney specialist physicians (nephrologists) with the outputs of commonly used LLMs using a questionnaire determining when a kidney biopsy should be performed. Methods This research group completed a large online questionnaire for nephrologists to determine when a kidney biopsy should be performed. The questionnaire was co-designed with patient input, refined through multiple iterations, and piloted locally before international dissemination. It was the largest international study in the field and demonstrated variation among human clinicians in biopsy propensity relating to human factors such as sex and age, as well as systemic factors such as country, job seniority, and technical proficiency. The same questions were put to both human doctors and LLMs in an identical order in a single session. Eight commonly used LLMs were interrogated: ChatGPT-3.5, Mistral Hugging Face, Perplexity, Microsoft Copilot, Llama 2, GPT-4, MedLM, and Claude 3. The most common response given by clinicians (human mode) for each question was taken as the baseline for comparison. Questionnaire responses on the indications and contraindications for biopsy generated a score (0-44) reflecting biopsy propensity, in which a higher score was used as a surrogate marker for an increased tolerance of potential associated risks. Results The ability of LLMs to reproduce human expert consensus varied widely with some models demonstrating a balanced approach to risk in a similar manner to humans, while other models reported outputs at either end of the spectrum for risk tolerance. In terms of agreement with the human mode, ChatGPT-3.5 and GPT-4 (OpenAI) had the highest levels of alignment, agreeing with the human mode on 6 out of 11 questions. The total biopsy propensity score generated from the human mode was 23 out of 44. Both OpenAI models produced similar propensity scores between 22 and 24. However, Llama 2 and MS Copilot also scored within this range but with poorer response alignment to the human consensus at only 2 out of 11 questions. The most risk-averse model in this study was MedLM, with a propensity score of 11, and the least risk-averse model was Claude 3, with a score of 34. Conclusions The outputs of LLMs demonstrated a modest ability to replicate human clinical decision-making in this study; however, performance varied widely between LLM models. Questions with more uniform human responses produced LLM outputs with higher alignment, whereas questions with lower human consensus showed poorer output alignment. This may limit the practical use of LLMs in real-world clinical practice.",
  "full_text": null,
  "topic": "Preprint",
  "concepts": [
    {
      "name": "Preprint",
      "score": 0.9056425094604492
    },
    {
      "name": "Computer science",
      "score": 0.49846768379211426
    },
    {
      "name": "Clinical decision making",
      "score": 0.4965894818305969
    },
    {
      "name": "Medicine",
      "score": 0.3578624725341797
    },
    {
      "name": "Data science",
      "score": 0.34271955490112305
    },
    {
      "name": "Intensive care medicine",
      "score": 0.2363843321800232
    },
    {
      "name": "World Wide Web",
      "score": 0.18680039048194885
    }
  ]
}