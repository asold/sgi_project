{
  "title": "A Novel Transformer Network With Shifted Window Cross-Attention for Spatiotemporal Weather Forecasting",
  "url": "https://openalex.org/W4387623972",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5065873137",
      "name": "Alabi Bojesomo",
      "affiliations": [
        "Khalifa University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5028846094",
      "name": "Hasan Al-Marzouqi",
      "affiliations": [
        "Khalifa University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5083852325",
      "name": "Panos Liatsis",
      "affiliations": [
        "Khalifa University of Science and Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3111294584",
    "https://openalex.org/W2893954686",
    "https://openalex.org/W2963870721",
    "https://openalex.org/W2998567488",
    "https://openalex.org/W3019433526",
    "https://openalex.org/W3035548318",
    "https://openalex.org/W2771590586",
    "https://openalex.org/W2991559313",
    "https://openalex.org/W2913181540",
    "https://openalex.org/W3120451880",
    "https://openalex.org/W1641696774",
    "https://openalex.org/W2849449027",
    "https://openalex.org/W6775349354",
    "https://openalex.org/W6756106973",
    "https://openalex.org/W3214062507",
    "https://openalex.org/W3211959704",
    "https://openalex.org/W6684191040",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W2963446712",
    "https://openalex.org/W1901129140",
    "https://openalex.org/W6786746828",
    "https://openalex.org/W6786387658",
    "https://openalex.org/W6804290963",
    "https://openalex.org/W6784333009",
    "https://openalex.org/W3131500599",
    "https://openalex.org/W4214520160",
    "https://openalex.org/W6796931752",
    "https://openalex.org/W4313007769",
    "https://openalex.org/W3138516171",
    "https://openalex.org/W4312560592",
    "https://openalex.org/W6800092589",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4321232185",
    "https://openalex.org/W4206632615",
    "https://openalex.org/W2625366777",
    "https://openalex.org/W6955071965",
    "https://openalex.org/W4212798740",
    "https://openalex.org/W2964006653",
    "https://openalex.org/W3157507404",
    "https://openalex.org/W2970403389",
    "https://openalex.org/W1789155650",
    "https://openalex.org/W1840414008",
    "https://openalex.org/W6632039431",
    "https://openalex.org/W2001459659",
    "https://openalex.org/W2782714865",
    "https://openalex.org/W3216328498",
    "https://openalex.org/W4206973253",
    "https://openalex.org/W4200474599",
    "https://openalex.org/W4210573520",
    "https://openalex.org/W3119915340",
    "https://openalex.org/W3177257602",
    "https://openalex.org/W2744623438",
    "https://openalex.org/W4210551630",
    "https://openalex.org/W4386034829",
    "https://openalex.org/W2036373175",
    "https://openalex.org/W2939806510",
    "https://openalex.org/W3159574193",
    "https://openalex.org/W4200061747",
    "https://openalex.org/W4210802227",
    "https://openalex.org/W6631848642",
    "https://openalex.org/W2639416113",
    "https://openalex.org/W3204636251",
    "https://openalex.org/W6788733023",
    "https://openalex.org/W3213415193",
    "https://openalex.org/W4290999163",
    "https://openalex.org/W4220664202",
    "https://openalex.org/W4205857837",
    "https://openalex.org/W4205099615",
    "https://openalex.org/W3202525453",
    "https://openalex.org/W3164939772",
    "https://openalex.org/W4317233441",
    "https://openalex.org/W4291366335",
    "https://openalex.org/W6628877408",
    "https://openalex.org/W4292829076",
    "https://openalex.org/W6745829810",
    "https://openalex.org/W6750259706",
    "https://openalex.org/W6739112683",
    "https://openalex.org/W4312304706",
    "https://openalex.org/W4379382937",
    "https://openalex.org/W3196107618",
    "https://openalex.org/W2884822772",
    "https://openalex.org/W6797399245",
    "https://openalex.org/W6780226713",
    "https://openalex.org/W2735039185",
    "https://openalex.org/W3209483374",
    "https://openalex.org/W6631190155",
    "https://openalex.org/W2037204816",
    "https://openalex.org/W3119773408",
    "https://openalex.org/W3108791197",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W3112689352",
    "https://openalex.org/W2619947201",
    "https://openalex.org/W3013229294",
    "https://openalex.org/W3171087525",
    "https://openalex.org/W3094502228",
    "https://openalex.org/W3105636206",
    "https://openalex.org/W2163605009",
    "https://openalex.org/W3190216403",
    "https://openalex.org/W2768975186",
    "https://openalex.org/W2901060304"
  ],
  "abstract": "Earth observation is a growing research area that can capitalize on the powers of artificial intelligence for short time forecasting, a now-casting scenario. In this work, we tackle the challenge of weather forecasting using a video transformer network. Vision transformer architectures have been explored in various applications, with major constraints being the computational complexity of attention and the data-hungry training. To address these issues, we propose the use of video Swin-transformer (VST), coupled with a dedicated augmentation scheme. Moreover, we employ gradual spatial reduction on the encoder side and cross-attention on the decoder. The proposed approach is tested on the Weather4Cast2021 weather forecasting challenge data, which requires the prediction of 8 h ahead future frames (4 per hour) from an hourly weather product sequence. The dataset was normalized to 0&#x2013;1 to facilitate the use of the evaluation metrics across different datasets. The model results in an mse score of 0.4750 when provided with training data, and 0.4420 during transfer learning without using training data, respectively.",
  "full_text": "JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERV ATIONS AND REMOTE SENSING, VOL. 1, NO. 1, APRIL 2022 1\nA Novel Transformer Network with Shifted\nWindow Cross-Attention for Spatiotemporal\nWeather Forecasting\nAlabi Bojesomo, Hasan AlMarzouqi, Panos Liatsis\n{alabi.bojesomo, hasan.almarzouqi, panos.liatsis }@ku.ac.ae\nAbstract—Earth Observation is a growing research area that\ncan capitalize on the powers of AI for short time forecasting,\na now-casting scenario. In this work, we tackle the challenge\nof weather forecasting using a video transformer network.\nVision transformer architectures have been explored in various\napplications, with major constraints being the computational\ncomplexity of attention and the data-hungry training. To address\nthese issues, we propose the use of Video Swin-Transformer,\ncoupled with a dedicated augmentation scheme. Moreover, we\nemploy gradual spatial reduction on the encoder side and cross-\nattention on the decoder. The proposed approach is tested on\nthe Weather4Cast2021 weather forecasting challenge data, which\nrequires the prediction of 8 hours ahead future frames (4 per\nhour) from an hourly weather product sequence. The dataset was\nnormalized to 0-1 to facilitate the use of the evaluation metrics\nacross different datasets. The model results in an MSE score\nof 0.4750 when provided with training data, and 0.4420 during\ntransfer learning without using training data, respectively.\nIndex Terms—Weather forecasting, Now-casting, Shifted Win-\ndow Cross Attention, Encoder-Decoder Video Architecture, Video\nSwin-Transformer\nI. I NTRODUCTION\nWeather forecasting is a crucial driving force in agriculture\nand the autonomous vehicle industry [1]. Accurate weather\nforecasting affects the successful deployment of autonomous\nvehicles and the management of food production. When de-\nsigning autonomous navigation and collision avoidance tech-\nnologies, for example, awareness of the weather is an essential\npart of the location context. Also, reasonable weather predic-\ntion is essential in monitoring soil nutrients and regulating\ncrop yield in the agricultural industry.\nArtificial intelligence (AI) is gradually gaining traction\nin weather forecasting due to its relative simplicity, when\ncompared to numerical weather prediction (NWP) [2]–[6]. AI\napproaches applicable to weather forecasting can be catego-\nrized according to the network structure, e.g., Convolutional\nNeural Networks (CNN) [7]–[10], Autoencoders [11], [12],\nand recurrent networks [13]–[16].\nCNN has been used in many state-of-the-art image classifi-\ncation [17]–[19] and semantic segmentation models [20], [21].\nSpatiotemporal forecasting has also been tackled with CNN\nmodels, based on their demonstrated performance on segmen-\ntation tasks [21]–[23]. Recently, self-attention transformer-\nbased models have gradually revolutionized computer vision\nThe authors are with the Department of Electrical Engineering and Com-\nputer Sciences, Khalifa University, Abu Dhabi, United Arab Emirates.\napplications [24]–[27]. While natural language processing\n(NLP) uses transformer networks on encoded tokens, vision\ntransformer-based models utilize patch-based image encoding\n[24]. Vision transformers are showing promise in many ap-\nplications; however, they involve the computationally costly\nself-attention mechanism, which presents a challenge to be\naddressed. Various modifications of self-attention [28]–[31]\nhave been proposed in the literature to address computational\ndemands.\nThe vision transformer is widely used in many computer\nvision applications, including semantic segmentation [24]–\n[26], [32]. Dosovitskiy et al., [24] uses patch-based image\nencoding, similar to word embedding in NLP, making vision\nproblems amenable to the transformer network [32]. Other\nworks explore modifications of the attention layer, resulting\nin more efficient transformer architectures for vision tasks,\nsuch as the pyramid vision transformer [25]. Spatiotemporal\nforecasting is similar to dense prediction tasks, e.g., depth es-\ntimation and segmentation, which have been tackled by CNN-\nbased architectures [20]. However, more recently, the vision\ntransformer is gradually becoming the dominant architecture\nin these applications [24]–[26], [29].\nAmong the widely adopted vision transformer architecture\nis the Shifted Window Transformer (Swin Transformer), which\nuses local window attention with shift operations between\ntransformer layers [29], popular in classification tasks. The\nSwin transformer has also been used as an encoder (feature\nextractor) for downstream tasks, such as object detection,\nsegmentation [33], and forecasting [21], [34]–[36]. Cao et al.\n[33] replace all CNN blocks of the typical UNet architecture\n[20] with swin transformer blocks, resulting in the Swin-\nUNet architecture. The Swin-UNet network uses an MLP-\nbased layer (Multilayer perceptron) as a patch expanding\nlayer for upsampling in the decoding branch. This layer can\nbe viewed as the opposite of the MLP-based downsampling\nlayer (i.e., patch merging layer), used in pyramid vision\ntransformers [25], [29], [33]. Lio et al. [30] proposed the 3-\ndimensional (3D/Video) Swin Transformer, replacing the patch\nembedding, patch merging and shifted window transformer\nwith their respective 3D variants, resulting in a parameter-\nefficient network, as evidenced in performance on several\nvideo datasets (e.g., Something-Something v2 [37], Kinetics-\n400 [38] and kinetics-600) [30].\nLow-rank architectures have also been applied for forecast-\ning time-series data with the aim of improving performance.\nThis article has been accepted for publication in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/JSTARS.2023.3323729\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERV ATIONS AND REMOTE SENSING, VOL. 1, NO. 1, APRIL 2022 2\nA novel multistep forecasting framework is proposed in [39]\nto address the challenges of ultra-short-term forecasting of\nwind speed and wind power. The approach combines selec-\ntive Hankelization, tensor decomposition, feature selection,\nand a low-rank tensor learning-based predictor. The method\nconverts the time series into a high-order tensor structure\nusing Hankelization and utilizes a low-rank tensor learning\nnetwork with an LSTM-based encoder and attention-based\ndecoder. Feature selection using similarity search is employed\nto enhance accuracy. The approach improves the accuracy\nof wind power and wind speed forecasting, but requires\nhigher computational costs. In [40], a structured low-rank\nmatrix completion is applied for data imputation in time series\nforecasting. The method employs Hankel matrices and convex\nrelaxation based on the nuclear norm. Proposed approach\nintroduces a new formulation that assigns different weights\nfor previous observations, resulting in improved performance.\nExperiments demonstrate its superiority in multi-step ahead\nprediction compared to state-of-the-art methods. Inspired by\ncompressed sensing, [41] introduces the Convolution Nuclear\nNorm Minimization (CNNM) approach to recover the future\npart of convolutionally low-rank time series. However, CNNM\nis sensitive to trends and dynamics. To address this, a learnable\northonormal transformation called Learning-Based CNNM\n(LbCNNM) is proposed. LbCNNM uses principal component\npursuit (PCP) to learn suitable transformations, integrating dic-\ntionary learning, model combination, and coherence. Although\ncomputationally complex, LbCNNM effectively handles time\nseries components and incorporates forecasts from other meth-\nods. In [42], an RNN-based time series model is combined\nwith a Gaussian copula process output model with a low-\nrank covariance structure. This approach enables modeling\ntime-varying correlations among numerous time series with\nnon-Gaussian marginal distributions. A low-rank factorization\nof the covariance matrix and a recursive formula for pa-\nrameter estimation and likelihood computation are employed.\nHowever, the computational resources necessary for practical\ndeployment of low-rank based methods in spatiotemporal\nforecasting are substantial.\nIn this paper, we propose a computationally efficient ar-\nchitecture based on transformers capable of capturing long-\nterm spatiotemporal interactions for weather forecasting. Our\ncontributions include the following:\n1) We propose a deep learning architecture capable of\ncapturing complex spatial relationships in remote sens-\ning images, through the novel paradigm of Video Swin\nTransformer (VST) with shifted window cross-attention.\nThe incorporation of shifted window attention promotes\nthe exploration of inter-window relationships and global\ncorrelation integration, while effectively mitigating com-\nputational overhead. In addition, we employ cross-\nattention in the decoder, to enahnce feature extraction\nand further optimize computational efficiency.\n2) The performance of the proposed approach is evaluated\non the Weather4Cast2021 weather forecasting challenge\ndataset. The objective is to predict the future frames\n8 hours ahead based on an hourly weather product\nsequence, with 4 frames per hour. Our model achieves\ncompetitive results compared to the state-of-the-art, at-\ntaining an MSE score of 0.4750 when trained with\navailable data and 0.4420 through transfer learning with-\nout utilizing training data. Notably, this is achieved by\nutilizing less than 50% of the parameters used by the\nmodel achieving the first position on the competition\nleaderboard, leading to faster training and inference\ntimes.\n3) Lastly, we present an ablation study that includes a quan-\ntitative analysis and systematic evaluation of the model’s\nprediction performance, focusing on both the weather\nproducts and the network structure. A qualitative analy-\nsis of the model prediction is presented, offering detailed\ninsights into its performance with respect to future time\nsteps (e.g., Fig. 6).\nThe outline of the paper is as follows. A summary of related\nworks is presented in Section II. The details of the proposed\narchitecture and its layers are given in Section III, while the\nexperimental results of the proposed approach in the IEEE\nBig Data 2021 Weather4cast challenge data are presented in\nSection IV. Finally, Section V provides the conclusions of this\nresearch and avenues for further work.\nII. R ELATED WORKS\nWeather forecasting is the foundation of meteorology. Tra-\nditionally, weather prediction is based on physical modeling\nof the associated physical phenomena. This numerical weather\nprediction (NWP) approach requires the solution of spatiotem-\nporal partial differential equations (PDE), related to a vari-\nety of underlying atmospheric processes, including radiative,\nchemical, dynamic, thermodynamic, etc [43]. It is obvious that\nmodeling and solving this multitude of atmospheric processes\nrequires substantial computational resources, which is, indeed,\none of the disadvantages of the NWP method [44]. However,\nthe most important drawback of the PDE approach is the\nchaotic nature of weather [45], which makes model perfor-\nmance highly dependent on the initial conditions. The use of\nNWP in short-term weather forecasting is problematic, it is\na popular approach in long-term forecasting, as it is able to\ntrack long-scale trends [46].\nThe spatiotemporal nature of weather prediction offers\nmajor opportunities and challenges for the use of AI and\ndata analytics methods. Data-driven weather prediction helps\nto avoid both the known and unknown chaotic behavior of\nweather fluctuations by focusing on the evolution of available\ndata [47]. Physical phenomena associated with the weather\nare too complex to model and sometimes not well under-\nstood, paving the way for a relatively simpler data-driven\napproach. AI methods for weather forecasting can be classified\ninto machine learning- and deep learning-based. Furthermore,\nmachine learning (ML) architectures, applied to weather fore-\ncasting, can be grouped into static and dynamic (recurrent)\nin terms of whether the prediction is generated sequentially\n[48]–[51], or not. Static ML architectures include clustering\n(K-means, PCA) [52], [53], artificial neural networks (ANN)\n[49], [54], [55], graph neural networks (GNN) [56], clustering\nThis article has been accepted for publication in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/JSTARS.2023.3323729\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERV ATIONS AND REMOTE SENSING, VOL. 1, NO. 1, APRIL 2022 3\n+ neural networks [57], [58], decision trees such as Gradient\nBoosting (XGBoost [59], AdaBoost [50], CatBoost [50], [60],\n[61]), and Random Forest [62], [63]. On the other hand,\ndynamic ML architectures for weather forecasting make use\nof the sequential nature of training data in generating the\nforecast. Methods in this category include partially recurrent\narchitectures (e.g., Elman neural networks (ENN)) [64], and\nfully recurrent ones, such as recurrent neural networks (RNN),\nlong short-term memory (LSTM) and gated recurrent units\n(GRU). The principle of fully recurrent architectures is that\nthey capitalize on the dynamic patterns in the input data\nsequences [8], [11], [14], [65]–[67]. The common challenge\nof machine learning-based methods is that they require a\ngood understanding of weather parameters in order to perform\nappropriate feature engineering. This limits their applicability\nas not all contributing factors to weather changes are yet\nknown or can be accurately measured and/or tracked.\nDeep learning-based approaches alleviate the need for the\nfeature engineering stage of ML methods. Instead, feature\nlearning is automatically performed with the use of convo-\nlution blocks, allowing data-driven extraction of the required\nfeatures. These features are then used as the input to the clas-\nsification/ regression layer, which is usually a fully connected\nlayer. Considering the spatiotemporal setting of weather data,\nCNN can be readily applied [10], NeXtNow [68], U-STNx\n[69]. In [20], a UNet architecture with a densely connected\nbackbone was used for weather prediction [70], where the\ncontinuous aggregation of the densely connected CNN in the\nbackbone ensures the reuse of the intermediate-state results.\nMoreover, generative adversarial networks (GAN) have been\nsuccessfully applied in weather forecasting [71]–[73], [74],\n[75]. Spatiotemporal weather forecasting using deep learning\nrequires appropriate treatment of the spatial and temporal in-\nformation in the data. For instance, CNN can be used to extract\nfeatures from the spatial information, while recurrent networks\n(RNN, LSTM, GRU) can be used to model the temporal\ninterrelationship. Combining CNN with recurrent networks\nresults in architectures such as ConvLSTM [15], [16], [76],\n[77], [54], PredRNN [78], PredRNN++ [79], MetNet [13],\nTrajGRU [80], ConvGRU [67], MFNet [81]. Spatiotemporal\nweather forecasting can also be tackled with transformers [82],\noriginally proposed for NLP [32]. This is because attention\nnetworks used in transformer can eradicate the need for time\nconsuming sequential forecasting, an approach common to\nrecurrent networks (ConvLSTM [76], PredRNN [78], Pre-\ndRNN++ [79], ConvGRU [67]).\nThe state-of-the-art (SOTA) architectures for spatiotemporal\nweather forecasting [67], [70], [71] are memory intensive and\nrequire a substantially large number of parameters. In light\nof this, there is a need to develop light-weight, efficient, and\nimproved accuracy spatiotemporal weather prediction models.\nIn this research, we are motivated by the self-attention\nmechanism of transformers, as it can capture the relationship\nbetween the input variables [32]. In fact, vision transformers\nare gradually dominating computer vision applications, includ-\ning dense prediction [26], [33]. These architectures [24], [28]–\n[31] can be applied to weather prediction. Solutions for this\napplication involve an encoder (backbone, feature extractor)\nand a decoder (segmentor, predictor, forecaster) [57], [67],\n[70], [71]. This makes models designed for classification\napplicable as feature extractors. Furthermore, decoders such\nas UNet [20], FaPN [83], UperNet [84], SegFormer [85]\namong others have been proposed for dense prediction (e.g.,\nweather forecasting). Among all these decoders, SegFormer\nuses attention layers, while others are based on CNN.\nIII. M ETHODS\nFig. 1. Spatiotemporal Encoder-Decoder architecture with cross attention in\nthe decoder.\nThe proposed model (see Fig. 1) includes multiple stages for\ngradual downsampling of the spatial dimension in the encoder,\nwhich aid in capturing salient global representations. The\nencoder uses self-attention, and the decoder employs cross-\nattention to merge the skip connected input from the encoder\nwith its main input [32], [35]. The developed model uses\nshifted window attention [30]. This encourages the exploita-\ntion of inter-window relationships as local window attention\nis used to reduce the computational overhead (see Fig. 2).\nRegular local transformer models exhibit a non-global cor-\nrelation similar to convolutional networks. The inter-window\nrelationship in shifted window transformer has the power to\nintegrate the global correlation, even while being window-\nbased.\nAs shown in Fig. 1, the input enters the network through a\npatch embedding layer, while the final output of the model\ncomes from a projected patch expanding layer. The patch\nembedding layer converts the spatiotemporal inputs into to-\nkens, while the final output is a projection of tokens to\nspatiotemporal format. Three encoder and three decoder blocks\nare included in the model, each with four 3D transformer\nlayers (encoder/decoder). The limited number of layers helps\nto avoid the need for huge datasets to pre-train transformer-\nbased models [24], [26], [29], [30]. The proposed model is\ncomposed of several layers and blocks; including the patch\npartitioning layer, patch merging layer, patch expanding layer,\nand the shifted window transformer encoder and decoder\nblocks.\nA. Patch Transformation Blocks\nThe transformation of the input into workable patches as re-\nquired by the transformer-based model is carried out by patch-\nspecific layers. Also, the downsampling and upsampling in the\nThis article has been accepted for publication in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/JSTARS.2023.3323729\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERV ATIONS AND REMOTE SENSING, VOL. 1, NO. 1, APRIL 2022 4\nintermediate blocks in the encoder and decoder, respectively,\nneed the path transformation blocks.\nIn the patch partitioning layer , the spatiotemporal features\nare divided into patches and transformed using linear em-\nbedding. Two CNN layers are used to accomplish this. The\nfirst convolution has a stride value equal to its kernel size\ndimension to encourage patch partitioning, whereas the second\nconvolution has a kernel size of 1 for linear embedding.\nThe patch merging layer down-samples features using linear\n(fully-connected (FC) layer, making it a knowledge-based\noperation contrary to traditional rule based ones (Average/Max\npooling operation). This layer flattens the features of each\ngroup of patches (2 x 2). This is followed by applying an\nFC-layer to convert the 4*C-dimensional features to 2*C-\ndimensional output, where C is the number of channels of\nthe incoming features [29], [30]. On the decoding branch of\nthe network, we have the patch expanding layer, which works\nin exactly the opposite way to the patch merging layer , thus\nresulting in a learned up-sampling operation.\nThe projection head of the network (Fig. 1) includes a patch\nexpanding layer to recover the original spatial dimensions.\nThis is followed by an FC-layer for channel dimension pro-\njection.\nB. Encoder Blocks\nThe proposed model’s encoder backbone network includes\na multi-stage Video Swin transformer (VST). We employ three\nstages (Fig. 1), each with four 3D transformer layers. Apart\nfrom the first encoder, which has linear embedding, each\nsubsequent encoder block has a Patch Merging unit, followed\nby Swin-Transformers.\nA multi-head self-attention (MSA) [24] layer is followed\nby a feed-forward network in the transformer layer used for\ncomputer vision tasks, with each of these layers preceded by\nlayer normalization (LN) [86]. Because of the spatiotemporal\nnature of the input, the 3D shifted-window MSA is used in\nthis study (See Fig. 2). As highlighted in Fig. 3, the Swin\nFig. 2. Outline of the local window grouping in the shifted window-based\narchitecture. The local window is shifted for a layern + 1 following a regularly\nplaced window in layer n. Since self(cross)-attention is window based, the\nshifting operation between layers provides the necessary connection, otherwise\nmissing in local window-based attention. [29]\nTransformer makes use of an interchange of sliding windows,\nwhere window (local) attention is next to another local but\nshifted window attention. This arrangement leads to equation\n(1) for any two attention layers:\nFig. 3. Swin Transformer Encoder block: An encoder stacking of two con-\ncurrent self-attention layers is shown, with shifted-window attention always\ncoming after non-shifted ones.\n¯xl = W-MSA(LN(xl−1)) + xl−1\nxl = MLP(LN(¯xl)) + ¯xl\n¯xl+1 = SW-MSA(LN(xl)) + xl\nxl+1 = MLP(LN(¯xl+1)) + ¯xl+1\n(1)\nwhere xl is the activation map (continuously processed input)\nof layer l, LN and MLP represent the layer normalization and\nfeed-forward layer, respectively, and W-MSA and SW-MSA\nrepresent windowed multi-head self-attention and shifted win-\ndow multi-head self-attention, respectively. In both W-MSA\nand SW-MSA, a relative position bias is used [29], [30]. How-\never, the primary distinction between W-MSA and SW-MSA\nis a shift in window positioning before computing the local\nattention within the windowed blocks. In this research, we use\n(1, 7, 7) as the window size for all Swin transformers, with a\nshift size of 2 for the shifted window versions. Additionally,\nthe MLP layers include two FC-layers (eqn 2):\nMLP(X) = f1(f2(X ∗ W1) ∗ W2) (2)\nwhere f1 and f2 are the transfer functions of the two layers,\nrespectively, X ∈ ℜ... x d is the input with ... being the other\npossible dimensions of the input, W1 ∈ ℜd x 4d is the weight\nThis article has been accepted for publication in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/JSTARS.2023.3323729\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERV ATIONS AND REMOTE SENSING, VOL. 1, NO. 1, APRIL 2022 5\nmatrix of the first (hidden) fully-connected layer and W2 ∈\nℜ4d x d is the weight matrix of (output) fully-connected layer.\nC. Decoder Blocks\nIn the decoder, we use multihead cross attention (MCA)\nunits that enable the interaction of encoded tokens with\ndecoding ones. In contrast to MSA which uses the same input\nas the key, query and value, MCA uses one input as the key\nand value, while using another as the query. This ensures that\nwe can explore the dependency of one input ( query) on the\nother parameters.\nThe use of multi-head cross-attention only deals with the\ninteraction between the skip connection (from the encoder) and\nthe decoding input. There arises the need to further deal with\nself-dependency in the form of self-attention of the resulting\noutput after MCA is applied before applying the MLP network.\nThe MSA layer is followed by another MCA layer in the\ndecoder [32]. Such an arrangement merges the skip-connected\npart with the decoding input. While this process is done\nusing addition in LinkNet [87] and by concatenation in U-\nNet [20], we use multi-head cross attention [32]. The building\nblocks of our cross-attention-based decoding are preceded by\nlayer normalization, an approach commonly used with Vision\ntransformers [24], [34]–[36].\nSimilar to the encoder layers, we use a 3D shifted window\nMCA in the decoder. Related to eq. (1), the Swin transformers\nin the decoder blocks alternately used self and cross attention,\nfollowed by shifted window self and cross attention, as illus-\ntrated in equation (3) (Fig. 4):\n¯xl = W-MSA(LN(xl−1)) + xl−1\n¯¯xl = W-MCA(LN(¯xl), y) + ¯xl\nxl = MLP(LN(¯¯xl)) + ¯¯xl\n¯xl+1 = SW-MSA(LN(xl)) + xl\n¯¯xl+1 = SW-MCA(LN(¯xl+1), y) + ¯xl+1\nxl+1 = MLP(LN(¯¯xl+1)) + ¯¯xl+1\n¯xl+1 = SW-MSA(LN(xl)) + xl\nxl+1 = MLP(LN(¯xl+1)) + ¯xl+1\n(3)\nwhere y represents the output of the corresponding encoder\n(skip connection) as shown in fig. (1). All other variables and\nfunctions follow the definitions in (eq. 1). The W-MCA and\nSW-MCA units are defined here with two inputs compared\nwith W-MSA and SW-MSA in (eq. 1).\nIV. E XPERIMENTAL RESULTS\nA. Data Description\nThe proposed system was tested on the challenging Traf-\nfic4cast 2021 [88], [89] weather dataset. The dataset used\nwas part of the the IEEE BigData Conference competition\nfor weather movie snippet forecasting. As shown in Fig. 5,\nthe dataset covers 11 regions including:\nFig. 4. Swin Transformer decoder block: A decoder stacking of two\nconcurrent cross-attention blocks is shown, with shifted-window attention\nalways coming after non-shifted ones.\n• R1: Nile region (covering Cairo)\n• R2: Eastern Europe (covering Moscow)\n• R3: South West Europe (covering Madrid and Barcelona)\n• R4: Central Maghreb (Timimoun)\n• R5: South Mediterranean (covering Tripoli and Tunis)\n• R6: Central Europe (covering Berlin)\n• R7: Bosphorus (covering Istanbul)\n• R8: East Maghreb (covering Marrakech)\n• R9: Canary Islands\n• R10: Azores Islands\n• R11: North West Europe (London, Paris, Brussels, Ams-\nterdam)\nThese regions are grouped into two for both core challenge\nand transfer challenge. The regions used for the core challenge\nare R1-R3, R7, and R8, and the data provided are divided\ninto training, validation, and test sets. The transfer challenge\nonly has the test set for testing the transferability of the\ntrained model on data from the remaining regions without prior\ntraining.\nThis article has been accepted for publication in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/JSTARS.2023.3323729\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERV ATIONS AND REMOTE SENSING, VOL. 1, NO. 1, APRIL 2022 6\nFig. 5. IEEE Big Data Weather4Cast 2021 Data Localization. The core challenge is shown in blue squares, while the regions in orange squares are for the\ntransfer learning challenge [89].\nThe data is presented in 256 x 256 weather images for\nvarious weather parameters, as shown in Table I, categorized\ninto five subgroups, with an area resolution of 4 km x 4 km\nper pixel. These weather images are captured 4 times per hour,\namounting to one in 15-minute intervals.\nTABLE I\nIEEE B IGDATA WEATHER 4CAST COMPOSITION\nWeather Product Weather variables\nTemperature at\nGround/Cloud\n(CTTH)\ntemperature, ctth tempe, ctth pres,\nctth alti, ctth effectiv, ctth method,\nctth quality, ishai skt, ishai quality\nConvective\nRainfall Rate\n(CRR)\ncrr, crr intensity, crr accum, crr quality\nProbability of\nOccurrence\nof Tropopause\nFolding (ASII)\nasii turb trop prob, asiitf quality\nCloud Mask\n(CMA)\ncma cloudsnow, cma, cma dust,\ncma volcanic, cma smoke, cma quality\nCloud Type (CT) ct, ct cumuliform, ct multilayer,\nct quality\nTraining variables in italic represent the exogeneous inputs, while\nwhile in bold are the autogressive terms.\nSome static context variables are also provided, including\nelevation and longitude/latitude. This static information is\nprovided in a format of 256 x 256 pixels, similar to the weather\nparameters. This information is unique to the specific regions\nand does not change over time.\nThe evaluation metric for these challenges (core and transfer\nchallenges) considers the presence of missing values for each\nvariable and attempts to remove the dominance of any variable\nin the metric calculation. The scaling factor used to remove\nsuch (target) variable depending on dominance is given by:\npersistence(v) =\n\n\n\n0.03163512, if v = temperature\n0.00024158, if v = crr intensity\n0.00703378, if v = asii turb trop prob\n0.19160305, if v = cma\n\n\n\n(4)\nThe evaluation metric using such persistence scaling leads to\na value of 1 for persistence modeling and is given by:\nScoreC = 1\nDTR CV\nD=36X\nd=1\nT=32X\nt=1\nX\nr∈RC\nX\nv∈V\nw(v)\nPr,v\nPr,vX\np=1\n(yr,d,t\nv,p −¯yr,d,t\nv,p )\n(5)\nwhere RC represents the set of all regions involved for a given\nchallenge, D is the total number of days in the testing set, T\nis the number of time steps, w(v) := 1\npersistence(v) is the\nscaling factor attributed to each variable v in the set of all\ntarget variables V . Also, Pr,v = 256 × 256 − Nr is used to\naccount for missing data for a target variable v in any region\nr, where Nr is the number of missing data (i.e., empty pixels).\nB. Model Training\nPytorch was used to implement the model shown in Figure\n1. In conjunction with the Adam optimizer [90], we use the\nevaluation metric (eqn. 5) as the loss function. We trained the\nmodel using this loss function in a multitask setting, as the\nscaling factor involved balances the effects of each variable\non the total loss. The learning rate starts at 1e-4 and is\ngradually reduced by half when the validation set performance\nplateaus for more than 3 epochs. The model was trained with\na dedicated data augmentation scheme for dense prediction\npurposes. The augmentation pipeline includes random horizon-\ntal (RandomHorizontalFlip) and vertical (RandomVerticalFlip)\nflipping of the data, as well as random rotations of the data\nblock (90 ◦ RandomRotation) The model training uses either\nThis article has been accepted for publication in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/JSTARS.2023.3323729\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERV ATIONS AND REMOTE SENSING, VOL. 1, NO. 1, APRIL 2022 7\nthe expected target data only or together with any combination\nof additional static and/or dynamic data available (Table II).\nThe parameters of the models v2, v6, v7, v8 will be presented\nlater in Table III. The additional data categories (i.e., static\nand dynamic) considered here are based on the fact that some\nweather variables are related, e.g., temperature and pressure.\nAlso, the elevation map of a given location has some impact\non weather fluctuations [91], [92].\nTABLE II\nDATA CATEGORIES USED IN MODEL TRAINING\nData type weather variables\ntarget temperature, crr intensity, asii turb trop prob, cma\nstatic elevation, latitude, longitude\ndynamic ctth tempe, ctth press, ctth effectiv, crr, crr accum,\ncma cloudsnow, cma dust, cma volcanic,\ncma smoke, ct, ct cumuliform, ct multilayer\nC. Experiments\nA forecasting model (Table III) was developed that follows\nthe architecture in Figure 1 with an embedding dimension of\n48 and a patch size of 4. Training of the model configurations\ninvolved whether additional data will be used. One of the\nmodels was trained using only the target variables as listed\nin Section IV-A, while the remaining models include either\nother dynamic or static data, or a combination of the two\ntogether with the target variables (Table III). We used different\ncombinations of data in model training to investigate the\npredictive capability of combining input data during training.\nTABLE III\nTRAINED MODELS PERFORMANCE COMPARISON\nModel Additional Data#Parameters Performance\nversion static others Core Transfer\nv2 No No 5.74M 0.4936 0.4516\nv6 Yes No 5.78M 0.4840 0.4516\nv7 No Yes 5.85M 0.4810 0.4447\nv8 Yes Yes 5.87M 0.4750 0.4420\nTop 3 models on the leaderboard\nConvGRU [67] (2021) Yes No 18M 0.4729 0.4323\nDense UNet [70] (2021) Yes Yes 12M 0.4802 0.4376\nVariational UNet [71] (2021)No Yes 16M 0.4857 0.4594\nblue, red, and brown colored results represents the 1 st, 2nd and 3rd\nAs shown in Table (III), training with different combinations\nof inputs results in different model configurations in terms of\nthe number of parameters (i.e., there is a change in the number\nof input channels).\nWe compared our models with the best performing models\nfor this dataset in Table III [89]. Our model has the least\nnumber of parameters and does not include ensembling, used\nby other models.\nD. Ablation Study\nWe developed several forecasting models (Table IV) that\nfollow the architecture in Figure 1 with changes in the hyper-\nparameters (i.e., embedding dimension, patch size, and weight\ndecay). As previously mentioned, model configuration training\ninvolves selecting whether additional data will be used. Some\nof the models were trained using only the target variables as\nlisted in Section IV-A, while some models included either\nother dynamic or static data, or combinations of the two\ntogether with the target variables (Table II and IV).\nTABLE IV\nTRAINED MODEL CONFIGURATIONS\nmodel Hyperparameters Additional Data\nversion embed-dim patch-size weight decay static dynamic\nv0 16 2x2 No No No\nv1 32 2x2 No No No\nv2 48 2x2 No No No\nv3 48 2x2 Yes No No\nv4 48 3x3 Yes No No\nv5 48 4x4 Yes No No\nv6 48 4x4 Yes Yes No\nv7 48 4x4 Yes No Yes\nv8 48 4x4 Yes Yes Yes\nStarting with model v3, A weight decaying factor of 1e-6 was\nincluded during training to address possible overfitting.\n1) Embedding dimension variation: : We trained several\nmodels that varied in the size of the embedding dimension,\ni.e., {16, 32, 48 }. These dimensions were chosen to avoid\nan excessively large number of parameters, as the intention\nwas to develop parameter-efficient models. All these models\nuse a patch size of 2x2 without any additional data (static\nor dynamic) (Table IV). The experimental results in Table V\nshow that we can obtain an improvement in performance by\nincreasing the embedding dimension.\nTABLE V\nMODEL PERFORMANCE WITH VARYING EMBEDDING DIMENSION\nModel embed-dim #Parameters Core Transfer\nv0 16 688,080 0.5015 0.4572\nv1 32 2,574,688 0.4940 0.4530\nv2 48 5,708,528 0.4936 0.4516\n2) Patch size variation: We explored the effect of increas-\ning the patch size used in the patch embedding layer of the\nmodel (Fig . 1). In this experiment, we use the best performing\nmodel of Table V, which uses an embedding dimension of 48.\nThe results of these experiments are shown in Table VI, and\nindicate that a patch size of 4 achieved the best results. It is\nworth noting that increasing the patch size has a noticeable\neffect on performance, while only incurring a very modest\nincrease in the number of parameters.\nTABLE VI\nMODEL PERFORMANCE WITH VARYING PATCH SIZE\nModel patch size #Parameters Core Transfer\nv3 2x2 5,708,528 0.5016 0.4516\nv4 3x3 5,721,008 0.4974 0.4516\nv5 4x4 5,738,480 0.4945 0.4516\n3) Using additional data: Earlier ablation experiments in\nthis study used only the target variables stated in Table II.\nIn the current experiment, we trained the best performing\nmodel in Table VI, i.e., with a patch size of 4x4 and an\nembedding dimension of 48, with different combinations of\nadditional data. We also considered models with an embedding\ndimension of 32 for this experiment to reduce model size,\nand possibly enhance transfer-ability, and reduce overfitting.\nThis article has been accepted for publication in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/JSTARS.2023.3323729\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERV ATIONS AND REMOTE SENSING, VOL. 1, NO. 1, APRIL 2022 8\nFig. 6. Comparing the temperature forecast with ground truth. The left side shows the situation before forecasting. On the right side, the first row shows the\nexpected values in a sample of future times, while the second row shows the predicted values. Values normalized to the range (0, 1)\nHowever, the experiments demonstrated that reducing the\nembedding dimension does not lead to improvements in model\ntransfer, instead the model is self resilient to overfitting.\nTABLE VII\nMODEL PERFORMANCE WITH ADDITIONAL DATA\nModel static dynamic #Parameters Core Transfer\nModels with embedding dimension of 48\nv6 Yes No 5,780,048 0.4840 0.4516\nv7 No Yes 5,847,632 0.4810 0.4516\nv8 Yes Yes 5,866,064 0.4750 0.4420\nModels with embedding dimension of 32\nv9 Yes No 2,616,256 0.4845 0.4529\nv10 No Yes 2,661,312 0.4764 0.4481\nv11 Yes Yes 2,673,600 0.4777 0.4446\nE. Qualitative Analysis\nWe conducted a pictorial representation and analysis of the\nvalidation data based on the effect of time. Here, the variables\nare plotted individually to show the trend over the time of\nforecasting window. The weather conditions were compared\nto the ground truth as shown in Figs. 6, 8, 9 and 7. This\nanalysis shows that the model was able to accurately predict\nthe weather variables quite well in the beginning but its\nreliability decreases with time. As an example, prediction in\nFig. (6) follows the expected value but slight blurriness occurs\ntowards the end of the prediction horizon. This is similar to the\nobservation in the analysis of cma (fig. 7), asii turb trop prob\n(8), and crr intensity (9). The crr intensity shown in figure (9)\nindicates that the model can learn even in scarcity of non-zero\nvalues.\nV. C ONCLUSIONS AND FUTURE WORK\nA short-time weather forecasting model was introduced for\nthe first time that uses the 3D Swin-Transformer in a U-\nNet architecture, which resulted in competitive results, i.e.,\na leaderboard score (scaled multitask MSE) of 0.4750 and\n0.4420, for the core and transfer challenges, respectively\n(IEEE Big Data Weather4Cast2021 [89]). The proposed model\nhas only three blocks of Swin-transformers in both the encoder\nand decoder parts. It uses cross-attention in the decoder to\nmerge data from the encoder with the upsampled decoding\ndata. This ensures that the model focuses only on important in-\nformation. We intend to investigate different types of attention\nlayers in the future. Similarly, we intend to investigate token\nmixing using hypercomplex networks, e.g., sedenion networks\n[21].\nACKNOWLEDGEMENTS\nThis work was supported by the ICT Fund, Telecommuni-\ncations Regulatory Authority (TRA), Abu Dhabi, United Arab\nEmirates.\nREFERENCES\n[1] X. Ren, X. Li, K. Ren, J. Song, Z. Xu, K. Deng, and\nX. Wang, “Deep learning-based weather prediction: A survey,” Big\nData Research , vol. 23, p. 100178, 2021. [Online]. Available:\nhttps://www.sciencedirect.com/science/article/pii/S2214579620300460\n[2] D. N. Fente and D. Kumar Singh, “Weather forecasting using artificial\nneural network,” in 2018 Second International Conference on Inventive\nCommunication and Computational Technologies (ICICCT) , 2018, pp.\n1757–1761.\n[3] B. Wang, J. Lu, Z. Yan, H. Luo, T. Li, Y . Zheng, and\nG. Zhang, “Deep uncertainty quantification: A machine learning\napproach for weather forecasting,” in Proceedings of the 25th ACM\nSIGKDD International Conference on Knowledge Discovery amp;\nData Mining , ser. KDD ’19. New York, NY , USA: Association\nfor Computing Machinery, 2019, p. 2087–2095. [Online]. Available:\nhttps://doi.org/10.1145/3292500.3330704\n[4] N. Singh, S. Chaturvedi, and S. Akhter, “Weather forecasting using\nmachine learning algorithm,” in2019 International Conference on Signal\nProcessing and Communication (ICSC) , 2019, pp. 171–174.\n[5] P. Hewage, A. Behera, M. Trovati, E. Pereira, M. Ghahremani,\nF. Palmieri, and Y . Liu, “Temporal Convolutional Neural (TCN)\nNetwork for an Effective Weather Forecasting Using Time-Series\nData from the Local Weather Station,” Soft Comput. , vol. 24,\nno. 21, p. 16453–16482, nov 2020. [Online]. Available: https:\n//doi.org/10.1007/s00500-020-04954-0\n[6] P. Hewage, M. Trovati, E. Pereira, and A. Behera, “Deep Learning-\nBased Effective Fine-Grained Weather Forecasting Model,” Pattern\nAnal. Appl. , vol. 24, no. 1, p. 343–366, feb 2021. [Online]. Available:\nhttps://doi.org/10.1007/s10044-020-00898-1\n[7] M. Qiu, P. Zhao, K. Zhang, J. Huang, X. Shi, X. Wang, and W. Chu, “A\nShort-Term Rainfall Prediction Model Using Multi-task Convolutional\nNeural Networks,” in 2017 IEEE International Conference on Data\nMining (ICDM), 2017, pp. 395–404.\nThis article has been accepted for publication in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/JSTARS.2023.3323729\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERV ATIONS AND REMOTE SENSING, VOL. 1, NO. 1, APRIL 2022 9\nFig. 7. Comparing the cma forecast with ground truth. The left side shows the situation before forecasting. On the right side, the first row shows the expected\nvalues in a sample of future times, while the second row shows the predicted values. The contour line in white is used to show the binary threshold at\n0.5.\nFig. 8. Comparing the asii turb trop prob forecast with ground truth. The left side shows the situation before forecasting. On the right side, the first row\nshows the expected values in a sample of future times, while the second row shows the predicted values. Values normalized to the range (0, 1)\nFig. 9. Comparing the crr intensity forecast with ground truth. The left side shows the situation before forecasting. On the right side, the first row shows the\nexpected values in a sample of future times, while the second row shows the predicted values. Values normalized to the range (0, 1)\nThis article has been accepted for publication in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/JSTARS.2023.3323729\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERV ATIONS AND REMOTE SENSING, VOL. 1, NO. 1, APRIL 2022 10\n[8] R. Castro, Y . M. Souto, E. Ogasawara, F. Porto, and E. Bezerra,\n“STConvS2S: Spatiotemporal Convolutional Sequence to Sequence\nNetwork for weather forecasting,” Neurocomputing, vol. 426, pp.\n285–298, 2021. [Online]. Available: https://www.sciencedirect.com/\nscience/article/pii/S0925231220315794\n[9] K. Yonekura, H. Hattori, and T. Suzuki, “Short-term local weather\nforecast using dense weather station by deep neural network,” in IEEE\nInternational Conference on Big Data, Big Data . IEEE, 2018, p.\n1683–1690.\n[10] C.-J. Zhang, X.-J. Wang, L.-M. Ma, and X.-Q. Lu, “Tropical cyclone\nintensity classification and estimation using infrared satellite images\nwith deep learning,” IEEE Journal of Selected Topics in Applied Earth\nObservations and Remote Sensing , vol. 14, pp. 2070–2086, 2021.\n[11] M. Hossain, B. Rekabdar, S. Louis, and S. Dascalu, “Forecasting the\nweather of nevada: a deep learning approach,” in International Joint\nConference on Neural Networks, IJCNN . IEEE, 2015, p. 1–6.\n[12] S.-Y . Lin, C.-C. Chiang, J.-B. Li, Z.-S. Hung, and K.-M. Chao,\n“Dynamic fine-tuning stacked auto-encoder neural network for weather\nforecast,” Future Gener. Comput. Syst , vol. 89, p. 446–454, 2018.\n[13] C. K. Sønderby, L. Espeholt, J. Heek, M. Dehghani, A. Oliver,\nT. Salimans, S. Agrawal, J. Hickey, and N. Kalchbrenner, “Metnet:\nA neural weather model for precipitation forecasting,” CoRR, vol.\nabs/2003.12140, 2020. [Online]. Available: https://arxiv.org/abs/2003.\n12140\n[14] Z. Karevan and J. A. K. Suykens, “Spatio-temporal stacked lstm for\ntemperature prediction in weather forecasting,” 2018.\n[15] S. Hou, W. Li, T. Liu, S. Zhou, J. Guan, R. Qin, and Z. Wang, “D2cl: A\ndense dilated convolutional lstm model for sea surface temperature pre-\ndiction,” IEEE Journal of Selected Topics in Applied Earth Observations\nand Remote Sensing , vol. 14, pp. 12 514–12 523, 2021.\n[16] T. Xiong, J. He, H. Wang, X. Tang, Z. Shi, and Q. Zeng, “Contextual\nSa-Attention Convolutional LSTM for Precipitation Nowcasting: A\nSpatiotemporal Sequence Forecasting View,” IEEE Journal of Selected\nTopics in Applied Earth Observations and Remote Sensing , vol. 14, pp.\n12 479–12 491, 2021.\n[17] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification\nwith deep convolutional neural networks,” in Advances in Neural\nInformation Processing Systems , F. Pereira, C. J. C. Burges, L. Bottou,\nand K. Q. Weinberger, Eds., vol. 25. Curran Associates, Inc.,\n2012. [Online]. Available: https://proceedings.neurips.cc/paper/2012/\nfile/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\n[18] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image\nrecognition,” in 2016 IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), 2016, pp. 770–778.\n[19] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, “Densely\nconnected convolutional networks,” in 2017 IEEE Conference on Com-\nputer Vision and Pattern Recognition (CVPR) , 2017, pp. 2261–2269.\n[20] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks\nfor biomedical image segmentation,” in Medical Image Computing and\nComputer-Assisted Intervention – MICCAI 2015 , N. Navab, J. Horneg-\nger, W. M. Wells, and A. F. Frangi, Eds. Cham: Springer International\nPublishing, 2015, pp. 234–241.\n[21] A. Bojesomo, P. Liatsis, and H. Al-Marzouqi, “Traffic flow prediction\nusing deep sedenion networks,” CoRR, vol. abs/2012.03874, 2020.\n[Online]. Available: https://arxiv.org/abs/2012.03874\n[22] S. Choi, “Utilizing unet for the future traffic map prediction\ntask traffic4cast challenge 2020,” CoRR, vol. abs/2012.00125, 2020.\n[Online]. Available: https://arxiv.org/abs/2012.00125\n[23] M. Kopp, D. Kreil, M. Neun, D. Jonietz, H. Martin, P. Herruzo,\nA. Gruca, A. Soleymani, F. Wu, Y . Liu, J. Xu, J. Zhang, J. Santokhi,\nA. Bojesomo, H. A. Marzouqi, P. Liatsis, P. H. Kwok, Q. Qi,\nand S. Hochreiter, “Traffic4cast at neurips 2020 - yet more on\nthe unreasonable effectiveness of gridded geo-spatial processes,” in\nProceedings of the NeurIPS 2020 Competition and Demonstration\nTrack, ser. Proceedings of Machine Learning Research, H. J. Escalante\nand K. Hofmann, Eds., vol. 133. PMLR, 06–12 Dec 2021, pp. 325–343.\n[Online]. Available: https://proceedings.mlr.press/v133/kopp21a.html\n[24] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai,\nT. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly,\nJ. Uszkoreit, and N. Houlsby, “An image is worth 16x16 words: Trans-\nformers for image recognition at scale,” ArXiv, vol. abs/2010.11929,\n2021.\n[25] W. Wang, E. Xie, X. Li, D.-P. Fan, K. Song, D. Liang, T. Lu, P. Luo, and\nL. Shao, “Pyramid vision transformer: A versatile backbone for dense\nprediction without convolutions,” ArXiv, vol. abs/2102.12122, 2021.\n[26] R. Ranftl, A. Bochkovskiy, and V . Koltun, “Vision transformers\nfor dense prediction,” in 2021 IEEE/CVF International Conference\non Computer Vision (ICCV) . Los Alamitos, CA, USA: IEEE\nComputer Society, oct 2021, pp. 12 159–12 168. [Online]. Available:\nhttps://doi.ieeecomputersociety.org/10.1109/ICCV48922.2021.01196\n[27] Z. Dai, H. Liu, Q. V . Le, and M. Tan, “Coatnet: Marrying convolution\nand attention for all data sizes,” in Advances in Neural Information\nProcessing Systems, M. Ranzato, A. Beygelzimer, Y . Dauphin, P. Liang,\nand J. W. Vaughan, Eds., vol. 34. Curran Associates, Inc., 2021, pp.\n3965–3977. [Online]. Available: https://proceedings.neurips.cc/paper/\n2021/file/20568692db622456cc42a2e853ca21f8-Paper.pdf\n[28] X. Dong, J. Bao, D. Chen, W. Zhang, N. Yu, L. Yuan, D. Chen,\nand B. Guo, “CSWin Transformer: A General Vision Transformer\nBackbone with Cross-Shaped Windows,” CoRR, vol. abs/2107.00652,\n2021. [Online]. Available: https://arxiv.org/abs/2107.00652\n[29] Z. Liu, Y . Lin, Y . Cao, H. Hu, Y . Wei, Z. Zhang, S. Lin, and\nB. Guo, “Swin transformer: Hierarchical vision transformer using shifted\nwindows,” in 2021 IEEE/CVF International Conference on Computer\nVision (ICCV), 2021, pp. 9992–10 002.\n[30] Z. Liu, J. Ning, Y . Cao, Y . Wei, Z. Zhang, S. Lin, and H. Hu, “Video\nSwin Transformer,” arXiv preprint arXiv:2106.13230 , pp. 1–12, 2021.\n[Online]. Available: http://arxiv.org/abs/2106.13230\n[31] W. Wang, L. Yao, L. Chen, D. Cai, X. He, and W. Liu,\n“CrossFormer: A Versatile Vision Transformer Based on Cross-scale\nAttention,” CoRR, vol. abs/2108.00154, 2021. [Online]. Available:\nhttps://arxiv.org/abs/2108.00154\n[32] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\nGomez, L. u. Kaiser, and I. Polosukhin, “Attention is all you\nneed,” in Advances in Neural Information Processing Systems ,\nI. Guyon, U. V . Luxburg, S. Bengio, H. Wallach, R. Fergus,\nS. Vishwanathan, and R. Garnett, Eds., vol. 30. Curran Associates,\nInc., 2017. [Online]. Available: https://proceedings.neurips.cc/paper/\n2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n[33] H. Cao, Y . Wang, J. Chen, D. Jiang, X. Zhang, Q. Tian, and\nM. Wang, “Swin-Unet: Unet-like Pure Transformer for Medical\nImage Segmentation,” pp. 1–14, 2021. [Online]. Available: http:\n//arxiv.org/abs/2105.05537\n[34] A. Bojesomo, H. Al-Marzouqi, and P. Liatsis, “Spatiotemporal Vision\nTransformer for Short Time Weather Forecasting,” in 2021 IEEE Inter-\nnational Conference on Big Data (Big Data) . IEEE, 2021, pp. 5741–\n5746.\n[35] ——, “Spatiotemporal swin-transformer network for short time weather\nforecasting,” in Proceedings of the CIKM 2021 Workshops colocated\nwith 30th ACM International Conference on Information and Knowledge\nManagement (CIKM 2021), Virtual Event, QLD, November 1-5, 2021,\nCEUR Workshop Proceedings. Association for Computing Machinery,\n2021.\n[36] A. Bojesomo, H. Al-Marzouqi, and P. Liatsis, “SwinUNet3D - A\nHierarchical Architecture for Deep Traffic Prediction using Shifted\nWindow Transformers,” CoRR, vol. abs/2201.06390, 2022. [Online].\nAvailable: https://arxiv.org/abs/2201.06390\n[37] R. Goyal, S. Ebrahimi Kahou, V . Michalski, J. Materzynska, S. West-\nphal, H. Kim, V . Haenel, I. Fruend, P. Yianilos, M. Mueller-Freitaget al.,\n“The” something something” video database for learning and evaluat-\ning visual common sense,” in Proceedings of the IEEE international\nconference on computer vision , 2017, pp. 5842–5850.\n[38] W. Kay, J. Carreira, K. Simonyan, B. Zhang, C. Hillier, S. Vijaya-\nnarasimhan, F. Viola, T. Green, T. Back, P. Natsev et al., “The kinetics\nhuman action video dataset,” arXiv preprint arXiv:1705.06950 , 2017.\n[39] T. Ji, Y . Jiang, M. Li, and Q. Wu, “Ultra-short-term wind speed and wind\npower forecast via selective hankelization and low-rank tensor learning-\nbased predictor”,” Electrical Power and Energy Systems , vol. 140, pp.\n107 994,.\n[40] J. Gillard and K. Usevich, “Structured low-rank matrix completion for\nforecasting in time series analysis”,” International Journal of Forecast-\ning, vol. 34, pp. 582–597,.\n[41] G. Liu, “Time series forecasting via learning convolutionally low-\nrank models”,” IEEE Trans Information Theory , vol. 68, no. 5, pp.\n3362–3380,.\n[42] J. Gasthaus, K. Benidis, Y . Wang, S. Rangapuram, D. Salinas,\nV . Flunkert, and T. Januschowski, “High-dimensional multivariate fore-\ncasting with low-rank gaussian copula processes”,” in Proc. 33rd\nConference on Neural Information Processing Systems (NeurIPS 2019 ,\nVancouver, Canada, pp. 6827–6837,.\n[43] P. Bauer, A. Thorpe, and G. Brunet, “The quiet revolution of numerical\nweather prediction,” Nature, vol. 525, p. 47–55, 2015.\n[44] I. Sandu, A. Beljaars, P. Bechtold, T. Mauritsen, and G. Balsamo, “Why\nis it so difficult to represent stably stratified conditions in numerical\nThis article has been accepted for publication in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/JSTARS.2023.3323729\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERV ATIONS AND REMOTE SENSING, VOL. 1, NO. 1, APRIL 2022 11\nweather prediction (nwp) models?” Journal of Advances in Modeling\nEarth Systems, vol. 5, no. 2, pp. 117–133, 2013.\n[45] A. Abraham, N. Philip, B. Nath, and P. Saratchandran, “Performance\nanalysis of connectionist paradigms for modeling chaotic behavior of\nstock indices,” in Second International Workshop on Intelligent Systems\nDesign and Applications, Computational Intelligence and Applications .\nUSA: Dynamic Publishers Inc, 2002, p. 181–186.\n[46] C. V oyant, M. Muselli, C. Paoli, and M.-L. Nivet, “Numerical weather\nprediction (nwp) and hybrid arma/ann model to predict global radiation,”\nEnergy, vol. 39, no. 1, pp. 341–355, 2012.\n[47] J. Pathak, B. Hunt, M. Girvan, Z. Lu, and E. Ott, “Model-free prediction\nof large spatiotemporally chaotic systems from data: A reservoir com-\nputing approach,” Physical review letters , vol. 120, no. 2, p. 024102,\n2018.\n[48] C. He, J. Wei, Y . Song, and J.-J. Luo, “Seasonal prediction\nof summer precipitation in the middle and lower reaches\nof the yangtze river valley: Comparison of machine learning\nand climate model predictions,” vol. 13, no. 22, 2021.\n[Online]. Available: https://www.scopus.com/inward/record.uri?eid=\n2-s2.0-85119970664&doi=10.3390%2fw13223294&partnerID=40&\nmd5=5f871022a5647c9c95094d77049655f3\n[49] B. Bochenek and Z. Ustrnul, “Machine learning in weather prediction\nand climate analyses—applications and perspectives,” vol. 13, no. 2,\n2022. [Online]. Available: https://www.scopus.com/inward/record.\nuri?eid=2-s2.0-85124086690&doi=10.3390%2fatmos13020180&\npartnerID=40&md5=af5d57af5589fe9a98d64c7dd8291c2d\n[50] E. Juarez and M. Petersen, “A comparison of machine learning methods\nto forecast tropospheric ozone levels in delhi,” vol. 13, no. 1, 2022.\n[Online]. Available: https://www.scopus.com/inward/record.uri?eid=\n2-s2.0-85121997176&doi=10.3390%2fatmos13010046&partnerID=\n40&md5=63c12de7bb39846e3af8a01b6db25747\n[51] M. Achite, M. Jehanzaib, N. Elshaboury, and T.-W. Kim, “Evaluation\nof machine learning techniques for hydrological drought modeling: A\ncase study of the wadi ouahrane basin in algeria,” vol. 14, no. 3,\n2022. [Online]. Available: https://www.scopus.com/inward/record.uri?\neid=2-s2.0-85123691238&doi=10.3390%2fw14030431&partnerID=\n40&md5=afcb2f30df6d19e09caf83f671dcd268\n[52] Y . Fang, H. Chen, Y . Lin, C. Zhao, Y . Lin, and F. Zhou, “Classification\nof northeast china cold vortex activity paths in early summer based on\nk-means clustering and their climate impact,” Advances in Atmospheric\nSciences, vol. 38, no. 3, pp. 400–412, 2021.\n[53] D. Lou, M. Yang, D. Shi, G. Wang, W. Ullah, Y . Chai, and Y . Chen, “K-\nmeans and c4.5 decision tree based prediction of long-term precipitation\nvariability in the poyang lake basin, china,” vol. 12, no. 7, 2021.\n[Online]. Available: https://www.scopus.com/inward/record.uri?eid=\n2-s2.0-85109636880&doi=10.3390%2fatmos12070834&partnerID=\n40&md5=721615d85cc65ee47a06e944513f19c7\n[54] J. Abbot and J. Marohasy, “The application of machine learning for\nevaluating anthropogenic versus natural climate change,” GeoResJ,\nvol. 14, pp. 36–46, 2017.\n[55] W. Almikaeel, L. ˇCubanov´a, and A. ˇSolt´esz, “Hydrological drought\nforecasting using machine learning—gidra river case study,” vol. 14,\nno. 3, 2022. [Online]. Available: https://www.scopus.com/inward/\nrecord.uri?eid=2-s2.0-85123703263&doi=10.3390%2fw14030387&\npartnerID=40&md5=44b26539167a4ecc0ebc381cd2fc6563\n[56] M. Ma, P. Xie, F. Teng, T. Li, B. Wang, S. Ji, and J. Zhang, “Histgnn:\nHierarchical spatio-temporal graph neural networks for weather fore-\ncasting,” arXiv preprint arXiv:2201.09101 , 2022.\n[57] B. P. Shukla, C. M. Kishtawal, and P. K. Pal, “Prediction of satellite\nimage sequence for weather nowcasting using cluster-based spatiotem-\nporal regression,” IEEE transactions on geoscience and remote sensing ,\nvol. 52, no. 7, pp. 4155–4160, 2013.\n[58] “Day-ahead spatiotemporal solar irradiation forecasting using frequency-\nbased hybrid principal component analysis and neural network,”\nApplied Energy , vol. 247, pp. 389–402, 2019. [Online]. Available:\nhttps://www.sciencedirect.com/science/article/pii/S0306261919307019\n[59] L. Huang, J. Kang, M. Wan, L. Fang, C. Zhang, and Z. Zeng, “Solar\nradiation prediction using different machine learning algorithms and\nimplications for extreme climate events,” Frontiers in Earth Science ,\nvol. 9, p. 202, 2021.\n[60] D. Niu, L. Diao, Z. Zang, H. Che, T. Zhang, and X. Chen,\n“A machine-learning approach combining wavelet packet denoising\nwith catboost for weather forecasting,” vol. 12, no. 12, 2021.\n[Online]. Available: https://www.scopus.com/inward/record.uri?eid=\n2-s2.0-85122790317&doi=10.3390%2fatmos12121618&partnerID=\n40&md5=c382761cb7f88374815f99aa1f604af0\n[61] V . Monego, J. Anochi, and H. de Campos Velho, “South\namerica seasonal precipitation prediction by gradient-boosting\nmachine-learning approach,” vol. 13, no. 2, 2022. [Online].\nAvailable: https://www.scopus.com/inward/record.uri?eid=2-s2.\n0-85124129167&doi=10.3390%2fatmos13020243&partnerID=40&\nmd5=bebfbce74f66e6d71dae103a9f348181\n[62] L. Iverson, A. Prasad, and A. Liaw, “New machine learning tools for\npredictive vegetation mapping after climate change: Bagging and random\nforest perform better than regression tree analysis,” in In: Smithers,\nRichard, ed. Landscape ecology of trees and forests, proceedings of\nthe twelfth annual IALE (UK) conference; 2004 June 21-24; Cirences-\nter, UK.[Place of publication unknown]: International Association for\nLandscape Ecology: 317-320. , 2004.\n[63] P.-S. Yu, T.-C. Yang, S.-Y . Chen, C.-M. Kuo, and H.-W. Tseng,\n“Comparison of random forests and support vector machine for\nreal-time radar-derived rainfall forecasting,” vol. 552, pp. 92–104,\n2017. [Online]. Available: https://www.scopus.com/inward/record.\nuri?eid=2-s2.0-85021687551&doi=10.1016%2fj.jhydrol.2017.06.020&\npartnerID=40&md5=a15fba257a86853e0788f5fa78c16555\n[64] C. Song, X. Chen, P. Wu, and H. Jin, “Combining time\nvarying filtering based empirical mode decomposition and machine\nlearning to predict precipitation from nonlinear series,” vol. 603,\n2021. [Online]. Available: https://www.scopus.com/inward/record.\nuri?eid=2-s2.0-85116582095&doi=10.1016%2fj.jhydrol.2021.126914&\npartnerID=40&md5=9d1640a89522d66d5298b824804ed5c8\n[65] J. N. Liu, Y . Hu, J. J. You, and P. W. Chan, “Deep neural network based\nfeature representation for weather forecasting,” in Proceedings on the\nInternational Conference on Artificial Intelligence (ICAI). The Steering\nCommittee of The World Congress in Computer Science, Computer . . . ,\n2014, p. 1.\n[66] S.-Y . Lin, C.-C. Chiang, J.-B. Li, Z.-S. Hung, and K.-M. Chao,\n“Dynamic fine-tuning stacked auto-encoder neural network for weather\nforecast,” Future Generation Computer Systems , vol. 89, pp. 446–\n454, 2018. [Online]. Available: https://www.sciencedirect.com/science/\narticle/pii/S0167739X17329801\n[67] J. Leinonen, “Improvements to short-term weather prediction with\nrecurrent-convolutional networks,” CoRR, vol. abs/2111.06240, 2021.\n[Online]. Available: https://arxiv.org/abs/2111.06240\n[68] A.-I. Albu, G. Czibula, A. Mihai, I. Czibula, and S. Burcea, “Nextnow:\nA convolutional deep learning model for the prediction of weather radar\ndata for noacasting purposes”,” Remote Sensing, vol. 14, pp. 3890,.\n[69] A. Chattopadhyay, M. Mustafa, P. Hassanzadeh, E. Bach, and\nK. Kashinath, “Towards physics-inspired data driven weather forecast-\ning: integrating data assimilation with a deep spatial-transformer-based\nu-net in a case study with era5”,” Geosci. Model Dev , vol. 15, pp.\n2221–2237,.\n[70] S. Choi, “UNet based future weather prediction on Weather4cast 2021\nstage 2,” in2021 IEEE International Conference on Big Data (Big Data),\n2021, pp. 5747–5749.\n[71] P. H. Kwok and Q. Qi, “Enhanced variational u-net for weather forecast-\ning,” in 2021 IEEE International Conference on Big Data (Big Data) ,\n2021, pp. 5758–5763.\n[72] S. Ravuri, K. Lenc, M. Willson, D. Kangin, R. Lam, P. Mirowski,\nM. Fitzsimons, M. Athanassiadou, S. Kashem, S. Madge et al., “Skilful\nprecipitation nowcasting using deep generative models of radar,” Nature,\nvol. 597, no. 7878, pp. 672–677, 2021.\n[73] C. Wang, P. Wang, P. Wang, B. Xue, and D. Wang, “Using conditional\ngenerative adversarial 3-d convolutional neural network for precise\nradar extrapolation,” IEEE Journal of Selected Topics in Applied Earth\nObservations and Remote Sensing , vol. 14, pp. 5735–5749, 2021.\n[74] C. Li and X. Chen, “Future video frame prediction based on generative\nmotion-assistant discriminative network”,” Applied Soft Computing, vol.\n135, pp. 110 028,.\n[75] X. Chen, M. Wang, S. Wang, Y . Chen, R. Wang, C. Zhao, and X. Hu,\n“Weather radar nowcasting for extreme precipitation prediction based on\nthe temporal and spatial generative adversarial network”,” Atmosphere,\nvol. 13, pp. 1291,.\n[76] X. Shi, Z. Chen, H. Wang, D.-Y . Yeung, W.-k. Wong, and W.-c.\nWoo, “Convolutional lstm network: A machine learning approach for\nprecipitation nowcasting,” in Proceedings of the 28th International\nConference on Neural Information Processing Systems - Volume 1 , ser.\nNIPS’15. Cambridge, MA, USA: MIT Press, 2015, p. 802–810.\n[77] C.-A. Diaconu, S. Saha, S. Guennemann, and X. Zhu, “Understanding\nthe role of weather data for earth surface forecasting using a convlstm-\nbased model”,” in Proc. 2022 IEEE/CVF CVPRW , pp. 1361–1370,.\n[78] Y . Wang, M. Long, J. Wang, Z. Gao, and P. S. Yu, “Predrnn:\nRecurrent neural networks for predictive learning using spatiotemporal\nThis article has been accepted for publication in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/JSTARS.2023.3323729\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nJOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERV ATIONS AND REMOTE SENSING, VOL. 1, NO. 1, APRIL 2022 12\nlstms,” in Advances in Neural Information Processing Systems ,\nI. Guyon, U. V . Luxburg, S. Bengio, H. Wallach, R. Fergus,\nS. Vishwanathan, and R. Garnett, Eds., vol. 30. Curran Associates,\nInc., 2017. [Online]. Available: https://proceedings.neurips.cc/paper/\n2017/file/e5f6ad6ce374177eef023bf5d0c018b6-Paper.pdf\n[79] Y . Wang, Z. Gao, M. Long, J. Wang, and P. S. Yu, “PredRNN++:\nTowards a resolution of the deep-in-time dilemma in spatiotemporal\npredictive learning,” in Proceedings of the 35th International Conference\non Machine Learning , ser. Proceedings of Machine Learning Research,\nJ. Dy and A. Krause, Eds., vol. 80. PMLR, 10–15 Jul 2018,\npp. 5123–5132. [Online]. Available: https://proceedings.mlr.press/v80/\nwang18b.html\n[80] X. Shi, Z. Gao, L. Lausen, H. Wang, D.-Y . Yeung, W.-k. Wong, and W.-\nc. Woo, “Deep learning for precipitation nowcasting: A benchmark and\na new model,” ser. NIPS’17. Red Hook, NY , USA: Curran Associates\nInc., 2017, p. 5622–5632.\n[81] X. Zhang, Q. Jin, S. Xiang, and C. Pan, “Mfnet: The spatio-temporal\nnetwork for meteorological forecasting with architecture search”,” pp.\n10 006 605,.\n[82] H. Wu, H. Zhou, M. Long, and J. Wang, “Interpretable weather\nforecasting for wordwide stations with a unified deep model”,” Nature\nMachine Intelligence, vol. 5, pp. 602–611,.\n[83] S. Huang, Z. Lu, R. Cheng, and C. He, “FaPN: Feature-aligned pyramid\nnetwork for dense image prediction,” in International Conference on\nComputer Vision (ICCV) , 2021.\n[84] T. Xiao, Y . Liu, B. Zhou, Y . Jiang, and J. Sun, “Unified perceptual\nparsing for scene understanding,” in European Conference on Computer\nVision. Springer, 2018.\n[85] E. Xie, W. Wang, Z. Yu, A. Anandkumar, J. M. Alvarez, and P. Luo,\n“Segformer: Simple and efficient design for semantic segmentation with\ntransformers,” in Advances in Neural Information Processing Systems ,\nA. Beygelzimer, Y . Dauphin, P. Liang, and J. W. Vaughan, Eds., 2021.\n[Online]. Available: https://openreview.net/forum?id=OG18MI5TRL\n[86] L. J. Ba, J. R. Kiros, and G. E. Hinton, “Layer normalization,”\nCoRR, vol. abs/1607.06450, 2016. [Online]. Available: http://arxiv.org/\nabs/1607.06450\n[87] A. Chaurasia and E. Culurciello, “LinkNet: Exploiting encoder\nrepresentations for efficient semantic segmentation,” 2017 IEEE Visual\nCommunications and Image Processing (VCIP) , Dec 2017. [Online].\nAvailable: http://dx.doi.org/10.1109/VCIP.2017.8305148\n[88] A. Gruca, P. Herruzo, P. R ´ıpodas, A. Kucik, C. Briese, M. K. Kopp,\nS. Hochreiter, P. Ghamisi, and D. P. Kreil, “Cdceo’21 - first workshop\non complex data challenges in earth observation,” in Proceedings of\nthe 30th ACM International Conference on Information Knowledge\nManagement, ser. CIKM ’21. New York, NY , USA: Association\nfor Computing Machinery, 2021, p. 4878–4879. [Online]. Available:\nhttps://doi.org/10.1145/3459637.3482044\n[89] “Multi-sensor weather forecast competition : IEEE Big Data Cup\n2021 Leaderboard,” https://www.iarai.ac.at/weather4cast/competitions/\nieee-big-data-core-final/?leaderboard, 2021.\n[90] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”\nCoRR, vol. abs/1412.6980, 2015.\n[91] I. Rangwala and J. R. Miller, “Climate change in mountains: a review of\nelevation-dependent warming and its possible causes,” Climatic change,\nvol. 114, no. 3, pp. 527–547, 2012.\n[92] M. Kuhn and M. Olefs, “Elevation-dependent climate\nchange in the european alps,” 12 2020. [Online].\nAvailable: https://oxfordre.com/climatescience/view/10.1093/acrefore/\n9780190228620.001.0001/acrefore-9780190228620-e-762\nAlabi Bojesomo is a Ph.D. Student from the De-\npartment of Electrical Engineering and Computer\nScience at Khalifa University of Science and Tech-\nnology. He received his Bachelor’s degree (Summa\nCum Laude) in Electronic and Electrical Engineer-\ning from Obafemi Awolowo University, Nigeria in\n2011, and his M.Sc. in Microsystems Engineering\nfrom Khalifa University in 2016. His research in-\nterests include deep learning, hardware security and\nspatiotemporal forecasting.\nHasan Al Marzouqi is an Assistant Professor in\nthe Department of Electrical Engineering and Com-\nputer Science at Khalifa University of Science and\nTechnology. He received his Bachelor’s degree (with\nhonors) and his M.Sc. degree, both in Electrical and\nComputer Engineering from Vanderbilt University,\nNashville, Tennessee, in 2004 and 2006, respec-\ntively. He received his Ph.D. degree in Electrical and\nComputer Engineering from the Georgia Institute of\nTechnology in 2014. Dr. Al-Marzouqi is a Senior\nMember of IEEE and a member of the IEEE Signal\nProcessing Society. His current research interests include deep learning,\nartificial intelligence, digital rock physics, and bioinformatics.\nPanos Liatsis is a Professor in the Department\nof Electrical Engineering and Computer Science at\nKhalifa University of Science and Technology. He\nreceived the Diploma in Electrical Engineering from\nthe University of Thrace, Greece, and the Ph.D.\nin Electrical Engineering and Electronics from the\nUniversity of Manchester, UK. He commenced his\nacademic career at the University of Manchester, be-\nfore joining City University of London, UK, where\nhe was a Professor and Head of the Electrical and\nElectronic Engineering Department. His research\ninterests are image processing, computer vision, pattern recognition, and\nmachine learning.\nThis article has been accepted for publication in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/JSTARS.2023.3323729\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7751374244689941
    },
    {
      "name": "Transformer",
      "score": 0.6990184783935547
    },
    {
      "name": "Weather forecasting",
      "score": 0.5382803082466125
    },
    {
      "name": "Transfer of learning",
      "score": 0.4891336262226105
    },
    {
      "name": "Encoder",
      "score": 0.4719725549221039
    },
    {
      "name": "Machine learning",
      "score": 0.4637383222579956
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4576375484466553
    },
    {
      "name": "Artificial neural network",
      "score": 0.4188443124294281
    },
    {
      "name": "Real-time computing",
      "score": 0.35703057050704956
    },
    {
      "name": "Data mining",
      "score": 0.3330817222595215
    },
    {
      "name": "Voltage",
      "score": 0.12015429139137268
    },
    {
      "name": "Meteorology",
      "score": 0.09861725568771362
    },
    {
      "name": "Engineering",
      "score": 0.09252059459686279
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I176601375",
      "name": "Khalifa University of Science and Technology",
      "country": "AE"
    }
  ]
}