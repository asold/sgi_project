{
  "title": "AI as Agency Without Intelligence: on ChatGPT, Large Language Models, and Other Generative Models",
  "url": "https://openalex.org/W4360957277",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5046574356",
      "name": "Luciano Floridi",
      "affiliations": [
        "University of Oxford"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4386010401",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W3120325630",
    "https://openalex.org/W6697229585",
    "https://openalex.org/W3152120512",
    "https://openalex.org/W3095319910",
    "https://openalex.org/W2094251476",
    "https://openalex.org/W1930001168",
    "https://openalex.org/W6631161901",
    "https://openalex.org/W2001236151"
  ],
  "abstract": null,
  "full_text": "Vol.:(0123456789)\nhttps://doi.org/10.1007/s13347-023-00621-y\n1 3\nEDITORIAL\nAI as Agency Without Intelligence: on ChatGPT, Large \nLanguage Models, and Other Generative Models\nLuciano Floridi1,2\nReceived: 1 March 2023 / Accepted: 1 March 2023 / \n© The Author(s), under exclusive licence to Springer Nature B.V. 2023\nThe first idea is old: all the texts are present in the dictionary; the difference is \nmade by the syntax, that is, by how the dictionary words are structured into sen -\ntences (Borges, 2000). The second idea is old: all the words in the dictionary are \npresent in the alphabet; the difference is made by morphology, that is, by how the \nletters of the alphabet are structured into words (Clarke, 1967). The third idea is \nold: all the letters are present in the digital code; the difference is made by how the \nfinite strings of zeros and ones of the digital code are structured into letters (Lodder, \n2008). The fourth idea is also old: all strings of zeros and ones are present in two \nelectromagnetic properties, current high or low, magnetisation present or absent, and \nthe difference is made by how such properties can be handled by electronic compu -\ntational devices (Mano, 1979). But the fifth idea is revolutionary: today, artificial \nintelligence (AI) manages the properties of electromagnetism to process texts with \nextraordinary success and often with outcomes that are indistinguishable from those \nthat human beings could produce. These AI systems are the so-called large language \nmodels (LLMs), and they are rightly causing a sensation.\nThe most famous LLMs are GPT3, ChatGPT (also known as GPT3.5, produced \nby OpenAI-Microsoft), Bard 1 (produced by Google) and LLaMA (produced by \nMeta). They do not think, reason or understand; they are not a step towards any sci-fi  \nAI; and they have nothing to do with the cognitive processes present in the animal \nworld and, above all, in the human brain and mind, to manage semantic contents \nsuccessfully (Bishop, 2021). However, with the staggering growth of available data, \nquantity and speed of calculation, and ever-better algorithms, they can do statisti -\ncally—that is, working on the formal structure, and not on the meaning of the texts \n * Luciano Floridi \n luciano.floridi@oii.ox.ac.uk\n1 Oxford Internet Institute, University of Oxford, 1 St Giles, Oxford OX1 3JS, UK\n2 Department of Legal Studies, University of Bologna, Via Zamboni, 27, 40126 Bologna, Italy\n1 To be precise, LaMDA (Language Model for Dialogue Applications) is the Google language model, \nand Bard is the name of the service.\nPublished online: 10 March 2023\nPhilosophy & Technology (2023) 36:15\n1 3\nthey process—what we do semantically, even if in ways (ours) that neuroscience has \nonly begun to explore.\nTheir abilities are extraordinary, as even the most sceptical must admit. Below is \na summary of The Divine Comedy made by ChatGPT (see Fig. 1).\nOne may criticize the summary because it is longer than 50 words and because \nThe Divine Comedy is not an epic poem—although there is a debate on this topic on \nthe Internet, hence the ChatGPT summary—but rather a tragedy, as Dante himself \nsuggested. That said, the summary is not bad, and certainly better than one produced \nby a mediocre student. The exercise is no longer to make summaries without using \nChatGPT, but to teach how to use the right prompts (the question or request that \ngenerates the text, see the first line of my request in Fig.  1), check the result, know \nwhat to correct in the text produced by ChatGPT, discover that there is a debate on \nwhich literary genre best applies to The Divine Comedy  and, in the meantime, in \ndoing all this, learn many things not only about the software but above all about \nThe Divine Comedy  itself. As I used to teach my students at Oxford in the 1990s, \na helpful exercise to write an essay on Descartes’ Meditations is not to summarise \nwhat has already been said, but to take the electronic text of one of the Meditations \nand try to improve its translation into English (thus one learns to check the original); \nclarify the less clear passages with a more accessible paraphrase (thus one sees if \none has really understood the text); try to criticise or refine the arguments, chang -\ning or strengthening them (thus one realizes that others have tried to do the same, \nand that is not so easy); and while doing all this, learn the nature, internal structure, \ndynamics and mechanisms of the content on which one is working. Or, to change \nthe example, one really knows a topic not when one knows how to write a Wiki -\npedia entry about it—this can be done by ChatGPT increasingly well—but when \none knows how to correct and improve it, and of course decide whether it should be \nwritten in the first place. One should use the software as a tool to get one’s hands on \nthe text/mechanism and get them dirty even by messing it up, as long as one masters \nthe nature and the logic of the artefact called text.\nThe limitations of these LLMs are now obvious even to the most enthusias -\ntic. They are fragile, because when they do not work, they fail catastrophically, in \nthe etymological sense of a vertical and immediate fall in the performance. The \nBard disaster, where it provided incorrect information in a demonstration failure \nFig. 1  ChatGPT Jan 30 Version. Test 1\n15   Page 2 of 7 L. Floridi \n1 3\nthat cost Google over $100 billion in stock losses, 2 is a good reminder that doing \nthings with zero intelligence, whether digital or human, is sometimes very pain -\nful (Bing Chat also has its problems 3). There is now a line of research that pro -\nduces very sophisticated analyses on how, when and why these LLMs, which seem \nincorrigible, have unlimited Achilles heels (when asked what his Achilles heel is, \nChatGPT correctly replied saying that it is just an AI system). They make up texts, \nanswers or references when they do not know how to reply; make obvious factual \nmistakes; sometimes cannot make the most trivial logical inferences or struggle \nwith simple mathematics, 4 including the numbers in crochet instructions 5; or have \nstrange linguistic blind spots where they get stuck (Arkoudas, 2023; Christian, \n2023; Rumbelow, 2023; Floridi & Chiriatti, 2020; Borji, 2023; Cobbe et al., 2021; \nPerez et  al., 2022). A simple example in English illustrates well the limits of a \nmechanism that manages texts statistically, understanding nothing of their content. \nWhen asked—using the Saxon genitive—what is the name of Laura’s mother’s \nonly daughter, the answer is (or rather “was”, since LLMs keep learning most \n“errors” are like zero-day exploits) kindly idiotic (see Fig.  2).\nForget passing the Turing Test. Had I been Google, I would not have staked the \nfortunes of my company on such a brittle mechanism.\nGiven the enormous successes and equally broad limitations, some people have \ncompared LLMs to stochastic parrots that repeat texts without understanding any -\nthing (Bender et al., 2021). The analogy helps, but only partially, not only because \nparrots have an intelligence of their own that would be the envy of any AI but, above \nall, because LLMs synthesise texts in new ways, restructuring the contents on which \nthey have been trained, not providing simple repetitions or juxtapositions. They look \nmuch more like the autocomplete function of a search engine. And in their capacity \nfor synthesis, they resemble those mediocre or lazy students who, to write a short \nessay, use a dozen relevant references suggested by the teacher and, by taking a lit -\ntle here and a little there, put together an eclectic text, coherent, but without hav -\ning understood much or added anything. As a college tutor at Oxford, I corrected \nmany of them every term. They can now be produced more quickly and efficiently \nby ChatGPT.\nUnfortunately, the best analogy I know to describe tools such as ChatGPT is \nculturally bounded and refers to a great classic in Italian literature, Manzoni’s The \nBetrothed (Manzoni, 2016). In a famous scene in which Renzo (one of the main \ncharacters) meets a lawyer, we read: “While the doctor [the lawyer] was uttering all \nthese words, Renzo was looking at him with ecstatic attention, like a gullible person \n[materialone] stands in the square looking at the trickster [giocator di bussolotti], \n2 https:// www. reute rs. com/ techn ology/ google- ai- chatb ot- bard- offers- inacc urate- infor mation- compa ny- \nad- 2023- 02- 08/\n3 https:// arste chnica- com. cdn. amppr oject. org/c/ s/ arste chnica. com/ infor mation- techn ology/ 2023/ 02/ ai- \npower ed- bing- chat- spills- its- secre ts- via- prompt- injec tion- attack/ amp/\n4 https:// ventu rebeat. com/ busin ess/ resea rchers- find- that- large- langu age- models- strug gle- with- math/ see \nalso https:// medium. com/ codex/ openai- updat es- chatg pt- with- impro ved- mathe matics- d6748 e98d5 34\n5 https ://  amp- thegu ardian- com. cdn. amppr oject. org/c/ s/ amp. thegu ardian. com/ techn ology/ 2023/ feb/ 26/ \nchatg pt- gener ated- croch et- patte rn- resul ts\nPage 3 of 7    15AI as   :  on  ChatGPT,  Large  Language…  Agency Without Intelligence\n1 3\nwhich, after stuffing tow and tow and tow into its mouth, takes out tape and tape \nand tape, which never ends [the word ‘nastro’ should be traduced more correctly as \n‘ribbon’, but obviously ‘tape’ is preferable in this context, for it reminds one of the \nendless tape of a Turing Machine]”. LLMs are like that trickster: they gobble data \nin astronomical quantities and regurgitate (what looks to us as) information. If we \nneed the “tape” of their information, it is good to pay close attention to how it was \nproduced, why and with what impact. And here, we come to more interesting things.\nThe implications of LLMs and the various AI systems that produce content of all \nkinds today will be enormous. Just consider DALL-E, which, as ChatGPT says (I \nquote with no modification), “is an artificial intelligence system developed by Ope -\nnAI that generates original images starting from textual descriptions. It uses state-\nof-the-art machine learning techniques to produce high-quality images matching \ninput text, including captions, keywords, and simple sentences. With DALL-E, users \ncan enter a text description of the image they want, and the system will produce an \nimage that matches the description”. There are ethical and legal issues: just think of \ncopyright and the re-production rights linked to the data sources on which the AI in \nquestion is trained. The first lawsuits have already begun, 6 and there have already \nbeen the first plagiarism scandals. 7 There are human costs: consider the use of con -\ntractors in Kenya, paid less than $2/hour to label harmful content to train ChatGPT; \nthey could not access adequate mental health resources, and many have been left \ntraumatized.8 There are human problems, like the impact on teachers who have \nto scramble to revamp their curriculum, 9 or security considerations, for example, \n6 https:// news. bloom bergl aw. com/ ip- law/ first- ai- art- gener ator- lawsu its- threa ten- future- of- emerg ing- tech\n7 https:// www. washi ngton post. com/ media/ 2023/ 01/ 17/ cnet- ai- artic les- journ alism- corre ctions/\n8 https:// time. com/ 62476 78/ openai- chatg pt- kenya- worke rs/\n9 https:// ethic alrec koner. subst ack. com/p/ er13- on- commu nity- chatg pt- and- human\nFig. 2  ChatGPT Jan 30 Version. Test 2\n15   Page 4 of 7 L. Floridi \n1 3\nconcerning the outputs of AI processes that are increasingly integrated into medical \ndiagnostics, with implications of algorithmic poisoning of the AI’s training data. Or \nthink of the financial and environmental costs of these new systems (Cowls et al., \n2021): is such a kind of innovation fair and sustainable? Then there are questions \nrelated to the best use of these tools, at school, at work, in research environments \nand for scientific publications, in the automatic production of code, or the generation \nof content in contexts such as customer service, or in the drafting of any text, includ-\ning scientific articles or new legislation. Some jobs will disappear, others are already \nemerging, and many will have to be reconsidered.\nBut above all, for a philosopher, there are many challenging questions about: the \nemergence of LEGO-like AI systems, working together in a modular and seamless \nway, with LLMs acting as an AI2AI kind of bridge to make them interoperable, as a \nsort of “confederated AI” 10; the relationship between form and its syntax, and con -\ntent and its semantics; the nature of personalisation of content and the fragmentation \nof shared experience (AI can easily produce a unique, single novel on-demand, for a \nsingle reader, for example); the concept of interpretability, and the value of the pro -\ncess and the context of the production of meaning; our uniqueness and originality \nas producers of meaning and sense, and of new contents; our ability to interact with \nsystems that are increasingly indiscernible from other human beings in their produc-\ntions; our replaceability as readers, interpreters, translators, synthesisers and evalua-\ntors of content; power as the control of questions, because, to paraphrase 1984, who-\never controls the questions controls the answers and whoever controls the answers \ncontrols reality (Floridi, forthcoming).\nMore questions will emerge as we develop, interact and learn to understand this \nnew form of agency. As Vincent Wang reminded me, ChatGPT leapfrogged GPT3 \nin performance by introducing reinforcement learning (RL) to fine-tune its outputs \nas an interlocutor, and RL is the machine learning approach to “solving agency”. It \nis a form of agency never seen before, because it is successful and can “learn” and \nimprove its behaviour without having to be intelligent to do so. It is a form of agency \nthat is alien to any culture in any past, because humanity has always and everywhere \nseen this kind of agency—which is not that of a sea wave, which makes the differ -\nence, but can make nothing but that difference, without being able to “learn” to make \na different or better difference—as a natural or even supernatural form of agency.\nWe have gone from being in constant contact with animal agents and what we \nbelieved to be spiritual agents (gods and forces of nature, angels and demons, souls \nor ghosts, good and evil spirits) to having to understand, and learn to interact with, \nartificial agents created by us, as new demiurges of such a form of agency. We have \ndecoupled the ability to act successfully from the need to be intelligent, understand, \n10 I o we this remark to Vincent Wang who reminded me of two interesting examples (1) having Chat -\nGPT and Wolfram Alpha talk to each other; ChatGPT outsources mathematics questions to Wolfram \nAlpha, which has considerable ability by itself to parse mathematical questions in natural language for -\nmat (see https:// writi ngs. steph enwol fram. com/ 2023/ 01/ wolfr amalp ha- as- the- way- to- bring- compu tatio \nnal- knowl edge- super powers- to- chatg pt/); and (2) “Socratic Models” for multimodal grounding/reason -\ning, where the idea is to tag different forms of data, e.g. sounds and images, with text descriptions so \nthat an LLM can serve as “central processing” allowing different narrow AIs to talk to each other. https:// \nsocra ticmo dels. github. io/.\nPage 5 of 7    15         AI as   :  on  ChatGPT,  Large  Language…  Agency Without Intelligence\n1 3\nreflect, consider or grasp anything. We have liberated agency from intelligence. So, \nI am not sure we may be “shepherds of Being” (Heidegger), but it looks like the new \n“green collars” (Floridi, 2017) will be “shepherds of AI systems”, in charge of this \nnew form of artificial agency (Floridi & Sanders, 2004).\nThe agenda of a demiurgic humanity of this intelligence-free (as in fat-free) AI—\nunderstood as Agere sine Intelligere, with a bit of high school Latin—is yet to be \nwritten. It may be alarming or exciting for many, but it is undoubtedly good news for \nphilosophers looking for work.\nAppendix\nApparently, ChatGPT liked the first paragraph, see Fig. 3 below.\nFig. 3  ChatGPT Jan 30 Version. Test 3\n15   Page 6 of 7 L. Floridi \n1 3\nAcknowledgements I am very grateful for the insightful comments by Ben Bariach, Alexander Blan -\nshard, Emmie Hine, Joshua Jaffe, Claudio Novelli, Mariarosaria Taddeo, and Vincent Wang. They made \na significant difference in improving an earlier version of this article.\nDeclarations \nDisclaimer This manuscript has been written using ChatGPT Jan 30 Version to generate the three figures.\nReferences\nArkoudas, K. (2023). \"ChatGPT is no stochastic parrot. But it also claims that 1 is greater than 1.\" \nMedium -  (also forthcoming in Philosophy & Technology ).  https:// medium. com/@ konst antine_ \n45825/ chatg pt- is- no- stoch astic- parrot- but- it- also- claims- that-1- is- great er- than-1- e3cd1 fc303 e0. \nAccessed 6 Mar 2023\nBender, E. M., Gebru, T., McMillan-Major A., Shmitchell S. (2021). \"On the dangers of stochastic \nparrots: can language models be too big?\" Proceedings of the 2021 ACM conference on fairness, \naccountability, and transparency.\nBishop, J. M. (2021). Artificial intelligence is stupid and causal reasoning will not fix it. Frontiers in \nPsychology, 11, 2603.\nBorges, J. L. (2000). The library of Babel. David R. Godine.\nBorji, A. (2023). A categorical archive of ChatGPT failures. arXiv preprint arXiv:2302.03494.\nChristian, J. (2023). Amazing \"Jailbreak\" Bypasses ChatGPT’s Ethics Safeguards. Futurism. https:// futur \nism. com/ amazi ng- jailb reak- chatg pt. Accessed 6 Mar 2023\nClarke, A. C. (1967). The nine billion names of God. Harcourt.\nCobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hil -\nton, J., Nakano, R. (2021). Training verifiers to solve math word problems. arXiv preprint \narXiv:2110.14168.\nCowls, J., Tsamados, A., Taddeo, M., Floridi, L. (2021). The AI gambit: leveraging artificial intelligence \nto combat climate change—opportunities, challenges, and recommendations. AI & Society, 1–25.\nFloridi, L. (2017). The rise of the algorithm need not be bad news for humans. Financial Times.\nFloridi, L. (Forthcoming). The Ethics of AI - Principles, Challenges, and Opportunities . Oxford Univer-\nsity Press.\nFloridi, L., & Chiriatti, M. (2020). GPT-3: Its nature, scope, limits, and consequences. Minds and \nMachines, 30, 681–694.\nFloridi, L., & Sanders, J. W. (2004). On the morality of artificial agents. Minds and Machines,  14(3), \n349–379.\nLodder, J. M. (2008). Binary arithmetic: from leibniz to von neumann. Resources for Teaching Discrete \nMathematics, 168–178.\nMano, M. M. (1979). Digital logic and computer design. Prentice-Hall.\nManzoni, A. (2016). The betrothed. Penguin Books.\nPerez, E., Ringer, S., Lukošiūtė, K., Nguyen, K., Chen, E., Heiner, S., Pettit, C., Olsson, C., Kundu, S., \nKadavath, S. (2022). Discovering language model behaviors with model-written evaluations. arXiv \npreprint arXiv:2212.09251.\nRumbelow, J. (2023). SolidGoldMagikarp (plus, prompt generation). AI ALIGNMENT FORUM. (https:// \nwww. align mentf orum. org/ posts/ aPeJE 8bSo6 rAFoL qg/ solid goldm agika rp- plus- prompt- gener ation). \nAccessed 6 Mar 2023\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps \nand institutional affiliations.\nPage 7 of 7    15\n         \nAI as   :  on  ChatGPT,  Large  Language…  Agency Without Intelligence",
  "topic": "Philosophy of technology",
  "concepts": [
    {
      "name": "Philosophy of technology",
      "score": 0.8177240490913391
    },
    {
      "name": "Generative grammar",
      "score": 0.760992169380188
    },
    {
      "name": "Cognitive science",
      "score": 0.5397371649742126
    },
    {
      "name": "Philosophy of science",
      "score": 0.4940264821052551
    },
    {
      "name": "Agency (philosophy)",
      "score": 0.48699456453323364
    },
    {
      "name": "Epistemology",
      "score": 0.42527467012405396
    },
    {
      "name": "Generative model",
      "score": 0.41074681282043457
    },
    {
      "name": "Psychology",
      "score": 0.4035976231098175
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3914795517921448
    },
    {
      "name": "Linguistics",
      "score": 0.3440507650375366
    },
    {
      "name": "Computer science",
      "score": 0.32119715213775635
    },
    {
      "name": "Philosophy",
      "score": 0.31952333450317383
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I40120149",
      "name": "University of Oxford",
      "country": "GB"
    }
  ],
  "cited_by": 226
}