{
  "title": "Research on the Application of Prompt Learning Pretrained Language Model in Machine Translation Task with Reinforcement Learning",
  "url": "https://openalex.org/W4385708855",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2207325303",
      "name": "Can-Jun Wang",
      "affiliations": [
        "Qilu University of Technology",
        "Shandong Academy of Sciences",
        "National Supercomputing Center in Wuxi"
      ]
    },
    {
      "id": "https://openalex.org/A2030397427",
      "name": "Zhao Li",
      "affiliations": [
        "National Supercomputing Center in Wuxi",
        "Qilu University of Technology",
        "Shandong Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2098753016",
      "name": "Tong Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2978785096",
      "name": "Wang Ruishuang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2556059533",
      "name": "Zhengyu Ju",
      "affiliations": [
        "National Supercomputing Center in Wuxi",
        "Shandong Academy of Sciences",
        "Qilu University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2207325303",
      "name": "Can-Jun Wang",
      "affiliations": [
        "Qilu University of Technology",
        "National Supercomputing Center in Wuxi",
        "Shandong Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2030397427",
      "name": "Zhao Li",
      "affiliations": [
        "National Supercomputing Center in Wuxi",
        "Qilu University of Technology",
        "Shandong Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2098753016",
      "name": "Tong Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2978785096",
      "name": "Wang Ruishuang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2556059533",
      "name": "Zhengyu Ju",
      "affiliations": [
        "National Supercomputing Center in Wuxi",
        "Shandong Academy of Sciences",
        "Qilu University of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2747680751",
    "https://openalex.org/W3149627794",
    "https://openalex.org/W4225935996",
    "https://openalex.org/W3046375318",
    "https://openalex.org/W4283219089",
    "https://openalex.org/W3169509819",
    "https://openalex.org/W3103462848",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2101391164",
    "https://openalex.org/W3160638507",
    "https://openalex.org/W4318822142",
    "https://openalex.org/W4315629614",
    "https://openalex.org/W4312850903",
    "https://openalex.org/W4225794806",
    "https://openalex.org/W4283022300",
    "https://openalex.org/W4226164531",
    "https://openalex.org/W4383341662",
    "https://openalex.org/W3046219587",
    "https://openalex.org/W4315648766",
    "https://openalex.org/W3110956179",
    "https://openalex.org/W4285820110",
    "https://openalex.org/W4287854450",
    "https://openalex.org/W2963474899",
    "https://openalex.org/W4386211255",
    "https://openalex.org/W4229506649",
    "https://openalex.org/W3154571463",
    "https://openalex.org/W3169934659",
    "https://openalex.org/W3000623537",
    "https://openalex.org/W3173777717",
    "https://openalex.org/W4281554051",
    "https://openalex.org/W3203011138",
    "https://openalex.org/W4321448364",
    "https://openalex.org/W4292779060"
  ],
  "abstract": "With the continuous advancement of deep learning technology, pretrained language models have emerged as crucial tools for natural language processing tasks. However, optimization of pretrained language models is essential for specific tasks such as machine translation. This paper presents a novel approach that integrates reinforcement learning with prompt learning to enhance the performance of pretrained language models in machine translation tasks. In our methodology, a “prompt” string is incorporated into the input of the pretrained language model, to guide the generation of an output that aligns closely with the target translation. Reinforcement learning is employed to train the model in producing optimal translation results. During this training process, the target translation is utilized as a reward signal to incentivize the model to generate an output that aligns more closely with the desired translation. Experimental results validated the effectiveness of the proposed approach. The pretrained language model trained with prompt learning and reinforcement learning exhibited superior performance compared to traditional pretrained language models in machine translation tasks. Furthermore, we observed that different prompt strategies significantly impacted the model’s performance, underscoring the importance of selecting an optimal prompt strategy tailored to the specific task. The results suggest that using techniques such as prompt learning and reinforcement learning can improve the performance of pretrained language models for tasks such as text generation and machine translation. The method proposed in this paper not only offers a fresh perspective on leveraging pretrained language models in machine translation and other related tasks but also serves as a valuable reference for further research in this domain. By combining reinforcement learning with prompt learning, researchers can explore new avenues for optimizing pretrained language models and improving their efficacy in various natural language processing tasks.",
  "full_text": null,
  "topic": "Reinforcement learning",
  "concepts": [
    {
      "name": "Reinforcement learning",
      "score": 0.8553893566131592
    },
    {
      "name": "Computer science",
      "score": 0.8470694422721863
    },
    {
      "name": "Machine translation",
      "score": 0.8091304898262024
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6893731951713562
    },
    {
      "name": "Task (project management)",
      "score": 0.6465085744857788
    },
    {
      "name": "Translation (biology)",
      "score": 0.5381366610527039
    },
    {
      "name": "Machine learning",
      "score": 0.5277284383773804
    },
    {
      "name": "Process (computing)",
      "score": 0.4998483657836914
    },
    {
      "name": "Natural language processing",
      "score": 0.4741867482662201
    },
    {
      "name": "Language model",
      "score": 0.4111039638519287
    },
    {
      "name": "Programming language",
      "score": 0.07819050550460815
    },
    {
      "name": "Engineering",
      "score": 0.06358811259269714
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Messenger RNA",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ]
}