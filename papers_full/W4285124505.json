{
  "title": "Conversational Bots for Psychotherapy: A Study of Generative Transformer Models Using Domain-specific Dialogues",
  "url": "https://openalex.org/W4285124505",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2603417723",
      "name": "Avisha Das",
      "affiliations": [
        "The University of Texas Health Science Center at Houston"
      ]
    },
    {
      "id": "https://openalex.org/A2602157910",
      "name": "Salih Selek",
      "affiliations": [
        "The University of Texas Health Science Center at Houston"
      ]
    },
    {
      "id": "https://openalex.org/A2307817173",
      "name": "Alia R. Warner",
      "affiliations": [
        "The University of Texas Health Science Center at Houston"
      ]
    },
    {
      "id": "https://openalex.org/A1979853317",
      "name": "Xu Zuo",
      "affiliations": [
        "The University of Texas Health Science Center at Houston"
      ]
    },
    {
      "id": "https://openalex.org/A2096506771",
      "name": "Yan Hu",
      "affiliations": [
        "The University of Texas Health Science Center at Houston"
      ]
    },
    {
      "id": "https://openalex.org/A2914537123",
      "name": "Vipina Kuttichi Keloth",
      "affiliations": [
        "The University of Texas Health Science Center at Houston"
      ]
    },
    {
      "id": "https://openalex.org/A2103418678",
      "name": "Jianfu Li",
      "affiliations": [
        "The University of Texas Health Science Center at Houston"
      ]
    },
    {
      "id": "https://openalex.org/A2167803262",
      "name": "W Jim Zheng",
      "affiliations": [
        "The University of Texas Health Science Center at Houston"
      ]
    },
    {
      "id": "https://openalex.org/A2105258892",
      "name": "Hua Xu",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W1989452694",
    "https://openalex.org/W3034178461",
    "https://openalex.org/W2914123964",
    "https://openalex.org/W2795743556",
    "https://openalex.org/W3100551981",
    "https://openalex.org/W3107007224",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2016126398",
    "https://openalex.org/W3086963535",
    "https://openalex.org/W2961793453",
    "https://openalex.org/W2966327596",
    "https://openalex.org/W2980364910",
    "https://openalex.org/W4288624561",
    "https://openalex.org/W3104982372",
    "https://openalex.org/W2988937804",
    "https://openalex.org/W3172764242",
    "https://openalex.org/W3169387186",
    "https://openalex.org/W1545795399",
    "https://openalex.org/W2806810262",
    "https://openalex.org/W3105218667",
    "https://openalex.org/W2944870985",
    "https://openalex.org/W2734969743",
    "https://openalex.org/W3000840260",
    "https://openalex.org/W2951583236",
    "https://openalex.org/W2972968667",
    "https://openalex.org/W2938704169",
    "https://openalex.org/W2962784628",
    "https://openalex.org/W3036236864",
    "https://openalex.org/W2743183116",
    "https://openalex.org/W2922711788",
    "https://openalex.org/W2182854643",
    "https://openalex.org/W2896784586",
    "https://openalex.org/W2883944442",
    "https://openalex.org/W4214606152",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3002330681"
  ],
  "abstract": "Conversational bots have become non-traditional methods for therapy among individuals suffering from psychological illnesses. Leveraging deep neural generative language models, we propose a deep trainable neural conversational model for therapy-oriented response generation. We leverage transfer learning methods during training on therapy and counseling based data from Reddit and AlexanderStreet. This was done to adapt existing generative models – GPT2 and DialoGPT – to the task of automated dialog generation. Through quantitative evaluation of the linguistic quality, we observe that the dialog generation model - DialoGPT (345M) with transfer learning on video data attains scores similar to a human response baseline. However, human evaluation of responses by conversational bots show mostly signs of generic advice or information sharing instead of therapeutic interaction.",
  "full_text": "Proceedings of the BioNLP 2022 workshop, Dublin, Ireland, pages 285–297\nMay 26, 2022. ©2022 Association for Computational Linguistics\n285\nConversational Bots for Psychotherapy: A Study of Generative\nTransformer Models Using Domain-specific Dialogues\nAvisha Das1, Salih Selek2, Alia R. Warner2,\nXu Zuo1, Yan Hu1, Vipina Kuttichi Keloth1, Jianfu Li1, W. Jim Zheng1, and Hua Xu1\n1School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX\n2Department of Psychiatry and Behavioral Sciences, UTHealth McGovern Medical School, Houston, TX\n{Avisha.Das, Salih.Selek, Alia.R.Warner, Xu.Zuo, Yan.Hu, Vipina.KuttichiKeloth, Jianfu.Li,\nWenjin.J.Zheng, Hua.Xu}@uth.tmc.edu\nAbstract\nConversational bots have become non-\ntraditional methods for therapy among\nindividuals suffering from psychological\nillnesses. Leveraging deep neural generative\nlanguage models, we propose a deep trainable\nneural conversational model for therapy-\noriented response generation. We leverage\ntransfer learning methods during training\non therapy and counseling based data from\nReddit and AlexanderStreet. This was done to\nadapt existing generative models – GPT2 and\nDIALO GPT – to the task of automated dialog\ngeneration. Through quantitative evaluation\nof the linguistic quality, we observe that the\ndialog generation model - DIALO GPT (345M)\nwith transfer learning on video data attains\nscores similar to a human response baseline.\nHowever, human evaluation of responses by\nconversational bots show mostly signs of\ngeneric advice or information sharing instead\nof therapeutic interaction.\n1 Introduction\nPsychological and mental disorders, such as de-\npression and anxiety, are a growing concern world-\nwide. About an estimated 5% of the global adult\npopulation suffer from depression.1 The National\nAlliance on Mental Illness (NAMI) reports 1 in\n5 adults in the U.S. were diagnosed with mental\nhealth issues.2\nPsychological ailments are complicated and chal-\nlenging to diagnose and can manifest in an indi-\nvidual, in any form, regardless of their age, race,\nand gender. In extreme situations, lack of diagno-\nsis and proper treatment can also be fatal. 2 How-\never, only a fraction of the suffering individuals\nseek proper treatment from a mental health profes-\n1Institute of Health Metrics and Evalua-\ntion - Global Health Data Exchange (GHDx),\nhttp://ghdx.healthdata.org/gbd-results-tool?params=gbd-api-\n2019-permalink/d780dffbe8a381b25e1416884959e88b\n2https://www.nami.org/mhstats\nsional due to the existing stigma surrounding men-\ntal health. Additionally, the growing dearth in the\ncurrent clinical workforce also adds to the problem.\nThis impending crisis has led to a growing interest\nin automated conversational bots as non-traditional\nmethods of receiving treatment for mental health\n(Ali et al., 2020; Vaidyam et al., 2019). A major-\nity of the available conversational agents generate\nresponses based on predefined rules or tree-based\ndialog flows, and may not be useful for therapeutic\ncounseling (Mousavi et al., 2021) due to shallow\nand ineffective conversations (Abd-Alrazaq et al.,\n2021). Recent developments in massive language\nmodeling through deep learning has resulted in suc-\ncessful outcomes in natural language understand-\ning and generation tasks. Transformer architectures\nlike OpenAI’s GPT-2 (Radford et al., 2019) have\nbeen used in conversational modeling and dialog\ngeneration with great empirical success (Zhang\net al., 2020; Wolf et al., 2019).\nWhile deep neural learning has helped improve\nthe cognitive capability of these conversational\nagents, training such chatbots for a particular task\nrequire massive amounts of in-domain conversa-\ntional data. Currently available massive pre-trained\nmodels have been trained on a motley of web-\nscraped articles and conversations on social me-\ndia platforms (Devlin et al., 2018; Radford et al.,\n2019) that may contain toxic and aggressive con-\ntent (Anderson, 2015). Therefore, dialog mod-\nels pre-trained on such text can often generate re-\nsponses that are harmful and callous, making them\nunsuitable for conversational psychotherapy (Pérez-\nRosas et al., 2018; Harrigian et al., 2021).\nExisting research on neural response generation\nhas generated multiple data sets for evaluating di-\nalog responses, however data related to mental\nhealth counseling is very limited (Harrigian et al.,\n2021; Pérez-Rosas et al., 2018). Additionally, a\nmajority of these data sets have been collected\nthrough crowd-sourced human-human conversa-\n286\ntions (Rashkin et al., 2019), video transcripts of mo-\ntivational interviewing (Pérez-Rosas et al., 2018),\nthrough text messaging (Gupta et al., 2020), etc.\nMental health and psychological counseling data\nis sensitive with limited access and availability –\nrestricting the improvement of dialog agents in the\ndomain of psychotherapy counseling.\nThis study leverages existing generative archi-\ntectures like the DialoGPT (Zhang et al., 2020),\nan open-domain dialog model based on OpenAI’s\nGPT-2 (Radford et al., 2019), for therapeutic con-\nversational modeling for mental and emotional sup-\nport. We additionally explore model fine-tuning\nthrough transfer learning on therapy counseling\nvideos for therapy-based response generation (Wolf\net al., 2019). For pre-training and fine-tuning, we\nuse Subreddit threads that contain submissions on\ntherapy and counseling, mental disorders and ail-\nments (De Choudhury and De, 2014; Sharma et al.,\n2020), and transcripts of English therapy and coun-\nseling videos from AlexanderStreet website. Se-\nlecting the top models through a metric-based quan-\ntitative evaluation (Sedoc et al., 2019), we perform\na task-based effectiveness study through human\nevaluation setup.\n2 Related Work\nWhile conversational agents have been used for\nmultiple reasons, one major area of application is\nthe diagnosis and treatment of psychological ill-\nnesses. From the first simple conversational agent\nELIZA developed in 1966 by Joseph Weizenbaum\nto act as a Rogerian psychotherapist, current chat-\nbots have undergone major improvements with the\nadvancements in the field of artificial intelligence\n(AI) like natural language processing (NLP) and\nmachine learning (ML) (Sharma et al., 2017).\n2.1 Therapy-based Conversational Systems\nChatbots can generate human-like social and emo-\ntional responses, however the effectiveness of such\nautomated agents have not been thoroughly inves-\ntigated. Previous researchers have examined the\nkey considerations and usefulness for incorporat-\ning conversation AI in psychotherapy (Miner et al.,\n2019; De Gennaro et al., 2020; Pham et al., 2022).\nPacheco-Lorenzo et al. (2021) study review how\nsmart conversational agents have been used to de-\ntect neuropsychiatric disorders by researchers – of\nwhich, (Mallol-Ragolta et al., 2019; Tsai and Lin,\n2018) applied deep neural learning models for psy-\nchiatric oriented response generation. Vaidyam\net al. (2019) also report studies showing the poten-\ntial of conversational agents in psycho-education\nand self-adherence. Most of the systems like (Bick-\nmore et al., 2010b,a; Tielman et al., 2017a,b) used\nthree-dimensional setups or interfaces to interact\nwith the users.\nZhang et al. (2020) proposes DIALO GPT , a\nlarge-scale, tunable conversational model trained\nand fine-tuned on Reddit conversational threads.\nThe model was built using OpenAI’s GPT-2 archi-\ntecture as the base model (Radford et al., 2018,\n2019). To better tune a massive generative model\nfor task-specific performance, (Wolf et al., 2019)\nused an architecture called TransferTransfo to fine-\ntune the transformer-based BERT model on conver-\nsational data for the ConvAI2 challenge. (Huang\net al., 2020) present a graph-based automated co-\nherence metric for evaluating open-domain didactic\nconversations. Sedoc et al. (2019) combines mul-\ntiple popular metrics like lexical diversity, BLEU\nscores, mean cosine similarity between generated\nand ground-truth responses, system perplexity, etc.\ninto an evaluation tool called ChatEval.\n2.2 Psychotherapy Dialog Datasets\nPérez-Rosas et al. (2018) proposes a novel dataset\nthat consists of high and low quality counseling\nconversations collected from publicly available\nsources. Along with collection procedure the au-\nthors also describe the annotation procedure in-\nvolving counseling skills like reflective listening\nand questioning. Harrigian et al. (2021) analyze\nthe state and impact of social media resources as\ndata for mental health research. Such sources like\nReddits have been used in systems proposed by\n(Sharma and De Choudhury, 2018) and (Sharma\net al., 2020) for studying empathy in human-human\nconversation threads. Researchers in (Rashkin\net al., 2019) and (Mousavi et al., 2021) have pro-\nposed corpora on empathetic and therapeutic di-\nalogs collected through real-life human-human con-\nversations. Rashkin et al. (2019) uses crowdsourc-\ning for building the corpora, while conversations\nbetween therapists and human participants are used\nby Mousavi et al. (2021) in their study. The au-\nthors in (Campillos-Llanos et al., 2020) address\nthe task of varied terminologies and ontologies in\nmedical domain by designing a knowledge-based\npatient record model using frame- and rule-based\napproach and terminology-rich resources like struc-\n287\ntured thesauri with linguistic, terminological and\nontological knowledge. Similar task of term-based\nadaptivity in the clinical domain was also studied\nby Nirenburg et al. (2008), who used a multi-agent\nnetwork model as a solution.\n3 Data Collection\nTo train and incorporate the attributes of therapy\nin conversation - we collect the data by scraping\nSubreddit threads on mental health and transcripts\nof videos on psychotherapy and counseling. We\nextract the conversations about mental health and\ntherapy from online sources and platforms such as\nReddit (Baumgartner et al., 2020) and Alexander\nStreet Press.3\n3.1 Mental Health Subreddits\nReddit ( www.reddit.com) is an online plat-\nform that hosts multiple sub-communities or sub-\nreddits where people share their comments and\nviews through posts and comments. Prior re-\nsearch (Sharma et al., 2020; De Choudhury and De,\n2014; Sharma and De Choudhury, 2018) has pro-\nposed the use of Reddit to facilitate conversations\nand support for mental health and wellness through\ndifferent subreddits like depression, anxiety, ther-\napy and counseling, etc. In this study, we collected\na total of 68,835 posts and 809,646 comments from\nmental-health related subreddits. These publicly\navailable subreddit threads have been curated and\nused in previous research for mental health and\nempathetic textual modeling. We use the Pushshift\nReddit API to periodically scrape Reddit for the\ndata.4\nWe followed the pre-processing steps outlined\nby Zhang et al. (2020) to prepare our scraped sub-\nreddit submission data. These include removal of\nsubmissions – (a) with a URL in source or target,\n(b) not containing at least one of the most frequent\nEnglish words (like \"the\", \"a\", etc.), (c) empty or\nupvoting comments, (d) with less than five words or\nmore than 200 words. To convert the thread-based\nstructure (posts and comments) to a conversational\ndialog-like input, we model them astree-structured\nreply chains(Zhang et al., 2020). Table 1 shows\nthe statistics of the data collected. The subred-\ndits scraped can be divided to the following broad\ncategories based on (Sharma and De Choudhury,\n2018): (a) Coping and Therapy (C-Th): 7Cup-\n3https://video.alexanderstreet.com/\n4https://github.com/pushshift/api\nsofTea, Existential_crisis, getting_over_it, Grief-\nSupport, helpmecope, hardshipmates, HereToHelp,\nitgetsbetter, LostALovedOne, offmychest, MMFB,\nMiscarriage, reasonstolive, SuicideBereavement,\ntherapy; (b) Mood Disorders (MD): depression, de-\npressed, lonely, mentalhealth; (c) Psychosis and\nAnxiety (P-An): anxiety, BipolarReddit, socialanxi-\nety; and (d) Trauma and Abuse (Tr-A): abuse, sur-\nvivors, Anger, emotionalabuse, PTSDcombat.\nTraining setup. We used the subreddit data to\nfine-tune the GPT-2 (345M) model and it served as\na baseline. This was done because we compared\nits performance with the DialoGPT model (Zhang\net al., 2020), which has already been trained on a\nhuge Reddit dump. We discuss the models in detail\nin Section 4.\n3.2 Psychotherapy Videos\nAlexander Street Press5 is a website with a large\ncollection of video transcripts and video recordings\nof therapy and counseling sessions on topics like\ndepression, abuse, trauma, mental disorders, etc.\nThe video transcript dataset was collected from the\nCounseling and Therapychannel on the website.6\nOf the 2,253 videos on the channel, we extracted\nvideos on counseling and therapy training sessions.\nCollecting only sessions recorded in English rang-\ning from the years 1980 to 2018, the collected set\nconsists of 1,284 videos and transcripts. We re-\nmoved some short-length non-informative videos,\nthe final set has 1,130 video transcripts with a total\nof 180,765 dialog turns. After cleaning the data to\nremove unicode characters, pauses, etc., the data\nconsists in total 2,914,307 words with a vocabulary\nsize of 30,438.\nTraining setup. We divide the set of video tran-\nscripts into different subsets, with 80% for training\n(904 videos), 10% for development (112 videos)\nand hyperparameter fine-tuning, and 10% for test-\ning (114 videos).\n3.3 Independent Test Data\nTo further evaluate, the performance of the dialog\ngeneration models, we built an independent con-\nversational dataset by collecting responses from a\ndifferent source. This is an out-of-domain dataset\nof synthetic human-human conversations. The Em-\npathic Conversationdataset was created by collect-\ning 25 conversations written by a group of research\n5https://alexanderstreet.com/\n6https://video.alexanderstreet.com/channel/counseling-\nand-therapy-in-video\n288\nDialog\nEmbeddings\nPsychotherapy\nTraining Videos\nTherapy\nSubreddits\nDialog Response\nGenerator\nDialogs Bot Inputs Embedding Model\nPre-training\nFine-Tuning\nTransfer  \nLearning\nPre-trained Generative Models\nGPT-2 DialoGPT\nGPT-2 DialoGPT\nTrained Language ModelsPost-Processing\nEvaluation\nFigure 1: The schematic of the model training and dialog response generation\nCategory Collected Posts Filtered Posts Comments Avg. CL V ocab Size\nC-Th 49,426 38,750 625,149 16.13 102,458\nMD 6,000 3,519 37,350 10.61 28,833\nP-An 3,048 1,925 31,112 16.17 28,116\nTr-A 10,361 6,758 116,035 17.17 56,542\nTable 1: Statistics for Scraped Subreddit Data. Avg. CL: Average Conversation Length or Number of Turns in\nConversation, Vocab Size: Vocabulary Size\nscientists, post-doctoral scholars and doctoral stu-\ndents for a given set of empathic prompts corre-\nsponding to stress inducing situations like health,\nwork, trauma or abuse (Zhang et al., 2019; Du et al.,\n2018). The group consisted of 5 participants, each\nof whom wrote 5 conversations. Each conversa-\ntion consisted of a total of 5 or more utterances. 7\nThe average conversation length was 7.2 utterances\nwith each utterance has an average of 12.3 words.\n4 Model\n4.1 Model Architecture\nWe use the Generative Pretrained Transformer\n(GPT-2) (Radford et al., 2019) architecture as our\nbaseline model. The massive pre-trained generative\nlanguage models like GPT-2 can generate realistic\nlooking text from a given prompt (Radford et al.,\n2019) – but the text may be noisy or unrelated to the\nnature of the task (Wolf et al., 2019). This becomes\nmore challenging in the case of automatic coherent\nresponse generation during didactic conversations.\nThe other baseline, Zhang et al. (2020)’s DialoGPT\nwas trained (fine-tuning and training from scratch)\n7An uninterrupted sequence of words spoken in a speech\nis an utterance.\non subreddit threads to capture task-oriented dia-\nlogue generation.\nAdditionally, to adapt the model for specialized\ntextual content, like therapeutic counseling, we\nneed to build a generative system that is more goal-\noriented, topical and coherent. While fine-tuning\nhas been widely used for domain adaptation - the\ntechnique may not be adequatefor our task for two\nmain reasons – (a) the nature of the dataset we use\nfor training/fine-tuning our base models is different,\nvideo transcripts vary in nature from community\nposts like Reddit (DialoGPT) and general web text\npages (GPT-2), and (b) dialog response generation\ntasks combines multiple linguistic aspects such as\nco-reference resolution, common-sense knowledge,\nand long-range dependency. Therefore, following\nthe technique proposed by (Wolf et al., 2019), we\nadd transfer learning during fine-tuning the pre-\ntrained baseline models for our dialog generation\ntask. The experimental setup and details are further\nexplained in the following sections.\n4.1.1 GPT-2\nOpenAI’s GPT-2 (Radford et al., 2019, 2018) is a\nlarge transformer-based network trained on web-\nscraped textual content (8 million pages of web-\n289\ntext). The generative pre-trained architecture is\nbased on transformer decoder-only blocks with at-\ntention modeling (Vaswani et al., 2017) and has\noutperformed previous state-of-the-art approaches\non natural language understanding based tasks. Of\nthe three model configurations, we use the GPT-2\nmedium (345M, 24, 1024, 64) 8 The models use\nbyte-pair encoding (BPE) scheme (Sennrich et al.,\n2015) to encode the input text allowing the architec-\nture to handle a wider range of vocabulary. Since\nthe GPT-2 model was trained on web text, we pre-\ntrain a baseline model on the collected subreddit\ndata.\n4.1.2 DialoGPT\nZhang et al. (2020) proposes the DialoGPT model\nthat adapts the GPT-2 (Radford et al., 2018) for\ndialog generation. The implementation of the Di-\naloGPT architecture along with the pre-trained\nmodels have been provided by (Zhang et al., 2020).\nIn our implementation, we use the DialoGPT model\nbased on a PyTorch adaptation made available by\nthe HuggingFace team.9 The model was trained on\n147M multi-turn dialogue from Reddit discussion\nthread, collected over a span of 2005 to 2017.\n4.2 Model Fine-tuning\nRetraining the pre-trained models is necessary to\ncondition the model for dialog generation – fine-\ntuning the generative architecture produce stylisti-\ncally and linguistically better content from a given\nprompt (Das and Verma, 2020). We use the Python\nimplementation of the GPT-2 models made avail-\nable by OpenAI.10\nThe traditional fine-tuning experiment on the\nvideo transcripts and Reddit threads resulted in\ntwo sets of models. We fine-tune the GPT2 model,\npre-trained on subreddit threads, on the psychother-\napy training videos. Since DialoGPT was already\ntrained on a huge dump of Reddit data, we only use\nthe video transcripts for fine-tuning it. Therefore,\nwe have two sets of models as a result of tradi-\ntional fine-tuning. Here, the transformer model\nsize varies from small, medium, and large, here we\nfocus on the medium (345M) size of the generative\nmodels. The set of fine-tuned models to evaluate:\n8We report the model configurations in the following or-\nder: Model-name (number of parameters, number of layers,\nembedding dimension, batch size/GPU)\n9https://huggingface.co/docs/transformers/model_doc\n/dialogpt\n10https://github.com/nshepperd/gpt-2\n(a) GPT2 (345M)-FT-V , and (b) DialoGPT (345M)-\nFT-V .11 The batch size and the learning rate were\nchosen based on the computation capability of the\nA100-SXM4 GPUs used to fine-tune the models.\n4.3 Fine-tuning with Transfer Learning\nWe use the TransferTransfoarchitecture proposed\nby Wolf et al. (2019) for the Conversational Intelli-\ngence Challenge 212 (ConvAI2). TransferTransfo\nuses the multi-layer transformer encoder model\nGPT-2 (Radford et al., 2018, 2019) along with po-\nsitional and segment embeddings extracted from a\nset of dialog conversations to incorporate speaker\npersonality into conversations. The architecture\nuses transfer learning to adapt a content generation\nmodel like GPT-2 to a dialog generation task.\nWe use a similar setup for our transfer learning\napproach during the fine-tuning step. Using the\npre-trained GPT-2 and DialoGPT (Radford et al.,\n2018; Zhang et al., 2020) as the base models, we\nfine-tune the language models on the collected\ntherapy-specific conversation data from Reddit and\nAlexanderStreet. Unlike the original model, we re-\nmove the persona inputs, but keep the conversation\nhistory of a pre-specified fixed sequence length.\nAdditionally, similar to Wolf et al. (2019)’s imple-\nmentation, we combine the ‘gold’ human response\n(or correct response) as well as sampled ‘distractor’\nresponse from the dataset. The distractor responses\nare actually randomly chosen responses from dif-\nferent conversation sequences in the dataset. The\ncombined set of inputs (conversation history, gold\nresponse, and distractor response) are then used to\ncreate the set of input embeddings using the GPT-2\ntokenizer model. The model schematic has been\nshown in Figure 2. To learn a global representation\nof the given context (nature of dialog conversa-\ntions), we use a double headed model implemen-\ntation called OpenAIGPTDoubleHeadsModel,13\ntrained using a multi-task loss function that models\nboth the generative and predictive loss functions.\nTo adapt the process of transfer learning for\nour purpose, we take a sequence of N = 5 sen-\ntences during training as conversation history. The\nN + 1-th response is added as gold responseand\nrandomly sampled a distractor responsefrom the\nutterances from other conversations. The Ope-\nnAI’s DoubleHead GPT2 Language Model was\n11FT - Fine-tuning based, V - Video\n12http://convai.io/\n13https://huggingface.co/docs/transformers/\nmodel_doc/gpt2#transformers.GPT2DoubleHeadsModel\n290\nFigure 2: Transfer Learning Architecture\nused for tokenization and embedding the inputs.\nUsing the medium (345M) configuration for our\nevaluation models, we evaluate the following mod-\nels for performance – (a) GPT2 (345M)-TL-V and\n(b) DialoGPT (345M)-TL-V .14 Similar to the fine-\ntuning, DialoGPT is fine-tuned using only video\ndata, while GPT-2 baseline model was used after\npre-training on the collected subreddit data.\n4.4 Generation Methods\nThe most popular and widely used decoding tech-\nniques for text generation include top-k sampling,\ngreedy decoding and beam search (Das and Verma,\n2020). Of these, top-k sampling (Holtzman et al.,\n2019) has shown the best results for coherent long-\nform text generation. We select the value of k as\n10 in our experiments. The softmax temperature t\nwas chosen as 1.0, which is the default value.\nGreedy decoding is also not a good decoding al-\ngorithm often generating incoherent textual content.\nBeam search (BS)method of sampling improves\nupon greedy sampling by selecting k most proba-\nble responses at each step of decoding the output\nand finally repeats the step iteratively until the most\nprobable sequence is selected. Here, k is the beam\nlength. DialoGPT models with 345M parameters\nand beam search of length 10, showed the best re-\nsults (Zhang et al., 2020) in comparison to top- k\nsampling method.\n14TL - Transfer learning based, V - Video\n4.5 Experiments and Evaluation\n4.5.1 Experimental Setup\nWe evaluate the performance of the GPT-2 and Di-\naloGPT models (Zhang et al., 2020; Radford et al.,\n2018, 2019) on the dialog response generation task\nwith the goal of therapeutic counseling. Based on\ncomputational ease and prior performance (Das and\nVerma, 2020; Zhang et al., 2020), we select the gen-\nerative model with the medium size with 345M\nparameters to demonstrate the findings for the\ntask. Finally, we also test two decoding/sampling\ntechniques – top-k and beam search, we set k and\nthe beam length to 10 in both cases. This was cho-\nsen empirically through a hyperparameter tuning\nsetup.\nWe fine-tune our models on a single A100-\nSXM4 GPU and select the training epoch size as\n1015 for both sets of models. The batch size and\ninitial learning rate for the fine tuning experiments\nare chosen as 16 and 2e−5. As used by Zhang\net al. (2020) for their implementation, we use the\nNoam learning rate (selected based on validation\nloss) scheduler with 2000 warm-up steps. 16 For\nan accelerated trainingof the DialoGPT models,\n(Zhang et al., 2020) first compress the training data\nto a lazy-loading file type for faster loading during\nfine-tuning. We convert our datasets (video and red-\ndit conversations) to an HDF5 file format to reduce\ncomputation load and accommodate GPU memory\nlimitations. For the transfer learning setup, we use\n15chosen through hyperparameter tuning on held-out devel-\nopment dataset\n16https://docs.allennlp.org/main/api/training/learning_rate\n_schedulers/noam/\n291\nAlexanderStreet\nTherapy Videos  \n(test set n =114)\nEmpathic Conversation\nData  \n(test set n = 25) \nTest Sets for Quantitative\nEvaluation of Models\nHuman Reference Data\n(Therapy training Videos) \n(Reference set n = 50) \nHUMAN Reference Data \nBLEU-2 Scores\nDistinct -1 and\nDistinct -2 Grams\nAverage Length \nCosine Similarity \nQuantitative Evaluation\nprompth u m a n \nresponseh u m a n responsem o d e l \nFigure 3: Quantitative Evaluation Setup\nthe 6.25e−5 as the learning rate with Adam opti-\nmizer and PiecewiseLinear as the rate scheduler.\nWe use the same number of epochs for fine-tuning\nthe models with transfer learning. For the GPT2\nmodel, the fine-tuning setup without the transfer\nlearning took about 27 hours on the GPU, and\nwith transfer learning the fine-tuning took approxi-\nmately 38 hours. The traditional fine-tuning of the\nDialoGPT model took an average of roughly 34\nhours and with transfer learning it took about 49\nhours.\n4.5.2 Evaluation Metrics\nThe ChatEval toolkit (Sedoc et al., 2019) is a col-\nlection of automatic quantitative metrics used for\nevaluating standard machine translation task per-\nformance. Using the metrics toolkit, we report the\nfollowing: (a) Lexical diversity (Distinct-n): The\nnumber of unique n-grams in the models’ response\nnormalized by the token length. We consider the\nvalue of n = 1, 2, (b) Average cosine-similarity\nbetween the word embedding vectors of a gener-\nated response with the ground-truth human written\nresponse. We use a Word2Vec model trained on the\nconversation data to create the embedding vectors,\n(c) Sentence average BLEU-2 score. Additionally,\nwe also report the average lengthof the generated\nresponses.\n5 Results\nWe discuss in detail the qualitative and quantitative\nevaluation metrics and performance of the differ-\nent generative language models for therapy-based\ndialog response generation. We show our evalua-\ntion setup in Figure 3. We first perform a quanti-\ntative metric-based evaluation on an in-domain\ntest dataset of therapy videos. The test dataset\nfor model evaluation consists of 114 videos col-\nlected from AlexanderStreet Therapy and Coun-\nseling training videos. The dataset has a total of\n18,237 dialog utterances and 312,276 words. To\ncompare the generated response with the test refer-\nence set, we select conversation length of at least\n5 utterances as the maximum sequence length for\nthe next utterance generation. Given a sequence\nof N responses, the generated N + 1th response\nis compared to the corresponding human response\nin the original conversation. Here, we evaluate\nthe model performance for a single utterance given\na prompt. For calculating the HUMAN system\nmetrics, we created a held-out subset of 50 con-\nversations to calculate the metrics. These 50 con-\nversations were selected from the AlexanderStreet\nvideo test dataset. We calculate the metrics by us-\ning the N-th response from these conversations\nand comparing them with the human ground truth\nresponse.\nFor the qualitative and task-based effective-\nness analysis, we selected responses generated by\nthe top three models from the quantitative evalu-\nation, and showed them to our psychotherapy do-\nmain experts to judge. We further calculate the\ninter-annotator agreement between two judges to\nmeasure the effectiveness of the systems and their\nfeasibility in automated therapy-based counseling.\nWe present the scores of the automated quantita-\ntive metrics provided by the ChatEval tool (Sedoc\net al., 2019) on the video test dataset in Table 2.\nThe different metric scores are denoted by \"Vid.\"\nin the table. We see that the DialoGPT model usu-\n292\nally scores closer to the human response baseline\nscores. With transfer learning on the video data,\nthe scores like BLEU-2 and Distinct-uni and bi-\ngrams in the generated responses are relatively\nhigher – even than the human baselines. Beam\nsearch also shows to generate responses with im-\nproved BLEU and Distinct-n scores. As explained\nin (Zhang et al., 2020), we also conclude that typ-\nically ‘higher’ scores from the generative models\ndo not mean that these systems generate responses\nlargely better in quality than human speakers. The\nquantitative evaluation is a measure ofsemantic dis-\ntance between a set of preceding responses and the\ngenerated content. So, a higher automatic BLEU-2\nscore shows a lower semantic distance and thus\nprovides an understanding of the model’s perfor-\nmance with respect to human baselines. Based\non the models’ performance across the Video test\ndataset, we see that DialoGPT is the best model\nwith techniques like transfer learning and beam\nsearch decoding helping in achieving better quanti-\ntative scores overall.\n5.1 Additional Evaluation\nWe also compare the quantitative evaluation met-\nrics on the independent dataset described in Sec-\ntion 3. The results on the independent synthetic\nEmpathic conversation datahave been summarized\nin Table 2 under \"Emp\". Although the quantitative\nscores are typically lower in this case, due to the\nshorter nature of the conversations, we see a sim-\nilar trend in the model performance – DialoGPT\nfine-tuned with transfer learning and beam search\ndecoding generated responses that score quantita-\ntively higher compared to other models.\nBased on the results shown in Table 2, we se-\nlect the top three dialog-based generative systems\nfor our human evaluation setup. The three mod-\nels selected were – DialoGPT-BS (beam search),\nDialoGPT-topk, and GPT-2-BS – all the models\ntrained using the transfer learning (TL setup).\n5.1.1 Human Evaluation\nWe evaluate the performance of dialog generation\nmodels based on qualitative scores to measure the\nlinguistic and task-based effectiveness of the gen-\nerated samples. We sample a set of 10 source\nstatements from Therapy and counseling videos\non AlexanderStreet. Each of these prompts belong\nto a psychotic stressor-inducing situation like ad-\ndiction, alcohol consumption, cyberbullying, etc\n(Zhang et al., 2019; Du et al., 2018). To anonymize\nthe system names and to remove any existing bias,\nwe refer to them as Systems A, B, and C respec-\ntively. Given a starting conversation prompt, each\nsystem generates the statement in response to the\nprompt – generating a total of 30 samples to be\nevaluated.\nWe present the samples to two judges – a psychi-\natrist and a psychologist, experts in psychotherapy\nand acquainted with the required resources for the\nevaluation. For every stressor situation, we present\nthree generated conversations to each judge to help\nthem compare the context across all three systems.\nThe average length (i.e., the number of utterances)\nof each generated conversation was 5 – we choose\nto present longer conversations to ensure the judges\nhave more context and content and look at the con-\nversation more globally before making a decision\n– instead of evaluating the system at a single utter-\nance generation level (Zhang et al., 2020).\nThe qualitative metrics used to measure the thera-\npeutic effectiveness were taken from a standard set\nof assessment questions used to score psychother-\napy resident performance– (a) Communication:\nDid the bot ask any relevant questions to under-\nstand the situation – reason for session, sugges-\ntions, response of patient, plans for future, etc.?\n(b) Basic Psychotherapy Skills: Which conversa-\ntion showed the signs of basic psychotherapy skills\nlike active listening, open-ended inquiries, restate-\nment/reflection/summarization, empathy? (c) Over-\nall Psychotherapy Competence: Which conversa-\ntion would you say is better on overall psycho-\ntherapeutic competence? Each sample is rated us-\ning Likert scale-based system from 1 to 5 for each\nmetric, with 1 denoting the conversation as ‘Not\neffective at all’and 5 being ‘Extremely effective’.\nWe calculated the Inter-Annotator Agreement\nscores using both Cohen’s κ and Krippendorff’s\nα, with 0.286 and 0.34 respectively – this demotes\nfair agreement between the judges. Although we\nobserve a strong preference for the DialoGPT gen-\nerated responses – the judges comment on the\nunhealthy and non-therapeutic advice from the\nchat agents, typically discouraged in psychotherapy\npractice, indicating the need for further improve-\nments in automated psychotherapy. Such an ex-\nample has been shown in Table 5 in the Appendix\nSection. The skewness in the scores could also\nmean the confusing nature of the conversations\ncausing the judges to not fully comprehend the ac-\ntual purpose of the bot. Along with some sample\n293\nMethod Type BLEU-2(%) Dist-1(%) Dist-2(%) Avg. Len. Cos. Sim.\nVid. Emp. Vid. Emp. Vid. Emp. Vid. Emp. Vid. Emp.\nGPT-2 (345M)-\ntop-k\n- 7.14 8.34 8.3 9.1 11.4 14.3 7.4 8.3 0.412 0.586\nFT 8.02 9.68 7.8 8.2 17.2 12.7 6.2 7.6 0.507 0.632\nTL 11.17 10.03 9.1 8.7 16.8 15.2 8.1 10.2 0.618 0.643\nGPT-2 (345M)-\nBS\n- 6.85 7.05 9.5 8.3 14.2 15.6 7.4 7.8 0.603 0.587\nFT 10.73 8.96 10.4 10.9 14.7 18.4 9.5 9.1 0.702 0.732\nTL 10.18 11.76 13.7 9.6 17.6 15.7 8.8 9.3 0.674 0.613\nDialoGPT (345M)-\ntop-k\n- 9.04 9.34 7.4 6.3 8.9 11.3 8.1 8.3 0.505 0.519\nFT 12.03 12.61 11.3 9.7 13.3 14.9 9.0 10.1 0.640 0.678\nTL 16.83 17.71 15.1 7.4 16.4 17.7 10.6 11.4 0.719 0.701\nDialoGPT (345M)-\nBS\n- 9.06 9.13 9.2 7.9 19.2 20.3 8.7 9.4 0.752 0.658\nFT 13.16 12.02 15.4 9.1 23.1 26.5 9.2 10.3 0.730 0.771\nTL 16.31 17.15 18.3 10.3 25.7 28.8 11.4 10.2 0.683 0.662\nHUMAN - 12.19 10.43 14.9 15.8 41.2 33.2 7.3 11.6 0.801 0.726\nTable 2: Evaluation Results on the AlexanderStreet Video test dataset (Vid.) and Empathic Conversation dataset\n(Emp.). Here, BS - Beam Search, TL - Transfer learning based, FT - Fine tuning based, Dist-1 - Distinct - 1, Dist-2 -\nDistinct-2, Avg. Len. - Average Length and Cos. Sim. - Cosine Similarity.\nconversations, we also include an example of the\nhuman evaluation template used for judging in the\nAppendix.\n6 Conclusion\nWe propose a novel technique to adapt existing\nopen-domain pre-trained generative models, Di-\naloGPT (dialog-based) and GPT-2, for therapeutic\nconversation modeling. To fine-tune the model to\nthe specific task of didactic conversations, we use\na transfer learning technique to model aspects of\ntherapist-patient counseling extracted from therapy\nvideo transcripts. On existing automated quantita-\ntive evaluation metrics, DialoGPT performed better\nthan the GPT-2. Furthermore, a task-based effec-\ntiveness evaluation by human judges of the gener-\nated samples show that the models, pre-trained on a\nsubsequently larger content of Subreddit data, gen-\nerate responses with unhealthy advice or generic\ninformation usually discouraged in traditional ther-\napeutic counseling. This indicates the need for fur-\nther improvements in automated therapy counsel-\ning like domain-specific clinical and therapy data.\n7 Future Work\nWe used a subset of the massive Reddit community\nto train our models – but there exists a large number\nof subreddit threads like r/therapy, r/askatherapist,\nr/schizophrenia, etc., that can capture contents and\ndiscussions on psychotherapy and psychosis. Inclu-\nsion of a variety of mental health related content\nwill enrich our conversational model incrementally.\nOur primary goal is to build an automated system\nthat can provide therapeutic guidance and advice to\nindividuals through conversation. The usefulness\nof such a bot-based therapist is the accessibility,\navailability, and convenience of a conversational\nassistant during emergencies. Therapist-patient\nconversational transcripts have not been used in\nprevious AI-based bots and is a novel contribution\nof this study and using further sophisticated post-\nprocessing and abstraction techniques will help\nalleviate the problems the bot is suffering from.\n8 Acknowledgements\nThis work is partly supported by the Cancer Pre-\nvention and Research Institute of Texas through\ngrant RP170668 (Dr. Wenjin J. Zheng), the Na-\ntional Institutes of Health (NIH) through grants\n1UL1TR003167 and R01AG066749 (Dr. Wenjin J.\nZheng), and NIA R56AG069880 (Dr. Hua Xu).\n9 Conflict of Interest Statement\nDr. Hua Xu and the University of Texas Health\nScience Center at Houston have research financial\ninterest at Melax Technologies Inc.\nReferences\nAlaa A Abd-Alrazaq, Mohannad Alajlani, Nashva Ali,\nKerstin Denecke, Bridgette M Bewick, and Mowafa\nHouseh. 2021. Perceptions and opinions of patients\n294\nabout mental health chatbots: Scoping review. Jour-\nnal of medical Internet research, 23(1):e17828.\nMohammad Rafayet Ali, Seyedeh Zahra Razavi, Raina\nLangevin, Abdullah Al Mamun, Benjamin Kane,\nReza Rawassizadeh, Lenhart K Schubert, and Ehsan\nHoque. 2020. A virtual conversational agent for\nteens with autism spectrum disorder: Experimental\nresults and design lessons. In Proceedings of the 20th\nACM International Conference on Intelligent Virtual\nAgents, pages 1–8.\nKatie Elson Anderson. 2015. Ask me anything: what is\nreddit? Library Hi Tech News.\nJason Baumgartner, Savvas Zannettou, Brian Keegan,\nMegan Squire, and Jeremy Blackburn. 2020. The\npushshift reddit dataset. In Proceedings of the inter-\nnational AAAI conference on web and social media,\nvolume 14, pages 830–839.\nTimothy W Bickmore, Suzanne E Mitchell, Brian W\nJack, Michael K Paasche-Orlow, Laura M Pfeifer,\nand Julie O’Donnell. 2010a. Response to a relational\nagent by hospital patients with depressive symptoms.\nInteracting with computers, 22(4):289–298.\nTimothy W Bickmore, Kathryn Puskar, Elizabeth A\nSchlenk, Laura M Pfeifer, and Susan M Sereika.\n2010b. Maintaining reality: Relational agents for an-\ntipsychotic medication adherence. Interacting with\nComputers, 22(4):276–288.\nLeonardo Campillos-Llanos, Catherine Thomas, Eric\nBilinski, Pierre Zweigenbaum, and Sophie Rosset.\n2020. Designing a virtual patient dialogue system\nbased on terminology-rich resources: Challenges\nand evaluation. Natural Language Engineering,\n26(2):183–220.\nAvisha Das and Rakesh M. Verma. 2020. Can machines\ntell stories? a comparative study of deep neural lan-\nguage models and metrics. IEEE Access, 8:181258–\n181292.\nMunmun De Choudhury and Sushovan De. 2014. Men-\ntal health discourse on reddit: Self-disclosure, so-\ncial support, and anonymity. In Eighth international\nAAAI conference on weblogs and social media.\nMauro De Gennaro, Eva G Krumhuber, and Gale Lucas.\n2020. Effectiveness of an empathic chatbot in com-\nbating adverse effects of social exclusion on mood.\nFrontiers in psychology, 10:3061.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nJingcheng Du, Yaoyun Zhang, Jianhong Luo, Yuxi Jia,\nQiang Wei, Cui Tao, and Hua Xu. 2018. Extracting\npsychiatric stressors for suicide from social media\nusing deep learning. BMC medical informatics and\ndecision making, 18(2):77–87.\nItika Gupta, Barbara Di Eugenio, Brian Ziebart,\nAiswarya Baiju, Bing Liu, Ben Gerber, Lisa Sharp,\nNadia Nabulsi, and Mary Smart. 2020. Human-\nhuman health coaching via text messages: Corpus,\nannotation, and analysis. In Proceedings of the 21th\nAnnual Meeting of the Special Interest Group on\nDiscourse and Dialogue, pages 246–256, 1st virtual\nmeeting. Association for Computational Linguistics.\nKeith Harrigian, Carlos Aguirre, and Mark Dredze.\n2021. On the state of social media data for men-\ntal health research. In Proceedings of the Seventh\nWorkshop on Computational Linguistics and Clinical\nPsychology: Improving Access, pages 15–24, Online.\nAssociation for Computational Linguistics.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\nYejin Choi. 2019. The curious case of neural text\ndegeneration. arXiv preprint arXiv:1904.09751.\nLishan Huang, Zheng Ye, Jinghui Qin, Liang Lin, and\nXiaodan Liang. 2020. GRADE: Automatic graph-\nenhanced coherence metric for evaluating open-\ndomain dialogue systems. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 9230–9240,\nOnline. Association for Computational Linguistics.\nAdria Mallol-Ragolta, Ziping Zhao, Lukas Stappen,\nNicholas Cummins, and Björn Schuller. 2019. A\nhierarchical attention network-based approach for\ndepression detection from transcribed clinical inter-\nviews.\nAdam S Miner, Nigam Shah, Kim D Bullock, Bruce A\nArnow, Jeremy Bailenson, and Jeff Hancock. 2019.\nKey considerations for incorporating conversational\nai in psychotherapy. Frontiers in psychiatry, page\n746.\nSeyed Mahed Mousavi, Alessandra Cervone, Morena\nDanieli, and Giuseppe Riccardi. 2021. Would you\nlike to tell me more? generating a corpus of psy-\nchotherapy dialogues. In Proceedings of the Second\nWorkshop on Natural Language Processing for Med-\nical Conversations, pages 1–9, Online. Association\nfor Computational Linguistics.\nSergei Nirenburg, Marjorie McShane, Stephen Beale,\nand Bruce Jarrell. 2008. Adaptivity in a multi-\nagent clinical simulation system. In Proceedings of\nAKRR’08, International and Interdisciplinary Con-\nference on Adaptive Knowledge Representation and\nReasoning, pages 17–19.\nMoisés R Pacheco-Lorenzo, Sonia M Valladares-\nRodríguez, Luis E Anido-Rifón, and Manuel J\nFernández-Iglesias. 2021. Smart conversational\nagents for the detection of neuropsychiatric disor-\nders: A systematic review. Journal of Biomedical\nInformatics, 113:103632.\nVerónica Pérez-Rosas, Xuetong Sun, Christy Li, Yuchen\nWang, Kenneth Resnicow, and Rada Mihalcea. 2018.\nAnalyzing the quality of counseling conversations:\n295\nthe tell-tale signs of high-quality counseling. In Pro-\nceedings of the Eleventh International Conference on\nLanguage Resources and Evaluation (LREC 2018),\nMiyazaki, Japan. European Language Resources As-\nsociation (ELRA).\nKay T Pham, Amir Nabizadeh, and Salih Selek. 2022.\nArtificial intelligence and chatbots in psychiatry. Psy-\nchiatric Quarterly, pages 1–5.\nAlec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nHannah Rashkin, Eric Michael Smith, Margaret Li, and\nY-Lan Boureau. 2019. Towards empathetic open-\ndomain conversation models: A new benchmark and\ndataset. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguistics,\npages 5370–5381, Florence, Italy. Association for\nComputational Linguistics.\nJoão Sedoc, Daphne Ippolito, Arun Kirubarajan, Jai\nThirani, Lyle Ungar, and Chris Callison-Burch. 2019.\nChatEval: A tool for chatbot evaluation. In Proceed-\nings of the 2019 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics (Demonstrations), pages 60–65, Minneapo-\nlis, Minnesota. Association for Computational Lin-\nguistics.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2015. Neural machine translation of rare words with\nsubword units. arXiv preprint arXiv:1508.07909.\nAshish Sharma, Adam Miner, David Atkins, and Tim Al-\nthoff. 2020. A computational approach to understand-\ning empathy expressed in text-based mental health\nsupport. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 5263–5276, Online. Association for\nComputational Linguistics.\nEva Sharma and Munmun De Choudhury. 2018. Men-\ntal health support and its relationship to linguistic\naccommodation in online communities. In Proceed-\nings of the 2018 CHI conference on human factors in\ncomputing systems, pages 1–13.\nVibhor Sharma, Monika Goyal, and Drishti Malik. 2017.\nAn intelligent behaviour shown by chatbot system.\nInternational Journal of New Technology and Re-\nsearch, 3(4):263312.\nMyrthe L Tielman, Mark A Neerincx, Rafael Bidarra,\nBen Kybartas, and Willem-Paul Brinkman. 2017a.\nA therapy system for post-traumatic stress disorder\nusing a virtual agent and virtual storytelling to re-\nconstruct traumatic memories. Journal of medical\nsystems, 41(8):1–10.\nMyrthe L Tielman, Mark A Neerincx, Marieke\nVan Meggelen, Ingmar Franken, and Willem-Paul\nBrinkman. 2017b. How should a virtual agent present\npsychoeducation? influence of verbal and textual pre-\nsentation on adherence. Technology and Health Care,\n25(6):1081–1096.\nYin-Te Tsai and Wei-An Lin. 2018. Design of an intel-\nligent cognition assistant for people with cognitive\nimpairment. In 2018 IEEE 20th International Con-\nference on High Performance Computing and Com-\nmunications; IEEE 16th International Conference on\nSmart City; IEEE 4th International Conference on\nData Science and Systems (HPCC/SmartCity/DSS),\npages 1207–1212. IEEE.\nAditya Nrusimha Vaidyam, Hannah Wisniewski,\nJohn David Halamka, Matcheri S Kashavan, and\nJohn Blake Torous. 2019. Chatbots and conversa-\ntional agents in mental health: a review of the psychi-\natric landscape. The Canadian Journal of Psychiatry,\n64(7):456–464.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in neural information pro-\ncessing systems, pages 5998–6008.\nThomas Wolf, Victor Sanh, Julien Chaumond, and\nClement Delangue. 2019. Transfertransfo: A transfer\nlearning approach for neural network based conver-\nsational agents. CoRR, abs/1901.08149.\nYaoyun Zhang, Olivia R Zhang, Rui Li, Aaron Flores,\nSalih Selek, Xiang Y Zhang, and Hua Xu. 2019. Psy-\nchiatric stressor recognition from clinical notes to\nreveal association with suicide. Health informatics\njournal, 25(4):1846–1862.\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen,\nChris Brockett, Xiang Gao, Jianfeng Gao, Jingjing\nLiu, and Bill Dolan. 2020. DIALOGPT : Large-scale\ngenerative pre-training for conversational response\ngeneration. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics:\nSystem Demonstrations, pages 270–278, Online. As-\nsociation for Computational Linguistics.\nA Appendix\n296\nRole Response\nHumanHello! I have been feeling very down lately.\nSystemWas there anything you do for fun or anything\nyou enjoy doing or interests hobbies.\nHuman\nYeah, like diving. We actually me and Lisa we\nwent to Hawaii a couple weeks ago.\nI guess she wanted to pull me out of this funk.\nShe saw it coming and wanted to do\nsomething that we both love.\nSystemDid you feel better.\nHuman\nNo. No. I just I don’t know. This time it just didn’t help.\nAnd that really scares me. Couldn’t even I didn’t even\nend up actually diving while I was there. Stayed on the boat.\nSystem\nMaybe you need to find something new to do to bring you joy.\nMaybe try some new activities or maybe take on a new hobby.\nDo you have any ideas?\nTable 3: Conversation with a DialoGPT trained through\nTransfer Learning on Video transcripts to assessdepres-\nsion\nRole Response\nHumanHi. I wanted to talk about something .\nSystemSure! What would you like to talk about?\nHuman\nI experienced some recent losses...\nthe loss of my mother about a year ago,\njust over a year ago.. then the loss of my partner in September.\nMy father also moved to a home. So, really, uh,\nan enormous amount of loss to cope with, to have to deal with in,\nin a relatively short time.\nSystemThat sounds very difficult. Can you tell me more?\nHumanMy mother passed away so quickly and unexpectedly...\nI cannot deal with it\nSystem\nI’m so sorry to hear that. Losing a loved one\nis never easy, no matter how long they’ve been gone.\nYou may find it helpful to talk to someone about\nhow you’re feeling, or to write down your thoughts and feelings.\nThere are also support groups\navailable for people who have lost a loved one.\nDon’t hesitate to reach out for help if you need it.\nTable 4: Conversation with a DialoGPT trained through\nTransfer Learning on Video transcripts to counselloss\nin family\nFigure 4: Sample Questionnaire\n297\nRole Response\nHuman Hi! I am here seeking help with my past history with various substances and alcohol.\nI drink sometimes. Alcohol, beer, vodka. Personal favorite is rum.\nSystem Okay. About. . . How often when you say you drink?\nHuman I mean, I used to drink uh. . . more often. Uh. . .\nLike, you know, three times a week, when I’ve tried to cut back.\nSystem How about marijuana? Have you ever used marijuana?\nHuman Before. I mean I’ve. . . I’ve tried. It wasn’t really my thing though.\nthe last time I used marijuana was couple of years ago...\nSystem Okay. How about other drugs?\nHuman No not much.\nSystem Okay. So marijuana and alcohol are the only two substances you’ve tried?\nHuman Yes\nSystem\nAll right. Well, from what you’ve said it sounds like you’re trying to cut back on your drinking.\nThat’s really good. You’re taking steps to improve your health and that’s important.\nAs far as marijuana goes, it sounds like you’ve tried it before and it wasn’t really your thing.\nThat’s okay. Not everyone likes marijuana.\nThere are plenty of other things to try out there. If you ever want to try marijuana again,\nthere are plenty of ways to do so safely.But if you’re not interested, that’s perfectly fine too.\nThanks for talking with me.\nTable 5: Conversation with a DialoGPT trained through Transfer Learning on Video transcripts to counselOpioid\nUse Disorder. This is a negative example.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.777320146560669
    },
    {
      "name": "Dialog box",
      "score": 0.7743978500366211
    },
    {
      "name": "Generative grammar",
      "score": 0.7146317362785339
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.6152338981628418
    },
    {
      "name": "Dialog system",
      "score": 0.5990408062934875
    },
    {
      "name": "Transformer",
      "score": 0.5558800101280212
    },
    {
      "name": "Generative model",
      "score": 0.552984356880188
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5432894825935364
    },
    {
      "name": "Transfer of learning",
      "score": 0.503046452999115
    },
    {
      "name": "Natural language processing",
      "score": 0.4989304542541504
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.42033514380455017
    },
    {
      "name": "Machine learning",
      "score": 0.3218395709991455
    },
    {
      "name": "World Wide Web",
      "score": 0.07934185862541199
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I919571938",
      "name": "The University of Texas Health Science Center at Houston",
      "country": "US"
    }
  ],
  "cited_by": 41
}