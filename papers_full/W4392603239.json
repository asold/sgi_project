{
  "title": "Detection of Suicidality Through Privacy-Preserving Large Language Models",
  "url": "https://openalex.org/W4392603239",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3205279857",
      "name": "Isabella Catharina Wiest",
      "affiliations": [
        "University Medical Centre Mannheim",
        "University Hospital Heidelberg",
        "Fresenius (Germany)",
        "Heidelberg University"
      ]
    },
    {
      "id": "https://openalex.org/A5022714367",
      "name": "Falk Gerrik Verhees",
      "affiliations": [
        "University Hospital Carl Gustav Carus",
        "TU Dresden"
      ]
    },
    {
      "id": "https://openalex.org/A2789987764",
      "name": "Dyke Ferber",
      "affiliations": [
        "National Center for Tumor Diseases",
        "University Hospital Heidelberg",
        "Heidelberg University",
        "Fresenius (Germany)"
      ]
    },
    {
      "id": "https://openalex.org/A2128231539",
      "name": "Jiefu Zhu",
      "affiliations": [
        "Fresenius (Germany)"
      ]
    },
    {
      "id": "https://openalex.org/A1935935271",
      "name": "Michael Bauer",
      "affiliations": [
        "TU Dresden",
        "University Hospital Carl Gustav Carus"
      ]
    },
    {
      "id": "https://openalex.org/A2148093476",
      "name": "Ute Lewitzka",
      "affiliations": [
        "TU Dresden",
        "University Hospital Carl Gustav Carus"
      ]
    },
    {
      "id": "https://openalex.org/A1846998094",
      "name": "Andrea Pfennig",
      "affiliations": [
        "University Hospital Carl Gustav Carus",
        "TU Dresden"
      ]
    },
    {
      "id": "https://openalex.org/A2085936581",
      "name": "Pavol Mikolas",
      "affiliations": [
        "TU Dresden",
        "University Hospital Carl Gustav Carus"
      ]
    },
    {
      "id": "https://openalex.org/A2056217728",
      "name": "Jakob Nikolas Kather",
      "affiliations": [
        "National Center for Tumor Diseases",
        "Heidelberg University",
        "Fresenius (Germany)",
        "University Hospital Heidelberg"
      ]
    },
    {
      "id": "https://openalex.org/A3205279857",
      "name": "Isabella Catharina Wiest",
      "affiliations": [
        "Heidelberg University",
        "University Medical Centre Mannheim",
        "TU Dresden",
        "University Hospital Heidelberg"
      ]
    },
    {
      "id": "https://openalex.org/A5022714367",
      "name": "Falk Gerrik Verhees",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2789987764",
      "name": "Dyke Ferber",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2128231539",
      "name": "Jiefu Zhu",
      "affiliations": [
        "National Center for Tumor Diseases",
        "University Hospital Heidelberg",
        "Heidelberg University",
        "TU Dresden"
      ]
    },
    {
      "id": "https://openalex.org/A1935935271",
      "name": "Michael Bauer",
      "affiliations": [
        "TU Dresden",
        "University Hospital Carl Gustav Carus"
      ]
    },
    {
      "id": "https://openalex.org/A2148093476",
      "name": "Ute Lewitzka",
      "affiliations": [
        "University Hospital Carl Gustav Carus",
        "TU Dresden"
      ]
    },
    {
      "id": "https://openalex.org/A1846998094",
      "name": "Andrea Pfennig",
      "affiliations": [
        "TU Dresden",
        "University Hospital Carl Gustav Carus"
      ]
    },
    {
      "id": "https://openalex.org/A2085936581",
      "name": "Pavol Mikolas",
      "affiliations": [
        "TU Dresden",
        "University Hospital Carl Gustav Carus"
      ]
    },
    {
      "id": "https://openalex.org/A2056217728",
      "name": "Jakob Nikolas Kather",
      "affiliations": [
        "Heidelberg University",
        "Städtisches Klinikum Dresden",
        "National Center for Tumor Diseases",
        "University Hospital Heidelberg",
        "TU Dresden",
        "University Hospital Carl Gustav Carus",
        "Hochschule für Technik und Wirtschaft Dresden – University of Applied Sciences"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4390694374",
    "https://openalex.org/W3108636332",
    "https://openalex.org/W4387500346",
    "https://openalex.org/W4389490684",
    "https://openalex.org/W3091781426",
    "https://openalex.org/W4313596849",
    "https://openalex.org/W2946938477",
    "https://openalex.org/W2550366730",
    "https://openalex.org/W4389523980",
    "https://openalex.org/W2124136543",
    "https://openalex.org/W3092071453",
    "https://openalex.org/W4293103192",
    "https://openalex.org/W4367186868",
    "https://openalex.org/W4387241391"
  ],
  "abstract": "Abstract Importance Attempts to use Artificial Intelligence (AI) in psychiatric disorders show moderate success, high-lighting the potential of incorporating information from clinical assessments to improve the models. The study focuses on using Large Language Models (LLMs) to manage unstructured medical text, particularly for suicide risk detection in psychiatric care. Objective The study aims to extract information about suicidality status from the admission notes of electronic health records (EHR) using privacy-sensitive, locally hosted LLMs, specifically evaluating the efficacy of Llama-2 models. Main Outcomes and Measures The study compares the performance of several variants of the open source LLM Llama-2 in extracting suicidality status from psychiatric reports against a ground truth defined by human experts, assessing accuracy, sensitivity, specificity, and F1 score across different prompting strategies. Results A German fine-tuned Llama-2 model showed the highest accuracy (87.5%), sensitivity (83%) and specificity (91.8%) in identifying suicidality, with significant improvements in sensitivity and specificity across various prompt designs. Conclusions and Relevance The study demonstrates the capability of LLMs, particularly Llama-2, in accurately extracting the information on suicidality from psychiatric records while preserving data-privacy. This suggests their application in surveillance systems for psychiatric emergencies and improving the clinical management of suicidality by improving systematic quality control and research. Key Points Question Can large language models (LLMs) accurately extract information on suicidality from electronic health records (EHR)? Findings In this analysis of 100 psychiatric admission notes using Llama-2 models, the German fine-tuned model (Emgerman) demonstrated the highest accuracy (87.5%), sensitivity (83%) and specificity (91.8%) in identifying suicidality, indicating the models’ effectiveness in on-site processing of clinical documentation for suicide risk detection. Meaning The study highlights the effectiveness of LLMs, particularly Llama-2, in accurately extracting the information on suicidality from psychiatric records, while preserving data privacy. It recommends further evaluating these models to integrate them into clinical management systems to improve detection of psychiatric emergencies and enhance systematic quality control and research in mental health care.",
  "full_text": "1 \nDetection of Suicidality Through  \nPrivacy-Preserving Large Language Models \n \nIsabella Catharina Wiest* (1,2), Falk Gerrik Verhees* (6),  \nDyke Ferber (1, 3, 4), Jiefu Zhu (1), Michael Bauer (6),  \nUte Lewitzka (6), Andrea Pfennig (6),  \nPavol Mikolas** (6), Jakob Nikolas Kather** (1, 3, 4, 5 +) \n \n1. Else Kroener Fresenius Center for Digital Health, Technical University Dresden, Dresden, \nGermany \n2. Department of Medicine II, Medical Faculty Mannheim, Heidelberg University, Mannheim, \nGermany \n3. National Center for Tumor Diseases (NCT), Heidelberg University Hospital, Heidelberg, \nGermany \n4. Department of Medical Oncology, Heidelberg University Hospital, Heidelberg, Germany \n5. Department of Medicine I, University Hospital Dresden, Dresden, Germany \n6. Department of Psychiatry and P sychotherapy, Carl Gustav Carus University Hospital, \nTechnische Universität Dresden, Germany \n \n* These two authors contributed equally as first authors \n** These authors contributed equally as last authors \n+ Corresponding author: jakob-nikolas.kather@alumni.dkfz.de \n \nJakob Nikolas Kather, MD, MSc \nProfessor of Clinical Artificial Intelligence \nElse Kröner Fresenius Center for Digital Health \nTechnische Universität Dresden \nDE – 01062 Dresden \nPhone: +49 351 458-7558 \nFax: +49 351 458 7236 \nMail: jakob_nikolas.kather@tu-dresden.de  \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n2 \nConflicts of Interest \nJNK declares consulting services for Owkin, France, DoMore Diagnostics, Norway, Panakeia, \nUK, Scailyte, Switzerland, Cancilico, Germany, Mindpeak, Germany, MultiplexDx, Slovakia, and \nHistofy, UK; furthermore he holds shares in StratifAI GmbH, Germany, has received a research \ngrant by GSK, and has received honoraria by AstraZeneca, Bayer, Eisai, Janssen, MSD, BMS, \nRoche, Pfizer and Fresenius. UL participated in advisory boards and received honoraria by \nJanssen Cilag GmbH. \nAuthor Contributions \nFGV, PM and ICW conceptualized the study and developed the methodology in close coordina-\ntion with JNK. ICW developed the scripts and ran the experiments. FGV, ICW, MB, AP, UL, and \nPM were writing and reviewing the initial manuscript. All authors were refining the draft. PM, UL, \nAP, MB and JNK provided supervision and resources for the project.  \nFunding \nJNK is supported by the German Federal Ministry of Health (DEEP LIVER, ZMVI1-2520DAT111), \nthe German Cancer Aid (DECADE, 70 115166), the German Federal Ministry of Education and \nResearch (PEARL, 01KD2104C; CAMINO, 01EO2101; SWAG, 01KD2215A; TRANSFORM \nLIVER, 031L0312A; TANGERINE, 01KT2302 through ERA -NET Transcan), the German Aca-\ndemic Exchange Service (SECAI, 57616814), the Germ an Federal Joint Committee (Trans-\nplantKI, 01VSF21048) the European Union’s Horizon Europe and innovation programme \n(ODELIA, 101057091; GENIAL, 101096312), the European Research Council (ERC; NADIR, \n101114631) and the National Institute for Health and Care Research (NIHR, NIHR213331) Leeds \nBiomedical Research Centre. The views expressed are those of the author(s) and not necessarily \nthose of the NHS, the NIHR or the Department of Health and Social Care. FGV was supported \nby the Federal Ministry of Education and Research (PATH, 16KISA100k). PM and AP were sup-\nported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) grant \nnumber GRK2773/1- 454245598. This work was funded by the European Union. Views and opin-\nions expressed are however those  of the author(s) only and do not necessarily reflect those of \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n3 \nthe European Union. Neither the European Union nor the granting authority can be held respon-\nsible for them. \n  \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n4 \nKey Points \n \nQuestion \nCan large language models (LLMs) accurately extract information on suicidality from electronic \nhealth records (EHR)? \n \nFindings  \nIn this analysis of 100 psychiatric admission notes using Llama-2 models, the German fine-tuned \nmodel (Emgerman) demonstrated the highest accuracy (87.5%), sensitivity (83%) and specificity \n(91.8%) in identifying suicidality, indicating the models' effectiveness in on-site processing of clin-\nical documentation for suicide risk detection. \n \nMeaning \nThe study highlights the effectiveness of LLMs, particularly Llama-2, in accurately extracting the \ninformation on suicidality from psychiatric records, while preserving data privacy. It recommends \nfurther evaluating these models to integra te them into clinical management systems to improve \ndetection of psychiatric emergencies and enhance systematic quality control and research in \nmental health care.\n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n5 \nAbstract \nImportance \nAttempts to use Artificial Intelligence (AI) in psychiatric disorders show moderate success, high-\nlighting the potential of incorporating information from clinical assessments to improve the models. \nThe study focuses on using Large Language Models (LLMs) to manage unstructured medical \ntext, particularly for suicide risk detection in psychiatric care. \n \nObjective  \nThe study aims to extract information about suicidality status from the admission notes of elec-\ntronic health records (EHR) using privacy -sensitive, locally hosted LLMs, specifically evaluating \nthe efficacy of Llama-2 models. \n \nMain Outcomes and Measures  \nThe study compares the performance of several variants of the open source LLM Llama -2 in \nextracting suicidality status from psychiatric reports against a ground truth defined by human ex-\nperts, assessing accuracy, sensitivity, specificity, and F1 score across different prompting strate-\ngies. \n \nResults  \nA German fine-tuned Llama-2 model showed the highest accuracy (87.5%), sensitivity (83%) and \nspecificity (91.8%) in identifying suicidality, with significant improvements in sensitivity and spec-\nificity across various prompt designs.  \n \nConclusions and Relevance \nThe study demonstrates the capability of LLMs, particularly Llama-2, in accurately extracting the \ninformation on suicidality from psychiatric records while preserving dat a-privacy. This suggests \ntheir application in surveillance systems for psychiatric emergencies and improving the clinical \nmanagement of suicidality by improving systematic quality control and research.  \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n6 \nIntroduction \nAttempts to apply artificial intelligenc e (AI) and machine learning to psychiatric disorders have \nyielded moderate accuracies due to small effect sizes and high heterogeneity. 1 Nevertheless, \nimproving prediction models by incorporating clinical assessments seems to enable clinical appli-\ncations.2 However, a significant challenge arises from the nature of clinical data: Medical free text, \nespecially in psychiatry, encapsulates a wealth of information about a patient's pathology and \nwell-being by unveiling its structure of thinking and feeling. This  information is vital but often re-\nmains inaccessible for scalable analysis due to its unstructured nature. The inability to effectively \nanalyze this text on a large scale potentially leads to missed opportunities in clinical decision \nmaking and research. \nRecent studies have emphasized the significant impact of advanced technology on managing \nunstructured medical data3. Specifically, the use of large language models (LLMs) has garnered \nsignificant attention.4 Unlike previously used methods of natural language processing that require \ndecomposing the text and substantial feature engineering, 5 LLMs are AI models primarily de-\nsigned to understand and generate text.6 They are trained on vast amounts of text data, allowing \nthem to learn the statistical patterns and relationships within language.7  \nAccounting for nearly half of all emergency psychiatric admissions, 8 suicide is one of the most \ntragic complications of psychiatric care and is often preventable. Sustained efforts can lead to \nmajor reductions in in-patient suicides, from 4.2 to 0.74 per 100,000 admissions. 9 Here, we hy-\npothesize that automated tools could help identify in -patient suicide risk using underexploited \nclinical records. Moreover, beyond clinical application, LLM might automatically identify and ex-\ntract suicidality from EHR to enhance research.    \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n7 \nMethods \nWe systematically extracted n=100 randomly selected text -based admission notes of inpatients \ntreated in and discharged from the acute psychiatric ward of the Department of Psychiatry and \nPsychotherapy at the University Hospital Carl Gustav Carus Dresden between 1 January and 31 \nDecember 2023, representing 54 female and 46 male patie nts with an average age of 50 years \n(standard deviation 23.8 years) ranging from 18 to 96 years of age. The most prevalent ICD -10 \nmain diagnoses were major depressive disorder (21%), psychotic disorders (20%) and dementia \n(17%), borderline personality disorder (9%), schizoaffective disorder (8%), alcohol use disorder \n(8%) and others (17%). We ensured data privacy by installing Llama -2 via the llama.cpp frame-\nwork on a local hospital computer. We extracted the suicidality status from psychiatric admission \nnotes using three different Llama-2-based models: the standard Llama-2 70b chat model adapted \nto allow deployment on low -resource consumer hardware,10 as well as two versions of Llama -2 \nthat were specifically fine-tuned for the German language (“Sauerkraut”11 and “Emgerman”12). We \ncompared the models’ results to a ground truth consensus which was established by a resident \n(FGV) and a consultant psychiatrist (PM) as a binary variable (suicidal / not suicidal). Suicidality \nwas defined as either suicidal thoughts, ideation, plans or attempt by admission.  \nWe applied a step-by-step approach to prompt engineering, as prompt engineering can substan-\ntially improve the performance of LLMs.13 The first prompt simply asked about suicidality in reports \n(P0). In the second prompt, we added fictional examples and explanations. We started with one \nexample (P1) and added one example (P2) at a time with three examples as a maximum (P3). \n(See prompts in Supplementary Table 1). After achieving improved performance, we incorpo-\nrated a chain-of-thought approach, where the model processes its own output one more time, for \nP3 (P4). To obtain reliable estimates, we used bootstrapping, a statistical resampling technique, \nwith 10.000 iterations.  \nAll research procedures were conducted in accordance with the Declaration of Helsinki. Ethics \napproval was granted by the ethics committee of Technical University Dresden, reference number \nBO-EK-400092023. All source co des are available at \nhttps://github.com/I2C9W/LLM4Psych/tree/v0.1.0. \n \n  \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n8 \nResults \nLlama-2 extracted suicidality from psychiatric reports with high accuracy across all five prompt \ndesigns and all three models tested. The highest overall accuracy was achieved by one of the \ngerman fine-tuned Llama-2 models (“Emgerman”), which correctly identified suicidality status in \n87.5% of the reports. With a sensitivity of 83% and a specificity of 92%, it demonstrated the high-\nest balanced accuracy of all models (87.4%) (Figure 2A).  \nThe confusion matrix ( Figure 2B) also highlights areas for model improvement, particularly in \nreducing false negatives. \nTo improve the performance, we designed the prompts and developed five different prompting \nstrategies that were tested for all three models (Figure 2C). The simplest prompt, which contained \nonly a “system prompt” framing the model in its role (“You are an attentive medical assistant with \nspecialized knowledge in psychiatry (...)“, one report at a time and the ultimate question of interest \n(“Is the patient suicidal? Answer yes or no. (...)”), yielded the highest sensitivity in the German \nfine-tuned Llama-2 model “Sauerkraut” (sensitivity: 87.5%, specificity: 61.2%, balanced accuracy: \n74.4%). It was immediately followed by the standard English Llama-2 chat model, with a sensitivity \nof 85.1%, specificity of 63% and a balanced accuracy of 74.1%. The Emgerman model had a \nworse sensitivity of 42.6%, but the highest specificity of 98.8%. Not all models improved when \nexamples were added to the prompt, allowing for in-context-learning. The Emgerman model im-\nproved substantially by adding more examples, with the lowest balanced accuracy in the prompt \nwith no examples (66.2%) and the highest balanced accuracy in the prompt with three examples \ngiven (87.4%). The English model was robust, showing similar balanced accuracies for prompts \nwith none, one, two or three examples (P0: 74.1%, P1: 73.3%, P2: 79.3%, P3: 80.3%). The “Sau-\nerkraut” model improved with adding examples but achieved its maximum performance with two \nexamples in the prompt. The use of the chain-of-thought approach did not improve performance \n(Sensitivities: “Emgerman” P4 17%,  \n“English” P4 63.8%, “Sauerkraut” P4 80.9%. Specificities:  “Emgerman” P4 75.5%,  \n“English” P4 63.3%, “Sauerkr aut” P4 77.6%. ( Table 1)). In fact, all models deteriorated, except \nfor the “Sauerkraut” model, which was not affected negatively by this approach. \n  \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n9 \nDiscussion \nWe show that LLMs demonstrate remarkable efficacy in identifying and extracting references to \nsuicidality from psychiatric reports. Its performance, in terms of both sensitivity and specificity, \nwas notable and improved progressively with the number of examples provided in the prompt. \nThese findings suggest a significant advancement in the field, hi ghlighting the potential of LLMs \nto revolutionize the way psychiatric medical text is analyzed. The real-life clinical data taken from \nan acute care ward in a supra-maximum care facility in a German urban center was processed at \nthe “edge” - with no need f or upload to commercial servers or a data -processing cloud - by an \nopen-source model on local servers. This enables a privacy-sensitive data protection strategy in \na closed loop, that alleviates concerns about data leaving the care provider’s control. \nThe good performance levels ( Figure 2) even in a (medical) domain in which the LLM was not \nfine-tuned, suggest even greater opportunities with further optimization for mental health, e.g. in \ndealing with physician-level linguistic idiosyncrasies or abbreviations.14 For a clinical application \nsuch as suicide risk detection, where false negatives are likely to lead to detrimental outcomes, \nsensitivity should approach 100%, even at the cost of detecting more false positives. The final \nrisk assessment remains in the judgment of the experienced clinician and further research needs \nto elucidate risks and challenges. On the other hand, in the case of data extraction for research \npurposes, correctly identifying 80% of cases (i.e. classification accuracy of 80%) might be  ade-\nquate to capture a representative cohort. In comparison, randomized clinical trials of major de-\npression may include only 22% of cases from real-life clinical cohorts that meet the eligibility cri-\nteria.15 \nSuicide risk was considered a binary parameter. Future research should concentrate on a more \ndetailed outcome that differentiates between overall suicide risk and acute high risk. 16 Addition-\nally, studies should apply extensive ground truth labeling,17 include open cases that have not been \nproofread and evaluate more comprehensive prompt engineering strategies. However, our results \nsuggest that, at least in the case of Llama -2, more complex prompting with a chain -of-thought \napproach might degrade performance. For some tasks, simple example prompting that requires \nvery few computing resources may be more suitable. Nevertheless, reproducibility should be \ntested on a larger external validation sample. Although privacy concerns have been addressed, \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n10 \nit is important to note that every LLM approach inherits ethic al issues related to bias, trust, au-\nthorship, and equitability. 18 Expert guidelines for development of LLMs for medical purposes \nshould be carefully considered.19  \nConclusion \nWe provide a proof-of-concept analysis for automated extraction of in-patient suicidality from EHR \nusing LLM. Possible applications include early warning and surveillance tools for psychiatric \nemergencies, preventing information transfer failures, quality assurance and last but not least \nevaluation of psychiatric symptoms on large clinical “real-world” samples.   \n  \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n11 \nFigures \n \nFigure 1 - Experimental Setup. A displays the information extraction pipeline. The psychiatry \nreports (n=100) were transferred to a csv table. Our pipeline then iterates over all reports with the \npredefined prompt and outputs a JavaScript Object Notation -File (JSON) file with all Large Lan-\nguage Model (LLM) outputs (PRED). The relevant classes (suicidality present: yes or no) were \nthen extracted from the LLM output, which was more verbose in some cases. These outputs were \nthen transferred to a pandas dataframe and automatically compared to the expert-based ground \ntruth (GT). B depicts the initial prompting strategy. One prompt and one report were given to the \nmodel at the same time. Every prompt contained a system prompt with general instructions and \na specific question to the report (Instruction) C shows the chain of thought approach: The psychi-\natry report with our prompt was fed into the LLM, which generated a first output. With a second \nprompt and a predefined answering grammar, the model was fed its own output and again forced \nto generate a certain, json based output structure. This final output then underwent performance \nanalysis. Icon Source: Midjourney. \n \n  \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n12 \n \nFigure 2 - Performance of german-language fine-tuned Llama-2 model. A depicts Sensitivity, \nSpecificity and balanced Accuracy score for five different prompting strategies. With P0, the model \nwas simply asked to provide the answer if suicidality was present from the report, P1, P2 and P3 \nprovided one, two or three examples to the model. P4 applied a chain-of- thought approach, where \nthe model was asked twice, with the first model output as input for the second run. B The confu-\nsion matrix represents the performance of the LLM indicating the presence of suicidality based \non the examined admission notes (n=100) with a sensitivity of 83% as well as specificity of 92% \nfor P3, a prompt that included three examples. C The bar chart shows the balanced accuracies \nfor all models and prompt engineering attempts. Error bars show the 95% c onfidence interval of \nthe bootstrapped samples. \n \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n13 \nTable 1 - Performance Metrics of all three tested models (“Emgerman”, “Sauerkraut”, “English”) with the five prompt variations (P0-\nP4). All results have been obtained by 10.000 fold bootstrapping, therefore means and standard deviations are given.  \nModel \nAccuracy \nMean \nAccuracy \nStd \nPPV  \nMean \nPPV  \nStd \nSensitivity \nMean \nSensitivity \nStd \nSpecificity \nMean \nSpecificity \nStd \nNPV  \nMean \nNPV  \nStd \nF1 Score \nMean \nF1 Score \nStd \nBalanced \nAccuracy \nMean \nBalanced \nAccuracy \nStd \nEmgerman P0 0.667 0.048 0.8 0.082 0.426 0.073 0.898 0.044 0.62 0.057 0.552 0.072 0.662 0.042 \nEmgerman P1 0.793 0.041 0.815 0.059 0.746 0.064 0.837 0.053 0.775 0.058 0.777 0.049 0.792 0.041 \nEmgerman P2 0.812 0.04 0.773 0.058 0.872 0.049 0.754 0.062 0.86 0.053 0.818 0.042 0.813 0.039 \nEmgerman P3 0.875 0.034 0.907 0.044 0.83 0.055 0.918 0.039 0.849 0.049 0.865 0.039 0.874 0.034 \nEmgerman P4 0.468 0.051 0.4 0.112 0.17 0.055 0.755 0.062 0.486 0.057 0.236 0.069 0.463 0.041 \nEnglish P0 0.741 0.046 0.7 0.061 0.851 0.052 0.629 0.072 0.805 0.067 0.767 0.047 0.74 0.045 \nEnglish P1 0.731 0.045 0.703 0.062 0.792 0.059 0.672 0.067 0.767 0.066 0.743 0.049 0.732 0.045 \nEnglish P2 0.788 0.048 0.731 0.069 0.881 0.055 0.703 0.074 0.866 0.062 0.797 0.052 0.792 0.046 \nEnglish P3 0.805 0.04 0.854 0.055 0.73 0.065 0.878 0.047 0.768 0.057 0.785 0.048 0.804 0.04 \nEnglish P4 0.635 0.049 0.625 0.07 0.638 0.071 0.633 0.068 0.646 0.069 0.629 0.058 0.636 0.049 \nSauerkraut P0 0.742 0.044 0.689 0.059 0.875 0.048 0.612 0.07 0.833 0.063 0.769 0.045 0.743 0.042 \nSauerkraut P1 0.742 0.044 0.897 0.057 0.542 0.072 0.939 0.034 0.677 0.056 0.672 0.062 0.74 0.04 \nSauerkraut P2 0.815 0.039 0.858 0.054 0.749 0.062 0.878 0.047 0.781 0.056 0.798 0.047 0.814 0.039 \nSauerkraut P3 0.773 0.042 0.964 0.035 0.562 0.071 0.98 0.02 0.696 0.055 0.708 0.06 0.771 0.037 \nSauerkraut P4 0.793 0.042 0.777 0.059 0.81 0.057 0.776 0.06 0.81 0.057 0.791 0.046 0.793 0.042 \nPPV=Positive Predictive Value, NPV = Negative Predictive Value, Std= Standard Deviation\n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n14 \nReferences \n1. Winter NR, Blanke J, Leenings R, et al. A Systematic Evaluation of Machine Learning–\nBased Biomarkers for Major Depressive Disorder. JAMA Psychiatry. Published online Janu-\nary 10, 2024. doi:10.1001/jamapsychiatry.2023.5083 \n2. Koutsouleris N, Dwyer DB, Degenhardt F, et al. Multimodal Machine Learning Workflows \nfor Prediction of Psychosis in Patients With Clinical High-Risk Syndromes and Recent-On-\nset Depression. JAMA Psychiatry. 2021;78(2):195-209. \n3. Clusmann J, Kolbinger FR, Muti HS, et al. The future landscape of large language models \nin medicine. Commun Med. 2023;3(1):141. \n4. Wiest IC, Ferber D, Zhu J, et al. From text to tables: A local privacy preserving large lan-\nguage model for structured information retrieval from medical documents. bioRxiv. Pub-\nlished online December 8, 2023. doi:10.1101/2023.12.07.23299648 \n5. Irving J, Patel R, Oliver D, et al. Using Natural Language Processing on Electronic Health \nRecords to Enhance Detection and Prediction of Psychosis Risk. Schizophr Bull. \n2021;47(2):405-414. \n6. Kjell ONE, Kjell K, Schwartz HA. Beyond Rating Scales: With Targeted Evaluation, Lan-\nguage Models are Poised for Psychological Assessment. Psychiatry Res. Published online \nDecember 10, 2023:115667. \n7. Zhao WX, Zhou K, Li J, et al. A Survey of Large Language Models. arXiv [csCL]. Published \nonline March 31, 2023. http://arxiv.org/abs/2303.18223v13 \n8. Van Veen M, Wierdsma AI, van Boeijen C, et al. Suicide risk, personality disorder and hos-\npital admission after assessment by psychiatric emergency services. BMC Psychiatry. \n2019;19(1):157. \n9. Watts BV, Shiner B, Young-Xu Y, Mills PD. Sustained Effectiveness of the Mental Health \nEnvironment of Care Checklist to Decrease Inpatient Suicide. Psychiatr Serv. \n2017;68(4):405-407. \n10. Jobbins T. Llama-2-70B-Chat-GGUF. TheBloke/Llama-2-70B-Chat-GGUF. Accessed De-\ncember 2023. https://huggingface.co/TheBloke/Llama-2-70B-Chat-GGUF \n11. VAGO Solutions. SauerkrautLM. VAGOsolutions/SauerkrautLM-70b-v1. Accessed Decem-\nber 2023. https://huggingface.co/VAGOsolutions/SauerkrautLM-70b-v1 \n12. Harries JP. EM-German. jphme/Llama-2-70b-chat-german. Accessed December 2023. \nhttps://github.com/jphme/EM_German/blob/main \n13. Chen B, Zhang Z, Langrené N, Zhu S. Unleashing the potential of prompt engineering in \nLarge Language Models: a comprehensive review. arXiv [csCL]. Published online October \n23, 2023. http://arxiv.org/abs/2310.14735 \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n15 \n14. Yang K, Zhang T, Kuang Z, Xie Q, Ananiadou S, Huang J. MentaLLaMA: Interpretable \nMental Health Analysis on Social Media with Large Language Models. arXiv [csCL]. Publis-\nhed online September 24, 2023. http://arxiv.org/abs/2309.13567 \n15. Wisniewski SR, Rush AJ, Nierenberg AA, et al. Can Phase III Trial Results of Antidepres-\nsant Medications Be Generalized to Clinical Practice? A STAR*D Report. AJP. \n2009;166(5):599-607. \n16. Ophir Y, Tikochinski R, Asterhan CSC, Sisso I, Reichart R. Deep neural networks detect \nsuicide risk from textual facebook posts. Sci Rep. 2020;10(1):16685. \n17. Meerwijk EL, Tamang SR, Finlay AK, Ilgen MA, Reeves RM, Harris AHS. Suicide theory-\nguided natural language processing of clinical progress notes to improve prediction of vet-\neran suicide risk: protocol for a mixed-method study. BMJ Open. 2022;12(8):e065088. \n18. Li H, Moon JT, Purkayastha S, Celi LA, Trivedi H, Gichoya JW. Ethics of large language \nmodels in medicine and medical research. Lancet Digit Health. 2023;5(6):e333-e335. \n19. Perlis RH, Fihn SD. Evaluating the Application of Large Language Models in Clinical Re-\nsearch Contexts. JAMA Netw Open. 2023;6(10):e2335924. \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint \n16 \nSupplement \nSupplementary Table 1 – P0 shows the simplest prompt without examples, P3 is the extended version with three examples in the \ntext to ensure in-context learning. P1 and P2 have one and two examples, respectively. The original German prompt has been trans-\nlated into English.  \n \nPrompt Abbreviation Prompt (Translation) \nP0 \"You are an attentive medical assistant with specialized expertise in psychiatry. Below you will find a psychiatric history. Please answer the question. \n \nMedical history: {} \nQuestion: Is the patient suicidal? Answer yes or no. Give an excerpt from the medical history to justify your answer.\" \nP3 \"You are an attentive medical assistant with specialized knowledge in psychiatry. Below you will find a psychiatric history. Please answer the question. First \nyou will be given an example. \n \nExample 1: Patient is awake, conscious, friendly and demonstrating a willingness to engage in a conversation. Disorientation of time (-1 day). Oriented to \nthe location, situation and personal identity. Perception, concentration and memory are intact. No evidence of formal thought disorder or abnormal thought \ncontent. Mood stable, affect appropriate to the situation and within normal fluctuations. No fears or compulsions. No abnormalities of activity. No feelings of \nweariness with life or suicidal thoughts. No immediate risk to self or others.  \nQuestion: Answer yes or no. Give an excerpt from the medical history to justify your answer. \nASSISTANT: no. Rationale: Medical history indicates that the patient is not experiencing any feelings of weariness with life or suicidal thoughts. In addition, \nthere is no immediate risk to self or others.  In summary, there is no suicidal ideation. \nExample 2: Awake, conscious. Signs of impaired comprehension and attention. Thought process of intact rate, perseverating and fixated to the precipitating \nsituation and desire to self-discharge. No signs of delusions. Perceptual disorders denied. Mood clearly dysphoric and depressed, without evident mood \nswings. Psychomotor agitation. No immediate indications of danger to others, acute danger to self in case of suicidal tendencies. \nQuestion: Answer yes or no. Give an excerpt from the medical history to justify your answer. \nASSISTANT: yes. Rationale: This can be inferred from the last sentence of the medical history: \"acute danger to self in case of suicidal tendencies” \nExample 3: Patient awake, conscious, fully oriented across all 4 dimensions, friendly, presenting himself as willing to provide information, however, mood \nbarely explorable due to drug intoxication, displaying intermittently parathymic and inappropriate affect, laughing out loud during the conversation. Formal \nand content-related thought process clearly incoherent, signs of hallucinations (looks around the room), no evidence of specific fears or compulsions. Cur-\nrently clearly not displaying acute suicidal tendencies. Signs of acute danger to others. A risk of harm to both themselves and others in the context of psy-\nchotic misinterpretation of reality.  \nQuestion: Answer yes or no. Give an excerpt from the medical history to justify your answer. \nASSISTANT: no. Reason: No, the patient is currently clearly not displaying acute suicidal tendencies \n \nMedical history: {} \nQuestion: Is the patient suicidal? Answer yes or no. Give an excerpt from the medical history to justify your answer.” \n \n \n \n . CC-BY-NC 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 8, 2024. ; https://doi.org/10.1101/2024.03.06.24303763doi: medRxiv preprint ",
  "topic": "German",
  "concepts": [
    {
      "name": "German",
      "score": 0.5142626166343689
    },
    {
      "name": "Medical record",
      "score": 0.4849146008491516
    },
    {
      "name": "Psychiatry",
      "score": 0.45914411544799805
    },
    {
      "name": "Relevance (law)",
      "score": 0.45131683349609375
    },
    {
      "name": "Health records",
      "score": 0.4273329973220825
    },
    {
      "name": "Psychology",
      "score": 0.3795830011367798
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3471432328224182
    },
    {
      "name": "Medicine",
      "score": 0.3253968358039856
    },
    {
      "name": "Computer science",
      "score": 0.3198477029800415
    },
    {
      "name": "Health care",
      "score": 0.3128643035888672
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Economic growth",
      "score": 0.0
    },
    {
      "name": "History",
      "score": 0.0
    },
    {
      "name": "Radiology",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210108778",
      "name": "Fresenius (Germany)",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I223822909",
      "name": "Heidelberg University",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I2802164966",
      "name": "University Hospital Heidelberg",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I4210156450",
      "name": "University Medical Centre Mannheim",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I78650965",
      "name": "Technische Universität Dresden",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I4210162051",
      "name": "University Hospital Carl Gustav Carus",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I4210111460",
      "name": "National Center for Tumor Diseases",
      "country": "DE"
    }
  ]
}