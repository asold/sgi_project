{
  "title": "How Can Large Language Models Enable Better Socially Assistive Human-Robot Interaction: A Brief Survey",
  "url": "https://openalex.org/W4398160853",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2129249079",
      "name": "Zhonghao Shi",
      "affiliations": [
        "Southern California University for Professional Studies",
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A5094347704",
      "name": "Ellen Landrum",
      "affiliations": [
        "University of Southern California",
        "Southern California University for Professional Studies"
      ]
    },
    {
      "id": "https://openalex.org/A4268519423",
      "name": "Amy O’Connell",
      "affiliations": [
        "University of Southern California",
        "Southern California University for Professional Studies"
      ]
    },
    {
      "id": "https://openalex.org/A5094347705",
      "name": "Mina Kian",
      "affiliations": [
        "University of Southern California",
        "Southern California University for Professional Studies"
      ]
    },
    {
      "id": "https://openalex.org/A4207893113",
      "name": "Leticia Pinto-Alva",
      "affiliations": [
        "Southern California University for Professional Studies",
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A5094347706",
      "name": "Kaleen Shrestha",
      "affiliations": [
        "University of Southern California",
        "Southern California University for Professional Studies"
      ]
    },
    {
      "id": "https://openalex.org/A2101902995",
      "name": "Xiaoyuan Zhu",
      "affiliations": [
        "University of Southern California",
        "Southern California University for Professional Studies"
      ]
    },
    {
      "id": "https://openalex.org/A2075666580",
      "name": "Maja J. Matarić",
      "affiliations": [
        "University of Southern California",
        "Southern California University for Professional Studies"
      ]
    },
    {
      "id": "https://openalex.org/A2129249079",
      "name": "Zhonghao Shi",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A5094347704",
      "name": "Ellen Landrum",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A4268519423",
      "name": "Amy O’Connell",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A5094347705",
      "name": "Mina Kian",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A4207893113",
      "name": "Leticia Pinto-Alva",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A5094347706",
      "name": "Kaleen Shrestha",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A2101902995",
      "name": "Xiaoyuan Zhu",
      "affiliations": [
        "University of Southern California"
      ]
    },
    {
      "id": "https://openalex.org/A2075666580",
      "name": "Maja J. Matarić",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4384447358",
    "https://openalex.org/W3087705571",
    "https://openalex.org/W4387372812",
    "https://openalex.org/W6851009546",
    "https://openalex.org/W3105925983",
    "https://openalex.org/W2943029779",
    "https://openalex.org/W6676224056",
    "https://openalex.org/W3187918213",
    "https://openalex.org/W4372348475",
    "https://openalex.org/W3126337491",
    "https://openalex.org/W3121188507",
    "https://openalex.org/W4205623709",
    "https://openalex.org/W3128663629",
    "https://openalex.org/W4389263544",
    "https://openalex.org/W4285097691",
    "https://openalex.org/W6775793267",
    "https://openalex.org/W4311597143",
    "https://openalex.org/W2936262349",
    "https://openalex.org/W2962948182",
    "https://openalex.org/W3122468786",
    "https://openalex.org/W2794425661",
    "https://openalex.org/W4297161808",
    "https://openalex.org/W3112188842",
    "https://openalex.org/W3133542152",
    "https://openalex.org/W6809838524",
    "https://openalex.org/W6840036810",
    "https://openalex.org/W4377371478",
    "https://openalex.org/W2573268309",
    "https://openalex.org/W4389116286",
    "https://openalex.org/W4388964727",
    "https://openalex.org/W4308352263",
    "https://openalex.org/W2770498732",
    "https://openalex.org/W4383108457",
    "https://openalex.org/W3128013500",
    "https://openalex.org/W3166396011",
    "https://openalex.org/W4386501849",
    "https://openalex.org/W4224912544",
    "https://openalex.org/W2970062726",
    "https://openalex.org/W4389911960",
    "https://openalex.org/W3142599250",
    "https://openalex.org/W4389072332",
    "https://openalex.org/W4386395818",
    "https://openalex.org/W4285803326",
    "https://openalex.org/W3011832253",
    "https://openalex.org/W4304111821",
    "https://openalex.org/W4281763794",
    "https://openalex.org/W4323536841",
    "https://openalex.org/W4382491841",
    "https://openalex.org/W3017144593",
    "https://openalex.org/W4362598512",
    "https://openalex.org/W4387293571",
    "https://openalex.org/W4387952963",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4379538499"
  ],
  "abstract": "Socially assistive robots (SARs) have shown great success in providing personalized cognitive-affective support for user populations with special needs such as older adults, children with autism spectrum disorder (ASD), and individuals with mental health challenges. The large body of work on SAR demonstrates its potential to provide at-home support that complements clinic-based interventions delivered by mental health professionals, making these interventions more effective and accessible. However, there are still several major technical challenges that hinder SAR-mediated interactions and interventions from reaching human-level social intelligence and efficacy. With the recent advances in large language models (LLMs), there is an increased potential for novel applications within the field of SAR that can significantly expand the current capabilities of SARs. However, incorporating LLMs introduces new risks and ethical concerns that have not yet been encountered, and must be carefully be addressed to safely deploy these more advanced systems. In this work, we aim to conduct a brief survey on the use of LLMs in SAR technologies, and discuss the potentials and risks of applying LLMs to the following three major technical challenges of SAR: 1) natural language dialog; 2) multimodal understanding; 3) LLMs as robot policies.",
  "full_text": "How Can Large Language Models Enable Better Socially Assistive\nHuman-Robot Interaction: A Brief Survey\nZhonghao Shi, Ellen Landrum, Amy O’Connell, Mina Kian, Leticia Pinto-Alva, Kaleen Shrestha,\nXiaoyuan Zhu, Maja J Matari´c\nUniversity of Southern California, Los Angeles, United States\n{zhonghas, elandrum, amy.dell, kian, pintoalv, kshresth, xzhu9839, mataric}@usc.edu\nAbstract\nSocially assistive robots (SARs) have shown great success\nin providing personalized cognitive-affective support for user\npopulations with special needs such as older adults, children\nwith autism spectrum disorder (ASD), and individuals with\nmental health challenges. The large body of work on SAR\ndemonstrates its potential to provide at-home support that\ncomplements clinic-based interventions delivered by mental\nhealth professionals, making these interventions more effec-\ntive and accessible. However, there are still several major\ntechnical challenges that hinder SAR-mediated interactions\nand interventions from reaching human-level social intelli-\ngence and efficacy. With the recent advances in large lan-\nguage models (LLMs), there is an increased potential for\nnovel applications within the field of SAR that can signifi-\ncantly expand the current capabilities of SARs. However, in-\ncorporating LLMs introduces new risks and ethical concerns\nthat have not yet been encountered, and must be carefully be\naddressed to safely deploy these more advanced systems. In\nthis work, we aim to conduct a brief survey on the use of\nLLMs in SAR technologies, and discuss the potentials and\nrisks of applying LLMs to the following three major technical\nchallenges of SAR: 1) natural language dialog; 2) multimodal\nunderstanding; 3) LLMs as robot policies.\nIntroduction\nAt the intersection of assistive robots and socially interac-\ntive robots, socially assistive robotsaim to provide assis-\ntance to support users’ cognitive-affective needs through so-\ncial interaction (Feil-Seifer and Matari ´c 2011). Past stud-\nies have demonstrated the benefits and potential of deploy-\ning SARs to support a diverse set of user populations, in-\ncluding individuals with mental health challenges (Scoglio\net al. 2019), children with ASD (Cabibihan et al. 2013),\nolder adults (Shishehgar, Kerr, and Blake 2018), and K-12\nstudents (Randall 2019). With more affordable robot hard-\nware (Koh, Ang, and Casey 2021; Pinto-Bernal et al. 2022;\nKoh et al. 2022), SARs have the potential to lower the socio-\neconomic barriers that limit access to personalized thera-\npies, companionship, and education. However, prior work\nhas also demonstrated that the existing SAR interactions\nhave not yet been able to understand multimodal (language\nCopyright © 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nand visual) social dynamics (Robinson et al. 2023; Li et al.\n2021) and respond with human-like dialog (Skantze 2021)\nand actions (Akalin and Loutfi 2021).\nWith the recent advances in natural language process-\ning (NLP) research, large language models (LLMs) such\nas GPT-4 have shown tremendous success in tasks both\nwithin the field of NLP (such as language modeling, ques-\ntion answering, and translation) (Achiam et al. 2023) and\noutside (such as programming (Xu et al. 2022), robot plan-\nning (Singh et al. 2023), and autonomous driving (Cui et al.\n2024)). These capabilities of LLMs may open new possibil-\nities for tackling the core technical challenges of SAR, and\nhelp us get closer to achieving more effective, human-level\nsocial assistance for users with differences.\nIn this work, we categorize the core technical challenges\nof SAR into three areas: 1) natural language dialog; 2) mul-\ntimodal user understanding; 3) LLMs as robot policies. To\nsurvey the existing work on LLM-powered SARs in these\nthree categories of technical challenges, we used Google\nScholar to search the relevant papers in major human-robot\ninteraction conferences, journals, and arXiv. In each of the\nfollowing sections, we aim to: identify the potential of LLMs\nfor SAR, survey existing work, and discuss future directions.\nThis research was supported by the National Science Foun-\ndation Grant ITE-2236320 and IIS-1925083.\nNatural Language Dialogue\nNatural language dialogue is at the core of human-centered\nsocial interaction. Yet, prior to the recent breakthroughs in\nLLM technologies, SARs mainly relied on Wizard-of-Oz\nteleoperation (Erich, Hirokawa, and Suzuki 2017) or prede-\nfined rule-based dialogue management systems (Erich, Hi-\nrokawa, and Suzuki 2017; Youssef et al. 2022). SARs em-\nploying traditional non-LLM-based conversational systems\nare limited by their inability to accurately interpret human\ndialogue, limited vocabulary in dialogue generation, lack of\nunderstanding of context and ability to personalize, and lack\nof ability to effectively utilize online resources (Grassi, Rec-\nchiuto, and Sgorbissa 2022).\nBy applying state-of-art LLM models such as GPT-\n4 (Achiam et al. 2023), recent work on LLM-powered SAR\nhas been mainly focused on enabling more accurate dia-\nlog understanding and more human-like and context-aware\ndialogue generation. LLM-powered SARs are able to pro-\nAAAI Spring Symposium Series (SSS-24)\n401\nduce varied dialogue while staying on topic (Billing, Ros´en,\nand Lamb 2023). They can engage in more natural, flex-\nible conversation with users from populations of interest,\nsuch as older adults and children with autism spectrum\ndisorder (Bertacchini et al. 2023). Spitale, Axelsson, and\nGunes (2023) designed an LLM-powered SAR as a motiva-\ntional coach with both informative and emotional objectives,\ndemonstrating that LLMs can be used to understand long-\nhorizon context and enable long-term personalization. In in-\nstructional settings, LLM-powered SARs combine the vast\nknowledge base and interactive content-delivery of LLMs\nwith the the capabilities and engaging nature of physically\nembodied agents (Wake et al. 2023).\nDespite this progress, Irfan, Kuoppam ¨aki, and Skantze\n(2023) showed that hallucinations, obsolete information, la-\ntency, and disengagement cues may still cause user frus-\ntration and confusion, which could be detrimental to so-\ncially assistive human-robot interaction. More exploration is\nneeded to overcome these limitations and harness the power\nof LLMs in ways that better align with the goals of SAR\ninteractions.\nMultimodal User Understanding\nTo enable successful socially assistive human-robot inter-\nactions, a SAR needs to understand the user’s cognitive-\naffective state (user engagement, affect, and intent) from\nmultimodal perceptual data (language, visual, and au-\ndio) (Youssef et al. 2022). Existing work on multimodal so-\ncial understanding has relied on training and fine-tuning ma-\nchine learning (ML) models with data collected from pre-\nvious SAR deployments (Robinson et al. 2023). However,\nthe definition of cognitive-affective states may vary in dif-\nferent social contexts. Due to the independent and identi-\ncally distributed (IID) assumption made by ML model train-\ning (Wang et al. 2022), existing ML models struggle to gen-\neralize effectively and quickly to test data that are distributed\ndifferently from the training data, particularly in the context\nof SAR (Shi et al. 2022).\nMultimodal language models (MLMs) such as state-of-\nthe-art vision-language models like CLIP (Radford et al.\n2021), ALIGN (Jia et al. 2021), and GPT-4V (Achiam et al.\n2023), have shown promising zero-shot performance on a\nvariety of human-centered visual tasks (Zhang et al. 2023a;\nWu et al. 2023). Furthermore, these MLMs also demonstrate\nimpressive few-shot capabilities of quickly adapting via\nprompting with natural language (Ge et al. 2023). This in-\ndicates that MLMs may also be capable of adapting to novel\nsocial context for more generalizable and accurate multi-\nmodal social understanding. Despite the recent progress in\ncomputer vision and robotics, using MLMs for SAR is still\nlargely unexplored, but this direction of research shows great\npotential for significantly enabling better multimodal social\nunderstanding for socially assistive human-robot interaction.\nLLMs as Robot Policies\nIn an ideal socially assistive human-robot interaction, a SAR\nshould fluently learn and reason about the user’s states and\nprovide the best feedback or action as assistance. The space\nof user’s states and robot feedback or actions can be large\nand continuous (Clabaugh and Matari ´c 2019) and exist-\ning approaches to encoding SAR policies, such as rule-\nbased system and reinforcement learning, are not efficiently\ntrained or sufficiently robust on large and continuous spaces\nwith limited amounts of data (Akalin and Loutfi 2021). Past\nwork has often circumvented this problem by constraining\ninteractions to pre-defined tablet/computer games with small\nuser state and action spaces (Clabaugh and Matari ´c 2019).\nLLMs may help to relax this constraint and enable more nat-\nural interaction by allowing continuous, more human-like\nformulation of space for user states and robot actions.\nRecent studies in robotics and NLP have successfully\nemployed LLMs as robot policies in the setting includ-\ning autonomous driving (Cui et al. 2024), robot task plan-\nning (Singh et al. 2023; Ahn et al. 2022), social common\nsense (Sap et al. 2019) and social reasoning (Gandhi et al.\n2023). In the field of SAR, existing work has mainly fo-\ncused on applying LLMs to matching the affective state of\nrobot feedback with the sentiment of the robot’s dialog (Lee\net al. 2023; Mishra et al. 2023; Lim et al. 2023). These stud-\nies have shown that LLM-powered robot policies for ges-\nture matching enable more context-aware and natural robot\ngesture. Research using LLMs as robot policies has not yet\nexplored 1) how to enable SARs to form robot policies for\nspontaneous tasks instead of only pre-defined ones, such as\nhelping children with ASD navigate through an unpleasant\nsocial interaction they just encountered during their school\nday; 2) how to enable SAR policies to engage users with\neducational tasks while keeping them both challenged and\nencouraged; 3) how to reason socially about the user’s in-\ntent and needs with partially observable information based\non multimodal data; and 4) how to enable personalized SAR\npolicies to quickly align with each user’s unique needs, per-\nsonality, and values, so the SAR can be more helpful and\nempathetic to each user.\nRisks and Safety Considerations\nBecause SAR aims to support vulnerable populations in-\ncluding children and individuals with physical and/or men-\ntal health challenges (Matari ´c and Scassellati 2016), it\nis crucial to ensure absolute safety during socially assis-\ntive human-robot interactions. Despite the great success in\nLLMs, their lack of explainability and theoretical safety\nguarantees (Huang et al. 2023) may introduce significant\nrisks and concerns by 1) amplifying unfairness and human\nbias (Acerbi and Stubbersfield 2023); 2) harming data secu-\nrity and privacy by unethical use of personal data (Liyanage\net al. 2020); and 3) hallucination behaviors causing potential\nharms to users (Zhang et al. 2023b). For these reasons, the\ntrustworthiness of LLM-powered SAR needs to be exten-\nsively evaluated before autonomous system can be deployed\nwith vulnerable populations without human monitoring and\noversight. As the first survey paper on this topic, this work\naims to inform and stimulate research toward leveraging the\ntremendous potential of LLM-powered SARs and address\nthe risks and safety concerns.\n402\nReferences\nAcerbi, A.; and Stubbersfield, J. M. 2023. Large language\nmodels show human-like content biases in transmission\nchain experiments. Proceedings of the National Academy\nof Sciences, 120(44): e2313790120.\nAchiam, J.; Adler, S.; Agarwal, S.; Ahmad, L.; Akkaya, I.;\nAleman, F. L.; Almeida, D.; Altenschmidt, J.; Altman, S.;\nAnadkat, S.; et al. 2023. GPT-4 Technical Report. arXiv\npreprint arXiv:2303.08774.\nAhn, M.; Brohan, A.; Brown, N.; Chebotar, Y .; Cortes, O.;\nDavid, B.; Finn, C.; Fu, C.; Gopalakrishnan, K.; Hausman,\nK.; Herzog, A.; Ho, D.; Hsu, J.; Ibarz, J.; Ichter, B.; Irpan,\nA.; Jang, E.; Ruano, R. J.; Jeffrey, K.; Jesmonth, S.; Joshi,\nN. J.; Julian, R.; Kalashnikov, D.; Kuang, Y .; Lee, K.-H.;\nLevine, S.; Lu, Y .; Luu, L.; Parada, C.; Pastor, P.; Quiambao,\nJ.; Rao, K.; Rettinghouse, J.; Reyes, D.; Sermanet, P.; Siev-\ners, N.; Tan, C.; Toshev, A.; Vanhoucke, V .; Xia, F.; Xiao, T.;\nXu, P.; Xu, S.; Yan, M.; and Zeng, A. 2022. Do As I Can,\nNot As I Say: Grounding Language in Robotic Affordances.\narXiv:2204.01691.\nAkalin, N.; and Loutfi, A. 2021. Reinforcement learning\napproaches in social robotics. Sensors, 21(4): 1292.\nBertacchini, F.; Demarco, F.; Scuro, C.; Pantano, P.; and\nBilotta, E. 2023. A social robot connected with chatGPT\nto improve cognitive functioning in ASD subjects.Frontiers\nin Psychology, 14.\nBilling, E.; Ros´en, J.; and Lamb, M. 2023. Language mod-\nels for human-robot interaction. In ACM/IEEE Interna-\ntional Conference on Human-Robot Interaction, March 13–\n16, 2023, Stockholm, Sweden, 905–906. ACM Digital Li-\nbrary.\nCabibihan, J.-J.; Javed, H.; Ang, M.; and Aljunied, S. M.\n2013. Why robots? A survey on the roles and benefits of\nsocial robots in the therapy of children with autism. Inter-\nnational journal of social robotics, 5: 593–618.\nClabaugh, C.; and Matari ´c, M. 2019. Escaping oz: Auton-\nomy in socially assistive robotics.Annual Review of Control,\nRobotics, and Autonomous Systems, 2: 33–61.\nCui, C.; Ma, Y .; Cao, X.; Ye, W.; Zhou, Y .; Liang, K.; Chen,\nJ.; Lu, J.; Yang, Z.; Liao, K.-D.; et al. 2024. A survey on\nmultimodal large language models for autonomous driving.\nIn Proceedings of the IEEE/CVF Winter Conference on Ap-\nplications of Computer Vision, 958–979.\nErich, F.; Hirokawa, M.; and Suzuki, K. 2017. A systematic\nliterature review of experiments in socially assistive robotics\nusing humanoid robots. arXiv preprint arXiv:1711.05379.\nFeil-Seifer, D.; and Matari ´c, M. J. 2011. Socially assistive\nrobotics. IEEE Robotics & Automation Magazine, 18(1):\n24–31.\nGandhi, K.; Fr ¨anken, J.-P.; Gerstenberg, T.; and Good-\nman, N. D. 2023. Understanding social reasoning in\nlanguage models with language models. arXiv preprint\narXiv:2306.15448.\nGe, W.; Chen, S.; Chen, G.; Chen, J.; Chen, Z.; Yan, S.;\nZhu, C.; Lin, Z.; Xie, W.; Wang, X.; et al. 2023. MLLM-\nBench, Evaluating Multi-modal LLMs using GPT-4V .arXiv\npreprint arXiv:2311.13951.\nGrassi, L.; Recchiuto, C. T.; and Sgorbissa, A. 2022.\nKnowledge-grounded dialogue flow management for social\nrobots and conversational agents. International Journal of\nSocial Robotics, 14(5): 1273–1293.\nHuang, X.; Ruan, W.; Huang, W.; Jin, G.; Dong, Y .; Wu, C.;\nBensalem, S.; Mu, R.; Qi, Y .; Zhao, X.; et al. 2023. A Sur-\nvey of Safety and Trustworthiness of Large Language Mod-\nels through the Lens of Verification and Validation. arXiv\npreprint arXiv:2305.11391.\nIrfan, B.; Kuoppam ¨aki, S.-M.; and Skantze, G. 2023. Be-\ntween Reality and Delusion: Challenges of Applying Large\nLanguage Models to Companion Robots for Open-Domain\nDialogues with Older Adults.\nJia, C.; Yang, Y .; Xia, Y .; Chen, Y .-T.; Parekh, Z.; Pham, H.;\nLe, Q.; Sung, Y .-H.; Li, Z.; and Duerig, T. 2021. Scaling\nup visual and vision-language representation learning with\nnoisy text supervision. In International conference on ma-\nchine learning, 4904–4916. PMLR.\nKoh, W. Q.; Ang, F. X. H.; and Casey, D. 2021. Impacts\nof low-cost robotic pets for older adults and people with de-\nmentia: scoping review. JMIR rehabilitation and assistive\ntechnologies, 8(1): e25340.\nKoh, W. Q.; Whelan, S.; Heins, P.; Casey, D.; Toomey, E.;\nand Dr¨oes, R.-M. 2022. The usability and impact of a low-\ncost pet robot for older adults and people with dementia:\nqualitative content analysis of user experiences and percep-\ntions on consumer websites. JMIR aging, 5(1): e29224.\nLee, Y . K.; Jung, Y .; Kang, G.; and Hahn, S. 2023. Develop-\ning Social Robots with Empathetic Non-Verbal Cues Using\nLarge Language Models. arXiv preprint arXiv:2308.16529.\nLi, Z.; Mu, Y .; Sun, Z.; Song, S.; Su, J.; and Zhang, J. 2021.\nIntention understanding in human–robot interaction based\non visual-NLP semantics. Frontiers in Neurorobotics, 14:\n610139.\nLim, J.; Sa, I.; MacDonald, B.; and Ahn, H. S. 2023. A Sign\nLanguage Recognition System with Pepper, Lightweight-\nTransformer, and LLM. arXiv preprint arXiv:2309.16898.\nLiyanage, H.; Kuziemsky, C.; Terry, A.; Schreiber, R.; Jon-\nnagaddala, J.; de Lusignan, S.; McGovern, A.; Hinton, W.;\nCorra, A.; Munro, N.; et al. 2020. Ethical use of electronic\nhealth record data and artificial intelligence: recommenda-\ntions of the primary care informatics working group of the\ninternational medical informatics association. Yearbook of\nmedical informatics, 29(01): 051–057.\nMatari´c, M. J.; and Scassellati, B. 2016. Socially assistive\nrobotics. Springer handbook of robotics, 1973–1994.\nMishra, C.; Verdonschot, R.; Hagoort, P.; and Skantze, G.\n2023. Real-time emotion generation in human-robot dia-\nlogue using large language models. Frontiers in Robotics\nand AI, 10.\nPinto-Bernal, M. J.; Cespedes, N.; Castro, P.; Munera, M.;\nand Cifuentes, C. A. 2022. Physical human-robot interaction\ninfluence in ASD therapy through an affordable soft social\nrobot. Journal of Intelligent & Robotic Systems, 105(3): 67.\nRadford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.;\nAgarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.;\n403\net al. 2021. Learning transferable visual models from nat-\nural language supervision. In International conference on\nmachine learning, 8748–8763. PMLR.\nRandall, N. 2019. A survey of robot-assisted language learn-\ning (RALL). ACM Transactions on Human-Robot Interac-\ntion (THRI), 9(1): 1–36.\nRobinson, N.; Tidd, B.; Campbell, D.; Kuli´c, D.; and Corke,\nP. 2023. Robotic vision for human-robot interaction and col-\nlaboration: A survey and systematic review. ACM Transac-\ntions on Human-Robot Interaction, 12(1): 1–66.\nSap, M.; Rashkin, H.; Chen, D.; Le Bras, R.; and Choi,\nY . 2019. Social IQa: Commonsense Reasoning about So-\ncial Interactions. In Inui, K.; Jiang, J.; Ng, V .; and Wan,\nX., eds., Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th Inter-\nnational Joint Conference on Natural Language Processing\n(EMNLP-IJCNLP), 4463–4473. Hong Kong, China: Asso-\nciation for Computational Linguistics.\nScoglio, A. A.; Reilly, E. D.; Gorman, J. A.; and Drebing,\nC. E. 2019. Use of social robots in mental health and well-\nbeing research: systematic review. Journal of medical Inter-\nnet research, 21(7): e13322.\nShi, Z.; Groechel, T. R.; Jain, S.; Chima, K.; Rudovic, O.;\nand Matari´c, M. J. 2022. Toward personalized affect-aware\nsocially assistive robot tutors for long-term interventions\nwith children with autism. ACM Transactions on Human-\nRobot Interaction (THRI), 11(4): 1–28.\nShishehgar, M.; Kerr, D.; and Blake, J. 2018. A system-\natic review of research into how robotic technology can help\nolder people. Smart Health, 7: 1–18.\nSingh, I.; Blukis, V .; Mousavian, A.; Goyal, A.; Xu, D.;\nTremblay, J.; Fox, D.; Thomason, J.; and Garg, A. 2023.\nProgprompt: Generating situated robot task plans using large\nlanguage models. In 2023 IEEE International Conference\non Robotics and Automation (ICRA), 11523–11530. IEEE.\nSkantze, G. 2021. Turn-taking in conversational systems and\nhuman-robot interaction: a review.Computer Speech & Lan-\nguage, 67: 101178.\nSpitale, M.; Axelsson, M.; and Gunes, H. 2023. VITA:\nA Multi-modal LLM-based System for Longitudinal, Au-\ntonomous, and Adaptive Robotic Mental Well-being Coach-\ning. arXiv preprint arXiv:2312.09740.\nWake, N.; Kanehira, A.; Sasabuchi, K.; Takamatsu, J.; and\nIkeuchi, K. 2023. GPT Models Meet Robotic Applica-\ntions: Co-Speech Gesturing Chat System. arXiv preprint\narXiv:2306.01741.\nWang, J.; Lan, C.; Liu, C.; Ouyang, Y .; Qin, T.; Lu, W.;\nChen, Y .; Zeng, W.; and Yu, P. 2022. Generalizing to un-\nseen domains: A survey on domain generalization. IEEE\nTransactions on Knowledge and Data Engineering.\nWu, W.; Yao, H.; Zhang, M.; Song, Y .; Ouyang, W.; and\nWang, J. 2023. GPT4Vis: What Can GPT-4 Do for Zero-\nshot Visual Recognition? arXiv preprint arXiv:2311.15732.\nXu, F. F.; Alon, U.; Neubig, G.; and Hellendoorn, V . J. 2022.\nA systematic evaluation of large language models of code. In\nProceedings of the 6th ACM SIGPLAN International Sympo-\nsium on Machine Programming, 1–10.\nYoussef, K.; Said, S.; Alkork, S.; and Beyrouthy, T. 2022.\nA survey on recent advances in social robotics. Robotics,\n11(4): 75.\nZhang, J.; Huang, J.; Jin, S.; and Lu, S. 2023a. Vision-\nlanguage models for vision tasks: A survey. arXiv preprint\narXiv:2304.00685.\nZhang, Y .; Li, Y .; Cui, L.; Cai, D.; Liu, L.; Fu, T.; Huang, X.;\nZhao, E.; Zhang, Y .; Chen, Y .; et al. 2023b. Siren’s Song in\nthe AI Ocean: A Survey on Hallucination in Large Language\nModels. arXiv preprint arXiv:2309.01219.\n404",
  "topic": "Psychological intervention",
  "concepts": [
    {
      "name": "Psychological intervention",
      "score": 0.6702854633331299
    },
    {
      "name": "Autism",
      "score": 0.5540515184402466
    },
    {
      "name": "Autism spectrum disorder",
      "score": 0.5176456570625305
    },
    {
      "name": "Dialog box",
      "score": 0.5005457401275635
    },
    {
      "name": "Psychology",
      "score": 0.4613710641860962
    },
    {
      "name": "Robot",
      "score": 0.42616182565689087
    },
    {
      "name": "Applied psychology",
      "score": 0.3316621780395508
    },
    {
      "name": "Computer science",
      "score": 0.323650598526001
    },
    {
      "name": "Developmental psychology",
      "score": 0.19806340336799622
    },
    {
      "name": "Psychiatry",
      "score": 0.1453774869441986
    },
    {
      "name": "Artificial intelligence",
      "score": 0.13794824481010437
    },
    {
      "name": "World Wide Web",
      "score": 0.0
    }
  ]
}