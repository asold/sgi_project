{
  "title": "MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention",
  "url": "https://openalex.org/W4387226154",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5119577072",
      "name": "Wu Ruolan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2100556307",
      "name": "Yu Chun",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2380872202",
      "name": "Pan Xiaole",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2094745862",
      "name": "Liu Yujia",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2225279630",
      "name": "Zhang Ningning",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2222436498",
      "name": "Fu Yue",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1535576110",
      "name": "Wang Yuhan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2104119821",
      "name": "Zheng Zhi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2095600869",
      "name": "Chen Li",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Jiang, Qiaolei",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2104531663",
      "name": "Xu, Xuhai",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2182666836",
      "name": "Shi, Yuanchun",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2799607522",
    "https://openalex.org/W4385847500",
    "https://openalex.org/W2416323622",
    "https://openalex.org/W968984893",
    "https://openalex.org/W2576300312",
    "https://openalex.org/W2907359540",
    "https://openalex.org/W4225164728",
    "https://openalex.org/W4361020491",
    "https://openalex.org/W2162167660",
    "https://openalex.org/W2186835692",
    "https://openalex.org/W2489796166",
    "https://openalex.org/W3005996117",
    "https://openalex.org/W4366548761",
    "https://openalex.org/W2011384858",
    "https://openalex.org/W2138611879",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4281779609",
    "https://openalex.org/W3163763055",
    "https://openalex.org/W2940570760",
    "https://openalex.org/W4387075911",
    "https://openalex.org/W1969429586",
    "https://openalex.org/W1977835193",
    "https://openalex.org/W2618035419",
    "https://openalex.org/W2897690397",
    "https://openalex.org/W2737692093",
    "https://openalex.org/W2795529671",
    "https://openalex.org/W4366549891",
    "https://openalex.org/W2043002652",
    "https://openalex.org/W2139976611",
    "https://openalex.org/W1573908710",
    "https://openalex.org/W2970026321",
    "https://openalex.org/W4382246105",
    "https://openalex.org/W3100372791",
    "https://openalex.org/W1994117915",
    "https://openalex.org/W3202566927",
    "https://openalex.org/W4388964602",
    "https://openalex.org/W2211847633",
    "https://openalex.org/W2910086092",
    "https://openalex.org/W2302342719",
    "https://openalex.org/W2886960793",
    "https://openalex.org/W3124724226",
    "https://openalex.org/W3125273512",
    "https://openalex.org/W2071802076",
    "https://openalex.org/W2082821694",
    "https://openalex.org/W3108514068",
    "https://openalex.org/W4385373745",
    "https://openalex.org/W2523153599",
    "https://openalex.org/W3093518649",
    "https://openalex.org/W3015500035",
    "https://openalex.org/W3029493744",
    "https://openalex.org/W2568836284",
    "https://openalex.org/W4366591012",
    "https://openalex.org/W4386875608",
    "https://openalex.org/W4392736453",
    "https://openalex.org/W3133784500",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4385291101",
    "https://openalex.org/W4387835481",
    "https://openalex.org/W2941852039",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W2530427141",
    "https://openalex.org/W2167357813",
    "https://openalex.org/W2102977671",
    "https://openalex.org/W4361230825",
    "https://openalex.org/W2980799813",
    "https://openalex.org/W4391420999",
    "https://openalex.org/W4366596321",
    "https://openalex.org/W3049568452",
    "https://openalex.org/W2794622338",
    "https://openalex.org/W4317437684",
    "https://openalex.org/W3032649576",
    "https://openalex.org/W4390961201",
    "https://openalex.org/W2920897010",
    "https://openalex.org/W205183655",
    "https://openalex.org/W4377121468",
    "https://openalex.org/W2040656687",
    "https://openalex.org/W4318719246",
    "https://openalex.org/W2972890723",
    "https://openalex.org/W2808257344",
    "https://openalex.org/W4225090108",
    "https://openalex.org/W3003601234",
    "https://openalex.org/W2505400317",
    "https://openalex.org/W2801150160",
    "https://openalex.org/W2069256380",
    "https://openalex.org/W4239882856",
    "https://openalex.org/W3167394498",
    "https://openalex.org/W4385847487",
    "https://openalex.org/W2516993240",
    "https://openalex.org/W4313451803",
    "https://openalex.org/W1999365908",
    "https://openalex.org/W2060118520",
    "https://openalex.org/W2899035333",
    "https://openalex.org/W3105160434",
    "https://openalex.org/W1512366833",
    "https://openalex.org/W2055101333",
    "https://openalex.org/W4285210452",
    "https://openalex.org/W2921330245",
    "https://openalex.org/W4308610353",
    "https://openalex.org/W3202487321",
    "https://openalex.org/W4235393368"
  ],
  "abstract": "Problematic smartphone use negatively affects physical and mental health. Despite the wide range of prior research, existing persuasive techniques are not flexible enough to provide dynamic persuasion content based on users' physical contexts and mental states. We first conducted a Wizard-of-Oz study (N=12) and an interview study (N=10) to summarize the mental states behind problematic smartphone use: boredom, stress, and inertia. This informs our design of four persuasion strategies: understanding, comforting, evoking, and scaffolding habits. We leveraged large language models (LLMs) to enable the automatic and dynamic generation of effective persuasion content. We developed MindShift, a novel LLM-powered problematic smartphone use intervention technique. MindShift takes users' in-the-moment app usage behaviors, physical contexts, mental states, goals \\&amp; habits as input, and generates personalized and dynamic persuasive content with appropriate persuasion strategies. We conducted a 5-week field experiment (N=25) to compare MindShift with its simplified version (remove mental states) and baseline techniques (fixed reminder). The results show that MindShift improves intervention acceptance rates by 4.7-22.5% and reduces smartphone usage duration by 7.4-9.8%. Moreover, users have a significant drop in smartphone addiction scale scores and a rise in self-efficacy scale scores. Our study sheds light on the potential of leveraging LLMs for context-aware persuasion in other behavior change domains.",
  "full_text": "MindShift: Leveraging Large Language Models for\nMental-States-Based Problematic Smartphone Use Intervention\nRuolan Wu\nTsinghua University\nBeijing, Beijing, China\nwurl21@mails.tsinghua.edu.cn\nChun Yu∗\nTsinghua University\nBeijing, Beijing, China\nchunyu@tsinghua.edu.cn\nXiaole Pan\nTsinghua University\nBeijing, Beijing, China\npxl22@mails.tsinghua.edu.cn\nYujia Liu\nTsinghua University\nBeijing, Beijing, China\nl-yj22@mails.tsinghua.edu.cn\nNingning Zhang\nTsinghua University\nBeijing, Beijing, China\nznn18@tsinghua.org.cn\nYue Fu\nUniversity of Washington\nSeattle, Washington, USA\nchrisfu@uw.edu\nYuhan Wang\nBeijing University of Posts and\nTelecommunications\nBeijing, Beijing, China\n2020211730@bupt.cn\nZhi Zheng\nTsinghua University\nBeijing, Beijing, China\ngeorgezhengzhi@gmail.com\nLi Chen\nTsinghua University\nBeijing, Beijing, China\nchenli19@mails.tsinghua.edu.cn\nQiaolei Jiang\nTsinghua University\nBeijing, Beijing, China\nqiaoleijiang@tsinghua.edu.cn\nXuhai Xu\nMassachusetts Institute of Technology\nCambridge, MA, USA\nxoxu@mit.edu\nYuanchun Shi\nTsinghua University\nBeijing, Beijing, China\nshiyc@tsinghua.edu.cn\nABSTRACT\nProblematic smartphone use negatively affects physical and mental\nhealth. Despite the wide range of prior research, existing persuasive\ntechniques are not flexible enough to provide dynamic persuasion\ncontent based on users’ physical contexts and mental states. We\nfirst conducted a Wizard-of-Oz study (N=12) and an interview study\n(N=10) to summarize the mental states behind problematic smart-\nphone use: boredom, stress, and inertia. This informs our design\nof four persuasion strategies: understanding, comforting, evoking,\nand scaffolding habits. We leveraged large language models (LLMs)\nto enable the automatic and dynamic generation of effective per-\nsuasion content. We developed MindShift, a novel LLM-powered\nproblematic smartphone use intervention technique. MindShift\ntakes users’ in-the-moment app usage behaviors, physical contexts,\nmental states, goals & habits as input, and generates personal-\nized and dynamic persuasive content with appropriate persuasion\nstrategies. We conducted a 5-week field experiment (N=25) to com-\npare MindShift with its simplified version (remove mental states)\nand baseline techniques (fixed reminder). The results show that\n∗Corresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA\n© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0330-0/24/05. . . $15.00\nhttps://doi.org/10.1145/3613904.3642790\nMindShift improves intervention acceptance rates by 4.7-22.5% and\nreduces smartphone usage duration by 7.4-9.8%. Moreover, users\nhave a significant drop in smartphone addiction scale scores and\na rise in self-efficacy scale scores. Our study sheds light on the\npotential of leveraging LLMs for context-aware persuasion in other\nbehavior change domains.\nCCS CONCEPTS\n• Human-centered computing → Empirical studies in HCI .\nKEYWORDS\nProblematic smartphone use, persuasion, large language model,\nmental model\nACM Reference Format:\nRuolan Wu, Chun Yu, Xiaole Pan, Yujia Liu, Ningning Zhang, Yue Fu, Yuhan\nWang, Zhi Zheng, Li Chen, Qiaolei Jiang, Xuhai Xu, and Yuanchun Shi.\n2024. MindShift: Leveraging Large Language Models for Mental-States-\nBased Problematic Smartphone Use Intervention. In Proceedings of the CHI\nConference on Human Factors in Computing Systems (CHI ’24), May 11–\n16, 2024, Honolulu, HI, USA. ACM, New York, NY, USA, 24 pages. https:\n//doi.org/10.1145/3613904.3642790\n1 INTRODUCTION\nIn recent years, the ubiquitous presence of smartphones has in-\ncreased people’s reliance on digital devices, resulting in problem-\natic smartphone usage behaviors, i.e., excessive or mindless us-\nage with negative consequences [45, 76], especially among adoles-\ncents and young adults [67]. Prior studies suggest that problematic\nsmartphone usage can detrimentally affect people in various ar-\neas such as efficiency (leading to diminished academic or work\narXiv:2309.16639v2  [cs.CL]  28 Feb 2024\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Wu et al.\nFigure 1: Overview of MindShift. When users exhibit problematic phone usage, MindShift actively collects data on phone\nusage behavior, physical contexts, and mental states, and uses the customized persuasion strategies we designed along with\nusers’ goals and habits, to generate prompts. Then, the large language model will generate a persuasion message. Finally, the\npersuasion will show up in users’ phones to encourage more mindful usage.\nperformance [9, 26]), physical well-being (resulting in decreased\nsleep and activity levels [22, 66, 124, 125]), and mental health (man-\nifesting as anxiety and depression [37, 39, 127]). Many individuals\nhave recognized their problematic smartphone usage and sought\nto reduce their over-reliance on smartphones [42, 58].\nA plethora of academic research and commercial products pro-\nvide just-in-time (JIT) smartphone use interventions, intervening\nprecisely when problematic use occurs [90]. These interventions\nfall into four categories based on their enforcement levels: (1) Self-\nmonitoring: offering insights on phone usage patterns via notifica-\ntion or visualization, enhancing user awareness about their smart-\nphone habits [5, 23, 57, 123]; (2) Reminders: countering immediate\nphone indulgence and promoting self-reflection through pop-up no-\ntifications [42, 98]; (3) Interaction friction: raising the effort needed\nto use the phone, thereby reducing its allure by introducing tasks\nlike typing [93, 99, 128]; (4) Lockout: disabling the user’s phone\naccess for a specified duration [54, 55, 58, 72]. However, there are a\nfew gaps among existing intervention techniques.\nFirst, existing methods are limited to strike a balance between\neffective intervention engagement and good usability [85]. The first\ntwo categories rely on the user’s self-control and are easily ignored,\nleading to low engagement and limited effectiveness [42, 57, 123].\nThe other two types are more restrictive, often causing user frustra-\ntion due to reduced usability across different contexts [54]. Our ap-\nproach utilizes reminder-based interventions with persuasive con-\ntent to encourage reduced smartphone usage. Persuasion, typically\nthrough natural language to influence people’s thoughts and behav-\nior [20, 108, 114], is more effective with diverse and context-specific\ncontent [50, 51], as supported by recent studies highlighting the suc-\ncess of personalized [18, 36, 50, 60], context-aware [53, 58, 107, 116]\ninterventions. However, most current reminders use repetitive,\ntemplate-based content, reducing efficacy [8, 46, 128]. To overcome\nthis, we employ Large Language Models (LLMs) [19, 94] to gener-\nate varied persuasive content. LLMs’ reasoning ability provides a\npromising solution to infer users’ current activities based on contex-\ntual information collected from smartphone sensors, such as time\nand location [16, 28, 56], enabling the creation of more relevant and\neffective intervention language.\nSecond, we identified the opportunity to leverage mental states\nassociated with problematic smartphone use, an essential aspect\nof user contexts. While some current interventions use context-\nbased strategies, like triggering interventions at specific times and\nlocations [53, 58], they tend to focus mainly on external physical\ncontexts, neglecting internal mental factors. Mental factors like\nstress and negative emotions are increasingly recognized as one\nkey factor leading to problematic smartphone use [27, 78, 120, 121].\nHowever, existing studies primarily address prolonged mental states\nrather than momentary contexts. Our study aims to bridge this gap\nby integrating an understanding of in-the-moment mental states\ninto the intervention framework. We believe that a more holistic\napproach, considering both the physical and mental contexts, could\nenhance intervention effectiveness.\nTo address these gaps, we first conducted a Wizard-of-Oz study\n(N=12), followed by an interview study (N=10) to better understand\nusers’ mental states during problematic phone usage. Focusing\non habitual usage ( i.e., ritualistic behavior, without a clear goal,\nsuch as passive social media content consumption) [ 43, 109], we\nsummarized three major mental states to address: boredom, stress,\nand inertia. Building on the Dual Systems Theory [44] and the ERG\n(Existence, Relatedness, and Growth) Theory [15], we proposed four\npersuasion strategies: 1) understanding, 2) comforting, 3) evoking,\nand 4) scaffolding habits.\nMindShift CHI ’24, May 11–16, 2024, Honolulu, HI, USA\nIntegrating our persuasion strategies with LLMs, we designed\nand implemented MindShift (Figure 1), a new JIT intervention tech-\nnique that can provide dynamic, personalized persuasion content\nbased on user contexts. MindShift leverages LLMs’ strong capabil-\nity in commonsense comprehension and natural language gener-\nation [19, 83] to generate proper and effective persuasive content\nbased on real-time information (phone usage behavior, physical\ncontexts, and mental states) and long-term user states (user goals\nand habits), guided by persuasion strategies we designed.\nTo evaluate MindShift’s effectiveness, we conducted a 5-week\nfield experiment deploying our intervention to 25 participants. We\ncompared MindShift against the baseline, a basic notification-based\nintervention that asked users to reflect on and report the purpose\nof their smartphone usage. Moreover, to assess the effect of the\nmental states factor, we compared MindShift against a simplified\nversion, MindShift-Simple, that excludes the mental states factor\nfrom the LLM-based content generation.\nOur study results indicate that MindShift and MindShift-Simple\noutperformed the baseline method on the intervention acceptance\nrate by 22.5% and 17.8%, respectively, with statistical significance.\nThey also significantly reduce overall app opening frequency by\n12.1% and 14.4% and app usage duration by 9.8% and 2.4%. Com-\nparing MindShift and MindShift-Simple, including the mental state\nfactor enhances the persuasion acceptance rate by 8.1% with sta-\ntistical significance. Moreover, the subjective report data shows\nthat participants using MindShift and MindShift-Simple experience\na significant reduction in smartphone addiction scale (SAS) score\n(34.7% and 25.8% respectively) and an increase in the self-efficacy\nscale score (10.7% and 10.4% respectively).\nOur paper makes the following contributions:\n(1) We conducted a Wizard-of-Oz study and an interview study,\nuncovering three major mental states (boredom, stress, and\ninertia) during habitual smartphone use, which led us to de-\nsign four persuasion strategies grounded in the Dual Systems\nTheory and the ERG Theory: Understanding, Comforting,\nEvoking, and Scaffolding Habits.\n(2) We created MindShift, a novel persuasive intervention tech-\nnique leveraging LLMs to generate dynamic and personal-\nized persuasion content based on users’ phone usage behav-\nior, physical contexts, mental states, goals and habits, and\nappropriate persuasion strategies.\n(3) We conducted a field experiment by deploying MindShift,\ndemonstrating significant improvements in intervention ac-\nceptance rates and reduced smartphone use by Mindshift.\nUsers’ subjective feedback also corroborated these observa-\ntions, validating the effectiveness of MindShift.\n2 RELATED WORK\nIn this section, we define problematic smartphone use and habitual\nsmartphone use (Sec. 2.1), explore the reasons behind engagement\nin problematic smartphone use (Sec. 2.2). We then briefly overview\nexisting intervention techniques (Sec. 2.3). Finally, close to our\nwork, we introduce behavior change persuasion techniques and\ntheir relationship with the emergence of LLMs (Sec. 2.4).\n2.1 Problematic Smartphone Use\nMany studies have explored the definition of problematic smart-\nphone use, which can be broadly classified into two categories. The\nfirst category defines whether users exhibit addictive behaviors\ntoward their phones. Some studies assess addictive behavior by\nmeasuring the level of user dependence on smartphones through\nquestionnaires, such as the Smartphone Addiction Scale (SAS) and\nthe Smartphone Addiction Inventory (SPAI) [64, 70]. The second\ncategory defines whether a specific instance of phone use is prob-\nlematic. Growing research suggests that problematic smartphone\nuse is determined not only by excessive use but also by the purpose\nand content of use in specific situations [ 39, 74, 75, 76, 102, 104].\nStudies have indicated that phone use purposes can be categorized\ninto (1) habitual use that is performed unconsciously and ritualis-\ntically usually without a specific goal [101], and (2) instrumental\nuse with a specific task or goal in mind [ 76]. Existing research\nsuggests that habitual use should be the primary target for inter-\nvention [76, 89, 101]. In this paper, we use SAS to measure users’\nlevel of addictive smartphone usage. We also distinguish users’\nphone use purpose and focus on intervening habitual use.\n2.2 Understanding Problematic Smartphone\nUse through A Dual Systems Perspective\nUnderstanding what leads to problematic smartphone use is es-\nsential for the design of effective persuasion strategies. The Dual\nSystems Theory [44, 49] has been used to explain the phone usage\npatterns [101]. This theory divides human cognitive activities into\ntwo types: System 1 (fast, intuitive, unconscious) and System 2\n(slow, analytical, conscious). Problematic smartphone use is typi-\ncally driven by System 1 [34], as it mainly involves unconscious,\nrapid responses and is easy to be guided by instant gratification.\nResearch suggests that two key factors contribute to the failure of\nusers to act on their goals: (1) limited ability of System 2 control;\nand (2) fluctuations of System 2 caused by emotional states and\nfatigue [78]. For the first factor, a growing amount of research sug-\ngests that the limited ability of control is attributed more to apps’\ndeliberate design than to users themselves [11, 33, 75, 87, 106]. Re-\ncent work identifies types of attention-capture deceptive designs in\ndigital interfaces, such as neverending autoplay and infinite scroll\n[87]. For the second factor, some findings suggest that mental states\nplay a significant role in habitual smartphone use [101, 120, 121]\nand previous research has identified external contexts, such as\nsocial awkwardness [104, 118], that may trigger the habitual use.\nHowever, there is limited research exploring what specific kinds\nof users’ in-the-moment mental states behind habitual use. In our\nwork, we pinpoint the major mental states linked to habitual use\nand propose corresponding persuasion strategies.\n2.3 Problematic Smartphone Use Intervention\nExisting problematic smartphone use intervention techniques fall\ninto two groups: external interventions that monitor and limit use,\nand internal interventions that change the interface itself.\nExternal intervention can be roughly divided into four categories\nbased on enforcement level: The first category provides users with\ninformation about their behavior such as visualization of usage [8,\n23, 42, 57, 73, 77, 92, 97, 123], requiring users to view it themselves\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Wu et al.\nto increase awareness of phone usage. The second actively sends\nreminders to users to provoke their reflection such as reminding\nusers of their daily goals [42, 79], informing their usage time [8]\nor the number of opens [105]. This category presents text to users\nand, therefore, serves as a persuasion. The third involves increasing\nthe difficulty of using the phone and intentionally slowing down\nuser interactions to suppress the desire to use it, such as requiring\nusers to enter random numbers or type self-reflective text [99, 128]\nand keeping the phone vibrating continuously [93]. The fourth is\nparticularly forceful by directly locking the users’ apps or phones\nfor a specific duration [7, 54, 58]. There are concerns about these\nmethods’ ability to strike an optimal balance between usability and\neffectiveness [85].\nInternal intervention involves redesigning app interfaces to coun-\nteract attention-capturing deceptive designs [87]. For example, in-\ncreasing user awareness of time spent through reading history\nlabels [11] and specific color change [ 86], eliminating the addic-\ntive design of infinite scroll through removing [79] and adjusting\nthe newsfeed [57, 106, 131], decreasing the guilty pleasure recom-\nmendations through using adaptable commitment interface [ 74]\nand redesigning search interface [86]. Compared to external inter-\nvention, internal intervention can better balance effectiveness and\nlong-term experience [106, 131]. However, these internal methods\noften require third-party development, as large companies rarely\nadopt such designs themselves due to financial interests [33]. This\nnecessitates additional development costs and the proposed design\nis typically tailored for a single app, making it hard to apply broadly.\nTherefore, we hope to create a universal external intervention,\nusing the form of reminders to ensure usability while boosting\nintervention effectiveness through personalized persuasion.\n2.4 Persuasion for User Behavior Change and\nLarge Language Models\nPersuasion is a psychological approach designed to influence atti-\ntudes, beliefs, or behaviors [ 20]. Language is the most common\nmeans of persuasion [ 108, 114], and leverages facts, emotional\nappeals, and so on to achieve its goal. Its effectiveness has been\nshown in multiple fields, such as advertising to encourage con-\nsumers to buy a product [ 13], supporting mental health such as\ncoping with stress [89, 96], and managing physical health such as\nreducing snacking behavior [50]. For smartphone use intervention,\npersuasion usually appears as reminders, such as leveraging the\nuser’s usage time in a template format [ 8, 46], or some thought-\nprovoking statements [ 128]. Prior work has suggested that per-\nsonalizing content can enhance persuasion effectiveness such as\nreducing snacks [50, 51]. Also, varying the timing and content of\ninterventions, sometimes even randomly, can improve effective-\nness. In contrast, static interventions tend to lose influence over\ntime [60].\nThe advent of Large Language Models (LLMs), like ChatGPT[94]\nand PaLM[19], has made vast progress in personalized and diverse\ncontent generation. Recent studies have explored various health\napplications supported by LLMs, such as health information seek-\ning [80, 129, 130], mental health support [ 61, 65, 126], personal\nhealth coaching [88, 122], health education [62], and public health\ninterventions [48]. These applications showcase LLMs’ capabilities\nin knowledge delivery and emotional support. Compared to them,\nour study further explores LLMs for just-in-time behavior change\nand intervention, beyond information presentation.\n3 MENTAL STATES OF HABITUAL\nSMARTPHONE USE AND PERSUASION\nSTRATEGIES\nTo comprehend the mental states of users’ smartphone use and\nguide our intervention system design, we initiated a Wizard-of-\nOz (WoZ) study, followed by a semi-structured interview study\n(Sec. 3.1). We summarized the main takeaways in Sec. 3.2. Based\non theories and our findings, we devised four persuasion strategies\nand their implementation under different mental states (Sec. 3.3).\n3.1 Exploratory Wizard-of-Oz &\nSemi-structured Interview Studies\nTo identify particular smartphone usage behaviors requiring tar-\ngeted interventions, we first recruited 12 end-users (6 females and\n6 males, aged 18-28) and conducted a 5-day WoZ study in the wild.\nThe findings suggested ideas for persuasion content design. For\ndeeper insights into participants’ mental states and concrete inter-\nvention design materials, we recruited another group of 10 users (5\nfemales and 5 males, aged 18-29) and conducted a semi-structured\ninterview study1. Both studies are approved by the institution’s\nIRB. Our studies focused on young adults who have been reported\nto have the most severe problematic smartphone use issues [67, 84].\nHowever, we do recognize that our sampling could limit the gener-\nalizability of our findings. We discuss this as a limitation in Sec. 8.\n3.1.1 Wizard-of-Oz Study. We developed a chatbot system for\nsmartphones that tracks user app activity. First, we asked partici-\npants to select apps for intervention, adding them to a blacklist. The\nchatbot then would send persuasive messages to the participants\nupon opening a blacklisted app.\nTo reduce the observation effect, participants were told that it\nwas an automatic chatbot instead of a human [52]. In reality, when\nparticipants opened a blacklisted app, a human experimenter would\nreceive an email notification. Based on smartphone usage duration\nand frequency (see the detection method in Sec. 5), the experimenter\ndesigned and delivered persuasive messages. Inspired by existing\nliterature on persuasion design [1, 14, 35], our messages fell into\n4 types (see examples in Table 4 in Appendix): (1) usage notice,\ntelling participants their usage data such as the accumulated usage\ntime today and time since last use, (2) practical guidance, asking\nparticipants’ goals today and suggesting tasks instead of smart-\nphone use, (3) encouragement, praising and cheering participants\nto keep smartphones away, and (4) deterrent, alarming participants\nthe consequences of using smartphones such as task delay and\nadmonishing them to stop.\nEvery evening, researchers conducted a brief 15-minute online\ninterview in person with each participant, structured around four\nquestions: (1) What was your overall experience of using the chat-\nbot? How did it change your smartphone usage? (2) Why were\n1Since the two studies are close in time, we choose a separate set of participants\nfor semi-structured interviews to avoid the impact of intervention in the WoZ study.\nMindShift CHI ’24, May 11–16, 2024, Honolulu, HI, USA\nyou using your phone at a particular time? (3) What were your\nreactions to the persuasive message, and why? (4) How did you like\nthe persuasive message? How can it be improved? At the study’s\nconclusion, we informed participants that the chatbot was actually\noperated by a human experimenter at the back end.\nAll persuasive messages and participants’ responses, along with\ntheir sending times, are documented. Daily interviews were audio-\nrecorded and transcribed. The recorded data and transcriptions\nwere independently reviewed by three researchers, who coded them\nbased on two main themes: types of smartphone use for question (2)\nand factors influencing persuasion effectiveness for questions (1),\n(3), and (4). Subsequently, the researchers convened to discuss the\ncodes until a consensus was reached. Following that, a thorough\nreview of all transcriptions was conducted to ensure the accuracy\nof the coding.\n3.1.2 Semi-structured Interview Study. Our WoZ study provided\ninsights into participants’ problematic use behavior and reactions\ntowards persuasion. To obtain a deeper understanding of the user’s\nmental states during phone use, we conducted a semi-structured\ninterview study with another participant group. We asked partic-\nipants to recollect instances of problematic smartphone use. Our\ninterview started with the question: “When would you want to use\nan intervention app to limit your smartphone use?” We then sought\ndetails about the scenario (e.g., time, place, and concurrent activi-\nties) and user behaviors and reactions (e.g., usage duration, feelings,\nand reflections). Next, we asked participants to share their mental\nstates during those instances. We asked questions: “Why do you\nuse your phone even though you think you should not? What’s your\nmental state behind these reasons?” We followed the participants’\nlead during the interview.\nAll interviews were audio recorded and transcribed. Three re-\nsearchers independently examined the transcriptions and coded\nthe mental states in different smartphone use cases and contexts.\nThen they met and discussed the codes until reaching a consensus.\nTo ensure coding accuracy, they went through all transcriptions\none more time.\n3.2 Main Takeaways about Problematic\nSmartphone Use\nWe summarized our main takeaways from the WoZ study and the\ninterview study below. Table 5 in the Appendix summarizes our\nfindings with participants’ quotes. Table 1 summarizes the findings\nabout mental states in Takeaway 3○and Takeaway 4○.\nTakeaway 1○Interventions for problematic smartphone\nuse should target habitual usage. Our WoZ study delineated\ntwo primary types of smartphone usage: instrumental and habitual,\nconsistent with prior research categorization [76]. We found that\nonly habitual smartphone use warrants intervention. Interventions\nduring instrumental use often led to user dissatisfaction. Notably,\nrelaxation emerged as a crucial form of instrumental use, where\nparticipants deliberately used their phones to unwind or reward\nthemselves after intense work or study. Intervening at such times\nwas considered intrusive and inappropriate. The finding aligns with\nthe Dual Systems Theory. In smartphone interactions, instrumental\nuse relies on conscious decision-making (System 2), while habitual\nuse is more instinctive (System 1). Hence, interventions should\nprimarily target habitual use, which is also supported by earlier\nstudies [76].\nTakeaway 2○The effectiveness of interventions depends\non the alignment with users’ mental states, personal goals,\nand contextual information . This is consistent with the litera-\nture, suggesting that a shift away from System 2 is due to emotional\nfluctuations and the absence of defined goals and intentions [78].\nWe experimented with different persuasive message content during\nour WoZ study. We found that when we incorporated users’ mental\nstates as a factor, which was inferred by their physical contexts and\napp usage patterns, into generating persuasive message content,\nparticipants were more willing to accept the intervention. Further-\nmore, highlighting users’ personal goals enhanced intervention\neffectiveness. For instance, sending messages like, “When you find\nyourself with idle time, consider engaging in meaningful activities\nsuch as reading, writing, or drawing ” proved effective when users\nwere in an idle state and had a goal for self-improvement. Our find-\nings are supported by prior studies linking habitual smartphone\nuse to specific mental states [4, 12].\nTakeaway 3○ Semi-structured interviews revealed three\nprimary mental states connected to habitual smartphone use:\nboredom, stress, and inertia.\n• Boredom is an affective state characterized by low arousal and\ndissatisfaction due to insufficient stimulation [30, 82]. The WoZ\nand interview studies identified common scenarios leading to\nboredom: (1) when the task at hand is too simple, lacking a\nbalance between skill and challenge, such as\"doing simple assign-\nments light on cognitive engagement\" (S3)2 , (2) lack of interest in\nthe current activity, such as \"completing assignments is to relieve\na burden, instead of reaching achievement\" (S6), and (3) devoid\nof any engaging activities during idle moments, such as \"after\nreturning to home\" when is \"not yet time to sleep\" (S8).\n• Stress refers to cognitive and behavioral reactions to unpre-\ndictable and unmanageable stimuli [59]. Participants frequently\nuse smartphones because they experience (1) heightened anxiety\nwhen work demands exceed their abilities, such as\"having a chal-\nlenging bug to locate when doing programming assignment\" (S3) or\n\"work not progressing well\" (S9) and (2) uncertainty about whether\nsomething would have a positive outcome, such as \"not sure if\ncan get a job offer\" (S10). This aligns with increasing evidence\nthat links smartphone use to perceived stress [17, 110, 119].\n• Inertia, in our context, refers to a psychological resistance that\nmakes users reluctant to change their current activity state. It\nis similar to the idea illustrated by literature such as emotional\ninertia [63] or decision-making inertia [2]. Participants stated\nthey commonly used their phones habitually to avoid changing\ninto a new activity state from an idle state, \"checking the phone\nbefore starting to do assignment\" (S1) or \"shifting from a relaxed\nstate to a focused state\" (S2). Unlike stress or boredom, inertia\ndoes not elicit overt negative emotions but impedes the shift to\nthe next task.\nTakeaway 4○Engaging vs. Not Engaging in Activities (Ta-\nble 1). We further noticed two nuanced categories within mental\n2This is the serial number of the participant in the semi-structured interview\nstudy.\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Wu et al.\nBoredom\nEngaging in Activities Not Engaging in Activities\nUsers find current tasks boring, lack interest, and struggle to concentrate.\nThis could be due to the task lacking challenges, not being sufficiently\nengaging, having high repetition, and not aligning with the user’s\ngenuine interests and desires.\nUsers feel bored with daily living in general, lack passion, and have no\nenthusiasm for engaging in activities. This might be because they have\nnothing to do, don’t know how to pass the time, lack excitement in life,\nand feel that living is meaningless.\nStress\nEngaging in Activities Not Engaging in Activities\nUsers feel stressed about current tasks due to challenges posed by the\nenvironment, which deplete their resources and result in feelings of\ntension and unhappiness. This might be due to the abundance, diffi-\nculty, and urgency of tasks, causing users to feel anxious, fatigued, and\nlacking confidence in their abilities, leading to a pessimistic view of the\noutcomes.\nUsers feel stressed in the face of daily living and challenges from the\nenvironment that deplete their resources, making them feel tense and\nunhappy. This might be due to setbacks and unexpected events in life\nthat users struggle to adapt to, leading to a pessimistic outlook on the\nfuture.\nInertia\nEngaging in Activities Not Engaging in Activities\nUsers find it difficult to transition from their current state to start the\nnext activity, but without explicit negative emotions. This might be\ndue to procrastination has become a habit, and there’s insufficient\nmotivation for the next activity.\nUsers indulge in idle inertia, but without specific negative emotions.\nThis might be due to idling around has become a habit, and there’s no\nmotivation to organize new activities.\nOthers\nBeyond the scope of the current paper.\nTable 1: Summary of Users’ Mental States behind Habitual Smartphone Use.\nstates. The first category (“engaging in activities”) denotes that users\nhave activities to complete while habitually using smartphones. Par-\nticipants either got distracted from the ongoing boring or stressful\nactivities (e.g., \"I find myself instinctively reaching for my phone in\nsearch of mental stimulation when doing simple assignments light on\ncognitive engagement\" (S3)) or procrastinated to face the upcoming\nactivities (e.g., \"I was reluctant to start handling this challenging\nwork that I scrolled my phone screen anxiously\" (S2)). In contrast,\nthe second category (“not engaging in activities”) means users have\nno schedule or don’t know what to do while using smartphones\nhabitually (e.g., \"After getting off work and returning home, I collapse\non the sofa and binge-watch Tiktok for one to two hours\" (S9)). Differ-\nentiating activity engagement states and combining with the three\nidentified mental states lead to six granular categories of habitual\nsmartphone use, making the persuasion strategies design more\nsituated to users’ scenarios. For users engaging in activities, the\npersuasion not only aims to stop them from smartphone use but\nalso to encourage them to either continue or initiate their activities.\n3.3 Persuasion Strategies Design\nBased on the takeaways and inspired by the Dual Systems The-\nory and the Existence, Relatedness, and Growth (ERG) theory,\nwe proposed four distinct persuasion strategies: Understanding,\nComforting, Evoking, and Scaffolding Habits. Developing from\nMaslow’s Hierarchy of Needs, the ERG theory further summarizes\nhuman motivation into three levels: (i) the physiological and safety\nbasic needs for existence, (ii) the social needs for feeling related and\naccepted, and (iii) the need to grow and self-actualize. The theory\nhas been applied to workplaces to increase productivity and job\nsatisfaction [10, 15].\nSome of our takeaways align with these theories. For example,\nTakeaway 1○aligns with the Dual Systems Theory and suggests\nthat to avoid habitual smartphone use out of instinctive System 1, it\nis necessary to cultivate enough motivation to maintain conscious\nbut difficult System 2. Moreover, Takeaway 2○shows that persua-\nsive messages relieving mental states and reminding personal goals\nare effective, which is consistent with the human motivation of\nrelatedness and growth outlined in the ERG theory.\nAccordingly, we map strategies to the relatedness level and\ngrowth level of the ERG theory to arouse users’ motivation for\nSystem 2 (Figure 2). The existence level concerning physiological\nand safety needs is not included in our theoretical framework. At\nthe level of relatedness, Understanding and Comforting aim to\nempathize with users’ emotions, offering support and empowering\nusers to manage System 2. At the growth level, Evoking reminds\nusers of their personal development goals, andScaffolding Habits\nguides them in replacing habitual smartphone use with activities\nconducive to self-fulfillment, thereby turning awareness into action.\nThen, we map 4 strategies to 3×2 mental states in Figure 3.\n3.3.1 Understanding. Understanding is a critical strategy to mo-\ntivate users at the Relatedness level. Past literature suggests that\nseeking understanding is a coping mechanism [24], and chatbots’\nempathetic expressions are favored over emotionally neutral ad-\nvice [71]. Therefore, Understanding covers all mental states. This\nexample shows how we integrate understanding into the persuasive\ncontent intervention: \"Hi, I know that sometimes you may feel bored\nand lacking interest. It’s okay, this is a very normal feeling. Everyone\ngoes through such times. \"\n3.3.2 Comforting. Comforting aims to comfort users who are ex-\nperiencing emotional fluctuations, which cause them to shift away\nfrom System 2. Prior studies suggest that coping with boredom\nshould focus on meaningfulness [ 91]. For example, we design a\npersuasive message to say \"Hey, I know some things might seem a\nMindShift CHI ’24, May 11–16, 2024, Honolulu, HI, USA\nFigure 2: Mapping of Persuasion Strategies to the ERG Theory\n(Existence, Relatedness, and Growth) and the Dual Systems\nTheory. According to the Dual Systems Theory, there is a\ncompetitive relationship between System 1 (habitual smart-\nphone use) and System 2 (meaningful activity), much like be-\ning placed on a scale. To make System 2 heavier than System\n1, weights are added—Relatedness needs and Growth needs\n(the second and third levels of ERG Theory). To support users’\nRelatedness needs, we design two persuasion strategies: Un-\nderstanding and Comforting. To motivate Growth needs, we\ndesign two other persuasion strategies: Evoking and Scaffold-\ning Habits.\nbit boring, but sometimes we need to find the fun in them. Have you\never thought that completing this task would bring you closer to your\ngoals?\" In addition, encouragement, humor, acceptance, and wish-\nful thinking [24] can be used to cope with stress by lightening the\nuncontrollable and unpredictable nature of stressors. For example,\n\"Don’t worry, you have the capability to complete the task! Believe in\nyourself, and the outcome will pleasantly surprise you. \" In the state\nof inertia without explicit negative emotions, Comforting is not\nemployed.\n3.3.3 Evoking. Evoking personal goals is a compelling, persuasive\ntechnique based on the WoZ study. Literature suggests that goals\nand values are important for people to sustain System 2 [78] and\nare closely related to growth motivation. Thus, Evoking considers\nusers’ goals (e.g., getting high scores in exams, achieving academic\nsuccess) for designing persuasive strategies. For example, \"Hi! I\nknow you want to play with your phone, but completing tasks is\ncrucial for your IELTS! Keep going, and you’re one step closer to a\nhigh score!\" This strategy is applied only to scenarios where users\nare engaging in activities. Goals are arguments used to encourage\nthem to complete or initiate their tasks. In scenarios where users are\nnot engaging in activities, Scaffolding Habits assumes the function\nof Evoking by recommending activities that correspond with users’\ngoals, as stated below.\n3.3.4 Scaffolding Habits. Last, we encourage users to develop alter-\nnative beneficial habits to habitual smartphone use, aligning with\ntheir personal value and growth need [78, 101]. By pre-identifying\nusers’ preferred habits and considering variables like location and\ntime of habitual smartphone use, we suggest appropriate substi-\ntutes to assist users in Scaffolding Habits . For example, \"Hi, why\nnot use this moment to memorize vocabulary instead of using your\nphone? It can help you learn a language and achieve your goals faster!\"\nScaffolding Habits covers all mental states.\n4 MINDSHIFT DESIGN\nBuilding on top of the persuasion strategies we propose in the pre-\nvious section, we introduce the design of our intervention system:\ngenerating persuasive content (what content to intervene with,\nSec. 4.1), interaction flow (how to intervene, Sec. 4.2), and interven-\ntion timing (when to intervene, Sec. 4.3).\n4.1 What Content to Intervene with:\nLLM-Powered Persuasive Content\nGeneration\nWe first delved into the importance of context and mental states\nin persuasion content generation (Sec. 4.1.1). After establishing\nthe significance of context and mental states, we explored how\nthese elements can be intricately integrated into the prompt design\n(Sec. 4.1.2).\n4.1.1 Context and Mental States in Generating Persuasive Content.\nAs suggested in theTakeaway 2○in Sec. 3.2, the effectiveness of in-\nterventions also depends on contextual information. We presented\na test case with examples to demonstrate the impact of context\nand mental states on content generation. In this case, we first con-\nstructed a typical college student’s context, including time (at late\nnight 00:36 AM), location (in the dorm), and phone usage data (5\nmins since the last habitual usage and 10 mins current habitual\nusage). We then outlined the user’s assigned mental state (stressed\n- engaging in activities), the user’s goals (growing research skills,\nstaying healthy) and habits (enjoying outdoor activities), and the\ncorresponding four strategies based on Figure 3.\nDiffering in context and mental state inclusion, we used GPT-3.5\nto generate four sets of persuasive content examples. Table 2 lists the\nexamples of GPT-3.5’s outputs, demonstrating that both contextual\ninformation and mental state guidance improve content quality.\nContextual data empowers GPT to tailor its outputs to the user’s\ncurrent situation, including more poetic sentence phrases such as\n\"enjoy the night sky outside the window\" or contextual information\nsuch as \"You’re unstoppable, even at 00:36 AM\" . Adding the mental\nstate guidance enhances GPT’s ability to assist users in managing\ntheir negative emotions, including empathetic messages such as\n\"you are not alone\" and encouraging phrases such as \"be closer to\ncompleting that great research job\" .\n4.1.2 Prompt Design. We constructed four important prompt input\nfactors and fed them to GPT to generate high-quality and persuasive\ncontent. As illustrated by purple text in Figure 4, four factors are\narranged in a sequence from 1 to 4. We then concatenated them to\nbuild a complete prompt as the input to LLMs to generate persuasive\ncontent. We tested both GPT-3.5 and GPT-4 and chose to adopt\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Wu et al.\nFigure 3: Summary of Persuasion Strategies under Different Mental States. In the table, each color denotes the corresponding\npersuasion strategy applicable to this scenario.\nTable 2: Examples of Generating Persuasive Content with A Test Case Study on Different Context and Mental State Combi-\nnations. The letters in parentheses at the end of the sentences indicate the strategies used during sentence generation: U for\nUnderstanding, C for Comforting, E for Evoking, S for Scaffolding Habits, and N for No Strategy\nWith Mental State Without Mental State\nWith Context\n1. It’s already 00:36, staying up late is stressful, you’re\nnot alone, we all feel this way. (U)\n2. Hey, you’ve got this! Embrace the challenge with a\nsmile. You’re unstoppable, even at 00:36 AM! (C)\n3. Think about that research article you’re about to\ncomplete, turn the stress into motivation! (E)\n4. Try putting down your phone, enjoy the night sky\noutside the window, relax your eyes. (S)\n1. It’s already 00:36, your phone should probably rest\ntoo. (N)\n2. At this time in the dorm, how about closing your\neyes and resting? (N)\n3. You’ve already enjoyed 10 minutes of the digital\nworld. (N)\n4. Just 5 minutes ago, we just said goodbye, meeting\nagain? (N)\nWithout Context\n1. Understand your anxiety, it’s normal, accept your\nemotions. (U)\n2. Relax, each task is a stepping stone to achievement,\nbe optimistic. (C)\n3. Keep going, you will be closer to completing that\ngreat research job. (E)\n4. How about relaxing in a different way, look far\naway, let your eyes rest too. (S)\n1. Friend, your phone might need a rest, and so do\nyour eyes! (N)\n2. Try putting down your phone, and take a look at\nthe outdoor night views. (N)\n3. The phone in your hand is not the world, the real\nfun is around you! (N)\n4. Every time you put down your phone, it’s an op-\nportunity to add points to life! (N)\nGPT-3.5 as our target LLM to strike a balance between the content\ngeneration quality and the speed3.\n3GPT-4 introduces a long lag and negatively impacts user experience. Moreover,\nas we introduce below, the prompts we used as the input for GPT-3.5 include general\ninformation that is not individually identifiable. However, we do acknowledge the\nprivacy risk of our method. We will have more discussion in Sec. 8\nWe lay out the details about how we designed the prompt below:\n(1) Task Setup: As shown in the left top box in the “Input Prompt\nto LLM” in Figure 4, Task setup includes <Background> module,\nproviding GPT-3.5 with the global instructions.\n(2) Description of the Current Contexts : To make each gener-\nated content contextually relevant and personalized, it is necessary\nMindShift CHI ’24, May 11–16, 2024, Honolulu, HI, USA\nFigure 4: Prompt Templates Used to Generate Persuasive Content with GPT-3.5. The word slots (in the top box) represent\ndifferent categories of information to be filled in based on the user’s current situation. The color indicates the mapping between\nthe slots and the input prompt. The small words under each slot explain the source of the content. The input prompt consists\nof four parts: (1) Task Setup; (2) Description of the Current Contexts; (3) Prompt Optimization (to improve language quality\nand reduce harmful content); and (4) Description of Persuasion Strategy (as introduced in Sec. 3 and Figure 3). The LLM output\nshows the persuasion example of four strategies when the user’s mental state is “stressed, engaging in an activity”.\nto describe the user’s current contexts (see the left bottom box in\nthe “Input Prompt to LLM” in Figure 4). This part includes three\nmodules: (a) The <User Data> module describes the user’s real-\ntime physical context, including the current time, location, habitual\nphone usage duration, and the time elapsed since the last habitual\nphone check. This is collected through phone sensors, see more de-\ntails in Sec. 5.1. (b) The <User Mental State> module includes users’\ninput from their devices regarding negative emotions and activities.\nThe prompt for this module is selected from the mental state defi-\nnition (Table 1). This is collected through real-time self-report, see\nSec. 4.2. (c) Finally, the <User Goals> module describes what the\nuser values and plays a crucial role in the generation of Evoking\nstrategies. Specific user goals are collected during the initialization\n(Step 0 in Figure 5). This is collected through the initial setup, see\nSec. 4.2. The elements mentioned above are represented as word\nslots (enclosed in brackets in the input prompt), where the users’\nactual context information can be inserted.\n(3) Prompt Optimization: To improve the GPT’s content qual-\nity and effectiveness, we carefully crafted the prompt according to\nOpenAI’s official guidelines [95]. Sometimes LLMs can generate\nharmful, offensive, or biased texts [38, 132]. We employed an itera-\ntive prompt design process to ensure that the persuasive content\nis appropriate. Initially, one researcher created initial prompts and\ngenerated content using GPT-3.5, for six mental states (Figure 3)\nwith five iterations each. Subsequently, two other researchers rated\nthe satisfaction level of the generated content (scoring from 1 to\n5), iterating until average satisfaction exceeded 4 to create con-\ntent that is concise, appropriate, and engaging, while also aligned\nwith our persuasive strategy. Through this process, we addressed\nsome issues with LLM-generated content, such as gender-biased\nexpressions and deviations from human preferences (like being\noverly exaggerated or stressful) by adding an additional <Notes>\nsection to instruct LLMs’ generation. We also took steps to prevent\nhallucinations by avoiding certain real-world fact-related prompt\nstatements that LLMs can easily make mistakes. By specifying the\nneed to consider current activities in the <output format>, we’ve\nmade the outputs more contextually relevant. We note that this\nprocess cannot fully address the ethical concerns, which we fur-\nther discuss in Sec. 8.3.3. Our final optimization prompt, shown\nin the middle top box in Figure 4, includes two modules: (a) The\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Wu et al.\nFigure 5: Interaction Flow. Users first complete the global settings for their value and app list (Step 0). When opening a\nblack-listed app, users need to first self-report their phone usage intent (Step 1). If the intent is habitual use, the app asks them\nto report their current mental state (Step 2). After that, a corresponding persuasion shows (Step 3).\n<Notes> module clarifies restrictions; (b) The <Output Format>\nmodule guarantees the correct output format.\n(4) Description of Persuasion Strategy : To ensure each gen-\nerated content aligned with our proposed strategies, we provide a\nshort description of each strategy based on our design in Sec. 3 and\nFigure 3, as indicated by the middle bottom box in Figure 4. Based\non users’ in-the-moment mental states, we will select the corre-\nsponding strategies. Note that for the scaffolding habits strategy,\nwe also input a habit selected from users’ initialization.\n4.2 How to Intervene: Interaction Flow\nThis section outlines the design of the interaction flow in our appli-\ncation. Our interaction process needs to achieve three functions: (1)\ncollect users’ phone usage intent to identify habitual use, (2) obtain\nnecessary information for prompt construction, and (3) display the\ngenerated content.\nFollowing Takeaway 1○in Sec. 3.2, interventions should be tar-\ngeted at habitual usage. Since automatic detection methods are\nunreliable (discussed further in Sec. 8), we ask users to self-report,\nand the system only triggers intervention when the user reports\nhabitual use. In our prompt design in Sec. 4.1.2, we need two cate-\ngories of information from users: their goals and habits, and their\nmental state. Goals and habits tend to be stable. So we integrated\nthem into the app’s settings page, and users could adjust them as\nneeded. Mental states, however, are more dynamic. Therefore, we\ncaptured them through participants’ self-reporting. In summary,\neach intervention episode includes three steps: (Step 1) the user\nreports their usage intent, (Step 2) the mental state, and (Step 3) the\ncorresponding generated content is displayed, as shown in Fig. 5.\nOur final design is as follows:\nStep 0: Initialization . When initiating the MindShift app, we\nask users to complete two global settings. The first is to set their\nvalues in four categories: career, health, life, and hobbies, detailing\ntheir goals and habits in each. This process serves two purposes:\nfirst, it provides the necessary goals for our Evoking strategy; sec-\nond, it enables the creation of personalized habits in the Scaffolding\nHabits strategy. The second is to set a blacklist of apps. Launching\napps from this list will trigger intervention.\nStep 1: Intent report . Interventions are only necessary when\nusers habitually use their phones (Takeaway 1○). To collect users’\nintents, we employ a self-reporting approach. Every time a black-\nlisted app is first opened during an unlock session, users choose\nfrom three options: \"Habitual use\", \"Instrumental use\", and \"Relax-\nation\". Only when users select \"Habitual use\", the intervention will\nproceed. Automatically detecting all use is beyond the scope of this\npaper. We envision that future work can automate this process, as\ndiscussed in Sec. 8.\nStep 2: Current mental state report . The mental state is a\nkey factor that triggers users’ habitual phone use. Unlike physical\ncontext, detecting mental state is challenging due to the lack of\nmature techniques. Therefore, we ask users to self-report. Based\non the mental states listed in Sec. 3.2 and Takeaway 3○ & 4○,\nwe propose two single-choice questions for users to report their\nmental state: (1) whether they are engaged in activities (\"Yes\" or\nMindShift CHI ’24, May 11–16, 2024, Honolulu, HI, USA\n\"No\"), and (2) whether they currently have any negative feelings,\nincluding options of \"Stress\", \"Boredom\", \"None\" (i.e., inertia), or\n\"Other Negative Feelings\". The \"Other Negative Feelings\" option,\nwith an adjacent text box for specifics, covers unlisted emotions. We\ntested these questions for reliability and validity [103]. To ensure\nvalidity (i.e., accurate reflection of mental states), three psychology\nexperts verified the alignment of our questions with mental state\ncoding in Sec. 3. To ensure reliability (answer consistency), we asked\nthree pilot study participants to respond to situational mental state\ndescriptions with two single-choice questions, achieving uniform\nresponses.4\nStep 3: Persuasion . Based on our intervention content design in\nFigure 4, we leverage the power of GPT-3.5 to generate persuasive\nmessages. The messages are displayed in a pop-up window, where\nusers can choose to either quit the app or continue using it (the\nbottom of Step 3 in Figure 5). Additionally, users can also provide\noptional feedback by giving a thumbs up or down.\nFurthermore, for the Scaffolding Habits strategy, it is essential\nto link users’ own habits to specific use contexts. Therefore, we\nimplement a user participation mechanism, adding an additional\nhabit item along with an edit button (the upper interface of Step 3 in\nFigure 5). The habit item represents a system-generated suggestion\nbased on the user’s current context and initial settings in Step 0.\nUsers can edit and update their desired habits. Once submitted, the\nmodified habit will be recommended the next time when users are\nin the same context.\n4.3 When to Intervene: Intervention Trigger\nMechanism\nWe consider the user’s intent of use in the intervention trigger rule\n(Step 1 of Sec. 4.2). Specifically, interventions will be triggered when\na user’s self-report intent is habitual use.\nAs in Figure 3, each mental state allows for multiple persuasion\nstrategies. We devise a simple procedure. After determining the\nmental state and narrowing down the specific strategies, we first\nrandomly sample one strategy and generate an intervention mes-\nsage. Then, we loop over other strategies and show new strategy\nmessages every two minutes until the users leave the app. After\nlooping over all appropriate strategies under this mental state, the\nintervention will stop. The usage duration is calculated based on\nthe total usage time of a single blacklisted app during one unlock-\ning session. The two-minute interval setting is derived from the\nstatistical analysis in the WoZ study, where 90% of users spent less\nthan 5 minutes on a blacklisted app in a single session. We thus set\nthe interval between interventions as two minutes as a convenient\ndelay to facilitate the exploration of different strategies, as further\nsupported by the analysis in Sec. 7.2.2.\nUsers only need to report their habitual use and mental states\nonce (i.e., Step 1 and 2 in Figure 5) when they open a specific app\nduring each screen unlock session. This design is based on three\nconsiderations: (1) The initial mental state when opening an app is\ncrucial, as it triggers habitual use (Sec. 3.2). (2) As reflected in our\npilot study in Sec. 4.2, multiple reports during app switching can be\nannoying and negatively affect user experience. (3) Some previous\n4We plan to conduct more comprehensive validity and reliability testing in future\nwork, as discussed in Sec. 8.\nstudies suggest that users’ stress level tends to be retained even\nwith coping techniques [27]. We assume this also applies to other\nmental states, so most users’ mental state remains stable during\none session (90% was less than 5 minutes), as further supported by\nthe analysis in Sec. 7.2.1. We also discuss future potential ways to\nenhance accuracy in Sec. 8.3.2 & 8.4.\n5 SYSTEM IMPLEMENTATION\nWe built an Android application to instantiate our design. Our\nsystem consists of a client and a server.\n5.1 Client-Side Implementation\nThe client-side is an Android app that implements all the features\nof our design. We use accessibility services to detect the opening\nand closing of apps on the phone. The client is also responsible\nfor collecting and uploading data to the server, including screen’s\noff and unlock status, application name, application opening and\nclosing times, and location data obtained through the Amap API [3].\nTo prevent the accidental killing of the accessibility service and\nensure compliance, our app includes a background service checking\nthe accessibility service status every 5 minutes. If it detects that\nthe service is terminated, the app informs the server to email a\nresearcher, who then reminds the user to reactivate the service,\nensuring data integrity.\n5.2 Server-Side Implementation\nThe server side is responsible for generating persuasive content\nthrough four key tasks, ensuring that the intervention is personal-\nized, contextually relevant, and delivered in a timely manner.\n(1) User Data Computation : The server processes user data\nfrom client-uploaded app data for use in word slots, including the\nphone’s total habitual use time and last habitual opening time.\n(2) Habit Selection : Next, the server selects a habit mostly\nmatched with the current user’s mental state, location ( i.e., the\nspecific building), and time (i.e., the hour of the day) from the users’\ninitialization (i.e., Step 1 in Figure 5). To reinforce the habit-context\nlink, unless users thumb down or modify it, the same habit will be\nrecommended in the same context. More details can be seen in Step\n4 of 4.2.\n(3) Strategy Counterbalance: To balance the frequency of each\nstrategy across mental states, the server counterbalances strategy\norder in the prompt in Sec. 4.2.\n(4) Content Generation : After obtaining the user contexts,\nhabits, and persuasion strategies, the server uses the OpenAI GPT-\n3.5 API to generate persuasive content. We adopted a streaming,\ncharacter-by-character generation approach, allowing the persua-\nsive content to start being displayed within 2 seconds.\n6 FIELD EXPERIMENT\nTo evaluate the effectiveness of MindShift, we conducted a 5-week\nfield experiment. We introduce experimental design (Sec. 6.1 & 6.2),\nparticipant recruitment (Sec. 6.3), and experiment procedure (Sec.\n6.4).\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Wu et al.\nTable 3: Comparison of Three Intervention Methods\nIntervention Methods\nCharacteristics\nIntent Report LLM-powered\nPersuasion\nMental-States-Based\nPersuasion Strategies\nBaseline ✓\nMindShift-Simple ✓ ✓\nMindShift ✓ ✓ ✓\n6.1 Baseline and MindShift-Simple Intervention\nMethods\nAs MindShift is one of the first persuasion intervention systems\nleveraging an LLM to generate dynamic persuasion content, there\nare no comparable systems other than the traditional persuasion\ntechniques. We compared MindShift against a persuasive reminder\nbaseline, one of the most commonly adopted intervention methods\nin commercial apps [8, 46]. To ensure the fairness of the comparison,\nthe baseline is designed to be the same as the intent report step, as\nillustrated in Step 1 in Figure 5. Specifically, it only requires users\nto report the intent the first time they open the blacklist app after\nunlocking. It can also be used to collect the proportion of users’\ninitial intents, facilitating the analysis of the intervention effect of\nMindShift. We name this intervention as Baseline.\nMoreover, in order to evaluate the effectiveness of the mental\nstates and persuasion strategies proposed in Sec. 3, we further\ndesigned a simplified version, MindShift-Simple, by removing the\nmental states and persuasion strategies from the prompt design.\nSpecifically, in the prompt design (Figure 4), we retained only <User\nData> in the (2) Description of the current context and removed\nthe (4) Description of the persuasion strategy. Meanwhile, the last\nsentence in <Output Format> was changed to generate four sen-\ntences at once. We kept other setups consistent, ensuring that both\nversions’ language features (such as both tone styles are humorous\nand caring) are as consistent as possible. Examples of content gen-\neration in MindShift-Simple are as shown in Table 2 under ‘With\nContext’ and ‘Without Strategy’.\nIn total, we have three intervention methods to compare:Baseline,\nMindShift-Simple, and MindShift. Table 3 shows the comparison.\nFigure 12 in Appendix further shows their interaction flow.\n6.2 Experiment Design\nWe adopted a within-subject design, with intervention techniques\nas independent variables ( Baseline, MindShift-Simple, and Mind-\nShift). We designed a 5-week field experiment. To measure users’\neveryday phone usage behavior, the first week is set as theBaseline\nstage, followed by two weeks of one MindShift version and another\ntwo weeks of the other version. We counter-balanced the order of\nMindShift-Simple and MindShift.\nOur evaluation metrics include various aspects: (1) Intervention\nacceptance rate. We measure the percentage of times users accept\nthe intervention and quit the blacklist app use when interventions\nare shown. (2) Intervention thumb-up rate. For MindShift-Simple\nand MindShift that show persuasion content, users can provide\nfeedback by thumb-up or thumb-down (step 4 in Figure 5). (3)\nApp usage behavior, which includes both app opening frequency\nand usage duration. (4) Subjective reports. At the beginning of the\nstudy and at the end of each intervention session, we distributed\nthe Smartphone Addiction Scale (SAS) [ 64] and the self-efficacy\nscale [111]. In addition, at the end of the study, we also conducted\na brief semi-structured interview to gather user experiences and\nfeedback on our intervention techniques. These metrics cover both\nthe objective and subjective measures of the interventions.\n6.3 Participants\nWe sent out recruitment material on social media platforms. We in-\ncluded a screening survey aiming to identify potential participants\nwho showed signs of smartphone addiction and the willing to re-\nduce their smartphone use. Specifically, besides basic demographics,\nwe included four questions selected from the SAS and self-efficacy\nquestionnaires, questions about the willingness to reduce smart-\nphone use, the extent of habitual phone use, future plans for the\nnext five weeks, and a screenshot of phone usage time of the last\nweek. We excluded users (1) without signs of smartphone addiction\n(SAS sub-score < 15), or (2) unwilling to reduce smartphone use, or\n(3) less than 20 hours of weekly phone use, or (4) having special\nplans such as long-term travel in the next five weeks (which may\nshift their phone usage patterns).\nWe received a total of 42 responses. We recruited 31 participants\nafter the screening process. 6 participants voluntarily dropped out\nduring the study. For the remaining participants, we divided them\ninto groups according to counterbalanced intervention orders. We\nconducted a Kruskal-Wallis test analysis to ensure that groups had\nno significant difference in the SAS scores and self-efficacy scores.\nIn the end, 25 participants completed the entire study (females=13,\nmales=12, age=22±2 years), including 17 undergraduates, 5 graduate\nstudents, and 3 professionals.\n6.4 Experiment Procedure\nAfter all the participants signed the consent form, we held a 20-\nminute onboarding session online to familiarize participants with\nthe research process and introduce the Android application. We\nexplained in detail the meanings of each selection in the intent\nreport interfaces (Step 2 in Figure 5). After the meeting, participants\nfilled out the first SAS and self-efficacy questionnaires. The app\nwas then deployed for a 5-week field experiment.\nBefore users started using one of two versions of MindShift\n(MindShift and MindShift-Simple), we provided participants with a\ntutorial explaining the three mental states (i.e., boredom, stress, and\ninertia) that they need to report. To confirm their understanding,\nMindShift CHI ’24, May 11–16, 2024, Honolulu, HI, USA\nparticipants were asked to take a brief test on the understanding of\nmental states until they reached a score of 90%. This ensured that\nthey had an accurate and consistent understanding of the mental\nstates, which in turn improved the accuracy and reliability of the\nreported data. At the end of the experiment, participants received\na compensation of $50 for their time.\n7 RESULTS\nDuring the five-week study, we collected 50,815 minutes of re-\nstricted app usage duration, and 54,467 restricted app opening\nevents (7539, 23,769, 21,994, and 835 for habitual use, instrumental\nuse, relax, and quit). We conducted statistical tests on the quan-\ntitative data collected from the app and scale scores to measure\ndifferences. For qualitative data from exit interviews, we conducted\nthematic coding to extract key insights.\n7.1 Intervention Acceptance Rate\nThe effectiveness of a persuasion strategy is directly measured by\nthe rate of successful prevention of user engagement with the tar-\ngeted application (i.e., intervention acceptance rate). We compared\nthe overall acceptance rate (Sec. 7.1.1), the acceptance rate for gen-\nerated persuasion content (Sec. 7.1.2), and thumb-up rate (Sec. 7.1.3).\nMoreover, we also conducted a detailed analysis of the acceptance\nrate across strategies (Sec. 7.1.4), mental states, and activities (Sec.\n7.1.5).\n7.1.1 Overall Acceptance Rate. MindShift and MindShift-Simple\nincrease the overall acceptance rate significantly and Mind-\nShift achieves best. We assess the overall acceptance rate using\ntwo methods. The first “session-based” rate means among total app\nvisits (excluding instrumental uses and relaxation), how many times\nusers quit during the intervention (including intent report and per-\nsuasion content 5). Figure 6a shows that MindShift (45.1±34.3%)\nachieves higher acceptance than MindShift-Simple (38.5±32.2%) and\nBaseline (12.7±17.4%). Significance is observed in a Friedman test\n(𝜒2(2) = 16.64, p < .001). Three post hoc Wilcoxon signed-rank tests,\ncorrected with Holm’s sequential Bonferroni procedure, indicate\nthat MindShift vs. Baseline (V = 31,p < .001) andMindShift-Simple vs.\nBaseline (V = 59, p < .01) are significantly different, while MindShift\nvs. MindShift-Simple is not (V = 126, n.s.).\nConsidering that the Baseline doesn’t trigger subsequent inter-\nventions like the Mindshift and Mindshift-simple, we also compare\nthe acceptance rates of the first round in particular. Both MindShift\nand MindShift-Simple initiate persuasion immediately after partic-\nipants report their intents, so we include this initial persuasion\nin calculating their first-round acceptance rates. Additionally, we\nanalyze the acceptance rate of the intent report to distinguish its\neffectiveness among the three intervention techniques. As shown in\nthe upper dashed lines in Figure 6a, the first-round acceptance rates\nfor MindShift (38.7%±24.9%) and MindShift-Simple (36.2%±25.8%)\nare still significantly higher than the Baseline (12.7%±17.4%,𝜒2(2)\n= 15.56, p < .001). Post hoc tests show significant differences in\nMindShift vs. Baseline (V = 43, p < .01), and MindShift-Simple vs.\n5Users click the \"I am great and I will quit playing\" in Step 1 or \"Quit using\" in\nStep 3 in Fig 5\n(a) Overall Acceptance Rate (Session-based)\n(b) Overall Acceptance Rate (Pop-up-based)\nFigure 6: Overall Acceptance Rate\nBaseline (V = 32, p < .001), but not in MindShift vs. MindShift-\nSimple (V = 134, n.s.). The lower dashed lines in Figure 6a indicate\nthat the acceptance rates when considering only reporting intent\nare still higher for MindShift (17.9%±17.5%) and MindShift-Simple\n(18.3%±18.2%) compared to the Baseline (12.7%±17.4%). However,\na Friedman test ( 𝜒2(2) = 5.59, p < .1) does not show significance,\nsuggesting that intent report has no difference among the three\nintervention techniques.\nFollowing the session-based method, we also investigate the pop-\nup-based acceptance rate, which equals the total number of quit\ntimes divided by the total number of intervention pop-ups (i.e., each\nround is counted as a pop-up). Figure 6b shows the comparison,\nMindShift (35.2±24.1%) still has a higher acceptance thanMindShift-\nSimple (30.5±23.6%) and Baseline (12.7±17.4%, 𝜒2(2) = 13.69, p < .01).\nPost hoc tests indicate significance for MindShift vs. Baseline (V =\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Wu et al.\n(a) Overall Persuasion Acceptance Rate\n(b) Persuasion Acceptance Rate Grouped by Round\nFigure 7: Persuasion Acceptance Rate\n52, p < .01) and MindShift-Simple vs. Baseline (V = 38, p < .001), but\nnot for MindShift vs. MindShift-Simple (V = 129, n.s.). Subsequent\nanalyses are all based on pop-ups.\n7.1.2 Acceptance Rate for Generated Persuasion Content. Mind-\nShift has a significantly higher persuasion acceptance rate\nthan MindShift-Simple. The overall acceptance rate includes two\nparts: exiting when reporting intent and exiting after seeing the\npersuasion content. To narrow down the comparison betweenMind-\nShift and MindShift-Simple, we exclude the intent report stage and\nfocus on the acceptance rate during the persuasion stage, as they dif-\nfer only in the persuasive content. As shown in Figure 7, MindShift\nachieves higher persuasion acceptance (20.1±20.2%) than MindShift-\nSimple (12.0±15.0%) and a paired-samples t-test shows that Mind-\nShift was statistically significantly higher (t = -2.21, p<0.05).\nMoreover, as we introduce in Sec. 4.3, every persuasion inter-\nvention could consist of 1 to 4 rounds, depending on which mental\n(a) Feedback Proportion\n(b) Acceptance Rate Grouped by Persuasion Strategies\nFigure 8: Feedback and Strategy Acceptance Rate\nstate participants are in and which stage participants leave the app.\nTherefore, we further compare the persuasion acceptance rates be-\ntween MindShift and MindShift-Simple across different persuasion\nrounds. The results show that MindShift outperforms MindShift-\nSimple at each round 6(ΔRound1=6%, ΔRound2=14.7%, ΔRound3=10.2%,\nΔRound4=11%) as indicated in Figure 7b. We conduct a paired-samples\nt-test between the two intervention techniques in each round. Re-\nsults indicate that, except for the first round, rounds 2 (p<0.05), 3\n(p<0.001), and 4 (p<0.001) all exhibit that MindShift achieves sig-\nnificantly higher acceptance rate. This trend suggests that as the\nnumber of interventions increases, MindShift’s advantage becomes\nmore pronounced, highlighting MindShift’s robustness and effec-\ntiveness in maintaining high acceptance rates.\n7.1.3 Thumb-up Rate of Interventions. MindShift has a signif-\nicantly higher thumb-up rate. Users can give feedback in the\n6Round 1 here only contains persuasion and excludes the intent report.\nMindShift CHI ’24, May 11–16, 2024, Honolulu, HI, USA\n(a) Strategy Acceptance Rate Grouped by Mental State. Significant\ndifferences compared to no strategy (green bar) are highlighted in\nred, while differences among strategies are indicated in black.\n(b) Strategy Acceptance Rate Grouped by Activity. The same annota-\ntion method as grouped by mental state.\nFigure 9: Strategy Acceptance Rate Grouped by Different\nMental States\npersuasion interface. As depicted in Figure 8a, 6.8% of interventions\nin MindShift receives thumb-up while MindShift-Simple receives\nonly 2.2%. A paired-samplest-test shows that significant differences\n(p<0.05) are observed for the thumb-up rate, but no significant differ-\nences (p=0.22) for the thumb-down rate between the two techniques.\nThis indicates that MindShift aligns better with users’ preferences.\n7.1.4 Acceptance Rate across Different Strategies. We design four\npersuasion strategies in MindShift whereas MindShift-Simple does\nnot incorporate any specific strategies, so we further compare the\npersuasion acceptance rates across different strategies. Figure 8b\nshows that all strategies we design outperform MindShift-Simple\n(ΔUnderstanding=8.9%, ΔComforting=3.3%, ΔEvoking=10.3%, Δ Scaffolding\nHabits=4.9%) but the differences are not statistically significant.\n7.1.5 Strategy Acceptance Rate across Different Mental States and\nActivities. As we show in Figure 3, each mental state has a different\nstrategy mapping. Therefore, we also seek to derive insights regard-\ning which strategies are most effective for users under different\nmental states (Figure 9a) and activities (Figure 9b). Friedman test\nand post hoc Wilcoxon signed-rank tests are employed to investi-\ngate the influence of different strategies on acceptance rate.\nFor mental states: under the mental state of \"Boredom\" and\n\"Inertia\", Evoking is significantly more effective ( ΔBoredom=3.6%,\nΔInertia=5.8% ) than MindShift-Simple (ps < 0.01); under the mental\nstate of \"Stress\", Comforting and Evoking show a trend toward sig-\nnificance compared with MindShift-Simple (Δ = 10.8%, p<0.1 and Δ\n= 3.8%, p<0.1 respectively).\nFor activity levels: when not engaging in activity, Comforting\nis significantly more effective than MindShift-Simple (Δ=5.6%, p <\n0.05); when engaging in activity, there are no significant differences\nin all the strategies compared to MindShift-Simple.\n7.2 App Usage Behavior\nWe then investigate the influence of the intervention on partic-\nipants’ app usage behavior. Overall, participants have less app\nusage frequency and duration when usingMindShift and MindShift-\nSimple, especially in habitual usage.\n7.2.1 Overall Usage Behavior. We count the number of app open-\ning attempts for restricted apps. Figure 10a presents the opening\nfrequency (daily open count) under three intervention techniques.\nMindShift-Simple (63.6±9.2) and MindShift (65.3±9.5) have lower\nopening frequency than Baseline (74.3±9.7). Compared to Baseline,\nMindShift reduces by 12.1% usage duration while MindShift-Simple\nreduces by 14.4%. However, a Friedman test does not show signifi-\ncance.\nWe also measure restricted app usage duration, another impor-\ntant factor for phone overuse. As can be seen from Figure 10b,\nparticipants have the lowest app usage duration in MindShift (1.11\n±0.7 hours) compared to theBaseline (1.23±0.7 hours) andMindShift-\nSimple (1.20 ± 0.8 hours). Compared to Baseline, MindShift reduces\nby 9.8% usage duration whileMindShift-Simple reduces by 2.4%. We\nconduct a Friedman test and find a significant difference among\ndifferent techniques (p<0.05). A post-hoc Wilcoxon test shows that\nMindShift has a trend of declining compared to Baseline, with mar-\nginal significance (p<0.1).\nTo validate the assumption that the intent and mental state re-\nmain stable in one unlock session across different apps in Sec. 4.3,\nwe analyze the duration of users’ intent and mental states. The\nresults show that the median duration of a mental state is 5 hours\n(third quartile 14.5 hours). The median duration for an intent (chang-\ning from habitual use to other intents) is 37 minutes (third quartile\n60 minutes). This validates our hypothesis that intent and mental\nstate are stable during one habitual usage session.\n7.2.2 Habitual Usage Behavior. MindShift and MindShift-Simple\nsignificantly reduce habitual app usage duration and fre-\nquency. The focus of our intervention is habitual use, so we in-\nvestigate the changes in habitual usage behavior. Results show\nthat MindShift and MindShift-Simple can both significantly reduce\nhabitual use. The app visit frequency and duration of habitual us-\nage cases also decrease significantly during the two versions of\nMindShift compared to Baseline (ΔMindShift-Simple equaled 80.6% for\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Wu et al.\n(a) Total App Opening Frequency\n(b) Total Phone Usage (Hours) per Day\nFigure 10: App Usage Behavior\nvisit frequency, 84.4% for usage duration, and 6.8% for habitual use\nproportion, 𝑝𝑠 < 0.001; ΔMindShift equaled 77.3% for visit frequency,\n80% for usage duration and 6.8% for habitual use proportion, 𝑝s <\n0.001).\nTo confirm the suitability of the 2-minute intervention inter-\nval, we analyze data on users’ habitual usage duration during the\nBaseline phase (unaffected by subsequent interventions). Analysis\nshows that 75% of users spent about 4 minutes in a single habit-\nual use, supporting our design choice of the 2-min intervention\ninterval.\n7.3 Subjective Report\nWe further analyze on user-reported SAS and self-efficacy scale\nresults. When using MindShift and MindShift-Simple, participants\nexperience a significant decrease in SAS score and a significant\nincrease in self-efficacy score, but they see no change when using\nBaseline. We summarize the results as follows.\n(a) SAS Score\n(b) Self-efficacy Score\nFigure 11: Subjective Scales Report\n7.3.1 Decrease of SAS Score. MindShift and MindShift-Simple\ndecrease SAS score significantly and MindShift achieves best.\nFigure 11a shows the results of the SAS scores during the interven-\ntion stages. MindShift exhibits the lowest SAS scores (35.2±10.2),\nfollowed by MindShift-Simple in the second position (37.6 ±10.1),\nwith the Baseline intervention ranking the third (44.5±8.7) and the\ninitial ranking the last (47.5±6.7). This indicates that MindShift and\nMindShift-Simple reduce SAS scores by 34.7 and 25.8%. The results\nof a Friedman test show a significant difference (p<0.001). Post-hoc\nWilcoxon tests show that both MindShift and MindShift-Simple are\nsignificantly lower than the Baseline and initial scores (all ps<0.01).\nThis suggests that the two versions of MindShift have the potential\nto fundamentally alter individuals’ mobile phone usage behavior.\n7.3.2 Increase of Self-efficacy Score. MindShift and MindShift-\nSimple increase Self-efficacy score significantly . Figure 11b\nshows the results of the self-efficacy scores during the intervention\nstages. MindShift (26.7±6.1) and MindShift-Simple (26.6±6.8) exhibit\nMindShift CHI ’24, May 11–16, 2024, Honolulu, HI, USA\nhigher scores compared to the Baseline intervention (24.1±5.6) and\nthe initial (24.1±5.6). This indicates that MindShift and MindShift-\nSimple increase self-efficacy scores by 10.7% and 10.4%. Friedman\ntest shows a significant difference (p<0.001). The post-hoc Wilcoxon\ntest shows that both MindShift and MindShift-Simple are signifi-\ncantly higher than the Baseline and initial scores (all ps<0.05). This\nindicates that persuasive techniques have the potential to enhance\nindividuals’ self-efficacy, which can result in overcoming excessive\nmobile phone usage. In contrast, conventional reminders may not\nachieve this goal.\n7.3.3 Subjective Comments. During the exit interview, participants\ngenerally had a positive experience. One participant said, “I can\nfeel that my recent dependency on the phone has decreased” (P17).\nOne participant felt using the app shifted them to self-improvement\ntasks instead of mindlessly usage, “Now, when I have nothing to do, I\ntend to do other things, like learning vocabulary, instead of aimlessly\nbrowsing my phone” (P10). Another participant was willing to use\nit longer, “I’m a little sad with the disappearance of pop-ups after\nthe experiment. If possible, I would like to keep using it\" (P3). Addi-\ntionally, participants had positive comments on MindShift which\nincludes the mental states factor, “I feel that its suggestions align\nwell with my emotional state at that time. ” (P25). They also valued\nthe “Understanding” and “Comforting” strategies, saying “It tells me\nthat I’m not the only one experiencing these painful emotions, which\nhelps me feel better ” (P22).\nDespite the majority of positive comments, a small number of\nparticipants expressed their dissatisfaction with MindShift. Some\nparticipants found the persuasive message to be “ a bit stiff and\ntemplated” (P4, P6), and they believed that “they would develop toler-\nance as they repeatedly use” (P20). Some participants also mentioned\nprivacy concerns. P15 mentioned that MindShift-Simple’s ability to\ncapture time and location made her uncomfortable. Moreover, par-\nticipants’ preference for linguistic characteristics is highly personal.\nSome felt harsh ones were more useful, “Gentle tone doesn’t work\nfor me, I wish the words could be harsher\" (P8). Some preferred data\nproof than pure textual reasoning,“It’s intuitive to tell me how long I\nhave used my phone today directly. The number is very eye-catching\"\n(P9). This suggests the future direction of personalized persuasive\ncontent design. We have more discussion in Sec. 8.2.\n7.4 Summary of Results\nOverall, two versions of MindShift show significantly higher accep-\ntance rates compared to the Baseline. MindShift has the highest ac-\nceptance (45.1% for session-based and 35.2% for pop-up-based) and\nthumb-up rates (6.8%), and it statistically significantly outperforms\nMindShift-Simple in both acceptance rates of generated persuasion\ncontent (8.1%) and on a per-round basis (6-14.7%). Furthermore,\nthere exist strategies that significantly outperformMindShift-Simple\n(3.6-10.8%) in every mental state, suggesting that the strategies\nwe design are meaningful. Furthermore, MindShift and MindShift-\nSimple lead to a decrease in overall app opening frequency (12.1-\n14.4%) and usage duration (9.8-2.4%) and are significantly effective\nin reducing habitual use. MindShift and MindShift-Simple also re-\nduce SAS scores by 34.7-25.8% and increase self-efficacy scores by\n10.7-10.4% statistically significantly while Baseline does not. This\nsuggests that MindShift has the potential to profoundly transform\nhuman behavior with enduring effects. Finally, users’ subjective\ncomments also confirm a perceived reduction in smartphone de-\npendency and an inclination to continue using MindShift.\n8 DISCUSSION\nIn this section, we discuss MindShift’s novelty in contrast to pre-\nvious intervention techniques (Sec 8.1), future work (Sec 8.2), the\npotential of leveraging LLMs for behavior change (Sec 8.3), and the\nlimitations (Sec 8.4).\n8.1 The Roles of Users’ Phone Use Purpose and\nMental States in Smartphone Intervention\nMost previous intervention techniques initiate interventions based\non the amount of time and frequency of smartphone usage. How-\never, quantifying smartphone use just by time oversimplifies and\nignores the underlying causes. People use smartphones for work,\nstudy, and relaxation, as long as for meaningful reasons, the time\nis not a true problem. As Lukoff et al. found, even if participants\ndidn’t reduce their screen time, the intervention could make them\nfeel better in the sense of agency and goal alignment, indicating\nusers prioritize the quality of time over quantification [74]. Mind-\nShift initiates persuasion only when users recognize their current\nusage as habitual, aiming to enhance users’ self-awareness of their\nhabitual phone use behavior.\nAdditionally, certain mental states are linked to habitual smart-\nphone use as a form of self-distraction. Although smartphone use\nserves as a coping mechanism for emotion fluctuations, studies\nshow that habitually using them for escapism fails to effectively\nmitigate emotions [27]. Using smartphones for emotional regula-\ntion can lead to problematic smartphone use behavior, potentially\nleading to severe psychological issues such as depression [25, 133].\nMindShift aims to intervene in habitual smartphone usage triggered\nby specific mental states. Our goal is to reduce users’ problematic\nsmartphone use and help individuals transition from avoidance-\noriented coping to approach-oriented coping [24].\n8.2 Towards Adaptive Persuasion Intervention\nMindShift generates dynamic and personalized persuasion content\nby combining information such as users’ simple physical contexts,\nmental states, and other behaviors. However, several participants\nstill mentioned that the LLM-generated content sometimes could be\n“stiff and templated ”. This may be attributed to the limited prompt\ntemplates. Although the content generated by the LLM varies, the\nmain theme is guided by our prompts, which could limit the varia-\ntion of persuasion content. To improve, we suggest integrating user\nfeedback into the system for more adaptive intervention. Currently,\nMindShift supports a simple thumb-up and thumb-down feedback\nmechanism. Even with such simple information, we could establish\na human-in-the-loop setup to fine-tune content, aligning better\nwith user preferences. Another aspect is to include more diverse\nbehavior features captured by passive sensors on smartphones and\nwearables [40, 81, 127].\nMoreover, future work can also consider collecting more compre-\nhensive feedback from users. Users could customize the language\nstyle generated by an LLM, which can be coupled with adaptive\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Wu et al.\nalgorithms such as reinforcement learning to achieve a more intelli-\ngent just-in-time adaptive intervention (JITAI) system that evolves\nwith users [32, 97].\n8.3 Leveraging LLMs for Behavior Change\n8.3.1 Advantages of Using LLMs for Behavior Change. Our study\nsheds light on the possibility of leveraging LLMs to change user be-\nhavior by influencing human cognition. Previous efforts in this field\noften hinge on users’ ability to self-reflect and self-persuade, lim-\nited by the narrow scope of sentence databases used [128]. LLMs\nbreak this barrier, offering a broader range of persuasive strate-\ngies. They can generate adaptive and diverse persuasive content,\ntailored to the individual’s context. In our study, we observed no-\ntable changes in cognition: participants’ smartphone addiction scale\nscores dropped, and self-efficacy scores rose after the study (Figure\n11a). This suggests a potential for long-term behavioral change,\nwhich we aim to explore further in our future work.\nWe also want to highlight that MindShift is just one example\nof the possibilities in this domain. Future research could integrate\nLLMs for more dynamic interventions, such as self-affirmation con-\ntent generation in the typing intervention [128] and personalized\nvisualizations [42]. Moreover, our methodology can potentially be\nexpanded to other domains, such as smoking or alcohol cessation,\neating diet, and physical activity promotion, where LLMs can be\nused to generate context-aware dynamic persuasive content for a\nspecific well-being goal. We envision our work can inspire a num-\nber of creative LLM-powered intervention techniques in the future.\n8.3.2 Design Implication for Using LLMs in Other Behavior Change\nDomains. Based on our findings in the study, we extract three design\nimplications of using LLMs for behavior change in various domains.\nFirst, investigating why people behave in certain ways is the\nbasis of any intervention design, especially when LLMs can uti-\nlize such insights when generating persuasion. Our study explores\nthe psychological factors behind habitual smartphone use. Mind-\nShift leveraging those factors outperformed MindShift-Simple only\nconsidering physical factors (see in Sec. 7.1.1 to 7.1.3).\nSecond, context is crucial for LLMs to generate dynamic, tai-\nlored persuasive messages. Our examples in Table 2 showcase\nthe importance of user contexts for content generation. In our\nstudy, some user contexts, like mental states, cannot be detected\nautomatically but depend on users’ self-reports, which can be im-\nproved in future design. Past work has explored how to use smart-\nphone usage data and machine learning to predict boredom and\nstress [21, 68, 81, 100, 115], and there have been researches using\nphysiological measuring instruments to learn mental states from\nbiosignals [112, 113, 124]. With the development of more smart\nand wearable technologies, there is the potential to track users’\nmental states automatically [31, 41]. This can simplify the inter-\nvention process and improve user experience. However, it remains\nan open question on how skipping self-reflection may impact the\neffectiveness of such a persuasion technique.\nLast, crafting a suitable prompt is crucial for effectively incorpo-\nrating expert knowledge into LLM generation. This often involves\nmultiple attempts and adjustments to ensure the generated content\naligns with expectations. While not the main contribution of our\nwork, we conducted extensive iterations to ensure the appropri-\nateness of the persuasive content. We have more discussion on\nthe ethical concerns if prompt engineering is not done properly in\nthe next paragraph. We refer future developers to recent studies,\nsuch as EmotionPrompt [69], for more comprehensive guidance on\nenhancing LLM outputs.\n8.3.3 Ethical Concerns and Risk of Using LLMs for Behavior Change.\nAlthough MindShift performs well in changing problematic smart-\nphone use, there are important ethical concerns we want to high-\nlight about the risk of using LLMs for behavior change.\nDespite carefully crafted prompts, developers face challenges\nensuring the constant safety of generated persuasive messages. For\nexample, while we fixed hallucination for our experiment, it is one\nof the biggest concerns in LLMs and can still possibly occur in\nreal-world deployment [29, 47]. Additionally, although we didn’t\nencounter it in our experiment, LLMs can generate dangerous con-\ntent, such as abusive and discriminatory sentences. Furthermore,\nthere is still room to improve LLMs’ understanding of the nuances\nof human mental states [126]. For instance, if users of MindShift\nare already stressed due to their life objectives (e.g., struggling with\nacademic stress), additional reminders of these goals could exac-\nerbate the stress or even cause harm. More future work is needed\nto improve safety and reduce the risk before we deploy LLMs for\nlarge-scale intervention studies.\nMoreover, privacy is another critical concern since the detec-\ntion of users’ physical and psychological context data is needed.\nMindShift employs a commercial API from OpenAI, transmitting\nusers’ data to a third party. Although we intentionally designed the\nprompt to avoid including any identifiable information, there is still\nthe risk of revealing information about their behavior and mental\nstates. One solution for future study is to leverage open-sourced\nLLMs (such as LLaMA2 [117] or PaLM2 [6]) so that user’s data can\nbe appropriately handled and encrypted by ourselves instead of a\nthird party.\n8.4 Limitations\nOur study has a few limitations. First, our experimental user group\nis limited to young adults, limiting result applicability. Future stud-\nies can expand the sample size and involve more diverse user groups.\nSecond, our field experiment is short. A five-week deployment can-\nnot reveal the longitudinal effect of such an intervention technique.\nMoreover, if our time and monetary budget allow, our experiment\ndesign can be improved by making the Baseline another two-week\nintervention session for a more fair comparison. Third, the validity\nand reliability test of mental state report questions needs further\nimprovement. Testing convergent and discriminant validity, recruit-\ning more samples for reliability tests, and using statistical methods\nto evaluate consistency are areas for enhancement. Additionally,\nour current method for detecting habitual use and mental states\nrelies on self-reporting, increasing users’ burden. We only consider\ninitial habitual use upon users unlocking phones, neglecting shifts\nin user purposes during app usage. As we mentioned in Sec. 8.3.2,\nfuture work can explore automatic intent and mental state detec-\ntion, and the data collected in this study can serve as a starting\nMindShift CHI ’24, May 11–16, 2024, Honolulu, HI, USA\npoint for machine learning training models. Finally, our study uti-\nlizes GPT-3.5 as a large language model, and its performance is\nstill unstable. Future work can explore more lighted weighted and\nrobust LLMs for local deployment, which can address the concerns\nmentioned in Sec. 8.3.3 to some extent.\n9 CONCLUSION\nThis paper introduces MindShift, a mental-based persuasion in-\ntervention technique powered by LLM designed to mitigate prob-\nlematic smartphone use. We conducted a Wizard-of-Oz study and\nan interview study to explore the mental states behind problem-\natic smartphone use: stress, boredom, inertia, and designed four\npersuasion strategies: understanding, comforting, evoking, and scaf-\nfolding habits . MindShift (1) collects users’ usage intent, usage be-\nhavior, physical context, mental states, goals&habits, (2) uses the\npersuasion strategies we design, (3) leverages LLMs to generate\ndynamic, personalized persuasion messages. Through a five-week\nwithin-subjects user experiment (N=25), we compared three inter-\nvention techniques (MindShift, MindShift-Simple, Baseline). Mind-\nShift outperforms MindShift-Simple and Baseline, improving accep-\ntance rates (4.7-22.5%) and reducing app usage (7.4-9.8%). Notably,\nMindShift and MindShift-Simple significantly reduce SAS scores\n(34.7-25.8%) and increase self-efficacy scores (10.7-10.4%). Finally,\nusers’ subjective comments also confirm a perceived reduction\nin smartphone dependency and a willingness to continue to use\nMindShift. Our work provides valuable insights into the mental\nstates behind problematic smartphone use and the effectiveness of\nLLMs-powered persuasion for smartphone intervention.\nREFERENCES\n[1] Dolores Albarracín, Aashna Sunderrajan, Sophie Lohmann, Man-Pui Sally Chan,\nand Duo Jiang. 2018. The psychology of attitudes, motivation, and persuasion.\nIn The handbook of attitudes, volume 1: Basic principles . Routledge, 3–44.\n[2] Carlos Alós-Ferrer, Sabine Hügelschäfer, and Jiahui Li. 2016. Inertia and decision\nmaking. Frontiers in psychology 7 (2016), 169.\n[3] Amap. 2023. Amap API website. (2023). https://lbs.amap.com/.\n[4] Ian A Anderson and Wendy Wood. 2021. Habits and the electronic herd: The\npsychology behind social media’s successes and failures. Consumer Psychology\nReview 4, 1 (2021), 83–99.\n[5] Ionut Andone, Konrad Blaszkiewicz, Mark Eibes, Boris Trendafilov, Christian\nMontag, and Alexander Markowetz. 2016. Menthal: quantifying smartphone\nusage. In Proceedings of the 2016 ACM International Joint Conference on Pervasive\nand Ubiquitous Computing: Adjunct . 559–564.\n[6] Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin,\nAlexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen,\net al. 2023. Palm 2 technical report. arXiv preprint arXiv:2305.10403 (2023).\n[7] Forest APP. 2021. Stay focused, be present. (2021). https://www.forestapp.cc/.\n[8] Apple. 2021. About the security content of iOS 14.1 and iPadOS 14.1. (2021).\nhttps://support.apple.com/en-us/HT208982.\n[9] Md Arefin, Md Islam, Mohitul Mustafi, Sharmina Afrin, Nazrul Islam, et al. 2018.\nImpact of smartphone addiction on academic performance of business students:\nA case study. Md. and Mustafi, Mohitul and Afrin, Sharmina and Islam, Nazrul,\nImpact of Smartphone Addiction on Academic Performance of Business Students:\nA Case Study (August 21, 2018) (2018).\n[10] Cecil A Arnolds and Christo Boshoff. 2002. Compensation, esteem valence and\njob performance: an empirical assessment of Alderfer’s ERG theory.International\nJournal of Human Resource Management 13, 4 (2002), 697–719.\n[11] Amanda Baughan, Mingrui Ray Zhang, Raveena Rao, Kai Lukoff, Anastasia\nSchaadhardt, Lisa D Butler, and Alexis Hiniker. 2022. “I Don’t Even Remember\nWhat I Read”: How Design Influences Dissociation on Social Media. In Pro-\nceedings of the 2022 CHI Conference on Human Factors in Computing Systems .\n1–13.\n[12] Joseph B Bayer and Robert LaRose. 2018. Technology habits: Progress, problems,\nand prospects. The psychology of habit: Theory, mechanisms, change, and contexts\n(2018), 111–130.\n[13] Stefan F Bernritter, Iris van Ooijen, and Barbara CN Müller. 2017. Self-persuasion\nas marketing technique: the role of consumers’ involvement. European Journal\nof Marketing 51, 5/6 (2017), 1075–1090.\n[14] Lauren G Block and Punam Anand Keller. 1997. Effects of self-efficacy and\nvividness on the persuasiveness of health communications. Journal of consumer\npsychology 6, 1 (1997), 31–54.\n[15] Jane R Caulton. 2012. The development and use of the theory of ERG: A literature\nreview. Emerging Leadership Journeys 5, 1 (2012), 2–8.\n[16] Weihao Chen, Chun Yu, Huadong Wang, Zheng Wang, Lichen Yang, Yukun\nWang, Weinan Shi, and Yuanchun Shi. 2023. From Gap to Synergy: Enhancing\nContextual Understanding through Human-Machine Collaboration in Personal-\nized Systems. InProceedings of the 36th Annual ACM Symposium on User Interface\nSoftware and Technology . 1–15.\n[17] Shao-I Chiu. 2014. The relationship between life stress and smartphone addiction\non Taiwanese university student: A mediation model of learning self-efficacy\nand social self-efficacy. Computers in human behavior 34 (2014), 49–57.\n[18] Eun Kyoung Choe, Saeed Abdullah, Mashfiqui Rabbi, Edison Thomaz, Daniel A\nEpstein, Felicia Cordeiro, Matthew Kay, Gregory D Abowd, Tanzeem Choudhury,\nJames Fogarty, et al. 2017. Semi-automated tracking: a balanced approach for\nself-monitoring applications. IEEE Pervasive Computing 16, 1 (2017), 74–84.\n[19] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav\nMishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Se-\nbastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways.\narXiv preprint arXiv:2204.02311 (2022).\n[20] Robert B Cialdini and Robert B Cialdini. 2007. Influence: The psychology of\npersuasion. Vol. 55. Collins New York.\n[21] Matteo Ciman and Katarzyna Wac. 2016. Individuals’ stress assessment us-\ning human-smartphone interaction analysis. IEEE Transactions on Affective\nComputing 9, 1 (2016), 51–65.\n[22] Russell B Clayton, Glenn Leshner, and Anthony Almond. 2015. The extended\niSelf: The impact of iPhone separation on cognition, emotion, and physiology.\nJournal of computer-mediated communication 20, 2 (2015), 119–135.\n[23] Emily IM Collins, Anna L Cox, Jon Bird, and Cassie Cornish-Tresstail. 2014. Bar-\nriers to engagement with a personal informatics productivity tool. InProceedings\nof the 26th Australian Computer-Human interaction Conference on Designing\nfutures: The future of design . 370–379.\n[24] Bruce E Compas, Jennifer K Connor-Smith, Heidi Saltzman, Alexandria Harding\nThomsen, and Martha E Wadsworth. 2001. Coping with stress during childhood\nand adolescence: problems, progress, and potential in theory and research.\nPsychological bulletin 127, 1 (2001), 87.\n[25] Sarah M Coyne, Jane Shawcroft, Megan Gale, Douglas A Gentile, Jordan T\nEtherington, Hailey Holmgren, and Laura Stockdale. 2021. Tantrums, toddlers\nand technology: Temperament, media emotion regulation, and problematic\nmedia use in early childhood. Computers in Human Behavior 120 (2021), 106762.\n[26] Éilish Duke and Christian Montag. 2017. Smartphone addiction, daily inter-\nruptions and self-reported productivity. Addictive behaviors reports 6 (2017),\n90–95.\n[27] Megan Duvenage, Helen Correia, Bep Uink, Bonnie L Barber, Caroline L Dono-\nvan, and Kathryn L Modecki. 2020. Technology can sting when reality bites:\nAdolescents’ frequent online coping is ineffective with momentary stress. Com-\nputers in Human Behavior 102 (2020), 248–259.\n[28] Zachary Englhardt, Chengqian Ma, Margaret E Morris, Xuhai Xu, Chun-Cheng\nChang, Lianhui Qin, Xin Liu, Shwetak Patel, Vikram Iyer, et al . 2023. From\nClassification to Clinical Insights: Towards Analyzing and Reasoning About\nMobile and Behavioral Health Data With Large Language Models.arXiv preprint\narXiv:2311.13063 (2023).\n[29] Xavier Ferrer, Tom van Nuenen, Jose M Such, Mark Coté, and Natalia Criado.\n2021. Bias and discrimination in AI: a cross-disciplinary perspective. IEEE\nTechnology and Society Magazine 40, 2 (2021), 72–80.\n[30] Cynthia D Fisherl. 1993. Boredom at work: A neglected concept.Human relations\n46, 3 (1993), 395–417.\n[31] Shruti Gedam and Sanchita Paul. 2021. A review on mental stress detection\nusing wearable sensors and machine learning techniques. IEEE Access 9 (2021),\n84045–84066.\n[32] Stephanie P Goldstein, Brittney C Evans, Daniel Flack, Adrienne Juarascio,\nStephanie Manasse, Fengqing Zhang, and Evan M Forman. 2017. Return of the\nJITAI: applying a just-in-time adaptive intervention framework to the devel-\nopment of m-health solutions for addictive behaviors. International journal of\nbehavioral medicine 24 (2017), 673–682.\n[33] Colin M Gray, Yubo Kou, Bryan Battles, Joseph Hoggatt, and Austin L Toombs.\n2018. The dark (patterns) side of UX design. In Proceedings of the 2018 CHI\nconference on human factors in computing systems . 1–14.\n[34] Martin S Hagger. 2016. Non-conscious processes and dual-process theories in\nhealth psychology. Health Psychology Review 10, 4 (2016), 375–380.\n[35] Jaap Ham and Sitwat Usman Langrial. 2020. Learning to Stop Smoking: Under-\nstanding Persuasive Applications’ Long-Term Behavior Change Effectiveness\nThrough User Achievement Motivation. In Persuasive Technology. Designing\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Wu et al.\nfor Future Change: 15th International Conference on Persuasive Technology, PER-\nSUASIVE 2020, Aalborg, Denmark, April 20–23, 2020, Proceedings 15 . Springer,\n139–149.\n[36] Daniel Harrison, Paul Marshall, Nadia Bianchi-Berthouze, and Jon Bird. 2015.\nActivity tracking: barriers, workarounds and customisation. InProceedings of the\n2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing .\n617–621.\n[37] Andree Hartanto and Hwajin Yang. 2016. Is the smartphone a smart choice? The\neffect of smartphone separation on executive functions. Computers in human\nbehavior 64 (2016), 329–336.\n[38] Thomas Hartvigsen, Saadia Gabriel, Hamid Palangi, Maarten Sap, Dipankar Ray,\nand Ece Kamar. 2022. Toxigen: A large-scale machine-generated dataset for\nadversarial and implicit hate speech detection. arXiv preprint arXiv:2203.09509\n(2022).\n[39] Joshua Harwood, Julian J Dooley, Adrian J Scott, and Richard Joiner. 2014.\nConstantly connected–The effects of smart-devices on mental health.Computers\nin Human Behavior 34 (2014), 267–272.\n[40] Liang He, Ruolin Wang, and Xuhai Xu. 2020. PneuFetch: supporting blind\nand visually impaired people to fetch nearby objects via light haptic cues. In\nExtended Abstracts of the 2020 CHI Conference on Human Factors in Computing\nSystems. 1–9.\n[41] Blake Anthony Hickey, Taryn Chalmers, Phillip Newton, Chin-Teng Lin, David\nSibbritt, Craig S McLachlan, Roderick Clifton-Bligh, John Morley, and Sara Lal.\n2021. Smart devices and wearable technologies to detect and monitor mental\nhealth conditions and stress: A systematic review. Sensors 21, 10 (2021), 3461.\n[42] Alexis Hiniker, Sungsoo Hong, Tadayoshi Kohno, and Julie A Kientz. 2016.\nMyTime: designing and evaluating an intervention for smartphone non-use. In\nProceedings of the 2016 CHI conference on human factors in computing systems .\n4746–4757.\n[43] Alexis Hiniker, Shwetak N Patel, Tadayoshi Kohno, and Julie A Kientz. 2016. Why\nwould you do that? predicting the uses and gratifications behind smartphone-\nusage behaviors. In Proceedings of the 2016 ACM International Joint Conference\non Pervasive and Ubiquitous Computing . 634–645.\n[44] Wilhelm Hofmann, Malte Friese, and Fritz Strack. 2009. Impulse and self-control\nfrom a dual-systems perspective. Perspectives on psychological science 4, 2 (2009),\n162–176.\n[45] Kyung-Hye Hwang, Yang-Sook Yoo, and Ok-Hee Cho. 2012. Smartphone overuse\nand upper extremity pain, anxiety, depression, and interpersonal relationships\namong college students. The Journal of the Korea Contents Association 12, 10\n(2012), 365–375.\n[46] Bytedance Inc. 2023. Tiktok App. (2023). https://www.tiktok.com/.\n[47] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii,\nYe Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of hallucination\nin natural language generation. Comput. Surveys 55, 12 (2023), 1–38.\n[48] Eunkyung Jo, Daniel A Epstein, Hyunhoon Jung, and Young-Ho Kim. 2023.\nUnderstanding the Benefits and Challenges of Deploying Conversational AI\nLeveraging Large Language Models for Public Health Intervention. In Proceed-\nings of the 2023 CHI Conference on Human Factors in Computing Systems . 1–16.\n[49] Daniel Kahneman. 2011. Thinking, fast and slow . macmillan.\n[50] Maurits Kaptein, Boris De Ruyter, Panos Markopoulos, and Emile Aarts. 2012.\nAdaptive persuasive systems: a study of tailored persuasive text messages to\nreduce snacking. ACM Transactions on Interactive Intelligent Systems (TiiS) 2, 2\n(2012), 1–25.\n[51] Maurits Kaptein, Panos Markopoulos, Boris De Ruyter, and Emile Aarts. 2015.\nPersonalizing persuasive technologies: Explicit and implicit personalization\nusing persuasion profiles. International Journal of Human-Computer Studies 77\n(2015), 38–51.\n[52] Alan E Kazdin. 1982. Observer effects: Reactivity of direct observation. New\nDirections for Methodology of Social & Behavioral Science (1982).\n[53] Inyeop Kim, Gyuwon Jung, Hayoung Jung, Minsam Ko, and Uichin Lee. 2017.\nLet’s focus: location-based intervention tool to mitigate phone use in college\nclassrooms. In Proceedings of the 2017 ACM International Joint Conference on Per-\nvasive and Ubiquitous Computing and Proceedings of the 2017 ACM International\nSymposium on Wearable Computers . 101–104.\n[54] Jaejeung Kim, Hayoung Jung, Minsam Ko, and Uichin Lee. 2019. Goalkeeper:\nExploring interaction lockout mechanisms for regulating smartphone use. Pro-\nceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies\n3, 1 (2019), 1–29.\n[55] Jaejeung Kim, Joonyoung Park, Hyunsoo Lee, Minsam Ko, and Uichin Lee. 2019.\nLocknType: Lockout task intervention for discouraging smartphone app use. In\nProceedings of the 2019 CHI conference on human factors in computing systems .\n1–12.\n[56] Yubin Kim, Xuhai Xu, Daniel McDuff, Cynthia Breazeal, and Hae Won Park.\n2024. Health-LLM: Large Language Models for Health Prediction via Wearable\nSensor Data. arXiv preprint arXiv:2401.06866 (2024).\n[57] Young-Ho Kim, Jae Ho Jeon, Eun Kyoung Choe, Bongshin Lee, KwonHyun Kim,\nand Jinwook Seo. 2016. TimeAware: Leveraging framing effects to enhance\npersonal productivity. In Proceedings of the 2016 CHI Conference on Human\nFactors in Computing Systems . 272–283.\n[58] Minsam Ko, Subin Yang, Joonwon Lee, Christian Heizmann, Jinyoung Jeong,\nUichin Lee, Daehee Shin, Koji Yatani, Junehwa Song, and Kyong-Mee Chung.\n2015. NUGU: a group-based intervention app for improving self-regulation of\nlimiting smartphone use. In Proceedings of the 18th ACM conference on computer\nsupported cooperative work & social computing . 1235–1245.\n[59] Jaap M Koolhaas, Alessandro Bartolomucci, Bauke Buwalda, Seitse F de Boer,\nGabriele Flügge, S Mechiel Korte, Peter Meerlo, Robert Murison, Berend Olivier,\nPaola Palanza, et al. 2011. Stress revisited: a critical evaluation of the stress\nconcept. Neuroscience & Biobehavioral Reviews 35, 5 (2011), 1291–1301.\n[60] Geza Kovacs, Zhengxuan Wu, and Michael S Bernstein. 2018. Rotating online\nbehavior change interventions increases effectiveness but also increases attrition.\nProceedings of the ACM on Human-Computer Interaction 2, CSCW (2018), 1–25.\n[61] Harsh Kumar, Yiyi Wang, Jiakai Shi, Ilya Musabirov, Norman A. S. Farb, and\nJoseph Jay Williams. 2023. Exploring the Use of Large Language Models for\nImproving the Awareness of Mindfulness. In Extended Abstracts of the 2023 CHI\nConference on Human Factors in Computing Systems (Hamburg, Germany) (CHI\nEA ’23). Association for Computing Machinery, New York, NY, USA, Article 129,\n7 pages. https://doi.org/10.1145/3544549.3585614\n[62] Tiffany H Kung, Morgan Cheatham, Arielle Medenilla, Czarina Sillos, Lo-\nrie De Leon, Camille Elepaño, Maria Madriaga, Rimel Aggabao, Giezel Diaz-\nCandido, James Maningo, et al . 2023. Performance of ChatGPT on USMLE:\nPotential for AI-assisted medical education using large language models. PLoS\ndigital health 2, 2 (2023), e0000198.\n[63] Peter Kuppens, Nicholas B Allen, and Lisa B Sheeber. 2010. Emotional inertia\nand psychological maladjustment. Psychological science 21, 7 (2010), 984–991.\n[64] Min Kwon, Joon-Yeop Lee, Wang-Youn Won, Jae-Woo Park, Jung-Ah Min, Chang-\ntae Hahn, Xinyu Gu, Ji-Hye Choi, and Dai-Jin Kim. 2013. Development and\nvalidation of a smartphone addiction scale (SAS). PloS one 8, 2 (2013), e56936.\n[65] Bishal Lamichhane. 2023. Evaluation of chatgpt for nlp-based mental health\napplications. arXiv preprint arXiv:2303.15727 (2023).\n[66] Liette Lapointe, Camille Boudreau-Pinsonneault, and Isaac Vaghefi. 2013. Is\nsmartphone usage truly smart? A qualitative investigation of IT addictive be-\nhaviors. In 2013 46th Hawaii international conference on system sciences . IEEE,\n1063–1072.\n[67] Uichin Lee, Joonwon Lee, Minsam Ko, Changhun Lee, Yuhwan Kim, Subin Yang,\nKoji Yatani, Gahgene Gweon, Kyong-Mee Chung, and Junehwa Song. 2014.\nHooked on smartphones: an exploratory study on smartphone overuse among\ncollege students. In Proceedings of the SIGCHI conference on human factors in\ncomputing systems . 2327–2336.\n[68] Damien Lekkas, George D Price, and Nicholas C Jacobson. 2022. Using smart-\nphone app use and lagged-ensemble machine learning for the prediction of\nwork fatigue and boredom. Computers in human behavior 127 (2022), 107029.\n[69] Cheng Li, Jindong Wang, Kaijie Zhu, Yixuan Zhang, Wenxin Hou, Jianxun Lian,\nand Xing Xie. 2023. Emotionprompt: Leveraging psychology for large language\nmodels enhancement via emotional stimulus. arXiv preprint arXiv:2307.11760\n(2023).\n[70] Yu-Hsuan Lin, Li-Ren Chang, Yang-Han Lee, Hsien-Wei Tseng, Terry BJ Kuo,\nand Sue-Huei Chen. 2014. Development and validation of the Smartphone\nAddiction Inventory (SPAI). PloS one 9, 6 (2014), e98312.\n[71] Bingjie Liu and S Shyam Sundar. 2018. Should machines express sympathy and\nempathy? Experiments with a health advice chatbot. Cyberpsychology, Behavior,\nand Social Networking 21, 10 (2018), 625–636.\n[72] Markus Löchtefeld, Matthias Böhmer, and Lyubomir Ganev. 2013. AppDetox:\nhelping users with mobile app addiction. In Proceedings of the 12th international\nconference on mobile and ubiquitous multimedia . 1–2.\n[73] Tao Lu, Hongxiao Zheng, Tianying Zhang, Xuhai Xu, and Anhong Guo. 2024.\nInteractOut: Leveraging Interaction Proxies as Input Manipulation Strategies\nfor Reducing Smartphone Overuse. In Proceedings of the 2024 CHI conference\non human factors in computing systems . Association for Computing Machinery,\nNew York, NY, USA, 1–18.\n[74] Kai Lukoff, Ulrik Lyngs, Karina Shirokova, Raveena Rao, Larry Tian, Himanshu\nZade, Sean A. Munson, and Alexis Hiniker. 2023. SwitchTube: A Proof-of-\nConcept System Introducing “Adaptable Commitment Interfaces” as a Tool\nfor Digital Wellbeing. In Proceedings of the 2023 CHI Conference on Human\nFactors in Computing Systems (Hamburg, Germany) (CHI ’23) . Association for\nComputing Machinery, New York, NY, USA, Article 197, 22 pages. https:\n//doi.org/10.1145/3544548.3580703\n[75] Kai Lukoff, Ulrik Lyngs, Himanshu Zade, J Vera Liao, James Choi, Kaiyue Fan,\nSean A Munson, and Alexis Hiniker. 2021. How the design of youtube influences\nuser sense of agency. InProceedings of the 2021 CHI Conference on Human Factors\nin Computing Systems . 1–17.\n[76] Kai Lukoff, Cissy Yu, Julie Kientz, and Alexis Hiniker. 2018. What makes smart-\nphone use meaningful or meaningless? Proceedings of the ACM on Interactive,\nMobile, Wearable and Ubiquitous Technologies 2, 1 (2018), 1–26.\n[77] Ulrik Lyngs, Kai Lukoff, Laura Csuka, Petr Slovák, Max Van Kleek, and Nigel\nShadbolt. 2022. The Goldilocks level of support: Using user reviews, ratings,\nand installation numbers to investigate digital self-control tools. International\nMindShift CHI ’24, May 11–16, 2024, Honolulu, HI, USA\njournal of human-computer studies 166 (2022), 102869.\n[78] Ulrik Lyngs, Kai Lukoff, Petr Slovak, Reuben Binns, Adam Slack, Michael Inzlicht,\nMax Van Kleek, and Nigel Shadbolt. 2019. Self-control in cyberspace: Applying\ndual systems theory to a review of digital self-control tools. In proceedings of\nthe 2019 CHI conference on human factors in computing systems . 1–18.\n[79] Ulrik Lyngs, Kai Lukoff, Petr Slovak, William Seymour, Helena Webb, Marina\nJirotka, Jun Zhao, Max Van Kleek, and Nigel Shadbolt. 2020. ’I Just Want to Hack\nMyself to Not Get Distracted’ Evaluating Design Interventions for Self-Control\non Facebook. In Proceedings of the 2020 CHI Conference on Human Factors in\nComputing Systems . 1–15.\n[80] Amama Mahmood, Junxiang Wang, Bingsheng Yao, Dakuo Wang, and Chien-\nMing Huang. 2023. LLM-Powered Conversational Voice Assistants: Interaction\nPatterns, Opportunities, Challenges, and Design Guidelines. arXiv preprint\narXiv:2309.13879 (2023).\n[81] Lakmal Meegahapola, William Droz, Peter Kun, Amalia De Götzen, Chaitanya\nNutakki, Shyam Diwakar, Salvador Ruiz Correa, Donglei Song, Hao Xu, Miriam\nBidoglia, et al. 2023. Generalization and Personalization of Mobile Sensing-Based\nMood Inference Models: An Analysis of College Students in Eight Countries.Pro-\nceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies\n6, 4 (2023), 1–32.\n[82] William L Mikulas and Stephen J Vodanovich. 1993. The essence of boredom.\nThe Psychological Record 43, 1 (1993), 3.\n[83] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu\nNguyen, Oscar Sainz, Eneko Agirre, Ilana Heintz, and Dan Roth. 2021. Recent\nadvances in natural language processing via large pre-trained language models:\nA survey. Comput. Surveys (2021).\n[84] Lewis Mitchell and Zaheer Hussain. 2018. Predictors of problematic smartphone\nuse: An examination of the integrative pathways model and the role of age, gen-\nder, impulsiveness, excessive reassurance seeking, extraversion, and depression.\nBehavioral Sciences 8, 8 (2018), 74.\n[85] Alberto Monge Roffarello and Luigi De Russis. 2019. The race towards digital\nwellbeing: Issues and opportunities. In Proceedings of the 2019 CHI conference on\nhuman factors in computing systems . 1–14.\n[86] Alberto Monge Roffarello and Luigi De Russis. 2023. Nudging Users or Re-\ndesigning Interfaces? Evaluating Novel Strategies for Digital Wellbeing Through\ninControl. In Proceedings of the 2023 ACM Conference on Information Technology\nfor Social Good . 100–109.\n[87] Alberto Monge Roffarello, Kai Lukoff, Luigi De Russis, et al . 2023. Defining\nand Identifying Attention Capture Damaging Patterns in Digital Interfaces. In\nProceedings of the 2023 CHI Conference on Human Factors in Computing Systems .\nACM, 1–30.\n[88] Sara Montagna, Stefano Ferretti, Lorenz Cuno Klopfenstein, Antonio Florio, and\nMartino Francesco Pengo. 2023. Data Decentralisation of LLM-Based Chatbot\nSystems in Chronic Disease Self-Management. In Proceedings of the 2023 ACM\nConference on Information Technology for Social Good . 205–212.\n[89] Robert R Morris, Kareem Kouddous, Rohan Kshirsagar, and Stephen M Schueller.\n2018. Towards an artificially empathic conversational agent for mental health\napplications: system design and user perceptions. Journal of medical Internet\nresearch 20, 6 (2018), e10148.\n[90] Inbal Nahum-Shani, Shawna N Smith, Bonnie J Spring, Linda M Collins, Katie\nWitkiewitz, Ambuj Tewari, and Susan A Murphy. 2018. Just-in-time adaptive\ninterventions (JITAIs) in mobile health: key components and design principles\nfor ongoing health behavior support. Annals of Behavioral Medicine 52, 6 (2018),\n446–462.\n[91] Ulrike E Nett, Thomas Goetz, and Lia M Daniels. 2010. What to do when feeling\nbored?: Students’ strategies for coping with boredom. Learning and Individual\nDifferences 20, 6 (2010), 626–638.\n[92] Chukwuemeka Nwagu. 2023. Design and Evaluation of the Chai Wallpaper:\nA Mindfulness-Based Persuasive Intervention for Absent-Minded Smartphone\nUse. (2023).\n[93] Fabian Okeke, Michael Sobolev, Nicola Dell, and Deborah Estrin. 2018. Good\nvibrations: can a digital nudge reduce digital overload?. In Proceedings of the\n20th international conference on human-computer interaction with mobile devices\nand services . 1–12.\n[94] OpenAI. 2022. Introducing ChatGPT. (2022). https://openai.com/blog/chatgpt.\n[95] OpenAI. 2023. GPT best practices. (2023). https://platform.openai.com/docs/\nguides/gpt-best-practices.\n[96] Rita Orji and Karyn Moffatt. 2018. Persuasive technology for health and wellness:\nState-of-the-art and emerging trends. Health informatics journal 24, 1 (2018),\n66–91.\n[97] Adiba Orzikulova, Han Xiao, Zhipeng Li, Yukang Yan, Yuntao Wang, Yuanchun\nShi, Marzyeh Ghassemi, Sung-Ju Lee, Anind K. Dey, and Xuhai Xu. 2024.\nTime2Stop: Adaptive and Explainable Human-AI Loop for Smartphone Overuse\nIntervention. In Proceedings of the 2024 CHI conference on human factors in\ncomputing systems . Association for Computing Machinery, New York, NY, USA,\n1–18. https://doi.org/10.1145/3613904.3642747\n[98] Hancheol Park and Gahgene Gweon. 2015. Initiating moderation in problematic\nsmartphone usage patterns. In Proceedings of the 33rd Annual ACM Conference\nExtended Abstracts on Human Factors in Computing Systems . 1585–1590.\n[99] Joonyoung Park, Jin Yong Sim, Jaejeung Kim, Mun Yong Yi, and Uichin Lee. 2018.\nInteraction restraint: enforcing adaptive cognitive tasks to restrain problematic\nuser interaction. In Extended Abstracts of the 2018 CHI Conference on Human\nFactors in Computing Systems . 1–6.\n[100] Martin Pielot, Tilman Dingler, Jose San Pedro, and Nuria Oliver. 2015. When\nattention is not scarce-detecting boredom from mobile phone usage. In Proceed-\nings of the 2015 ACM international joint conference on pervasive and ubiquitous\ncomputing. 825–836.\n[101] Charlie Pinder, Jo Vermeulen, Benjamin R Cowan, and Russell Beale. 2018. Digi-\ntal behaviour change interventions to break and form habits. ACM Transactions\non Computer-Human Interaction (TOCHI) 25, 3 (2018), 1–66.\n[102] Aarathi Prasad, Lucas S LaFreniere, Vaasu Taneja, and Zoe Beals. 2021. Address-\ning Problematic Smartphone Use with a Personalized, Goal-based Approach. In\nAdjunct Proceedings of the 2021 ACM International Joint Conference on Perva-\nsive and Ubiquitous Computing and Proceedings of the 2021 ACM International\nSymposium on Wearable Computers . 131–134.\n[103] Paul C Price, Rajiv S Jhangiani, and I-Chant A Chiang. 2015. Reliability and\nvalidity of measurement. Research methods in psychology (2015).\n[104] Aditya Kumar Purohit, Louis Barclay, and Adrian Holzer. 2020. Designing for\ndigital detox: Making social media less addictive with digital nudges. InExtended\nAbstracts of the 2020 CHI Conference on Human Factors in Computing Systems .\n1–9.\n[105] Aditya Kumar Purohit, Torben Jan Barev, Sofia Schöbel, Andreas Janson, and\nAdrian Holzer. 2023. Designing for DigitalWellbeing on a Smartphone: Co-\ncreation of Digital Nudges to Mitigate Instagram Overuse. (2023).\n[106] Aditya Kumar Purohit, Kristoffer Bergram, Louis Barclay, Valéry Bezençon, and\nAdrian Holzer. 2023. Starving the Newsfeed for Social Media Detox: Effects of\nStrict and Self-regulated Facebook Newsfeed Diets. In Proceedings of the 2023\nCHI Conference on Human Factors in Computing Systems . 1–16.\n[107] Aditya Kumar Purohit and Adrian Holzer. 2019. Functional digital nudges:\nIdentifying optimal timing for effective behavior change. In Extended abstracts\nof the 2019 CHI conference on human factors in computing systems . 1–6.\n[108] Christof Rapp. 2002. Aristotle’s rhetoric. (2002).\n[109] Alan M Rubin. 2009. Uses and gratifications. The SAGE handbook of media\nprocesses and effects (2009), 147–159.\n[110] Maya Samaha and Nazir S Hawi. 2016. Relationships among smartphone ad-\ndiction, stress, academic performance, and satisfaction with life. Computers in\nhuman behavior 57 (2016), 321–325.\n[111] Ralf Schwarzer and Matthias Jerusalem. 1995. Generalized self-efficacy scale.\nJ. Weinman, S. Wright, & M. Johnston, Measures in health psychology: A user’s\nportfolio. Causal and control beliefs 35 (1995), 37.\n[112] Jungryul Seo, Teemu H Laine, and Kyung-Ah Sohn. 2019. An exploration of\nmachine learning methods for robust boredom classification using EEG and\nGSR data. Sensors 19, 20 (2019), 4561.\n[113] Jungryul Seo, Teemu H Laine, and Kyung-Ah Sohn. 2019. Machine learning\napproaches for boredom classification using EEG.Journal of Ambient Intelligence\nand Humanized Computing 10 (2019), 3831–3846.\n[114] Herbert W Simons. 1976. Persuasion: Understanding, practice, and analysis.\n(No Title) (1976).\n[115] Thomas Stütz, Thomas Kowar, Michael Kager, Martin Tiefengrabner, Markus\nStuppner, Jens Blechert, Frank H Wilhelm, and Simon Ginzinger. 2015. Smart-\nphone based stress prediction. In User Modeling, Adaptation and Personalization:\n23rd International Conference, UMAP 2015, Dublin, Ireland, June 29–July 3, 2015.\nProceedings 23 . Springer, 240–251.\n[116] Kelly J Thomas Craig, Laura C Morgan, Ching-Hua Chen, Susan Michie, Nicole\nFusco, Jane L Snowdon, Elisabeth Scheufele, Thomas Gagliardi, and Stewart Sill.\n2021. Systematic review of context-aware digital behavior change interventions\nto improve health. Translational behavioral medicine 11, 5 (2021), 1037–1048.\n[117] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi,\nYasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\nBhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models.\narXiv preprint arXiv:2307.09288 (2023).\n[118] Jonathan A Tran, Katie S Yang, Katie Davis, and Alexis Hiniker. 2019. Modeling\nthe engagement-disengagement cycle of compulsive phone use. In Proceedings\nof the 2019 CHI conference on human factors in computing systems . 1–14.\n[119] Zahra Vahedi and Alyssa Saiphoo. 2018. The association between smartphone\nuse, stress, and anxiety: A meta-analytic review. Stress and Health 34, 3 (2018),\n347–358.\n[120] Chuang Wang, Matthew Lee, and Zhongsheng Hua. 2014. Understanding\nand predicting compulsive smartphone use: An extension of reinforcement\nsensitivity approach. (2014).\n[121] Chuang Wang and Matthew KO Lee. 2020. Why we cannot resist our smart-\nphones: investigating compulsive use of mobile SNS from a Stimulus-Response-\nReinforcement perspective. Journal of the Association for Information Systems\n21, 1 (2020), 4.\n[122] Jing Wei, Sungdong Kim, Hyunhoon Jung, and Young-Ho Kim. 2023. Leveraging\nLarge Language Models to Power Chatbots for Collecting User Self-Reported\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Wu et al.\nData.\n[123] Steve Whittaker, Vaiva Kalnikaite, Victoria Hollis, and Andrew Guydish. 2016.\n’Don’t Waste My Time’ Use of Time Information Improves Focus. InProceedings\nof the 2016 CHI Conference on Human Factors in Computing Systems . 1729–1738.\n[124] Xuhai Xu, Prerna Chikersal, Afsaneh Doryab, Daniella K Villalba, Janine M\nDutcher, Michael J Tumminia, Tim Althoff, Sheldon Cohen, Kasey G Creswell,\nJ David Creswell, et al. 2019. Leveraging routine behavior and contextually-\nfiltered features for depression detection among college students. Proceedings of\nthe ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 3, 3 (2019),\n1–33.\n[125] Xuhai Xu, Prerna Chikersal, Janine M Dutcher, Yasaman S Sefidgar, Woosuk\nSeo, Michael J Tumminia, Daniella K Villalba, Sheldon Cohen, Kasey G Creswell,\nJ David Creswell, et al. 2021. Leveraging collaborative-filtering for personal-\nized behavior modeling: a case study of depression detection among college\nstudents. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous\nTechnologies 5, 1 (2021), 1–27.\n[126] Xuhai Xu, Bingshen Yao, Yuanzhe Dong, Saadia Gabriel, Hong Yu, James Hendler,\nMarzyeh Ghassemi, Anind K. Dey, and Dakuo Wang. 2023. Mental-LLM: Lever-\naging Large Language Models for Mental Health Prediction via Online Text\nData. arXiv:2307.14385 [cs.HC]\n[127] Xuhai Xu, Han Zhang, Yasaman Sefidgar, Yiyi Ren, Xin Liu, Woosuk Seo, Jen-\nnifer Brown, Kevin Kuehn, Mike Merrill, Paula Nurius, Shwetak Patel, Tim\nAlthoff, Margaret E Morris, Eve Riskin, Jennifer Mankoff, and Anind K Dey.\n2022. GLOBEM Dataset: Multi-Year Datasets for Longitudinal Human Behav-\nior Modeling Generalization. In Thirty-sixth Conference on Neural Information\nProcessing Systems Datasets and Benchmarks Track . 18.\n[128] Xuhai Xu, Tianyuan Zou, Han Xiao, Yanzhang Li, Ruolin Wang, Tianyi Yuan,\nYuntao Wang, Yuanchun Shi, Jennifer Mankoff, and Anind K Dey. 2022. TypeOut:\nLeveraging Just-in-Time Self-Affirmation for Smartphone Overuse Reduction. In\nProceedings of the 2022 CHI Conference on Human Factors in Computing Systems .\n1–17.\n[129] Ziqi Yang, Xuhai Xu, Bingsheng Yao, Shao Zhang, Ethan Rogers, Stephen Intille,\nNawar Shara, Dakuo Wang, et al. 2023. Talk2Care: Facilitating Asynchronous\nPatient-Provider Communication with Large-Language-Model. arXiv preprint\narXiv:2309.09357 (2023).\n[130] Li Yunxiang, Li Zihan, Zhang Kai, Dan Ruilong, and Zhang You. 2023. Chat-\ndoctor: A medical chat model fine-tuned on llama model using medical domain\nknowledge. arXiv preprint arXiv:2303.14070 (2023).\n[131] Mingrui Ray Zhang, Kai Lukoff, Raveena Rao, Amanda Baughan, and Alexis\nHiniker. 2022. Monitoring Screen Time or Redesigning It? Two Approaches\nto Supporting Intentional Social Media Use. In Proceedings of the 2022 CHI\nConference on Human Factors in Computing Systems . 1–19.\n[132] Terry Yue Zhuo, Yujin Huang, Chunyang Chen, and Zhenchang Xing. 2023. Ex-\nploring ai ethics of chatgpt: A diagnostic analysis.arXiv preprint arXiv:2301.12867\n(2023).\n[133] Andras N Zsido, Nikolett Arato, Andras Lang, Beatrix Labadi, Diana Stecina, and\nSzabolcs A Bandi. 2021. The role of maladaptive cognitive emotion regulation\nstrategies and social anxiety in problematic smartphone and social media use.\nPersonality and Individual Differences 173 (2021), 110647.\nMindShift CHI ’24, May 11–16, 2024, Honolulu, HI, USA\nAPPENDIX\nTable 4: Persuasive Messages in WoZ Study. Four types of persuasive messages delivered in WoZ study and their examples.\nTypes Examples\nUsage Notice \"You have used Wechat for 2 hours and 25 minutes today. Put down your phone please!\"\nPractical Guidance \"Are you still using WeChat? Have you completed the task of analyzing data today?\"\nEncouragement \"You have only spent 2 hours on your phone today, that’s excellent! Keep up the good work ∼\"\nDeterrent \"Using the phone before bedtime can affect the quality of your sleep. \"\nTable 5: Takeaways from WoZ & semi-structured interview studies. (E) shows messages sent by experimenters, (W) demonstrates\nparticipants’ reflection quotes in the WoZ study, and (S) means participants’ quotes in the semi-structured interview study.\nWoZ study\nTypes of smartphone use Representative quote(s)\nInstrumental use\n(not to be intervened)\n\"You’ve already spent one and a half an hour on WeChat today. Please put your phone down and focus on other aspects of\nlife. (E)\"\n\"I felt a bit resentful because I was using WeChat to manage my affairs, rather than idly wasting time. (W1)\"\nInstrumental use - relaxation\n(not to be intervened)\n\"Please stop browsing Zhihu and engage in more meaningful activities. (E)\"\n\"I don’t agree. Finding joy in browsing Zhihu constitutes meaning for me. (W5)\"\nHabitual use\n(to be intervened)\n\"You have used Zhihu for 2 hours today. Think about what else you have to do tonight. (E)\"\n\"Thanks for this suggestion. I always failed to control myself to open Zhihu. (W10)\"\nFactors affecting persuasion ef-\nfectiveness\nRepresentative quote(s)\nMental states \"When you find yourself with idle time, consider engaging in meaningful activities such as reading, writing, or drawing.\n(E)\"\n\"It correctly identified my state of not knowing what to do and offered sensible advice. (W11)\"\nPersonal goals \"Your WeChat session has lasted 10 minutes. Please set aside your device to alleviate eye strain. (E)\"\n\"Keeping the eyes healthy is one thing I really care about, so I like this advice. (W12)\"\nContextual information \"The afternoon is a good time for studying. Don’t spend too much time on your phone. (E)\"\n\"Afternoon is indeed my study time during which I should improve my efficiency. It is right. (W4)\"\nSemi-structured interview study\nMental states related to habit-\nual use\nRepresentative quote(s)\nBoredom \"I find myself instinctively reaching for my phone in search of mental stimulation when doing simple assignments light\non cognitive engagement. \" (S1)\nStress \"One day, work wasn’t progressing well and I was so frustrated that I unlocked my phone for a quick view to ease my\nmood. \" (S9)\nInertia \"Upon returning home after work, I intended to transition back into a focused state for reading or other activities but\nstruggled to shift from a relaxed state. At that point, my phone was the tool for procrastination. \" (S2)\nActivity engagement states Representative quote(s)\nEngaging in activities \"I was reluctant to start handling this challenging work that I scrolled my phone screen anxiously. \" (S2)\nNot engaging in activities \"After getting off work and returning home, I collapse on the sofa and binge-watch Tiktok for one to two hours. \" (S9)\nCHI ’24, May 11–16, 2024, Honolulu, HI, USA Wu et al.\nFigure 12: Interaction Process of Three Intervention Techniques. The two red process blocks illustrate the differences between\nthe three intervention techniques.",
  "topic": "Persuasion",
  "concepts": [
    {
      "name": "Persuasion",
      "score": 0.8854051828384399
    },
    {
      "name": "Boredom",
      "score": 0.4994635581970215
    },
    {
      "name": "Context (archaeology)",
      "score": 0.4979865550994873
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.4934164583683014
    },
    {
      "name": "Persuasive technology",
      "score": 0.484567791223526
    },
    {
      "name": "Mental health",
      "score": 0.48278605937957764
    },
    {
      "name": "Applied psychology",
      "score": 0.4520561099052429
    },
    {
      "name": "Intervention (counseling)",
      "score": 0.44438228011131287
    },
    {
      "name": "Smartphone application",
      "score": 0.44374826550483704
    },
    {
      "name": "Psychology",
      "score": 0.4319276809692383
    },
    {
      "name": "Psychological intervention",
      "score": 0.4115489423274994
    },
    {
      "name": "Computer science",
      "score": 0.37781211733818054
    },
    {
      "name": "Social psychology",
      "score": 0.3189266622066498
    },
    {
      "name": "Multimedia",
      "score": 0.22269240021705627
    },
    {
      "name": "Psychotherapist",
      "score": 0.11515083909034729
    },
    {
      "name": "Artificial intelligence",
      "score": 0.09020650386810303
    },
    {
      "name": "Psychiatry",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ]
}