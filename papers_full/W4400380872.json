{
    "title": "CoTCoNet: An optimized coupled transformer-convolutional network with an adaptive graph reconstruction for leukemia detection",
    "url": "https://openalex.org/W4400380872",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5100045823",
            "name": "Chandravardhan Singh Raghaw",
            "affiliations": [
                "Indian Institute of Technology Indore"
            ]
        },
        {
            "id": "https://openalex.org/A5104344712",
            "name": "Arnav Sharma",
            "affiliations": [
                "The University of Texas at Dallas"
            ]
        },
        {
            "id": "https://openalex.org/A5076096927",
            "name": "Shubhi Bansal",
            "affiliations": [
                "Indian Institute of Technology Indore"
            ]
        },
        {
            "id": "https://openalex.org/A5030387769",
            "name": "Mohammad Zia Ur Rehman",
            "affiliations": [
                "Indian Institute of Technology Indore"
            ]
        },
        {
            "id": "https://openalex.org/A5009822257",
            "name": "Nagendra Kumar",
            "affiliations": [
                "Indian Institute of Technology Indore"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4315754639",
        "https://openalex.org/W6748773803",
        "https://openalex.org/W6760324639",
        "https://openalex.org/W6852388363",
        "https://openalex.org/W4390613124",
        "https://openalex.org/W4316020772",
        "https://openalex.org/W2726556767",
        "https://openalex.org/W4390597412",
        "https://openalex.org/W4380369697",
        "https://openalex.org/W6862423394",
        "https://openalex.org/W4368376242",
        "https://openalex.org/W3004876557",
        "https://openalex.org/W4286516489",
        "https://openalex.org/W4310554239",
        "https://openalex.org/W3162222275",
        "https://openalex.org/W4390629764",
        "https://openalex.org/W4391788404",
        "https://openalex.org/W4388861117",
        "https://openalex.org/W6845908641",
        "https://openalex.org/W4392138800",
        "https://openalex.org/W4296009403",
        "https://openalex.org/W6850171904",
        "https://openalex.org/W4200485593",
        "https://openalex.org/W4303649515",
        "https://openalex.org/W6854800515",
        "https://openalex.org/W4318479195",
        "https://openalex.org/W3210804650",
        "https://openalex.org/W3093187293",
        "https://openalex.org/W6784276132",
        "https://openalex.org/W3137244318",
        "https://openalex.org/W3005177875",
        "https://openalex.org/W2994902461",
        "https://openalex.org/W3048471978",
        "https://openalex.org/W4306173965",
        "https://openalex.org/W6854824678",
        "https://openalex.org/W4321507483",
        "https://openalex.org/W4313704016",
        "https://openalex.org/W4352977351",
        "https://openalex.org/W4393336938",
        "https://openalex.org/W4308422427",
        "https://openalex.org/W6749781174",
        "https://openalex.org/W4287219540",
        "https://openalex.org/W4392883923",
        "https://openalex.org/W4391819303",
        "https://openalex.org/W4324144441",
        "https://openalex.org/W4324030848",
        "https://openalex.org/W6851578965",
        "https://openalex.org/W4390990291",
        "https://openalex.org/W6818723395",
        "https://openalex.org/W4392882143",
        "https://openalex.org/W2232317135",
        "https://openalex.org/W4221127924",
        "https://openalex.org/W6650527785",
        "https://openalex.org/W3044848211",
        "https://openalex.org/W6687483927",
        "https://openalex.org/W6725739302",
        "https://openalex.org/W6810938606",
        "https://openalex.org/W6792155083",
        "https://openalex.org/W6791353385",
        "https://openalex.org/W6798046796",
        "https://openalex.org/W4310722056",
        "https://openalex.org/W4224130636",
        "https://openalex.org/W4296182953",
        "https://openalex.org/W6639824700",
        "https://openalex.org/W6753182481",
        "https://openalex.org/W6726258750",
        "https://openalex.org/W4255344443",
        "https://openalex.org/W2884436604",
        "https://openalex.org/W4392238047",
        "https://openalex.org/W2789390702",
        "https://openalex.org/W4384945644",
        "https://openalex.org/W4301409532",
        "https://openalex.org/W4307844358",
        "https://openalex.org/W4385234734",
        "https://openalex.org/W4390956599",
        "https://openalex.org/W4234552385"
    ],
    "abstract": null,
    "full_text": "CoTCoNet: An Optimized Coupled Transformer-Convolutional Network with an\nAdaptive Graph Reconstruction for Leukemia Detection\nChandravardhan Singh Raghaw, Arnav Sharma, Shubhi Bansal, Mohammad Zia Ur Rehman, Nagendra Kumar\nHighlights\nâ€¢ An optimized novel coupled transformer-convolution network for leukemia detection.\nâ€¢ Correlated global and spatial features help in identifying hematological malignancies.\nâ€¢ Graph-based feature reconstruction module to capture hidden features of leukocytes.\nâ€¢ A deep synthetic leukocyte generator is devised to mitigate data imbalance issues.\nâ€¢ Extensive evaluations signify efficacy on four datasets with more than 16,982 WSIs.\nThis is the preprint version of the accepted paper.\nThis paper is accepted inComputers in Biology and Medicine, 2024.\nDOI: https://doi.org/10.1016/j.compbiomed.2024.108821\narXiv:2410.08797v2  [cs.CV]  21 Oct 2024\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network\nwith an Adaptive Graph Reconstruction for Leukemia Detection\nChandravardhan Singh Raghawa,âˆ—, Arnav Sharmab, Shubhi Bansala, Mohammad Zia Ur Rehmana\nand Nagendra Kumara\naDepartment of Computer Science and Engineering, Indian Institute of Technology Indore, Khandwa Road, Simrol, Indore, 453552, Madhya\nPradesh, India\nbDepartment of Computer Science, The University of Texas at Dallas, 800 W Campbell Rd, Richardson, 75080, Texas, USA\nARTICLE INFO\nKeywords:\nAcute lymphoblastic leukemia\nConvolutional neural networks\nTransformer\nCell classification\nDeep learning\nAbstract\nSwift and accurate blood smear analysis is an effective diagnostic method for leukemia and other\nhematological malignancies. However, manual leukocyte count and morphological evaluation using\na microscope is time-consuming and prone to errors. Conventional image processing methods also\nexhibit limitations in differentiating cells due to the visual similarity between malignant and benign\ncell morphology. This limitation is further compounded by the skewed training data that hinders\nthe extraction of reliable and pertinent features. In response to these challenges, we propose an\noptimizedCoupledTransformerConvolutionalNetwork(CoTCoNet)frameworkfortheclassification\nofleukemia,whichemploysawell-designedtransformerintegratedwithadeepconvolutionalnetwork\nto effectively capture comprehensive global features and scalable spatial patterns, enabling the\nidentificationofcomplexandlarge-scalehematologicalfeatures.Further,theframeworkincorporates\nagraph-basedfeaturereconstructionmoduletorevealthehiddenorunobservedhard-to-seebiological\nfeatures of leukocyte cells and employs a Population-based Meta-Heuristic Algorithm for feature\nselection and optimization. To mitigate data imbalance issues, we employ a synthetic leukocyte\ngenerator. In the evaluation phase, we initially assess CoTCoNet on a dataset containing 16,982\nannotated cells, and it achieves remarkable accuracy and F1-Score rates of 0.9894 and 0.9893,\nrespectively. To broaden the generalizability of our model, we evaluate it across four publicly\navailable diverse datasets, which include the aforementioned dataset. This evaluation demonstrates\nthatourmethodoutperformscurrentstate-of-the-artapproaches.Wealsoincorporateanexplainability\napproachintheformoffeaturevisualizationcloselyalignedwithcellannotationstoprovideadeeper\nunderstanding of the framework.\n1. Introduction\nLeukemia belongs to the broader class of blood cancer,\nwherein white blood cells (known as leukocytes) undergo\nmalignant transformation into cancerous entities. These en-\ntities lead to an uncontrolled increase in the leukocytes that\nhampersaveragebloodcellgrowthinleukemia.Regrettably,\nleukemia is the leading cause of cancer death worldwide,\nwith a significant impact on global public health [1]. No-\ntably, the mortality rates tend to be disproportionately high\nin Low and Middle Income Countries (LMICs) due to the\nscarcity of early diagnosis and high-quality treatment, re-\nsulting in an increased morbidity rate. This results in the\nglobal burden of leukemia falling on LMICs, where 84% of\nthe cases are reported [2].\nAmong the various subtypes of blood cancer, Acute\nLymphocyticLeukemia(ALL)andMultipleMyeloma(MM)\nare most prominent. The term â€œAcuteâ€ in ALL signifies the\nrapid proliferation of immature White Blood Cell (WBC)\nblasts within the bone marrow. Conversely, MM is asso-\nciated with diminished platelet counts in the blood. Treat-\nment approaches for blood cancer hinge on several factors,\nincluding specific leukemia subtype, the age of the patient,\nâˆ—Corresponding author: Chandravardhan Singh Raghaw\nphd2201101016@iiti.ac.in (C.S. Raghaw);axs230011@utdallas.edu\n(A. Sharma);phd2001201007@iiti.ac.in (S. Bansal);\nphd2101201005@iiti.ac.in (M.Z.U. Rehman);nagendra@iiti.ac.in (N.\nKumar)\nrate of disease progression, and affected areas [3]. Among\nall, the blood cell count density plays an instrumental role\nin categorizing the precise subtype of blood cancer. Early\ndiagnostic tests include blood cell count and morpholog-\nical evaluation. The manual counting under the expertise\nof a skilled practitioner is a time-consuming process [4]\nand necessitates expensive, sophisticated medical devices.\nHence,thereisapressingneedforautomatedcomputational\nmethods that can overcome these limitations and omit the\nrequirement of a skilled practitioner to run early diagnostic\ntests.\nIn recent years, several automated diagnostic methods\nfor ALL have been introduced [5]. These methods depend\non a predefined feature set designed to capture the cellular\nnucleus or cytoplasm for training classifiers used in ALL\ndetection.However,asignificantlimitationofthesemethods\nis the utilization of small datasets to train the classifier,\nwhichcanleadtooverfittingandpoorgeneralizationofnew\nbloodsmearsamples.Moreover,theperformanceonsmaller\ntest sets may not be reliable [6]. Another constraint for such\ntechniques includes feature learning from raw data samples\nwithout prior segmentation of blood cells, which may not\nbe optimal. These factors can hinder the effectiveness of\nthese methods when deployed in real-world clinical set-\ntings. Several methodologies also incorporate local features\nby utilizing predefined or manually crafted features while\nneglecting the cohesive integration of spatial and global\nRaghaw et al.: Preprint submitted to Elsevier Page 1 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nFigure 1: Illustration of sample images depicting the presence or absence of leukemic cells. The first row denotes the Whole\nSlide Image (WSI) of the blood samples, while the last row shows a zoomed-in view of WSI containing leukocytes. This figure\nhighlights the indistinguishability of cell images across classes.\nrelationshipsamongthesefeatures.Asaconsequence,these\nmethodologies need to be more effectively capturing all\npivotal features and associating them with classes in an\nefficient manner.\nRecent advances in Machine Learning (ML) and Deep\nLearning (DL) have led to their successful application in\nmedical diagnosis, including cancer survival [7], cognitive\nneuroscience [8], cardiology [9] and cancer image classi-\nfication [10]. An essential prerequisite for accurate can-\ncer image classification is precise segmentation since it\nenables a variety of quantitative analyses, such as shape,\ntexture,andsize.However,achievingaccuratesegmentation\nof pathology images proves to be complex due to factors\nsuch as blurred regions during image acquisition, noise\ninterference,andlowcontrastbetweenforegroundandback-\nground elements. Furthermore, the segmentation process is\ncompounded by significant variations in cell size, shape,\nand the heterogeneity of intracellular density [11]. Among\nthevarioustechniquesemployedforALLdetection,Convo-\nlutional Neural Networks (CNNs) have gained widespread\npopularity [12, 13, 14]. CNNs possess the capacity to ex-\ntract task-specific local features directly from input blood\nsmear images through a comprehensive learning approach.\nHowever, an inherent demand for a substantial volume of\ntrainingdataisrequiredtoachieveoptimalperformance.An\nalternative approach involves the utilization of transform-\ners to capture global features of leukocytes [15]. Despite\nthis,morphological-basedglobalfeaturesalonecannotaccu-\nrately classify affected leukocytes. Furthermore, including\nhigh-dimensional features containing irrelevant, redundant,\nor noisy blood smear samples can lead to inaccurate diag-\nnoses. Such feature vector tends to yield non-reproducible\nresults and continues to exhibit considerable variance.\nFigure 1 shows the analysis of blood smears from the\nWhole Slide Image (WSI), illustrating the presence or\nabsence of leukemic cells. The challenge arises from the\nfact that, in specific scenarios, peripheral blood smears\nexhibit visual characteristics that closely resemble one an-\nother, thereby complicating the diagnosis of leukemic cell\npresence. Leukocytes with similar visual features pose a\nchallenge for feature extraction, including suboptimal stain-\ning quality, extensive overlapping of cell nuclei, and subtle\nmorphological differences within and between leukocyte\ntypes. Currently, the detection of leukemic cells heavily\nrelies on labor-intensive manual microscopy examinations,\nwhichnotonlyconsumeasignificantamountoftimebutalso\nlack consistent objectivity [16]. The complex and diverse\nleukocyte image features in the microscopic blood smear\nimages pose a challenge in the development of a precise\nand efficient framework for the detection of leukemia [17].\nHence, there is a need for a more efficient and generalized\nframework that can reduce time demands and enhance the\naccuracy of leukemia classification.\nIn light of the aforementioned challenges, we propose\nCoupled Transformer ConvolutionalNetwork (CoTCoNet)\nframework for efficient classification of leukocytes. CoT-\nCoNet tackles the limited dataset challenges by generating\nRaghaw et al.: Preprint submitted to Elsevier Page 2 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nsyntheticleukocytesamplesthatcloselymimicactualmedi-\ncal samples while preserving their inherent characteristics.\nIt is imperative to note that these synthetic samples are\nmeticulouslydesignedtoexcludeanypersonallyidentifiable\ninformation, thereby ensuring the practical nullification of\nprivacy concerns. Subsequently, CoTCoNet employs an ex-\nactsegmentationtechniquetofacilitatetheaccurateidentifi-\ncation of the relevant regions of WBC within blood pathol-\nogyimages.Inaddition,ahybridframeworkthatcapitalizes\non the strengths of coupled transformers and convolutions\nis introduced to gain insight into the salient characteristics\nof blood smear samples. This framework comprehensively\nunderstandshematologicalfeaturesonbothaglobalandspa-\ntialscalewhilealsounveilinghiddenfeatures.Furthermore,\nwe incorporate a feature selection technique to efficiently\noptimize the feature vectors, with the principal objective\nbeing the reduction of data dimensionality while preserving\nthe most pertinent features. This objective aims to enhance\ntherepresentationalcapacityoftheselectedfeaturesandthe\ngeneralizationcapabilitiesoftheframework.Finally,aclas-\nsifier utilizes the optimized features to classify leukocytes\nprecisely.\nIn summary, the primary objective of the research is\nto develop a framework that acquires knowledge of the\nhematological characteristics of blood cells to predict the\npresence or absence of leukemic cells within unseen leuko-\ncytes. These characteristics are acquired through extensive\nexperiments on four diverse datasets. Experimental results\ndemonstrate a notable superiority over existing methods.\nThe key contributions of this work are summarized below:\nâ€¢ We propose a novel framework, the Coupled Trans-\nformer Convolution Network (CoTCoNet), designed\nto classify leukemia cells. CoTCoNet integrates the\nGlobal Feature Module (GMod) and the Spatial Fea-\nture Module (SMod) to combine long-range contex-\ntual information and scalable spatial patterns, identi-\nfyingcomplexandlarge-scalehematologicalfeatures.\nâ€¢ The proposed Graph-based Feature Reconstruction\n(GraFR)moduleisdesignedtounveilhiddenfeatures\nbycalculatingsimilaritywithprominentneighborfea-\ntures while preserving the geometric information of\nthe blood cells.\nâ€¢ We employ an enhanced Population-based Meta-\nHeuristic Algorithm for feature selection and opti-\nmization, aiming for a harmonious balance between\nthe influential feature mapping in the negative and\npositive classes of leukocyte cells.\nâ€¢ We introduce LeuGAN, an architecture powered by\nGenerativeAdversarialNetworksthateffectivelyman-\nages class imbalance by generating high-resolution\nleukocyte samples. Simultaneously, it preserves the\nextensive global and spatial information found within\nbloodcellimagesbyutilizinganinterconnectedfeed-\nback loop.\nâ€¢ CoTCoNet framework effectively utilizes the finely-\ntunedLeukemiaSegmentAnythingModel(LeuSAM)\nto segment leukocyte cells. LeuSAM proficiently\nidentifies atypically shaped blood cells with limited\nsurface areas, effectively excluding extraneous re-\ngions, such as plasma, and precisely segments the\nprimary area for more efficient feature extraction.\nâ€¢ We conducted comprehensive experiments and in-\ndepth analyses on four distinct publicly available\ndatasets to demonstrate the effectiveness of the CoT-\nCoNet framework. The superior performance of the\nmodel,whencomparedtoexistingmethodsforleuke-\nmia detection, validates its robustness.\nThis article is organized into distinct sections, as fol-\nlows.Section2providesanin-depthexaminationofexisting\nliterature on leukemia classification. Section 3 provides an\nelaborate account of the proposed methodology. Section 4\nprovides an overview of the evaluation process conducted\nduring the experiments. Lastly, Section 6 provides the pri-\nmary findings, followed by examining prospective avenues\nfor future research.\n2. Related Work\nThissectionprovidesacomprehensivesurveyofthepre-\nvious literature on leukemia classification. For better under-\nstanding, we divide the leukemia classification techniques\ninto three categories: Deep Learning-based Leukemia De-\ntection,Segmentation-basedLeukemiaDetection,andClass\nImbalance in Leukemia Detection.\n2.1. Deep Learning-based Leukemia Detection\nDeep Learning (DL) methods have achieved promis-\ning results in leukemia cell classification from microscopic\nblood smear images in recent studies [18, 19, 20]. DL\nmethods learn features and patterns autonomously, leading\nto effective leukemic cell classification. Mohammedet al.\nintroduced a stacked ensemble framework [14], which har-\nnessed transfer learning techniques, specifically ResNet-\n101, GoogleNet, SqueezeNet, DenseNet-201, and Mobile-\nNetV2, for leukemia detection. In contrast, CoTCoNet cap-\nitalizes on the capability of coupled transformers and con-\nvolution filters to learn long-range dependencies integrated\nwith local features. Gehlot et al. [12] proposed SDCT-\nAuxNetğœƒ, which focuses on stain absorption and sparse fea-\ntures. SDCT-AuxNetğœƒ incorporates a base CNN integrated\nwith bilinear pooling and the Stain-Deconvolution (SD)-\nNet architecture to improve features with Optical Density-\nspaceanalysis.Jawahar etal. [13]designedaneuralnetwork\nfeaturing three cluster layers that employ a combination\nof convolution and max-pooling operations to extract hi-\nerarchical and robust features. The features generated have\nspatial information but are not fully optimized. CoTCoNet,\nhowever,leveragesapopulation-basedalgorithmforfeature\noptimization to enhance the modelâ€™s ability to extract and\nlearn complex patterns in the data.\nRaghaw et al.: Preprint submitted to Elsevier Page 3 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nDas et al.proposed a novel Orthogonal SoftMax Layer\n(OSL)-based model [21] that combines ResNet 18-based\nfeature extraction and OSL-based classification. OSL im-\nproves classification by making weight vectors orthogonal.\nCoTCoNet, on the other hand, incorporates a Hierarchical\nDeep Learning Classifier (HDLC) that can classify effec-\ntivelyevenwhenthecellimagesexhibitstrikingvisualsim-\nilarity.Dhalla etal. introducedanencoder-decoderarchitec-\nture[22]thatprioritizesextractinglocalmultiscalefeatures.\nThe attention module in the architecture filters the most\nrelevantfeatures,focusingonspatialattributes.Das etal. uti-\nlized a transfer-learning-based approach by employing Mo-\nbileNetV2 [23] for feature extraction, enhanced with depth-\nwise separable convolution for computational efficiency.\nAtteia et al. presented a novel Bayesian-based optimized\nCNN [24] that employs an informed iterative procedure to\nexplorethehyperparameterconfigurationthatyieldsthebest\nnetwork settings for minimizing an objective errorfunction.\nIncontrast,theCoTCoNetframeworkutilizesagraph-based\nfeature reconstruction technique to identify hidden features.\nSubsequently,itleveragesapopulation-basedmeta-heuristic\noptimization technique to derive optimized reconstructed\nfeatures, enabling efficient classification.\n2.2. Segmentation-based Leukemia Detection\nMedical image segmentation is essential for the anal-\nysis and diagnosis of diseases, as it allows for the precise\nidentification of Regions of Interest (ROIs) [25, 26] within\nsamples.Devi etal. [27]employedGaussianBlurforimage\ndenoising and applied morphological operations to create\nan image mask. Subsequently, binary thresholding was ap-\nplied to the mask to generate cell contours, enabling the\nsegmentationandidentificationofmalignantcells.However,\ntheCoTCoNetframeworkadeptlyleveragesthefinely-tuned\nLeukemia Segment Anything Model (LeuSAM) to accu-\nrately identify irregularly shaped blood cells with limited\nsurface areas. Khandekar et al. [11] leveraged the You\nOnlyLookOnce(YOLOv4)architecturetodetectunhealthy\nWhite Blood Cells (WBC). YOLOv4 incorporates cross-\nstage-partialconnectionsfortheprecisepredictionofbound-\ning boxes within the designated ROIs. Alaguet al. [28]\nutilized the UNet architecture to extract in-depth features\nfrom models like AlexNet, GoogleNet, and SqueezeNet,\nwhich enabled accurate segmentation and discrimination of\nhealthy and blast cell nuclei.\nMohammed et al. [29] proposed a technique for seg-\nmenting WBC and deriving relevant features from the\nsegmented cells. This method employs threshold segmen-\ntation, which leads to the generation of segmented WBCs.\nSubsequently, the segmented WBCs undergo a discrete\ncosine transformation, and the resulting coefficients serve\nas classification features. In contrast, CoTCoNet extracted\ncombined global and spatial features from transformer and\nconvolutional-based modules for efficacious classification.\nDas et al. [30] segmented the lymphocyte by employing\nhand-crafted features involving a color-based k-means clus-\ntering technique. Additionally, a gray-level co-occurrence\nmatrix and gray-level run-length matrix extract the relevant\nfeatures from lymphocytes. Daset al. proposed a hybrid\nellipse fitting-based blood-cell segmentation [31] mecha-\nnismutilizingaLaplacian-of-Gaussian(LoG)andleverages\nfastradialsymmetry-basedseed-pointdetectiontoprecisely\nsegment overlapping cells and low-contrast visual features.\nOn the other hand, the CoTCoNet framework enhances\nthe visibility of low-contrast features by implementing a\ncontrast-limited adaptive histogram equalization technique.\nFurthermore,thefinelytunedLeuSAMexcludesextraneous\nregions,suchasplasma,andachievesprecisesegmentation,\nthereby enhancing the efficiency of feature extraction.\n2.3. Class Imbalance in Leukemia Detection\nMany real-world applications, such as fraud detection\n[32],intrusionidentification[33],andcancerdiagnosis[34],\nface classification problems with imbalanced data distribu-\ntion [35]. Leukemia detection is very challenging due to\nthe large imbalance in the number of samples between the\nminority and majority classes. Chen et al. proposed the\nWBC-GLAformer [36], a hybrid transformer-based model\nto acquire local and global features. The WBC-GLAformer\ncomprises a low-level feature extractor to extract local fea-\ntures and a global-local attention encoder to combine the\nstrengths of local and global features. However, CoTCoNet\nintegrates spatial and global features and incorporates hid-\nden features through graph-based feature reconstruction.\nUmar et al.[37] trained a robust CNN by addressing cross-\ndomain data imbalance, domain shifts, and missing classes.\nThe author shows an improvement in existing pre-trained\ndeepmodelsbyoptimizingthelossfunctioninthenetwork.\nDeptoetal. [6]highlightedtheimbalanceclassproblemand\npresented detailed quantitative and qualitative analyses for\nleukemia classification. The result demonstrates that Gen-\nerative Adversarial Networks and loss-based methods effi-\nciently mitigate class imbalance challenges. However, CoT-\nCoNet utilizes fine-tuned LeuGAN by synthesizing high-\nquality leukocyte samples, preserving the morphological\ninformationbyleveraginganinter-connectedfeedbackloop.\n3. Methodology\nThis section includes a comprehensive breakdown of\nthe proposed Coupled Transformer Convolution Network\n(CoTCoNet) framework, as illustrated in Figure 2, which\ncomprises five distinct sub-modules: (A) leukocyte pre-\nprocessing and segmentation undertakes the initial process-\ning and segmentation of cell images; (B) generative ad-\nversarial network-driven cell synthesis responsible for gen-\nerating synthetic cells; (C) global and spatial deep fea-\nture extraction extracts integrated global and spatial fea-\ntures,coupledwiththeidentificationofhiddenfeatures;(D)\npopulation-based optimization for feature selection selects\nandrefinesthemostoptimizedsetoffeatures;(E)hierarchi-\ncaldeeplearningclassifiercategorizescellsaseithernormal\nor leukemic.\nRaghaw et al.: Preprint submitted to Elsevier Page 4 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nFigure 2:Proposed Coupled Transformer Convolution Network (CoTCoNet) for Leukemia Detection. Firstly, the leukocyte cell\nimages are inputted into (A) for pre-processing and segmentation. In step (A), the fusion of CLAHE and Sharpen image\nenhancement technique is applied, followed by Region of Interest Identification. Then, images are segmented by utilizing LeuSAM.\nThe output of Step (A) is fed to the proposed GAN-driven cell synthesis step (B). The outcome of step (B) comprises synthetic cell\nimages produced by the GAN adhering to the real images. In step (C), CoTCoNet first isolates the global and spatial features and\nthen proceeds to regenerate them through graph-based feature reconstruction techniques. At step (D), a meta-heuristic sine-cosine\nalgorithm optimizes the feature. Finally, step (E) classifies the optimized features into normal or leukemia. The effectiveness of\nthe proposed framework is assessed on four different datasets.\n3.1. Problem Formulation\nThis work proposes an advanced framework for acute\nlymphoblastic leukemia detection. It accurately identifies\nblast or leukemic cells in the blood, extracting their unique\nfeatures through global and spatial modules. Given a set\nof leukocyte cell samplesğ’³ âˆˆ {ğ‘¥1,ğ‘¥2,â‹¯,ğ‘¥ğ‘›} and the\ncorresponding labels ğ’´, we aim to predict the presence\nor absence of leukemic cells in unseen leukocyte blood\ncell images. The prediction is based on the feature learning\nframework, which learns the hematological features of cells\nin a supervised manner and creates the custom mapping\nğ‘“âˆ¶ğ’³â†’ ğ’´, such thatğ’´ âˆˆ (0,1)and the goal is to predict\nRaghaw et al.: Preprint submitted to Elsevier Page 5 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nthe presence or absence of leukemic cells in a blood cell\nimage.\n3.2. Data Preprocessing\nWe devise a leukocyte cell pre-processing and seg-\nmentation pipeline, as illustrated in Figure 2. Firstly, we\nemploy Contrast Limited Adaptive Histogram Equalization\n(CLAHE) for image contrast amplification and visibility\nenhancement. After that, we sharpen filters to emphasize\ntheedgesandfeaturesofthemicroscopicimages.Secondly,\nwe identify and capture Region-of-Interest (ROIs) that are\nmore likely to exhibit variations indicative of leukemia\nwhile excluding any superfluous sections such as plasma.\nSubsequently,weleveragethefine-tunedLeukemiaSegment\nAnything Model (LeuSAM) [38] to perform segmentation\nand extraction of leukocyte cells from the ROI images,\nresulting in the production of segmented leukocytes xğ‘ .\nFinally,thearrayofsegmentedimagesisutilizedasinputfor\na mechanism driven by a Generative Adversarial Network,\nwith the aim of synthesizing cells.\n3.3. Generative Adversarial Network-driven Cell\nSynthesis\nThis section introduces LeuGAN, a novel method for\ngenerating synthetic hematological cells while preserving\nessential features. LeuGAN consists of a twin neural net-\nwork, a generatorîˆ³ and one discriminatorîˆ°. The trained\nîˆ³ effectively characterizes a probability distributionğ‘ğ‘§(ğ‘§)\nin the training of segmented leukocytexğ‘ . The generator\ndevises synthetic mapping îˆ³(z,ğœƒğ‘”) from ğ‘ğ‘§(z), where ğœƒğ‘”\nrepresents the learning parameter of the generator network.\nAs illustrated in Figure 3,z is 128dimensional vector with\neach ğ‘§ğ‘– âˆˆ (âˆ’1,+1)is transformed in1024feature maps of\ndistributedconvolutions.Inordertosynthesizehigh-fidelity\nartificialleukocytes,asequenceoffourstridedconvolutions\nis employed to project and reshape the noise vectorz into\na 256 Ã— 256pixel representation of leukocyte cell image,\ndenoted asÌ‚x.\nTheDiscriminatorNetwork îˆ°(xğ‘ ,ğœƒğ‘‘),where ğœƒğ‘‘ denotes\nthe discriminator learning parameter, accepts either a syn-\nthesized leukocyte Ì‚x or real leukocyte xğ‘  cell image. As\nshown in Figure 3, inputs traverse from four convolution\nlayers and generate an outputÌ‚ ğ‘œwhich indicates whether the\ninput image is real or synthetic; it can be mathematically\nrepresented in Equation 1 as follows:\nÌ‚ ğ‘¦= ğ‘’Ì‚ ğ‘œ\n1+ ğ‘’Ì‚ ğ‘œ s.t. Ì‚ ğ‘¦âˆˆ[0,1] (1)\nwhere Ì‚ ğ‘¦denotes the class = {synthetic leukocyte, real\nleukocyte}. The final objective is to increase the classifica-\ntion performance of real leukocytes and synthetic leukocyte\ncells, with the generator networkîˆ³(z,ğœƒğ‘”)and discriminator\nnetwork îˆ°(xğ‘ ,ğœƒğ‘‘) improves learning by incorporating the\nclassification loss. The adversarial interplay betweenîˆ³ and\nîˆ° integrates the binary loss and can be depicted in Equa-\ntion 2:\nğ‘šğ‘–ğ‘›\nîˆ³\nğ‘šğ‘ğ‘¥\nîˆ°\nîˆ¸ğºğ´ğ‘(îˆ°,îˆ³)=\nğ”¼\nxğ‘ âˆ¼pğ‘‘ğ‘ğ‘¡ğ‘\n(xğ‘ )[ğ‘™ğ‘œğ‘”(îˆ°(xğ‘ ))]+ ğ”¼\nzâˆ¼pğ‘§(ğ‘§)\n(xğ‘ )\n[\nğ‘™ğ‘œğ‘”\n(\n1âˆ’ îˆ°(îˆ³(z)))]\n(2)\nwhere the generator aims to minimize the adversarial\nloss îˆ¸ğºğ´ğ‘(îˆ°,îˆ³), while the discriminator strives to maxi-\nmize it. To train the discriminator network, the generatorîˆ³\nworks in backpropagation (i.e., in an interlinked feedback\nloop), and to train the generator network, the discriminator\ndoes the same. After generating the synthetic leukocyte\ncells, we introduce them into the feature extraction module\nintegratedwithintheprovidedframework.Weelucidatethis\nprocess in the following Section 3.4.\nFigure 3: Proposed Generative Adversarial Network-driven\narchitecture (LeuGAN) for synthetic leukocyte cell generation.\nOur approach involves a 128-dimensional noise vector ğ‘§,\nGenerator îˆ³ and corresponding Discriminatorîˆ°. Specifically,\nîˆ³ uses the noise vector to craft synthetic leukocyte blood\ncells, while îˆ° evaluates both real and generated leukocytes\ncombined. The network employs the generator-adversarial loss\nfunction îˆ¸ğºğ´ğ‘(îˆ°,îˆ³)to maintain consistency effectively.\n3.4. Coupled Transformer Convolution Network\n(CoTCoNet)\nThis section unveils the arranged configuration of the\nCoTCoNet framework, as illustrated in Figure 2. The Cot-\nCoNet comprises three integral modules: Global Feature\nRaghaw et al.: Preprint submitted to Elsevier Page 6 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nModule (GMod), Spatial Feature Module (SMod), and\nGraph-based Feature Reconstruction module. This frame-\nworkinvolvesleveragingawell-designedtransformer-based\nGModtocapturetheoverarchingglobalfeatureseffectively.\nAt the same time, the SMod module capitalizes on the\nextractioncapabilitiesoftheConvolutionalNeuralNetwork\n(CNN) by inheriting the spatial features. Subsequently,\nthe combined features undergo a reconstruction process\nutilizing a Graph-based Feature Reconstruction (GraFR)\nmodule to extract the pertinent features of each data point\nby evaluating the similarity score of feature vectors. These\nthree modules form a cohesive network that collaboratively\nleverages the extracted features.\n3.4.1. Global Feature Module (GMod)\nWe design a transformer-based network called Global\nFeature Module (GMod) that focuses on extracting global\ninformationfromtheinputimagestoclassifyleukemiccells\naccurately.TheGModmoduleisschematicallyillustratedin\nFigure 4.\nFigure 4:Architecture of the proposed Global Feature Module\n(top) and details of the Transformer Layer block(bottom).\nThe input image is first split into equal-sized patches and\nflattened. Then, each patch is projected into a feature space\nwhere a transformer layer block processes them to extract\nglobal features.\nPatch Decomposition The standard transformer accepts\na 1-D sequence of token embeddings as its primary input;\nhowever, the manipulation of 2-D synthetic leukocyte im-\nages involves a reshaping operation of inputxğ‘ âˆˆâ„â„Ã—ğ‘¤Ã—ğ‘\nto xğ‘ âˆˆ â„ğ‘›Ã—(ğ‘2â‹…ğ‘), where(â„,ğ‘¤,ğ‘ ) corresponds to height,\nwidth, channels and(ğ‘,ğ‘) indicates the spatial resolution\nof an individual patch. The overall count of these patches,\nreferred to asğ‘›, is computed as(â„Ã—ğ‘¤)âˆ•ğ‘2, furnished as\ninput to the stacked transformer layers.\nLinear Transformation and Positional Embedding\nWe apply the trainable linear projection to map the vec-\ntorized token patches xğ‘ into a latent embedding space\nwith ğ‘‘ğ¿ dimensionality. The token sequence denoted as\nxğ‘ = [x(1)\nğ‘ ,x(2)\nğ‘ â‹¯x(ğ‘)\nğ‘ ] is initially structured as an array\nafterincorporatingthelearnableembeddingandtheposition\nembedding the resultant Ìƒ ğ‘§0, [refer Equation 3] is directed\ntowardsthetransformer,whoseoutputisgivenby Ìƒ ğ‘§ğ¿,where\nğ¿signifiesthenumberoftransformerblocks.Subsequently,\nwe integrate position embeddings into token embedding to\ninherit the positional information as follows:\nÌƒ ğ‘§0 =[x(1)\nğ‘ E; x(2)\nğ‘ E; â‹¯; x(ğ‘)\nğ‘ E]+ Eğ‘ğ‘œğ‘  (3)\nwhere, E âˆˆ â„(ğ‘2â‹…ğ‘)Ã—ğ‘‘ğ¿ denotes the patch embedding\nprojection, andEğ‘ğ‘œğ‘  âˆˆ â„(ğ‘›+1)Ã—ğ‘‘ğ¿ represents the positional\nembedding.\nSelf-Attention Mechanism The resulting token embed-\ndings Ìƒ ğ‘§0areintroducedasinputtoatransformerthatconsists\nof a Multihead Self-Attention (MSA) blocks and Multi-\nLayerPerceptrons(MLP)blocks[referEquation4andEqua-\ntion5].TheMLPblockincludesadualfullyconnecteddense\nlayer with a Gaussian error Linear Unit (GeLU) residing\nbetween them. The Layer Normalization (LN), as defined\nin Equation 6, is employed prior to the MSA and MLP\nblocks, while residual concatenation is utilized after each\nblock. The procedure for the forward calculation is outlined\nas follows:\nÌƒ ğ‘§ğ‘™ =ğ‘€ğ‘†ğ´(ğ¿ğ‘(ğ‘§ğ‘™âˆ’1))+ğ‘§ğ‘™âˆ’1, ğ‘™ =1,â€¦,ğ¿ (4)\nğ‘§ğ‘™ =ğ‘€ğ¿ğ‘ƒ(ğ¿ğ‘(Ìƒ ğ‘§ğ‘™))+ Ìƒ ğ‘§ğ‘™, ğ‘™ =1,â€¦,ğ¿ (5)\nğ‘¦=ğ¿ğ‘(ğ‘§0\nğ¿) (6)\nThe core mechanism of the transformer is MSA, which\naims to capture correlated global contextual information\neffectively. To utilize diverse implications, three adaptable\nweight matrices (Wîˆ½, Wîˆ·, Wî‰‚) are established. Simulta-\nneously, Wîˆ½ âˆˆ â„â„Ã—ğ‘¤Ã—ğ‘,Wîˆ· âˆˆ â„â„Ã—ğ‘¤Ã—ğ‘,Wî‰‚ âˆˆ â„â„Ã—ğ‘¤Ã—ğ‘\nare initialized randomly. Leveraging these trainable weight\nmatricesfacilitatesalineartransformationoftokensintoa3-\nDinvariantmatrixcomprisingQueries( îˆ½ âˆˆâ„â„Ã—ğ‘¤Ã—ğ‘),Keys\n(îˆ· âˆˆ â„â„Ã—ğ‘¤Ã—ğ‘), and Values (î‰‚ âˆˆ â„â„Ã—ğ‘¤Ã—ğ‘). Subsequently,\nthecomputationofattentionscoresinvolvestheentireinfor-\nmation encompassed withinîˆ½, îˆ·, î‰‚, and the weights are\ncalculated using the softmax function. Concisely, the SA\nmechanism can be encapsulated in Equation 7:\nğ‘†ğ´=ğ´ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘œğ‘›(îˆ½, îˆ·, î‰‚)= ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥\n(\nîˆ½îˆ·ğ‘‡\nâˆš\nğ‘‘îˆ·\n)\nî‰‚ (7)\nRaghaw et al.: Preprint submitted to Elsevier Page 7 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nFigure 5:Architecture of the proposed Spatial Feature Module, comprising five Spatial Feature Learning (SFL) blocks, represented\nby ğœ‘ğ‘†ğ¹ğ¿(ğ‘–), ğ‘–âˆˆ[1,2,3,4,5]. The numerical values at the bottom indicate the number of filters employed in each SFL block.\nwhere, ğ‘‘îˆ· is the dimension ofîˆ·. The MSA module\nis equipped with multiple weight matrices to facilitate the\nmapping ofîˆ½, îˆ·, andî‰‚ components; this plays a crucial\nrole in computing MSA values through uniform operational\nprocedures. Then, the outcomes from individual attention\nheadsarecombinedthroughconcatenation.Thelineartrans-\nformation represented in Equation 8 is the final step in\nderiving the MSA outcomes.\nğ‘€ğ‘†ğ´(îˆ½,îˆ·,î‰‚)= ğ¶ğ‘œğ‘›ğ‘ğ‘ğ‘¡(ğ‘†ğ´1,ğ‘†ğ´2,â€¦,ğ‘†ğ´ğ»)W (8)\nwhere,ğ»representtotalnumberofheads, W âˆˆâ„â„Ã—ğ‘‘îˆ· Ã—ğ‘‘î‰ƒ\ndenotes the parameter matrix of he linear layers andğ‘‘î‰ƒ =\nğ‘+1 corresponds to token number.\nThe pre-trained MSA module generates the feature ma-\ntrix and is directed into the MLP module. Also, the MLP is\nfollowed by Layer Normalization (LN) to amplify gradient\nmagnitudes, mitigating the gradient vanishing concerns and\nacceleratingthetrainingprocess.Inthetransformermodule,\nthedimensionsoftheinput ğ‘§ğ‘™âˆ’1andtheoutput Ìƒ ğ‘§fromthe ğ‘™ğ‘¡â„\ntransformer module are identical. The trainable embedding\nğ‘§0\nğ¿, comprising a set of global leukocyte featuresâƒ—îˆ²ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™ is\nfed into the Spatial Module consisting of several convolu-\ntions for capturing spatial features.\n3.4.2. Spatial Feature Module (SMod)\nTransformer-based GMod can capture global features\nefficiently, but it is less effective than Convolution Neural\nNetwork (CNN) to learn scalable spatial patterns. Hence,\na Convolutional-based Spatial Module (SMod) is incorpo-\nrated to learn spatial features at different scales efficiently.\nAspresentedin Figure5,SModarchitectureconsistsoffive\nSpatial Feature Learning (SFL) blocks, denoted asğœ‘ğ‘†ğ¹ğ¿(ğ‘–),\nğ‘–âˆˆ[1,2,3,4,5].Usingthisconcurrentstructure,thesystem\ncanextractandhandlespatialinformationwhilemaintaining\nthe integrity of global information as much as possible.\nSMod is defined as a dual feature extraction block as it ex-\ntracts the spatial features from the global features of GMod.\nAs shown in Figure 5, the SFL block begins with a\ncascaded arrangement of convolution layer(CONV), batch\nnormalization layer(BN), max-pooling layer(MXP), ReLU\nactivation function and dropout layer(DRP). The CONV\nlayer employs a spatial filter with dimensions 3 Ã— 3to\ncapture the detailed features at the finest levels from global\nfeatures.Notably,thepaddingconfigurationissettoâ€œsameâ€\nto preserve the homogeneity in feature map dimensions\nthroughout the SFL block. The presence of theBN layer\nmitigates overfitting and accelerates the learning process.\nIncorporating a ReLU activation function introduces non-\nlinearity during the learning process. A dropout layer is\nparameterized by a value of0.2, a regularization to address\ntheoverfitting.Consequently,thislayerselectivelyrandomly\ndeactivates neurons to reduce the dependency on any single\nneuron and leads to more robust feature learning.\nLet ğœ‘ğ‘“\nğ‘†ğ¹ğ¿(ğ‘–)(Ìˆîˆ¯)represent the output of a SFL block with\nğ‘“ filters, ğœ˜\nÌƒğ‘˜,Ìƒğ‘˜\nğ‘  denotes theMXP with kernel sizeÌƒğ‘˜Ã—Ìƒğ‘˜and\nstride ğ‘ . Î¨ğ‘˜,ğ‘˜,ğ‘“\nğ‘†ğ¹ğ¿(ğ‘–)(Ìˆîˆ¯)represent convolution operation withğ‘“\nnumberofkernelsofsize ğ‘˜Ã—ğ‘˜,ğ›½denotethe BN,and ğœŒdenote\nthe ReLU activation function. Equation 9 mathematically\nformalizes the functioning of the SFL blockğœ‘ğ‘“\nğ‘†ğ¹ğ¿(ğ‘–)(Ìˆîˆ¯), as\noutlined below:\nğœ‘ğ‘“\nğ‘†ğ¹ğ¿(ğ‘–)(Ìˆîˆ¯) = ğœ˜2,2\n2\n(ğœŒ(ğ›½(Î¨3,3,ğ‘“(Ìˆîˆ¯)))) (9)\nIn the SFL block, the initial phase involves channeling\ntheinputthroughamax-poolinglayerfeaturingakernelsize\nof 2Ã—2 with stride value2to reduce the size of the feature\nmap. Subsequently, the resultant is fed into a convolution\nCONV layeremployinga 3Ã—3 kernelsizeandincorporating\ndistinctfiltersdenotedas ğ‘“ğ‘–,where ğ‘–âˆˆ[32,64,128,256,256]\nrepresents the filter values of each SFL block. As a result,\nRaghaw et al.: Preprint submitted to Elsevier Page 8 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nthe procedure generates a tensor of spatial feature maps\nconsisting of the fine-grained features of the leukocyte cell,\nsuch as textures, corners, edges, and colors. Next, the gen-\nerated feature maps are fed intoBN to elevate the feature\nlearning mechanism by normalizing the input through the\ncomputation of the mean and variance within the input\nmini-batch.Thisfacilitatesmanagingalterationstotheinput\ndistribution layer by changing vital parameters of preceding\nlayers. Consequently, this operation enhances the speed of\nconvergence as well as the generalization ability of the\nnetwork. Lastly, a dropout layer (DRP) is introduced to\nmitigate the co-adaptation of features, thereby compelling\nthenetworktodevelopmorerobustrepresentations.Finally,\ntheSFLblocksgenerateaflattenedoutputcontainingspatial\nfeatures âƒ—îˆ²ğ‘ ğ‘ğ‘ğ‘¡ğ‘–ğ‘ğ‘™, which is then fed into the Graph-based\nfeature reconstruction (GraFR). GraFR aims to improve the\nquality of the features by utilizing aggregated information\nfrom all preceding layers within the SFL blocks, thereby\nenhancing the feature reconstruction. This reconstruction\nimproves the feature quality, which measures how well the\nfeatures represent the leukocyte cell and its type.\n3.4.3. Graph-based Feature Reconstruction (GraFR)\nThe complex and hard-to-see biological features of the\nleukocyte cell are challenging to emphasize. This requires\na method focused on reconstructing hidden or unobserved\nfeatures from a lower-dimensional to a higher-dimensional\nfeature map. Hence, a Graph-based feature reconstruction\n(GraFR) is proposed to scale up the unobserved sample\nfeatures.Theprimaryaimbehindthistechniqueistoamplify\nthe hidden features of nodes by leveraging the features of\ntheir neighboring nodes. The GraFR module establishes a\nconnectionbetweenfeatureelementsusinglow-levelfeature\nmaps to steer the up-sampling process using high-level fea-\nture maps. GraFR considers the whole feature information,\nbridging the gap between global and local perspectives of\nsemanticinformation.TheGraFRmodulefollowsfoursteps:\n(1) Node generation for feature maps, (2) Edge weight\ncomputation, (3) Hidden feature selection criteria, and (4)\nFeature map reconstruction.\nNode Generation for Feature MapsLet ğ”¾(ğ‘‰ğ‘”,ğ¸ğ‘”)be\nthe graph, whereğ‘‰ğ‘” is the set of nodes, andğ¸ğ‘” is the set of\nedges. Each nodeğ‘£ in the graph is associated with a one-\ndimensional (1D) flattened arrayğ‘¥ğ‘£ that contains coupled\nglobal and spatial features. This can be represented asâƒ— ğ‘¥ğ‘£ =[ğ‘¥ğ‘£,1,ğ‘¥ğ‘£,2,â‹¯,ğ‘¥ğ‘£,ğ‘‘\n] where ğ‘‘ represents the dimensionality\nof the feature vectors.\nEdge Weight Computation The edge weights in the\ngraph are calculated using the Euclidean distance between\nthe feature vectors of nodes. This means that for any two\nnodes ğ‘¢ and ğ‘£ in ğ‘‰ğ‘”, the Euclidean distanceğ‘‘ğ‘¢ğ‘£ between\ntheir feature vectorsğ‘¥ğ‘¢ and ğ‘¥ğ‘£ is given in Equation 10:\nğ‘‘ğ‘¢ğ‘£(ğ‘¢,ğ‘£)=\nâˆšâˆšâˆšâˆš\nğ‘›âˆ‘\nğ‘–=1\nâ€–âƒ— ğ‘¥ğ‘¢ğ‘– âˆ’âƒ— ğ‘¥ğ‘£ğ‘–â€–2 (10)\nwhere, âƒ— ğ‘¥ğ‘¢ğ‘– and âƒ— ğ‘¥ğ‘¢ğ‘– are the ğ‘–ğ‘¡â„ elements of ğ‘¥ğ‘¢ and ğ‘¥ğ‘£,\nrespectively.\nHidden Feature Selection CriteriaThe criteria for se-\nlectingthehiddenfeatures â„aimstoidentifynodeswiththe\nhighest similarity scores. The node incorporates global and\nspatial features while considering all features from lower-\ndimensional representations. The similarity scoreâˆ‡ğ‘¢â†”ğ‘£ be-\ntween nodesğ‘¢ and ğ‘£ is the inverse of the edge weight, as\nshown in Equation 11:\nâˆ‡ğ‘¢â†”ğ‘£ =\n(\n1\nğ‘‘ğ‘¢ğ‘£\n)\n(11)\nA higher similarity score indicates a stronger similarity\nbetween core and hidden features. For inclusion of the\nfeature node, each nodeğ‘–in ğ‘‰ğ‘” is considered if it possesses\nthe highest similarity score across all other nodes inğ‘‰ğ‘”, as\nshown in the following Equation 12,\nâ„={ğ‘–âˆˆğ‘‰ğ‘” |âˆ€ğ‘£âˆˆğ‘‰ğ‘”, (âˆ‡ğ‘–â†”ğ‘£ â‰¥ âˆ‡ğ‘£â†”ğ‘–)} (12)\nThe set of hidden features â„ includes node ğ‘– if this\ncondition is satisfied.\nFeature Map ReconstructionThe output of the Feature\nMap Reconstruction is a vectorîˆ²ğ‘Ÿğ‘’ğ‘ğ‘œğ‘›ğ‘ ğ‘¡ğ‘Ÿğ‘¢ğ‘ğ‘¡ğ‘’ğ‘‘ that summa-\nrizesallfeaturesandhighlightshiddenfeaturesofthenodes\nin the graph. This can be obtained by weighing the contri-\nbution of each nodeâ€™s feature vector based on the similarity\nscore. Equation 13 is used to compute the reconstructed\nfeaturesîˆ²ğ‘Ÿğ‘’ğ‘ğ‘œğ‘›ğ‘ ğ‘¡ğ‘Ÿğ‘¢ğ‘ğ‘¡ğ‘’ğ‘‘.\nîˆ²ğ‘Ÿğ‘’ğ‘ğ‘œğ‘›ğ‘ ğ‘¡ğ‘Ÿğ‘¢ğ‘ğ‘¡ğ‘’ğ‘‘ =\nâˆ‘\nğ‘£=ğ‘‰ğ‘”\nâˆ‡ğ‘¢â†”ğ‘£ â‹…ğ‘¥ğ‘£\nâˆ‘\nğ‘£=ğ‘‰ğ‘”\nâˆ‡ğ‘¢â†”ğ‘£\n(13)\nThis reconstructed featureîˆ²ğ‘Ÿğ‘’ğ‘ğ‘œğ‘›ğ‘ ğ‘¡ğ‘Ÿğ‘¢ğ‘ğ‘¡ğ‘’ğ‘‘ incorporates in-\nformation from all nodes in the graph, with nodes that have\nhigher similarity scores contributing more significantly to\nthefinalrepresentationofreconstructedfeatures.CoTCoNet\nframeworkprocedureisoutlinedinAlgorithm1.Weextract\nglobal features from Lines 1-5 and spatial features from\nLines6-12.Lines13-16performgraph-basedfeaturerecon-\nstruction to identify hidden features.\n3.5. Population-based Optimization for Feature\nSelection\nThis section explains how a population-based meta-\nheuristic algorithm is applied for feature selection and op-\ntimization. Since population-based optimization techniques\nRaghaw et al.: Preprint submitted to Elsevier Page 9 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nAlgorithm 1COTCONET FRAMEWORK\nInput:A set of augmented imagesxğ‘ of sizeâ„â„Ã—ğ‘¤Ã—ğ‘\nOutput: Reconstructed featuresâƒ—îˆ²ğ‘Ÿğ‘’ğ‘ğ‘œğ‘›ğ‘ ğ‘¡ğ‘Ÿğ‘¢ğ‘ğ‘¡ğ‘’ğ‘‘\nprocedure:GMod (xğ‘ âˆˆâ„â„Ã—ğ‘¤Ã—ğ‘, âƒ—îˆ²ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™\n)\n1: Decompose images into patches with no overlap.\n(xğ‘›Ã—(ğ‘2â‹…ğ‘)\nğ‘ â† xâ„Ã—ğ‘¤Ã—ğ‘\nğ‘ ), whereğ‘›=(â„Ã—ğ‘¤)âˆ•ğ‘2\n2: Transform into linear tokens and add position encoding.\nÌƒ ğ‘§0 =[x(1)\nğ‘ E; x(2)\nğ‘ E; â‹¯; x(ğ‘)\nğ‘ E]+ Eğ‘ğ‘œğ‘ \n3: Apply self-attention to the patch embeddings to capture global features using multi-head attention withîˆ·\nheads,îˆ½ queries andî‰‚ values.\nğ‘†ğ´=ğ´ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘œğ‘›(îˆ½, îˆ·, î‰‚)= ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥\n(\nîˆ½îˆ·ğ‘‡\nâˆš\nğ‘‘îˆ·\n)\nî‰‚\n4: The final feature set is a combination of all weighted Self Attention outputs\nâƒ—îˆ²ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™ â† ğ¶ğ‘œğ‘›ğ‘ğ‘ğ‘¡(ğ‘†ğ´1,ğ‘†ğ´2,â€¦,ğ‘†ğ´ğ»)W\n5: return âƒ—îˆ²ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™\nfunction:SMod (âƒ—îˆ²ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™, âƒ—îˆ²ğ‘ ğ‘ğ‘ğ‘¡ğ‘–ğ‘ğ‘™\n)\n6: forâˆ€1â‰¤ğ‘–â‰¤5 âˆˆğœ‘ğ‘†ğ¹ğ¿(ğ‘–) Spatial Feature Learning blockdo\n7: Apply Max Pooling to the inputâƒ—îˆ²ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™ featuring a kernel size of2Ã—2 with stride value2\nMXP â† ğœ˜2Ã—2\n2 [âƒ—îˆ²ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™]\n8: Apply the Convolution operation with filterğ‘“ğ‘– âˆˆ[32,64,128,256,256]and3Ã—3 kernel to Max Pooling.\nCONV â† Î¨3,3,ğ‘“ğ‘–(Ìˆîˆ¯)[MXP]\n9: Apply Batch Normalization after Convolution operation\nBN â† ğ›½[CONV]\n10: Apply regularization on Normalized input by randomly setting 20% of the units to zero.\nDRP â† BN\n11: end for\n12: The output of the Spatial Feature Learning block is flattened and can be represented as:\nâƒ—îˆ²ğ‘ ğ‘ğ‘ğ‘¡ğ‘–ğ‘ğ‘™ â† ğ¹ğ‘™ğ‘ğ‘¡ğ‘¡ğ‘’ğ‘› [DRP]\nfunction:GraFR(âƒ—îˆ²ğ‘ ğ‘ğ‘ğ‘¡ğ‘–ğ‘ğ‘™, âƒ—îˆ²ğ‘Ÿğ‘’ğ‘ğ‘œğ‘›ğ‘ ğ‘¡ğ‘Ÿğ‘¢ğ‘ğ‘¡ğ‘’ğ‘‘\n)\n13: Nodes represent the global and spatial features.\nâƒ— ğ‘¥ğ‘£ =[ğ‘¥ğ‘£,1,ğ‘¥ğ‘£,2,â‹¯,ğ‘¥ğ‘£,ğ‘‘\n]\n14: Euclidea-based edge weight computation between the feature vectors of nodes.\nğ‘‘ğ‘¢ğ‘£(ğ‘¢,ğ‘£)=\nâˆšâˆ‘ğ‘›\nğ‘–=1â€–âƒ— ğ‘¥ğ‘¢ğ‘– âˆ’âƒ— ğ‘¥ğ‘£ğ‘–â€–2\n15: Hidden feature nodeâ„identification using the highest similarity scores.\nâ„={ğ‘–âˆˆğ‘‰ğ‘” |âˆ€ğ‘£âˆˆğ‘‰ğ‘”, (âˆ‡ğ‘–â†”ğ‘£ â‰¥ âˆ‡ğ‘£â†”ğ‘–)}, whereâˆ‡ğ‘¢â†”ğ‘£ =\n(\n1\nğ‘‘ğ‘¢ğ‘£\n)\n16: Feature map reconstruction involves leveraging edge weights determined by similarity scores.\nîˆ²ğ‘Ÿğ‘’ğ‘ğ‘œğ‘›ğ‘ ğ‘¡ğ‘Ÿğ‘¢ğ‘ğ‘¡ğ‘’ğ‘‘ =\nâˆ‘\nğ‘£=ğ‘‰ğ‘” âˆ‡ğ‘¢â†”ğ‘£â‹…ğ‘¥ğ‘£\nâˆ‘\nğ‘£=ğ‘‰ğ‘” âˆ‡ğ‘¢â†”ğ‘£\nrandomly search for the optima of optimization problems,\nthere is no certainty of discovering a solution in a single\nexecution. However, as the optimization iterations and the\nnumber of random solutions increases, the likelihood of\nidentifying the global optimum rises. Furthermore, a local\nsearch technique called Adaptiveğ›½-Hill Climbing (Ağ›½HC)\nis employed to refine the obtained feature subset. The opti-\nmized feature set learns a mapping between the feature set\nandoutputclasses.ThismappingfacilitatestheHierarchical\nDeep Learning Classifier (HDLC) to perform the final dis-\ntinctionbetweennormalcellsandleukocytecells,leveraging\nthe optimized feature set as its input.\nIn this work, a population-based meta-heuristic algo-\nrithm,namelySine-CosineAlgorithm(SCA)[39],isapplied\nforfeatureselectionandoptimization.SCAfollowsiterative\nstochastic and population-based methods that imitate the\nharmoniousbehaviorofsineandcosinefunctionstoexplore\nthe solution space and find the optimal destination space.\nSCA typically consists of two primary stages: exploration\nRaghaw et al.: Preprint submitted to Elsevier Page 10 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nand exploitation. The exploration phase combines the ran-\ndom solutions with a high degree of randomness to identify\npromising regions within the search space. In contrast, the\nexploitation phase alters the solutions with gradual modifi-\ncations to reduce randomness in the variations.\nTo initiate the optimization procedure using SCA, the\nsearch element alters its self-position based on the sine and\ncosine functions as given in Equation 14.\nîˆ¼ğ‘¡+1\nğ‘–,ğ‘— =\n{\nîˆ¼ğ‘¡\nğ‘–,ğ‘— +ğ‘Ÿğ‘¡\n1,ğ‘— Ã—sin( ğ‘Ÿğ‘¡\n2,ğ‘—)Ã— |ğ‘Ÿğ‘¡\n3,ğ‘—ğ·ğ‘¡\nğ‘— âˆ’îˆ¼ğ‘¡\nğ‘–,ğ‘—|,ğ‘Ÿğ‘¡\n4,ğ‘— <0.5\nîˆ¼ğ‘¡\nğ‘–,ğ‘— +ğ‘Ÿğ‘¡\n1,ğ‘— Ã—cos( ğ‘Ÿğ‘¡\n2,ğ‘—)Ã— |ğ‘Ÿğ‘¡\n3,ğ‘—ğ·ğ‘¡\nğ‘— âˆ’îˆ¼ğ‘¡\nğ‘–,ğ‘—|,ğ‘Ÿğ‘¡\n4,ğ‘— â‰¥ 0.5\n(14)\nHere,îˆ¼ğ‘¡\nğ‘–,ğ‘— isthepositionofcurrentsolutionin ğ‘—ğ‘¡â„dimen-\nsionof ğ‘–ğ‘¡â„searchelementat ğ‘¡ğ‘¡â„iteration.ğ‘Ÿğ‘¡\n2,ğ‘—,ğ‘Ÿğ‘¡\n3,ğ‘— andğ‘Ÿğ‘¡\n4,ğ‘— are\nuniformly distributed random numbers,ğ·ğ‘¡\nğ‘— represents the\npositionof ğ‘—ğ‘¡â„ dimensionofdestinationpoint(bestsolution)\nat ğ‘¡ğ‘¡â„ iteration and || signify the absolute value. A ran-\ndom numberğ‘Ÿğ‘¡\n1,ğ‘— facilitates the transition from exploration\nto exploitation of the search space, which is determined\nby Equation 15.\nğ‘Ÿğ‘¡\n1,ğ‘— =ğ›¼âˆ’ğ‘¡ğ›¼\nğ‘‡ (15)\nHere, ğ›¼, ğ‘¡and ğ‘‡ represents the constant number, theğ‘¡ğ‘¡â„\niteration and total number of iterations, respectively.\nThe value ofğ‘Ÿğ‘¡\n1,ğ‘— decides if the search area is for ex-\nploitation (destination solution region)(ğ‘Ÿğ‘¡\n1,ğ‘— âˆˆ [âˆ’1,1]) or\nexploration (feasible solution region)(ğ‘Ÿğ‘¡\n1,ğ‘— âˆˆ [âˆ’1,âˆ’2] or\nğ‘Ÿğ‘¡\n1,ğ‘— âˆˆ [1,2]). Meanwhile, the stochastic variable (ğ‘Ÿğ‘¡\n2,ğ‘—,\ndefines the search agentâ€™s movement towards or away from\nthe destination point, bounded within[0,2ğœ‹], in sync with\na complete cycle of sine and cosine functions.(ğ‘Ÿğ‘¡\n3,ğ‘— bal-\nances the exploration and exploitation rates by bringing a\nrandom weight between(0,2). Furthermore,ğ‘Ÿğ‘¡\n3,ğ‘— introduces\na stochastic step size for the destination point, either em-\nphasizing (ğ‘Ÿğ‘¡\n3,ğ‘—>1) or not emphasizing(ğ‘Ÿğ‘¡\n3,ğ‘—<1) its impact.\nFinally, the parameterğ‘Ÿğ‘¡\n4,ğ‘— evenly transitions between the\nsine and cosine components, as given in Equation 14. The\nflowchart of feature optimization utilizing the SCA algo-\nrithm is presented in Figure 6.\nAfter the identification of the most efficient features\nthroughthemeta-heuristicalgorithmSCA,furtherenhance-\nment of exploitation ability can be achieved by integrating\nthe local search technique named Adaptiveğ›½-Hill Climbing\n(Ağ›½HC). Ağ›½HC is a feature optimization algorithm utiliz-\ning local search-based techniques. These search techniques\nare guided by a pair of control parametersîˆºHC and ğ›½HC,\nrespectively.Byadjustingtheseparameters,thesearchtech-\nnique finds the optimal trade-off between exploitation and\nexploration.Fine-tuningtheseparametersplaysasignificant\nrole in the optimization because it helps to enhance the\nconvergence rate. The parameterîˆºHC is initially set to a\nFigure 6:Flowchart of the Sine Cosine Algorithm:îˆ¼ğ‘¡\nğ‘–,ğ‘— denotes\nthe ğ‘–ğ‘¡â„ element of populationîˆ¼ at ğ‘¡ğ‘¡â„ iteration. ğ›¼, ğ‘‡ represents\na constant number and a maximum number of iterations.ğ‘Ÿğ‘¡\n1,ğ‘—,\nğ‘Ÿğ‘¡\n2,ğ‘—, ğ‘Ÿğ‘¡\n3,ğ‘— and ğ‘Ÿğ‘¡\n4,ğ‘— designates the random number.\nvalue close to1, but it is gradually decreased as the search\nprocess iterates. This allows the algorithm to dynamically\nadjust îˆºHC to improve the search performance, as given\nin Equation 16.\nîˆºğ‘¡\nHC =1âˆ’ ğ‘¡\n1\nğ‘ƒ\nğ‘‡\n1\nğ‘ƒ\nğ‘šğ‘ğ‘¥\n(16)\nHere, îˆºğ‘¡\nHC represents the value ofîˆºHC at timeğ‘¡, ğ‘ƒ is\nconstantusedtolinearlydecreasethevalueof îˆºHC toavalue\ncloseto 0andğ‘‡ğ‘šğ‘ğ‘¥representstheupperlimitofiterationsfor\nAğ›½HC algorithm.\nMoreover,the ğ›½parameterundergoesdeterministicadap-\ntationwithinadefinedrange âˆˆ[ğ›½ğ‘šğ‘–ğ‘›\nHC , ğ›½ğ‘šğ‘ğ‘¥\nHC ],mathematically\nexpressed in Equation 17.\nğ›½ğ‘¡\nHC =ğ›½ğ‘šğ‘–ğ‘›\nHC +ğ‘¡Ã—\nğ›½ğ‘šğ‘ğ‘¥\nHC âˆ’ğ›½ğ‘šğ‘–ğ‘›\nHC\nğ‘‡ğ‘šğ‘ğ‘¥\n(17)\nHere, ğ›½ğ‘¡\nHC denotes the rate ofğ›½HC at time ğ‘¡, ğ›½ğ‘šğ‘–ğ‘›\nHC and\nğ›½ğ‘šğ‘ğ‘¥\nHC represents the minimum and maximum value ofğ›½HC\nrespectively, ğ‘‡ğ‘šğ‘ğ‘¥ is the total number of iterations andğ‘¡\nsignifies the current time.\n3.6. Hierarchical Deep Learning Classifier\nThe Hierarchical Deep Learning Classifier (HDLC) is\na multi-stage DL classifier that utilizes the potential of\ntheoptimizedreconstructedfeatureset îˆ²ğ‘Ÿğ‘’ğ‘ğ‘œğ‘›ğ‘ ğ‘¡ğ‘Ÿğ‘¢ğ‘ğ‘¡ğ‘’ğ‘‘.HDLC\nRaghaw et al.: Preprint submitted to Elsevier Page 11 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nTable 1\nComprehensive Dataset Description: The experimental configuration includes four distinct datasets, each correlated\nwith unique cell types.\nDataset Original Leukocyte Synthetic Leukocyte Total Leukocyte\nCancer Class Normal Class Cancer Class Normal Class Cancer Class Normal Class\nC-NMC 2019 8491 4037 NIL 4454 8491 8491\nALL-IDB1 49 59 NIL NIL 49 59\nALL-IDB2 130 130 NIL NIL 130 130\nSN-AM 30 30 NIL NIL 30 30\nâ€˜NILâ€™ represents the absence of synthetic leukocyte generation.\nfocuses on the hematological features of cells for effec-\ntively classifying both normal and leukocyte cells. HDLC\nis structured into two phases: an initial convolutional phase\nand a subsequent fully-connected phase. During the initial\nphase, a 1D convolutional layer employs128 filters with\ndimensions of3Ã—3 . It computes the dot product between\nthesefiltersandtheinputfeaturesetdenotedby îˆ²ğ‘Ÿğ‘’ğ‘ğ‘œğ‘›ğ‘ ğ‘¡ğ‘Ÿğ‘¢ğ‘ğ‘¡ğ‘’ğ‘‘.\nTheconvolutionlayerinternallyemploysanon-linear ReLU\nactivationfunctiontopreservetheessentialinformation.The\noutput of a 1D convolution undergoes a linear transforma-\ntion to produce a one-dimensional vector and subsequently\ninput into a sequence of six fully connected dense layers in\nthe second stage. The neurons in the fully connected layer\nlearn non-linear associations between input features and the\ndesired output. The final output can be interpreted as the\nlikelihood of the input being a leukocyte cell, which is the\nfinal prediction of the classifier.\n4. Experimental Evaluations\nThis section illustrates the diverse datasets used for\nexperimentalevaluationsoftheproposedCoTCoNetframe-\nwork for classifying leukemic cells on blood cell images.\nSubsequently, we present the experimental setup, which\nincludesthecomparisonmethods,alongwiththeevaluation\nmetrics used. Finally, experimental results show the effec-\ntiveness of our framework.\n4.1. Dataset Summarization\nThe proposed CoTCoNet framework was tested using\nfourpubliclyavailabledatasets,namely,C-NMC2019[40],\nALL-IDB1[41],ALL-IDB2[41],andSN-AMdatasets[42].\nThe leukocyte samples used for experimentation are tabu-\nlatedinTable1.Webrieflysummarizethedatasetasfollows:\nC-NMC 2019:It is also known as the ALL Challenge\ndataset of ISBI 2019, a collection of microscopic images of\nbonemarrowfromhealthyparticipantsandparticipantswith\nAcute Lymphoblastic Leukemia (ALL). C-NMC 2019 was\ncreated to broaden the scope of research on differentiating\nleukemic blasts from normal cells, as both appear similar\nunder a microscope. The leukemic cells in the dataset are\nlabeled as â€œallâ€, and normal cells are labeled as â€œhemâ€.\nALL-IDB1: Acute Lymphoblastic Leukemia Image\nDatabase (ALL-IDB1) for Image Processing initiative re-\nsulted in datasets for segmentation and image classification.\nIt consists of multi-cell blood microscopic images and is\ndivided into two main categories: ALL-positive (blood\nsamples with leukemic cells), labeled as â€œImXXX_1.jpgâ€\nand ALL-negative (blood samples from non-ALL patients),\nlabeledasâ€œImXXX_0.jpgâ€.Expertoncologistshavelabeled\nthe lymphocytes in these blood samples.\nALL-IDB2:Theimagesinthisdatasetarecroppedareas\nof interest of normal and leukemic cells from ALL-IDB1.\nIt is a single-cell blood microscopic image for evaluating\nleukemic cell classification systems.\nSN-AM: The microscopic images in this dataset are\ncollected from patients using a bone marrow aspiration\nprocedure. The bone marrow slides of patients diagnosed\nwith B-lineage Acute Lymphoblastic Leukemia (B-ALL)\nand Multiple Myeloma (MM).\n4.2. Experimental Setup\nInthissection,wepresentaconciseoverviewofthecur-\nrent state-of-the-art methods used as benchmarks to assess\nthe effectiveness of our proposed methods. We also discuss\nthe evaluation metrics used for appraising the performance\nof different methods.\n4.2.1. Comparison Methods\nWecompareourframeworkagainstthreedifferenttypes\nof methods.\ni) Deep Learning-based Classification :The existing ap-\nproach for Acute Lymphoblastic Leukemia (ALL) classifi-\ncation includes Transfer Learning and Convolutional Neu-\nral Networks (CNN) architecture as their backbone. Mo-\nhammed et al.[14] propose an ensemble strategy that com-\nbines a CNN with Bidirectional Long Short-Term Memory\n(BiLSTM) and a Gated Recurrent Unit (GRU) architec-\nture in conjunction with Multiclass Support Vector Ma-\nchine (MSVM) classifier. Gehlotet al. [12] incorporate a\nstain deconvolutional CNN alongside a Kernel SVM aux-\niliary classifier to harness spectral-averaged features. Jawa-\nhar et al.[13] employs depth-wise convolution with diverse\ndilation rates to extract robust global and local features\nfrom microscopic bone marrow slides. Daset al.[21] use\nResNet18-based architecture supplemented with an orthog-\nonal softmax layer for ALL detection.\nii) Imbalanced Classification:This includes comprehen-\nsive qualitative and quantitative assessments of imbalanced\nRaghaw et al.: Preprint submitted to Elsevier Page 12 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nTable 2\nPerformance Comparison on C-NMC 2019 Dataset.\nMethods Acc ğ‘ Preğ‘ Recğ‘ F1ğ‘‘\nDeep Learning-based Classification\nMohammed et al.[14] 0.9629 0.9793 0.9458 0.9623\nGehlot et al.[12] 0.9630 0.9554 0.9291 0.9480\nJawaharet al.[13] 0.9100 0.9300 0.9800 0.9600\nDas et al.[21] 0.9529 0.9282 0.9765 0.9517\nImbalanced Classification Depto et al.[6] 0.7729 0.7803 0.7729 0.7766\nSegmentation-based Classification Khandekar et al.[11] 0.9710 0.9720 0.9701 0.9710\nCoTCoNet 0.9894 0.9800 0.9988 0.9893\nğ‘ Accuracy,ğ‘ Precision, ğ‘ Recall, ğ‘‘ F1-Score\nleukemia datasets. Depto et al. [6] handles class imbal-\nance issues by incorporating Generative Adversarial Net-\nworks (GANs) and integrating DL methods to introduce\na bias towards the majority class. Their approach adopts\nDenseNet121 primary architecture and integrates a class-\nweighted loss technique for both the original hematological\ncell images and conditional GAN-generated images.\niii) Segmentation-based Classification:This involves seg-\nmentationtechniquestopredictleukemiccellswithinmicro-\nscopic blood smear images. Khandekaret al.[11] employ\nYou Only Look Once (YOLOv4) in combination with CSP-\nDarkNet53 for feature extraction. Additionally, the author\nincorporates Spatial Pyramid Pooling and the Path Aggre-\ngation Network to enhance feature extraction and produce\nthe output along with its corresponding class label.\n4.2.2. Evaluation Metrics\nTo assess the performance of our framework, we adopt\nwidely used evaluation metrics for leukemic cell classifi-\ncation, such as accuracy, precision, recall, andğ¹1-Score.\nWe focus on accuracy andğ¹1-Score because our dataset\nis not skewed towards the majority or minority class. We\nalso consider precision and recall to visualize the modelâ€™s\nabilitytomakeaccuratepositivepredictionsandidentifyall\nrelevant positive instances. Table 3 shows the mathematical\nrepresentations of the metrics.\nTable 3\nEvaluation metrics for CoTCoNet framework in leuko-\ncyte and normal cell classification.\nEvaluation Metrics Mathematical Formulation\nAccuracy ğ‘‡ğ‘ƒğ‘™ğ‘’ğ‘¢ğ‘˜ +ğ‘‡ğ‘ğ‘›ğ‘œğ‘Ÿ\nğ‘‡ğ‘ƒğ‘™ğ‘’ğ‘¢ğ‘˜ +ğ¹ğ‘ƒğ‘™ğ‘’ğ‘¢ğ‘˜ +ğ‘‡ğ‘ğ‘›ğ‘œğ‘Ÿ +ğ¹ğ‘ğ‘›ğ‘œğ‘Ÿ\nPrecision ğ‘‡ğ‘ƒğ‘™ğ‘’ğ‘¢ğ‘˜\nğ‘‡ğ‘ƒğ‘™ğ‘’ğ‘¢ğ‘˜ +ğ¹ğ‘ƒğ‘™ğ‘’ğ‘¢ğ‘˜\nRecall ğ‘‡ğ‘ƒğ‘™ğ‘’ğ‘¢ğ‘˜\nğ‘‡ğ‘ƒğ‘™ğ‘’ğ‘¢ğ‘˜ +ğ¹ğ‘ğ‘›ğ‘œğ‘Ÿ\nF1 - Score 2Ã— ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› Ã—ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™\nğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› +ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™\nHere, ğ‘‡ğ‘ƒğ‘™ğ‘’ğ‘¢ğ‘˜ is True Positive, a leukemia sample cor-\nrectly predicted as leukemia. ğ‘‡ğ‘ğ‘›ğ‘œğ‘Ÿ is True Negative, a\nnon-leukemia sample correctly predicted as non-leukemia.\nğ¹ğ‘ƒğ‘™ğ‘’ğ‘¢ğ‘˜ is False Positive, a non-leukemia sample incorrectly\npredicted as leukemia.ğ¹ğ‘ğ‘›ğ‘œğ‘Ÿ is False Negative, a leukemia\nsample incorrectly predicted as non-leukemia.\n4.3. Experimental Results\nThis section presents the experimental results and com-\nparisons of our proposed method. First, we evaluate the\nperformanceofourmethodagainststate-of-the-artmethods.\nNext, we perform ablation studies to evaluate the impact\nand effectiveness of individual modules consisting of our\nframework.\nhl\n4.3.1. Performance Evaluation\nWe compare the proposed CoTCoNet framework with\nthe existing methods on different datasets to show its per-\nformance.\nEffective Comparison on C-NMC 2019 Dataset:Table 2\npresents a detailed overview of the state-of-the-art methods\nin leukemic cell classification and shows how our proposed\nmethod outperforms other methods.\nWecanobservethatDeepLearning-basedClassification\n(proposed by Mohammed et al. [14], Gehlot et al. [12],\nJawaharet al.[13] and Daset al.[21]) does not yield favor-\nable performance in comparison to CoTCoNet. Particularly,\nJawaharet al.[13] approach exhibits a lower performance,\nwith a decrease of 7.94% due to the limited effectiveness of\nits cluster layers in capturing both local and global features\nefficiently. On the other hand, [21] struggles to capture the\nhiddendiscriminativefeatureswithinleukocytecellimages,\nresulting in a 3.65% decrease in accuracy. The methods\nproposedby[14]and[12]bothcombineafeatureextraction\nmodule with a Support Vector Machine (SVM) classifier,\nwhich results in satisfactory performance but not as good\nas CoTCoNet. However, CoTCoNet integrates spatial and\nglobal features and identifies the hidden features to achieve\nanoverallimprovementof2-7%inaccuracyand2-4%inF1-\nScore compared to these methods. Deptoet al.[21] method\nofferspotentialforimprovementcomparedtoothermethods,\nprimarily due to its handling of imbalanced data samples.\nRaghaw et al.: Preprint submitted to Elsevier Page 13 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nTable 4\nPerformance Comparison on ALL-IDB1 Dataset.\nMethods Acc ğ‘ Preğ‘ Recğ‘ F1ğ‘‘\nDeep Learning-based Classification\nMohammed et al.[14] 0.9412 0.8889 1.0000 0.9412\nGehlot et al.[12] 1.0000 1.0000 1.0000 1.0000\nJawahar et al.[13] 0.9412 0.8750 1.0000 0.9333\nDas et al.[21] 0.9939 1.0000 0.9865 0.9932\nImbalanced Classification Depto et al.[6] 0.9118 0.9444 0.8947 0.9189\nSegmentation-based Classification Khandekar et al.[11] 0.9787 0.9844 0.9844 0.9844\nCoTCoNet 1.0000 1.0000 1.0000 1.0000\nğ‘ Accuracy,ğ‘ Precision, ğ‘ Recall, ğ‘‘ F1-Score\nTable 5\nPerformance Comparison on ALL-IDB2 Dataset.\nMethods Acc ğ‘ Preğ‘ Recğ‘ F1ğ‘‘\nDeep Learning-based Classification\nMohammed et al.[14] 0.9750 1.0000 0.9524 0.9756\nGehlot et al.[12] 0.9250 0.9500 0.9048 0.9268\nJawaharet al.[13] 0.8250 0.9500 0.76.00 0.8444\nDas et al.[21] 0.9821 0.9845 0.9795 0.9820\nImbalanced Classification Depto et al.[6] 0.8167 0.8659 0.8417 0.8536\nSegmentation-based Classification Khandekar et al.[11] 0.9787 0.9844 0.9844 0.9844\nCoTCoNet 1.0000 1.0000 1.0000 1.0000\nğ‘ Accuracy,ğ‘ Precision, ğ‘ Recall, ğ‘‘ F1-Score\nConversely, Khandekaret al. [11] demonstrates competi-\ntive performance by incorporating segmentation techniques\nwith feature extraction methods, resulting in a minor ac-\ncuracy drop of 1.84%. Our proposed CoTCoNet frame-\nwork addresses the class imbalance issue by employing a\nGAN-driven mechanism for cell synthesis and segmenting\nleukocytecellswhileexcludingextraneoussections,suchas\nplasma, to enhance feature extraction.\nEffective Comparison on ALL-IDB1 Dataset:The per-\nformance evaluation of the CoTCoNet framework relative\nto existing methods on the ALL-IDB1 dataset can be ob-\nserved in Table 4. The method proposed by Deptoet al.[6]\naddresses the imbalance in the ALL-IDB1 dataset, result-\ning in a noticeable reduction in accuracy of 8.82%. Khan-\ndekaretal. [11]proposesamethodthatclassifiescellsbased\non regional features, demonstrating commendable perfor-\nmance with a marginal accuracy variation of merely 2.13%.\nCoTCoNet, in contrast, uses a balanced dataset and gives\nequal importance to geometrical and global features, lead-\ning to improved classification performance. Among Deep\nLearning-based Classification, Gehlotet al.[12] and CoT-\nCoNet framework outperforms other methods due to their\nfocusonfeature-baseddeepclassifier.However,themethods\nby Mohammed et al. [14] and Jawaharet al. [13] do not\nefficiently utilize the prime features of cell images, which\nresultsinaccuracygapof5.88%.Meanwhile,Das etal. [21]\nachieve comparable performance, with a mere 0.61% differ-\nence in accuracy, when utilizing a residual-based architec-\nture for feature learning. However, when compared to these\ntechniques, the CoTCoNet framework is curated to learn\nthe hidden features of cell images for precise classification,\nwhich gives it an edge over the other techniques.\nEffective Comparison on ALL-IDB2 Dataset:\nComparison results on the ALL-IDB2 dataset are pre-\nsented in Table 5. The study conducted by Deptoet al.[6]\ndiscussesanimbalancedscenarioinleukemiaclassification,\nwhere their method learns fewer features, resulting in a\nsignificant decrease in performance. Khandekaret al.[11]\neffectively segments overlapped cells in clustered regions,\nleading to satisfactory classification performance. CoT-\nCoNet, on the other hand, takes a comprehensive approach\nby incorporating GAN-driven solutions to tackle class im-\nbalance problems and segmenting blood smear images to\nlearn sharp features for precise classification. The Deep\nLearning classification method that Jawahar et al. [13]\nutilizes does not yield promising results, this method fails\ntoemphasizeprominenthiddenfeatures.Furthermore,tech-\nniques by Mohammed et al. [14] and Das et al. [21]\nexhibit almost identical performance, as the author uses\nconvolution-based filters to obtain features but fail to com-\nbine spatial and global features which leads to marginal\naccuracy decrease in the range of 1-3%. The method pro-\nposedbyGehlot etal. [12]utilizesspectral-averagedfeatures\nconstrainedly, resulting in a 7.5% performance decline.\nRaghaw et al.: Preprint submitted to Elsevier Page 14 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nFigure 7:Comparative Analysis of CoTCoNet framework and existing methods across four datasets. The ROC (Receiver Operating\nCharacteristic) is used to evaluate performance. Radar charts depict the performance of each method across accuracy, precision,\nrecall, and F1-Score metrics across various datasets.\nTable 6\nPerformance Comparison on SN-AM Dataset.\nMethods Acc ğ‘ Preğ‘ Recğ‘ F1ğ‘‘\nDeep Learning-based Classification\nMohammed et al.[14] 0.8462 1.0000 0.7778 0.8750\nGehlot et al.[12] 0.9231 0.8571 1.0000 0.9231\nJawaharet al.[13] 0.8462 0.8571 0.8571 0.8571\nDas et al.[21] 0.7692 0.7143 0.8333 0.7692\nImbalanced Classification Depto et al.[6] 0.8769 0.8142 0.9521 0.8778\nSegmentation-based Classification Khandekar et al.[11] 0.9231 1.0000 0.8750 0.9333\nCoTCoNet 1.0000 1.000 1.0000 1.0000\nğ‘ Accuracy,ğ‘ Precision, ğ‘ Recall, ğ‘‘ F1-Score\nHowever,CoTCoNetdemonstratessuperiorperformanceby\noptimizing the learning of features, thereby significantly\nimproving the overall performance for the classification of\nleukocytes.\nEffective Comparison on SN-AM Dataset:The perfor-\nmance of the CoTCoNet framework and other state-of-the-\nart techniques in leukemic cell classification is presented\nin Table 6. Several studies, including Daset al.[21], Mo-\nhammed et al. [14] and Jawaharet al. [13] overlook fea-\nture selection and optimization, resulting in lower perfor-\nmance. In contrast, Gehlotet al.[12] effectively harnesses\nspectral-averaged features of blood cells to achieve supe-\nrior performance among Deep Learning-based methods.\nKhandekaret al.[11] employs a region-based segmentation\ntechnique to classify leukemic cells. On the other hand,\nDepto et al.[6] demonstrate that the classification perfor-\nmanceisdegradedwithimbalanceddatasamples.However,\nCoTCONet leverages a GAN-driven technique to decode\nclassimbalanceissueseffectively.Additionally,asegmenta-\ntiontechniqueisemployedtoextractleukocytecellstolearn\na robust mapping between features and classes. This map-\npingenablesthefeature-learningmechanismtoquantifythe\ncore features for better discrimination of the leukemic class\nandnon-leukemicclass.Asaresult,ourproposedframework\nexhibits superior performance when applied to the SN-AM\ndataset compared to existing techniques. Figure 7 shows\nthe Receiver Operating Characteristic (ROC) curve and the\nperformance comparison of different methods.\n4.3.2. Ablation Study\nTo assess the contributions of the key modules within\nthe CoTCoNet framework, we systematically removed each\nRaghaw et al.: Preprint submitted to Elsevier Page 15 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nTable 7\nAblation Study on CNMC Dataset.\nMethods Acc ğ‘ Preğ‘ Recğ‘ F1ğ‘‘\nEffect of Image Enhancement\nCoTCoNet (No Enhancement) 0.9011 0.8681 0.9294 0.8977\nCoTCoNet (Fuzzy) 0.9211 0.9741 0.8807 0.9251\nCoTCoNet (MirNET) 0.9499 0.8999 1.0000 0.9473\nCoTCoNet (HE) 0.9541 0.9753 0.9356 0.9550\nCoTCoNet (Sharpen) 0.9611 0.9435 0.9780 0.9604\nCoTCoNet (CLAHE) 0.9788 0.9647 0.9927 0.9785\nEffect of Segmentatiom\nCoTCoNet (UNet) 0.8657 0.8092 0.9124 0.8577\nCoTCoNet (UNet++) 0.8920 0.6568 0.9839 0.7878\nEffect of Augmentation\nCoTCoNet (No Augmentation) 0.8206 0.5457 0.8024 0.6496\nCoTCoNet (Traditional Augmentation) 0.8767 0.8499 0.8919 0.8704\nEffect of Feature Extraction\nCoTCoNet (ViT-B/32) 0.8581 0.8269 0.8819 0.8535\nCoTCoNet (ViT-L/32) 0.8422 0.8996 0.7703 0.8299\nCoTCoNet (ViT-H/16) 0.8351 0.6914 0.9702 0.8075\nCoTCoNet (GMod) 0.8651 0.8422 0.8827 0.862\nCoTCoNet (VGG-16) 0.8528 0.8492 0.8303 0.8396\nCoTCoNet (SMod) 0.8687 0.9184 0.8092 0.8604\nCoTCoNet (GMod + SMod) 0.9395 0.8898 0.9883 0.9365\nEffect of Graph-based Feature Reconstruction and Feature Selection\nCoTCoNet (w\\o graph + w\\o selection) 0.9435 0.9764 0.9160 0.9453\nCoTCoNet (with graph + w\\o selection) 0.9510 0.9494 0.9988 0.9734\nCoTCoNet (w\\o graph + with selection) 0.9865 0.9741 0.9988 0.9863\nCoTCoNet 0.9894 0.9800 0.9988 0.9893\nğ‘ Accuracy,ğ‘ Precision, ğ‘ Recall, ğ‘‘ F1-Score, w/o shorthand for â€œwithoutâ€\nmoduleoneatatimeontheC-NMC2019Dataset(referTa-\nble 7). This ablation study showed that all proposed com-\nponents and strategies actively enhance the overall perfor-\nmanceofourframework.InTable7,theadditionaltechnique\nor module under examination is indicated within parenthe-\nses (e.g., CoTCoNet [technique/module]). Specifically, we\nexplored the effects of different components, such as Image\nEnhancement, Segmentation, Data Augmentation, Feature\nExtraction, Graph-based Feature Reconstruction, and Fea-\nture Selection. The pipeline for our proposed model is com-\nprehensively described in Section 3.2.\nEffect of Image Enhancement:The ablation study in Ta-\nble 7 shows that the accuracy of CoTCoNet drops by 8.83%\nwhen no image enhancement technique is applied. Other\nenhancement techniques, such as Fuzzy [43], MirNet [44],\nand Histogram Equalization [45], yield accuracy reductions\nranging from 3-6%. CoTCoNet leverages the combined use\nof CLAHE, followed by the Sharpen technique. The perfor-\nmance decreases by 2.83% without Sharpen and by 1.06%\nwithoutCLAHE.Theseresultsshowastrongdependencyon\nimageenhancementtechniqueswithintheCoTCoNetframe-\nwork or enhancing the learning of features from leukocytes.\nEffect of Segmentation:Table 7 shows that CoTCoNet\nachieves a significantly higher accuracy of 12.57% and\n9.27%thanCoTCoNet(UNet[46])andCoTCoNet(UNet++\n[47]), respectively. CoTCoNet outperforms the above tech-\nniques and takes advantage of the finely-tuned Leukemia\nSegment Anything Model (LeuSAM) to precisely identify\nleukocyte cell linings. This provides a good initialization\npoint for parameter learning, contributing to the superior\nperformance of CoTCoNet.\nEffect of Augmentation: Examining the data augmen-\ntation in Table 7, it is apparent that utilizing imbalanced\nleukemia samples leads to a substantial accuracy drop of\n16.88%, primarily due to overfitting. Conversely, employ-\ning CoTCoNet (Traditional Augmentation), which includes\nscaling, cropping, translation, flipping, and rotation, there\nis a notable performance improvement of 5.61%. However,\nthis improvement is 11.27% lower than what is achieved by\nourproposedCoTCoNetframework.Thesefindingsdemon-\nstrate the positive impact of data augmentation techniques\nto enhance method performance. Unlike the previous tech-\nniques, CoTCoNet incorporates LeuGAN with the aim of\nRaghaw et al.: Preprint submitted to Elsevier Page 16 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\n(a)\n (b)\nFigure 8:(a) Feature maps of leukemic cells capturing global and block-wise spatial features. (b) Feature maps of normal cells\ncapturing global and block-wise spatial features. The features of the leukemic class show denser patterns compared to the normal\nclass. This densification pattern helps to enhance classifier performance.\nsynthesizinghigh-qualityleukocytecellstobalancethedata\nsamples, making the model more robust and trainable.\nEffect of Feature Extraction:To assess the importance\nof the feature extractor, we perform an ablation experi-\nment using only transformer-based and convolution-based\nfeature extractors (i.e., without Feature Reconstruction and\nSelection). The results in Table 7 indicate that performance\ndeclines by 13-15% in transformer-based feature extractors,\nspecifically ViT-B/32, ViT-L/32, and ViT-H/16. Interest-\ningly, the utilization of a custom feature extractor known as\nthe Global Module (GMod) demonstrates a 3-7% improve-\nment over transformer-based extractors. Furthermore, the\naccuracy of the convolution-based VGG-16 feature module\nis 1.59% less accurate compared to the custom convolution-\nbased feature extractor, Spatial Module (SMod). However,\nthecoupledperformanceofbothGModandSModsurpasses\nthat of the other feature extractors because they learn from\nthe integrated global and spatial features of the leukocyte\ncells.\nEffect of Graph-based Feature Reconstruction and Fea-\nture Selection:Table 7 demonstrates the supremacy of the\nCoTCoNetframework,whichemploysagraph-basedmech-\nanism for feature reconstruction and a population-based al-\ngorithm for feature selection and optimization. Specifically,\nCoTCoNet (w\\o graph + with selection) achieves competi-\ntiveperformance,outperformingtheproposedCoTCoNetby\na margin of 0.29%. This observation highlights the signifi-\ncanceoffeatureselectioninthetrainingprocess.Conversely,\nalternative combinations (i.e., w\\o graph + w\\o selection\nand with graph + w\\o selection) failed to deliver effective\nperformance on classifying leukemic cells.\n5. Discussion\nInthisstudy,weproposeanadvancedframeworkknown\nas CoTCoNet for detecting acute lymphoblastic leukemia.\nCoTCoNet leverages the power of transformers and convo-\nlutional networks to extract both global and spatial features\nfrom blood cell images. We evaluate CoTCoNet on four di-\nversedatasetsanddemonstrateitssuperiorperformanceand\nrobustness over existing methods. Additionally, we employ\naLocalInterpretableModel-agnosticExplanations(LIME),\nan Explainable Artificial Intelligence (XAI) method that\nassignsweightstothemostinfluentialregionsandhighlights\nthem. The prominently highlighted regions are the primary\ncontributors to the accurate classification of leukocytes.\nFrom a feature learning viewpoint, the transformer-\nbasedGModmodule,describedinSection3.4.1,specializes\nin learning long-range dependencies and contextual infor-\nmation within the cells. Meanwhile, the CNN-based SMod\nmodule, detailed in Section 3.4.2, focuses on preserving\nlocal details and the structural integrity of the cells. These\ncoupled modules enable our framework to extract more\ncomprehensive and discriminative features for leukemia\ndetection.Moreover,ourframeworkemploysanovelgraph-\nbased feature reconstruction module known as GraFR, as\noutlined in Section 3.4.3. GraFR is a key component that\nidentifies the hidden features and reconstructs them by\ncomputing their similarity scores with other data points in\na graph structure.\nRaghaw et al.: Preprint submitted to Elsevier Page 17 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\nFigure 9:Visualization of 20 microscopic blood smear images from C-NMC 2019 Dataset and highlighted features using LIME.\nThe images in the first row are diagnosed as positive (cancerous cell) by our CoTCoNet framework, while the images in the third\nrow are diagnosed as negative (normal cell).\nThefeaturesofCoTCoNetcanbevisualizedinFigure8,\nshowing denser patterns for the leukemic class compared\nto the normal class. This observation implies that different\ndensification induced by the GMod, SMod, and GraFR\nmodulesisanessentialcharacteristicofclassdiscrimination,\nwheretheHierarchicalDeepLearningClassifier(HDLC)is\ncapableofeffectivelydifferentiatingbetweenthetwoclasses\nbased on feature density, even when the visual appearance\nof images from both classes is similar. Figure 10 illustrates\nclass discrimination in the final layers, allowing a linear\nseparationofthetwoclasses.Thisreinforcestheclearinsight\nthat the dissimilarity in density arises due to the coupled\nfeatures of the CoTCoNet framework.\nFigure 10: Class Discrimination at last layer of Hierarchical\nDeep Learning Classifier. The final layer allows the linear\nseparation of the two indistinguishable classes.\nClassifying the leukemic cell requires robustness to\nsubject-level variability. To assess the robustness of our\nframework,weconductedacomprehensiveevaluationusing\nfour publicly available and diverse datasets, encompassing\nboth single-cell and multi-cell data (refer Section 4.1). The\nexperimentalsetupinvolvescomparingourproposedframe-\nwork with state-of-the-art methods (refer Section 4.2.1) and\nusing appropriate evaluation metrics (refer Section 4.2.2) to\nassess performance. CoTCoNet demonstrates superior per-\nformanceacrossdiversedatasets,underscoringtheprofound\nsignificance of our proposed framework. To gain deeper\ninsights into the superior performance of CoTCoNet, we\nconductedablationstudies(referSection4.3.2)showingthe\nefficacy of each module in effectively distinguishing sparse\ncell features.\nFor the visual explanation of the decision reasoning of\nour CoTCoNet framework, we adopt Local Interpretable\nModel-agnostic Explanations (LIME) [48] to gain insights\ninto the specific regions that significantly contribute to the\nclassification process. Figure 9 illustrates 20 microscopic\nbloodsmearimagessourcedfromtheC-NMC2019dataset;\neachimageisaccompaniedbyhighlightedpertinentfeatures\ngenerated by the LIME technique. The first ten images in\nthe first row have been diagnosed as positive for leukemia\nby our CoTCoNet framework, while the images in the third\nrow were diagnosed as negative. However, if no highly\nsuspicious blood cells are detected, the model classifies the\nimage as negative. This visualization underscores the inter-\npretability of our CoTCoNet framework, providing valuable\ninsights into its decision-making process.\nRaghaw et al.: Preprint submitted to Elsevier Page 18 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\n6. Conclusion\nIn this study, we propose a novel framework called\nCoupledTransformerConvolutionalNetwork(CoTCoNet),\nwhich hierarchically integrates a deep convolution net-\nwork with a powerful transformer for the classification of\nleukemiawithinmicroscopicbloodsmearslides.CoTCoNet\neffectively utilizes the capabilities of transformers and deep\nconvolution networks to proficiently extract both global and\nspatial features from blood cell images. Furthermore, we\nincorporate graph-based feature reconstruction to elevate\nthefeatureknowledge,leveragingtheadvantageofcomplex\nand hard-to-see biological features of the leukocytes. The\naforementioned technical framework comprises several ad-\nvantages: (a) the proposed method acquires features from\nindistinguishable cell images across different classes, sig-\nnificantly enhancing model flexibility in clinical practice.\nMoreover, the preservation of the structural integrity of\ncells in blood smear images yields comprehensive and\ndiscriminativefeatures; (b)theproposedframeworkutilizes\na Population-based Meta-Heuristic Algorithm to identify\noptimal features, effectively reducing optimization errors;\n(c) the proposed method is capable of generating inter-\npretable attention maps to reinforce the prediction results,\nthereby facilitating hematopathologists in their decision-\nmaking process when utilizing AI algorithms; (d) the pro-\nposed framework demonstrates superior classification per-\nformanceacrossfourpubliclyavailableanddiversedatasets.\nWeacknowledgesomelimitationsinourresearch,firstly,\ntheproposedmethodconsidersthefinalstagesofleukocytes,\noverlooking the early stages of cellular development. Sec-\nondly, our approach depends on labeled data, necessitating\nconsiderable input from experienced experts. In our future\nresearchendeavors,weaimtoovercometheselimitationsby\ndevelopingaframeworkcapableofidentifyingdevelopmen-\ntalcellstatesanddistinguishingthembasedoncytochemical\nfeatures.Weaimtoleveragepriorinformationbyintegrating\nbloodsmearhistologywithdevelopmentalcellstatestohar-\nness semi-supervised learning techniques for the automated\nclassification of leukemia and its subtypes.\nReferences\n[1] R. L. Siegel, K. D. Miller, N. S. Wagle, A. Jemal, Cancer statistics,\n2023, CA: A Cancer Journal for Clinicians 73 (2023) 17â€“48.doi:\n10.3322/caac.21763.\n[2] S.Asthana,S.Labani,S.Mehrana,S.Bakhshi,Incidenceofchildhood\nleukemia and lymphoma in india (2018).doi:10.1016/j.phoj.2017.\n12.004.\n[3] Y. Liu, F. Long, Acute lymphoblastic leukemia cells image analysis\nwith deep bagging ensemble learning, Springer, 2019, Ch. 12, pp.\n113â€“121. doi:10.1007/978-981-15-0798-4_12 .\n[4] A. B. Kulâ€™chynsâ€™kyi, V. M. Kyjenko, W. Zukow, I. L. Popovych,\nCausal neuro-immune relationships at patients with chronic\npyelonephritis and cholecystitis. correlations between parameters\neeg, hrv and white blood cell count, Open Medicine (Poland) 12 (1)\n(2017) 201â€“213.doi:10.1515/med-2017-0030 .\n[5] A.Mittal,S.Dhalla,S.Gupta,A.Gupta,Automatedanalysisofblood\nsmearimagesforleukemiadetection:Acomprehensivereview,ACM\nComputing Surveys 54 (2022).doi:10.1145/3514495.\n[6] D. S. Depto, M. M. Rizvee, A. Rahman, H. Zunair, M. S. Rahman,\nM. R. Mahdy, Quantifying imbalanced classification methods for\nleukemia detection, Computers in Biology and Medicine 152 (2023).\ndoi:10.1016/j.compbiomed.2022.106372.\n[7] S.Huang,I.Arpaci,M.Al-Emran,S.KÄ±lÄ±Ã§arslan,M.A.Al-Sharafi,A\ncomparativeanalysisofclassicalmachinelearninganddeeplearning\ntechniquesforpredictinglungcancersurvivability,MultimediaTools\nand Applications 82 (2023).doi:10.1007/s11042-023-16349-y .\n[8] E. SantamarÃ­a-VÃ¡zquez, V. MartÃ­nez-Cagigal, D. Marcos-MartÃ­nez,\nV. RodrÃ­guez-GonzÃ¡lez, S. PÃ©rez-Velasco, S. Moreno-CalderÃ³n,\nR. Hornero, MedusaÂ©: A novel python-based software ecosystem to\naccelerate brain-computer interface and cognitive neuroscience re-\nsearch,ComputerMethodsandProgramsinBiomedicine230(2023).\ndoi:10.1016/j.cmpb.2023.107357.\n[9] Ã‰lodie Labrecque Langlais, P. ThÃ©riault-Lauzier, G. Marquis-Gravel,\nM. Kulbay, D. Y. So, J. F. Tanguay, H. Q. Ly, R. Gallo, F. Lesage,\nR. Avram, Novel artificial intelligence applications in cardiology:\nCurrentlandscape,limitations,andtheroadtoreal-worldapplications\n(2023). doi:10.1007/s12265-022-10260-x .\n[10] H. Jiang, Z. Diao, T. Shi, Y. Zhou, F. Wang, W. Hu, X. Zhu, S. Luo,\nG. Tong, Y. D. Yao, A review of deep learning-based multiple-\nlesion recognition from medical images: classification, detection and\nsegmentation (2023).doi:10.1016/j.compbiomed.2023.106726.\n[11] R. Khandekar, P. Shastry, S. Jaishankar, O. Faust, N. Sampathila,\nAutomated blast cell detection for acute lymphoblastic leukemia\ndiagnosis,BiomedicalSignalProcessingandControl68(2021). doi:\n10.1016/j.bspc.2021.102690.\n[12] S. Gehlot, A. Gupta, R. Gupta, Sdct-auxnetğœƒ: Dct augmented stain\ndeconvolutional cnn with auxiliary classifier for cancer diagnosis,\nMedicalImageAnalysis61(2020). doi:10.1016/j.media.2020.101661.\n[13] M. Jawahar, S. H, J. A. L, A. H. Gandomi, Alnett: A cluster layer\ndeep convolutional neural network for acute lymphoblastic leukemia\nclassification, Computers in Biology and Medicine 148 (2022).doi:\n10.1016/j.compbiomed.2022.105894.\n[14] K. K. Mohammed, A. E. Hassanien, H. M. Afify, Refinement of en-\nsemblestrategyforacutelymphoblasticleukemiamicroscopicimages\nusing hybrid cnn-gru-bilstm and msvm classifier, Neural Computing\nand Applications 35 (2023).doi:10.1007/s00521-023-08607-9 .\n[15] B.Leng,C.Wang,M.Leng,M.Ge,W.Dong,Deeplearningdetection\nnetworkforperipheralbloodleukocytesbasedonimproveddetection\ntransformer, Biomedical Signal Processing and Control 82 (2023).\ndoi:10.1016/j.bspc.2022.104518.\n[16] C. J. Heaven, H. C. Wanstall, N. T. Henthorn, J. W. Warmenhoven,\nS. P. Ingram, A. L. Chadwick, E. Santina, J. Honeychurch, C. K.\nSchmidt, K. J. Kirkby, N. F. Kirkby, N. G. Burnet, M. J. Merchant,\nThesuitabilityofmicronucleiasmarkersofrelativebiologicaleffect,\nMutagenesis 37 (2022).doi:10.1093/mutage/geac001.\n[17] I. Varadarajan, E. Pierce, L. Scheuing, A. Morris, F. E. Chaer,\nM.Keng,Post-hematopoieticcelltransplantationrelapsedacutelym-\nphoblasticleukemia:Currentchallengesandfuturedirections(2023).\ndoi:10.2147/OTT.S274551.\n[18] A. Abhishek, R. K. Jha, R. Sinha, K. Jha, Automated detection\nand classification of leukemia on a subject-independent test dataset\nusing deep transfer learning supported by grad-cam visualization,\nBiomedical Signal Processing and Control 83 (2023).doi:10.1016/\nj.bspc.2023.104722.\n[19] W. Wang, M. Luo, P. Guo, Y. Wei, Y. Tan, H. Shi, Artificial\nintelligence-assisteddiagnosisofhematologicdiseasesbasedonbone\nmarrow smears using deep neural networks, Computer Methods and\nPrograms in Biomedicine 231 (2023). doi:10.1016/j.cmpb.2023.\n107343.\n[20] N. Jiwani, K. Gupta, G. Pau, M. Alibakhshikenari, Pattern recogni-\ntion of acute lymphoblastic leukemia (all) using computational deep\nlearning, IEEE Access 11 (2023).doi:10.1109/ACCESS.2023.3260065.\n[21] P.K.Das,B.Sahoo,S.Meher,Anefficientdetectionandclassification\nof acute leukemia using transfer learning and orthogonal softmax\nlayer-based model, IEEE/ACM Transactions on Computational Bi-\nology and Bioinformatics (2022).doi:10.1109/TCBB.2022.3218590.\nRaghaw et al.: Preprint submitted to Elsevier Page 19 of 20\nCoTCoNet: An Optimized Coupled Transformer-Convolution Network for Leukemia Detection\n[22] S. Dhalla, A. Mittal, S. Gupta, J. Kaur, Harshit, H. Kaur, A combi-\nnationofsimpleanddilatedconvolutionwithattentionmechanismin\na feature pyramid network to segment leukocytes from blood smear\nimages, Biomedical Signal Processing and Control 80 (2023).doi:\n10.1016/j.bspc.2022.104344.\n[23] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, L. C. Chen, Mo-\nbilenetv2: Inverted residuals and linear bottlenecks, in: Proceedings\nof the IEEE conference on computer vision and pattern recognition,\n2018, pp. 4510â€“4520.doi:10.1109/CVPR.2018.00474.\n[24] G. Atteia, A. A. Alhussan, N. A. Samee, Bo-allcnn: Bayesian-based\noptimized cnn for acute lymphoblastic leukemia detection in mi-\ncroscopic blood smear images, Sensors 22 (2022). doi:10.3390/\ns22155520.\n[25] F.Hoorali,H.Khosravi,B.Moradi,Irunetformedicalimagesegmen-\ntation,ExpertSystemswithApplications191(2022). doi:10.1016/j.\neswa.2021.116399.\n[26] I. Qureshi, J. Yan, Q. Abbas, K. Shaheed, A. B. Riaz, A. Wahid,\nM. W. J. Khan, P. Szczuko, Medical image segmentation using deep\nsemantic-based methods: A review of techniques, applications and\nemerging trends, Information Fusion 90 (2023). doi:10.1016/j.\ninffus.2022.09.031.\n[27] T. G. Devi, N. Patil, S. Rai, C. S. Philipose, Gaussian blurring\ntechnique for detecting and classifying acute lymphoblastic leukemia\ncancer cells from microscopic biopsy images, Life 13 (2023).doi:\n10.3390/life13020348.\n[28] S.Alagu,N.A.Priyanka,G.Kavitha,K.B.Bagan,Automaticdetec-\ntion of acute lymphoblastic leukemia using unet based segmentation\nand statistical analysis of fused deep features, Applied Artificial\nIntelligence 35 (2021).doi:10.1080/08839514.2021.1995974.\n[29] Z. F. Mohammed, A. A. Abdulla, An efficient cad system for all cell\nidentificationfrommicroscopicbloodimagesd,MultimediaToolsand\nApplications 80 (2021).doi:10.1007/s11042-020-10066-6 .\n[30] P. K. Das, P. Jadoun, S. Meher, Detection and classification of acute\nlymphocyticleukemia,in:2020IEEE-HYDCON,2020,pp.1â€“5. doi:\n10.1109/HYDCON48903.2020.9242745.\n[31] P. K. Das, S. Meher, R. Panda, A. Abraham, An efficient blood-\ncell segmentation for the detection of hematological disorders, IEEE\nTransactions on Cybernetics 52 (2022). doi:10.1109/TCYB.2021.\n3062152.\n[32] L. Wang, C. Wu, Dynamic imbalanced business credit evaluation\nbased on learn++ with sliding time window and weight sampling\nand fcm with multiple kernels, Information Sciences 520 (2020).\ndoi:10.1016/j.ins.2020.02.011.\n[33] R. Panigrahi, S. Borah, Dual-stage intrusion detection for class im-\nbalance scenarios, Computer Fraud and Security 2019 (2019).doi:\n10.1016/S1361-3723(19)30128-9 .\n[34] S. Saxena, S. Shukla, M. Gyanchandani, Breast cancer histopathol-\nogy image classification using kernelized weighted extreme learning\nmachine, International Journal of Imaging Systems and Technology\n31 (2021).doi:10.1002/ima.22465.\n[35] A.Farshidvard,F.Hooshmand,S.A.MirHassani,Anoveltwo-phase\nclustering-based under-sampling method for imbalanced classifica-\ntionproblems,ExpertSystemswithApplications213(2023)119003.\ndoi:10.1016/J.ESWA.2022.119003.\n[36] B. Chen, F. Qin, Y. Shao, J. Cao, Y. Peng, R. Ge, Fine-grained\nimbalanced leukocyte classification with global-local attention trans-\nformer,JournalofKingSaudUniversity-ComputerandInformation\nSciences 35 (2023).doi:10.1016/j.jksuci.2023.101661.\n[37] R. M. Umer, A. Gruber, S. S. Boushehri, C. Metak, C. Marr, Im-\nbalanced domain generalization for robust single cell classification\nin hematological cytomorphology, https://arxiv.org/abs/2303.07771\n(2023).\n[38] A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson,\nT. Xiao, S. Whitehead, A. C. Berg, W.-Y. Lo, P. DollÃ¡r, R. Girshick,\nSegment anything, https://arxiv.org/abs/2304.02643 (2023).\n[39] S. Mirjalili, Sca: A sine cosine algorithm for solving optimization\nproblems, Knowledge-Based Systems 96 (2016). doi:10.1016/j.\nknosys.2015.12.022.\n[40] R.Gupta,S.Gehlot,A.Gupta,C-nmc:B-lineageacutelymphoblastic\nleukaemia:Abloodcancerdataset,MedicalEngineeringandPhysics\n103 (2022).doi:10.1016/j.medengphy.2022.103793.\n[41] R. D. Labati, V. Piuri, F. Scotti, All-idb: The acute lymphoblastic\nleukemia image database for image processing, in: 2011 18th IEEE\ninternational conference on image processing, 2011, pp. 2045â€“2048.\ndoi:10.1109/ICIP.2011.6115881.\n[42] A. Gupta, R. Duggal, S. Gehlot, R. Gupta, A. Mangal, L. Kumar,\nN. Thakkar, D. Satpathy, Gcti-sn: Geometry-inspired chemical and\ntissue invariant stain normalization of microscopic medical images,\nMedicalImageAnalysis65(2020). doi:10.1016/j.media.2020.101788.\n[43] U. Kadak, Fractional sampling operators of multivariate fuzzy func-\ntions and applications to image processing, Applied Soft Computing\n132 (2023).doi:10.1016/j.asoc.2022.109901.\n[44] S. W. Zamir, A. Arora, S. Khan, M. Hayat, F. S. Khan, M. H. Yang,\nL. Shao, Learning enriched features for fast image restoration and\nenhancement, IEEE Transactions on Pattern Analysis and Machine\nIntelligence 45 (2023).doi:10.1109/TPAMI.2022.3167175.\n[45] H. Rahman, G. C. Paul, Tripartite sub-image histogram equalization\nfor slightly low contrast gray-tone image enhancement: Slightly low\ncontrast image enhancement with tsihe, Pattern Recognition 134\n(2023). doi:10.1016/j.patcog.2022.109043.\n[46] O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional networks\nfor biomedical image segmentation, in: Medical Image Computing\nand Computer-Assisted Interventionâ€“MICCAI 2015: 18th Interna-\ntional Conference, Munich, Germany, October 5-9, 2015, Proceed-\nings, Part III 18, Vol. 9351, 2015, pp. 234â€“241. doi:10.1007/\n978-3-319-24574-4_28 .\n[47] Z. Zhou, M. M. R. Siddiquee, N. Tajbakhsh, J. Liang, Unet++:\nA nested u-net architecture for medical image segmentation, in:\nDeep Learning in Medical Image Analysis and Multimodal Learning\nfor Clinical Decision Support: 4th International Workshop, DLMIA\n2018, and 8th International Workshop, ML-CDS 2018, Held in Con-\njunction with MICCAI 2018, Granada, Spain, September 20, 2018,\nProceedings 4, Vol. 11045 LNCS, 2018, pp. 3â€“11. doi:10.1007/\n978-3-030-00889-5_1 .\n[48] M. T. Ribeiro, S. Singh, C. Guestrin, \"why should i trust you?\" ex-\nplaining the predictions of any classifier, in: Proceedings of the 22nd\nACMSIGKDDinternationalconferenceonknowledgediscoveryand\ndata mining, Vol. 13-17-August-2016, 2016, pp. 1135â€“1144.doi:\n10.1145/2939672.2939778.\nRaghaw et al.: Preprint submitted to Elsevier Page 20 of 20"
}