{
  "title": "A Natural Language Processing Model for COVID-19 Detection Based on Dutch General Practice Electronic Health Records by Using Bidirectional Encoder Representations From Transformers: Development and Validation Study",
  "url": "https://openalex.org/W4387326738",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2996880591",
      "name": "Maarten Homburg",
      "affiliations": [
        "University Medical Center Groningen"
      ]
    },
    {
      "id": "https://openalex.org/A2711788013",
      "name": "Eline Meijer",
      "affiliations": [
        "University Medical Center Groningen"
      ]
    },
    {
      "id": "https://openalex.org/A2809197388",
      "name": "Matthijs Berends",
      "affiliations": [
        "University Medical Center Groningen",
        "Certe"
      ]
    },
    {
      "id": "https://openalex.org/A5092999222",
      "name": "Thijmen Kupers",
      "affiliations": [
        "University Medical Center Groningen"
      ]
    },
    {
      "id": "https://openalex.org/A4202110434",
      "name": "Tim Olde Hartman",
      "affiliations": [
        "Radboud University Medical Center",
        "Radboud University Nijmegen"
      ]
    },
    {
      "id": "https://openalex.org/A4201642348",
      "name": "Jean Muris",
      "affiliations": [
        "Maastricht University"
      ]
    },
    {
      "id": "https://openalex.org/A2628003255",
      "name": "Evelien de Schepper",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2642185539",
      "name": "Premysl Velek",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2775483115",
      "name": "Jeroen Kuiper",
      "affiliations": [
        "Dialyse Centrum Groningen"
      ]
    },
    {
      "id": "https://openalex.org/A2590630914",
      "name": "Marjolein Berger",
      "affiliations": [
        "University Medical Center Groningen"
      ]
    },
    {
      "id": "https://openalex.org/A2147566763",
      "name": "Lilian Peters",
      "affiliations": [
        "University Medical Center Groningen",
        "Vrije Universiteit Amsterdam"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2895763047",
    "https://openalex.org/W2664267452",
    "https://openalex.org/W3009785512",
    "https://openalex.org/W2169818249",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3083883615",
    "https://openalex.org/W2996580882",
    "https://openalex.org/W4225372987",
    "https://openalex.org/W4312220150",
    "https://openalex.org/W4289596936",
    "https://openalex.org/W4310464163",
    "https://openalex.org/W4309004304",
    "https://openalex.org/W4288421367",
    "https://openalex.org/W3038174280",
    "https://openalex.org/W4312113143"
  ],
  "abstract": "Background Natural language processing (NLP) models such as bidirectional encoder representations from transformers (BERT) hold promise in revolutionizing disease identification from electronic health records (EHRs) by potentially enhancing efficiency and accuracy. However, their practical application in practice settings demands a comprehensive and multidisciplinary approach to development and validation. The COVID-19 pandemic highlighted challenges in disease identification due to limited testing availability and challenges in handling unstructured data. In the Netherlands, where general practitioners (GPs) serve as the first point of contact for health care, EHRs generated by these primary care providers contain a wealth of potentially valuable information. Nonetheless, the unstructured nature of free-text entries in EHRs poses challenges in identifying trends, detecting disease outbreaks, or accurately pinpointing COVID-19 cases. Objective This study aims to develop and validate a BERT model for detecting COVID-19 consultations in general practice EHRs in the Netherlands. Methods The BERT model was initially pretrained on Dutch language data and fine-tuned using a comprehensive EHR data set comprising confirmed COVID-19 GP consultations and non–COVID-19–related consultations. The data set was partitioned into a training and development set, and the model’s performance was evaluated on an independent test set that served as the primary measure of its effectiveness in COVID-19 detection. To validate the final model, its performance was assessed through 3 approaches. First, external validation was applied on an EHR data set from a different geographic region in the Netherlands. Second, validation was conducted using results of polymerase chain reaction (PCR) test data obtained from municipal health services. Lastly, correlation between predicted outcomes and COVID-19–related hospitalizations in the Netherlands was assessed, encompassing the period around the outbreak of the pandemic in the Netherlands, that is, the period before widespread testing. Results The model development used 300,359 GP consultations. We developed a highly accurate model for COVID-19 consultations (accuracy 0.97, F1-score 0.90, precision 0.85, recall 0.85, specificity 0.99). External validations showed comparable high performance. Validation on PCR test data showed high recall but low precision and specificity. Validation using hospital data showed significant correlation between COVID-19 predictions of the model and COVID-19–related hospitalizations (F1-score 96.8; P&lt;.001; R2=0.69). Most importantly, the model was able to predict COVID-19 cases weeks before the first confirmed case in the Netherlands. Conclusions The developed BERT model was able to accurately identify COVID-19 cases among GP consultations even preceding confirmed cases. The validated efficacy of our BERT model highlights the potential of NLP models to identify disease outbreaks early, exemplifying the power of multidisciplinary efforts in harnessing technology for disease identification. Moreover, the implications of this study extend beyond COVID-19 and offer a blueprint for the early recognition of various illnesses, revealing that such models could revolutionize disease surveillance.",
  "full_text": "Original Paper\nA Natural Language Processing Model for COVID-19 Detection\nBased on Dutch General Practice Electronic Health Records by\nUsing Bidirectional Encoder Representations From Transformers:\nDevelopment and Validation Study\nMaarten Homburg1, MSc, MD; Eline Meijer1,2, MSc; Matthijs Berends1,3,4, PhD; Thijmen Kupers1,2, MSc; Tim Olde\nHartman5, MD, PhD; Jean Muris6, MD, Prof Dr; Evelien de Schepper7, MD, PhD; Premysl Velek7, MSc; Jeroen\nKuiper8, MSc; Marjolein Berger1, MD, Prof Dr; Lilian Peters1,2,9, PhD\n1Department of Primary- and Long-Term Care, University Medical Center Groningen, Groningen, Netherlands\n2Data Science Center in Health, University Medical Center Groningen, Groningen, Netherlands\n3Department of Medical Microbiology and Infection Prevention, University Medical Center Groningen, Groningen, Netherlands\n4Department of Medical Epidemiology, Certe Foundation, Groningen, Netherlands\n5Department of Primary and Community Care, Radboud University Nijmegen Medical Center, Nijmegen, Netherlands\n6Care and Public Health Research Institute, Department of Family Medicine, Maastricht University Medical Center, Maastricht, Netherlands\n7Department of General Practice, Erasmus Medical Center, Rotterdam, Netherlands\n8Municipal Health Service Groningen, Groningen, Netherlands\n9Midwifery Science, Amsterdam Public Health, Vrije Universiteit Amsterdam, Amsterdam University Medical Center, Amsterdam, Netherlands\nCorresponding Author:\nMaarten Homburg, MSc, MD\nDepartment of Primary- and Long-Term Care\nUniversity Medical Center Groningen\nHome Post Code FA21\nPO Box 196\nGroningen, 9700 RB\nNetherlands\nPhone: 31 050 3616161\nEmail: t.m.homburg@umcg.nl\nAbstract\nBackground: Natural language processing (NLP) models such as bidirectional encoder representations from transformers\n(BERT) hold promise in revolutionizing disease identification from electronic health records (EHRs) by potentially enhancing\nefficiency and accuracy. However, their practical application in practice settings demands a comprehensive and multidisciplinary\napproach to development and validation. The COVID-19 pandemic highlighted challenges in disease identification due to limited\ntesting availability and challenges in handling unstructured data. In the Netherlands, where general practitioners (GPs) serve as\nthe first point of contact for health care, EHRs generated by these primary care providers contain a wealth of potentially valuable\ninformation. Nonetheless, the unstructured nature of free-text entries in EHRs poses challenges in identifying trends, detecting\ndisease outbreaks, or accurately pinpointing COVID-19 cases.\nObjective: This study aims to develop and validate a BERT model for detecting COVID-19 consultations in general practice\nEHRs in the Netherlands.\nMethods: The BERT model was initially pretrained on Dutch language data and fine-tuned using a comprehensive EHR data\nset comprising confirmed COVID-19 GP consultations and non–COVID-19–related consultations. The data set was partitioned\ninto a training and development set, and the model’s performance was evaluated on an independent test set that served as the\nprimary measure of its effectiveness in COVID-19 detection. To validate the final model, its performance was assessed through\n3 approaches. First, external validation was applied on an EHR data set from a different geographic region in the Netherlands.\nSecond, validation was conducted using results of polymerase chain reaction (PCR) test data obtained from municipal health\nJ Med Internet Res 2023 | vol. 25 | e49944 | p. 1https://www.jmir.org/2023/1/e49944\n(page number not for citation purposes)\nHomburg et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nservices. Lastly, correlation between predicted outcomes and COVID-19–related hospitalizations in the Netherlands was assessed,\nencompassing the period around the outbreak of the pandemic in the Netherlands, that is, the period before widespread testing.\nResults: The model development used 300,359 GP consultations. We developed a highly accurate model for COVID-19\nconsultations (accuracy 0.97, F1-score 0.90, precision 0.85, recall 0.85, specificity 0.99). External validations showed comparable\nhigh performance. Validation on PCR test data showed high recall but low precision and specificity. Validation using hospital\ndata showed significant correlation between COVID-19 predictions of the model and COVID-19–related hospitalizations (F1-score\n96.8; P<.001; R2=0.69). Most importantly, the model was able to predict COVID-19 cases weeks before the first confirmed case\nin the Netherlands.\nConclusions: The developed BERT model was able to accurately identify COVID-19 cases among GP consultations even\npreceding confirmed cases. The validated efficacy of our BERT model highlights the potential of NLP models to identify disease\noutbreaks early, exemplifying the power of multidisciplinary efforts in harnessing technology for disease identification. Moreover,\nthe implications of this study extend beyond COVID-19 and offer a blueprint for the early recognition of various illnesses,\nrevealing that such models could revolutionize disease surveillance.\n(J Med Internet Res 2023;25:e49944) doi: 10.2196/49944\nKEYWORDS\nnatural language processing; primary care; COVID-19; EHR; electronic health records; public health; multidisciplinary; NLP;\ndisease identification; BERT model; model development; prediction\nIntroduction\nHealth care has been transformed by artificial intelligence (AI),\nleading to remarkable breakthroughs in diagnosis and treatment\n[1-3]. Among the most commonly used methods is natural\nlanguage processing (NLP), a form of AI that focuses on\nunderstanding and interpreting human language. NLP can extract\nmeaningful information from unstructured data such as free-text\nfields by recognizing patterns and relationships between words\nin a sentence [4]. One such NLP technique is the bidirectional\nencoder representations from transformers (BERT) model, which\ncan be fine-tuned with an additional output layer for a specific\ntask [5]. For instance, a BERT model can be adjusted for disease\nidentification in electronic health records (EHRs), allowing it\nto analyze and interpret large amounts of data to identify patterns\nindicative of a particular disease.\nGeneral practitioners (GPs) serve as gatekeepers to specialist\ncare in the Dutch health care system, making them the first point\nof contact for most patients and giving them a key role in\nrecording patient health information in EHRs. This includes\nlinking an International Classification of Primary Care (ICPC)\ncode to each entry [6]. However, the absence of a specific ICPC\ncode for COVID-19 and the limited availability of suitable\ntesting at the outbreak of the COVID-19 pandemic highlighted\nthe difficulty in identifying relevant patient consultations in GP\nEHRs [7-9]. Extracting meaningful information from medical\nfree-text fields has also proven difficult [4]. Nevertheless,\naccurate health surveillance requires the identification of\nCOVID-19 consultations not only during the acute phase of the\npandemic but also in retrospect (eg, to evaluate post-COVID\ntrajectories). The use of NLP in health care has the potential to\nrevolutionize disease identification, but significant challenges\nneed to be overcome before this potential can be realized. A\nkey challenge is ensuring that NLP models are robust, reliable,\nand safe for use in medical practice. This requires a rigorous\napproach to model development and validation.\nFor this study, we found BERT to employ the most advanced\nNLP technique available to analyze GP registration texts and\npredict COVID-19 cases. BERT’s key superiority lies in its\nability to capture contextual information from both preceding\nand succeeding words, enabling a deeper understanding of\ncomplex medical language and context. To the best of our\nknowledge, this has not been done on Dutch GP registration\ntexts until now. Additionally, and more technically, BERT’s\npretrained architecture on extensive corpora ensures superior\nfeature extraction and generalization, empowering our model\nto detect subtle nuances in GP texts and predict COVID-19\ncases with potentially very high precision. BERT models in\nmedical literature have been shown to improve performance in\ncommon clinical NLP tasks such as named entity recognition\nand medical natural language inference [10]. By leveraging the\ncapabilities of BERT over traditional NLP methods, our study\naims to significantly advance the field of medical informatics\nand contribute to more effective disease surveillance and\nmanagement strategies.\nWe aimed to develop a BERT model that could accurately\nidentify COVID-19 GP consultations from unstructured text in\nthe EHRs of Dutch general practice, thereby validating the\ngeneralizability and applicability of this approach in different\nsettings. This innovative approach addresses the urgent need to\nidentify COVID-19 consultations accurately from unstructured\ntext in general practice EHRs. We anticipate that the\ncomprehensive methodology described in this study will lay\nthe groundwork for the development of reliable and robust NLP\nmodels, which in turn, could revolutionize disease identification\nin general practice and improve patient outcomes.\nMethods\nData Source and Study Population\nThe required data were extracted from the EHRs of general\npractices participating in research networks managed by 3\nuniversity medical centers in the Netherlands. These databases\ncontain routinely collected data from longitudinal EHRs. The\nJ Med Internet Res 2023 | vol. 25 | e49944 | p. 2https://www.jmir.org/2023/1/e49944\n(page number not for citation purposes)\nHomburg et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nnetworks were the Academic GP Development Network\n(Academisch Huisartsen Ontwikkel Netwerk [AHON]) managed\nby the University Medical Center Groningen, which includes\n59 practices in the north of the Netherlands; the Family\nMedicine Network managed by Radboud University Medical\nCenter Nijmegen, which includes 6 practices in the east; and\nthe Research Network Family Medicine managed by Maastricht\nUniversity Medical Center, which includes 28 practices in the\nsouth. The EHRs covered a period from January 1, 2019, to\nDecember 31, 2021. A GP consultation was defined as any\nconsultation between a patient and either a GP or a practice\nnurse, which had at least one ICPC code and a corresponding\nfree-text note recorded in the EHR. All Dutch GPs use the\ncountry-specific ICPC-1 managed by the Dutch College of GPs\n[11]. To define the study database, we manually assessed\nexisting ICPC-1 codes to develop a list of all codes that could\nbe related to acute COVID-19 infection. This list was created\nby a GP (MH) and a microbiologist (M Berends), and all GP\nconsultations linked to at least one of these codes were extracted\n(Multimedia Appendix 1).\nEthical Considerations\nData from the registry databases were pseudonymized such that\nthe researchers could not access individual patient details. The\nmedical research ethics committee of the University Medical\nCenter Groningen determined that this research did not require\nethics approval, according to Dutch law (Medical Research\nInvolving Human Subjects Act 2020/309).\nBERT Model Development and Testing\nA BERT model was developed to classify GP consultations as\nCOVID-19 or non–COVID-19 by using an open source,\npretrained, Dutch BERT model [12]. This neural network model\ncould effectively interpret the contextual relationships between\nwords in a sentence if written in Dutch [12]. The pretrained\nmodel was fine-tuned for the classification task by adding neural\nnetwork layers before training the whole model to perform the\nspecific task of identifying COVID-19 GP consultations. This\napproach leveraged the language understanding capabilities of\nthe base model, while tailoring it to the specific task of\nclassifying GP consultations. Details regarding the development\nand performance of our model can be found in Multimedia\nAppendix 2. A stepwise approach was followed to fine-tune the\nBERT model. We divided the data set into 3 parts, using 60%\nfor the training set, 20% for the development set, and 20% for\nthe test set (Figure 1).\nJ Med Internet Res 2023 | vol. 25 | e49944 | p. 3https://www.jmir.org/2023/1/e49944\n(page number not for citation purposes)\nHomburg et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nFigure 1. Flowchart for the composition of the database and composition of the bidirectional encoder representations from transformers model. BERT:\nbidirectional encoder representations from transformers; EHR: electronic health record; ICPC: International Classification of Primary Care.\n1. Training set: Supervised learning uses a labeled data set to\ntrain the model. We labeled all GP consultations included\nfrom 2019 but before the outbreak of the pandemic as\nconclusively negative COVID-19 GP consultations (label\n0) and consultations labeled with ICPC code R83.03\n(confirmed SARS-CoV-2) as conclusively positive\nCOVID-19 GP consultations (label 1). The\nCOVID-19–specific ICPC code R83.03, introduced in the\nNetherlands in November 2020, came with the instruction\nthat all GPs should use the code for confirmed COVID-19\nconsultations [7]. During the training step, the BERT model\ndid not have access to corresponding ICPC codes to ensure\nthat it only had access to the EHR text and could not use\nthe ICPC codes to differentiate between\nCOVID-19–positive and COVID-19–negative consultations.\n2. Development set: Model performance was evaluated using\nthe development set. Two independent researchers (MH\nand M Berends) labeled 350 GP consultations as related or\nnot related to COVID-19 before comparing their results\nwith the same consultations used in the BERT model. The\nfinal model was chosen based on a sigmoid plot and relevant\nmetrics (ie, accuracy, F1-score, precision, recall, and\nspecificity).\n3. Test set: To assess the accuracy of the final BERT model,\nits performance was evaluated on new data (the test set).\nJ Med Internet Res 2023 | vol. 25 | e49944 | p. 4https://www.jmir.org/2023/1/e49944\n(page number not for citation purposes)\nHomburg et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nEvaluation of Generalizability and Applicability\nFollowing the development and testing of the fine-tuned BERT\nmodel, its performance was validated with 3 different methods\nthat assessed its generalizability in practical applications. Each\nvalidation method offered different insights into the model’s\nability to classify COVID-19–related GP consultations\naccurately and consistently across data sets.\nExternal Validation\nThe generalizability of the final BERT model to a different\ngeographic region with a similar health care system was assessed\nthrough an EHR data set with the same structure as the training\ndata. We relied on data from the Rijnmond Primary Care\ndatabase, managed by the Department of General Practice of\nthe Erasmus Medical Center, University Medical Centre\nRotterdam, which covered the west of the Netherlands. The\nRijnmond Primary Care database included GP consultations\nfrom 2019 with potential COVID-19–related ICPC codes\n(negative COVID status) and GP consultations with ICPC code\nR83.03 (positive COVID status).\nValidation Using Polymerase Chain Reaction Tests\nIn this validation step, the performance of the BERT model was\nassessed using GP consultations from before the introduction\nof the specific ICPC code for COVID-19. We used data from\nthe municipal health services and linked these to the AHON\ndatabase to include patients who underwent polymerase chain\nreaction (PCR) testing for COVID-19 around the time of a GP\nconsultation with a potential COVID-19–related ICPC code (7\ndays before to 7 days after the date of testing). GP consultations\nwith a positive PCR test result during this 2-week window were\nlabeled as related to COVID-19, while GP consultations with\na negative PCR test were labeled as not related to COVID-19.\nFor patients who underwent multiple testing and had both\npositive and negative PCR test results within the defined 2-week\nwindow, we considered them COVID-positive and having\nsymptoms related to COVID-19.\nValidation Before the Introduction of a\nCOVID-19–Specific ICPC Code\nTo evaluate the model’s ability to identify COVID-19\nconsultations in the data from before the introduction of a\nCOVID-19–specific ICPC code, its predictions were compared\nwith data for COVID-19 hospital admissions in the Netherlands\nduring the first year of the pandemic based on open data from\nthe National Institute for Public Health and the Environment\n[13]. This step improved our understanding of the model’s utility\nin medical settings.\nStatistical Analysis\nThis study’s primary outcome was the performance of the BERT\nmodel in identifying health care consultations related to\nCOVID-19 in the test set, evaluated using performance metrics\nand sigmoid plots. External validation and PCR test validation\nwere assessed using descriptive statistics, performance metrics,\nand sigmoid plots, while the comparison with\nCOVID-19–related hospital admissions in 2020 was done by\nlinear regression modeling. For the linear regression, we set the\ndependent variable as the weekly number of hospital admissions\nfor COVID-19 in 2020 and the independent variable as the\npredicted COVID-19 consultations generated by the BERT\nmodel, using a significance level of P<.05. Sigmoid plots and\nperformance metrics were analyzed using Python software, and\nadditional analyses were conducted using R software (version\n4.1.1; R Foundation for Statistical Computing) [14].\nResults\nData Source and Study Population\nThis study included 300,359 GP consultations extracted based\non ICPC codes potentially related to COVID-19 or ICPC code\nR83.03 for confirmed SARS-CoV-2 (COVID-19). Among these,\n251,362 consultations (83.7%) from 2019 had at least one ICPC\ncode potentially related to COVID-19, while 48,997 (16.3%)\nhad the ICPC code R83.03. The AHON database provided\n191,508 consultations (63.8%) of 184,700 patients, the Family\nMedicine Network database provided 29,409 consultations\n(9.8%) of 31,351 patients, and the Research Network Family\nMedicine database provided 79,442 consultations (26.4%) of\n87,499 patients. Additional population characteristics can be\nfound in Multimedia Appendix 3.\nTesting the Developed BERT Model\nThe database was partitioned into 3 sets. The training set\ncomprised 180,215 consultations, of which 150,706 were not\nCOVID-19–related (label 0) and 29,509 were\nCOVID-19–related (label 1). The development and test sets\neach comprised 60,072 consultations: the development set\nincluded 50,279 non–COVID-19 consultations and 9793\nCOVID-19 consultations, while the test set included 50,377\nnon–COVID-19 consultations and 9695 COVID-19\nconsultations. The distribution of non–COVID-19 to COVID-19\nconsultations for all 3 sets was approximately 86:14. The model\nwas applied to the test set after training and development. Table\n1 shows the performance metrics of the developed BERT model.\nIt achieved an overall F1-score of 0.91, precision of 0.98, and\nrecall of 0.85, with consistent performance across both labels.\nFigure 2A shows the sigmoid plots for labels 0 and 1. The curve\nfor label 0 was slightly more distinct than that for label 1,\nindicating that the model performed slightly better at predicting\nlabel 0.\nJ Med Internet Res 2023 | vol. 25 | e49944 | p. 5https://www.jmir.org/2023/1/e49944\n(page number not for citation purposes)\nHomburg et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nFigure 2. Sigmoid plots of the distribution of predictions for non–COVID-19 consultations (label 0) and COVID-19 consultations (label 1) developed\nas bidirectional encoder representations from transformers model on the test set (A), external validation set (B), and polymerase chain reaction validation\nset (C). PCR: polymerase chain reaction.\nJ Med Internet Res 2023 | vol. 25 | e49944 | p. 6https://www.jmir.org/2023/1/e49944\n(page number not for citation purposes)\nHomburg et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nTable 1. Performance metrics of the bidirectional encoder representations from transformers model on the test, external validation, and polymerase\nchain reaction validation sets.\nPolymerase chain reaction validationExternal validationTest set\n0.4610.9380.972Accuracy\n0.6070.8860.920Balanced accuracy\n0.3520.8700.907F1-score\n0.2230.9900.98Precision\n0.8330.7760.845Recall/sensitivity\n0.3810.9970.997Specificity\nExternal Validation\nThe model was applied to comparable data from the Rijnmond\nPrimary Care database to assess performance on a new data set\ncomprising 234,231 consultations: 171,603 from 2019 with\nICPC codes potentially related to COVID-19 and 62,628 linked\nwith ICPC code R83.03. Table 1 describes the performance of\nthe BERT model on this data set. The model achieved an overall\nF1-score of 0.91, precision of 0.98, and recall of 0.85. Figure\n2B shows the sigmoid plots for label 0 and 1. These plots were\ngenerated using a random sample of 60,000 consultations,\nmaintaining a label 0 to label 1 ratio of 86:14. This ratio is\ncomparable to the distribution observed in the test set, ensuring\nrepresentativeness.\nValidation Using PCR Tests\nThe AHON database, linked with municipal health service\ntesting data, provided the data set for PCR test validation. Out\nof 8987 consultations, 7408 were labeled COVID-19–negative\n(consultation + negative PCR test within the defined 2-week\nperiod) and 1579 were labeled COVID-19–positive (consultation\n+ positive PCR findings within the defined 2-week period). The\nBERT model achieved an F1-score of 0.35, precision of 0.22,\nand recall of 0.83 (Table 1). Figure 2C shows the sigmoid curves\nfor labels 0 and 1. There are relatively smooth curves and\nexpected sigmoid shapes for label 1 predictions, suggesting that\nthe model performed well in identifying COVID-19\nconsultations. However, there is an increase in the density of\npredictions toward the upper end of the curve for label 0,\nsuggesting an overconfident model that makes false-positive\npredictions.\nValidation Before the Specific ICPC Code for\nCOVID-19\nThe BERT model’s ability to identify COVID-19 consultations\nduring the early stages of the pandemic was evaluated by\ncomparing its predictions for GP consultations in 2020 that had\nICPC codes possibly related to COVID-19 and for national\nhospitalization data for COVID-19 admissions. This data set\ncomprised 244,068 consultations. Figure 3 displays the relative\nnumber of positive predictions by the BERT model compared\nto the total number of consultations as well as the national\nhospitalization data for COVID-19 per week. This shows a\nhigher percentage of predicted positive labels that corresponded\nwith an increase in COVID-19 hospitalizations and a lower\npercentage of predictions associated with a decrease in\nhospitalizations. Unlike other ICPC codes potentially related\nto COVID-19, which showed a high frequency from January\nwhen there were no confirmed COVID-19 cases, the model’s\nCOVID-19 predictions remained close to zero until weeks before\nthe first confirmed case in the Netherlands (week 9) and then\ngradually increased over time [13]. To assess this correlation\nfurther, we performed a linear regression analysis (Figure 4).\nThis generated a correlation coefficient (r) of 0.83, indicating\na strong positive correlation between the variables. The\nreproduction script for the statistical model can be found in\nMultimedia Appendix 4.\nJ Med Internet Res 2023 | vol. 25 | e49944 | p. 7https://www.jmir.org/2023/1/e49944\n(page number not for citation purposes)\nHomburg et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nFigure 3. Predicted COVID-19 consultations displayed as relative to all included consultations in 2020. COVID-19–related hospital admissions are\ndisplayed in red. GP: general practitioner; ICPC: International Classification of Primary Care.\nFigure 4. Scatterplot showing the relationship between predicted COVID-19 consultations by developed bidirectional encoder representations from\ntransformers model and hospital admissions related to COVID-19 in the Netherlands. This plot shows the linear regression line (red) and the 95% CI\n(gray-shaded area). Each dot represents a weekly observation. BERT: bidirectional encoder representations from transformers; GP: general practitioner.\nThe F1-score for overall significance of the model was 96.8 (1\nand 43 degrees of freedom), with a P value of 1.411e-12,\nsuggesting a statistically significant relationship between\npredicted COVID-19 consultations and COVID-19–related\nhospital admissions. The R2 value of 0.69 provides robust\nevidence of the model’s predictive power, indicating that 69%\nJ Med Internet Res 2023 | vol. 25 | e49944 | p. 8https://www.jmir.org/2023/1/e49944\n(page number not for citation purposes)\nHomburg et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nof the variance in hospital admissions can be explained by the\nlinear relationship with the predicted cases.\nDiscussion\nMain Findings\nThis study shows that a highly accurate BERT model can be\ndeveloped to identify COVID-19–related GP consultations from\nEHR data in the Netherlands. The high performance metrics\nwith the test set suggest the potential of such NLP methods to\nidentify COVID-19 consultations accurately in general practice\nsettings. Employing multiple validation methods further helped\nto describe the reliability and utility of the model in different\n(medical) settings.\nFirst, external validation with a separate data set confirmed the\nhigh accuracy of the model and indicated that it is both\ngeneralizable and effective across different geographic regions\nwith comparable EHR data. In the future, additional features\ncould be incorporated to improve the model’s performance.\nThis might include information about the region or the specific\nEHR system.\nSecond, the model was validated with PCR test results from\nbefore the introduction of a specific ICPC code for COVID-19,\nand this showed good recall but poor specificity and precision.\nThis strengthens the findings because the model correctly\nidentified true positives in this period. Moreover, the low\nprecision and specificity can be attributed to the model’s\ninability to differentiate between negative and absent test results\nfor COVID-19. Since the model was trained on confirmed\nCOVID-19 cases using the ICPC code, cases with mentioned\nnegative test results were new for the model and led to false\npositives.\nThird, the model was applied to data from before the\nintroduction of either nationwide testing or the specific ICPC\ncode for COVID-19. This revealed a highly significant\ncorrelation between the model’s predicted values and true\nhospital admissions for COVID-19 in the Netherlands in 2020,\nwith the number of predicted COVID-19 consultations starting\nto rise from week 6. Linear regression (Figure 4) confirmed that\nthat our BERT model could significantly predict hospital\nadmissions with a good fit, making it capable of early disease\nidentification. The first confirmed diagnosis and hospitalization\noccurred in week 9 in the Netherlands [13]. Given that most\npatients do not require hospitalization and that hospitalization\nusually occurs a week after developing symptoms [15], the first\npatients to present with COVID-19 in general practice likely\nconsulted their GP several weeks before the first confirmed case\nof COVID-19. The ability of the model to identify potential\nCOVID-19 cases before the confirmed outbreak shows its\npotential for detecting infectious disease early. By analyzing\nthe data in the weeks leading to the first confirmed case and\nhospitalization, the model could be developed to identify early\nindicators of disease and improve early detection and the\nresponse to future pandemics.\nComparison With Previous Studies\nRecent literature shows an increased use and interest in NLP\nfor the analysis of EHRs [16]. Concerning the COVID-19\npandemic, several studies have highlighted the potential of NLP\nmethods to detect and characterize cases from EHR data [17-20].\nA large review focusing on the predictive value of COVID-19\nsymptoms showed that both the absence and presence of specific\nsymptoms could accurately determine COVID-19 status [21].\nNLP models can recognize unknown patterns in data, which\ncould potentially lead to more accurate and efficient disease\nidentification than conventional methods [4]. However, only\nscarce data exist regarding the development and especially the\nvalidation of NLP models in different GP care settings. This\nstudy adds to the growing body of evidence showing the\npotential utility of NLP methods in health care, particularly in\nthe context of pandemic preparedness and response.\nPrevious research has shown that the medical use of NLP faces\nvarious barriers, including limited access to medical data,\ncomputational resources, and labeled data, together with\ndifficulties in sharing pretrained models [22]. This study\novercomes these barriers by showing the high performance of\na fine-tuned, open-source, pretrained language model, with\nvalidation in comparable but different regions and time periods.\nOur findings suggest that the developed NLP models have the\npotential for broader application, which could reduce the need\nfor additional training, computational resources, and labeling.\nImplications for Medical Settings\nThe results of this study suggest that automated disease\nidentification through NLP methods can greatly improve the\nefficiency and accuracy of disease identification during a\npandemic. These methods also have the potential to improve\ndisease identification during regular consultations, potentially\nreducing treatment delays and improving outbreak prediction.\nThe external validation has effectively demonstrated our model’s\nrobustness and readiness for application in GP registry databases\nwith comparable data structures. This indicates that the model\nhas the ability to identify patients with suspected COVID-19\nbased on either symptoms or other findings in retrospective\nanalyses. Nonetheless, the translation and implementation of\nthis into GP electronic health registry systems for direct clinical\nfeedback are yet to be explored. Further development of NLP\nmodels for disease identification could lead to its use for\nchecking symptoms and conditions in text fields and enabling\nprompt action. A validated model could eventually be used to\nidentify COVID-19 cases that may have been missed in the\nearly stages of the pandemic when no specific tests or ICPC\ncodes existed. This has relevance because these patients may\nstill experience negative post-COVID outcomes, and the model\ncould give insights into their expected disease trajectories.\nThe development and validation of our BERT model also\nhighlights the potential of NLP methods to improve disease\nidentification and management in general practice. NLP methods\ncould facilitate more efficient and accurate diagnosis and\ntreatment for a wide range of diseases by enabling rapid and\nautomated analysis of large volumes of EHR data. The results\nof this study also support the feasibility and effectiveness of\ndeveloping our BERT model to identify other diseases and\nconditions in general practice.\nJ Med Internet Res 2023 | vol. 25 | e49944 | p. 9https://www.jmir.org/2023/1/e49944\n(page number not for citation purposes)\nHomburg et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nLimitations\nThe developed model was trained and tested using data from\ngeneral practice EHRs in the Netherlands, which may limit its\ngeneralizability and necessitate further training and validation\nbefore its application in other languages and health care systems.\nUsing the COVID-19 ICPC codes may also have affected the\nmodel’s performance due to their limited sensitivity and\nspecificity for identifying COVID-19 consultations. This may\nhave resulted in missed or misclassified consultations and\npotential biases in the training and validation data. Additionally,\ndifferences in disease prevalence among regions or populations\ncould affect the model’s sensitivity and specificity. Despite\nusing multiple validation methods to address this issue, further\nstudies are still needed to evaluate the utility of the model in\nreal-world (medical) settings.\nConclusions\nThe developed BERT model was able to accurately identify\nCOVID-19 cases among GP consultations even preceding\nconfirmed cases. This study demonstrates the potential of NLP\nmethods to revolutionize disease identification in general\npractice, highlight their potential to identify disease outbreaks\nearly, and improve public health outcomes. The full implications\nmay extend beyond COVID-19 to pave the way for NLP models\nthat can aid in the early identification of other diseases in general\npractice.\nWe showed the power of multidisciplinary efforts in harnessing\ntechnology for disease identification. Model development and\nvalidation should adopt a transparent and explainable approach\nthat includes stakeholder involvement (including clinicians and\nother end users). This will not only ensure the model’s relevance\nand usability in real-world settings but also help ensure the\ndevelopment and validation of AI models in a manner that\nmaximizes their impact on public health and outbreak\nmanagement. This study therefore offers a blueprint for the\nearly recognition of various illnesses, revealing that such models\ncould revolutionize (infectious) disease surveillance. Continued\nresearch and innovation in the field of NLP, especially in the\ncontext of pandemic preparedness, may prove crucial for the\nfuture of health care. Our findings underscore the argument for\nfurther exploration and implementation of NLP methods to\nimprove disease detection and management in primary care.\nAcknowledgments\nThis research was conducted using the central databases of Academisch Huisartsen Ontwikkel Netwerk, Family Medicine Network,\nResearch Network Family Medicine, and Rijnmond. We are grateful for the support provided by Feikje Groenhof and Ronald\nWilmink (Academisch Huisartsen Ontwikkel Netwerk), Jose Donkers and Hans Peters (Family Medicine Network), Donovan\nde Jonge (Research Network Family Medicine), and Angeline Bosman (Rijnmond Central) in these networks. We also want to\nthank Robin Twickler and Karina Sulim, data scientists from the University Medical Center Groningen, who are affiliated with\nthe Department of General Practice and Elderly Care Medicine and Data Science in Health Care. Finally, we thank Dr Roberts\nSykes at Doctored Ltd for providing English language editing of the final drafts of this manuscript. The Netherlands Organization\nfor Health Research and Development (ZonMW) funded this study: “Changes in the Use and Organization of Care in General\nPractices and Out-of-hours Services: Lessons Learned from the COVID-19 Pandemic” (10430022010006) and the “General\nPractice Research Infrastructure Pandemic Preparedness Program” (GRIP3) (10430112110001). The funder played no role in\nthe study design, data collection, data analysis and interpretation, or writing of this manuscript.\nData Availability\nAccess to the data used to train the bidirectional encoder representations from transformers model in this study can be facilitated\nafter obtaining approval from the steering committees of the involved general practitioner networks. The data set employed in\nour research consists of registration texts from general practitioners, detailing sensitive and confidential information about patients’\nhealth. However, it is important to note that the data set is not freely available; permission must be sought, along with the potential\nassociated fees, before access is granted. These arrangements are in place to ensure proper data usage. For more information\nabout the data set’s specifics as used in this study, inquiries can be directed to the corresponding author.\nAuthors' Contributions\nAll authors made substantial contributions to this study by providing important intellectual content and writing the manuscript.\nThey all approve the final version for submission and agree to be accountable for all aspects of this work. They also ensure that\nany questions regarding accuracy or integrity are addressed and resolved appropriately. MH contributed to conceptualization,\nmethodology, validation, investigation, and visualization writing. EM contributed to methodology, validation, formal analysis,\ninvestigation, data curation, and writing. M Berends contributed to conceptualization, methodology, and writing. TK contributed\nto methodology, validation, investigation, data curation, visualization, and writing. TOH contributed to data curation, resources,\nwriting, and funding acquisition. JM contributed to data curation, resource allocation, writing, and funding acquisition. EdS\ncontributed to data curation, resources, writing, and funding acquisition. PV contributed to investigation and writing. JK contributed\nto data curation and writing. M Berger contributed to conceptualization, methodology, resources, writing, supervision, and funding\nacquisition. LP contributed to conceptualization, methodology, resources, writing, supervision, project administration, and funding\nacquisition.\nJ Med Internet Res 2023 | vol. 25 | e49944 | p. 10https://www.jmir.org/2023/1/e49944\n(page number not for citation purposes)\nHomburg et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nConflicts of Interest\nNone declared.\nMultimedia Appendix 1\nPotential acute COVID-19–related International Classification of Primary Care-1 codes.\n[PDF File (Adobe PDF File), 47 KB-Multimedia Appendix 1]\nMultimedia Appendix 2\nModel card.\n[PDF File (Adobe PDF File), 81 KB-Multimedia Appendix 2]\nMultimedia Appendix 3\nCharacteristics of the included population from the 3 academic general practitioner networks.\n[PDF File (Adobe PDF File), 48 KB-Multimedia Appendix 3]\nMultimedia Appendix 4\nReproduction script of the statistical model.\n[PDF File (Adobe PDF File), 51 KB-Multimedia Appendix 4]\nReferences\n1. Yu K, Beam A, Kohane I. Artificial intelligence in healthcare. Nat Biomed Eng 2018 Oct;2(10):719-731 [doi:\n10.1038/s41551-018-0305-z] [Medline: 31015651]\n2. Jiang F, Jiang Y, Zhi H, Dong Y, Li H, Ma S, et al. Artificial intelligence in healthcare: past, present and future. Stroke\nVasc Neurol 2017 Dec;2(4):230-243 [FREE Full text] [doi: 10.1136/svn-2017-000101] [Medline: 29507784]\n3. Shimizu H, Nakayama K. Artificial intelligence in oncology. Cancer Sci 2020 May;111(5):1452-1460 [FREE Full text]\n[doi: 10.1111/cas.14377] [Medline: 32133724]\n4. Nadkarni P, Ohno-Machado L, Chapman W. Natural language processing: an introduction. J Am Med Inform Assoc\n2011;18(5):544-551 [FREE Full text] [doi: 10.1136/amiajnl-2011-000464] [Medline: 21846786]\n5. Devlin J, Chang M, Lee K, Toutanova K. BERT: Pre-training of deep bidirectional transformers for language understanding.\narXiv. Preprint posted online on October 11, 2018 [FREE Full text] [doi: 10.48550/arXiv.1810.04805]\n6. Duineveld BH, Kohle HM, van Werven H. Adequate dossiervorming met het elektronisch patiëntdossier (ADEPD).\nNederlands Huisarts Genootschap. 2019. URL: https://www.nhg.org/wp-content/uploads/2022/11/\nNHG-Richtlijn-ADEPD-2019.pdf [accessed 2023-05-01]\n7. NHG-Registratieadvies voor het medisch dossier COVID-19. Nederlands Huisarts Genootschap. URL: https://www.nhg.org/\ndocumenten/nhg-registratieadvies-voor-het-medisch-dossiercovid-19/ [accessed 2023-09-20]\n8. Juni 2020: Versoepeling coronamaatregelen en testen voor iedereen. Rijksoverheid Nederland. URL: https://tinyurl.com/\n4rue3p4a [accessed 2023-05-01]\n9. Huston P, Campbell J, Russell G, Goodyear-Smith F, Phillips RJ, van Weel C, et al. COVID-19 and primary care in six\ncountries. BJGP Open 2020 Sep 08;4(4):bjgpopen20X101128 [doi: 10.3399/bjgpopen20x101128]\n10. Alsentzer EJ, Murphy JR, Boag W, Weng WH, Jin D, Naumann T, et al. Publicly available clinical BERT embeddings.\nAclanthology. URL: https://aclanthology.org/W19-1909.pdf [accessed 2023-09-20]\n11. ICPC-Thesaurus 2022. Nederlands Huisartsen Genootschap. URL: https://referentiemodel.nhg.org/tabellen/1421/\npublieksversie/published [accessed 2023-05-09]\n12. de Vries W, Bisazza A, Caselli T, van Noord G, Nissim M. BERTje: A Dutch BERT Model. arXiv. Preprint posted online\non December 19, 2019 [FREE Full text] [doi: 10.48550/arXiv.1912.09582]\n13. Aantal positieve testen door de tijd heen. Rijksinstituut voor Volksgezondheid en Milieu (RIVM). URL: https:/\n/coronadashboard.rijksoverheid.nl/landelijk/positief-geteste-mensen [accessed 2023-05-01]\n14. Team R. R: A language and environment for statistical computing. R Foundation for Statistical Computing. URL: https:/\n/www.R-project.org/ [accessed 2023-05-01]\n15. Schäfer E, Scheer C, Saljé K, Fritz A, Kohlmann T, Hübner NO, et al. Course of disease and risk factors for hospitalization\nin outpatients with a SARS-CoV-2 infection. Sci Rep 2022 May 04;12(1):7249 [FREE Full text] [doi:\n10.1038/s41598-022-11103-0] [Medline: 35508524]\n16. Yang X, Chen A, PourNejatian N, Shin H, Smith K, Parisien C, et al. A large language model for electronic health records.\nNPJ Digit Med 2022 Dec 26;5(1):194 [FREE Full text] [doi: 10.1038/s41746-022-00742-2] [Medline: 36572766]\nJ Med Internet Res 2023 | vol. 25 | e49944 | p. 11https://www.jmir.org/2023/1/e49944\n(page number not for citation purposes)\nHomburg et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\n17. Shapiro M, Landau R, Shay S, Kaminsky M, Verhovsky G. Early detection of COVID-19 outbreaks using textual analysis\nof electronic medical records. J Clin Virol 2022 Oct;155:105251 [FREE Full text] [doi: 10.1016/j.jcv.2022.105251] [Medline:\n35973330]\n18. Malden D, Tartof S, Ackerson B, Hong V, Skarbinski J, Yau V, et al. Natural language processing for improved\ncharacterization of COVID-19 symptoms: Observational study of 350,000 patients in a large integrated health care system.\nJMIR Public Health Surveill 2022 Dec 30;8(12):e41529 [FREE Full text] [doi: 10.2196/41529] [Medline: 36446133]\n19. Al-Garadi M, Yang Y, Sarker A. The role of natural language processing during the COVID-19 pandemic: health applications,\nopportunities, and challenges. Healthcare (Basel) 2022 Nov 12;10(11):2270 [FREE Full text] [doi:\n10.3390/healthcare10112270] [Medline: 36421593]\n20. Zhu Y, Mahale A, Peters K, Mathew L, Giuste F, Anderson B. Using natural language processing on free-text clinical notes\nto identify patients with long-term COVID effects. 2022 Presented at: BCB '22: Proceedings of the 13th Association for\nComputing Machinery International Conference on Bioinformatics, Computational Biology and Health Informatics; August;\nNew York\n21. Struyf T, Deeks J, Dinnes J, Takwoingi Y, Davenport C, Leeflang M, Cochrane COVID-19 Diagnostic Test Accuracy\nGroup. Signs and symptoms to determine if a patient presenting in primary care or hospital outpatient settings has COVID-19\ndisease. Cochrane Database Syst Rev 2020 Jul 07;7(7):CD013665 [FREE Full text] [doi: 10.1002/14651858.CD013665]\n[Medline: 32633856]\n22. Wu H, Wang M, Wu J, Francis F, Chang Y, Shavick A, et al. A survey on clinical natural language processing in the United\nKingdom from 2007 to 2022. NPJ Digit Med 2022 Dec 21;5(1):186 [FREE Full text] [doi: 10.1038/s41746-022-00730-6]\n[Medline: 36544046]\nAbbreviations\nAHON: Academisch Huisartsen Ontwikkel Netwerk\nAI: artificial intelligence\nBERT: bidirectional encoder representations from transformers\nEHR: electronic health record\nGP: general practitioner\nICPC: International Classification of Primary Care\nNLP: natural language processing\nPCR: polymerase chain reaction\nEdited by A Mavragani; submitted 14.06.23; peer-reviewed by D Chrimes, I Mircheva; comments to author 27.07.23; revised version\nreceived 16.08.23; accepted 23.08.23; published 04.10.23\nPlease cite as:\nHomburg M, Meijer E, Berends M, Kupers T, Olde Hartman T, Muris J, de Schepper E, Velek P, Kuiper J, Berger M, Peters L\nA Natural Language Processing Model for COVID-19 Detection Based on Dutch General Practice Electronic Health Records by\nUsing Bidirectional Encoder Representations From Transformers: Development and Validation Study\nJ Med Internet Res 2023;25:e49944\nURL: https://www.jmir.org/2023/1/e49944\ndoi: 10.2196/49944\nPMID: 37792444\n©Maarten Homburg, Eline Meijer, Matthijs Berends, Thijmen Kupers, Tim Olde Hartman, Jean Muris, Evelien de Schepper,\nPremysl Velek, Jeroen Kuiper, Marjolein Berger, Lilian Peters. Originally published in the Journal of Medical Internet Research\n(https://www.jmir.org), 04.10.2023. This is an open-access article distributed under the terms of the Creative Commons Attribution\nLicense (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any\nmedium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete\nbibliographic information, a link to the original publication on https://www.jmir.org/, as well as this copyright and license\ninformation must be included.\nJ Med Internet Res 2023 | vol. 25 | e49944 | p. 12https://www.jmir.org/2023/1/e49944\n(page number not for citation purposes)\nHomburg et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6900014281272888
    },
    {
      "name": "Test set",
      "score": 0.5079029202461243
    },
    {
      "name": "Data mining",
      "score": 0.4651551842689514
    },
    {
      "name": "Artificial intelligence",
      "score": 0.45614051818847656
    },
    {
      "name": "Data science",
      "score": 0.4476100206375122
    },
    {
      "name": "Natural language processing",
      "score": 0.4275173842906952
    },
    {
      "name": "Data set",
      "score": 0.42154577374458313
    },
    {
      "name": "Machine learning",
      "score": 0.4078432321548462
    },
    {
      "name": "Information retrieval",
      "score": 0.3270880877971649
    }
  ]
}