{
    "title": "Sparse Low-rank Adaptation of Pre-trained Language Models",
    "url": "https://openalex.org/W4389524340",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A1903586662",
            "name": "Ning Ding",
            "affiliations": [
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A5108934300",
            "name": "Xingtai Lv",
            "affiliations": [
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A2556929192",
            "name": "Qiaosen Wang",
            "affiliations": [
                "University of Chicago"
            ]
        },
        {
            "id": "https://openalex.org/A2096431253",
            "name": "Yulin CHEN",
            "affiliations": [
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A2110030736",
            "name": "Bowen Zhou",
            "affiliations": [
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A2051269448",
            "name": "Zhiyuan Liu",
            "affiliations": [
                "Tsinghua University"
            ]
        },
        {
            "id": "https://openalex.org/A2157167650",
            "name": "Maosong Sun",
            "affiliations": [
                "Tsinghua University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2799054028",
        "https://openalex.org/W4330338093",
        "https://openalex.org/W3197876970",
        "https://openalex.org/W2963748441",
        "https://openalex.org/W3174702398",
        "https://openalex.org/W3211686893",
        "https://openalex.org/W4205991051",
        "https://openalex.org/W2964303773",
        "https://openalex.org/W3195577433",
        "https://openalex.org/W4287122891",
        "https://openalex.org/W2923014074",
        "https://openalex.org/W3176468671",
        "https://openalex.org/W3207663303",
        "https://openalex.org/W3168867926",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W131533222",
        "https://openalex.org/W2135046866",
        "https://openalex.org/W4253067820",
        "https://openalex.org/W2100556411",
        "https://openalex.org/W4283019279",
        "https://openalex.org/W4386566659",
        "https://openalex.org/W2130158090",
        "https://openalex.org/W2978670439",
        "https://openalex.org/W4379539500",
        "https://openalex.org/W4282961290",
        "https://openalex.org/W2158252006",
        "https://openalex.org/W2950305991",
        "https://openalex.org/W3176828726",
        "https://openalex.org/W4367628410",
        "https://openalex.org/W4288480287",
        "https://openalex.org/W2460144244",
        "https://openalex.org/W2164452299",
        "https://openalex.org/W4385565348",
        "https://openalex.org/W3122890974",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W3205949070",
        "https://openalex.org/W4295312788",
        "https://openalex.org/W4322766882",
        "https://openalex.org/W2963000224",
        "https://openalex.org/W4322718191",
        "https://openalex.org/W3198659451",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W4378509449",
        "https://openalex.org/W3174770825",
        "https://openalex.org/W2979826702",
        "https://openalex.org/W2251939518",
        "https://openalex.org/W2963846996",
        "https://openalex.org/W3204669968"
    ],
    "abstract": "Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency. The popular method of low-rank adaptation (LoRA) offers a notable approach, hypothesizing that the adaptation process is intrinsically low-dimensional. Although LoRA has demonstrated commendable performance, it is implemented with a fixed and unalterable intrinsic rank that might not always be the ideal choice. Recognizing the need for more flexible adaptation, we extend the methodology of LoRA to an innovative approach we call sparse low-rank adaptation (SoRA) that enables dynamic adjustments to the intrinsic rank during the adaptation process. We achieve this through the incorporation of a gate unit optimized with proximal gradient method in the training stage, controlling the cardinality of rank under the sparsity of the gate. In the subsequent inference stage, we eliminate the parameter blocks corresponding to the zeroed-out ranks, to reduce each SoRA module back to a concise yet rank-optimal LoRA. Our approach strengthens the representation power of LoRA by initializing it with a higher rank, while efficiently taming a temporarily increased number of parameters via updating in a sparse way. We further introduce a sparsifying scheduler for SoRA, aiming to examine the impact of the number of non-zero parameters on the model’s memorization and generalization. Our experimental results demonstrate that SoRA can outperform other baselines even with 70% retained parameters and 70% training time.",
    "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 4133–4145\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nSparse Low-rank Adaptation of Pre-trained Language Models\nNing Ding1∗, Xingtai Lv1∗, Qiaosen Wang4, Yulin Chen2\nBowen Zhou1†, Zhiyuan Liu2,3†, Maosong Sun2,3†\n1Department of Electronic Engineering, Tsinghua University\n2Department of Computer Science and Technology, Tsinghua University\n3 BNRIST, IAI, Tsinghua University,4Department of Statistics, The University of Chicago\ndn97@mail.tsinghua.edu.cn, lvxt20@mails.tsinghua.edu.cn\nAbstract\nFine-tuning pre-trained large language mod-\nels in a parameter-efficient manner is widely\nstudied for its effectiveness and efficiency.\nThe popular method of low-rank adaptation\n(LoRA) offers a notable approach, hypothe-\nsizing that the adaptation process is intrinsi-\ncally low-dimensional. Although LoRA has\ndemonstrated commendable performance, it is\nimplemented with a fixed and unalterable in-\ntrinsic rank that might not always be the ideal\nchoice. Recognizing the need for more flexi-\nble adaptation, we extend the methodology of\nLoRA to an innovative approach we call sparse\nlow-rank adaptation (SoRA) that enables dy-\nnamic adjustments to the intrinsic rank during\nthe adaptation process. We achieve this through\nthe incorporation of a gate unit optimized with\nproximal gradient method in the training stage,\ncontrolling the cardinality of rank under the\nsparsity of the gate. In the subsequent inference\nstage, we eliminate the parameter blocks cor-\nresponding to the zeroed-out ranks, to reduce\neach SoRA module back to a concise yet rank-\noptimal LoRA. Our approach strengthens the\nrepresentation power of LoRA by initializing\nit with a higher rank, while efficiently taming\na temporarily increased number of parameters\nvia updating in a sparse way. We further intro-\nduce a sparsifying scheduler for SoRA, aiming\nto examine the impact of the number of non-\nzero parameters on the model’s memorization\nand generalization. Our experimental results\ndemonstrate that SoRA can outperform other\nbaselines even with 70% retained parameters\nand 70% training time.\n1 Introduction\nAdapting large-scale pre-trained language mod-\nels (Devlin et al., 2019; Brown et al., 2020; He et al.,\n2020; Bommasani et al., 2021; Han et al., 2021;\nTouvron et al., 2023) in a parameter-efficient (He\n∗ equal contributions\n† corresponding authors\net al., 2022; Ding et al., 2023; Hu et al., 2023) man-\nner is increasingly gaining traction within the re-\nsearch community. The methods of this paradigm\ntypically keep most of the parameters of the un-\nderlying model unchanged, either insert additional\ntrainable parameters into the model (Houlsby et al.,\n2019; Li and Liang, 2021), or specify a small num-\nber of parameters (Zaken et al., 2021; Liu et al.,\n2021; Su et al., 2023) to be trainable or reparame-\nterize the adaptation process into a more efficient\nform (Hu et al., 2021; Qin et al., 2021). They have\nbeen validated to be effective across various mod-\nels and tasks, often yielding comparable or even\nbetter results than full-parameter fine-tuning.\nThe development potential of parameter-efficient\nfine-tuning became evident after extensive vali-\ndation of its performance. These methods offer\nthe opportunity to adapt the base model to fit any\ndata, allowing for enhancements and customiza-\ntion of language models tailored to specific tasks\nand personalized user characteristics. Due to the\nlightweight nature of the optimized parameters,\nthey can be seamlessly plugged into the model, al-\nlowing targeted enhancements to be made. Among\nthese methods, low-rank adaptation ( LORA (Hu\net al., 2021)) is considered one of the most efficient\nmethods at present. It assumes that the change of\nthe model’s parameters after adaptation is \"intrin-\nsically low-dimensional\" and performs adaptation\nby optimizing the matrix obtained from low-rank\ndecomposition. LoRA avoids forward propaga-\ntion latency caused by inserting additional neural\nmodules while demonstrating stable performance.\nAlthough effective, the setup of the intrinsic rank\n(normally as a hyperparameter) is still unclear. In-\ntuitively, a larger rank brings larger optimization\nspace and creates the capacity to handle more chal-\nlenging tasks. However, in practice, the optimal\nintrinsic rank would vary according to multiple\nfactors such as the backbone model and the task.\nGiven the enormous computational cost of\n4133\nsearching hyperparameters on large-scale models\n(such as GPT-3 (Brown et al., 2020) with 175 bil-\nlion parameters and LLaMA (Touvron et al., 2023)\nwith 700 million to 65 billion parameters), develop-\ning a method based on adaptive ranks is a natural\napproach. Some existing work has attempted to\nexplore this direction (Valipour et al., 2022; Zhang\net al., 2023), but they are largely heuristic or intro-\nduce additional costs. In this paper, we propose\nSoRA, a simple, effective, and automated method\nfor adaptive parameter-efficient fine-tuning. We\nintroduce a gating module with a proximal gradient\ndecent update under L1 regularization to control\nthe sparsity of the updated matrices. After train-\ning, the zero entry of the gating vector records\nthe columns of the down-projection matrix and the\nrows of the up-projection matrix, which can be\nsimply dropped and stored in a more parameter-\nefficient manner. Compared to other adaptive ap-\nproaches, the proximal gradient method has a clear\nmathematical meaning and does not have to involve\nother computations and heuristics. For example,\nAdaLoRA (Zhang et al., 2023) introduces an addi-\ntional regularizer to ensure that the lower and upper\nprojection matrices strictly adhere to the definition\nof singular value decomposition (SVD), with each\nmatrix being orthogonal. However, this regular-\nization term incurs substantial computational over-\nhead due to the gradient calculations. In contrast,\nwe eliminate this requirement and instead selec-\ntively filter low-rank components by controlling\nthe intermediate diagonal matrix. We detailedly\ncompare SoRA and related methods in Section 3.\nThe mechanism of SoRA also allows us to con-\ntrol the sparsity temporarily and investigate the\nrelationship between the number of non-zero train-\nable parameters and memorization and generaliza-\ntion capabilities. We propose a sparsifying sched-\nuler and find that the process of model adapta-\ntion exhibits a strong “compression capability”,\nand even a tiny portion of parameters (lower than\nLoRA rank being 1) could retain considerable per-\nformance. Extensive experiments are conducted to\ndemonstrate the effectiveness of our method. Par-\nticularly, our model could consistently outperform\nparameter-efficient baselines with fewer parame-\nters and 30% shorter training time on a wide range\nof downstream tasks. The code of this work will be\npublicly available at https://github.com/\nTsinghuaC3I/SoRA.\n2 A Closer Look to Adaptive Rank\nRelated Work. Before introducing our approach,\nwe first briefly recap parameter-efficient tuning\nand our backbone low-rank adaptation (LoRA).\nParameter-efficient tuning is a set of methods that\nonly optimize a small portion of parameters and\nkeep the main model untouched for adaptation.\nSome parameter-efficient methods would insert ad-\nditional neural modules or parameters to the back-\nbone model, such as Adapter (Houlsby et al., 2019),\nPrefix and Prompt Tuning (Li and Liang, 2021;\nLester et al., 2021). And another line of such meth-\nods attempts to specify particular parameters to be\ntrainable or prunable (Guo et al., 2021; Zhao et al.,\n2020; Zaken et al., 2021). Researchers derive a\nseries of variants of parameter-efficient methods to\nimprove the effectiveness or efficiency (Karimi Ma-\nhabadi et al., 2021; Hu et al., 2022; Sung et al.,\n2022; He et al., 2022). Recently, the applications\nof parameter-efficient fine-tuning are expanded to\nmulti-modal and instruction-tuning scenarios (Gao\net al., 2023; Dettmers et al., 2023). In this paper,\nwe focus more on LoRA (Hu et al., 2021), which\nuses low-rank matrices to approximate the change\nof weights.\nIn LoRA, pre-trained weights (denoted asW0 ∈\nRp×q) are frozen, and the trainable LoRA modules\nare low-rank decomposition matrices Wd ∈Rr×q\nand Wu ∈Rp×r of the change of each weight ma-\ntrix ∆ = WuWd ∈Rp×q. In this way, the output\nof the current layer h could be represented as\ny ← −W0x + WuWdx, (1)\nwhere r ≪ min{p,q}is a hyper-parameter of\n“intrinsic dimension” that controls the size of\nlow-rank matrices and the number of trainable\nparameters. In this section, we primarily focus on\nthe last term, denoting z ← −WuWdx.\nAdaptive Rank on LoRA. Despite a great step\nforward in tractability and efficiency, LoRA is still\nrestricted by its inflexibility in selecting the opti-\nmal rank r. Unlike continuous hyperparameters\nsuch as learning rate and weight decay that can be\ntuned adaptively online during the training process,\nLoRA rank rtakes discrete values – the change of\nwhich will directly alter the model structures. The\noptimal choice of rank can vary across different\nbackbone models and downstream tasks. A conser-\nvative choice of huge rankrcan waste training time\nand computation resources, while progressively set-\nting r tiny may degrade model performance and\n4134\n· ·\n·\n<latexit sha1_base64=\"cAiOZblwH8iALsf/vkdYLcRxSgQ=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit>\n\u0000 ·[ [\n·\n<latexit sha1_base64=\"cAiOZblwH8iALsf/vkdYLcRxSgQ=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit>\n\u0000· [ [\n<latexit sha1_base64=\"UjUn3B7ufgCOmxVTlETrJ0C/vJY=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>\nx\n<latexit sha1_base64=\"7LjW4inxM3IqVcFm0MkAOftM7UI=\">AAAB83icbVDLSsNAFL2pr1pfVZduBovgKiRS1GXBjcsK9gFNKJPJpB06mYSZiVBCfsONC0Xc+jPu/BsnbRbaemDgcM693DMnSDlT2nG+rdrG5tb2Tn23sbd/cHjUPD7pqySThPZIwhM5DLCinAna00xzOkwlxXHA6SCY3ZX+4IlKxRLxqOcp9WM8ESxiBGsjeV6M9TSI8kExDsfNlmM7C6B14lakBRW64+aXFyYki6nQhGOlRq6Taj/HUjPCadHwMkVTTGZ4QkeGChxT5eeLzAW6MEqIokSaJzRaqL83chwrNY8DM1lmVKteKf7njTId3fo5E2mmqSDLQ1HGkU5QWQAKmaRE87khmEhmsiIyxRITbWpqmBLc1S+vk/6V7V7b7Yd2q2NXddThDM7hEly4gQ7cQxd6QCCFZ3iFNyuzXqx362M5WrOqnVP4A+vzB0Ivkcc=</latexit>\nW d\n<latexit sha1_base64=\"pIWFDq2Tt0ud+NvmF88Xp+emVao=\">AAAB6nicbVBNS8NAEJ34WetX1aOXxSKIh5BIUY8FLx4r2g9oY9lsN+3SzW7Y3Qgh9Cd48aCIV3+RN/+N2zYHbX0w8Hhvhpl5YcKZNp737aysrq1vbJa2yts7u3v7lYPDlpapIrRJJJeqE2JNORO0aZjhtJMoiuOQ03Y4vpn67SeqNJPiwWQJDWI8FCxiBBsr3WeP5/1K1XO9GdAy8QtShQKNfuWrN5AkjakwhGOtu76XmCDHyjDC6aTcSzVNMBnjIe1aKnBMdZDPTp2gU6sMUCSVLWHQTP09keNY6ywObWeMzUgvelPxP6+bmug6yJlIUkMFmS+KUo6MRNO/0YApSgzPLMFEMXsrIiOsMDE2nbINwV98eZm0Llz/0q3d1ap1t4ijBMdwAmfgwxXU4RYa0AQCQ3iGV3hzuPPivDsf89YVp5g5gj9wPn8A/fCNjg==</latexit>\ny⇤\n<latexit sha1_base64=\"z65MLNYS9m9NIMg0IO7wQhtVhZc=\">AAAB8XicbVDLSsNAFL2pr1pfVZduBovgqiQi6rLgxmUF+8A2lMn0ph06mYSZiVBC/8KNC0Xc+jfu/BsnbRbaemDgcM69zLknSATXxnW/ndLa+sbmVnm7srO7t39QPTxq6zhVDFssFrHqBlSj4BJbhhuB3UQhjQKBnWBym/udJ1Sax/LBTBP0IzqSPOSMGis99iNqxkGYjWaDas2tu3OQVeIVpAYFmoPqV38YszRCaZigWvc8NzF+RpXhTOCs0k81JpRN6Ah7lkoaofazeeIZObPKkISxsk8aMld/b2Q00noaBXYyT6iXvVz8z+ulJrzxMy6T1KBki4/CVBATk/x8MuQKmRFTSyhT3GYlbEwVZcaWVLEleMsnr5L2Rd27ql/eX9Ya9aKOMpzAKZyDB9fQgDtoQgsYSHiGV3hztPPivDsfi9GSU+wcwx84nz/gTpEA</latexit>\ng\n<latexit sha1_base64=\"pcjqgRbl/D1PXi1iZ64D301adTY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hE1GPBi8eK9gPaUDbbTbt0swm7E6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSQ7uf9as1z/XmIKvEL0gNCjT61a/eIGFZzBUySY3p+l6KQU41Cib5tNLLDE8pG9Mh71qqaMxNkM9PnZIzqwxIlGhbCslc/T2R09iYSRzazpjiyCx7M/E/r5thdBPkQqUZcsUWi6JMEkzI7G8yEJozlBNLKNPC3krYiGrK0KZTsSH4yy+vktaF61+5l/eXtbpbxFGGEziFc/DhGupwBw1oAoMhPMMrvDnSeXHenY9Fa8kpZo7hD5zPHz1kjbg=</latexit>\nW u\n<latexit sha1_base64=\"ot/yvaZQPa9zErjmSLBW76zU60o=\">AAACHnicbVDLSitBEO3xba5Xoy7dNAbBu7hhRnwtBV24cKFgVMiEoaZTExt7eobuGiEM8yVu/BU3LhQRXOnf2IlZ+DrQcPqcKqrqxLmSlnz/zRsbn5icmp6Zrf2Z+zu/UF9cOrNZYQS2RKYycxGDRSU1tkiSwovcIKSxwvP4an/gn1+jsTLTp9TPsZNCT8tECiAnRfWtXlRSxf+HSBARDzXECqIeD1OgSwGqPKoif334i5MyPEBFUP2L6g2/6Q/Bf5JgRBpshOOo/hJ2M1GkqEkosLYd+Dl1SjAkhcKqFhYWcxBX0MO2oxpStJ1yeF7F15zS5Ulm3NPEh+rnjhJSa/tp7CoHe9rv3kD8zWsXlOx2SqnzglCLj0FJoThlfJAV70qDglTfERBGul25uAQDglyiNRdC8P3kn+RsoxlsNzdPNht7zVEcM2yFrbJ1FrAdtscO2TFrMcFu2B17YI/erXfvPXnPH6Vj3qhnmX2B9/oOBb2iYA==</latexit>\ng t \u0000 ⌘ t r g L 0 ( \u0000 )\n<latexit sha1_base64=\"8/UihlMxlt0wyylqbLxBDRogGzg=\">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>\nT ( · )\n<latexit sha1_base64=\"F+Pa0tnka1i85dgk3KuWQdNTg88=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>\nz\n·\n<latexit sha1_base64=\"cAiOZblwH8iALsf/vkdYLcRxSgQ=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit>\n\u0000· [ [\n<latexit sha1_base64=\"UjUn3B7ufgCOmxVTlETrJ0C/vJY=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>\nx\n<latexit sha1_base64=\"7LjW4inxM3IqVcFm0MkAOftM7UI=\">AAAB83icbVDLSsNAFL2pr1pfVZduBovgKiRS1GXBjcsK9gFNKJPJpB06mYSZiVBCfsONC0Xc+jPu/BsnbRbaemDgcM693DMnSDlT2nG+rdrG5tb2Tn23sbd/cHjUPD7pqySThPZIwhM5DLCinAna00xzOkwlxXHA6SCY3ZX+4IlKxRLxqOcp9WM8ESxiBGsjeV6M9TSI8kExDsfNlmM7C6B14lakBRW64+aXFyYki6nQhGOlRq6Taj/HUjPCadHwMkVTTGZ4QkeGChxT5eeLzAW6MEqIokSaJzRaqL83chwrNY8DM1lmVKteKf7njTId3fo5E2mmqSDLQ1HGkU5QWQAKmaRE87khmEhmsiIyxRITbWpqmBLc1S+vk/6V7V7b7Yd2q2NXddThDM7hEly4gQ7cQxd6QCCFZ3iFNyuzXqx362M5WrOqnVP4A+vzB0Ivkcc=</latexit>\nW d\n<latexit sha1_base64=\"pIWFDq2Tt0ud+NvmF88Xp+emVao=\">AAAB6nicbVBNS8NAEJ34WetX1aOXxSKIh5BIUY8FLx4r2g9oY9lsN+3SzW7Y3Qgh9Cd48aCIV3+RN/+N2zYHbX0w8Hhvhpl5YcKZNp737aysrq1vbJa2yts7u3v7lYPDlpapIrRJJJeqE2JNORO0aZjhtJMoiuOQ03Y4vpn67SeqNJPiwWQJDWI8FCxiBBsr3WeP5/1K1XO9GdAy8QtShQKNfuWrN5AkjakwhGOtu76XmCDHyjDC6aTcSzVNMBnjIe1aKnBMdZDPTp2gU6sMUCSVLWHQTP09keNY6ywObWeMzUgvelPxP6+bmug6yJlIUkMFmS+KUo6MRNO/0YApSgzPLMFEMXsrIiOsMDE2nbINwV98eZm0Llz/0q3d1ap1t4ijBMdwAmfgwxXU4RYa0AQCQ3iGV3hzuPPivDsf89YVp5g5gj9wPn8A/fCNjg==</latexit>\ny⇤\n<latexit sha1_base64=\"z65MLNYS9m9NIMg0IO7wQhtVhZc=\">AAAB8XicbVDLSsNAFL2pr1pfVZduBovgqiQi6rLgxmUF+8A2lMn0ph06mYSZiVBC/8KNC0Xc+jfu/BsnbRbaemDgcM69zLknSATXxnW/ndLa+sbmVnm7srO7t39QPTxq6zhVDFssFrHqBlSj4BJbhhuB3UQhjQKBnWBym/udJ1Sax/LBTBP0IzqSPOSMGis99iNqxkGYjWaDas2tu3OQVeIVpAYFmoPqV38YszRCaZigWvc8NzF+RpXhTOCs0k81JpRN6Ah7lkoaofazeeIZObPKkISxsk8aMld/b2Q00noaBXYyT6iXvVz8z+ulJrzxMy6T1KBki4/CVBATk/x8MuQKmRFTSyhT3GYlbEwVZcaWVLEleMsnr5L2Rd27ql/eX9Ya9aKOMpzAKZyDB9fQgDtoQgsYSHiGV3hztPPivDsfi9GSU+wcwx84nz/gTpEA</latexit>\ng\n<latexit sha1_base64=\"pcjqgRbl/D1PXi1iZ64D301adTY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hE1GPBi8eK9gPaUDbbTbt0swm7E6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSQ7uf9as1z/XmIKvEL0gNCjT61a/eIGFZzBUySY3p+l6KQU41Cib5tNLLDE8pG9Mh71qqaMxNkM9PnZIzqwxIlGhbCslc/T2R09iYSRzazpjiyCx7M/E/r5thdBPkQqUZcsUWi6JMEkzI7G8yEJozlBNLKNPC3krYiGrK0KZTsSH4yy+vktaF61+5l/eXtbpbxFGGEziFc/DhGupwBw1oAoMhPMMrvDnSeXHenY9Fa8kpZo7hD5zPHz1kjbg=</latexit>\nW u\n<latexit sha1_base64=\"ot/yvaZQPa9zErjmSLBW76zU60o=\">AAACHnicbVDLSitBEO3xba5Xoy7dNAbBu7hhRnwtBV24cKFgVMiEoaZTExt7eobuGiEM8yVu/BU3LhQRXOnf2IlZ+DrQcPqcKqrqxLmSlnz/zRsbn5icmp6Zrf2Z+zu/UF9cOrNZYQS2RKYycxGDRSU1tkiSwovcIKSxwvP4an/gn1+jsTLTp9TPsZNCT8tECiAnRfWtXlRSxf+HSBARDzXECqIeD1OgSwGqPKoif334i5MyPEBFUP2L6g2/6Q/Bf5JgRBpshOOo/hJ2M1GkqEkosLYd+Dl1SjAkhcKqFhYWcxBX0MO2oxpStJ1yeF7F15zS5Ulm3NPEh+rnjhJSa/tp7CoHe9rv3kD8zWsXlOx2SqnzglCLj0FJoThlfJAV70qDglTfERBGul25uAQDglyiNRdC8P3kn+RsoxlsNzdPNht7zVEcM2yFrbJ1FrAdtscO2TFrMcFu2B17YI/erXfvPXnPH6Vj3qhnmX2B9/oOBb2iYA==</latexit>\ng t \u0000 ⌘ t r g L 0 ( \u0000 )\n<latexit sha1_base64=\"8/UihlMxlt0wyylqbLxBDRogGzg=\">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>\nT ( · )\n<latexit sha1_base64=\"F+Pa0tnka1i85dgk3KuWQdNTg88=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>\nz\n4x3 3x14x14x13x43x1\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>\nL 0 ( \u0000 )\n<latexit sha1_base64=\"NfIpreFiwZKqcEZ9f+kK1kWNKNc=\">AAACRHicdVDLSgMxFM3Ud31VXboJFkFBhowtWheC4EZwo2CrMDMOmTTThmYeJBmhhPk4N36AO7/AjQtF3IrpC1T0QOBw7r3n3pww40wqhJ6s0tT0zOzc/EJ5cWl5ZbWytt6SaS4IbZKUp+ImxJJyltCmYorTm0xQHIecXoe900H9+o4KydLkSvUz6se4k7CIEayMFFRc7Q1NXNEJfY3s2pFBYw/ZdYSQg8YE1QqPG9M29mQeB7p37BS3+rzwWlQo6MVYdcNId4y209sdqYFTBJXqxBBODOHEEDo2GqIKxrgIKo9eOyV5TBNFOJbSdVCmfI2FYoTTouzlkmaY9HCHuoYmOKbS18P7C7htlDaMUmFeouBQ/T6hcSxlPw5N5+Be+bs2EP+qubmKGr5mSZYrmpDRoijnUKVwkChsM0GJ4n1DMBHM3ApJFwtMlMm9bEKY/BT+T1r7tnNg1y/r1RN7HMc82ARbYAc44BCcgDNwAZqAgHvwDF7Bm/VgvVjv1seotWSNZzbAD1ifX4sqrvw=</latexit>\n\u0000\nKX\nk =1\nk g ( k )\nk 1\n<latexit sha1_base64=\"fQbJT0bmzDSzA+yL/oTkkH6TgLg=\">AAAB8nicbVDLSgMxFL1TX7W+qi7dBIvgapgRUZcFNy5cVLAPmA4lk2ba0EwyJBmhDP0MNy4UcevXuPNvzLSz0NYDgcM595JzT5Rypo3nfTuVtfWNza3qdm1nd2//oH541NEyU4S2ieRS9SKsKWeCtg0znPZSRXEScdqNJreF332iSjMpHs00pWGCR4LFjGBjpaCfYDMmmOf3s0G94bneHGiV+CVpQInWoP7VH0qSJVQYwrHWge+lJsyxMoxwOqv1M01TTCZ4RANLBU6oDvN55Bk6s8oQxVLZJwyaq783cpxoPU0iO1lE1MteIf7nBZmJb8KciTQzVJDFR3HGkZGouB8NmaLE8KklmChmsyIyxgoTY1uq2RL85ZNXSefC9a/cy4fLRtMt66jCCZzCOfhwDU24gxa0gYCEZ3iFN8c4L86787EYrTjlzjH8gfP5A33vkVc=</latexit>\nL\n<latexit sha1_base64=\"8uB+wur6y1P5uh20XI3SQtWrgok=\">AAACMHicbVDLSgMxFM34rPVVdekmWJQWYZiRom4KBRcKuqhgH9Bph0yaaUMzmSHJCGWYT3Ljp+hGQRG3foXpY1FbDwTOPffeJOd4EaNSWda7sbS8srq2ntnIbm5t7+zm9vbrMowFJjUcslA0PSQJo5zUFFWMNCNBUOAx0vAGV6N+45EISUP+oIYRaQeox6lPMVJacnPXToBUHyOW3KUn5ZnCtQqN4qnD9FVd5Mg4cJNB+TbtJDx16kQo2OskhUFxUri2m8tbpjUGXCT2lOTBFFU39+J0QxwHhCvMkJQt24pUO0FCUcxImnViSSKEB6hHWppyFBDZTsaGU3islS70Q6EPV3Cszm4kKJByGHh6cuRIzvdG4n+9Vqz8y3ZCeRQrwvHkIT9mUIVwlB7sUkGwYkNNEBZU/xXiPhIIK51xVodgz1teJPUz0z43S/elfMWcxpEBh+AIFIANLkAF3IAqqAEMnsAr+ACfxrPxZnwZ35PRJWO6cwD+wPj5BWUFqb4=</latexit>\nL = L 0 ( W )+ \u0000\nnX\nk = K\nk g ( k )\nk 1\nNon-zero\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>\nL 0 ( \u0000 )\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>\nL 0 ( \u0000 )\n<latexit sha1_base64=\"oMVNr0TY+RuNTPo/mXm4PRr/4ks=\">AAAB/XicbVDLSsNAFJ3UV62v+Ni5GSyCq5JIUZdFNy4r2Ac0IUwmk3boJBNmboRair/ixoUibv0Pd/6N0zYLbT0wcDjnXO6dE2aCa3Ccb6u0srq2vlHerGxt7+zu2fsHbS1zRVmLSiFVNySaCZ6yFnAQrJspRpJQsE44vJn6nQemNJfpPYwy5iekn/KYUwJGCuwjT5hwRLBHIwnYY0ACCOyqU3NmwMvELUgVFWgG9pcXSZonLAUqiNY918nAHxMFnAo2qXi5ZhmhQ9JnPUNTkjDtj2fXT/CpUSIcS2VeCnim/p4Yk0TrURKaZEJgoBe9qfif18shvvLHPM1yYCmdL4pzgUHiaRU44opRECNDCFXc3IrpgChCwRRWMSW4i19eJu3zmntRq9/Vq43roo4yOkYn6Ay56BI10C1qohai6BE9o1f0Zj1ZL9a79TGPlqxi5hD9gfX5A/BClOg=</latexit>\n\u0000 · ⌘ t\n<latexit sha1_base64=\"KMS8K7k8Fpgib6SgzOKf+ZCOSwY=\">AAAB/XicbVDLSsNAFJ34rPUVHzs3g0VwFRIp6rLgxmUF+4AmhMlk0g6dTMLMjVBL8VfcuFDErf/hzr9x2mahrQcGDuecy71zolxwDa77ba2srq1vbFa2qts7u3v79sFhW2eFoqxFM5GpbkQ0E1yyFnAQrJsrRtJIsE40vJn6nQemNM/kPYxyFqSkL3nCKQEjhfaxL0w4JtincQbYZ0BCCO2a67gz4GXilaSGSjRD+8uPM1qkTAIVROue5+YQjIkCTgWbVP1Cs5zQIemznqGSpEwH49n1E3xmlBgnmTJPAp6pvyfGJNV6lEYmmRIY6EVvKv7n9QpIroMxl3kBTNL5oqQQGDI8rQLHXDEKYmQIoYqbWzEdEEUomMKqpgRv8cvLpH3heJdO/a5eazhlHRV0gk7ROfLQFWqgW9RELUTRI3pGr+jNerJerHfrYx5dscqZI/QH1ucP6j6U1A==</latexit>\n\u0000 · ⌘ t\n<latexit sha1_base64=\"mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit>\n⇠\n<latexit sha1_base64=\"2ib/1NcO2EZySJ8nP9FjmEGX2Ic=\">AAAB6nicbVBNSwMxEJ2tX7V+VT16CRaheCi7UtRjwYvHivYD2rVk02wbmk2WJCssS3+CFw+KePUXefPfmLZ70NYHA4/3ZpiZF8ScaeO6305hbX1jc6u4XdrZ3ds/KB8etbVMFKEtIrlU3QBrypmgLcMMp91YURwFnHaCyc3M7zxRpZkUDyaNqR/hkWAhI9hY6T59PB+UK27NnQOtEi8nFcjRHJS/+kNJkogKQzjWuue5sfEzrAwjnE5L/UTTGJMJHtGepQJHVPvZ/NQpOrPKEIVS2RIGzdXfExmOtE6jwHZG2Iz1sjcT//N6iQmv/YyJODFUkMWiMOHISDT7Gw2ZosTw1BJMFLO3IjLGChNj0ynZELzll1dJ+6LmXdbqd/VKo5rHUYQTOIUqeHAFDbiFJrSAwAie4RXeHO68OO/Ox6K14OQzx/AHzucP/CKNiA==</latexit>\ny ⇤\nInput & Output\n··\n<latexit sha1_base64=\"UjUn3B7ufgCOmxVTlETrJ0C/vJY=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>\nx\n<latexit sha1_base64=\"7LjW4inxM3IqVcFm0MkAOftM7UI=\">AAAB83icbVDLSsNAFL2pr1pfVZduBovgKiRS1GXBjcsK9gFNKJPJpB06mYSZiVBCfsONC0Xc+jPu/BsnbRbaemDgcM693DMnSDlT2nG+rdrG5tb2Tn23sbd/cHjUPD7pqySThPZIwhM5DLCinAna00xzOkwlxXHA6SCY3ZX+4IlKxRLxqOcp9WM8ESxiBGsjeV6M9TSI8kExDsfNlmM7C6B14lakBRW64+aXFyYki6nQhGOlRq6Taj/HUjPCadHwMkVTTGZ4QkeGChxT5eeLzAW6MEqIokSaJzRaqL83chwrNY8DM1lmVKteKf7njTId3fo5E2mmqSDLQ1HGkU5QWQAKmaRE87khmEhmsiIyxRITbWpqmBLc1S+vk/6V7V7b7Yd2q2NXddThDM7hEly4gQ7cQxd6QCCFZ3iFNyuzXqx362M5WrOqnVP4A+vzB0Ivkcc=</latexit>\nW d\n<latexit sha1_base64=\"pcjqgRbl/D1PXi1iZ64D301adTY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hE1GPBi8eK9gPaUDbbTbt0swm7E6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSQ7uf9as1z/XmIKvEL0gNCjT61a/eIGFZzBUySY3p+l6KQU41Cib5tNLLDE8pG9Mh71qqaMxNkM9PnZIzqwxIlGhbCslc/T2R09iYSRzazpjiyCx7M/E/r5thdBPkQqUZcsUWi6JMEkzI7G8yEJozlBNLKNPC3krYiGrK0KZTsSH4yy+vktaF61+5l/eXtbpbxFGGEziFc/DhGupwBw1oAoMhPMMrvDnSeXHenY9Fa8kpZo7hD5zPHz1kjbg=</latexit>\nW u\n<latexit sha1_base64=\"ot/yvaZQPa9zErjmSLBW76zU60o=\">AAACHnicbVDLSitBEO3xba5Xoy7dNAbBu7hhRnwtBV24cKFgVMiEoaZTExt7eobuGiEM8yVu/BU3LhQRXOnf2IlZ+DrQcPqcKqrqxLmSlnz/zRsbn5icmp6Zrf2Z+zu/UF9cOrNZYQS2RKYycxGDRSU1tkiSwovcIKSxwvP4an/gn1+jsTLTp9TPsZNCT8tECiAnRfWtXlRSxf+HSBARDzXECqIeD1OgSwGqPKoif334i5MyPEBFUP2L6g2/6Q/Bf5JgRBpshOOo/hJ2M1GkqEkosLYd+Dl1SjAkhcKqFhYWcxBX0MO2oxpStJ1yeF7F15zS5Ulm3NPEh+rnjhJSa/tp7CoHe9rv3kD8zWsXlOx2SqnzglCLj0FJoThlfJAV70qDglTfERBGul25uAQDglyiNRdC8P3kn+RsoxlsNzdPNht7zVEcM2yFrbJ1FrAdtscO2TFrMcFu2B17YI/erXfvPXnPH6Vj3qhnmX2B9/oOBb2iYA==</latexit>\ng t \u0000 ⌘ t r g L 0 ( \u0000 )\n<latexit sha1_base64=\"8/UihlMxlt0wyylqbLxBDRogGzg=\">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>\nT ( · )\n<latexit sha1_base64=\"F+Pa0tnka1i85dgk3KuWQdNTg88=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>\nz\nDrop after training\nZero\nNon-zero\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>\nL 0 ( \u0000 )\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>\nL 0 ( \u0000 )\n<latexit sha1_base64=\"mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit>\n⇠\n<latexit sha1_base64=\"2ib/1NcO2EZySJ8nP9FjmEGX2Ic=\">AAAB6nicbVBNSwMxEJ2tX7V+VT16CRaheCi7UtRjwYvHivYD2rVk02wbmk2WJCssS3+CFw+KePUXefPfmLZ70NYHA4/3ZpiZF8ScaeO6305hbX1jc6u4XdrZ3ds/KB8etbVMFKEtIrlU3QBrypmgLcMMp91YURwFnHaCyc3M7zxRpZkUDyaNqR/hkWAhI9hY6T59PB+UK27NnQOtEi8nFcjRHJS/+kNJkogKQzjWuue5sfEzrAwjnE5L/UTTGJMJHtGepQJHVPvZ/NQpOrPKEIVS2RIGzdXfExmOtE6jwHZG2Iz1sjcT//N6iQmv/YyJODFUkMWiMOHISDT7Gw2ZosTw1BJMFLO3IjLGChNj0ynZELzll1dJ+6LmXdbqd/VKo5rHUYQTOIUqeHAFDbiFJrSAwAie4RXeHO68OO/Ox6K14OQzx/AHzucP/CKNiA==</latexit>\ny ⇤\nInput & Output\nDrop after training\nZero\nNon-zero\nInput & Output\nLoRA\nSoRA\nMulti-head Attention\nAdd & LayerNorm\nAdd & LayerNorm\nFeed Forward Net\nQ K V\nW W W\nHidden States\nPreﬁx\nLoRA LoRA\nPreﬁx\nTransformer Layer × L\n+\n·\n<latexit sha1_base64=\"cAiOZblwH8iALsf/vkdYLcRxSgQ=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit>\n\u0000· [ [\n<latexit sha1_base64=\"UjUn3B7ufgCOmxVTlETrJ0C/vJY=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>\nx\n<latexit sha1_base64=\"8/UihlMxlt0wyylqbLxBDRogGzg=\">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>\nT ( · )\n<latexit sha1_base64=\"F+Pa0tnka1i85dgk3KuWQdNTg88=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>\nz\n<latexit sha1_base64=\"NfIpreFiwZKqcEZ9f+kK1kWNKNc=\">AAACRHicdVDLSgMxFM3Ud31VXboJFkFBhowtWheC4EZwo2CrMDMOmTTThmYeJBmhhPk4N36AO7/AjQtF3IrpC1T0QOBw7r3n3pww40wqhJ6s0tT0zOzc/EJ5cWl5ZbWytt6SaS4IbZKUp+ImxJJyltCmYorTm0xQHIecXoe900H9+o4KydLkSvUz6se4k7CIEayMFFRc7Q1NXNEJfY3s2pFBYw/ZdYSQg8YE1QqPG9M29mQeB7p37BS3+rzwWlQo6MVYdcNId4y209sdqYFTBJXqxBBODOHEEDo2GqIKxrgIKo9eOyV5TBNFOJbSdVCmfI2FYoTTouzlkmaY9HCHuoYmOKbS18P7C7htlDaMUmFeouBQ/T6hcSxlPw5N5+Be+bs2EP+qubmKGr5mSZYrmpDRoijnUKVwkChsM0GJ4n1DMBHM3ApJFwtMlMm9bEKY/BT+T1r7tnNg1y/r1RN7HMc82ARbYAc44BCcgDNwAZqAgHvwDF7Bm/VgvVjv1seotWSNZzbAD1ifX4sqrvw=</latexit>\n\u0000\nKX\nk =1\nk g ( k )\nk 1\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>\nL 0 ( \u0000 )\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>\nL 0 ( \u0000 )\n<latexit sha1_base64=\"mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit>\n⇠\nDrop after training\nZero\nNon-zero\nInput & Output\nProximal Gradient Descent\nGating\nDown-\nprojection\nUp-\nprojection\n<latexit sha1_base64=\"SQNLzP+oVKTBulPSpmKN+TfSpd4=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJM21oJjMkd4Qy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1gNOE+xEdKREKRtFKj/2I4jgIs/FsUK64NXcBsk68nFQgR3NQ/uoPY5ZGXCGT1Jie5yboZ1SjYJLPSv3U8ISyCR3xnqWKRtz42SLxjFxYZUjCWNunkCzU3xsZjYyZRoGdnCc0q95c/M/rpRje+JlQSYpcseVHYSoJxmR+PhkKzRnKqSWUaWGzEjammjK0JZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMEzvMKbY5wX5935WI4WnHznFP7A+fwB4AWQ+w==</latexit>\nh\n<latexit sha1_base64=\"HBl2VMqsA9H1oNFDXe3UKmJfeFw=\">AAAB8nicbVDLSgMxFL1TX7W+qi7dBIvYVZmRoi4LblxWsA+YDiWTZtrQTDIkGaEM/Qw3LhRx69e482/MtLPQ1gOBwzn3knNPmHCmjet+O6WNza3tnfJuZW//4PCoenzS1TJVhHaI5FL1Q6wpZ4J2DDOc9hNFcRxy2gund7nfe6JKMykezSyhQYzHgkWMYGMlfxBjMwmjbDK/HFZrbsNdAK0TryA1KNAeVr8GI0nSmApDONba99zEBBlWhhFO55VBqmmCyRSPqW+pwDHVQbaIPEcXVhmhSCr7hEEL9fdGhmOtZ3FoJ/OIetXLxf88PzXRbZAxkaSGCrL8KEo5MhLl96MRU5QYPrMEE8VsVkQmWGFibEsVW4K3evI66V41vOtG86FZa9WLOspwBudQBw9uoAX30IYOEJDwDK/w5hjnxXl3PpajJafYOYU/cD5/AERUkSw=</latexit>\nh0\n<latexit sha1_base64=\"nbqJXXGN5BTEUvsIFXww4ZYe/LA=\">AAAB83icbVDLSgMxFL3xWeur6tJNsAgupMxIUZcFNy4r2Ad0hpLJZNrQTGZIMkIZ+htuXCji1p9x59+YaWehrQcCh3Pu5Z6cIBVcG8f5RmvrG5tb25Wd6u7e/sFh7ei4q5NMUdahiUhUPyCaCS5Zx3AjWD9VjMSBYL1gclf4vSemNE/ko5mmzI/JSPKIU2Ks5HkxMeMgynuzYTis1Z2GMwdeJW5J6lCiPax9eWFCs5hJQwXReuA6qfFzogyngs2qXqZZSuiEjNjAUklipv18nnmGz60S4ihR9kmD5+rvjZzEWk/jwE4WGfWyV4j/eYPMRLd+zmWaGSbp4lCUCWwSXBSAQ64YNWJqCaGK26yYjoki1NiaqrYEd/nLq6R71XCvG82HZr11WdZRgVM4gwtw4QZacA9t6ACFFJ7hFd5Qhl7QO/pYjK6hcucE/gB9/gBBlZHF</latexit>\nW d\n<latexit sha1_base64=\"/zBQzt27borSCLHZJETVK/L3JjQ=\">AAAB83icbVDLSsNAFL2pr1pfVZduBovgQkoipbosuHFZwT6gCWUynbRDJ5MwD6GE/oYbF4q49Wfc+TdO2iy09cDA4Zx7uWdOmHKmtOt+O6WNza3tnfJuZW//4PCoenzSVYmRhHZIwhPZD7GinAna0Uxz2k8lxXHIaS+c3uV+74lKxRLxqGcpDWI8FixiBGsr+X6M9SSMst58aIbVmlt3F0DrxCtIDQq0h9Uvf5QQE1OhCcdKDTw31UGGpWaE03nFN4qmmEzxmA4sFTimKsgWmefowiojFCXSPqHRQv29keFYqVkc2sk8o1r1cvE/b2B0dBtkTKRGU0GWhyLDkU5QXgAaMUmJ5jNLMJHMZkVkgiUm2tZUsSV4q19eJ93rutesNx4atdZVUUcZzuAcLsGDG2jBPbShAwRSeIZXeHOM8+K8Ox/L0ZJT7JzCHzifP1tZkdY=</latexit>\nW u\n<latexit sha1_base64=\"QxHJIYnglv0qz/Wz78YlSTh0Gbg=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>\ng\n<latexit sha1_base64=\"dNEdt8VzjdxuWRV2qtIdvhVZt+I=\">AAACMnicbZBNS+RAEIY7fq2Oro569NI4LOhhh0REPQp6WMGDgqPCZAiVnsrY2OmE7srCEPKbvPhLBA/rQRGv/gh7xhG/tqDh4X2r6Ko3zpW05Pv/vLHxicmpH9Mztdm5n/ML9cWlU5sVRmBLZCoz5zFYVFJjiyQpPM8NQhorPIsv9wb+2V80Vmb6hPo5dlLoaZlIAeSkqH4QpkAXcVL2qqikiv8OkSAiHmqIFUTlu13xIQtQ5WEV+WtvTriPiqBaj+oNv+kPi3+HYAQNNqqjqH4TdjNRpKhJKLC2Hfg5dUowJIXCqhYWFnMQl9DDtkMNKdpOOTy54r+c0uVJZtzTxIfqx4kSUmv7aew6B3var95A/J/XLijZ6ZRS5wWhFq8fJYXilPFBfrwrDQpSfQcgjHS7cnEBBgS5lGsuhODryd/hdKMZbDU3jzcbu81RHNNsha2yNRawbbbL/rAj1mKCXbFbds8evGvvznv0nl5bx7zRzDL7VN7zC+Blq6w=</latexit>\ng t \u0000 ⌘ t r g L 0 ( \u0000 )\nUpdate \n<latexit sha1_base64=\"QxHJIYnglv0qz/Wz78YlSTh0Gbg=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>\ng\n·\n<latexit sha1_base64=\"cAiOZblwH8iALsf/vkdYLcRxSgQ=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit>\n\u0000· [ [\n<latexit sha1_base64=\"UjUn3B7ufgCOmxVTlETrJ0C/vJY=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>\nx\n<latexit sha1_base64=\"8/UihlMxlt0wyylqbLxBDRogGzg=\">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>\nT ( · )\n<latexit sha1_base64=\"F+Pa0tnka1i85dgk3KuWQdNTg88=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>\nz\n<latexit sha1_base64=\"NfIpreFiwZKqcEZ9f+kK1kWNKNc=\">AAACRHicdVDLSgMxFM3Ud31VXboJFkFBhowtWheC4EZwo2CrMDMOmTTThmYeJBmhhPk4N36AO7/AjQtF3IrpC1T0QOBw7r3n3pww40wqhJ6s0tT0zOzc/EJ5cWl5ZbWytt6SaS4IbZKUp+ImxJJyltCmYorTm0xQHIecXoe900H9+o4KydLkSvUz6se4k7CIEayMFFRc7Q1NXNEJfY3s2pFBYw/ZdYSQg8YE1QqPG9M29mQeB7p37BS3+rzwWlQo6MVYdcNId4y209sdqYFTBJXqxBBODOHEEDo2GqIKxrgIKo9eOyV5TBNFOJbSdVCmfI2FYoTTouzlkmaY9HCHuoYmOKbS18P7C7htlDaMUmFeouBQ/T6hcSxlPw5N5+Be+bs2EP+qubmKGr5mSZYrmpDRoijnUKVwkChsM0GJ4n1DMBHM3ApJFwtMlMm9bEKY/BT+T1r7tnNg1y/r1RN7HMc82ARbYAc44BCcgDNwAZqAgHvwDF7Bm/VgvVjv1seotWSNZzbAD1ifX4sqrvw=</latexit>\n\u0000\nKX\nk =1\nk g ( k )\nk 1\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>\nL 0 ( \u0000 )\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>\nL 0 ( \u0000 )\n<latexit sha1_base64=\"mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit>\n⇠\nDrop after training\nZero\nNon-zero\nInput & Output\nProximal Gradient Descent\nGating\nDown-\nprojection\nUp-\nprojection\n<latexit sha1_base64=\"SQNLzP+oVKTBulPSpmKN+TfSpd4=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJM21oJjMkd4Qy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1gNOE+xEdKREKRtFKj/2I4jgIs/FsUK64NXcBsk68nFQgR3NQ/uoPY5ZGXCGT1Jie5yboZ1SjYJLPSv3U8ISyCR3xnqWKRtz42SLxjFxYZUjCWNunkCzU3xsZjYyZRoGdnCc0q95c/M/rpRje+JlQSYpcseVHYSoJxmR+PhkKzRnKqSWUaWGzEjammjK0JZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMEzvMKbY5wX5935WI4WnHznFP7A+fwB4AWQ+w==</latexit>\nh\n<latexit sha1_base64=\"HBl2VMqsA9H1oNFDXe3UKmJfeFw=\">AAAB8nicbVDLSgMxFL1TX7W+qi7dBIvYVZmRoi4LblxWsA+YDiWTZtrQTDIkGaEM/Qw3LhRx69e482/MtLPQ1gOBwzn3knNPmHCmjet+O6WNza3tnfJuZW//4PCoenzS1TJVhHaI5FL1Q6wpZ4J2DDOc9hNFcRxy2gund7nfe6JKMykezSyhQYzHgkWMYGMlfxBjMwmjbDK/HFZrbsNdAK0TryA1KNAeVr8GI0nSmApDONba99zEBBlWhhFO55VBqmmCyRSPqW+pwDHVQbaIPEcXVhmhSCr7hEEL9fdGhmOtZ3FoJ/OIetXLxf88PzXRbZAxkaSGCrL8KEo5MhLl96MRU5QYPrMEE8VsVkQmWGFibEsVW4K3evI66V41vOtG86FZa9WLOspwBudQBw9uoAX30IYOEJDwDK/w5hjnxXl3PpajJafYOYU/cD5/AERUkSw=</latexit>\nh0\n<latexit sha1_base64=\"nbqJXXGN5BTEUvsIFXww4ZYe/LA=\">AAAB83icbVDLSgMxFL3xWeur6tJNsAgupMxIUZcFNy4r2Ad0hpLJZNrQTGZIMkIZ+htuXCji1p9x59+YaWehrQcCh3Pu5Z6cIBVcG8f5RmvrG5tb25Wd6u7e/sFh7ei4q5NMUdahiUhUPyCaCS5Zx3AjWD9VjMSBYL1gclf4vSemNE/ko5mmzI/JSPKIU2Ks5HkxMeMgynuzYTis1Z2GMwdeJW5J6lCiPax9eWFCs5hJQwXReuA6qfFzogyngs2qXqZZSuiEjNjAUklipv18nnmGz60S4ihR9kmD5+rvjZzEWk/jwE4WGfWyV4j/eYPMRLd+zmWaGSbp4lCUCWwSXBSAQ64YNWJqCaGK26yYjoki1NiaqrYEd/nLq6R71XCvG82HZr11WdZRgVM4gwtw4QZacA9t6ACFFJ7hFd5Qhl7QO/pYjK6hcucE/gB9/gBBlZHF</latexit>\nW d\n<latexit sha1_base64=\"/zBQzt27borSCLHZJETVK/L3JjQ=\">AAAB83icbVDLSsNAFL2pr1pfVZduBovgQkoipbosuHFZwT6gCWUynbRDJ5MwD6GE/oYbF4q49Wfc+TdO2iy09cDA4Zx7uWdOmHKmtOt+O6WNza3tnfJuZW//4PCoenzSVYmRhHZIwhPZD7GinAna0Uxz2k8lxXHIaS+c3uV+74lKxRLxqGcpDWI8FixiBGsr+X6M9SSMst58aIbVmlt3F0DrxCtIDQq0h9Uvf5QQE1OhCcdKDTw31UGGpWaE03nFN4qmmEzxmA4sFTimKsgWmefowiojFCXSPqHRQv29keFYqVkc2sk8o1r1cvE/b2B0dBtkTKRGU0GWhyLDkU5QXgAaMUmJ5jNLMJHMZkVkgiUm2tZUsSV4q19eJ93rutesNx4atdZVUUcZzuAcLsGDG2jBPbShAwRSeIZXeHOM8+K8Ox/L0ZJT7JzCHzifP1tZkdY=</latexit>\nW u\n<latexit sha1_base64=\"QxHJIYnglv0qz/Wz78YlSTh0Gbg=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>\ng\n<latexit sha1_base64=\"dNEdt8VzjdxuWRV2qtIdvhVZt+I=\">AAACMnicbZBNS+RAEIY7fq2Oro569NI4LOhhh0REPQp6WMGDgqPCZAiVnsrY2OmE7srCEPKbvPhLBA/rQRGv/gh7xhG/tqDh4X2r6Ko3zpW05Pv/vLHxicmpH9Mztdm5n/ML9cWlU5sVRmBLZCoz5zFYVFJjiyQpPM8NQhorPIsv9wb+2V80Vmb6hPo5dlLoaZlIAeSkqH4QpkAXcVL2qqikiv8OkSAiHmqIFUTlu13xIQtQ5WEV+WtvTriPiqBaj+oNv+kPi3+HYAQNNqqjqH4TdjNRpKhJKLC2Hfg5dUowJIXCqhYWFnMQl9DDtkMNKdpOOTy54r+c0uVJZtzTxIfqx4kSUmv7aew6B3var95A/J/XLijZ6ZRS5wWhFq8fJYXilPFBfrwrDQpSfQcgjHS7cnEBBgS5lGsuhODryd/hdKMZbDU3jzcbu81RHNNsha2yNRawbbbL/rAj1mKCXbFbds8evGvvznv0nl5bx7zRzDL7VN7zC+Blq6w=</latexit>\ng t \u0000 ⌘ t r g L 0 ( \u0000 )\nUpdate \n<latexit sha1_base64=\"QxHJIYnglv0qz/Wz78YlSTh0Gbg=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>\ng\n·\n<latexit sha1_base64=\"cAiOZblwH8iALsf/vkdYLcRxSgQ=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit>\n\u0000· [ [\n<latexit sha1_base64=\"UjUn3B7ufgCOmxVTlETrJ0C/vJY=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>\nx\n<latexit sha1_base64=\"8/UihlMxlt0wyylqbLxBDRogGzg=\">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>\nT ( · )\n<latexit sha1_base64=\"F+Pa0tnka1i85dgk3KuWQdNTg88=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>\nz\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>\nL 0 ( \u0000 )\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>\nL 0 ( \u0000 )\n<latexit sha1_base64=\"mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit>\n⇠\nDrop after training\nZero values\nNon-zero values\nInput & Output\nProximal Gradient Descent\nGating\nDown-\nprojection\nUp-\nprojection\n<latexit sha1_base64=\"SQNLzP+oVKTBulPSpmKN+TfSpd4=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJM21oJjMkd4Qy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1gNOE+xEdKREKRtFKj/2I4jgIs/FsUK64NXcBsk68nFQgR3NQ/uoPY5ZGXCGT1Jie5yboZ1SjYJLPSv3U8ISyCR3xnqWKRtz42SLxjFxYZUjCWNunkCzU3xsZjYyZRoGdnCc0q95c/M/rpRje+JlQSYpcseVHYSoJxmR+PhkKzRnKqSWUaWGzEjammjK0JZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMEzvMKbY5wX5935WI4WnHznFP7A+fwB4AWQ+w==</latexit>\nh\n<latexit sha1_base64=\"HBl2VMqsA9H1oNFDXe3UKmJfeFw=\">AAAB8nicbVDLSgMxFL1TX7W+qi7dBIvYVZmRoi4LblxWsA+YDiWTZtrQTDIkGaEM/Qw3LhRx69e482/MtLPQ1gOBwzn3knNPmHCmjet+O6WNza3tnfJuZW//4PCoenzS1TJVhHaI5FL1Q6wpZ4J2DDOc9hNFcRxy2gund7nfe6JKMykezSyhQYzHgkWMYGMlfxBjMwmjbDK/HFZrbsNdAK0TryA1KNAeVr8GI0nSmApDONba99zEBBlWhhFO55VBqmmCyRSPqW+pwDHVQbaIPEcXVhmhSCr7hEEL9fdGhmOtZ3FoJ/OIetXLxf88PzXRbZAxkaSGCrL8KEo5MhLl96MRU5QYPrMEE8VsVkQmWGFibEsVW4K3evI66V41vOtG86FZa9WLOspwBudQBw9uoAX30IYOEJDwDK/w5hjnxXl3PpajJafYOYU/cD5/AERUkSw=</latexit>\nh0\n<latexit sha1_base64=\"nbqJXXGN5BTEUvsIFXww4ZYe/LA=\">AAAB83icbVDLSgMxFL3xWeur6tJNsAgupMxIUZcFNy4r2Ad0hpLJZNrQTGZIMkIZ+htuXCji1p9x59+YaWehrQcCh3Pu5Z6cIBVcG8f5RmvrG5tb25Wd6u7e/sFh7ei4q5NMUdahiUhUPyCaCS5Zx3AjWD9VjMSBYL1gclf4vSemNE/ko5mmzI/JSPKIU2Ks5HkxMeMgynuzYTis1Z2GMwdeJW5J6lCiPax9eWFCs5hJQwXReuA6qfFzogyngs2qXqZZSuiEjNjAUklipv18nnmGz60S4ihR9kmD5+rvjZzEWk/jwE4WGfWyV4j/eYPMRLd+zmWaGSbp4lCUCWwSXBSAQ64YNWJqCaGK26yYjoki1NiaqrYEd/nLq6R71XCvG82HZr11WdZRgVM4gwtw4QZacA9t6ACFFJ7hFd5Qhl7QO/pYjK6hcucE/gB9/gBBlZHF</latexit>\nW d\n<latexit sha1_base64=\"/zBQzt27borSCLHZJETVK/L3JjQ=\">AAAB83icbVDLSsNAFL2pr1pfVZduBovgQkoipbosuHFZwT6gCWUynbRDJ5MwD6GE/oYbF4q49Wfc+TdO2iy09cDA4Zx7uWdOmHKmtOt+O6WNza3tnfJuZW//4PCoenzSVYmRhHZIwhPZD7GinAna0Uxz2k8lxXHIaS+c3uV+74lKxRLxqGcpDWI8FixiBGsr+X6M9SSMst58aIbVmlt3F0DrxCtIDQq0h9Uvf5QQE1OhCcdKDTw31UGGpWaE03nFN4qmmEzxmA4sFTimKsgWmefowiojFCXSPqHRQv29keFYqVkc2sk8o1r1cvE/b2B0dBtkTKRGU0GWhyLDkU5QXgAaMUmJ5jNLMJHMZkVkgiUm2tZUsSV4q19eJ93rutesNx4atdZVUUcZzuAcLsGDG2jBPbShAwRSeIZXeHOM8+K8Ox/L0ZJT7JzCHzifP1tZkdY=</latexit>\nW u\n<latexit sha1_base64=\"QxHJIYnglv0qz/Wz78YlSTh0Gbg=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>\ng\nUpdate \n<latexit sha1_base64=\"QxHJIYnglv0qz/Wz78YlSTh0Gbg=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>\ng\n<latexit sha1_base64=\"GfJz1eI/r4ne/tVxPM2b6z4LLBs=\">AAACRHicbVBJSwMxGM241rpVPXoJFkFFhowWl4NQ8CJ4UbBVmBmHTJppQzMLSUYoYX6cF3+AN3+BFw+KeBXTdg5uDwKP920vL8w4kwqhJ2ticmp6ZrYyV51fWFxarq2stmWaC0JbJOWpuAmxpJwltKWY4vQmExTHIafXYf90WL++o0KyNLlSg4z6Me4mLGIEKyMFNVd7oyWu6Ia+Rvb+scHRLrIbCCEHlQTtFx43SzvYk3kc6P6JU9zq88JrU6GgF2PVCyPdNdpWf3usBk4R1OrIRiPAv8QpSR2UuAhqj14nJXlME0U4ltJ1UKZ8jYVihNOi6uWSZpj0cZe6hiY4ptLXI/8F3DRKB0apMC9RcKR+n9A4lnIQh6Zz6Ff+rg3F/2purqIjX7MkyxVNyPhQlHOoUjhMFHaYoETxgSGYCGa8QtLDAhNlcq+aEJzfX/5L2nu2c2A3Lhv15k4ZRwWsgw2wBRxwCJrgDFyAFiDgHjyDV/BmPVgv1rv1MW6dsMqZNfAD1ucXMyyuvQ==</latexit>\n\u0000\nKX\nk =1\nk g (k ) k 1\n<latexit sha1_base64=\"sXEWZE7Ef6gwsVRn6Y2lkbFH6Dw=\">AAACMnicbZBNixNBEIZ7ou7G6K5ZPXppDEIEN8wswd1jQA8KHiKYbCAThppOTdKkp2forlkIw/ymvfhLFvagB2XZqz/CzofofhQ0PLxvFV31xrmSlnz/u1d78PDRzm79cePJ0739Z82D50ObFUbgQGQqM6MYLCqpcUCSFI5yg5DGCk/jxfuVf3qGxspMf6VljpMUZlomUgA5KWp+ClOgeZyUsyoqqeKHIRJExEMNsYKo/GdXfM0CVPm5ivz2Xyf8gIqgehM1W37HXxe/C8EWWmxb/ah5EU4zUaSoSSiwdhz4OU1KMCSFwqoRFhZzEAuY4dihhhTtpFyfXPHXTpnyJDPuaeJr9f+JElJrl2nsOld72tveSrzPGxeUnExKqfOCUIvNR0mhOGV8lR+fSoOC1NIBCCPdrlzMwYAgl3LDhRDcPvkuDI86wbtO90u31Xu7jaPOXrJXrM0Cdsx67CPrswET7Jxdsp/sl/fN++Fdedeb1pq3nXnBbpT3+w/fy6uq</latexit>\ng t \u0000 ⌘ t r g L 0 ( \u0000 )\nFigure 1: An illustration of sparse low-rank adaptation (SoRA). At the training stage, the gate g will control the\nsparsity of Wd and Wu. At the inference stage, zero vectors in Wd and Wu, indexed by the zero entries of g,\nwould be eliminated.\nlead to from-scratch re-training. These limitations\nhighlight the importance of upgrading LoRA with\nan adaptive-rank-selection plug-in.\nSeveral remedies have been proposed in re-\ncent years to enable the flexible tuning of LoRA\nrank. For example, rather than setting a fixed rank,\nValipour et al. (Valipour et al., 2022) introduce Dy-\nLoRA in which a pre-defined discrete distribution\npB(·) is cast over a range of rank choices. This\napproach is related to but different from nested\ndropout (Rippel et al., 2014), and can be regarded\nas optimizing a mixture model with LoRA modules\nof different ranks.\nNevertheless, tuning LoRA rank straightfor-\nwardly and deterministically appears to be a more\nattractive approach. To devise such an approach,\nwe first gain a crucial hint from the connection be-\ntween a matrix’s rank and its singular value decom-\nposition (SVD). Let us denote the tunable incre-\nmental weight matrix in LoRA by ∆ := WuWd.\nWe can then formulate its SVD as\n∆p×q = Up×pΣp×qV⊤\nq×q, (2)\nin which U and V are orthogonal respectively, and\nΣ is a (rectangular) diagonal matrix with diagonal\nelements being the singular values of ∆: σ(∆) =\n{σ1 ≥σ2 ≥···≥ σmin{p,q} ≥0}. For notation\nconvenience, we reshape the diagonal of Σ into a\ncolumn vector\ng := (σ1,σ2,··· ,σmin{p,q})⊤. (3)\nThen, letting d = min{p,q}, we can reformulate\nthe LoRA forward propagation as\nz ← −∆x = U·,1:d(g ⊙V⊤\n·,1:dx), (4)\nwhere ⊙ denotes element-wise dot product\n(Hadamard product). Note that rank(∆) =∥g∥0\nwhich is the ℓ0 norm of g. Therefore, tuning\nthe LoRA rank suffices to control the sparsity of\nthe vector g. Zhang et al. precede along this\nSVD-based track with their methodology named\nAdaLoRA (Zhang et al., 2023). In AdaLoRA,\nthe elements in vector g are calibrated such that\nthe number of nonzero entries is smaller than a\npre-defined budget b. To be specific, they pre-\nserve only the entries with top-bimportance score –\nwhich is their newly proposed metric of \"sensitiv-\nity\" heuristically constructed from weight-gradient\nproduct. The nonnegativity of g entries is reason-\nably dropped since a negative gi can be simply\nreduced to the positive case by flipping the sign\nof either ui or vi. Besides, they transform the\nconstrained optimization problem into its uncon-\nstrained version by replacing the orthogonality con-\nditions U⊤U = Ip and V⊤V = Iq with a regular-\nization term\nR(U,V) =∥U⊤U −Ip∥2\nF + ∥V⊤V −Iq∥2\nF.\n(5)\nIn spite of the effectiveness demonstrated\nthrough experiments, there are still two problems\nin AdaLoRA that demand rethinking of the method-\nology and wait for further improvements. First, the\n4135\nsparsity selection criterion in AdaLoRA is based\non their newly proposed importance score relied\non the moving average of weight-gradient prod-\nuct. Despite its effectiveness in empirical study,\nthis criterion is largely heuristic, lacking theoreti-\ncal motivation. Second, both the moving average\noperation of importance scores and the gradients\nof orthogonality regularization (5) add up to addi-\ntional computation cost. Compared to AdaLoRA\nwith the aforementioned limitations, our approach,\nSoRA, serves as an amelioration with highly simpli-\nfied updating rules and is backed up by the theory\nof sparsity regularization and proximal gradient\nmethods. Detailed methodology of SoRA will be\nelaborated in the next section.\n3 Our Approach\nThe key idea of our approach, sparse low-rank adap-\ntation (SoRA), is to dynamically adjust the intrinsic\nrank in the training process with a sparse gating\nunit trained by proximal gradient method. SoRA\nadopts the previously introduced framework of low-\nrank decomposition because of its widely validated\neffectiveness and parameter efficiency.\n3.1 Sparse Low-rank Adaptation\nModule Structure. At the start of building a\nSoRA module, we pre-define a maximum accept-\nable rank rmax according to practical or research\nconcerns. Then, each SoRA module will inherit\ntwo matrices Wd ∈Rrmax×q and Wu ∈Rp×rmax\nfrom LoRA for down projection and up projection.\nThe maximum rank rmax is set to be relatively large,\nbut we will show in the subsequent paragraph how\nto tame it efficiently in a sparse sense. In fact, this\nis realized by injecting a gating unit g ∈Rrmax be-\ntween the projection matrices, which imitates the\nformulation of SVD. The forward propagation of\nthe SoRA module proceeds as follows:\nh\ndown projection\n←−−−−−−−−Wdx; (6)\nh′ gating\n←−−−g ⊙h; (7)\nz\nup projection\n←−−−−−−−Wuh′; (8)\nor, more compactly,\nz ←Wu(g ⊙(Wdx)) . (9)\nOptimization. We optimize down-projection and\nup-projection matrices with stochastic gradient\nmethods as in LoRA, while each gate g is updated\nin a different sparsity-promoting way:\ngt+1 ←Tηt·λ(gt −ηt∇gL0(∆t)), (10)\nin which L0(·) is the original loss function of the\nlanguage model, ∆ denotes the complete tunable\nparameter (including the gates), ηt >0 stands for\nthe step-size at the t-th iteration, and λ> 0 works\nas the regularization strength hyperparameter that\npromotes sparsity. Besides, Tηt·λ(·) in the above\nexpression stands for the element-wise broadcast\nof the following soft-thresholding function:\nTξ(x) :=\n\n\n\nx−ξ, x>ξ\n0, −ξ <x≤ξ\nx+ ξ, x ≤−ξ\n(11)\nwith ξ= ηt·λbeing the threshold. In practice, the\ntrue gradient ∇gL0 in (10) is approximated by its\nmini-batch stochastic counterpart.\nPost-pruning. When training is completed, we\nfurther prune the SoRA weights to drop the zeroed-\nout ranks and reduce the module back to the LoRA\nform. To be specific, for the k-th SoRA module, let\nI(k) =\n{\ni∈[1 :rmax] |g(k)\ni = 0\n}\n(12)\nbe the index of zero entry in the k-th gating vector\ng(k). We drop the I(k)-th rows of down-projection\nW(k)\nd to obtain ˜W(k)\nd , the I(k)-th columns of up-\nprojection W(k)\nu to obtain ˜W(k)\nu , as well as the\nI(k)-th entry of gateg(k) to obtain ˜g(k). In this way,\nduring inference time the k-th SoRA module will\nproceed as a usual LoRA module of rank rmax −\n|I(k)|with down-projection matrix ˜W(k)\nd and up-\nprojection matrix ˜W(k)\nu ·diag(˜g(k)).\n3.2 Interpretation and Comparison\nTheoretical interpretation. The update rule (10)\nis in fact an application of the proximal gradient\nmethod for ℓ1 loss (Chambolle et al., 1998; Beck\nand Teboulle, 2009). This follows immediately\nonce we reformulate (10) equivalently as\ngt+1 ←arg min\ng\nηt ·λ∥g∥1\n+ 1\n2∥g −(gt −ηt∇L0(gt))∥2\n2. (13)\nThe above equation (13) is exactly the proximal\ngradient update of the ℓ1 regularized loss function\nL(∆) :=L0(∆) +λ\nK∑\nk=1\n∥g(k)∥1, (14)\n4136\nwhere g(k) denotes the gate of the k-th SoRA mod-\nule. This sparsity-promoting strategy dates back\nto LASSO estimator (Tibshirani, 1996) and com-\npressed sensing (Candes et al., 2006), and is also\nadopted by many works within the realm of deep\nlearning (Wen et al., 2016; Scardapane et al., 2017).\nComparision with AdaLoRA. Inspired alike by\nSVD decomposition, our approach SoRA differs\nfrom the preceding work AdaLoRA (Zhang et al.,\n2023) in the following sense. First, we do not\napply the orthogonality regularization (5) used in\nAdaLoRA. The reason is that for rank selection\npurposes, sparsifying the gate g will be sufficient.\nSticking to the original requirements of SVD can\nresult in additional computation expenditure. Sec-\nond, the moving averaged importance score in\nAdaLoRA works as an approximation to the change\nin loss when the corresponding entry is zeroed out,\nwhich is regarded as a heuristic measurement of\nparameter \"sensitivity\". However, a model’s tempo-\nral sensitivity to a certain parameter cannot imply\nthat the parameter should be retained, since there\nis no rigorous theory for doing so. By contrast,\nour rank selection based on soft-thresholding oper-\nation (10) proceeds in a much cleaner form and is\nsoundly justified by the theory of proximal gradient\niteration. As is explained earlier this section, the\nupdating rule of SoRA module exactly follows the\nfirst principle of interpolation-complexity trade-off\nby minimizing a regularized loss objective (14).\nBeyond the formal simplicity and theoretical\nclearness is SoRA’s superior experimental perfor-\nmance achieved with fewer parameters in less wall-\nclock time, which will be presented in Section 4.\n3.3 Scheduling ξto Explore Memorization\nand Generalization\nWe dub the threshold ξas a sparsity indicator. As\nthe name implies, this parameter could directly de-\ntermine the sparsity of SoRA in the training process.\nIt can be set as a constant to heuristically control\nthe sparsity according to the budget of parame-\nters and expected performance. When dynamically\nchanging ξin the adaptation process, SoRA serves\nas an effective tool to assess the memorization and\ngeneralization under a model Mand a dataset D.\nIn other words, we can visually observe how many\nadditional parameters are required to achieve a par-\nticular point of performance given the model M\nand data D. We elaborate the fundamental idea\nas follows. The process starts by assigning a rel-\natively small value to ξ. Consequently, the SoRA\nmodel is initially \"dense\" and is trained until con-\nvergence. Once this stage is achieved, we introduce\na scheduler to incrementally increase the value of\nξ, thereby enhancing the model’s sparsity. During\nthis transition from a dense to a sparse model, it\nbecomes possible to evaluate the model’s memo-\nrization and generalization abilities by examining\nperformance on the training and testing data respec-\ntively. The procedure is reported in Algorithm 1.\nThe process can be regarded as exploring\nthe “compression loss” in the scenario of model\nadaptation. Here, “compression loss” refers to\nthe reduction in model performance due to the\nincreased sparsity, providing a measure of how\nwell the model can retain its predictive power\nunder constraints. Investigating this “compres-\nsion loss” is meaningful to understanding the\nbehavior of model adaptation and can facilitate\ndeveloping efficient, compact models that maintain\nhigh-performance levels.\nAlgorithm 1: Scheduling Algorithm of ξ\nInput : M,ξ0,ξmax,δξ,D\nOutput :M′= {M0,M1,...}\nξ←ξ0;\nM′←∅;\nM= TrainUntilConvergence(M,D,ξ);\nM′.add(M);\nξ←ξ+ ξλ;\nwhile ξ≤ξmax do\nfor epoch ←1 to 5 do\nM= Update(M,D,ξ);\nend\nM′.add(M);\nξ←ξ+ δξ;\nend\n4 Experiments\nExtensive experiments are carried out to assess\nthe effectiveness of our approach comprehensively.\nGenerally speaking, we explore two aspects in this\nsection: (1) the performance and corresponding\nanalysis as a normal parameter-efficient method;\nand (2) the investigation of memorization and gen-\neralization in virtue of the sparsity nature of SoRA.\n4.1 Experimental Settings.\nBaselines. Our baselines comprise full-parameter\nfine-tuning and other well-recognized parameter-\nefficient methods, including Adapter (Houlsby\n4137\nMethod #Params CoLA SST-2 MRPC QQP STS-B MNLI QNLI RTE Avg.\nFine-Tune 184M 69.21 95.64 89.22 92.05/89.31 91.59 89.98/89.95 93.78 82.49 87.82\nAdapter 1.41M 69.00 95.16 89.90 91.45/88.88 92.21 90.11/90.11 93.79 82.44 87.85\nBitfit 0.1M 68.70 94.38 87.16 87.86/84.20 89.71 87.45/87.45 91.90 76.12 85.18\nLoRA (r=8) 1.33M 69.73 95.57 89.71 91.95/89.26 91.86 90.47/90.46 93.76 85.32 88.38\nAdaLoRA 1.27M 70.86 95.95 90.22 92.13/88.41 91.39 90.27/90.30 94.28 87.36 88.83\nSoRA 0.91M 71.48 95.64 91.98 92.39/89.87 92.22 90.35/90.38 94.28 87.77 89.36\nTable 1: Test results of SoRA and other baselines on the GLUE benchmark. We denote the best result in bold and\nunderline the second best result. The standard deviations of results from different methods are similar and we show\nthem in Table 8 in Appendix A.4.\net al., 2019), BitFit (Zaken et al., 2021), LoRA (Hu\net al., 2021) and AdaLoRA (Zhang et al., 2023).\nWe omit the variants of the Adapter since we find\nthat the performance between them is very close.\nWe also do not include Prompt Tuning since we\nfind that it takes considerably longer time for con-\nvergence and cannot yield non-trivial performance\non our backbone models.\nDatasets For evaluation, we adaopt the\nGLUE benchmark (Wang et al.), including\nCoLA (Warstadt et al., 2019), SST-2 (Socher\net al., 2013), MRPC (Dolan and Brockett,\n2005), QQP (Wang et al.), STS-B (Wang et al.),\nMNLI (Williams et al., 2017), QNLI (Rajpurkar\net al., 2016) and RTE (Dagan et al., 2005; Haim\net al., 2006; Giampiccolo et al., 2007; Bentivogli\net al., 2009). We mainly use DeBERTaV3-base (He\net al., 2021) as the backbone model. Additionally,\nwe also use RoBERTa-large (Liu et al., 2019) for\nanalysis. Other experimental details are described\nin Appendix A.\n4.2 Results\nWe first conduct an evaluation on GLUE bench-\nmark, a widely recognized benchmark for natural\nlanguage understanding. The experimental perfor-\nmance of SoRA, as well as other baseline method-\nologies, is recorded in Table 1. We reproduce these\nmethods in our infrastructure and present the av-\nerage results drawn from 5 random seeds. Our\nfindings indicate that both AdaLoRA and SoRA\nconsistently outperform the initial LoRA baseline.\nThis underlines the validity of adaptive rank as a po-\ntent solution for enhanced model adaptation. Most\nnotably, SoRA outshines all other baselines, partic-\nularly LoRA and AdaLoRA, despite utilizing fewer\nparameters. This lends credence to the argument\nthat our proximal gradient method may constitute a\nmore efficacious and essential approach to achiev-\ning adaptive rank. For instance, on the MRPC,\nSoRA achieved an accuracy of 91.98%, surpassing\nAdaLoRA by 1.76%. On average, SoRA surpassed\nLoRA and AdaLoRA on the GLUE benchmark by\n0.98% and 0.52%, respectively, using 31.5% and\n28.3% fewer parameters. To take a closer look\nat the effectiveness of adaptive rank, we conduct\nan experiment to compare LoRA and SoRA with\ndifferent ranks in Table 2. The results affirm that\nSoRA’s superiority is consistent across different\nbudgets of parameters, that is, SoRA could out-\nperform the LoRA baseline in all settings while\nutilizing over 30% fewer parameters.\n4.3 Sparsifying Scheduler\nWe apply the sparsifying scheduler introduced in\nSection 3.3 by enlarging the sparse indicator ξ\n(starting from 1e-4) of SoRA progressively in the\nadaptation process. As illustrated in Figure 2, we\nplot the memorization and generalization curve of\nRoBERTa-large (Liu et al., 2019) on MRPC, RTE,\nSTS-B, CoLA, QNLI, and SST-2, where the mem-\norization is gauged by the performance on the train-\ning set and the generalization is measured by the\nperformance on the validation set. Intriguingly,\nwe observe a robust “compression performance\"\nacross almost all the datasets. Among these, SST-2\nemerges as the most \"compressible\" task, where the\nmodel sustains over 99% performance even when\nrestricted to 47,104 non-zero parameters. Remark-\nably, a mere 4,096 parameters can still conserve\nabove 90% memorization and generalization capa-\nbilities. As the sparsifying process proceeds, the\nmodel encounters an “inflection point” on differ-\nent data, after which the performance significantly\nplummets. This consistent phenomenon suggests\nthat there exist some critical parameters that un-\nderpin the performance and are worth further in-\nvestigation. Insight gleaned from the graph also\nindicates varying degrees of adaptation difficulty\nfor the model across different datasets. For exam-\nple, certain datasets, like CoLA, prompt an earlier\n4138\nMethod #Params CoLA SST-2 MRPC QQP STS-B MNLI QNLI RTE Avg.\nLoRAr=1 0.17M 68.60 94.95 88.24 91.20/88.37 91.41 90.09/90.28 93.35 81.29 87.23\nSoRAr=1 0.12M-29.41%70.24+1.64 95.14+0.19 89.22+0.98 91.52/88.73+0.34 91.41+0.00 90.08/90.41+0.06 93.43+0.08 83.02+1.73 87.85+0.62\nLoRAr=2 0.33M 68.93 95.04 88.43 91.59/88.87 91.53 90.35/90.30 93.63 84.17 87.79\nSoRAr=2 0.25M-24.24%70.22+1.29 95.64+0.60 89.71+1.28 91.88/89.12+0.27 91.63+0.10 90.37/90.51+0.12 93.78+0.15 85.18+1.01 88.39+0.60\nLoRAr=4 0.66M 69.27 95.55 89.22 91.40/88.41 91.69 90.36/90.49 93.83 82.01 87.74\nSoRAr=4 0.47M-28.79%71.05+1.78 95.57+0.02 90.20+0.98 92.06/89.44+0.85 91.76+0.07 90.38/90.43-0.02 93.92+0.09 86.04+4.03 88.71+0.97\nLoRAr=8 1.33M 69.73 95.57 89.71 91.95/89.26 91.86 90.47/90.46 93.76 85.32 88.38\nSoRAr=8 0.91M-31.58%71.48+1.75 95.64+0.07 91.98+2.27 92.39/89.87+0.53 92.22+0.36 90.35/90.38-0.10 94.28+0.52 87.77+2.45 89.36+0.98\nLoRAr=16 2.65M 69.87 95.53 89.91 92.22/89.63 91.79 90.55/90.31 93.46 87.05 88.62\nSoRAr=16 1.78M-32.83%71.93+2.06 95.61+0.08 92.00+2.09 92.37/89.84+0.18 92.05+0.26 90.34/90.47-0.03 94.11+0.65 87.41+0.36 89.33+0.71\nTable 2: Test results and number of parameters of SoRA initialized with differentrmax on the GLUE benchmark,\ncompared with LoRA of the same rank. The standard deviations of results from different methods are similar and\nwe show them in Table 9 in Appendix A.4.\nFigure 2: The memorization and generalization curve on six datasets. The \"Param\" axis indicates the number of\nnon-zero parameters. The sparsity indicator ξincreases every 5 epochs.\nand more pronounced decline in performance com-\npared to others. Another finding is that the trend\nof memorization and generalization is consistent\nin the sparsifying procedure, which is aligned with\nintuition. Our observations also indicate a tendency\nfor the parameters of intermediate and deep layers\nto maintain their density, while those of the shallow\nlayers show a higher propensity towards sparsity.\n4.4 Rank Analysis\nAn intuitive statement is that a single model suf-\nfers from varying extents of difficulty when being\nadapted to different downstream datasets. Concur-\nrently, it is evident that not all parameters within the\nmodel carry equal importance—some are more crit-\nical to performance than others. In this section, we\nvisualize the final ranks after the training process\nconverges with SoRA on four datasets in Figure\n3. Quite obviously, the trained parameter matrices\non QQP are exceedingly dense and others do not\nexhibit such density, which echos the existence of\ndifferent levels of difficulties. This phenomenon\nalso suggests that leveraging the performance and\nthe parameter budget does not have an invariable\nconstant law, but needs specific considerations in\ndifferent situations.\n4.5 Applying SoRA to Different Weights\nIn our experiments in Table 1, we utilize LoRA,\nAdaLoRA, and SoRA on all weight matrices to\nenhance performance. It should be noted that\nthe performance may fluctuate when parameter-\nefficient fine-tuning is applied to various positions\nwithin the model, as evidenced by previous\n4139\nFigure 3: The final ranks after training with SoRA on four datasets (l.e., QQP, MNLI, QNLI, and MRPC). The\nX-axis is the index of DeBERTaV3-base layers, and the Y-axis indicates different layers SoRA applies to.\nresearch (Zaken et al., 2021; Hu et al., 2022;\nZhang et al., 2023). We carry out such ablation\nexperiments with SoRA on three datasets to\ninvestigate the impact. Although SoRA is not a\nbudget-oriented method, we adjust λto approxi-\nmately equate the retained non-zero parameters.\nAs reported in Table 3, in most cases, the applica-\ntion of SoRA to all weight matrices resulted in a\nconsiderable improvement in performance com-\npared to the application of merely one or several\ntypes of weights, which suggest that uniformly\napplying SoRA to all weight matrices can serve\nas a beneficial strategy. And merely applying\nSoRA to WQ,K will experience considerable\nperformance drop, which is aligned with LoRA.\n#Params CoLA MRPC STS-B\nWQ,K 0.80M 65.56±2.24 86.43±0.83 72.30±2.61\nWQ,K,V 0.69M 69.07±2.17 88.24±1.84 90.82±0.70\nWQ,K,V,A.O 0.87M 71.99±1.30 90.20±1.83 91.71±0.34\nAll 0.77M 71.48±1.17 91.98±1.16 92.22±0.24\nTable 3: Test results that applying SoRA to different\nweights. Q, K, V , and A.O represent query, key, value\nand attention output layers respectively. #Params\nmeans the number of parameters that would remain\nafter training.\n4.6 Efficiency Analysis\nWe elaborate that SoRA is a theoretically clear and\ncomputation-efficient method in Section 3.2. To\nevaluate this, we measure the efficiency of SoRA\nand AdaLora in this section. We compute the clock\ntime of average epoch of AdaLoRA and SoRA on\nsix datasets with identical compute infrastructure\nand batch size. As shown in Table 4, SoRA takes\nabout 30% less training time than AdaLoRA. In\ncertain instances, such as the CoLA, QNLI, and\nRTE datasets, SoRA exhibits a significant edge in\nefficiency over its counterpart. Conversely, while\nSoRA consistently outpaces AdaLoRA on other\ndatasets, the margin is not as wide. This discrep-\nancy could be attributable to the different rank dis-\ntributions of AdaLoRA and SoRA under varying\ntasks. Such distributions exert influence on the\ncalculation of regularization in AdaLoRA.\nDatasets AdaLoRA (s) SoRA (s)\nCoLA 160.2 57.2 -64.29%\nSST-2 491.0 433.0 -11.81%\nMRPC 27.3 24.8 -9.16%\nSTS-B 48.2 38.4 -20.33%\nQNLI 1001.0 676.3 -32.44%\nRTE 79.8 45.1 -43.48%\nAvg. 301.3 212.5 -29.47%\nTable 4: The average training time per epoch on six\ndatasets. For each task, the experiments with AdaLoRA\nand SoRA have the same batch size 32.\n5 Conclusion\nOur work presents Sparse Low-Rank Adapta-\ntion (SoRA), an innovative method for parameter-\nefficient fine-tuning large pre-trained language\nmodels. Upon the hypothesis that the adaptation\nprocess could be intrinsically sparse, we offer a\ndynamic alternative rank by introducing an opti-\nmizable gate with a proximal gradient method to\n4140\nregulate sparsity, thereby expanding the optimiza-\ntion space while enhancing parameter efficiency.\nThe method is simple and theoretically supported\nwith promising performance across various tasks.\nUtilizing SoRA as a tool, we propose a sparsify-\ning scheduler to analyze the correlation between\nparameters and memorization and generalization.\nLimitations\nDespite the encouraging results demonstrated by\nSoRA, there are certain limitations in our current\nstudy that are worth acknowledging. This paper\nonly evaluates the effectiveness of SoRA on tra-\nditional natural language processing tasks. How-\never, recent studies demonstrate that parameter-\nefficient methods could be applied to cross-modal\nor instruction-tuning scenarios. In those cases, how\nthe sparsity of SoRA is displayed is still unknown\nand worth investigating. Our sparsifying scheduler\ncould provide insights on the adaptation process of\nlanguage models, but it is still challenging to rigor-\nously explain the procedure and more efficiently to\nassess the difficulty of an adaptation process.\nAcknowledgements\nThis work is supported by the National Key R&D\nProgram of China (No. 2022ZD0119101), Na-\ntional Natural Science Foundation of China (No.\n62236004), the Young Elite Scientists Sponsorship\nProgram by CAST, and Institute Guo Qiang at Ts-\ninghua University.\nReferences\nAmir Beck and Marc Teboulle. 2009. A fast itera-\ntive shrinkage-thresholding algorithm for linear in-\nverse problems. SIAM journal on imaging sciences,\n2(1):183–202.\nLuisa Bentivogli, Peter Clark, Ido Dagan, and Danilo\nGiampiccolo. 2009. The fifth pascal recognizing\ntextual entailment challenge. In Proceedings of Text\nAnalysis Conference.\nRishi Bommasani, Drew A Hudson, Ehsan Adeli,\nRuss Altman, Simran Arora, Sydney von Arx,\nMichael S Bernstein, Jeannette Bohg, Antoine Bosse-\nlut, Emma Brunskill, et al. 2021. On the opportuni-\nties and risks of foundation models. arXiv preprint\narXiv:2108.07258.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems 33:\nAnnual Conference on Neural Information Process-\ning Systems 2020, NeurIPS 2020, December 6-12,\n2020, virtual.\nEmmanuel J Candes, Justin K Romberg, and Terence\nTao. 2006. Stable signal recovery from incomplete\nand inaccurate measurements. Communications on\nPure and Applied Mathematics: A Journal Issued\nby the Courant Institute of Mathematical Sciences,\n59(8):1207–1223.\nAntonin Chambolle, Ronald A De V ore, Nam-Yong Lee,\nand Bradley J Lucier. 1998. Nonlinear wavelet im-\nage processing: variational problems, compression,\nand noise removal through wavelet shrinkage. IEEE\nTransactions on Image Processing, 7(3):319–335.\nIdo Dagan, Oren Glickman, and Bernardo Magnini.\n2005. The pascal recognising textual entailment chal-\nlenge. In Machine Learning Challenges Workshop,\npages 177–190. Springer.\nTim Dettmers, Artidoro Pagnoni, Ari Holtzman, and\nLuke Zettlemoyer. 2023. Qlora: Efficient finetuning\nof quantized llms. arXiv preprint arXiv:2305.14314.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nNing Ding, Yujia Qin, Guang Yang, Fuchao Wei,\nZonghan Yang, Yusheng Su, Shengding Hu, Yulin\nChen, Chi-Min Chan, Weize Chen, et al. 2023.\nParameter-efficient fine-tuning of large-scale pre-\ntrained language models. Nature Machine Intelli-\ngence, 5(3):220–235.\nBill Dolan and Chris Brockett. 2005. Automati-\ncally constructing a corpus of sentential paraphrases.\nIn Third International Workshop on Paraphrasing\n(IWP2005).\nDan Friedman, Ben Dodge, and Danqi Chen. 2021.\nSingle-dataset experts for multi-dataset question an-\nswering. ArXiv preprint, abs/2109.13880.\nPeng Gao, Jiaming Han, Renrui Zhang, Ziyi Lin, Shijie\nGeng, Aojun Zhou, Wei Zhang, Pan Lu, Conghui\nHe, Xiangyu Yue, et al. 2023. Llama-adapter v2:\nParameter-efficient visual instruction model. arXiv\npreprint arXiv:2304.15010.\n4141\nDanilo Giampiccolo, Bernardo Magnini, Ido Dagan, and\nBill Dolan. 2007. The third PASCAL recognizing\ntextual entailment challenge. In Proceedings of the\nACL-PASCAL Workshop on Textual Entailment and\nParaphrasing, pages 1–9, Prague. Association for\nComputational Linguistics.\nDemi Guo, Alexander Rush, and Yoon Kim. 2021.\nParameter-efficient transfer learning with diff prun-\ning. In Proceedings of the 59th Annual Meeting of the\nAssociation for Computational Linguistics and the\n11th International Joint Conference on Natural Lan-\nguage Processing (Volume 1: Long Papers), pages\n4884–4896, Online. Association for Computational\nLinguistics.\nR Bar Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo\nGiampiccolo, Bernardo Magnini, and Idan Szpektor.\n2006. The second pascal recognising textual entail-\nment challenge. In Proceedings of the Second PAS-\nCAL Challenges Workshop on Recognising Textual\nEntailment, volume 7.\nXu Han, Zhengyan Zhang, Ning Ding, Yuxian Gu, Xiao\nLiu, Yuqi Huo, Jiezhong Qiu, Liang Zhang, Wentao\nHan, Minlie Huang, Qin Jin, Yanyan Lan, Yang Liu,\nZhiyuan Liu, Zhiwu Lu, Xipeng Qiu, Ruihua Song,\nJie Tang, Ji-Rong Wen, Jinhui Yuan, Wayne Xin\nZhao, and Jun Zhu. 2021. Pre-trained models: Past,\npresent and future. AI Open.\nJunxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-\nKirkpatrick, and Graham Neubig. 2022. Towards a\nunified view of parameter-efficient transfer learning.\nIn International Conference on Learning Representa-\ntions.\nPengcheng He, Jianfeng Gao, and Weizhu Chen. 2021.\nDebertav3: Improving deberta using electra-style pre-\ntraining with gradient-disentangled embedding shar-\ning. arXiv preprint arXiv:2111.09543.\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and\nWeizhu Chen. 2020. Deberta: Decoding-enhanced\nbert with disentangled attention. arXiv preprint\narXiv:2006.03654.\nNeil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski,\nBruna Morrone, Quentin de Laroussilhe, Andrea Ges-\nmundo, Mona Attariyan, and Sylvain Gelly. 2019.\nParameter-efficient transfer learning for NLP. In Pro-\nceedings of the 36th International Conference on Ma-\nchine Learning, ICML 2019, 9-15 June 2019, Long\nBeach, California, USA, volume 97 of Proceedings\nof Machine Learning Research, pages 2790–2799.\nPMLR.\nEdward J Hu, Yelong Shen, Phillip Wallis, Zeyuan\nAllen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,\nand Weizhu Chen. 2021. Lora: Low-rank adap-\ntation of large language models. ArXiv preprint,\nabs/2106.09685.\nShengding Hu, Ning Ding, Weilin Zhao, Xingtai Lv,\nZhen Zhang, Zhiyuan Liu, and Maosong Sun. 2023.\nOpendelta: A plug-and-play library for parameter-\nefficient adaptation of pre-trained models. arXiv\npreprint arXiv:2307.03084.\nShengding Hu, Zhen Zhang, Ning Ding, Yadao Wang,\nYasheng Wang, Zhiyuan Liu, and Maosong Sun.\n2022. Sparse structure search for parameter-efficient\ntuning. arXiv preprint arXiv:2206.07382.\nRabeeh Karimi Mahabadi, James Henderson, and Se-\nbastian Ruder. 2021. Compacter: Efficient low-rank\nhypercomplex adapter layers. Advances in Neural\nInformation Processing Systems, 34:1022–1035.\nBrian Lester, Rami Al-Rfou, and Noah Constant. 2021.\nThe power of scale for parameter-efficient prompt\ntuning. ArXiv preprint, abs/2104.08691.\nQuentin Lhoest, Albert Villanova del Moral, Yacine\nJernite, Abhishek Thakur, Patrick von Platen, Suraj\nPatil, Julien Chaumond, Mariama Drame, Julien Plu,\nLewis Tunstall, Joe Davison, Mario Šaško, Gun-\njan Chhablani, Bhavitvya Malik, Simon Brandeis,\nTeven Le Scao, Victor Sanh, Canwen Xu, Nicolas\nPatry, Angelina McMillan-Major, Philipp Schmid,\nSylvain Gugger, Clément Delangue, Théo Matus-\nsière, Lysandre Debut, Stas Bekman, Pierric Cis-\ntac, Thibault Goehringer, Victor Mustar, François\nLagunas, Alexander Rush, and Thomas Wolf. 2021.\nDatasets: A community library for natural language\nprocessing. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Process-\ning: System Demonstrations, pages 175–184, Online\nand Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nXiang Lisa Li and Percy Liang. 2021. Prefix-tuning:\nOptimizing continuous prompts for generation. In\nProceedings of the 59th Annual Meeting of the Asso-\nciation for Computational Linguistics and the 11th\nInternational Joint Conference on Natural Language\nProcessing (Volume 1: Long Papers), pages 4582–\n4597, Online. Association for Computational Lin-\nguistics.\nPeiyu Liu, Ze-Feng Gao, Wayne Xin Zhao, Zhong-Yi\nLu, and Ji-Rong Wen. 2021. Enabling lightweight\nfine-tuning for pre-trained language model compres-\nsion based on matrix product operators. arXiv\npreprint arXiv:2106.02205.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. ArXiv preprint, abs/1907.11692.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, et al. 2019. Pytorch: An imperative style,\nhigh-performance deep learning library. Advances in\nneural information processing systems, 32.\n4142\nYujia Qin, Xiaozhi Wang, Yusheng Su, Yankai Lin,\nNing Ding, Zhiyuan Liu, Juan-Zi Li, Lei Hou, Peng\nLi, Maosong Sun, and Jie Zhou. 2021. Exploring\nlow-dimensional intrinsic task subspace via prompt\ntuning. ArXiv, abs/2110.07867.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016. Squad: 100,000+ questions\nfor machine comprehension of text. arXiv preprint\narXiv:1606.05250.\nOren Rippel, Michael Gelbart, and Ryan Adams. 2014.\nLearning ordered representations with nested dropout.\nIn International Conference on Machine Learning,\npages 1746–1754. PMLR.\nSimone Scardapane, Danilo Comminiello, Amir Hus-\nsain, and Aurelio Uncini. 2017. Group sparse regular-\nization for deep neural networks. Neurocomputing,\n241:81–89.\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D Manning, Andrew Y Ng, and\nChristopher Potts. 2013. Recursive deep models for\nsemantic compositionality over a sentiment treebank.\nIn Proceedings of the 2013 conference on empiri-\ncal methods in natural language processing, pages\n1631–1642.\nYusheng Su, Chi-Min Chan, Jiali Cheng, Yujia Qin,\nYankai Lin, Shengding Hu, Zonghan Yang, Ning\nDing, Zhiyuan Liu, and Maosong Sun. 2023. Ar-\nbitrary few parameters are good enough for adapt-\ning large-scale pre-trained language models. arXiv\npreprint arXiv:2306.02320.\nYi-Lin Sung, Jaemin Cho, and Mohit Bansal. 2022.\nLst: Ladder side-tuning for parameter and mem-\nory efficient transfer learning. arXiv preprint\narXiv:2206.06522.\nRobert Tibshirani. 1996. Regression shrinkage and se-\nlection via the lasso. Journal of the Royal Statistical\nSociety: Series B (Methodological), 58(1):267–288.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro,\nFaisal Azhar, et al. 2023. Llama: Open and effi-\ncient foundation language models. arXiv preprint\narXiv:2302.13971.\nMojtaba Valipour, Mehdi Rezagholizadeh, Ivan\nKobyzev, and Ali Ghodsi. 2022. Dylora: Parameter\nefficient tuning of pre-trained models using dynamic\nsearch-free low-rank adaptation. arXiv preprint\narXiv:2210.07558.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel R Bowman. Glue:\nA multi-task benchmark and analysis platform for\nnatural language understanding.\nAlex Warstadt, Amanpreet Singh, and Samuel R Bow-\nman. 2019. Neural network acceptability judgments.\nTransactions of the Association for Computational\nLinguistics, 7:625–641.\nWei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen,\nand Hai Li. 2016. Learning structured sparsity in\ndeep neural networks. Advances in neural informa-\ntion processing systems, 29.\nAdina Williams, Nikita Nangia, and Samuel R Bow-\nman. 2017. A broad-coverage challenge corpus for\nsentence understanding through inference. arXiv\npreprint arXiv:1704.05426.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,\net al. 2020. Transformers: State-of-the-art natural\nlanguage processing. In Proceedings of the 2020 con-\nference on empirical methods in natural language\nprocessing: system demonstrations, pages 38–45.\nElad Ben Zaken, Shauli Ravfogel, and Yoav Gold-\nberg. 2021. Bitfit: Simple parameter-efficient\nfine-tuning for transformer-based masked language-\nmodels. ArXiv preprint, abs/2106.10199.\nQingru Zhang, Minshuo Chen, Alexander Bukharin,\nPengcheng He, Yu Cheng, Weizhu Chen, and\nTuo Zhao. 2023. Adaptive budget allocation for\nparameter-efficient fine-tuning. arXiv preprint\narXiv:2303.10512.\nMengjie Zhao, Tao Lin, Fei Mi, Martin Jaggi, and Hin-\nrich Schütze. 2020. Masking as an efficient alterna-\ntive to finetuning for pretrained language models. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 2226–2241, Online. Association for Computa-\ntional Linguistics.\n4143\nA Experimental Details\nA.1 Datasets\nThe GLUE benchmark, consisting of\nCoLA (Warstadt et al., 2019), SST-2 (Socher\net al., 2013), MRPC (Dolan and Brockett,\n2005), QQP (Wang et al.), STS-B (Wang et al.),\nMNLI (Williams et al., 2017), QNLI (Rajpurkar\net al., 2016) and RTE (Dagan et al., 2005; Haim\net al., 2006; Giampiccolo et al., 2007; Bentivogli\net al., 2009), is used for natural language under-\nstanding. The details and the evaluation metric\nare reported in Table 5. We source each dataset\nfrom Huggingface Datasets (Lhoest et al., 2021)\nand utilize the full dataset for our experiments.\nFor almost all experiments, we run 5 times using\ndifferent random seeds and report the average\nresults in order to ensure statistical significance.\nDataset #Train #Valid #Test Metric\nCoLA 8.5k 1,043 1,063 Mcc\nSST-2 67k 872 1.8k Acc\nMRPC 3.7k 408 1.7k Acc\nQQP 364k 40.4k 391k Acc/F1\nSTS-B 5.7k 1.5k 1.4k Corr\nMNLI 393k 9.8k/9.8k 9.8k/9.8k Acc(m/mm)\nQNLI 105k 5.5k 5.5k Acc\nRTE 2.5k 277 3k Acc\nTable 5: The size and evaluation metric of the datasets\nin GLUE benchmark. \"Mcc\", \"Acc\", \"F1\" and \"Corr\"\nrepresent matthews correlation coefficient, accuracy, the\nF1 score and pearson correlation coefficient respectively.\nAnd \"Acc(m/mm)\" represents the results corresponding\nto matched and mismatched datasets of MNLI while the\nmetric is accuracy.\nA.2 Implementation Details\nRegarding hyper-parameters, we set the learning\nrate to 8e-4. Based on the size and training conver-\ngence speed of the datasets, we set the number of\nepochs for CoLA, MRPC, and STS-B to 20, and\nthe number of epochs for the remaining tasks to 10.\nAs for RTE, we reference the settings of Friedman\net al. 2021, which entail a learning rate of 1.2e-3\nand an epoch count of 50. We set λto 0.1 in all\nour experiments, and select ξ with a grid search\nin {1e-5, 5e-5, 1e-4}. When dealing with MRPC,\nRTE, and STS-B datasets, a common trick in cer-\ntain studies is that using the best model checkpoint\non the MNLI dataset could boost the performance.\nIn our experiments, we do not use this strategy and\ninstead opt for standard initializations across all\nmodels.\nThe Huggingface Transformers (Wolf et al.,\n2020) and PyTorch (Paszke et al., 2019) are utilized\nfor all the experiments. We use NVIDIA GeForce\nRTX 3090 (maximum GPU memory=24268MB)\nand the application of SoRA with a batch size of 8\noccupies 6110MB GPU memory on average.\nA.3 Optimization of Hyperparameters\nIn this section, we delve into the optimization of\nhyperparameters. The results of different rmax are\nproved in Table 2 and we supplement the results of\ntwo other important hyperparameters, ξ and η in\nthe Table 6 and Table 7. The performance of SoRA\nis highly stable with respect to different choices of\nξand η. And for each fixed ξand η, the variance of\nperformance is rather low. In general, we suggest\nsetting ξto 1e-4 level and ηaround 1e-1∼1e-3.\nξ COLA STS-B\n1e-3 63.25±0.71 90.85±0.53\n8e-4 64.98±1.25 91.12±0.38\n5e-4 66.94±0.98 91.61±0.24\n3e-4 68.61±1.23 92.22±0.24\n1e-4 70.18±1.05 92.01±0.14\n8e-5 68.78±1.43 92.00±0.15\n5e-5 71.48±1.17 92.02±0.18\n3e-5 69.68±1.94 92.18±0.15\n1e-5 69.65±1.93 92.08±0.15\nTable 6: Test results of the optimization experiments on\ndifferent ξ.\nηt COLA STS-B\n10 69.06±2.18 91.75±0.41\n1 70.54±1.15 92.02±0.20\n0.1 71.48±1.17 92.22±0.24\n0.01 68.78±2.29 92.06±0.17\n0.001 69.86±1.54 91.83±0.22\n0.0001 69.70±1.70 92.13±0.40\nTable 7: Test results of the optimization experiments on\ndifferent ηt.\nA.4 Results with Standard Deviations\nThe test results in Table 1 are shown in Table 8,\nand results in Table 2 are shown in Table 9.\n4144\nMethod #Params CoLA SST-2 MRPC QQP STS-B MNLI QNLI RTE Avg.\nFine-Tune 184M 69.21\n(2.24)\n95.64\n(0.52)\n89.22\n(0.69)\n92.05/89.31\n(0.09)/(0.07)\n91.59\n(0.47)\n89.98/89.95\n(0.06)/(0.33)\n93.78\n(0.02)\n82.49\n(1.48) 87.82\nAdapter 1.41M 69.00\n(0.91)\n95.16\n(0.46)\n89.90\n(2.10)\n91.45/88.88\n(0.18)/(0.40)\n92.21\n(0.33)\n90.11/90.11\n(0.57)/(0.57)\n93.79\n(0.07)\n82.44\n(1.74) 87.85\nBitfit 0.1M 68.70\n(1.85)\n94.38\n(0.28)\n87.16\n(0.58)\n87.86/84.20\n(0.52)/(0.74)\n89.71\n(0.58)\n87.45/87.45\n(0.76)/(0.76)\n91.90\n(0.14)\n76.12\n(1.54) 85.18\nLoRA (r=8) 1.33M 69.73\n(1.42)\n95.57\n(0.21)\n89.71\n(1.32)\n91.95/89.26\n(0.12)/(0.18)\n91.86\n(0.29)\n90.47/90.46\n(0.23)/(0.12)\n93.76\n(0.36)\n85.32\n(0.86) 88.38\nAdaLoRA 1.27M 70.86\n(1.43)\n95.95\n(0.37)\n90.22\n(0.40)\n92.13/88.41\n(0.06)/(0.05)\n91.39\n(0.25)\n90.27/90.30\n(0.11)/(0.18)\n94.28\n(0.11)\n87.36\n(0.30) 88.83\nSoRA 0.91M 71.48\n(1.17)\n95.64\n(0.23)\n91.98\n(1.16)\n92.39/89.87\n(0.17)/(0.27)\n92.22\n(0.24)\n90.35/90.38\n(0.09)/(0.12)\n94.28\n(0.06)\n87.77\n(1.56) 89.36\nTable 8: Test results of SoRA and other baselines on the GLUE benchmark. We denote the best result in bold and\nunderline the second best result. The standard deviation is provided in parentheses.\nMethod #Params CoLA SST-2 MRPC QQP STS-B MNLI QNLI RTE Avg.\nLoRAr=1 0.17M 68.60\n(1.58)\n94.95\n(0.20)\n88.24\n(1.42)\n91.20/88.37\n(0.20/0.33)\n91.41\n(0.29)\n90.09/90.28\n(0.16/0.14)\n93.35\n(0.34)\n81.29\n(2.83) 87.23\nSoRAr=1 0.12M 70.24\n(1.10)\n95.14\n(0.25)\n89.22\n(2.12)\n91.52/88.73\n(0.14/0.22)\n91.41\n(0.29)\n90.08/90.41\n(0.18/0.12)\n93.43\n(0.33)\n83.02\n(2.47) 87.85\nLoRAr=2 0.33M 68.93\n(1.50)\n95.04\n(0.37)\n88.43\n(1.06)\n91.59/88.87\n(0.06/0.12)\n91.53\n(0.32)\n90.35/90.30\n(0.13/0.17)\n93.63\n(0.37)\n84.17\n(1.20) 87.79\nSoRAr=2 0.25M 70.22\n(1.03)\n95.64\n(0.09)\n89.71\n(0.81)\n91.88/89.12\n(0.13/0.17)\n91.63\n(0.30)\n90.37/90.51\n(0.06/0.08)\n93.78\n(0.23)\n85.18\n(0.73) 88.39\nLoRAr=4 0.66M 69.27\n(2.22)\n95.55\n(0.56)\n89.22\n(1.64)\n91.40/88.41\n(0.17/0.27)\n91.69\n(0.24)\n90.36/90.49\n(0.12/0.32)\n93.83\n(0.35)\n82.01\n(1.76) 87.74\nSoRAr=4 0.47M 71.05\n(0.74)\n95.57\n(0.05)\n90.20\n(1.60)\n92.06/89.44\n(0.17/0.14)\n91.76\n(0.17)\n90.38/90.43\n(0.04/0.25)\n93.92\n(0.09)\n86.04\n(1.96) 88.71\nLoRAr=8 1.33M 69.73\n(1.42)\n95.57\n(0.21)\n89.71\n(1.32)\n91.95/89.26\n(0.12/0.18)\n91.86\n(0.29)\n90.47/90.46\n(0.23/0.12)\n93.76\n(0.36)\n85.32\n(0.86) 88.38\nSoRAr=8 0.91M 71.48\n(1.17)\n95.64\n(0.23)\n91.98\n(1.16)\n92.39/89.87\n(0.17/0.27)\n92.22\n(0.24)\n90.35/90.38\n(0.09/0.12)\n94.28\n(0.06)\n87.77\n(1.56) 89.36\nLoRAr=16 2.65M 69.87\n(0.86)\n95.53\n(0.15)\n89.91\n(1.69)\n92.22/89.63\n(0.05/0.04)\n91.79\n(0.16)\n90.55/90.31\n(0.10/0.03)\n93.46\n(0.12)\n87.05\n(3.11) 88.62\nSoRAr=16 1.78M 71.93\n(0.97)\n95.61\n(0.11)\n92.00\n(0.23)\n92.37/89.84\n(0.15/0.19)\n92.05\n(0.16)\n90.34/90.47\n(0.13/0.04)\n94.11\n(0.07)\n87.41\n(1.08) 89.33\nTable 9: Test results and number of parameters of SoRA initialized with differentrmax on the GLUE benchmark,\ncompared with LoRA of the same rank. The standard deviation is provided in parentheses.\n4145"
}