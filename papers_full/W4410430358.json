{
  "title": "From prompt to platform: an agentic AI workflow for healthcare simulation scenario design",
  "url": "https://openalex.org/W4410430358",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2132593481",
      "name": "Federico Lorenzo Barra",
      "affiliations": [
        "Università degli Studi del Piemonte Orientale “Amedeo Avogadro”",
        "Azienda Ospedaliero Universitaria Maggiore della Carita"
      ]
    },
    {
      "id": "https://openalex.org/A5114879489",
      "name": "Giovanna Rodella",
      "affiliations": [
        "Università degli Studi del Piemonte Orientale “Amedeo Avogadro”"
      ]
    },
    {
      "id": "https://openalex.org/A2103124656",
      "name": "Alessandro Costa",
      "affiliations": [
        "Presidio Ospedaliero",
        "Università degli Studi del Piemonte Orientale “Amedeo Avogadro”"
      ]
    },
    {
      "id": "https://openalex.org/A5012810060",
      "name": "Antonio Scalogna",
      "affiliations": [
        "Università degli Studi del Piemonte Orientale “Amedeo Avogadro”"
      ]
    },
    {
      "id": "https://openalex.org/A1451817826",
      "name": "Luca Carenzo",
      "affiliations": [
        "IRCCS Humanitas Research Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A3003730503",
      "name": "Alice Monzani",
      "affiliations": [
        "Università degli Studi del Piemonte Orientale “Amedeo Avogadro”"
      ]
    },
    {
      "id": "https://openalex.org/A2132756300",
      "name": "FRANCESCO DELLA CORTE",
      "affiliations": [
        "Università degli Studi del Piemonte Orientale “Amedeo Avogadro”"
      ]
    },
    {
      "id": "https://openalex.org/A2132593481",
      "name": "Federico Lorenzo Barra",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5114879489",
      "name": "Giovanna Rodella",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2103124656",
      "name": "Alessandro Costa",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5012810060",
      "name": "Antonio Scalogna",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1451817826",
      "name": "Luca Carenzo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3003730503",
      "name": "Alice Monzani",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2132756300",
      "name": "FRANCESCO DELLA CORTE",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2285308027",
    "https://openalex.org/W4400348041",
    "https://openalex.org/W2892498858",
    "https://openalex.org/W4382319862",
    "https://openalex.org/W4396667204",
    "https://openalex.org/W4360955159",
    "https://openalex.org/W4400145417",
    "https://openalex.org/W4404844219",
    "https://openalex.org/W4400270729",
    "https://openalex.org/W4387002307",
    "https://openalex.org/W4210970171",
    "https://openalex.org/W4391308235",
    "https://openalex.org/W2618274490",
    "https://openalex.org/W4396600931"
  ],
  "abstract": "Abstract Healthcare simulation scenario design remains a resource-intensive process, demanding significant time and expertise from educators. This article presents an innovative AI-driven agentic workflow for healthcare simulation scenario development, bridging technical capability with pedagogical effectiveness. The system evolved from an initial ChatGPT-based prototype to a sophisticated platform implementation utilizing multiple specialized AI agents. Each agent addresses specific sub-tasks, including objective formulation, patient narrative generation, diagnostic data creation, and debriefing point development. The workflow employs advanced AI methodologies including decomposition, prompt chaining, parallelization, retrieval-augmented generation, and iterative refinement, all orchestrated through a user-friendly conversational interface. Critical to implementation was the demonstration that healthcare professionals with modest technical skills could develop these complex workflows without specialized AI expertise. The system ensures consistent adherence to established simulation guidelines, including INACSL Standards of Best Practice and ASPiH Standards Framework, while significantly reducing scenario development time by approximately 70–80%. Designed for broad applicability across diverse clinical settings and learner levels, the workflow incorporates multilingual capabilities for global application. Potential pitfalls include the necessity for rigorous review of AI-generated content and awareness of bias in model outputs. Key lessons learned emphasize interdisciplinary collaboration, systematic prompt refinement, essential human oversight, and the democratization of AI tools in healthcare education. This innovation demonstrates how sophisticated agentic AI implementations can transform healthcare simulation through enhanced efficiency, consistency, and accessibility without sacrificing pedagogical integrity.",
  "full_text": "Barra et al. Advances in Simulation           (2025) 10:29  \nhttps://doi.org/10.1186/s41077-025-00357-z\nINNOVATION Open Access\n© The Author(s) 2025. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory \nregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this \nlicence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecom-\nmons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\nFrom prompt to platform: an agentic AI \nworkflow for healthcare simulation scenario \ndesign\nFederico Lorenzo Barra1,2, Giovanna Rodella2, Alessandro Costa2,3, Antonio Scalogna2, Luca Carenzo4*  , \nAlice Monzani2,5 and Francesco Della Corte2 \nAbstract \nHealthcare simulation scenario design remains a resource-intensive process, demanding significant time and exper-\ntise from educators. This article presents an innovative AI-driven agentic workflow for healthcare simulation sce-\nnario development, bridging technical capability with pedagogical effectiveness. The system evolved from an initial \nChatGPT-based prototype to a sophisticated platform implementation utilizing multiple specialized AI agents. Each \nagent addresses specific sub-tasks, including objective formulation, patient narrative generation, diagnostic data \ncreation, and debriefing point development. The workflow employs advanced AI methodologies including decom-\nposition, prompt chaining, parallelization, retrieval-augmented generation, and iterative refinement, all orchestrated \nthrough a user-friendly conversational interface. Critical to implementation was the demonstration that healthcare \nprofessionals with modest technical skills could develop these complex workflows without specialized AI expertise. \nThe system ensures consistent adherence to established simulation guidelines, including INACSL Standards of Best \nPractice and ASPiH Standards Framework, while significantly reducing scenario development time by approximately \n70–80%. Designed for broad applicability across diverse clinical settings and learner levels, the workflow incorporates \nmultilingual capabilities for global application. Potential pitfalls include the necessity for rigorous review of AI-gener-\nated content and awareness of bias in model outputs. Key lessons learned emphasize interdisciplinary collaboration, \nsystematic prompt refinement, essential human oversight, and the democratization of AI tools in healthcare educa-\ntion. This innovation demonstrates how sophisticated agentic AI implementations can transform healthcare simula-\ntion through enhanced efficiency, consistency, and accessibility without sacrificing pedagogical integrity.\nKeywords Artificial intelligence, AI, Agentic workflow, Scenario design, Healthcare simulation, Automation, N8n, \nChatGPT, INACSL standards, ASPiH standards\n*Correspondence:\nLuca Carenzo\nluca.carenzo@hunimed.eu\nFull list of author information is available at the end of the article\nPage 2 of 9Barra et al. Advances in Simulation           (2025) 10:29 \nIntroduction\nThe cornerstone of effective healthcare simulation lies \nin meticulously crafted scenarios that provide realistic, \ncontrolled environments for learners to develop clinical \nskills and practice decision-making [1–3]. Traditionally, \nthe creation of these high-fidelity scenarios has been a \nresource-intensive process, demanding significant time \nand expertise from simulation educators. The often-\nquoted figure of 24 h of preparation for a 10–20 min sce -\nnario underscores the substantial investment required [1, \n4]. The recent advent of advanced large language mod -\nels (LLMs), such as ChatGPT, has sparked considerable \ninterest in their potential to revolutionize this process \n[5–8]. Early explorations suggest that LLMs can contrib -\nute to streamlining scenario development, potentially \noffering insights that conventional methods might miss. \nHowever, concerns regarding the accuracy, relevance, \nand structural coherence of AI-generated content have \nalso been raised, necessitating careful consideration and \nhuman oversight [9].\nThis article chronicles the development and implemen-\ntation of an innovative, AI-powered, agentic workflow \nfor healthcare simulation scenario design in SIMNOVA \nSimulation Center in Novara, Italy. The project evolved \nfrom an initial prototype based on a structured ChatGPT \ninterface to a fully automated system leveraging “n8n, ” \na no-code open-source platform. The narrative details \nthe development process, the underlying rationale, the \nscope of potential applications, and the critical lessons \nlearned. The overarching objective is to provide simula -\ntion educators with a comprehensive understanding of \nhow AI-driven approaches can enhance efficiency and \nconsistency in scenario design while ensuring rigorous \nadherence to established best-practice standards.\nAim and objectives\nThe primary aim of this innovation was to develop an \nAI-powered system capable of significantly reducing the \ntime and effort required to create high-quality, stand -\nards-compliant healthcare simulation scenarios. This \nreduction in development time was hypothesized to free \nup valuable educator resources, allowing for greater focus \non learner interaction and debriefing [10].\nBeyond simply accelerating the process, the pro -\nject aimed to achieve several specific objectives. First, \nthe system needed to automate the generation of core \nscenario components, including learning objectives, a \ndetailed patient narrative, relevant diagnostic data, and \ncomprehensive debriefing points. Second, it was essen -\ntial that the system’s outputs were consistently aligned \nwith established simulation design standards, specifi -\ncally the INACSL Standards of Best Practice: Simu -\nlation Design and the ASPiH Standards Framework \nfor Simulation-Based Education [11, 12]. Third, user-\nfriendliness was paramount; the workflow needed to be \naccessible to educators with varying levels of technical \nexpertise, not requiring specialized programming skills. \nFourth, the system was designed for adaptability, sup -\nporting customization for a wide range of clinical settings \nand learner levels, from undergraduate nursing students \nto experienced medical professionals. Fifth, to enhance \nits global applicability, the system incorporated multilin -\ngual scenario generation capabilities. Finally, the develop-\nment process prioritized addressing potential issues of \nfactual accuracy, bias in AI outputs, and ethical consider-\nations related to intellectual property and patient privacy.\nTarget group\nThe primary target group for this innovation encom -\npasses a broad spectrum of individuals involved in \nhealthcare simulation. This includes simulation educa -\ntors across various disciplines (nursing, medicine, allied \nhealth professions), simulation center directors and tech-\nnical staff responsible for scenario implementation, and \ncurriculum developers seeking to integrate simulation-\nbased learning into their programs. Furthermore, the \nsystem is particularly relevant for institutions aiming \nto expand their simulation offerings and for educators \nworking in resource-constrained settings where time and \nexpertise may be limited. The system’s accessibility aims \nto lower the barrier to entry for those new to simulation \nscenario design, while also providing advanced capabili -\nties for experienced simulationists.\nDevelopment process\nThe development of the AI-assisted scenario design sys -\ntem unfolded in two distinct, yet interconnected, phases \n(Fig. 1).\nPhase 1: the initial ChatGPT‑based scenario designer\nInitially, we focused on creating what OpenAI refers to \nas GPTs (generalized pre-trained models). These are \nstructured, custom, interactive interfaces powered by \nChatGPT (OpenAI, USA), tailored for specific tasks or \ntopics [13]. This implementation took the concrete form \nof a publicly accessible custom GPT titled “Scenario \nDesigner, ” [14] (Fig. 1a) specifically trained with compre -\nhensive simulation scenario templates and specialized \nmaterials for healthcare simulation scenario creation. \nRather than relying on free-form interaction with the \nLLM, this customized application guided users through a \nmethodically structured series of prompts, systematically \neliciting key parameters such as the clinical case type, tar-\nget learner demographic, and specific learning objectives.\nThis structured approach, informed by established \nscenario design principles [11, 12], ensured that the \nPage 3 of 9\nBarra et al. Advances in Simulation           (2025) 10:29 \n \nAI-generated content adhered to standardized formats \nand comprehensively addressed all critical elements \nrequired for effective simulation scenarios. The system \nsequentially generated a short text for each discrete sec -\ntion of the scenario, allowing educators to review and \nrefine the AI’s output at each developmental stage. This \niterative process proved crucial for maintaining rigorous \nhuman oversight and ensuring clinical and pedagogical \naccuracy.\nThe Custom GPT underwent significant evolution in \nDecember 2024 when it was enhanced to leverage Chat -\nGPT’s Canvas functionality [15]. This technical advance -\nment enabled users to modify the scenario structure \ndirectly within the web interface, facilitating a more \ndynamic and responsive design process. The Canvas \nimplementation allowed for real-time visualization and \nmanipulation of the scenario framework, enhancing user \nengagement and streamlining the refinement process.\nThroughout development, simulation educators served \nas key informants and stakeholders, providing feedback \nand modifying the system prompt and template’s struc -\nture and the quality of the AI-generated content. This \ncollaborative approach ensured that the technological \nimplementation remained firmly grounded in evidence-\nbased simulation pedagogy. The phase was conceptually \nanchored in the understanding that LLMs could signifi -\ncantly accelerate the drafting of scenario components, \neffectively reducing development time and allowing edu -\ncators to allocate their expertise toward refining the sce -\nnario’s nuances and critical pedagogical aspects [10].\nFig. 1 Evolution from ChatGPT-based prototype to agentic AI workflow. a Initial ChatGPT-based scenario designer. A structured, custom interface \npowered by ChatGPT, specifically trained with simulation content and scenario templates. Educators interact with the AI via a chat-based interface \nwithin the ChatGPT platform, guiding the model through a series of prompts to generate scenario elements. The LLM generates an editable \nCanvas that allows users’ refinements and finalization. Limitations are text-based outputs, limited knowledge retrieval, and lack the capacity \nfor external system integration or automated visual aid generation. b Advanced agentic workflow in n8n. Featuring an AI agent that autonomously \nmakes decisions (research context, create scenario) and takes actions without constant human oversight. Educators still interact with the system \nvia a chat-like interface but with greatly expanded accessibility. This interaction can occur through various channels, including local or web-based \npages and mainstream messaging systems. The knowledge is an unlimited vector database, utilizes diverse tools, and seamlessly integrates external \nAPIs. The key action is the generation of formatted files containing the complete simulation scenario and supplementary materials, such as arterial \nblood gases (ABGs), lab exam results, and imaging findings, delivered directly to the user, that has the task to review the material and finalize \nthe scenario\nPage 4 of 9Barra et al. Advances in Simulation           (2025) 10:29 \nDespite its advantages, this implementation demon -\nstrated several inherent limitations. First, the system \nremained entirely contained within the ChatGPT envi -\nronment, restricting its integration with external systems \nand workflows, and limiting its content knowledge to a \nmaximum of 12 documents. Second, it relied exclusively \non the OpenAI models, preventing exploration of alter -\nnative LLM architectures potentially better suited for \nspecific aspects of scenario design. Third, the system \nlacked connectivity with document creation tools, neces -\nsitating manual export and formatting of generated con -\ntent. Finally, its outputs were limited to text, precluding \nthe automatic generation of visual elements that could \nenhance scenario fidelity and learner engagement.\nPhase 2: from chatbot to agent: building an AI workflow \nwith n8n\nThese limitations ultimately necessitated the transi -\ntion from a guided chatbot interaction to a fully agentic \nAI workflow. An AI agent, in this context, represents an \nautonomous system capable of perceiving its environ -\nment, making independent decisions, and taking actions \nto accomplish specific objectives without constant \nhuman intervention. Unlike conventional chatbots that \nprimarily respond to direct prompts within a single con -\nversation, agents can maintain persistent state, execute \nsequences of operations across multiple systems, and \nadaptively respond to changing conditions over time. \nThis agentic approach enables a significant expansion of \nfunctionality, allowing the AI to perform complex tasks \nsuch as accessing databases, triggering simulations, eval -\nuating outcomes, and coordinating multiple informa -\ntion streams, all while maintaining coherence within the \noverarching workflow framework. An automated agentic \nworkflow with AI large language models (LLMs) consti -\ntutes a structured sequence of processes where LLMs \nfunction as integral components within a broader orches-\ntrated system. Such workflows systematically coordinate \nthe execution of predefined tasks, leveraging LLMs’ lin -\nguistic and reasoning capabilities at strategic intervention \npoints while maintaining procedural consistency through \nformalized data pathways. These workflows enable the \ncreation of robust systems capable of processing informa-\ntion, making determinations, and initiating subsequent \nactions according to predetermined logical frameworks \nwithout requiring continuous human oversight for rou -\ntine operational decisions.\nThe n8n platform (n8n Software, Germany) was \nselected for several critical reasons that aligned with the \nproject’s objectives and constraints. First, its open-source \nnature eliminated licensing costs and provided full trans -\nparency into the workflow’s operations. Second, its ability \nto self-host offered simulation centers complete control \nover their data and infrastructure, addressing poten -\ntial privacy concerns when working with sensitive clini -\ncal scenarios. Third, n8n’s flexibility in integrating with \ndiverse LLM providers (including OpenAI, Anthropic, \nGoogle and others) prevented vendor lock-in and allowed \nfor adaptation as new models emerged.\nA critical aspect of this phase was that the entire \ndevelopment process was executed by the lead author, a \nCritical Care physician and Healthcare Simulation Edu -\ncator with basic coding knowledge but no specialized \nAI expertise. This approach demonstrated that health -\ncare simulation educators with modest technical skills \ncan successfully implement sophisticated AI workflows \nwithout requiring dedicated AI specialists or software \nengineers. This democratization of AI implementation \nis particularly significant for simulation centers operat -\ning with limited technical resources but possessing moti -\nvated staff willing to explore innovative approaches.\nThe workflow leverages a strategic combination of AI \nmodels to optimize both performance and cost-effective -\nness. The system primarily utilizes GPT-4o for tool-call -\ning agents that require specialized capabilities, Gemini \n2.0 Flash and Pro for the main workflow components due \nto their extensive context token capacity and cost-free \navailability (significantly reducing operational expenses), \nand Anthropic Claude 3.7 Sonnet for reviewing and final \nediting to ensure high-quality outputs. This thoughtful \nmodel selection exemplifies how simulation centers can \nimplement sophisticated AI workflows while managing \ncosts effectively. The authors also tested a complete local \nLLMs system powered by Qwen QWQ 32B (Alibaba, \nChina) and Mistral Small 3 (Mistral AI, France), achiev -\ning similar results but noting longer execution times due \nto hardware limitations (Apple Mac Mini M4Pro with \n32GB RAM).\nTechnical performance metrics demonstrate the sys -\ntem’s efficiency, with an average processing time of 4.5 \nmin across 50 test runs. The workflow supports com -\nprehensive multilingual output capabilities, enabling \nglobal application across diverse educational contexts. At \nSIMNOVA Simulation Center, the system has been cus -\ntomized to incorporate institutional branding elements, \nincluding logos and structured document templates, fur -\nther enhancing the professional quality of the generated \nmaterials.\nAgentic workflow structure (n8n implementation)\nThe agentic workflow within n8n was designed to mimic \nthe structure of a complex, multi-step reasoning process, \ndrawing heavily on principles of agent-based AI systems \n[16].\nThe core concepts employed include the following:\nPage 5 of 9\nBarra et al. Advances in Simulation           (2025) 10:29 \n \n• Decomposition (sub-agents): The overall task of \nscenario generation was broken down into a series \nof smaller, more manageable sub-tasks. Each sub-\ntask was handled by a dedicated agent, imple -\nmented as a separate node or set of nodes within \nthe n8n workflow. This hierarchical decomposition \nallowed higher-level agents to orchestrate lower-\nlevel, specialized agents, ensuring that each com -\nponent of the scenario received focused attention.\n• Prompt chaining (sequential execution with con -\ntext passing): The workflow utilized prompt chain -\ning extensively, where the output of one agent \nbecame part of the input prompt for the subse -\nquent agent. This ensured that each agent had the \nnecessary context from previous steps. This serial \nprompt chaining created a coherent progression of \nscenario elements.\n• Parallelization (concurrent execution): Where \nappropriate, agents were executed in parallel to \nimprove efficiency. For example, agents responsi -\nble for generating “roles and resources” and “brief -\ning, debriefing, references” could operate concur -\nrently, as they both depended on common inputs \nbut were independent of each other. This parallel \nexecution significantly reduced the overall pro -\ncessing time.\n• Retrieval-augmented generation (RAG): The ini -\ntial interaction agent utilized RAG to access and \nincorporate information from various knowledge \nsources, including a vector database populated \nwith healthcare simulation textbooks, direct search \ncapabilities for PubMed and Semantic Scholar, and \nguidelines repositories for specific clinical scenar -\nios. This enhanced the factual accuracy and rele -\nvance of the generated content.\n• Tool use (external API calls and data transforma -\ntions): The workflow leveraged n8n’s ability to \nintegrate with external APIs to perform tasks such \nas retrieving relevant research articles, generat -\ning text with LLMs, validating data formats, con -\nverting data between formats, and sending emails. \nThis integration capability expanded the system’s \nfunctionality beyond what a standalone LLM could \nachieve.\n• Iterative refinement (reviewer agent and feedback \nloop): A dedicated “reviewer” agent was included \nin the workflow to assess the output of the scenario \ngeneration process for adherence to the user’s ini -\ntial query and established simulation best-practice \nstandards. This provided a crucial layer of quality \ncontrol and allowed for potential automated refine -\nment before the final output was presented to the \nuser.\nDetailed workflow steps and agent interactions\nThe agentic workflow (Figs.  1b and 2) was built to oper -\nate through a conversational interface resembling famil -\niar chat experiences, ensuring that end users were not \nconfronted with complex coding interfaces or techni -\ncal barriers. The core of the system was an initial agent \nwith advanced retrieval-augmented generation (RAG) \ncapabilities and access to specialized tools, serving as \nthe front-end interface. A typical interaction began with \nthe educator providing basic scenario requirements, \nproviding comprehensive simulation parameters includ -\ning title, main problem/diagnosis, target learner group, \nSimZone classification [17], simulated location, specific \nlearning objectives, required key actions, detailed patient \ncharacteristics, preferred language output. This agent \nperformed RAG, searching relevant databases and syn -\nthesizing findings into a comprehensive Research Output \nparameter that informed subsequent workflow processes. \nOnce the educator reviewed and confirmed the param -\neters and the researched content, the system activated \nthe specialized Scenario Designer n8n workflow, which \norchestrated a network of interconnected AI agents:\n1. Scenario outline and objectives agent: This agent \nreceived the user’s query parameters and the \nResearch Output, generating a structured JSON \nobject containing key elements like scenario title, \ndescription, needs assessment, learning objectives, \nand scenario classification metadata. The agent \nexplicitly referenced ASPiH core values and curricu -\nlum mapping, ensuring alignment with established \nstandards.\n2. Roles and resources agent: This component gener -\nated a detailed specification of the roles required and \nthe physical resources needed for the scenario.\n3. Scenario patient and briefings creation: This agent \ngenerated structured briefings (faculty script, pre-\nbriefing, briefing) and a detailed patient profile.\n4. Scenario states agent: This component generated a \nstructured description of the scenario states, includ -\ning detailed physiological parameters, transitions \nbetween states, and resources required at each stage. \nThe agent incorporated extensive guidance on trigger \nmechanisms (both time-based and action-based) and \nadhered to realistic clinical progressions.\n5. Educational content agent: This agent focused on \ngenerating the pedagogical elements of the scenario, \nincluding desired actions for learners and facilitators, \ndebriefing points, and relevant teaching notes and \nreferences.\n6. Reviewer agent: Acting as a quality control mecha -\nnism, this agent assessed the combined output for \nadherence to the user’s initial query, consistency with \nPage 6 of 9Barra et al. Advances in Simulation           (2025) 10:29 \nsimulation best-practice standards, clinical accuracy, \ncompleteness, and coherence. This feedback could \neither trigger refinements or be presented to the user \nas part of the final output.\n7. Editor agent: This final component received all JSON \ndata and formatted it into HTML, subsequently con -\nverted to PDF for easy distribution and printing.\nFig. 2 Agentic workflow for scenario generation with user feedback loop. This figure illustrates the detailed structure of the agentic AI workflow \nimplemented in n8n for healthcare simulation scenario design. The process begins with an input comprising “user parameters + research output,” \nderived from the initial interaction agent’s retrieval-augmented generation (RAG) process. This input is fed into a sequence of specialized LLM \nagents (LLM 1 through LLM 7), each responsible for a specific sub-task of scenario generation (decomposition-sub-agent task). Prompt chaining \nensures that the output of each agent informs the subsequent agent’s input, maintaining contextual coherence. The workflow demonstrates \nparallelization, where three separate agentic workflows generate supplementary materials (ABGs, Lab Exams, Imaging) concurrently with the main \nscenario components. An iterative refinement loop, involving a “scenario reviewer” agent (LLM 6) and a “scenario editor” agent (LLM 7), ensures \nquality control and formatting. The “final output” (complete scenario + supplement materials) is then presented back to the user for review, editing, \nand final approval before implementation in simulation-based education\nPage 7 of 9\nBarra et al. Advances in Simulation           (2025) 10:29 \n \nIn parallel with the main workflow, supplemental mate-\nrial creation agents generated realistic clinical docu -\nments (e.g., arterial blood gas results, imaging findings, \nlaboratory test results) based on the patient’s condition \nand progression defined in the scenario states. Finally, \nan assembly process combined the outputs from various \nagents into a single, cohesive document, which was then \ndelivered to the user’s email address.\nThe entire workflow represented a sophisticated \norchestration of AI agents, each with specialized respon -\nsibilities yet working in concert to produce a compre -\nhensive, standards-compliant simulation scenario. This \napproach not only accelerated the scenario creation pro -\ncess but also enhanced consistency and adherence to \nestablished guidelines.\nScope of innovation’s potential application\nThe AI-driven scenario design workflow possesses a \nbroad scope of potential application within the field of \nhealthcare simulation. The system’s versatility allows it \nto be adapted to a wide range of clinical settings, includ -\ning, but not limited to, emergency medicine, critical care, \nobstetrics, pediatrics, and mental health. Furthermore, it \ncan be customized to suit different learner levels, ranging \nfrom undergraduate students to experienced healthcare \nprofessionals, by adjusting the complexity of the clinical \npresentation and the expected level of performance.\nThe system’s design facilitates the tailoring of sce -\nnarios to specific learning objectives, encompassing \nclinical skills acquisition, teamwork and communica -\ntion training, and clinical decision-making practice. The \ninclusion of multilingual output capabilities signifi -\ncantly expands the system’s reach, making it applicable \nin diverse educational contexts across the globe. The \nworkflow also facilitates the rapid generation of scenario \nvariations, allowing educators to create multiple ver -\nsions of a scenario with differing patient presentations, \ncomplications, or resource availability. This capability is \nparticularly valuable for research purposes, enabling con-\ntrolled comparisons of different pedagogical approaches. \nThe generated scenarios can be used in simulation with \nstandardized patients, and within environments such \nas hospital wards, simulation centers, and community \nsettings.\nInstructions for implementation and use\nImplementing and utilizing this innovation requires \na series of straightforward steps. First, access to the \nn8n platform is necessary, either through a self-hosted \ninstance or a cloud-based subscription. The pre-built \nscenario design workflow can then be imported into the \nn8n environment. API keys for the required AI models, \nsuch as OpenAI’s GPT models, Anthropic’s Claude, and \nGoogle’s Gemini models, must be obtained and config -\nured within the n8n workflow.\nTo generate a scenario, educators provide a clear \nand concise brief, specifying the clinical topic, tar -\nget learner level, learning objectives, and any specific \nrequirements or constraints. The workflow is then exe -\ncuted within n8n, triggering the sequence of AI agent \nactions. Critically, after the workflow completes, a thor -\nough review and refinement of the AI-generated sce -\nnario by a subject matter expert is essential. This step \nensures the accuracy, realism, and pedagogical sound -\nness of the scenario before it is used with learners. \nFinally, the finalized scenario can be implemented in \nsimulation-based education activities.\nFor simulation centers with sufficient computa -\ntional resources, the system can be configured to use \nlocally-hosted, smaller LLMs rather than commercial \nAPI services. This option reduces ongoing operational \ncosts and addresses potential data privacy concerns, \nmaking the system more accessible to resource-con -\nstrained institutions. The implementation typically \nrequires modest technical skills comparable to those of \na simulation technician or educator with basic coding \nexperience.\nPotential pitfalls and workarounds\nWhile the AI-driven workflow offers significant advan -\ntages, several potential pitfalls must be acknowledged \nand addressed. A primary concern is the potential for \ninaccuracies in the AI-generated content. LLMs, while \npowerful, do not possess true understanding and may \noccasionally produce information that is factually \nincorrect or clinically inappropriate. To mitigate this \nrisk, a rigorous review process involving subject matter \nexperts is crucial.\nAnother potential issue is bias in the AI model’s out -\nputs, reflecting biases present in the training data. To \naddress this, prompts were designed to encourage \ndiverse and equitable representation, and the outputs \nare reviewed for inclusivity. Technical issues with the \nn8n platform or the AI models themselves may also \narise, necessitating backup plans and access to techni -\ncal support. For centers using self-hosted LLMs, addi -\ntional challenges may include managing computational \nresources and maintaining model updates. These can be \naddressed through careful infrastructure planning and \nestablishing regular update protocols. The initial learn -\ning curve for configuring n8n workflows might also \npresent a barrier, though this can be mitigated by pro -\nviding detailed documentation and establishing peer \nsupport networks among simulation centers imple -\nmenting similar systems.\nPage 8 of 9Barra et al. Advances in Simulation           (2025) 10:29 \nResources needed and cost estimation\nThe resources required for implementation include \naccess to the n8n platform, which may involve costs \ndepending on the chosen deployment option (self-hosted \nor cloud-based). API access to the chosen AI models \nalso incurs costs, which are dependent on usage and the \nspecific provider’s pricing structure. For centers opting \nfor self-hosted n8n and local LLMs, initial costs would \ninclude server hardware with sufficient computational \ncapacity, particularly if running multiple concurrent \nworkflows.\nA precise cost estimation is challenging, as it is highly \ndependent on usage patterns and specific pricing plans. \nHowever, it is important to consider the potential cost \nsavings resulting from the significant reduction in sce -\nnario development time, which may offset the direct \ncosts of the platform and API access. By our preliminary \nestimations, the system reduces scenario development \ntime by approximately 70–80%, translating to substan -\ntial labor cost savings for simulation centers regularly \nproducing new scenarios. This aligns with the find -\nings by the University of Toronto’s pilot program, which \nshowed reduced scenario development time by 73% while \nmaintaining 92% clinical accuracy compared to human-\nauthored cases when using AI as an aid to writing [18].\nThe self-hosted approach with local LLMs offers the \nmost cost-effective long-term solution for centers with \nfrequent scenario development needs, as it eliminates \nongoing API fees. However, this approach requires \ngreater initial investment in hardware and technical con -\nfiguration. For centers with occasional scenario develop -\nment needs, the cloud-based approach with commercial \nAPI services may offer a more flexible, pay-as-you-go \nsolution.\nThe strategic use of different AI models in our imple -\nmentation demonstrates how costs can be managed \neffectively. By utilizing Gemini 2.0 models (which are \ncurrently free to use) for the main workflow components \nwhile reserving premium models like GPT-4o and Claude \n3.5 for specialized tasks requiring their unique capabili -\nties, the system achieves cost optimization without com -\npromising quality.\nLessons learned\nThe development and implementation of this AI-assisted \nscenario design workflow yielded several valuable les -\nsons. The importance of interdisciplinary collaboration \nbetween simulation experts and individuals with techni -\ncal aptitude was paramount, though we demonstrated \nthat specialized AI expertise is not a prerequisite for suc -\ncessful implementation. The iterative process of refin -\ning AI prompts and workflow logic proved crucial for \noptimizing the quality and accuracy of the outputs. The \nproject reinforced the essential role of human oversight \nin AI-assisted processes, emphasizing that AI should be \nviewed as a powerful tool, not a replacement for human \nexpertise. The need for user training became evident, as \neducators require guidance on how to effectively interact \nwith the AI tool and interpret its outputs. Ethical consid -\nerations, particularly regarding accuracy, bias, and intel -\nlectual property, required careful attention throughout \nthe development process. Finally, the process of creating \nthe AI workflow unexpectedly led to a deeper under -\nstanding of our own scenario design practices, forcing us \nto make our implicit knowledge explicit and transferable.\nPerhaps most significantly, the project demonstrated \nthat sophisticated AI implementations in healthcare \nsimulation are within reach of motivated clinicians and \neducators without requiring specialized technical exper -\ntise or external consultants. This realization has profound \nimplications for the democratization of AI tools within \nhealthcare education, potentially accelerating innovation \nand adoption across diverse settings and resource levels.\nAbbreviations\nAI  Artificial intelligence\nASPiH  Association for Simulated Practice in Healthcare\nINACSL  International Nursing Association for Clinical Simulation and \nLearning\nLLM  Large Language Model\nRAG   Retrieval-augmented generation\nSMART   Specific, measurable, attainable, relevant, timely\nAcknowledgements\nNot applicable\nAuthors’ contributions\nFLB and GR conceived the initial idea, FLB developed the ChatGPT prototype \nand the n8n workflow. FLB and GR contributed to the pedagogical framework \nand agentic workflow architecture and features. AS, LC, AC, AM and FDC pro-\nvided feedback and beta-testing. All authors contributed to the manuscript \nwriting and review.\nFunding\nThis project received no external funding.\nData availability\nNo datasets were generated or analysed during the current study.\nDeclarations\nEthics approval and consent to participate\nNot applicable. This article describes the development of a software tool and \ndoes not involve human participants, human data, or human tissue.\nConsent for publication\nNot applicable. This manuscript does not contain data from any individual \nperson.\nCompeting interests\nThe authors declare no competing interests.\nAuthor details\n1 Department of Anesthesiology and Intensive Care Medicine, Azienda \nOspedaliero-Universitaria “Maggiore Della Carità” , Novara, Italy. \nPage 9 of 9\nBarra et al. Advances in Simulation           (2025) 10:29 \n \n2 SIMNOVA-Interdepartmental Center for Innovative Learning and Simulation \nin Medicine and Allied Health Professions, University of Piemonte Orientale, \nNovara, Italy. 3 Department of Anesthesiology and Intensive Care Medicine, \nPresidio Ospedaliero SS. Trinità, ASL 13, Borgomanero, Italy. 4 Department \nof Anesthesia and Intensive Care Medicine, IRCCS Humanitas Research \nHospital, Rozzano, Italy. 5 Division of Pediatrics, Department of Health Sciences, \nUniversity of Piemonte Orientale, Novara, Italy. \nReceived: 16 March 2025   Accepted: 11 May 2025\nReferences\n 1. Bambini D. Writing a simulation scenario: a step-by-step guide. AACN Adv \nCrit Care. 2016;27(1):62–70. https:// doi. org/ 10. 4037/ aacna cc201 6986.\n 2. Elendu C, Amaechi DC, Okatta AU, Amaechi EC, Elendu TC, Ezeh CP , et al. \nThe impact of simulation-based training in medical education: a review. \nMedicine. 2024;103(27):e38813. https:// doi. org/ 10. 1097/ MD. 00000 00000 \n038813.\n 3. Lamé G, Dixon-Woods M. Using clinical simulation to study how to \nimprove quality and safety in healthcare. BMJ Simul Technol Enhanced \nLearning. 2020;6(2):87–94. https:// doi. org/ 10. 1136/ bmjst el- 2018- 000370.\n 4. Saleem M, Khan Z. Healthcare simulation: an effective way of learning in \nhealth care. Pakistan J Med Sci. 2023;39(4):1185–90. https:// doi. org/ 10. \n12669/ pjms. 39.4. 7145.\n 5. Hamilton A. Artificial intelligence and healthcare simulation: the shifting \nlandscape of medical education. Cureus. 2024;16(5):e59747. https:// doi. \norg/ 10. 7759/ cureus. 59747.\n 6. Harder N. Using ChatGPT in simulation design: what can (or should) it \ndo for you? Clin Simul Nurs. 2023;78:A1–2. https:// doi. org/ 10. 1016/j. ecns. \n2023. 02. 011.\n 7. Xu T, Weng H, Liu F, Yang L, Luo Y, Ding Z, et al. Current status of ChatGPT \nuse in medical education: potentials, challenges, and strategies. J Med \nInternet Res. 2024;26:e57896. https:// doi. org/ 10. 2196/ 57896.\n 8. Barra FL, Costa A, Rodella G, Semeraro F, Carenzo L. Shaping the future \nof simulator interactions: the role of ChatGPT’s Advanced Voice Mode. \nResuscitation. 2024;110452. https:// doi. org/ 10. 1016/j. resus citat ion. 2024. \n110452.\n 9. Aljamaan F, Temsah M-H, Altamimi I, Al-Eyadhy A, Jamal A, Alhasan K, \net al. Reference hallucination score for medical artificial intelligence chat-\nbots: development and usability study. JMIR Med Inform. 2024;12:e54345. \nhttps:// doi. org/ 10. 2196/ 54345.\n 10. Rodgers DL, Needler M, Robinson A, Barnes R, Brosche T, Hernandez \nJ, et al. Artificial intelligence and the simulationists. Simul Healthcare. \n2023;18(6):395–9. https:// doi. org/ 10. 1097/ SIH. 00000 00000 000747.\n 11. INACSL standards of best practice. simulationsm simulation design. Clin \nSimul Nurs. 2016;12:S5–12. https:// doi. org/ 10. 1016/j. ecns. 2016. 09. 005.\n 12. ASPiH standards 2023–ASPiH. https:// aspih. org. uk/ stand ards-2/. Accessed \n9 Mar 2025.\n 13. Masters K, Benjamin J, Agrawal A, MacNeill H, Pillow MT, Mehta N. Twelve \ntips on creating and using custom GPTs to enhance health professions \neducation. Med Teach. 2024;46(6):752–6. https:// doi. org/ 10. 1080/ 01421 \n59X. 2024. 23053 65.\n 14. Barra FL. ChatGPT [GPT]. Scenario designer. https:// chatg pt. com/g/ g- \n9FFaq AL3L- scena rio- desig ner. Accessed 10 Mar 2025.\n 15. Introducing canvas. https:// openai. com/ index/ intro ducing- canvas/. \nAccessed 9 Mar 2025.\n 16. Building effective AI agents | anthropic. https:// www. anthr opic. com/ \nengin eering/ build ing- effec tive- agents. Accessed 10 Mar 2025\n 17. Roussin CJ, Weinstock P . SimZones: an organizational innovation for \nsimulation programs and centers. Acad Med. 2017;92(8):1114. https:// doi. \norg/ 10. 1097/ ACM. 00000 00000 001746.\n 18. Sumpter S. Automated generation of high-quality medical simulation \nscenarios through integration of semi-structured data and large lan-\nguage models. Published online May 6, 2024. https:// doi. org/ 10. 48550/ \narXiv. 2404. 19713.\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in pub-\nlished maps and institutional affiliations.",
  "topic": "Workflow",
  "concepts": [
    {
      "name": "Workflow",
      "score": 0.7550675868988037
    },
    {
      "name": "Health services research",
      "score": 0.5928595066070557
    },
    {
      "name": "Health care",
      "score": 0.5515194535255432
    },
    {
      "name": "Medicine",
      "score": 0.44590675830841064
    },
    {
      "name": "Computer science",
      "score": 0.44220292568206787
    },
    {
      "name": "Process management",
      "score": 0.3681713938713074
    },
    {
      "name": "Public health",
      "score": 0.35846734046936035
    },
    {
      "name": "Knowledge management",
      "score": 0.34625715017318726
    },
    {
      "name": "Nursing",
      "score": 0.29190945625305176
    },
    {
      "name": "Engineering",
      "score": 0.23188677430152893
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Economic growth",
      "score": 0.0
    },
    {
      "name": "Database",
      "score": 0.0
    }
  ]
}