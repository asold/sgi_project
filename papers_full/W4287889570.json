{
  "title": "Multimodal large language models for inclusive collaboration learning tasks",
  "url": "https://openalex.org/W4287889570",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2289816709",
      "name": "Armanda Lewis",
      "affiliations": [
        "New York University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4214937105",
    "https://openalex.org/W4220747294",
    "https://openalex.org/W2794512630",
    "https://openalex.org/W3208743309",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2776114802",
    "https://openalex.org/W2100960835",
    "https://openalex.org/W3100307207",
    "https://openalex.org/W3021672059",
    "https://openalex.org/W4287136589",
    "https://openalex.org/W2963217826",
    "https://openalex.org/W3015777882",
    "https://openalex.org/W3188116539",
    "https://openalex.org/W2990153250",
    "https://openalex.org/W3159421271",
    "https://openalex.org/W4286973660",
    "https://openalex.org/W3037032032",
    "https://openalex.org/W2042803654",
    "https://openalex.org/W3157194636",
    "https://openalex.org/W4221152848",
    "https://openalex.org/W2899274165",
    "https://openalex.org/W2806284028",
    "https://openalex.org/W2912601588",
    "https://openalex.org/W3037340813",
    "https://openalex.org/W3035296331",
    "https://openalex.org/W3001279689",
    "https://openalex.org/W3102393842",
    "https://openalex.org/W4385468994",
    "https://openalex.org/W2950330308",
    "https://openalex.org/W3199241049",
    "https://openalex.org/W3034937117",
    "https://openalex.org/W4312910992",
    "https://openalex.org/W3195577433",
    "https://openalex.org/W1840435438",
    "https://openalex.org/W3001799900",
    "https://openalex.org/W2026767251",
    "https://openalex.org/W2012731075",
    "https://openalex.org/W2125336414",
    "https://openalex.org/W3130174139",
    "https://openalex.org/W1861914525",
    "https://openalex.org/W2594475271",
    "https://openalex.org/W3174429158",
    "https://openalex.org/W2999071598",
    "https://openalex.org/W3104617516",
    "https://openalex.org/W2893425640",
    "https://openalex.org/W2748669378",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W2017428456",
    "https://openalex.org/W3034266838",
    "https://openalex.org/W3037831233",
    "https://openalex.org/W4214844842"
  ],
  "abstract": "This PhD project leverages advancements in multimodal large language models to build an inclusive collaboration feedback loop, in order to facilitate the automated detection, modeling, and feedback for participants developing general collaboration skills. This topic is important given the role of collaboration as an essential 21st century skill, the potential to ground large language models within learning theory and real-world practice, and the expressive potential of transformer models to support equity and inclusion. We address some concerns of integrating advances in natural language processing into downstream tasks such as the learning analytics feedback loop.",
  "full_text": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies: Student Research Workshop, pages 202 - 210\nJuly 10-15, 2022 ©2022 Association for Computational Linguistics\nMultimodal large language models for inclusive collaboration learning tasks\nArmanda Lewis\nNew York University\n726 Broadway\nNew York, NY 10003\nal861@nyu.edu\nAbstract\nThis PhD project leverages advancements in\nmultimodal large language models to build an\ninclusive collaboration feedback loop, in order\nto facilitate the automated detection, modeling,\nand feedback for participants developing gen-\neral collaboration skills. This topic is important\ngiven the role of collaboration as an essential\n21st century skill, the potential to ground large\nlanguage models within learning theory and\nreal-world practice, and the expressive poten-\ntial of transformer models to support equity and\ninclusion. We address some concerns of inte-\ngrating advances in natural language process-\ning into downstream tasks such as the learning\nanalytics feedback loop.\n1 Introduction\nCollaboration, a coordinated process involving two\nor more individuals participating in a task in an\ninterdependent way, is an important topic of study\ngiven its importance as a major 21st century skill\n(Lai et al., 2017; Council, 2011; Rios et al., 2020).\nThough collaboration as a general term is viewed\nas a learnable competency, notable distinctions\nemerge when examining how collaboration sur-\nfaces within relevant research. One semantic dis-\ntinction is that the term collaboration is not ex-\nplicitly defined, or is used interchangeably with\nconcepts such as group collaboration, teamwork,\ncollective problem solving, cooperation, and more\n(OECD, 2015). These inconsistencies in meaning\nmake it challenging to connect various research\nagendas that purport the advantages of collabo-\nration. Another distinction to note is modality-\nrelated. Some research does not make any modal-\nity distinctions when reporting the impacts of re-\nsults, though much has viewed collaboration via\nonline/computer-mediated interactions, both syn-\nchronous and asynchronous, while other research\nhas examined co-located collaborative acts that\nhappen face-to-face. Despite semantic, modality,\nand other distinctions, various fields have advanced\nwhat we know about collaboration, specifically col-\nlaboration as a language-mediated process.\nScholars within the fields of NLP, cognitive sci-\nence, and educational research have focused sepa-\nrately on verbal and written aspects of collabora-\ntive exchanges - speech, text-based outputs, and\naudio such as non-linguistic pauses - to better un-\nderstand aspects of collaboration. Recent NLP re-\nsearch, for example, has explored neural models\nequipped with dynamic knowledge graph embed-\ndings, the use of large language models to model\nreal world speech, and the development of collab-\noration datasets (Ekstedt and Skantze, 2020; He\net al., 2017; Lee et al., 2022), while cognitive sci-\nence has explored general modeling approaches for\ncollaborative behavior and large language models\nas knowledge sources for intelligent agents (Gold-\nstone and Gureckis, 2009; Huang et al., 2022; Wray\net al., 2021). Learning analytics, a subset of edu-\ncational research that extracts diverse datastreams\nfrom the learning process to improve learning, has\ndeveloped automated multimodal approaches to de-\ntect, model and provide feedback about collabora-\ntive learning exchanges (Dowell et al., 2019; Pugh\net al., 2022; Worsley and Ochoa, 2020). Though\nthese studies differ in their disciplinary perspec-\ntives, they view language as essential to individu-\nals’ application of collaborative behavior and re-\nsearchers’ understanding of said behavior.\n2 Purpose of Research Project\nBecause language is grounded in experience (Bisk\net al., 2020), and collaboration is mediated through\nlanguage, collaboration is an appropriate skill to be\nlearned, practiced, and analyzed through language-\nmediated experiences and techniques. This disser-\ntation project, situated at the intersection of NLP,\ncognitive science, and learning analytics, focuses\non how we may support people in their develop-\nment of complex, dynamic collaborative language\n202\nskills. The project extends prior research, but\nalso introduces unexplored areas such as multi-\nmodal language modeling and inclusive collabora-\ntion. Therefore, the aim is to contribute to several\nopen research questions related to how we may\nfoster collaborative language, a proxy for overall\ncollaboration skills, in people as an explicit act of\nlearning. This project examines these critical gaps\nin current research to explore the ultimate question\nof: How can we use multimodal large language\nmodels to detect, model, and provide feedback on\ninclusive collaboration behavior? Sub-questions\ninclude:\n• How may a multimodal framework offer im-\nproved collaborative language detection over\nand above unimodal language modeling?;\n• What are possibilities for detecting and mod-\neling inclusive collaboration language among\na group of diverse participants?, and\n• How may we leverage multimodal large lan-\nguage modeling in the service of learning to\ncollaborate through automated and feedback\nmechanisms?\nThis study explores the potentials of adopting\nmultimodal NLP techniques within a learning ana-\nlytics lens. Multimodal NLP is an emerging area\nwithin NLP that stems from the development of\nthe large language model, a massive-parameter pre-\ntrained model. Large language models are an active\narea of development within NLP, and one set of re-\nsearchers have demonstrated impressive semantic\nand generative capabilities (Kaplan et al., 2020; Tay\net al., 2021), while others pose ethical, environmen-\ntal, and interpretability concerns about unbounded\nscaling of model size (Bender et al., 2021; Strubell\net al., 2020; Weidinger et al., 2021). We focus on\nthe potential of multimodal NLP, large language\nmodels that integrate multimodal (acoustic, image,\ntactile, and/or video) data beyond text-based lan-\nguage, and explore potentials of multimodal NLP\nfor automated, fine-grained detection of collabora-\ntive processes that will support learners within and\nacross experiences, an important downstream appli-\ncation of the technology (Bommasani et al., 2021;\nBrown et al., 2020; Islam and Iqbal, 2021; Rahman\net al., 2020). We also contribute to current cri-\ntiques of performance-first modeling that may over-\nlook important opportunities to create real world\nNLP models that reduce bias. This project opera-\ntionalizes an inclusive collaboration index with the\ngoal of general equity and inclusion over identity-\nspecific bias mitigation.\n3 Integrating Inclusion into Downstream\nNLP Collaboration Tasks\nWithin learning analytics (Holstein and Doroudi,\n2021), NLP (Blodgett et al., 2020; Tsvetkov et al.,\n2018), and general machine learning/AI applica-\ntions (Doshi-Velez and Kim, 2017; Dwork et al.,\n2012), researchers have made arguments for more\nequitable, fair, and inclusive practices. This in-\ncludes verifying that the research approach is in-\nformed by ethical and human-centered principles,\ndeveloping research methods that detect/mitigate\nunethical outcomes, and/or our aim of proposing\nthat research methods should translate ethically\nwhen used in real-world contexts.\nWith the recent focus on equity and inclusion\nacross our fields of interest, formal inclusion the-\nories are stated as important to integrate as a fu-\nture idealized goal, though we lack blueprints for\nwhat forms these integrations may take. Within\nresearch across learning analytics, NLP, and ma-\nchine learning, formal experiments provide em-\npirical support for those methods with the most\npromise for identifying and reducing unwanted so-\ncietal bias, ambiguity, and exclusion in datasets and\nmodels (Caliskan et al., 2017; Dinan et al., 2020;\nHutchinson et al., 2020; Sap et al., 2020), though\nthere is less support for what works as an embedded\npractice within downstream tasks that utilize these\nalgorithms, datasets, and platforms. This study con-\nsiders ethical research approaches and outcomes,\nbut primarily focuses on the stated areas of poten-\ntial development - the ethical deployment of our\nNLP and learning analytics research methods in\ndownstream tasks situated within actual learning\nsettings by detecting lack of inclusion and inter-\nvening. Our focus is not yet to identify any causal\nrelationship between one or more social identities\nand collaboration quality, but rather to detect inclu-\nsive collaboration of individuals and groups, and in\nthe process identify any disparities in collaboration\nquality among individuals and within the group as\na whole.\nIn this sense, our work advances the concept of\ninclusion (Mor-Barak and Cherin, 1998; Young,\n1995), defined as the degree to which diverse indi-\nviduals demonstrate that they are part of the collab-\norative process. We recognize that this study falls\nshort of addressing equity since equity examines\n203\noutcomes at the societal rather than individual or\ngroup level, though we highlight that inclusion is\nan integral step on the way to equity and ethical\ntreatment within collaborative experiences (Bern-\nstein et al., 2020).\n4 Methodology\nWe have sub-divided the planned methodology into\nmultiple tasks as: Due to the multidisciplinary na-\nture of collaboration, this study will incorporate\nmethods that stem from four distinct fields - learn-\ning analytics, cognitive science, natural language\nprocessing, and inclusion theory - to create an inclu-\nsive view of learning to collaborate. From learning\nanalytics, we get a roadmap for developing an au-\ntomated feedback loop necessary for learning to\ncollaborate, and a variety of methods for detecting\ncollaborative behaviors and operationalizing them\ninto signals for model building. From cognitive sci-\nence, we have an example for linking psychological\ntheory, model, and real world behaviors, as well\nas ongoing research on intelligent agents as used\nfor understanding learning and adaptation through\nfeedback. From natural language processing, we\nhave access to the ability of large language models\nto parse and generate human language, as well as\napproaches for addressing inclusion in language\nmodel building. Lastly, we operationalize tenets\nof inclusion theory in order to build a learning to\ncollaborate model that detects linguistic bias, thus\nworking towards a more inclusive collaboration\nenvironment.\nAll aspects involving human subjects, including\nPhase 1 data collected via Amazon Mechanical\nTurk, Phase 2 large language modeling, and Phase\n3 interventions will receive full approval of the\nUniversity’s Institutional Review Board (IRB) prior\nto launching the study. Datasets are either open for\nresearch use and cited, or collected and stored as\npart of the IRB approval process and regulations.\n4.1 Phase 1: Multimodal collaboration\ndetection and dataset creation\nAs part of Phase 1 (multimodal collaboration de-\ntection and dataset creation), we will (a) develop a\nrubric for inclusive collaboration; (b) finalize the\nprocess of capturing and preprocessing multimodal\ndata (video and transcribed audio) from collabora-\ntive exchanges, and (c) create an evaluation dataset.\nThe inclusive collaboration rubric pulls from exist-\ning research on collaboration quality that identifies\nfour collaboration indicators (information sharing,\nreciprocal interaction, shared understanding, and\ninclusion) from participants’ audio, text, and video\ndata (Cukurova et al., 2018; Praharaj et al., 2021),\nand the technical feat of capturing and preprocess-\ning collaborative exchanges is informed by previ-\nous scholarship in Multimodal Learning Analytics\nresearch (Ochoa et al., 2013; Worsley and Blik-\nstein, 2015). Automatic distillation of raw data\ninto collaboration features would include: auto-\nmatic speech recognition, computational linguistic\nmethods to clean, parse, and analyze transcribed di-\nalogue (eg. word counts, duration, general content\nanalysis, inclusive content analysis), detection of\nnon-linguistic audio (speech prosody), and video\nsignal filtering to detect person placement and basic\ngestures.\nFollowing the general dataset collection proce-\ndures described in He et al. (2017), we will gather\nhuman annotations according to our collaboration\nrubric of transcribed audio at the sentence-level and\nvideo portions at the frame-level that is captured for\ncollaborative exchanges. We will use representa-\ntive samples of open source collaboration datasets\nand datasets collected as part of an approved IRB\nprotocol that contain text-based dialogue, spoken\ndialogue, and/or video of multi-person collabora-\ntive exchanges, including the AMI Meeting Corpus\n(Carletta et al., 2006), D64 Multimodal Conver-\nsation Corpus (Oertel et al., 2013) How2 Dataset\nfor Multimodal Language Understanding (Sanabria\net al., 2018), Pragmatic Framework for Collabo-\nration (Boothe et al., 2022), and MutualFriends\nCorpus (He et al., 2017). In addition to annota-\ntion of the four dimensions of interest, we also\nhave annotators evaluate along the modality (text,\nimage, and video). We integrate recent NLP crowd-\nsourcing research findings (Nangia et al., 2021) by\ncollecting expert annotations that will then inform\nguidance for generally skilled Amazon Mechanical\nTurk (MTurk) workers, and and will use the pro-\ncess outlined in Bowman et al. (2015), and the Fair\nWork tool (Whiting et al., 2019) to ensure a fair\npayment structure.\nThe contributions of Phase 1 are multiple: to\nexpand beyond research that analyzes collabora-\ntive language at the surface level, such as looking\nat word counts or temporal durations, and support\ndeeper content-level analysis (Praharaj et al., 2021);\nto map current trends in large language modeling to\ntheoretically-sound learning and inclusion frame-\n204\nworks that extend past pure performance measures\nand support responsible downstream usage of such\nmodels.\n4.2 Phase 2: Multimodal large language\nmodels for measuring collaboration\nquality\nPhase 2 focuses on formalizing the task speci-\nfication for inclusive collaboration, a process in\nwhich we operationalize human-supplied descrip-\ntions into an inclusive collaboration quality classi-\nfication model. Specifically, we will conduct fine-\ntuning experiments with large transformer models\nto detect collaborative language and behaviors of\nindividual members of a 3-person group.\nWe will utilize several pretrained large language\nmodels accessible through HuggingFace ((Wolf\net al., 2020)), including BERT-base (Sanh et al.,\n2020), GPT-2 (Radford and Narasimhan, 2018),\nGPT-J, the open source version of GPT-3 (Brown\net al., 2020), and FLA V A (Singh et al., 2022), a\nrecent multimodal language model pretrained on\nvisual and linguistic data. We will also integrate\nlessons learned from education-specific research\nutilizing large language models (Clavié and Gal,\n2019; Shen et al., 2021; Suresh et al., 2021). These\npretrained models will be finetuned on a random\nsample of the multimodal collaboration data (au-\ndio, text, and/or video frames) that has been held\nout of the evaluation dataset step. We will gen-\nerate finetuned models with unimodal and multi-\nmodal collaborative data, and learning rates and\nbatch sizes will be determined according to stan-\ndard task settings, and we follow the training-test\nsplits and standards articulated by Guo et al. (2020)\nand Minaee et al. (2021). For this study, we will\nlimit our datasets and modeling experiments to\nEnglish-language text and dialogue datasets to sup-\nplement those pre-trained models primarily trained\non English-language data.\nWe compare the performance of our finetuned\nmodels in terms of classification accuracy of our ex-\npert and general crowdworker classification scores\non the 4 collaboration dimensions. The area un-\nder the receiver operating characteristic curve (AU-\nROC) metric is used for each dimension. Following\nPugh et al. (2022), we report the chance baseline\nas a random shuffling of labels within each col-\nlaborative session and thus computing accuracy.\nComparing different unimodal and multimodal fine-\ntuned model performance will serve as an ablation\napproach to examine the role of additional data\nmodalities in terms of overall model performance,\nas well as a comparison between unimodal and\nmultimodal models (Singh et al., 2022). Addition-\nally, we conduct an analysis of random examples to\ndetermine points of synergy with, divergence from,\nand bias markers that differ from human classifica-\ntion. This will serve as essential future directions to\nframe the use of automated collaboration detection\nusing large language models.\nFollowing the design-based protocol outlined in\n(Praharaj et al., 2018), we will complete a pilot\nstudy within a real classroom. Small groups (of 3\npeople) conduct a general collaborative task and\nwe use the detection setup established in Phase 1 to\ndetect multimodal signals (eg. speaking duration,\npauses, large language model features) correlated\nto collaboration quality and use our multimodal\nmodels to assess quality. We will conduct an ad-\nditional automated and human evaluation on this\nreal-life scenario.\nThere are two novel aspects of this modeling of\ncollaborative quality. One involves using the large\nlanguage model to provide a nuanced view of col-\nlaborative linguistic exchanges at the content level.\nAccording to Praharaj et al. (2021) note that very\nfew studies integrate an analysis of “verbal audio\nindicators or the content of the audio for the analy-\nsis of [in-person] collaboration quality” (pg. 2). We\nleverage the large language model to explore im-\nprovements in supervised dialogue detection tasks,\nand also unsupervised training strategies to explore\nemergent and content-specific cases of collabora-\ntion so that the model can learn without direct su-\npervision. Additionally, we propose a measure on\ninclusive collaboration and evaluate its association\non overall collaboration quality.\n4.3 Phase 3: Language generation to support\ncollaboration learning\nSince we are ultimately concerned with learning\nto collaborate, we build a learning analytics cycle\nwith the development of a robust feedback loop.\nThe feedback system will take the form of an intel-\nligent agent that can monitor and detect aspects of\nthe collaboration process, focusing on the measure-\nment of collaboration quality. The key behavior is\nfor our model to detect differences in collaboration,\nin order to pinpoint disparities in inclusion. The\ninclusive collaboration models created by genera-\ntive language models will drive generative behavior\n205\nof the intelligent agent, which will produce select\naudio-based feedback during the collaboration ex-\nchange based on detected features.\nThe study will take on an experimental setup for\nhigher education course recitations that engage in\ncollaborative problem solving. The three groups\n- the no feedback control group (i.e. those ran-\ndomly assigned as the control group with no inter-\nvention), the manual feedback experimental group\n(i.e. those randomly assigned as the manual feed-\nback group which entails an instructor offering\ngeneral, preparatory guidance on quality collab-\noration), and the automated feedback experimental\ngroup (i.e. those randomly assigned as the auto-\nmated feedback group) - will engage in a series\nof four collaborative sessions. During session 1,\nwe will record collaboration exchanges between\nthe randomly assigned groups in order to capture\nmultimodal baseline collaboration data. During\nsessions 2 and 3, the control group will collabo-\nrate in the absence of any explicit feedback, the\nmanual feedback group will collaborate with initial\ncollaboration guidance by the instructor, and the\nautomated feedback group will collaborate while\nthe intelligent agent interjects in real time. Ses-\nsion 4 will record collaboration exchanges between\nthe three groups in the absence of any intervention.\nThe goal is to assess how well all groups perform\non inclusive collaboration quality.\nThis study hypothesizes that feedback loops built\non top of multimodal large language models will\ncapture the most relevant information associated\nwith collaboration due to their scaled representa-\ntional qualities. We will extend progress - fine-\ntuning; masked language model prompting; contex-\ntual prompting; and case-based prompting - made\nin extracting relevant information from language\nmodels to serve as knowledge sources for cogni-\ntive agents, and identify the method that maps to\nencouraging collaboration quality (Huang et al.,\n2022; Wray et al., 2021; Yousfi-Monod and Prince,\n2007). The development of the agent will use lan-\nguage and simple feedback to offer corrective and\nencouraging input to students.\n5 Initial Results\nAn initial pilot focused on the language model-\ning portion, and uses IRB-approved data that takes\nplace within recitations of a large, STEM class.\nGroups of 3 students participated in small group\nwork for the duration of the 75 minute period, and\nwere tasked with solving problems related to the\nlecture and readings. Audio and video record-\nings were captured, cleaned, and processed. Tran-\nscripts were generated by an Automated Speech\nRecognition (ASR) software and corrected by hand,\nand were then paired with video frames. A ran-\ndom sampling of the text-based dialogue and video\nframes were generated and then mapped to the in-\nclusive collaboration framework by 2 expert anno-\ntators and an additional 5 general skill annotators.\nThese data will serve as the evaluation set. BERT-\nbase and GPT-2 were finetuned on a randomized\nsample (80%) of the AMI collaboration dataset,\nas well as dialogue (text-based) portions of the\nMulti-party Collaboration corpus. Results indicate\nsome marginal improvement between the finetuned\nmodels, and between BERT and the larger GPT-2\nmodel, but additional analysis and more thorough\ndata preparation and testing are needed. The fine-\ntuned GPT-2 model performed better than chance\non all except for the inclusion dimension. We antic-\nipate that more thorough finetuning and integration\nof multimodal finetuning data should improve per-\nformance on multimodal classification tasks.\n6 Conclusion\nAs an essential 21st century skill, our aim is to\nutilize the potentials of multimodal large language\nmodels to advance our ability to detect and model\ncollaborative behaviors, with the ultimate goal be-\ning to offer feedback to learners as they develop\nthese important skills. Importantly, we focus on\nthe tenets of inclusive collaboration, so that col-\nlaborators are encouraged to have equitable and\ninclusive exchanges as they work with each other.\nThis doctoral research project builds an automated\nend-to-end inclusive collaboration feedback loop,\nrelying on advancements in large language model-\ning as it is used in downstream tasks, and ground-\ning machine learning methods within theory and\nreal-world practice.\nReferences\nEmily M. Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\nDangers of Stochastic Parrots: Can Language Mod-\nels Be Too Big? &#x1f99c;. In Proceedings of the\n2021 ACM Conference on Fairness, Accountability,\nand Transparency, FAccT ’21, pages 610–623, Vir-\ntual Event, Canada. Association for Computing Ma-\nchinery.\n206\nDimension BERT BERT* GPT-2 GPT-2* Shuffled\nInfo sharing .43 .51 .52 .59 .56\nReciprocity .41 .49 .55 .61 .54\nUnderstanding .47 .49 .59 .64 .52\nInclusion .37 .43 .45 .50 .53\nTable 1: Mean AUROC score across 5 iterations on 4 collaboration dimensions. Asterisk indicates models finetuned\non dialogue data only.\nRuth Sessler Bernstein, Morgan Bulger, Paul Salipante,\nand Judith Y . Weisinger. 2020. From Diversity to\nInclusion to Equity: A Theory of Generative Interac-\ntions. Journal of Business Ethics, 167(3):395–410.\nYonatan Bisk, Ari Holtzman, Jesse Thomason, Jacob\nAndreas, Yoshua Bengio, Joyce Chai, Mirella Lap-\nata, Angeliki Lazaridou, Jonathan May, Aleksandr\nNisnevich, Nicolas Pinto, and Joseph Turian. 2020.\nExperience Grounds Language. arXiv:2004.10151\n[cs]. ArXiv: 2004.10151.\nSu Lin Blodgett, Solon Barocas, Hal Daumé III, and\nHanna Wallach. 2020. Language (Technology)\nis Power: A Critical Survey of \"Bias\" in NLP.\narXiv:2005.14050 [cs]. ArXiv: 2005.14050.\nRishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ\nAltman, Simran Arora, Sydney von Arx, Michael S.\nBernstein, Jeannette Bohg, Antoine Bosselut, Emma\nBrunskill, Erik Brynjolfsson, Shyamal Buch, Dallas\nCard, Rodrigo Castellon, Niladri Chatterji, Annie\nChen, Kathleen Creel, Jared Quincy Davis, Dora\nDemszky, Chris Donahue, Moussa Doumbouya,\nEsin Durmus, Stefano Ermon, John Etchemendy,\nKawin Ethayarajh, Li Fei-Fei, Chelsea Finn, Trevor\nGale, Lauren Gillespie, Karan Goel, Noah Goodman,\nShelby Grossman, Neel Guha, Tatsunori Hashimoto,\nPeter Henderson, John Hewitt, Daniel E. Ho, Jenny\nHong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil\nJain, Dan Jurafsky, Pratyusha Kalluri, Siddharth\nKaramcheti, Geoff Keeling, Fereshte Khani, Omar\nKhattab, Pang Wei Kohd, Mark Krass, Ranjay Kr-\nishna, Rohith Kuditipudi, Ananya Kumar, Faisal Lad-\nhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle\nLevent, Xiang Lisa Li, Xuechen Li, Tengyu Ma,\nAli Malik, Christopher D. Manning, Suvir Mirchan-\ndani, Eric Mitchell, Zanele Munyikwa, Suraj Nair,\nAvanika Narayan, Deepak Narayanan, Ben Newman,\nAllen Nie, Juan Carlos Niebles, Hamed Nilforoshan,\nJulian Nyarko, Giray Ogut, Laurel Orr, Isabel Pa-\npadimitriou, Joon Sung Park, Chris Piech, Eva Porte-\nlance, Christopher Potts, Aditi Raghunathan, Rob\nReich, Hongyu Ren, Frieda Rong, Yusuf Roohani,\nCamilo Ruiz, Jack Ryan, Christopher Ré, Dorsa\nSadigh, Shiori Sagawa, Keshav Santhanam, Andy\nShih, Krishnan Srinivasan, Alex Tamkin, Rohan\nTaori, Armin W. Thomas, Florian Tramèr, Rose E.\nWang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai\nWu, Sang Michael Xie, Michihiro Yasunaga, Jiaxuan\nYou, Matei Zaharia, Michael Zhang, Tianyi Zhang,\nXikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn\nZhou, and Percy Liang. 2021. On the Opportunities\nand Risks of Foundation Models. arXiv:2108.07258\n[cs]. ArXiv: 2108.07258.\nMaurice Boothe, Collin Yu, Armanda Lewis, and Xavier\nOchoa. 2022. Towards a Pragmatic and Theory-\nDriven Framework for Multimodal Collaboration\nFeedback. In LAK22: 12th International Learning\nAnalytics and Knowledge Conference, LAK22, pages\n507–513, New York, NY , USA. Association for Com-\nputing Machinery.\nSamuel R. Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D. Manning. 2015. A large anno-\ntated corpus for learning natural language inference.\narXiv:1508.05326 [cs]. ArXiv: 1508.05326.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language Models are Few-Shot Learners.\narXiv:2005.14165 [cs]. ArXiv: 2005.14165.\nAylin Caliskan, Joanna J. Bryson, and Arvind\nNarayanan. 2017. Semantics derived automatically\nfrom language corpora contain human-like biases.\nScience, 356(6334):183–186.\nJean Carletta, Simone Ashby, Sebastien Bourban, Mike\nFlynn, Mael Guillemot, Thomas Hain, Jaroslav\nKadlec, Vasilis Karaiskos, Wessel Kraaij, Melissa\nKronenthal, Guillaume Lathoud, Mike Lincoln,\nAgnes Lisowska, Iain McCowan, Wilfried Post, Den-\nnis Reidsma, and Pierre Wellner. 2006. The AMI\nMeeting Corpus: A Pre-announcement. In Steve Re-\nnals and Samy Bengio, editors,Machine Learning for\nMultimodal Interaction, volume 3869, pages 28–39.\nSpringer Berlin Heidelberg, Berlin, Heidelberg.\nBenjamin Clavié and Kobi Gal. 2019. EduBERT: Pre-\ntrained Deep Language Models for Learning Analyt-\nics. arXiv:1912.00690 [cs]. ArXiv: 1912.00690.\nNational Research Council. 2011. Assessing 21st Cen-\ntury Skills: Summary of a Workshop . National\nAcademies Press, Washington, D.C.\n207\nMutlu Cukurova, Rose Luckin, Eva Millán, and Manolis\nMavrikis. 2018. The NISPI framework: Analysing\ncollaborative problem-solving from students’ phys-\nical interactions. Computers & Education, 116:93–\n109.\nEmily Dinan, Angela Fan, Ledell Wu, Jason Weston,\nDouwe Kiela, and Adina Williams. 2020. Multi-\nDimensional Gender Bias Classification. pages 314–\n331.\nFinale Doshi-Velez and Been Kim. 2017. Towards A\nRigorous Science of Interpretable Machine Learning.\narXiv:1702.08608 [cs, stat]. ArXiv: 1702.08608.\nNia Dowell, Yiwen Lin, Andrew Godfrey, and Christo-\npher Brooks. 2019. Promoting Inclusivity Through\nTime-Dynamic Discourse Analysis in Digitally-\nMediated Collaborative Learning. In Artificial In-\ntelligence in Education, Lecture Notes in Computer\nScience, pages 207–219, Cham. Springer Interna-\ntional Publishing.\nCynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer\nReingold, and Rich Zemel. 2012. Fairness through\nAwareness. In Proceedings of the 3rd innovations\nin theoretical computer science conference , pages\n214–226. ACM.\nErik Ekstedt and Gabriel Skantze. 2020. TurnGPT: a\nTransformer-based Language Model for Predicting\nTurn-taking in Spoken Dialog. Findings of the Asso-\nciation for Computational Linguistics: EMNLP 2020,\npages 2981–2990. ArXiv: 2010.10874.\nRobert L. Goldstone and Todd M. Gureckis. 2009.\nCollective Behavior. Topics in Cognitive Science ,\n1(3):412–438.\nMandy Guo, Yinfei Yang, Daniel Cer, Qinlan Shen, and\nNoah Constant. 2020. MultiReQA: A Cross-Domain\nEvaluation for Retrieval Question Answering Models.\narXiv:2005.02507 [cs]. ArXiv: 2005.02507.\nHe He, Anusha Balakrishnan, Mihail Eric, and Percy\nLiang. 2017. Learning Symmetric Collaborative\nDialogue Agents with Dynamic Knowledge Graph\nEmbeddings. arXiv:1704.07130 [cs] . ArXiv:\n1704.07130.\nKenneth Holstein and Shayan Doroudi. 2021. Eq-\nuity and Artificial Intelligence in Education: Will\n\"AIEd\" Amplify or Alleviate Inequities in Educa-\ntion? arXiv:2104.12920 [cs]. ArXiv: 2104.12920.\nWenlong Huang, Pieter Abbeel, Deepak Pathak, and\nIgor Mordatch. 2022. Language Models as Zero-\nShot Planners: Extracting Actionable Knowledge for\nEmbodied Agents. arXiv:2201.07207 [cs]. ArXiv:\n2201.07207.\nBen Hutchinson, Vinodkumar Prabhakaran, Emily Den-\nton, Kellie Webster, Yu Zhong, and Stephen Denuyl.\n2020. Social Biases in NLP Models as Barriers for\nPersons with Disabilities. arXiv:2005.00813 [cs].\nArXiv: 2005.00813.\nMd Mofijul Islam and Tariq Iqbal. 2021. Multi-GAT: A\nGraphical Attention-Based Hierarchical Multimodal\nRepresentation Learning Approach for Human Ac-\ntivity Recognition. IEEE Robotics and Automation\nLetters, 6(2):1729–1736.\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B.\nBrown, Benjamin Chess, Rewon Child, Scott Gray,\nAlec Radford, Jeffrey Wu, and Dario Amodei.\n2020. Scaling Laws for Neural Language Models.\narXiv:2001.08361 [cs, stat]. ArXiv: 2001.08361.\nEmily Lai, Kristen DiCerbo, and Peter Foltz. 2017.\nSkills for Today: What We Know about Teaching\nand Assessing Collaboration. Pearson.\nMina Lee, Percy Liang, and Qian Yang. 2022. CoAu-\nthor: Designing a Human-AI Collaborative Writing\nDataset for Exploring Language Model Capabilities.\narXiv:2201.06796 [cs]. ArXiv: 2201.06796.\nShervin Minaee, Nal Kalchbrenner, Erik Cambria, Nar-\njes Nikzad, Meysam Chenaghlu, and Jianfeng Gao.\n2021. Deep Learning Based Text Classification: A\nComprehensive Review. arXiv:2004.03705 [cs, stat].\nArXiv: 2004.03705.\nMichal E. Mor-Barak and David A. Cherin. 1998. A\nTool to Expand Organizational Understanding of\nWorkforce Diversity. Administration in Social Work,\n22(1):47–64.\nNikita Nangia, Saku Sugawara, Harsh Trivedi, Alex\nWarstadt, Clara Vania, and Samuel R. Bowman. 2021.\nWhat Ingredients Make for an Effective Crowd-\nsourcing Protocol for Difficult NLU Data Collection\nTasks? In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Papers),\npages 1221–1235, Online. Association for Computa-\ntional Linguistics.\nXavier Ochoa, Katherine Chiluiza, Gonzalo Mén-\ndez, Gonzalo Luzardo, Bruno Guamán, and James\nCastells. 2013. Expertise estimation based on simple\nmultimodal features. In Proceedings of the 15th ACM\non International conference on multimodal interac-\ntion, ICMI ’13, pages 583–590, Sydney, Australia.\nAssociation for Computing Machinery.\nOECD. 2015. PISA 2015 Assessment and Analytical\nFramework: Science, Reading, Mathematic, Finan-\ncial Literacy and Collaborative Problem Solving.\nCatharine Oertel, Fred Cummins, Jens Edlund, Petra\nWagner, and Nick Campbell. 2013. D64: a corpus of\nrichly recorded conversational interaction. Journal\non Multimodal User Interfaces, 7(1-2):19–28.\nSambit Praharaj, Maren Scheffel, Hendrik Drachsler,\nand Marcus Specht. 2018. MULTIFOCUS - MULTI-\nmodal Learning Analytics FOr Co-located Collabora-\ntion Understanding and Support. Proceedings of the\n13th EC-TEL Doctoral Consortium co-located with\n13th European Conference on Technology Enhanced\n208\nLearning (EC-TEL 2018), Leeds, UK, September 3rd,\n2018.\nSambit Praharaj, Maren Scheffel, Marcel Schmitz, Mar-\ncus Specht, and Hendrik Drachsler. 2021. Towards\nAutomatic Collaboration Analytics for Group Speech\nData Using Learning Analytics. Sensors, 21(9):3156.\nSamuel L. Pugh, Arjun Rao, Angela E.B. Stewart, and\nSidney K. D’Mello. 2022. Do Speech-Based Collab-\noration Analytics Generalize Across Task Contexts?\nIn LAK22: 12th International Learning Analytics\nand Knowledge Conference, pages 208–218, Online\nUSA. ACM.\nAlec Radford and Karthik Narasimhan. 2018. Im-\nproving Language Understanding by Generative Pre-\nTraining. undefined.\nWasifur Rahman, Md Kamrul Hasan, Sangwu Lee,\nAmir Zadeh, Chengfeng Mao, Louis-Philippe\nMorency, and Ehsan Hoque. 2020. Integrating Multi-\nmodal Information in Large Pretrained Transformers.\narXiv:1908.05787 [cs, stat]. ArXiv: 1908.05787.\nJoseph A. Rios, Guangming Ling, Robert Pugh, Dovid\nBecker, and Adam Bacall. 2020. Identifying Critical\n21st-Century Skills for Workplace Success: A Con-\ntent Analysis of Job Advertisements. Educational\nResearcher, 49(2):80–89.\nRamon Sanabria, Ozan Caglayan, Shruti Palaskar,\nDesmond Elliott, Loïc Barrault, Lucia Specia, and\nFlorian Metze. 2018. How2: A Large-scale\nDataset for Multimodal Language Understanding.\narXiv:1811.00347 [cs]. ArXiv: 1811.00347.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and\nThomas Wolf. 2020. DistilBERT, a distilled ver-\nsion of BERT: smaller, faster, cheaper and lighter.\narXiv:1910.01108 [cs]. ArXiv: 1910.01108.\nMaarten Sap, Saadia Gabriel, Lianhui Qin, Dan Juraf-\nsky, Noah A. Smith, and Yejin Choi. 2020. Social\nBias Frames: Reasoning about Social and Power Im-\nplications of Language. pages 5477–5490.\nJia Tracy Shen, Michiharu Yamashita, Ethan Prihar, Neil\nHeffernan, Xintao Wu, Ben Graff, and Dongwon Lee.\n2021. MathBERT: A Pre-trained Language Model\nfor General NLP Tasks in Mathematics Education.\narXiv:2106.07340 [cs]. ArXiv: 2106.07340.\nAmanpreet Singh, Ronghang Hu, Vedanuj Goswami,\nGuillaume Couairon, Wojciech Galuba, Marcus\nRohrbach, and Douwe Kiela. 2022. FLA V A: A Foun-\ndational Language And Vision Alignment Model.\narXiv:2112.04482 [cs]. ArXiv: 2112.04482.\nEmma Strubell, Ananya Ganesh, and Andrew Mc-\nCallum. 2020. Energy and Policy Considerations\nfor Modern Deep Learning Research. Proceedings\nof the AAAI Conference on Artificial Intelligence ,\n34(09):13693–13696.\nAbhijit Suresh, Jennifer Jacobs, Vivian Lai, Chen-\nhao Tan, Wayne Ward, James H. Martin, and\nTamara Sumner. 2021. Using Transformers to Pro-\nvide Teachers with Personalized Feedback on their\nClassroom Discourse: The TalkMoves Application.\narXiv:2105.07949 [cs]. ArXiv: 2105.07949.\nYi Tay, Mostafa Dehghani, Jinfeng Rao, William\nFedus, Samira Abnar, Hyung Won Chung, Sha-\nran Narang, Dani Yogatama, Ashish Vaswani, and\nDonald Metzler. 2021. Scale Efficiently: Insights\nfrom Pre-training and Fine-tuning Transformers.\narXiv:2109.10686 [cs]. ArXiv: 2109.10686.\nYulia Tsvetkov, Vinodkumar Prabhakaran, and Rob\nV oigt. 2018. Socially Responsible NLP. In Pro-\nceedings of the 2018 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Tutorial Abstracts , pages 24–26, New\nOrleans, Louisiana. Association for Computational\nLinguistics.\nLaura Weidinger, John Mellor, Maribeth Rauth, Conor\nGriffin, Jonathan Uesato, Po-Sen Huang, Myra\nCheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh,\nZac Kenton, Sarah Brown, Will Hawkins, Tom\nStepleton, Courtney Biles, Abeba Birhane, Julia\nHaas, Laura Rimell, Lisa Anne Hendricks, William\nIsaac, Sean Legassick, Geoffrey Irving, and Iason\nGabriel. 2021. Ethical and social risks of harm from\nLanguage Models. Technical report, DeepMind.\nMark E. Whiting, Grant Hugh, and Michael S. Bernstein.\n2019. Fair Work: Crowd Work Minimum Wage with\nOne Line of Code. Proceedings of the AAAI Con-\nference on Human Computation and Crowdsourcing,\n7:197–206.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,\nJoe Davison, Sam Shleifer, Patrick von Platen, Clara\nMa, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le\nScao, Sylvain Gugger, Mariama Drame, Quentin\nLhoest, and Alexander M. Rush. 2020. Hugging-\nFace’s Transformers: State-of-the-art Natural Lan-\nguage Processing. arXiv:1910.03771 [cs]. ArXiv:\n1910.03771.\nMarcelo Worsley and Paulo Blikstein. 2015. Leveraging\nmultimodal learning analytics to differentiate student\nlearning strategies. In Proceedings of the Fifth In-\nternational Conference on Learning Analytics And\nKnowledge, LAK ’15, pages 360–367, Poughkeepsie,\nNew York. Association for Computing Machinery.\nMarcelo Worsley and Xavier Ochoa. 2020. Towards col-\nlaboration literacy development through multimodal\nlearning analytics. In Companion Proceedings 10th\nInternational Conference on Learning Analytics &\nKnowledge (LAK20), volume 2610, pages 53–63.\nI. I. I. Wray, James R. Kirk, and John E. Laird. 2021.\nLanguage Models as a Knowledge Source for Cog-\nnitive Agents. arXiv:2109.08270 [cs] . ArXiv:\n2109.08270.\n209\nH. Peyton Young. 1995. Equity: in theory and practice,\n1. princeton paperback printing edition. A Russell\nSage Foundation book. Princeton Univ. Press, Prince-\nton, NJ.\nMehdi Yousfi-Monod and Violaine Prince. 2007.\nKnowledge Acquisition Modeling through Dialog Be-\ntween Cognitive Agents. International Journal of In-\ntelligent Information Technologies (IJIIT), 3(1):060.\n210",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7675602436065674
    },
    {
      "name": "Learning analytics",
      "score": 0.6304612159729004
    },
    {
      "name": "Human–computer interaction",
      "score": 0.46098193526268005
    },
    {
      "name": "Language model",
      "score": 0.43760547041893005
    },
    {
      "name": "Data science",
      "score": 0.3528563380241394
    },
    {
      "name": "Artificial intelligence",
      "score": 0.34854793548583984
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I57206974",
      "name": "New York University",
      "country": "US"
    }
  ]
}