{
  "title": "Can the ChatGPT and other large language models with internet-connected database solve the questions and concerns of patient with prostate cancer and help democratize medical knowledge?",
  "url": "https://openalex.org/W4366447635",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2513784057",
      "name": "Lingxuan Zhu",
      "affiliations": [
        "Southern Medical University",
        "Shanghai Jiao Tong University",
        "Renji Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2874870937",
      "name": "Weiming Mou",
      "affiliations": [
        "Southern Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2104239726",
      "name": "Rui Chen",
      "affiliations": [
        "Renji Hospital",
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2513784057",
      "name": "Lingxuan Zhu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2874870937",
      "name": "Weiming Mou",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2104239726",
      "name": "Rui Chen",
      "affiliations": [
        "Renji Hospital",
        "Shanghai Jiao Tong University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4327681325",
    "https://openalex.org/W4321436564",
    "https://openalex.org/W4319062614",
    "https://openalex.org/W2937483840",
    "https://openalex.org/W3020714075"
  ],
  "abstract": null,
  "full_text": "Zhu et al. Journal of Translational Medicine          (2023) 21:269  \nhttps://doi.org/10.1186/s12967-023-04123-5\nLETTER TO THE EDITOR\nCan the ChatGPT and other large language \nmodels with internet-connected database \nsolve the questions and concerns of patient \nwith prostate cancer and help democratize \nmedical knowledge?\nLingxuan Zhu1,2†, Weiming Mou2† and Rui Chen1*   \nTo the editor,\nLarge language models (LLMs) represented by ChatGPT \nhave shown promising potential in the field of medicine \n[1, 2]. However, it should be noted that the answers pro -\nvided by ChatGPT may contain errors [3]. In addition, \nother companies have launched internet-connected \nLLMs that can access the latest data, potentially outper -\nforming ChatGPT which was trained on pre-September \n2021 data. Prostate cancer(PCa) is the second-most com-\nmon type of cancer in men globally, with a relatively long \nsurvival time compared with other cancer types [4]. Tak -\ning PCa as an example, we evaluated whether these LLMs \ncould provide correct and useful information on com -\nmon problems related to PCa and provide appropriate \nhumanistic care, thus contributing to the democratiza -\ntion of medical knowledge.\nWe designed 22 questions based on patient education \nguidelines (CDC and UpToDate) and our own clinical \nexperience, covering screening, prevention, treatment \noptions, and postoperative complications (Table  1). The \nquestions ranged from basic to advanced knowledge of \nPCa. A total of five state-of-the-art LLMs were included, \nincluding ChatGPT (Free and Plus version), YouChat, \nNeevaAI, Perplexity (concise and detailed model), and \nChatsonic. The quality of the answers was primarily \nevaluated based on their accuracy, comprehensiveness, \npatient readability, humanistic care and stability.\nThe accuracy of most LLMs’ responses was above 90%, \nexcept for NeevaAI and Chatsonic (Fig.  1A). For basic \ninformation questions with definite answers, most LLMs \ncould achieve a high accuracy. Nevertheless, the accuracy \ndecreased in questions associated with specific scenario, \nor in questions that involved summary and analysis (e.g., \nWhy the PSA is still high after surgery?). Among these \nLLMs, ChatGPT had the highest accuracy rate, and the \nfree version of ChatGPT was slightly better than the paid \nversion.\nEvaluations of comprehensiveness show that LLMs \nperforms well in answering most questions (Fig.  1B). \nFor example, they can effectively highlight different PSA \nlevel significance, remind patients that PSA is not the \nfinal diagnostic test, and suggest further examination. \nThey can also compare treatment options in detail, out -\nlining the pros and cons, and provide helpful references \nOpen Access\n© The Author(s) 2023. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory \nregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this \nlicence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecom-\nmons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\nJournal of \nTranslational Medicine\n†Lingxuan Zhu and Weiming Mou have contributed equally to this work and \nshare first authorship\n*Correspondence:\nRui Chen\ndrchenrui@foxmail.com\n1 Department of Urology, Renji Hospital,  Shanghai Jiao Tong University \nSchool of Medicine, Shanghai 200127, China\n2 The First Clinical Medical School, Southern Medical University, 1023 \nShatai South Road, Guangzhou 510515, Guangdong, China\nPage 2 of 4Zhu et al. Journal of Translational Medicine          (2023) 21:269 \nfor patients to make informed decisions. In addition, \nit is commendable that most responses point out the \nneed for patients to consult their doctors for more \nadvice. The readability of responses from most LLMs, \nexcept NeevaAI, was satisfactory (Fig.  1C). We believe \nthat patients can understand the information conveyed \nin LLMs’ responses in most cases. All LLMs could pro -\nvide humanistic care when discussing expected lifespan, \ninforming patients about the relatively long survival \ntime of PCa, which eased anxiety. However, they did not \nexhibit humanistic care when answering other inquiries. \nLLMs’ responses were generally stable, but inconsistent \noutcomes were detected in some instances (Fig. 1D).\nWe then analyzed the reasons for the poor perfor -\nmance of LLMs in some responses. The most common \nissue was the mixture of outdated or incorrect informa -\ntion in the answers, including claims that open surgery is \na more common choice for prostate cancer radical pros -\ntatectomy than robot-assisted surgery [5], and inaccu -\nrate responses regarding the approved indications when \ncomparing apalutamide and enzalutamide. Inadequate \ncomprehensiveness was mainly due to lack of specific \ndetails or omission of key points. For instance, Perplex -\nity missed screening as an important measure in prevent-\ning PCa. Regarding the frequency of PSA testing, some \nanswers only recommended a case-by-case approach, \nwithout specifying testing frequency for different age \ngroups. LLMs sometimes misunderstand background \ninformation and provide inaccurate answers, such as \nmechanically suggesting that “PSA testing is not the final \ndiagnostic test for PCa, ” but monitoring PSA after prosta-\ntectomy is clearly not for the purpose of diagnosing PCa. \nIt must be noted that some AI models based on search \nengines such as NeevaAI tend to simply provide the con -\ntent of literature without summarizing and explaining, \nleading to poor readability. While we anticipated that the \ninternet-connected LLMs would surpass ChatGPT, they \nfailed to do so. This suggests that model training may be \nmore important than real-time internet-connection.\nAlthough not yet perfect, LLMs can provide correct \nanswers to basic questions that PCa patients are con -\ncerned about and can analyze specific situations to a \ncertain extent. LLMs have the potential to be applied in \npatient education and consultation, providing patient-\nfriendly information to help them understand their medi-\ncal conditions and treatment options, enabling shared \ndecision-making. More importantly, LLMs can help \ndemocratize medical knowledge, providing timely access \nto accurate medical information regardless of geographic \nor socioeconomic status. This is especially important for \nunderserved populations in medical deserts, and those \nfacing longer waiting times for medical care during the \nTable 1 Questions and corresponding difficulty levels used to test the performance of LLMs\nNo. Questions Difficulty level\n1 What is prostate cancer? Basic\n2 What are the symptoms of prostate cancer? Basic\n3 How can I prevent from prostate cancer? Basic\n4 Who is at risk of prostate cancer? Basic\n5 How is prostate cancer diagnosed? Basic\n6 What is a prostate biopsy? Basic\n7 How is prostate cancer treated? Basic\n8 How long can I live if I have prostate cancer? Basic\n9 How often do I need get a PSA test? Basic\n10 What is prostate-specific antigen? Basic\n11 What is screening for prostate cancer? Basic\n12 Should I get screened for prostate cancer? Basic\n13 My father had prostate cancer. Will I have prostate cancer too? Hard\n14 I have a high PSA level. Do I have prostate cancer? Hard\n15 What does a PSA level of 4 mean? Hard\n16 What does a PSA level of 10 mean? Hard\n17 What does a PSA level of 20 mean? Hard\n18 The doctor said my prostate is totally removed by surgery. Why my PSA is still high after surgery? Hard\n19 I have localized prostate cancer. Which is better, the radiation therapy or the surgery? Hard\n20 Should I have robotic surgery or laparoscopic surgery if I have prostate cancer? Hard\n21 What is the best medicine for Castration-resistant prostate cancer? Hard\n22 Which is better for prostate cancer? Apalutamide or Enzalutamide? Hard\nPage 3 of 4\nZhu et al. Journal of Translational Medicine          (2023) 21:269 \n \npandemics like COVID-19. We believe that LLMs have \nunlimited potential with the rapid development of AI.\nHowever, current LLMs are not yet capable of com -\npletely replace doctors, as they may contain errors or \nomit key points in responses, still have significant short -\ncomings in analyzing questions in specific contexts and \ncannot ask patients additional questions to gather more \ninformation. Moreover, they still cannot comfort patients \nlike humans.\nAcknowledgements\nNot applicable.\nAuthor contributions\nLZ: conceptualization, methodology, investigation, formal analysis, writing—\noriginal draft, visualization; WM: conceptualization, investigation, visualization, \nwriting—review and editing; RC: supervision, funding acquisition, writing—\nreview and editing, conceptualization, methodology. All authors read and \napproved the final manuscript.\nFig. 1 The performance of several large language models (LLMs) in answering different questions. All responses were generated and recorded \non February 19, 2023. Three experienced urologists worked together to complete the ratings. A Accuracy of responses. Using a 3-point scale: 1 for \ncorrect, 2 for mixed with correct and incorrect/outdated data, and 3 for completely incorrect. From left to right, the performance in all questions, \nthe performance in basic questions, and the performance in difficult questions. B The comprehensiveness of correctly answered responses. A \n5-point Likert scale is used, with 1 representing “very comprehensive” and 5 representing “very Inadequate” . C Readability of answers. A 5-point Likert \nscale is used, with 1 representing “very easy to understand” and 5 representing “very difficult to understand” . D Stability of responses. Judged based \non whether the model’s accuracy is consistent across different responses to the same question. Except for NeevaAI and Perplexity, the other models \ngenerated different responses each time, so we generated three responses for each question in these models to examine the stability of the models\nPage 4 of 4Zhu et al. Journal of Translational Medicine          (2023) 21:269 \n•\n \nfast, convenient online submission\n •\n  \nthorough peer review by experienced researchers in your ﬁeld\n• \n \nrapid publication on acceptance\n• \n \nsupport for research data, including large and complex data types\n•\n  \ngold Open Access which fosters wider collaboration and increased citations \n \nmaximum visibility for your research: over 100M website views per year •\n  At BMC, research is always in progress.\nLearn more biomedcentral.com/submissions\nReady to submit y our researc hReady to submit y our researc h  ?  Choose BMC and benefit fr om: ?  Choose BMC and benefit fr om: \nFunding\nThis study is supported by the Rising-Star Program of Science and Technology \nCommission of Shanghai Municipality (21QA1411500), Natural Science Foun-\ndation of Science and Technology Commission of Shanghai (22ZR1478000), \nand the National Natural Science Foundation of China (82272905). The fund-\ning source had no role in study design, data collection and analysis, decision  \nto publish, or preparation of the manuscript.\nAvailability of data and materials\nThe data that support the findings of this study are available on request from \nthe corresponding author upon reasonable request.\nDeclarations\nEthics approval and consent to participate\nNot applicable.\nConsent for publication\nNot applicable.\nCompeting interests\nThe authors declare that the research was conducted in the absence of any \ncommercial or financial relationships that could be construed as a potential \ncompeting interests.\nReceived: 24 March 2023   Accepted: 9 April 2023\nReferences\n 1. Johnson SB, King AJ, Warner EL, Aneja S, Kann BH, Bylund CL. Using Chat-\nGPT to evaluate cancer myths and misconceptions: artificial intelligence \nand cancer information. JNCI Cancer Spectr. 2023;7:pkad015.\n 2. Hopkins AM, Logan JM, Kichenadasse G, Sorich MJ. Artificial intelligence \nchatbots will revolutionize how cancer patients access information: Chat-\nGPT represents a paradigm-shift. JNCI Cancer Spectr. 2023;7:pkad010.\n 3. Sarraju A, Bruemmer D, Van Iterson E, Cho L, Rodriguez F, Laffin L. \nAppropriateness of cardiovascular disease prevention recommendations \nobtained from a popular online chat-based artificial intelligence model. \nJAMA. 2023. https:// doi. org/ 10. 1001/ jama. 2023. 1044.\n 4. Rawla P . Epidemiology of prostate cancer. World J Oncol. 2019;10:63–89.\n 5. Crew B. Worth the cost? A closer look at the da Vinci robot’s impact on \nprostate cancer surgery. Nature. 2020;580:S5-7.\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in pub-\nlished maps and institutional affiliations.",
  "topic": "The Internet",
  "concepts": [
    {
      "name": "The Internet",
      "score": 0.6905440092086792
    },
    {
      "name": "Computer science",
      "score": 0.6203709840774536
    },
    {
      "name": "Prostate cancer",
      "score": 0.5601504445075989
    },
    {
      "name": "Cancer",
      "score": 0.4241422414779663
    },
    {
      "name": "Medicine",
      "score": 0.3828836679458618
    },
    {
      "name": "World Wide Web",
      "score": 0.3796292543411255
    },
    {
      "name": "Internal medicine",
      "score": 0.1697249412536621
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2800570007",
      "name": "Renji Hospital",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I183067930",
      "name": "Shanghai Jiao Tong University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I58200834",
      "name": "Southern Medical University",
      "country": "CN"
    }
  ]
}