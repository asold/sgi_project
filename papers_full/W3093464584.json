{
  "title": "Empirical study of transformers for source code",
  "url": "https://openalex.org/W3093464584",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2889654865",
      "name": "Nadezhda Chirkova",
      "affiliations": [
        "National Research University Higher School of Economics"
      ]
    },
    {
      "id": "https://openalex.org/A2761191295",
      "name": "Sergey Troshin",
      "affiliations": [
        "National Research University Higher School of Economics"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3034689979",
    "https://openalex.org/W2799855324",
    "https://openalex.org/W2979792666",
    "https://openalex.org/W2887364112",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3098605233",
    "https://openalex.org/W2605202003",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2884276923",
    "https://openalex.org/W2516621648",
    "https://openalex.org/W3011564318",
    "https://openalex.org/W2964194820",
    "https://openalex.org/W2768572539",
    "https://openalex.org/W2533695286",
    "https://openalex.org/W3022049116",
    "https://openalex.org/W2238673293",
    "https://openalex.org/W2963925437",
    "https://openalex.org/W2997847174",
    "https://openalex.org/W2963355447",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2888557792",
    "https://openalex.org/W2964772344"
  ],
  "abstract": "Initially developed for natural language processing (NLP), Transformers are\\nnow widely used for source code processing, due to the format similarity\\nbetween source code and text. In contrast to natural language, source code is\\nstrictly structured, i.e., it follows the syntax of the programming language.\\nSeveral recent works develop Transformer modifications for capturing syntactic\\ninformation in source code. The drawback of these works is that they do not\\ncompare to each other and consider different tasks. In this work, we conduct a\\nthorough empirical study of the capabilities of Transformers to utilize\\nsyntactic information in different tasks. We consider three tasks (code\\ncompletion, function naming and bug fixing) and re-implement different\\nsyntax-capturing modifications in a unified framework. We show that\\nTransformers are able to make meaningful predictions based purely on syntactic\\ninformation and underline the best practices of taking the syntactic\\ninformation into account for improving the performance of the model.\\n",
  "full_text": null,
  "topic": null,
  "concepts": [],
  "institutions": [
    {
      "id": "https://openalex.org/I118501908",
      "name": "National Research University Higher School of Economics",
      "country": "RU"
    }
  ],
  "cited_by": 48
}