{
  "title": "A Framework for Exploring Player Perceptions of LLM-Generated Dialogue in Commercial Video Games",
  "url": "https://openalex.org/W4389519934",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2773695560",
      "name": "Nader Akoury",
      "affiliations": [
        "University of Massachusetts Amherst"
      ]
    },
    {
      "id": "https://openalex.org/A2004076105",
      "name": "Qian Yang",
      "affiliations": [
        "Cornell University"
      ]
    },
    {
      "id": "https://openalex.org/A2068391019",
      "name": "Mohit Iyyer",
      "affiliations": [
        "University of Massachusetts Amherst"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4385734098",
    "https://openalex.org/W3166797128",
    "https://openalex.org/W2998557583",
    "https://openalex.org/W4404782613",
    "https://openalex.org/W4288804596",
    "https://openalex.org/W3100501376",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3172150561",
    "https://openalex.org/W4385571412",
    "https://openalex.org/W2115196958",
    "https://openalex.org/W3177813494",
    "https://openalex.org/W2971077754",
    "https://openalex.org/W4362649003",
    "https://openalex.org/W2631156816",
    "https://openalex.org/W3024131638",
    "https://openalex.org/W4385572789",
    "https://openalex.org/W4385573754",
    "https://openalex.org/W3132711960",
    "https://openalex.org/W4385574333",
    "https://openalex.org/W4386566467",
    "https://openalex.org/W3103780890",
    "https://openalex.org/W4291028494",
    "https://openalex.org/W3211384372",
    "https://openalex.org/W2979355707",
    "https://openalex.org/W1574298831",
    "https://openalex.org/W4389519421",
    "https://openalex.org/W4287891012",
    "https://openalex.org/W3174519801",
    "https://openalex.org/W3100047304"
  ],
  "abstract": "The growing capabilities of large language models (LLMs) have inspired recent efforts to integrate LLM-generated dialogue into video games. However, evaluation remains a major challenge: how do we assess the player experience in a commercial game augmented with LLM-generated dialogue? To explore this question, we introduce a dynamic evaluation framework for the dialogue management systems that govern the task-oriented dialogue often found in roleplaying video games. We first extract dialogue from the widely-acclaimed role-playing game *Disco Elysium: The Final Cut*, which contains 1.1M words of dialogue spread across a complex graph of utterances where node reachability depends on game state (e.g., whether a certain item is held). Using this dataset, we have GPT-4 perform *dialogue infilling* to generate grounded utterances based on game state represented via code. In a statistically robust study of 28 players recruited from the r/DiscoyElysium subreddit, the LLM outputs are evaluated against the game designers' writing via both preference judgments and free-form feedback using a web interface that recreates the game's core conversation functionality. Overall, the game designers' prose is significantly preferred to GPT-4 generations, with participants citing reasons such as improved logical flow and grounding with the game state. To spur more principled future research in this area, we release our web interface and tools to enable researchers to build upon our work. https://pl.aiwright.dev",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 2295–2311\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nA Framework for Exploring Player Perceptions of LLM-Generated\nDialogue in Commercial Video Games\nNader Akoury\nUniversity of Massachusetts\nAmherst\nnsa@cs.umass.edu\nQian Yang\nCornell University\nqianyang@cornell.edu\nMohit Iyyer\nUniversity of Massachusetts\nAmherst\nmiyyer@cs.umass.edu\nAbstract\nThe growing capabilities of large language\nmodels (LLMs) have inspired recent efforts to\nintegrate LLM-generated dialogue into video\ngames. However, evaluation remains a ma-\njor challenge: how do we assess the player\nexperience in a commercial game augmented\nwith LLM-generated dialogue? To explore this\nquestion, we introduce a dynamic evaluation\nframework for the dialogue management sys-\ntems that govern the task-oriented dialogue of-\nten found in roleplaying video games. We first\nextract dialogue from the widely-acclaimed\nrole-playing game Disco Elysium: The Final\nCut, which contains 1.1M words of dialogue\nspread across a complex graph of utterances\nwhere node reachability depends on game state\n(e.g., whether a certain item is held). Using\nthis dataset, we have GPT-4 performdialogue\ninfilling to generate grounded utterances based\non game state represented via code. In a statisti-\ncally robust study of 28 players recruited from\nthe r/DiscoElysium subreddit, the LLM out-\nputs are evaluated against the game designers’\nwriting via both preference judgments and free-\nform feedback using a web interface that recre-\nates the game’s core conversation functionality.\nOverall, the game designers’ prose is signif-\nicantly preferred to GPT-4 generations, with\nparticipants citing reasons such as improved\nlogical flow and grounding with the game state.\nTo spur more principled future research in this\narea, we release our web interface and tools to\nenable researchers to build upon our work.1\n1 Introduction\nDialogue in most narrative-driven video games has\nhistorically been static: players may choose from a\nsmall number of pre-written dialogue options that\ndepend on the game’s state (e.g., items held or goals\nachieved). The advent of large language models\n(LLMs) has inspired efforts to dynamically gener-\nate dialogue in video game environments, such as\n1https://pl.aiwright.dev\nthose by AI Dungeon (Walton, 2019), InWorld AI\n(Gelfenbeyn et al., 2021), and ConvAI (Mukherjee,\n2022), which can potentially imbue games with\nendless variety.2 However, evaluating the impacts\nof LLM-generated dialogue on the player experi-\nence has yet to be tackled in a principled manner.\nIn this paper, we directly evaluate the player ex-\nperience by asking video gamers to interact with\nLLM-generated dialogue injected into Disco Ely-\nsium: The Final Cut, a highly-acclaimed dialogue-\ncentered video game (Kurvitz et al., 2021). 3 To\nmitigate difficulties with evaluating open-ended\ntext generation (Karpinska et al., 2021), we specif-\nically examine a constrained dialogue generation\ntask in which an LLM must decide how to update\na dialogue to match the corresponding game state.\nTake for example a scene in which the\ngame’s protagonist (an amnesiac detective) is\ninterrogating an uncooperative suspect. If\nthe player decides to act like the suspect’s\nfriend to obtain more information, the vari-\nable seafort.deserter_sugg_you_are_buddies is set\nto true, and the corresponding line of dialogue\nis:\nYou can tell me, here. It won’t be *that* usable.\nContinuing the example, we then prompt an\nLLM to appropriately modify the dialogue when\nthe variable seafort.deserter_i_am_also_communist\nis set to true. We evaluate the generated dialogue\nagainst the game writers’ original line:\nYou can tell a comrade. It won’t be *that* usable.\nWhile the semantics of the utterance remains\nmostly unchanged, the player’s assumed commu-\nnist persona is reflected in the second dialogue.\nThese dialogue options, and any associated non-\nplayer character (NPC) responses, are defined us-\n2See for example Nvidia’s recent ACE demo.\n3Disco Elysium: The Final Cut is currently rated the #1\nPC video game of all time on Metacritic.\n2295\ning a graph structure commonly referred to as a “di-\nalogue tree” in the video game industry. Crucially,\nour task setup does not expect an LLM to generate\nall of the game’s dialogue (as in e.g., AI Dungeon),\nbut rather provides the LLM with human-written di-\nalogue as input and tweaks it to fit various dynamic\naspects of the game state. To condition on the game\nstate, we devise a clever approach of encoding the\ngraph structure as a mix of code and natural lan-\nguage, which also opens the possibility in future\nwork of modifying the game state in response to a\ngenerated utterance. This constrained setup makes\nthe task tractable to evaluate and also practically\nrelevant to future LLM-human collaborative game\nwriting applications.\nCan an LLM understand enough about the game\nstate to appropriately modify dialogue in a way that\nis logically and tonally consistent with the game\nstate? More generally, how does LLM-generated\ndialogue stack up with the award-winning dialogue\nwritten by Disco Elysium’s designers, and what\ndo video gamers think are the biggest issues with\nit? By choosing a popular roleplaying game with\na dedicated following, we are more easily able to\nfind participants familiar with the expected tone\nand lore needed to effectively assess our generated\ndialogue. We evaluate OpenAI’s state-of-the-art\nGPT-4 LLM (OpenAI, 2023) via a statistically ro-\nbust user study, asking Disco Elysium fans to pro-\nvide preference judgments and free-form feedback\nwithin an interface designed to mimic the game’s\ndialogue engine.\nPerhaps unsurprisingly, players strongly pre-\nfer the original dialogue (H) compared to LLM-\ngenerated dialogue (G), with participants citing\nreasons such as better logical consistency (H: 61%\nvs G: 28%) and flow (H: 67% vs G: 21%). How-\never, participants note that GPT-4 begins to close\nthe gap at providing interesting dialogue options\n(H: 47% vs G: 36%) that advance their goals (H:\n57% vs G: 33%), though further work is required\nto ground the dialogue to the game state as 32% of\ngenerations rated by at least one player are deemed\nillogical upon reading the next utterance. To facili-\ntate future research in player-centered video game\ndialogue generation, we release our annotation in-\nterface and tools to reproduce our dataset.\n2 Related Work\nCommercial video games have become increas-\ningly popular testbeds for neural approaches to\ngrounded language (Suhr et al., 2019) and re-\ninforcement learning (Bellemare et al., 2012;\nKempka et al., 2016). To the best of our knowl-\nedge, only the sandbox game Minecraft has been\nexplored as a testbed for interactive dialogue re-\nsearch (V olum et al., 2022), despite some commer-\ncial video game dialogue being explored in non-\ninteractive settings (Lopez Latouche et al., 2023;\nWeir et al., 2023).\nDialogue systems in roleplaying video games\nare task-oriented (Grosz, 1974), where quests in\nthe game act as tasks that the player must complete\nwithin the constraints of the game world. The static\npre-written dialogue graphs are a form of finite-\nstate dialogue management (Brabra et al., 2022).\nUsing such a rigidly constrained dialogue man-\nagement approach ensures the authorial intent of\nthe game writers at the expense of more natural\nconversation flows. Rather than upend these famil-\niar techniques for more flexible approaches which\nhave yet to gain traction (Riedl and Young, 2004;\nMateas and Stern, 2005), likely due to their com-\nplexity, we opt to augment the existing approaches\nactively in use in commericial video games. Our\nwork bridges the tightly scripted scenarios com-\nmon to video games, with more natural speech that\noffers humans more agency over their interaction\nwith virtual agents, leading to easier to design agent\ninteractions useful for training simulations (Demasi\net al., 2020) and tutoring (Wang et al., 2023a).\nNarrative-driven video games fall under the um-\nbrella of interactive storytelling, which can take\non many forms including tabletop roleplaying\ngames like Dungeons and Dragons (Callison-Burch\net al., 2022), choose your own adventure books\n(Clark and Smith, 2021), and interactive fiction\n(Hausknecht et al., 2020). More broadly, graph rep-\nresentations have been used for finite-state dialogue\nmanagement (Koller et al., 2018), and as knowl-\nedge bases (Gritta et al., 2021) for slot-filling ap-\nproaches (Cohen, 2019) to task-oriented dialogue.\n3 The Disco ElysiumDataset\nIn Disco Elysium: The Final Cut, the player takes\non the role of a down-on-his-luck detective in order\nto solve a murder mystery in a dystopian city. The\nmajority of in-game interactions are in the form of\ndialogue, including interactions with not only other\ncharacters but also inanimate objects (e.g., a ceiling\nfan and a bathroom mirror from the first scene of\nthe game), which makes the game well-suited for\n2296\nFigure 1: As part of the effort to decipher the data format from Disco Elysium: The Final Cut, we created a tool\nto display and analyze the dialogue graphs from the game. This tool allows for filtering data in various ways,\ndisplaying attributes of the dialogue nodes, visualizing entire conversations, creating dataset splits (Section 3.1;\nAppendix A), preprocessing dialogues into Lua scripts (Section 4.2), analyzing experiements (Section 6), and more.\nour experiments. Additionally, the game’s state is\nencoded in Lua4 via descriptively-named boolean\nvariables and getter/setter functions that trigger on\ncertain nodes of the dialogue graph. In this section,\nwe describe how we extract and process the rich di-\nalogue graph (Figure 1) and game state from Disco\nElysium for our constrained dialogue generation\ntask.\n3.1 Extracting data from Disco Elysium\nWe begin by extracting a catalog of all top-level\nentities (characters, items, conversations, dialogue\nentries, and game state variables) from a purchased\nPC version of Disco Elysium: The Final Cut using\nthe open source tool AssetStudio.5 Its prose, with\nover 70K utterances consisting of roughly 1.1M\nwords of dialogue (Table 1), is nearly twice the\nlength of Atlas Shrugged. As with many games,\nDisco Elysium encodes game state variables and\nfunctions into Lua expressions that are run by the\ngame engine based on the player’s actions.\n4https://www.lua.org\n5https://github.com/Perfare/AssetStudio\nDataset Splits\nTrain Valid Test Total\n89.8% 5.4% 4.7%\nUtterances 65,316 4,143 3,237 72,696\nWords 1,001,191 59,877 52,816 1,113,884\nNodes 98,442 6,950 5,092 110,484\nForks 17,283 1,544 964 19,791\nVariables 99,015 6,989 5,132 111,136\nTable 1: We split the data into training, validation, and\ntest sets based on the number of dialogue words, while\nensuring an approximately similar proportion of condi-\ntional dialogue forks and referenced Lua variables. See\nTable A1 for more information.\nDialogue and game state encoding: The game\nstate of Disco Elysium is an exhaustive mix of vari-\nables and functions that are descriptively named\nand commented. All dialogue entries in the graph\ninclude metadata about the character who is speak-\ning, as well as any preconditions (boolean-valued\nexpressions) required to speak the utterance. For\nexample, the first dialogue option in Figure 2’s Lua\n2297\nStep 1: Cluster similar dialogue\nStep 2: Linearize into masked Lua script\nStep 3: Generate masked dialogue\nFigure 2: In this conversation from Disco Elysium: The Final Cut , we first cluster dialogue nodes by semantic\nsimilarity of game state variables and spoken dialogue. Then, we linearize the next turn of dialogue in the graph\ninto a Lua script that contains game logic and dialogue. Finally, we <MASK> one utterance from the cluster and ask\nGPT-4 (an LLM trained on code and natural language) to infill the masked dialogue.\nscript contains the following precondition:\nif CheckPassiveSkill(\"suggestion\")\nWe also observe comments written by the game\ndevelopers used to document the intent of a variable\nor function, as in this comment before setting the\nvariable seafort.deserter_hl_threaten_with_pain:\npain for talking and respect. does not\nactually work\nThese comments provide a rich, natural source\nof context to better explain the vast array of entities\n(Table A1) referenced throughout the game logic.\nEach dialogue entry may also contain functions that\ncan alter game state when uttered that also serve as\nimportant context to understand the dialogue, as in:\nSetVariableValue(\n\"seafort.deserter_sugg_you_are_buddies\",\ntrue\n)\nCreating dataset splits: Since the dialogue in\nDisco Elysium ultimately tells a single overarching\nstory, it is not possible to create a dataset split in\nwhich each fold contains a disjoint set of charac-\nters, items, and game state variables. The game’s\ndialogue graph implicitly forms a hypergraph, with\nhyperedges defined by the Lua variables. Opti-\nmal partitioning of a hypergraph is known to be\nNP-hard, and an exhaustive enumeration is often\nmore efficient for smaller hypergraphs than spe-\ncialized algorithms (Papa and Markov, 2007). We\nuse the branch and bound algorithm to enumerate\nall valid partitions of the dialogue graph that sat-\nisfy an ϵ= 1.5% variation from the desired splits\nof 90%/5%/5% train/valid/test.6 The final split is\nachieved with minimal overlap in game variables\n(Table 1).7\n4 Grounded dialogue infilling\nAs prior text generation and dialogue research has\nclearly demonstrated (Karpinska et al., 2021; Clark\net al., 2021), evaluating LLM-generated dialogue\nis a daunting challenge. We examine a more con-\nstrained subtask in which an LLM is given multi-\nple lexically-similar human-written responses to a\ngiven utterance, each of which is slightly different\nfrom each other based on the game state. One of\nthese responses is masked out, and an LLM is asked\nto generate it based on cues from the game state\n(e.g., that communists have historically referred\nto one another as comrade). While this task is\nstrictly easier than open-ended dialogue generation,\n6Luckily, many distinct conversations are connected by one\nor more dialogue edges, making it such that a small handful\nof connected components in the graph make up roughly 70%\nof the dialogue and thus are required to be in the training set.\n7While the rest of this paper uses the validation set, in-\ncluding as a source of few-shot demonstrations to prompt\nGPT-4, we describe preliminary fine-tuning experiments on\nthe training set in Appendix C.\n2298\nwe find that state-of-the-art LLMs still struggle to\nsolve it. This section details the data filtering and\npreprocessing steps we performed, as well as the\nfew-shot prompting strategy we use with GPT-4.\n4.1 Clustering lexically-similar utterances\nWe detect lexically-similar utterances by applying\na simple token-based clustering algorithm on the\nnodes in the dialogue graph. Starting from a source\ndialogue node, we traverse all outgoing directed\npaths which terminate upon encountering a dia-\nlogue node; we collect all such sets by using each\ndialogue node as a source. Then, we tokenize the\ndialogue in each node set on whitespace and punc-\ntuation boundaries while preserving common con-\ntractions (e.g., ’ll, ’s, etc). Next, we compute bag-\nof-words F1 among utterances within each set to\nmeasure similarity, and also apply the same proce-\ndure to the associated Lua conditions. Finally, we\nconsider all disjoint subsets for which F1>= 0.5\n(for utterances or conditions), which we qualita-\ntively validated as producing clusters of high lexi-\ncal similarity.8\n4.2 Linearizing clusters into Lua scripts\nNow that we have a set of clusters, we convert\neach cluster into a single Lua script (see Figure 2,\nright) that can be fed to a language model. We\nprefix all the characters, items, comments, and\nvariables referenced by the clustered nodes at the\ntop of the script, along with default values and\nmetadata. Each node in the cluster is visited in\nsequential order, and its Lua conditions, dialogue,\nand any associated post-speech game state alter-\ning actions are included in the script. Lastly, we\nenumerate all variants of each script by masking\nout each instance in a cluster one-by-one. Our\nmasked infilling prompts use a prefix-suffix-mask\n(Donahue et al., 2020; Bavarian et al., 2022) or-\ndering, where the prefix contains the portion of the\nscript before the masked utterance, followed by the\ntext <MASK> ; the suffix contains the remainder of\nthe script, followed by <MASK> = ; and the mask\ncontains the utterance we want the model to infill,\nfollowed by <MASK:END> .\n4.3 Few-shot prompting to infill dialogue\nFrom our set of linearized Lua scripts, we build\nfew-shot prompts to perform dialogue infilling us-\ning GPT-4. We first prefix each prompt with the\n8See Appendix B for more details on alternate clustering\nalgorithms that we experimented with.\nFew-Shot Prompt Statistics\nMin Avg Max\nExample Length 158 330 2228\nExamples per Prompt 15 33 45\nTable 2: Here we report statistics for token lengths of\neach example, along with the number of examples per\nprompt.\nfollowing instruction to guide the model to gener-\nate dialogue constrained to the game state:\nYou are a creative game designer writing engag-\ning dialogue for a roleplaying game. For each\nself-contained dialogue script fill in the <MASK>\nwith interesting dialogue using only facts from\nthe script.\nThen for a given script, we select demonstrations\nfrom our validation set that do not contain any\nutterances in common with the target script. We fill\nthe full 8k context of GPT-4 with demonstrations,\nwhich we qualitatively find to produce utterances\nthat best match the game’s writing style (Table 2).9\n5 Setting up a strong user study\nEvaluating LLM-generated dialogue within a large\ncommercial video game is a complex undertak-\ning. Both automatic and crowdsourced evaluation\nlead to misleading and unreliable conclusions for\ncreative generation tasks (Karpinska et al., 2021;\nWang et al., 2023b), which motivates expert anno-\ntation (Xu et al., 2023; Karpinska and Iyyer, 2023).\nMore importantly, we want to collect evaluations\nfrom people who are actually invested in Disco\nElysium, as a primary goal of our study is to char-\nacterize how LLM-generated dialogue affects the\nplayer experience. This entails collecting evalua-\ntions within an interactive setting rather than hav-\ning annotators rate utterances in isolation. In this\nsection, we specify our evaluation setup, which in-\nvolves (1) designing an interface that mimics the\nDisco Elysium dialogue engine; (2) conducting pi-\nlot tasks to determine common error categories and\nfurther refine the interface to reduce annotator bur-\nden; and (3) recruiting participants from Reddit\nwho have completed one or more playthroughs of\nDisco Elysium to complete our main user study.\n9Additional details, including our full prompt template,\ncan be found in Appendix D.\n2299\nStep 1: read conversation context \nand select preferred response\nStep 2: provide justiﬁcation for \npreference\nStep 3: read next utterance and \nupdate preference if desired\nFigure 3: Three panels from the mobile version of our web app, which reproduces Disco Elysium’s dialogue\nengine and allows us to collect preference judgments and justifications. In the first panel, players take part in a\nconversation and are given multiple candidate responses to choose from. Options denoted witha and b are randomly\nshuffled between human and LLM-generated dialogue. Upon selecting a paired dialogue option, the second panel is\ndisplayed to collect a justification for their choice. The final panel allows players to see the next line of dialogue\nthat will be spoken and optionally change (and justify) their preference.\n5.1 Designing an interface to recreate Disco\nElysium’s dialogue engine\nIn Disco Elysium, players control a virtual represen-\ntation of the main character that can move around\nand interact with the environment, including initiat-\ning conversations. This freedom makes it difficult\nfor us to constrain our study within the confines of\nthe video game. Thus, rather than creating a game\nmod that includes LLM-generated dialogue,10 we\ndesign a custom web app11 that recreates the core\ngameplay systems that underpin the game’s dia-\nlogue system. This interface allows us to present\na specific conversation taken from our validation\nsplit to players (i.e., study participants).\nWhat annotations do we collect? Players are\npresented with the original human-written dia-\nlogue for all characters from the game, while the\nmain character’s dialogue options are paired along-\nside generated utterances from GPT-4 (Section 4),\nwhich we randomly shuffle and label with the sub-\nscripts a and b. Players are then asked to provide a\npreference judgment over the candidate utterances:\n10See for example the InWorld AI-based Skyrim mod.\n11We use the React framework with an integrated Lua in-\nterpreter that executes the gameplay logic as defined in our\nlinearized Lua scripts (Section 4.2).\nchoose which candidate best fits their goals while\ntaking into account the previous conversation his-\ntory and story context (Figure 3a). After making a\npreference judgment, they are asked to justify their\nchoice via both predefined tags (e.g., advances my\ngoals or matches desired mood ) as well as op-\ntional free-form comments (Figure 3b). Finally,\nthey are shown the ground-truth human-written\nnext line of dialogue, and they are asked whether\nthey would change their judgment in retrospect\ngiven this knowledge; if so, they are again asked to\njustify their decision (Figure 3c).\n5.2 Running usability studies to refine the\nannotation task\nWe conduct two usability studies to better under-\nstand common types of free-form participant feed-\nback; additionally, these studies guide the refine-\nment of our interface to reduce cognitive load for\nparticipants (e.g., switching to the two-stage anno-\ntation flow presented in Figure 3b & c). These us-\nability studies also led to the coding and integration\nof predefined tags discussed above. Our first usabil-\nity study enlists six college students (each of whom\nhad previously played through Disco Elysium) to\nspend one hour with our web app. We also con-\nducted a follow-up controlled observational study\n2300\nReddit Player Demographics\nMin Avg Max\nHours Played 25 82.6 230\nPlaythroughs 1 2.7 11\nTable 3: The number of hours and playthroughs ofDisco\nElysium as reported by the Redditors who took part in\nthe study.\nwith two more college students, using the Nielsen\nNorman Group Observer Guidelines12 to assess the\nuser experience implications of our interface.13\nManually coding human feedback: We manu-\nally code the human-written feedback from our first\nusability study to build a list of common justifica-\ntions for player preferences. This leads to a catego-\nrization of 13 high-level justifications of a player’s\ninitial preference, and 8 reasons for retroactively\nupdating their preference. To improve annotator\nefficiency, we update our annotation interface to\nprovide a list of common justification tags partic-\nipants can choose from in addition to free-form\ntext.14\n5.3 Statistically robust Reddit study\nOur task necessitates a study with many players\nsince post-utterance functions can alter the current\ngame state, potentially affecting reachability in the\ngraph, which leads to dozens of paths through the\nconversation chosen from our validation set that we\nuse for our evaluation. For that reason we recruit\n28 fans of the game from ther/DiscoElysium sub-\nreddit to take part in our study (Table 3).15 Based\non our usability studies, we estimated players re-\nquire between 1-2 hours to complete our study, and\nwe provide $25 gift cards for participation in the\nstudy.\nAll participants have played Disco Elysium\nbefore: We limit participation in our study to\nplayers who have completed at least one full\nplaythrough of Disco Elysium: The Final Cut in\nEnglish.16 This is necessary since the game weaves\na complex narrative that incorporates the player’s\n12https://www.nngroup.com/articles/observer-g\nuidelines/\n13See Appendix E for more details about our usability stud-\nies and refinements.\n14See Appendix F for specifics on each tag.\n15Our study was approved by IRB review, and all partici-\npants are at least 18 years of age.\n16We leave evaluation of other languages to future work.\nReddit Study Details\nNumber of Players 28\nTotal Utterances Rated 1,158\nAvg Utterances Rated per Player 41\nAvg Utterances Seen per Player 203\nUnique Utterances Rated 112\nTable 4: Study details, including number of annotators,\nthe number of unique generated utterances that were\nrated, and the total number of ratings.\ndialogue choices. For example, if a player often\nchooses dialogue options that indicate the main\ncharacter is a fascist, the player will more fre-\nquently be presented with dialogue options that\nreflect this world view. Thus, each player will have\na unique trajectory through the dialogue graph and\nmust mentally keep track of their choices, a skill\nplayers learn through experience with the game.\nFurthermore, due to the dataset split (Section 3.1),\nour validation data is from a late stage in the game,\nso participants must know the full story context to\nunderstand the nuances of each dialogue choice.\nStudy parameters: Approximately 20% of ut-\nterances a player reads during our study contain\nLLM-generated dialogue. This is another reason\nwhy we hired so many participants, as it requires\nsubstantial reading time between annotations. In\naggregate, 112 unique utterances are rated by our\nparticipants, though since each player performs a\nunique walk of the dialogue graph, on average each\nplayer rates 41 utterances, and only 100 utterances\nreceive at least three ratings (Table 4).17\n6 Results & analysis\nOverall, our study reveals a strong preference for\nhuman-written dialogue over LLM-generated dia-\nlogue. Participants most commonly cite reasons\nfor their preferences such as increased appropriate-\nness, better match with their gameplay goals, and\nstylistic properties (Figure 4). Because assessing\nthe generative capabilities of LLMs is confounded\nby the subjective nature of rating narrative qual-\nity (Ethayarajh and Jurafsky, 2022; Wang et al.,\n2023b), we also conduct a fine-grained analysis\nof free-form player justifications to uncover where\nGPT-4 succeeds and where it needs improvement.\n17Following Card et al. (2020), our study design has a statis-\ntical power of 0.96 for a margin of 10%, though our reported\nmargins in Section 6.1 are often much larger.\n2301\nfeels more appropriateadvances my goalsmatches desired moodexploring my optionsseems interestingseems more logicalcontains more specificsreferences earlier infoother option is irrelevantrandomly selectedother option is a repeatother accidentally selected0\n100\n200\n300\n400\nGPT-4 (756)\nHuman (1300)\nOriginal Preference\n(a)\nillogical in hindsightbetter matches desired moodseems more interesting nowbetter advances my goalsother better explores my optionscontains more specificsis a repeat in hindsight0\n10\n20\n30\n40\n From human to GPT-4 (14)\nFrom GPT-4 to human (71)\nUpdated Preference\n(b)\nFigure 4: Histogram of tags, aggregated across all 1,158 judgements, (a) upon initially choosing the dialogue, and\n(b) after a player retroactively updates their preference upon seeing the next utterance in the conversation.\n6.1 Participants prefer human-written\ndialogue\nOverall, out of the 1,158 total judgements we col-\nlect from players, 702 (61%) state a preference for\nhuman-written dialogue while 456 prefer GPT-4.\nWhen aggregating at the instance level (i.e., com-\nputing the majority vote on all instances for which\nwe collected annotations from at least three dif-\nferent players), we note a stronger preference for\nhuman-written dialogues. Specifically, upon their\nfirst assessment (Figure 3b), players prefer human-\nwritten dialogue to that of GPT-4 (H: 64% vs G:\n23%; rest ties), and after retrospectively updating\ntheir preference (Figure 3c), annotators prefer the\noriginal dialogue even more (H: 66% vs G: 23%).\nReasons for preference: When players prefer\nhuman-written dialogue over model-generated dia-\nlogue, they cite reasons such as increased logical\nconsistency (H: 61% vs G: 28%) and flow (H: 67%\nvs G: 21%). After seeing the next utterance, the\nmost common reason for players to change their\npreference is that the selected utterance was illog-\nical in hindsight (Figure 4b), which affects 32%\nof GPT-4 generations rated by at least one player.\nOverall, these results suggest that future research\nshould focus on better grounding of LLM gener-\nations to the game state. However, GPT-4 does\nclose the gap on certain aspects of the generated\ndialogue, including providing interesting dialogue\noptions (H: 47% vs G: 36%) that contain more\nspecifics (H: 43% vs G: 46%) and advance player\ngoals (H: 57% vs G: 33%), which shows the poten-\ntial of collaborative human-LLM dialogue.\n6.2 Fine-grained analysis\nWhile the overall results show a strong preference\nfor human-written dialogue, we note that the task\nis inherently subjective, and player preference is\nnot always related to the quality of the options.\nSome level of disagreement between participants\nis expected, which motivates us to perform a more\nfine-grained analysis to uncover common facets\nthat provide insight on these disagreements and\nhighlight where GPT-4 excels and struggles.\nInconsistencies with the game world: Many of\nthe justifications for players’ preferences mention\nappropriateness or logical consistency / flow with\nthe conversation history. In general, the world cre-\nated by the game designers has a depth and con-\nsistency that is difficult for models to understand,\nespecially when it is encoded programmatically\n(e.g., in Lua scripts) rather than in unstructured\ntext. In the following example, four players justify\ntheir preference (one shown below) for the human-\nwritten text by noting that the generated utterance\ndoes not conform to the game’s notion of an “ultra-\nliberal” character, which requires an understanding\nof the game’s various political factions.\n(1) a. That’s a *choice*. You could have become self-\nemployed. Create the system.\nHUMAN -WRITTEN\nb. I steal from the rich, redistribute wealth, and\nfight for a borderless world.\nGPT-4 GENERATED\ni. As an Ultraliberal character, this option feels\nmore appropriate in this playthrough.\nfeels more appropriate\nPREFERS HUMAN -WRITTEN\nAwkward articulation: Sometimes, the compet-\ning objectives of generating a fluent utterance and\n2302\nstaying faithful to the game state result in awkward\ngenerations that can impact logical and stylistic\ncoherence, as in:\n(2) a. We’re not ’Coalition-appointed. ’ We just try to\nhelp people.\nHUMAN -WRITTEN\nb. I’m not ’Coalition-appointed. ’ We just try to\nhelp people.\nGPT-4 GENERATED\ni. Since Kim is with me, it’s more appropriate\nto say \"we\".\nfeels more appropriate, matches desired mood\nPREFERS HUMAN -WRITTEN\nii. I never know if we can trust Kim\nfeels more appropriate, matches desired mood,\nadvances my goals, contains more specifics\nPREFERS GPT-4 GENERATED\nHere, six players prefer the original utterance,\nin which both sentences use the plural pronoun\n“we”, and call out the awkwardness of excluding the\nmain character’s partner Kim in the second GPT-4\ngenerated sentence; one example justification is\nshown in (2i). Despite this conflict, however, two\nplayers prefer the GPT-4 generation as they believe\nit better matches the mood (2ii).\nFit with play style: An attractive aspect of role-\nplaying games is that players can mold the game’s\nnarrative to their individual play style. Disco Ely-\nsium allows for a huge variety of play styles; for\nexample, players can choose to tackle the game\nas an analytic Sherlock Holmes-type detective or\nas a physically imposing but dim-witted enforcer.\nGPT-4 is able to provide diverse dialogue that is\namenable with certain play styles:\n(3) a. [Pick up the gun lying in the sand.]\nHUMAN -WRITTEN\nb. Mind if I examine your gun, Mr. Dros?\nGPT-4 GENERATED\ni. He threw it away \"like an amputated limb\"\nso I don’t think asking him for permission\nrhetorical or not seems appropriate\nfeels more appropriate\nPREFERS HUMAN -WRITTEN\nii. I am being passive aggressive here, I do not,\nin fact, care if he minds.\nfeels more appropriate\nPREFERS GPT-4 GENERATED\nIn the above example, one player thinks it does\nnot make sense to ask permission to look at the\ngun (3i), while the other prefers the GPT-4 genera-\ntion because they intentionally want to be passive\naggressive towards Mr. Dros (3ii). Both players\nmarked feels more appropriate as a justification,\nwhich is not a contradiction since they each have\ndifferent play styles and objectives.\nParaphrasing: Dialogue in games tends to be\nstatic: speaking with a non-player character of-\nten leads to the same utterances being repeated in\nthe absence of relevant game state changes. For-\ntunately, recent LLMs like GPT-4 are quite adept\nat paraphrasing text. When the model correctly\nreproduces an utterance semantically similar to the\nhuman written dialogue, players often randomly\nchoose between the two:\n(4) a. One more time: what have you used this gun\nfor?\nHUMAN -WRITTEN\nb. Alright, I’ll ask again. What have you been\nusing this gun for?\nGPT-4 GENERATED\ni. These are both basically the same so I just\npicked one at random\nrandomly selected\nPREFERS HUMAN -WRITTEN\nHowever, in some cases the generated para-\nphrases include small extraneous information that\nfeel off to the players. In the following example,\ntwo players specifically call out GPT-4’s phrasing:\n(5) a. Stop changing the subject – we have the murder\nweapon. (Point to it.)\nHUMAN -WRITTEN\nb. Enough squirming. I have the murder weapon,\nand Kim here can confirm it.\nGPT-4 GENERATED\ni. I don’t think Kim is a figure of authority at\nthis point - he knows about as much about\nthe murder weapon as Harry does.\nfeels more appropriate,\nadvances my goals, seems more logical\nPREFERS HUMAN -WRITTEN\n7 Conclusion\nIn this paper, we perform a user study of LLM-\ngenerated dialogue integrated into video games,\nhiring fans of Disco Elysium: The Final Cut to\nprovide fine-grained insights about issues in this\ndomain. We examine a constrained dialogue gener-\nation task, in which the game state is integrated into\nthe LLM prompt via Lua scripts that encode game\nvariables, functions, and dialogue. We develop\na web interface that reproduces Disco Elysium’s\ndialogue engine to conduct the evaluation. Human-\nwritten dialogue is strongly preferred over GPT-4\ngenerations for reasons such as improved logical\nflow, appropriateness, and tonal consistency. Fu-\nture work can build on our framework to consider\nuser play style, faithfulness to the game state, and\ndynamically updating game state as important com-\nponents of the modeling and evaluation process.\n2303\n8 Acknowledgements\nThanks to all of the Disco Elysium fans who took\npart in the studies described in the paper. Also,\nthanks to the reviewers and to Brendan O’Connor\nfor valuable feedback which helped improve the\nmanuscript. Finally, thanks to Ronan Salz and\nGeorge Wei who conducted an early exploration of\nthe Disco Elysium data. This project was partially\nsupported by awards IIS-2202506 and IIS-2046248\nfrom the National Science Foundation (NSF).\n9 Limitations\nWhile the dialogue for Disco Elysium is available\nin Simplified Chinese, Traditional Chinese, En-\nglish, French, German, Japanese, Korean, Polish,\nPortuguese-Brazilian, Russian, Spanish, and Turk-\nish, our study focuses exclusively on the English\nversion of the game, which was necessary due to\nthe large number of players required for adequate\ncoverage of the dialogue graph. Additionally, the\ngenerated dialogue we show participants is gener-\nated once from GPT-4, such that each player rates\nthe same generated utterance. This reduces varia-\ntion in the annotation task allowing us to have high\nstatistical power for our results. Though due to the\nstatic nature of the generated dialogue we do not ac-\ncount for the player’s unique walk of the dialogue\ngraph, which would require dynamically generated\nutterances, even though this could better reflect the\ninteractive nature of video games. We live this\nto future work. We also note that Disco Elysium\nrepresents a niche genre of narrative-driven games\nthat does not reflect the full diversity of narratives\nseen in video games, thus our approach is unlikely\nto generalize to the diverse catalog of video game\nnarratives. Though our work does apply to a large\nclass of popular video games such as the recently\nreleased Baldur’s Gate 3 and Starfield18, both of\nwhich have enthralled millions of gamers within a\nmonth of their release19.\n10 Ethical Considerations\nDisco Elysium contains adult themes, including\ndiscussions of suicide, murder, and rape. For this\nreason, we ensure participants in our study are at\nleast 18 years of age as required by our institutional\n18https://www.ign.com/articles/starfield-hit\ns-10-million-players-in-less-than-three-weeks\n19https://gameworldobserver.com/2023/10/19/bg3\n-topped-starfield-player-engagement-steam-us-cir\ncana\nreview board. We do not collect any demographic\ninformation of the participants beyond age veri-\nfication. Additionally, we ensure participants in\nour study are fairly compensated for their time, of-\nfering $25 gift cards for Reddit participants, $30\ngift cards for our observational study participants,\nand either $25 or $50 gift cards for our initial pilot\nparticipants depending on the length of time they\nspent on the study.\nWe also note that Disco Elysium: The Final Cut\nis a copyrighted game, so we take special care to\nensure we respect the intellectual property of the\ngame’s designers.20 We do not release any models\ntrained on the game’s data, nor do we widely re-\nlease our web interface, which requires registering\nan account with an authorization token to take part\nin the study. Finally, the web app only has access\nto a small portion of the overall game data taken\nfrom the validation set which is needed to conduct\nthe study, and that data is only ever kept in memory,\nnever persisted to disk.\nReferences\nMohammad Bavarian, Heewoo Jun, and Nikolas Tezak.\n2022. Efficient Training of Language Models to Fill\nin the Middle. arXiv:2207.14255 [cs], page 30.\nMarc G. Bellemare, Yavar Naddaf, Joel Veness, and\nMichael Bowling. 2012. The arcade learning envi-\nronment: An evaluation platform for general agents.\nCoRR, abs/1207.4708.\nHayet Brabra, Marcos Báez, Boualem Benatallah, Walid\nGaaloul, Sara Bouguelia, and Shayan Zamanirad.\n2022. Dialogue management in conversational sys-\ntems: A review of approaches, challenges, and op-\nportunities. IEEE Transactions on Cognitive and\nDevelopmental Systems, 14:783–798.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language Models are Few-Shot Learners.\narXiv:2005.14165 [cs].\n20The intellectual property rights of the game are currently\nthe subject of a legal dispute between the game’s designers\nand their former development studio ZA/UM. For more infor-\nmation, see https://www.pcgamer.com/the-legal-war\n-over-disco-elysium-reaches-disco-elysium-level\ns-of-complexity/\n2304\nChris Callison-Burch, Gaurav Singh Tomar, Lara Mar-\ntin, Daphne Ippolito, Suma Bailis, and David Reit-\nter. 2022. Dungeons and dragons as a dialog chal-\nlenge for artificial intelligence. In Proceedings of\nthe 2022 Conference on Empirical Methods in Nat-\nural Language Processing, pages 9379–9393, Abu\nDhabi, United Arab Emirates. Association for Com-\nputational Linguistics.\nDallas Card, Peter Henderson, Urvashi Khandelwal,\nRobin Jia, Kyle Mahowald, and Dan Jurafsky. 2020.\nWith little power comes great responsibility. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 9263–9274, Online. Association for Computa-\ntional Linguistics.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming\nYuan, Henrique Ponde de Oliveira Pinto, Jared Ka-\nplan, Harri Edwards, Yuri Burda, Nicholas Joseph,\nGreg Brockman, Alex Ray, Raul Puri, Gretchen\nKrueger, Michael Petrov, Heidy Khlaaf, Girish Sas-\ntry, Pamela Mishkin, Brooke Chan, Scott Gray,\nNick Ryder, Mikhail Pavlov, Alethea Power, Lukasz\nKaiser, Mohammad Bavarian, Clemens Winter,\nPhilippe Tillet, Felipe Petroski Such, Dave Cum-\nmings, Matthias Plappert, Fotios Chantzis, Eliza-\nbeth Barnes, Ariel Herbert-V oss, William Hebgen\nGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie\nTang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\nWilliam Saunders, Christopher Hesse, Andrew N.\nCarr, Jan Leike, Josh Achiam, Vedant Misra, Evan\nMorikawa, Alec Radford, Matthew Knight, Miles\nBrundage, Mira Murati, Katie Mayer, Peter Welinder,\nBob McGrew, Dario Amodei, Sam McCandlish, Ilya\nSutskever, and Wojciech Zaremba. 2021. Evaluating\nLarge Language Models Trained on Code.\nElizabeth Clark, Tal August, Sofia Serrano, Nikita\nHaduong, Suchin Gururangan, and Noah A. Smith.\n2021. All that’s ‘human’ is not gold: Evaluating\nhuman evaluation of generated text. In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 7282–7296, Online.\nAssociation for Computational Linguistics.\nElizabeth Clark and Noah A. Smith. 2021. Choose your\nown adventure: Paired suggestions in collaborative\nwriting for evaluating story generation models. In\nProceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\npages 3566–3575, Online. Association for Computa-\ntional Linguistics.\nPhilip Cohen. 2019. Foundations of collaborative task-\noriented dialogue: What’s in a slot? In Proceedings\nof the 20th Annual SIGdial Meeting on Discourse\nand Dialogue, pages 198–209, Stockholm, Sweden.\nAssociation for Computational Linguistics.\nOrianna Demasi, Yu Li, and Zhou Yu. 2020. A multi-\npersona chatbot for hotline counselor training. In\nFindings of the Association for Computational Lin-\nguistics: EMNLP 2020 , pages 3623–3636, Online.\nAssociation for Computational Linguistics.\nChris Donahue, Mina Lee, and Percy Liang. 2020. En-\nabling language models to fill in the blanks. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 2492–\n2501, Online. Association for Computational Lin-\nguistics.\nKawin Ethayarajh and Dan Jurafsky. 2022. The authen-\nticity gap in human evaluation. In Proceedings of\nthe 2022 Conference on Empirical Methods in Nat-\nural Language Processing, pages 6056–6070, Abu\nDhabi, United Arab Emirates. Association for Com-\nputational Linguistics.\nIlya Gelfenbeyn, Kylan Gibbs, and Michael Ermolenko.\nInWorld AI [online]. 2021.\nMilan Gritta, Gerasimos Lampouras, and Ignacio Ia-\ncobacci. 2021. Conversation graph: Data augmenta-\ntion, training, and evaluation for non-deterministic\ndialogue management. Transactions of the Associa-\ntion for Computational Linguistics, 9:36–52.\nBarbara Grosz. 1974. The structure of task oriented\ndialogs. In IEEE Symposium on Speech Recogni-\ntion: Contributed Papers. Carnegie Mellon Univer-\nsity Computer Science Dept., Pittsburgh, Pennsylva-\nnia, volume 10.\nMatthew Hausknecht, Prithviraj Ammanabrolu, Marc-\nAlexandre Côté, and Xingdi Yuan. 2020. Interactive\nFiction Games: A Colossal Adventure. Proceedings\nof the AAAI Conference on Artificial Intelligence ,\n34(05):7903–7910.\nMarzena Karpinska, Nader Akoury, and Mohit Iyyer.\n2021. The perils of using Mechanical Turk to evalu-\nate open-ended text generation. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 1265–1285, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nMarzena Karpinska and Mohit Iyyer. 2023. Large lan-\nguage models effectively leverage document-level\ncontext for literary translation, but critical errors per-\nsist.\nMarzena Karpinska, Nishant Raj, Katherine Thai, Yix-\niao Song, Ankita Gupta, and Mohit Iyyer. 2022.\nDEMETR: Diagnosing evaluation metrics for trans-\nlation. In Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Processing,\npages 9540–9561, Abu Dhabi, United Arab Emirates.\nAssociation for Computational Linguistics.\nMichal Kempka, Marek Wydmuch, Grzegorz Runc,\nJakub Toczek, and Wojciech Ja´skowski. 2016. ViZ-\nDoom: A Doom-based AI research platform for vi-\nsual reinforcement learning. 2016 IEEE Conference\non Computational Intelligence and Games (CIG) ,\npages 1–8.\n2305\nAlexander Koller, Timo Baumann, and Arne Köhn.\n2018. Dialogos: Simple and extensible dialogue\nmodeling. In Interspeech.\nRobert Kurvitz, Helen Hindepere, Argo Tuulik, Cash\nDe Cuir, and Olga Moskvina. 2021. Disco Elysium:\nThe Final Cut. ZA/UM Studios.\nGaetan Lopez Latouche, Laurence Marcotte, and Ben\nSwanson. 2023. Generating video game scripts with\nstyle. In Proceedings of the 5th Workshop on NLP for\nConversational AI (NLP4ConvAI 2023), pages 129–\n139, Toronto, Canada. Association for Computational\nLinguistics.\nMichael Mateas and Andrew Stern. 2005. Demonstra-\ntion: The Interactive Drama Façade. In Proceed-\nings of the First AAAI Conference on Artificial In-\ntelligence and Interactive Digital Entertainment, AI-\nIDE’05, pages 153–155, Marina del Rey, California.\nAAAI Press.\nPurnendu Mukherjee. ConvAI [online]. 2022.\nOpenAI. 2023. GPT-4 Technical Report.\nDavid A. Papa and Igor L. Markov. 2007. Hypergraph\npartitioning and clustering. In Handbook of Approxi-\nmation Algorithms and Metaheuristics.\nMark O. Riedl and Robert Michael Young. 2004. An\nintent-driven planner for multi-agent story genera-\ntion. Proceedings of the Third International Joint\nConference on Autonomous Agents and Multiagent\nSystems, 2004. AAMAS 2004., pages 186–193.\nAlane Suhr, Claudia Yan, Jack Schluger, Stanley Yu,\nHadi Khader, Marwa Mouallem, Iris Zhang, and\nYoav Artzi. 2019. Executing instructions in situ-\nated collaborative interactions. In Proceedings of\nthe 2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 2119–2130, Hong Kong,\nChina. Association for Computational Linguistics.\nRyan V olum, Sudha Rao, Michael Xu, Gabriel Des-\nGarennes, Chris Brockett, Benjamin Van Durme,\nOlivia Deng, Akanksha Malhotra, and Bill Dolan.\n2022. Craft an iron sword: Dynamically generating\ninteractive game characters by prompting large lan-\nguage models tuned on code. In Proceedings of the\n3rd Wordplay: When Language Meets Games Work-\nshop (Wordplay 2022), pages 25–43, Seattle, United\nStates. Association for Computational Linguistics.\nNick Walton. AI dungeon [online]. 2019.\nLingzhi Wang, Mrinmaya Sachan, Xingshan Zeng, and\nKam-Fai Wong. 2023a. Strategize before teach-\ning: A conversational tutoring system with pedagogy\nself-distillation. In Findings of the Association for\nComputational Linguistics: EACL 2023, pages 2268–\n2274, Dubrovnik, Croatia. Association for Computa-\ntional Linguistics.\nYuxin Wang, Jieru Lin, Zhiwei Yu, Wei Hu, and Börje F.\nKarlsson. 2023b. Open-world story generation with\nstructured knowledge enhancement: A comprehen-\nsive survey.\nNathaniel Weir, Ryan Thomas, Randolph D’Amore, Kel-\nlie Hill, Benjamin Van Durme, and Harsh Jhamtani.\n2023. Ontologically faithful generation of non-player\ncharacter dialogues.\nFangyuan Xu, Yixiao Song, Mohit Iyyer, and Eunsol\nChoi. 2023. A Critical Evaluation of Evaluations\nfor Long-form Question Answering. In Proceedings\nof the 61st Annual Meeting of the Association for\nComputational Linguistics, Toronto, CA. Association\nfor Computational Linguistics.\n2306\nA Dataset Splits\nWe provide additional details regarding our dataset\nsplits. As we note in the main body of the paper, a\nkey challenge in splitting theDisco Elysium dataset\ninto train, valid, and test splits is the high degree\nof interconnectedness across conversations in the\ngame. While it is not possible to create a dialogue\nsplit with a disjoint set of game state variables, we\nminimize overlaps amongst the splits.\nVariable Overlap Dataset Totals\nTrain⋂Valid 2897 Items 259\nTrain⋂Test 2871 Characters 424\nValid⋂Test 303 Conversations 610\n(a) (b)\nTable A1: For the Disco Elysium dataset: (a) we take\nspecial care to minimize the number of referenced vari-\nable overlaps amongst the splits; (b) though we do not at-\ntempt to disentangle Characters and Items across splits.\nB Additional Clustering Details\nWe experiment with a number of algorithms for\nclustering the game’s dialogue, including the Lev-\nenshtein distance, Jaccard index, and the Dice co-\nefficient. We also vary the features used for cluster-\ning by splitting the words into characters, grouping\nby ngrams, and through the use of lowercasing.\nWe conduct a manual inspection of the various ap-\nproaches to clustering, including a hyperparameter\nsweep of the similarity threshold. This inspection\nindicated that solely clustering based on the dia-\nlogue utterances would either systematically miss\nsemantically similar text, or cluster dissimilar ut-\nterances when the similarity threshold was made\nmore permissive.\nTo combat this tendency, we additionally tried\nclustering nodes by inspecting the associated Lua\nconditions. We first parse the Lua expression, ex-\ntract identifiers (which often refer to functions)\nand string literals (which often refer to variables).\nWe then split the literals into their constituent\nwords (e.g., whirling.dreamone_brave becomes\nwhirling, dreamone, brave ), before running\nthe above battery of clustering approaches. In the\nend, we find that clustering based on a combina-\ntion of dialogue and Lua expressions produced the\nbest results, without the need for the extra feature\nengineering, while only relying on the simple Dice\ncoefficient with a threshold d>= 0.5.\nC Preliminary Experiments\nWe conduct experiments using two LLMs: GPT-\n3 Curie and Codex (Table A2). GPT-3 Curie is\na strong generation model for natural language\n(Brown et al., 2020), especially when finetuned on\na downstream task, while Codex is an extremely ca-\npable few-shot LM for code (Chen et al., 2021). As\nour task contains elements of both natural language\nand code, it is important to assess the capabilities\nof each model paradigm.\nModel\nClass\nPrompt\nTokens\nModel\nType\nOpenAI API\nName\nCurie 1 2048 Finetuned curie\nCodex 8000 Few-Shot code-davinci-002\nTable A2: Details of the models used in our experiments.\nAs OpenAI does not provide parameter counts or details\non finetuning, we also provide the API name for the\nmodels to help reproducibility.\n1Likely 6.7B parameters, see:\nhttps://blog.eleuther.ai/gpt3-model-sizes/\nSince the two models perform different tokeniza-\ntion2 and support different context lengths, we filter\nthe clusters, keeping only those that fit the smallest\ncontext length (2048 tokens) using the GPT-3 tok-\nenizer. We then generate all the linearized scripts\nrepresenting semantically related text for the next\nturn of dialogue. After filtering and generating\nmasked variants of the clusters, we are left with\n30,501 training examples and 2,668 validation ex-\namples.\nWe finetune Curie for 1 epoch, with a batch size\nof 32 examples and a learning rate of 0.2× the\nlearning rate of the pretrained model and we weight\nthe loss for the prompt tokens by 0.01. For the\nfew-shot Codex model, we prefix each linearized\nLua script with several samples from the validation\nset such that they take up nearly the full context\nwindow (we reserve 100 tokens of the context for\ngeneration). We also ensure there are no overlaps\nin dialogue between the few-shot examples and\nthe script. Consequently, each Codex script has 7\nfew-shot examples on average.\nWe choose to measure the performance of the\nmodels on the validation set using a bag-of-words\nF1, as the clustered utterances have a large over-\nlap with the masked text the model is tasked with\n2Codex uses a modified tokenizer that collapses whitespace\nsince it is commonly used in code formatting.\n2307\nModel Examples Tokens BLEURT F1\nCurie 2,668 3,041,299 41.9 25.6\nCodex 2,668 21,077,200 44.2 29.5\nTable A3: Preliminary experiments over the validation\nset show that few-shot Codex outperforms a finetuned\nCurie model for generating context-aware dialogue.\ninfilling. In addition, we use BLEURT which has\nproven to be robust for semantic similarity of gen-\nerated text (Karpinska et al., 2022). Both metrics\nfavor Codex slightly, though given the low F1 score,\nit’s clear the models have much room for improve-\nment on this simplified form of our task. That is to\nsay, naïvely applying our preliminary approach to\nall the dialogue in the game, not just to the subset\nof dialogue clustered via similarity, is even more\nlikely to fail. We also posit that Codex likely out-\nperforms Curie since it is a larger model that is\nexplicitly trained on a large corpus of code, even\nthough it uses a few-shot approach to inference.\nTo better understand the performance difference\nbetween the two models we also conduct a small\nanalysis of each model’s output. We find that both\nmodels tend to copy from the prompt (Table A4),\nbut Codex does it nearly twice as often.\nModel Examples Copied\nCurie 2,668 235\nCodex 2,668 455 (8) †\nTable A4: We find that both Curie and Codex occassion-\nally copy dialogue from the prompt, and in 8† instances\nCodex directly copies a completion from the few-shot\nexamples.\nA qualitative inspection of the generations from\nthe Codex model (our best performer) seem to indi-\ncate the model may struggle to generate plausible\ncompletions due to a lack of historical context to\nthe current conversation. Our script-based prompts\ndo not include any previous dialogue utterances,\nbut rather rely only on the combination of dialogue\nthat can be emitted next and conditional game logic\ngating those options. It is clear the models also do\nnot make effective use of the game designer’s anno-\ntations to fill in the gaps. While these comments are\nlikely useful reference for the writers of the game,\nthey may not contain enough context alone to guide\ngeneration. Considering Codex has a very long con-\ntext window and performs better than a finetuned\nCurie (Table A3), future experiments could attempt\nFew-Shot Prompt Statistics\nMin Avg Max\nExample Length 158 330 2228\nExamples per Prompt 15 33 45\nPrompt Length 7547 7566 8089\nTable A5: Here we report statistics for token lengths of\neach example and the overall prompts, along with the\nnumber of examples per prompt.\nto include previous turns of dialogue in the prompt\nto see if that improves generation quality.\nD Few-shot Prompting\nSince we target GPT-4 for our main study, we pro-\nvide few shot prompts using their chat format. All\nprompts are prefixed with the following system\nmessage:\nYou are a creative game designer writing engag-\ning dialogue for a roleplaying game. For each\nself-contained dialogue script fill in the <MASK>\nwith interesting dialogue using only facts from\nthe script.\nAdditionally, our few shot examples are encoded\nas chat conversations where a user message pro-\nvides the model with a script, and the the assis-\ntant responds with the completion. In terms of the\nlinearization we describe in Section 4.2, the user\nmessage consists of the prefix and suffix, while the\nassistant message consists of the mask. Note we,\nexperimented with other prompting approaches,\nbut found the above worked best. We investigated\nzero-shot and few-shot prompts containing various\nnumbers of examples. The resultant GPT-4 gen-\nerations often did not match the style of the game\nwriting, frequently leading to verbose utterances.\nWe also tried interleaving instructions before each\nfew-shot example, and that seemed to have no no-\nticeable difference is quality.\nE Interface adjustments from usability\nstudies\nTwo-step annotation flow In our initial interface\nplayers are presented with a single screen in which\nto provide free-form feedback on both the selected\nutterance and whether they want to change their\nmind after seeing the next utterance. This unified\nfeedback screen led players to conflate the reason\nthey chose a dialogue option with their post-hoc\nreasoning after seeing the next utterance. Before\n2308\nPredefined Tag Description\nrandomly selected You randomly selected between the paired options.\naccidentally selected You accidentally selected the dialogue option.\nadvances my goals The selected dialogue option advances your goals.\nexploring my options You are just trying to explore all the dialogue options.\nfeels more appropriate The selected dialogue option fits the conversation better than it’s\ncounterpart.\nmatches desired mood The selected dialogue option matches the mood you are going for.\ncontains more specifics The selected dialogue option contains more context specific infor-\nmation than it’s counterpart.\nother option is a repeat The paired dialogue option that was not selected repeats something\nthat was already stated.\nother option is irrelevant The paired dialogue option that was not select is irrelevant to the\ncurrent context.\nreferences earlier info The selected dialogue option references information from earlier in\nthe conversation.\nseems interesting The selected dialogue option seems more interesting than it’s coun-\nterpart.\nseems more logical The selected dialogue option fits the current context more logically\nthan it’s counterpart.\nother Please explain in your own words why you selected the dialogue\noption.\nTable A6: List of predefined tags and their associated description from our web app for justifying why a player\ninitially chose a candidate utterance.\nour observational study, we split the feedback pro-\ncess into two screens (Figure 3b & c) and note that\nthis obviates the player confusion seen in our initial\nstudy.\nUpdating the interface The second observa-\ntional study highlighted three major concerns. First,\nthe actual Disco Elysium game provides visual cues\nthat were missing from the web interface that play-\ners relied upon to follow the conversation. We\naddress this concern by tweaking our interface to\nbetter match the one from the game, including high-\nlighting actor names using the same colors from the\ngame and updating the icons for the player statis-\ntics shown at the bottom of the screen in Figure 3a.\nSecond, we decided to instruct players to exhaust\nall dialogue options within the conversation, which\nallows us to improve our coverage of the generated\nutterances in the dialogue graph. This process dif-\nfers from the actual gameplay, in which players are\nfree to skip through many dialogues that serve to\nprovide a backstory to the game world. Finally, it\nbecame clear that players might not complete the\nannotation task within one session, so we added\nsupport for automatically saving and resuming the\ntask starting where the player left off.\nF Predefined Tags\nWe manually code the free-form comments from\nour first pilot study to understand common justifi-\ncations for expressed preferences. We do this both\nfor comments on a player’s initial preference and\nupon retroactively updating their preference based\nupon seeing the next utterance. We then update our\ninterface to include our manually coded categoriza-\ntions as predefined tags that players can select to\njustify their choices. For the full list of predefined\ntags and the description we provide for the tag in\nour interface, please see Table A6 (initial prefer-\nence) and Table A7 (upon retrospectively changing\npreference).\n2309\nPredefined Tag Description\nbetter advances my goals After seeing the next line of dialogue, it turns out that the other\ndialogue option better advances your goals.\nbetter explores my options After seeing the next line of dialogue, it turns out that the other\ndialogue option better explores the conversation.\nbetter matches desired mood After seeing the next line of dialogue, it turns out that the other\ndialogue option better matches the mood your are going for.\ncontains more specifics After seeing the next line of dialogue, it turns out that the other\ndialogue option actually contains more context specific information.\nillogical in hindsight After seeing the next line of dialogue, it turns out that the other\ndialogue option does not make sense in context.\nis a repeat in hindsight After seeing the next line of dialogue, it turns out that the other\ndialogue option repeats something that was previously stated.\nseems more interesting now After seeing the next line of dialogue, it turns out that the other\ndialogue option is actually more interesting.\nother Please explain in your own words why you changed the selected\ndialogue option.\nTable A7: List of predefined tags and their associated description from our web app for justifying why a player\nretrospectively changed their preference.\n2310\nG Rating Trends\nDue to the nature of the game using a dialogue\ngraph where node reachability is altered depend-\ning on the dialogue option chosen, on average\neach player only rates 41 utterances out of the 112\nunique utterances rated by all players (Table 4).\nTo understand how the player preference changes\nas the number of ratings a particular utterance re-\nceives, we produce stacked histograms (Figure A1\n& Figure A2) where each bar represents player\npreference given the number of players rating an\nutterance.\n5 10 15 200\n50\n100\n Tied\nGPT-4 Preferred\nHuman Preferred\nMinimum Number of Users Rating an Utterance\nUtterances\nOriginal Preference\nFigure A1: Histogram of initial candidate preferences\nbased on minimum number of players rating the utter-\nance.\n5 10 15 200\n50\n100\n Tied\nGPT-4 Preferred\nHuman Preferred\nMinimum Number of Users Rating an Utterance\nUtterances\nUpdated Preference\nFigure A2: Histogram of retroactively updated prefer-\nences based on minimum number of players rating the\nutterance.\n2311",
  "institutions": [
    {
      "id": "https://openalex.org/I24603500",
      "name": "University of Massachusetts Amherst",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I205783295",
      "name": "Cornell University",
      "country": "US"
    }
  ],
  "cited_by": 16
}