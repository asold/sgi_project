{
    "title": "Incorporating Medical Knowledge to Transformer-based Language Models for Medical Dialogue Generation",
    "url": "https://openalex.org/W4285293250",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2963399842",
            "name": "Usman Naseem",
            "affiliations": [
                "University of Sydney"
            ]
        },
        {
            "id": "https://openalex.org/A2556776446",
            "name": "Ajay Bandi",
            "affiliations": [
                "Northwest Missouri State University"
            ]
        },
        {
            "id": "https://openalex.org/A2568404297",
            "name": "Shaina Raza",
            "affiliations": [
                "University of Toronto",
                "Public Health Ontario"
            ]
        },
        {
            "id": "https://openalex.org/A2336063370",
            "name": "Junaid Rashid",
            "affiliations": [
                "Kongju National University"
            ]
        },
        {
            "id": "https://openalex.org/A2913265672",
            "name": "Bharathi Raja Chakravarthi",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2971066408",
        "https://openalex.org/W2998382872",
        "https://openalex.org/W3101223450",
        "https://openalex.org/W2886305736",
        "https://openalex.org/W2903928064",
        "https://openalex.org/W1522301498",
        "https://openalex.org/W3034999214",
        "https://openalex.org/W2952468927",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W4324392584",
        "https://openalex.org/W2156997379",
        "https://openalex.org/W2788477667",
        "https://openalex.org/W3169483174",
        "https://openalex.org/W3165058054",
        "https://openalex.org/W2998186887",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W3025997466",
        "https://openalex.org/W2130942839",
        "https://openalex.org/W2078861931",
        "https://openalex.org/W2970678056",
        "https://openalex.org/W4385245566"
    ],
    "abstract": "Medical dialogue systems have the potential to assist doctors in expanding access to medical care, improving the quality of patient experiences, and lowering medical expenses. The computational methods are still in their early stages and are not ready for widespread application despite their great potential. Existing transformer-based language models have shown promising results but lack domain-specific knowledge. However, to diagnose like doctors, an automatic medical diagnosis necessitates more stringent requirements for the rationality of the dialogue in the context of relevant knowledge. In this study, we propose a new method that addresses the challenges of medical dialogue generation by incorporating medical knowledge into transformer-based language models. We present a method that leverages an external medical knowledge graph and injects triples as domain knowledge into the utterances. Automatic and human evaluation on a publicly available dataset demonstrates that incorporating medical knowledge outperforms several state-of-the-art baseline methods.",
    "full_text": "Proceedings of the BioNLP 2022 workshop, Dublin, Ireland, pages 110–115\nMay 26, 2022. ©2022 Association for Computational Linguistics\n110\nIncorporating Medical Knowledge to Transformer-based Language Models\nfor Medical Dialogue Generation\nUsman Naseem1, Ajay Bandi2, Shaina Raza3, Junaid Rashid4, Bharathi Raja Chakravarthi5\n1School of Computer Science, University of Sydney, Australia\n2School of Computer Science and Information Systems, Northwest Missouri State University Maryville, USA\n3The Dalla Lana School of Public Health, University of Toronto Toronto, Canada\n4Department of Computer Science and Engineering, Kongju National University, South Korea\n5 Data Science Institute, National University of Ireland Galway, Ireland\nAbstract\nMedical dialogue systems have the potential to\nassist doctors in expanding access to medical\ncare, improving the quality of patient experi-\nences, and lowering medical expenses. The\ncomputational methods are still in their early\nstages and are not ready for widespread ap-\nplication despite their great potential. Exist-\ning transformer-based language models have\nshown promising results but lack domain-\nspecific knowledge. However, to diagnose like\ndoctors, an automatic medical diagnosis ne-\ncessitates more stringent requirements for the\nrationality of the dialogue in the context of rel-\nevant knowledge. In this study, we propose a\nnew method that addresses the challenges of\nmedical dialogue generation by incorporating\nmedical knowledge into transformer-based lan-\nguage models. We present a method that lever-\nages an external medical knowledge graph and\ninjects triples as domain knowledge into the ut-\nterances. Automatic and human evaluation on\na publicly available dataset demonstrates that\nincorporating medical knowledge outperforms\nseveral state-of-the-art baseline methods.\n1 Introduction\nMedical dialogue systems, which have gained in-\ncreasing attention, aim to communicate with pa-\ntients to enquire about diseases beyond their self-\nreported and make an automatic diagnosis (Wei\net al., 2018; Xu et al., 2019; Lin et al., 2019). It\nhas the potential to substantially automate the di-\nagnostic process while also lowering the cost of\ngathering information from patients (Kao et al.,\n2018). In addition, preliminary diagnosis findings\nthat are generated by a medical dialogue system\nmay help doctors make a diagnosis more quickly.\nBecause of these advantages, researchers work on\naddressing sub-problems in a medical dialogue sys-\ntem, such as natural language understanding (Lin\net al., 2019; Shi et al., 2020).\nHowever, the dialogue system for medical di-\nagnosis, on the other hand, has specific require-\nFigure 1: An example of medical dialogue between a\npatient (left) and a doctor (right).\nments for dialogue reasoning in the context of med-\nical knowledge. The diagnosis elicited by the dia-\nlogue system should be associated with the under-\nlying medical condition and coherent with medical\nknowledge. In the absence of medical knowledge,\ntraditional generative dialogue models frequently\nuse neural sequence modelling (Sutskever et al.,\n2014; Vaswani et al., 2017) and cannot be directly\napplied to the medical dialogue scenario.\nRecently, transformer-based language mod-\nels (LMs) (Devlin et al., 2019; Radford et al.,\n2019; Song et al., 2019) are fine-tuned for med-\nical dialogue tasks. Zeng et al. (2020) col-\nlected a MedDialog dataset and fine-tuned various\ntransformer-based LMs which includes a vanilla\ntransformer (Vaswani et al., 2017), GPT (Radford\net al., 2019) and BERT-GPT (Wu et al., 2020;\nLewis et al., 2020) for medical dialogue genera-\ntion task. Yang et al. (2020), in another study,\npresented a CovidDialog dataset and then train di-\nalogue generation models based on Transformer,\nGPT-based model, and BART (Lewis et al., 2020)\nand BERT-GPT for medical dialogue generation\ntasks. These LMs are trained on huge corpus but\nmay not provide a good representation of specific\ndomains (Müller et al., 2020) and need an adequate\namount of task-specific data (Dou et al., 2019) in\norder to establish correlations between diseases and\nsymptoms (see Figure 1). Instead of using publicly\navailable models, we can pre-train a model that\nemphasizes domain-specificity. On the other hand,\npre-training is time-intensive and computationally\ncostly, making it unavailable for most users.\nFurthermore, while it is possible to inject\n111\ndomain-specific knowledge into LMs during pre-\ntraining, this method of acquiring knowledge can\nbe expensive and inefficient. For instance, pre-\ntraining data must contain many occurrences of\nthe words \"Panadol\" and \"headache\" occurring to-\ngether for the model to learn that \"Panadol\" can\ntreat headaches. What other options do we have to\nmake the model an expert in its field besides this\none? The knowledge graph (KG), also known as\nan ontology, was a good solution in the early stages\nof research. SNOMED-CT (Bodenreider, 2008), in\nthe medical field, and HowNet (Dong et al., 2010),\nin the field of Chinese conception, are two exam-\nples of KGs developed as knowledge was distilled\ninto a structured form. If KG can be incorporated\ninto the LM, it will provide domain knowledge to\nthe computational method, enhancing its effective-\nness on domain-specific tasks while significantly\nlowering the expense of pre-training. To address\nthe limitations mentioned above, this article de-\nscribes a method for incorporating domain-specific\nexternal knowledge into transformer-based LMs\nfor medical dialogue generation tasks. Our contri-\nbutions are as follows:\n• We presented a new method that incorporates\nmedical knowledge to transformer-based lan-\nguage models;\n• The proposed method first injects knowledge\nfrom a medical knowledge graph into an utter-\nance. Next, the embedding layer transforms the\nutterance tree into an embedding that is fed to the\nmasked self-attention of a transformer, followed\nby the decoder to generate the response.\n• To evaluate the performance of the proposed\nmethod, we performed both automatic and hu-\nman evaluations. Our results demonstrated that\nincorporating medical knowledge improves the\nperformance compared to several state-of-the-art\nbaselines on the MedDialog dataset.\n2 Methodology\nProblem Definition: Given a dialogue, we process\na patient-doctor dialogue as a set of pairs {(si, ti)},\nwhere source si is the dialogue from a patient and\ntarget ti is a doctor’s response. A dialogue genera-\ntion model generates t from s.\nOverview of Architecture: As illustrated in Fig-\nure 2, the proposed method contains four mod-\nules, i.e., knowledge layer, embedding layer,\nFigure 2: Overall architecture of proposed method\nmasked transformer encoder, where we extend self-\nattention to mask-self attention, and transformer de-\ncoder. Our knowledge layer injects relevant triples\ninto an input utterance (i.e., conversation) from a\nKG, converting it to a knowledge-rich utterance\ntree. Simultaneously, the utterance tree is fed into\nthe embedding layer for token-level representation.\nThe representation from an embedding layer is fed\nto the masked transformer encoder and decoder to\ngenerate a response. We will describe each of these\nmodules in detail in the following discussion.\n2.1 Knowledge layer\nThe knowledge layer incorporates domain-specific\n(medical) knowledge into utterances and trans-\nforms them into utterance trees. The knowledge\nlayer generates an utterance tree given an input ut-\nterance (s) and a KG. This method involves two\nstages: query of medical knowledge, referred to as\nK-Query, and injection of knowledge, referred to as\nK-Inject. K-Query extracts all entity names from\nthe utterance s and queries their correlating triples\nfrom knowledge k. K-Query can be expressed as\nfollows:\nE = K_Query(s, KG), (1)\nWhere E is a set of associating triples. K-Inject\nthen injects the queried E into the utterance s by\ncombining the triples in E to their corresponding\npositions, resulting in an utterance tree t. An ut-\nterance tree can have different branches; however,\nits depth is limited, indicating that entity names\nin triples will not iteratively derive branches. The\nformulation for K-Inject is as follows:\nt = K_Inject(s, E) (2)\nKnowledge graph: To generate knowledge, we\nuse the medical knowledge graph released by Liu\net al. (2021), which is centered on organs and re-\nlated disorders. A set of 52.6K triplets (head, re-\n112\nlation, tail) containing medical information was\nretrieved. The head and tail represent entities such\nas organs or diseases. In contrast, the relation in-\ndicates the relationship between entities, such as\nfunction and treatment. In this study, we employed\nthe English language vocabulary, which has 2,603\ntriples in total.\n2.2 Embedding layer\nThe embedding layer aims to transform the utter-\nance tree into embedded representations that can\nbe forwarded to the transformer’s encoder and then\ndecoder to generate the dialogue. Our embedding\nlayer consists of token, position, and segment em-\nbedding layers. However, it differs in that the pro-\nposed method’s embedding layer receives an ut-\nterance tree rather than a token sequence as input.\nBelow, we discuss a method adopted to transform\nan utterance tree into a sequence that retains its\nstructural information.\nToken embedding: In our study, the token em-\nbedding, including the vocabulary used, is consis-\ntent with the original transformer-based LM (see\nsection 3.3). Each token in the expression tree is\ntransformed into a H dimensional embedding vec-\ntor by a trainable lookup table. Token embeddings\nmade using the proposed method differ from those\nmade using the original LMs. The utterance tree\ntokens must first be rearranged before embedding\ncan occur. After incorporating tokens in the branch,\nwe reverse the order of the tokens in the follow-\ning nodes. Even though this process is simple, it\nmakes the utterance hard to read and loses impor-\ntant structural information that can be solved using\nsoft-position.\nSoft-position embedding: Without position em-\nbedding, encoders within a transformer will behave\nsimilarly to a bag-of-words (BoWs) method, lead-\ning to a loss of structural information (i.e., the order\nof tokens). The position embedding contains all\nof the structural information in the encoder’s input\nsentence, allowing us to reconstruct the unreadable\nrearranged utterance. As an alternative to using\nthe transformer encoder’s self-attention score for\nwords that appear to be connected but are not, we\nused masked self-attention (see section 2.3).\nSegment embedding : Like the transformer en-\ncoder, the proposed method uses segmentation em-\nbedding to detect utterances when multiple utter-\nances are included. For instance, when two utter-\nances are fed, [SEP] is used to incorporate them.\nA sequence of segment tags is used to denote the\ncombined utterance.\n2.3 Transformer Encoder with Masked-Self\nAttention\nWe present a mask-self-attention to avoid false se-\nmantic changes, which is a self-attention extension.\nMask-self-attention is defined as follow:\nQi+1, Ki+1, Vi+1 = hiWq, hiWk, hiWv (3)\nSi+1 = softmax(Qi+1Ki+1\n√dk\n) (4)\nhi+1 = Si+1V i+1 (5)\nwhere Wq , Wk , and Wv are model parameters\nthat can be trained. The hidden state of the i − th\nmask-self-attention blocks is hi. The scaling factor\nis dk. This process improves the representation but\ndoes not affect the original utterance’s meaning.\n2.4 Transformer Decoder\nThe knowledge enriched representation from the\ntransformer encoder is fed to the decoder of an\noriginal LM to generate a response. The working\nprocess of the decoder layers is similar to that of\nthe vanilla transformer decoder layers.\n3 Experiments\n3.1 Datasets\nIn this study, we used the English version of Med-\nDialog (Zeng et al., 2020) dataset. Table 1 presents\nstatistics of the MedDialog dataset.\nTable 1: Dataset Statistics\nDataset MedDialog-EN\n# dialogues 257,332\n# utterances 514,664\n# tokens 44,527,872\n#diseases 172\nAvg. # of utterances 2\nMax # of utterances 2\nMin # of utterances 2\nAvg. # of tokens 87\nMax # of tokens 3,672\nMin # tokens 1\n3.2 Experimental Settings\nWe used five different LMs, and all configuration\nand pre-training settings are consistent with the\noriginal LMs used (see section3.3). Adam (Kingma\nand Ba, 2014) optimizer is used to train our model\nat 1e-6 initial learning rate. We used a batch size\n113\nTable 2: Results: Automatic (BLEU2, BLEU4, METEOR , NIST − 4) and Human (5-point scale) evaluation\nAutomated Evaluation for MedDialog-EN Human Evaluation\nModel BLEU 2 BLEU4 METEOR NIST-4 Avg. Score\nBERT-GPT (Wu et al., 2020) 5.72 4.82 0.28 0.42 3.70\nBERT-GPT+Knowledge (Ours) 9.38 6.07 17.62 0.61 4.00\nPerformance Increase 3.66↑ 1.25↑ 17.34↑ 0.19↑ 0.30↑\nTransformer (Vaswani et al., 2017) 2.13 2.28 11.57 0.03 2.70\nTransformer+Knowledge (Ours) 2.48 2.46 12.32 0.31 3.00\nPerformance Increase 0.35↑ 0.18↑ 0.75↑ 0.28↑ 0.30↑\nmT5 (Xue et al., 2020) 2.59 0.84 0.20 0.41 2.70\nmT5+Knowledge (Ours) 7.32 3.63 1.11 0.94 3.00\nPerformance Increase 4.73↑ 2.79↑ 0.91↑ 0.53↑ 0.80↑\nBART (Lewis et al., 2020) 15.92 9.72 0.70 2.03 3.90\nBART+Knowledge (Ours) 17.25 11.07 1.73 2.07 4.15\nPerformance Increase 1.33↑ 1.35↑ 1.03↑ 0.04↑ 0.250↑\nT5 (Raffel et al., 2019) 7.05 1.79 0.95 1.05 3.50\nT5+Knowledge (Ours) 15.20 8.96 1.73 1.78 4.00\nPerformance Increase 8.15↑ 7.17↑ 0.78↑ 0.73↑ 0.50↑\nof 64 for 50 epochs. We used grid-search optimiza-\ntion to derive the optimal parameters. We divided\nall datasets into training, validation, and test sets,\nwith an 80:10:10 ratio for all experiments. The\nnumber of heads in multi-head attention is set to\n12. The trained models were evaluated using auto-\nmatic metrics such as NIST-4 (Doddington, 2002),\nBLEU2, BLEU4 (Papineni et al., 2002), and ME-\nTEOR (Lavie and Agarwal, 2007).\n3.3 Baselines\nWe compared our results with state-of-the-art\nLMs that are used in previous studies for med-\nical dialogue generation tasks. To be precise,\nwe used BERT-GPT (Wu et al., 2020), Trans-\nformer (Vaswani et al., 2017), mT5 (Xue et al.,\n2020), BART (Lewis et al., 2020), and T5 (Raffel\net al., 2019) to compare the performance.\n3.4 Results\nAutomated Evaluation: Table 2 demonstrates the\nautomatic evaluation results achieved by different\nLMs, with and without knowledge. The results\nshow that adding medical knowledge to LMs im-\nproves the performance across all evaluation met-\nrics. For the MedDialogue-EN, we observed an\nincrease in BLEU2 score ranging from 0.35% to\n8.15%, for BLEU4, the improvement range is\n0.18% to 7.17%, For METEOR, the increase is\nfrom 0.91% to 17.34%, and finally, for NIST-4, the\nincrease in performance is in the range of 0.04%\nto 0.73%. From the results in Table 2, we can con-\nclude that adding medical knowledge to LMs is\nbeneficial and increases the performance of medi-\ncal dialogue generation tasks.\nHuman Evaluation: We randomly selected 100 di-\nalog examples for human evaluation. Five medical\ndoctors were asked to rate the generated responses\nindependently on a scale of 1 to 5. The greater the\nscore, the better. The final results are obtained by\naveraging the ratings provided by various experts.\nFrom the human evaluation scores (right column)\nin Table 2, we deduce that incorporating medical\nknowledge into LMs generates a more accurate,\nclinically informative, and human-like response.\n4 Conclusion\nWe present a method for enabling LMs with KGs\nto achieve domain knowledge like doctors. The\nproposed method transforms an utterance into a\nknowledge-enriched utterance tree by injecting\nmedical knowledge from KG. The embedding layer\nconverts the utterance tree into an embedding fed\nto the masked self-attention of a transformer, fol-\nlowed by the decoder to generate the response us-\ning medical dialogue history. Experimental results\ndemonstrated that our method outperforms state-\nof-the-art LMs trained on general data. Further,\nthrough human evaluation, we conclude that gener-\nated responses are informative and doctor-like. In\nfuture, we aim to expand this work to other tasks\nand datasets.\n114\nReferences\nOlivier Bodenreider. 2008. Biomedical ontologies in\naction: role in knowledge management, data inte-\ngration and decision support. Yearbook of medical\ninformatics, 17(01):67–79.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nGeorge Doddington. 2002. Automatic evaluation of ma-\nchine translation quality using n-gram co-occurrence\nstatistics. In Proceedings of the second interna-\ntional conference on Human Language Technology\nResearch, pages 138–145.\nZhendong Dong, Qiang Dong, and Changling Hao.\n2010. HowNet and its computation of meaning. In\nColing 2010: Demonstrations, pages 53–56, Beijing,\nChina. Coling 2010 Organizing Committee.\nZi-Yi Dou, Keyi Yu, and Antonios Anastasopoulos.\n2019. Investigating meta-learning algorithms for low-\nresource natural language understanding tasks. arXiv\npreprint arXiv:1908.10423.\nHao-Cheng Kao, Kai-Fu Tang, and Edward Chang.\n2018. Context-aware symptom checking for disease\ndiagnosis using hierarchical reinforcement learning.\nIn Proceedings of the AAAI Conference on Artificial\nIntelligence, volume 32.\nDiederik Kingma and Jimmy Ba. 2014. Adam: A\nmethod for stochastic optimization. arXiv preprint\narXiv:1412.6980.\nAlon Lavie and Abhaya Agarwal. 2007. Meteor: An\nautomatic metric for mt evaluation with high levels\nof correlation with human judgments. In Proceed-\nings of the second workshop on statistical machine\ntranslation, pages 228–231.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020. Bart:\nDenoising sequence-to-sequence pre-training for nat-\nural language generation, translation, and comprehen-\nsion. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pages\n7871–7880.\nXinzhu Lin, Xiahui He, Qin Chen, Huaixiao Tou,\nZhongyu Wei, and Ting Chen. 2019. Enhancing dia-\nlogue symptom diagnosis with global attention and\nsymptom graph. In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 5033–5042.\nBo Liu, Li-Ming Zhan, Li Xu, Lin Ma, Yan Yang, and\nXiao-Ming Wu. 2021. Slake: A semantically-labeled\nknowledge-enhanced dataset for medical visual ques-\ntion answering. In 2021 IEEE 18th International\nSymposium on Biomedical Imaging (ISBI) , pages\n1650–1654. IEEE.\nMartin Müller, Marcel Salathé, and Per E Kummervold.\n2020. Covid-twitter-bert: A natural language pro-\ncessing model to analyse covid-19 content on twitter.\narXiv preprint arXiv:2005.07503.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic evalu-\nation of machine translation. In Proceedings of the\n40th annual meeting of the Association for Computa-\ntional Linguistics, pages 311–318.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2019. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. arXiv preprint arXiv:1910.10683.\nXiaoming Shi, Haifeng Hu, Wanxiang Che, Zhongqian\nSun, Ting Liu, and Junzhou Huang. 2020. Under-\nstanding medical conversations with scattered key-\nword attention and weak supervision from responses.\nIn Proceedings of the AAAI Conference on Artificial\nIntelligence, volume 34, pages 8838–8845.\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-\nYan Liu. 2019. Mass: Masked sequence to sequence\npre-training for language generation. arXiv preprint\narXiv:1905.02450.\nIlya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.\nSequence to sequence learning with neural networks.\nAdvances in neural information processing systems,\n27.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. Advances in neural information processing\nsystems, 30.\nZhongyu Wei, Qianlong Liu, Baolin Peng, Huaixiao\nTou, Ting Chen, Xuan-Jing Huang, Kam-Fai Wong,\nand Xiang Dai. 2018. Task-oriented dialogue system\nfor automatic diagnosis. In Proceedings of the 56th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers) , pages 201–\n207.\nQingyang Wu, Lei Li, Hao Zhou, Ying Zeng, and Zhou\nYu. 2020. Importance-aware learning for neural head-\nline editing. In Proceedings of the AAAI Conference\non Artificial Intelligence , volume 34, pages 9282–\n9289.\n115\nLin Xu, Qixian Zhou, Ke Gong, Xiaodan Liang, Jian-\nheng Tang, and Liang Lin. 2019. End-to-end\nknowledge-routed relational dialogue system for au-\ntomatic diagnosis. In Proceedings of the AAAI Con-\nference on Artificial Intelligence, volume 33, pages\n7346–7353.\nLinting Xue, Noah Constant, Adam Roberts, Mihir Kale,\nRami Al-Rfou, Aditya Siddhant, Aditya Barua, and\nColin Raffel. 2020. mt5: A massively multilingual\npre-trained text-to-text transformer. arXiv preprint\narXiv:2010.11934.\nWenmian Yang, Guangtao Zeng, Bowen Tan, Zeqian Ju,\nSubrato Chakravorty, Xuehai He, Shu Chen, Xingyi\nYang, Qingyang Wu, Zhou Yu, et al. 2020. On the\ngeneration of medical dialogues for covid-19. arXiv\npreprint arXiv:2005.05442.\nGuangtao Zeng, Wenmian Yang, Zeqian Ju, Yue Yang,\nSicheng Wang, Ruisi Zhang, Meng Zhou, Jiaqi Zeng,\nXiangyu Dong, Ruoyu Zhang, et al. 2020. Med-\ndialog: Large-scale medical dialogue datasets. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 9241–9250."
}