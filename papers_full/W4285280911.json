{
  "title": "Can Transformer be Too Compositional? Analysing Idiom Processing in Neural Machine Translation",
  "url": "https://openalex.org/W4285280911",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2948260773",
      "name": "Verna Dankers",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2113597228",
      "name": "Christopher Lucas",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2127391507",
      "name": "Ivan Titov",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2264742718",
    "https://openalex.org/W4294103325",
    "https://openalex.org/W2981041749",
    "https://openalex.org/W2951025380",
    "https://openalex.org/W2964204621",
    "https://openalex.org/W564141097",
    "https://openalex.org/W2963685900",
    "https://openalex.org/W2986378306",
    "https://openalex.org/W2972324944",
    "https://openalex.org/W3192500523",
    "https://openalex.org/W2970820321",
    "https://openalex.org/W2970810442",
    "https://openalex.org/W2664496537",
    "https://openalex.org/W588298820",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2137815321",
    "https://openalex.org/W2980941473",
    "https://openalex.org/W2912351236",
    "https://openalex.org/W3029337234",
    "https://openalex.org/W2897507397",
    "https://openalex.org/W2964130895",
    "https://openalex.org/W4237723258",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2964343359",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2970726176",
    "https://openalex.org/W4299384410",
    "https://openalex.org/W3035241006",
    "https://openalex.org/W3155825510",
    "https://openalex.org/W2911312217",
    "https://openalex.org/W2739967986",
    "https://openalex.org/W3082928416",
    "https://openalex.org/W3173508720",
    "https://openalex.org/W4297730150",
    "https://openalex.org/W3176846012",
    "https://openalex.org/W2592517737",
    "https://openalex.org/W3118354424",
    "https://openalex.org/W1971563122",
    "https://openalex.org/W2966176804",
    "https://openalex.org/W3104652292",
    "https://openalex.org/W3183582945",
    "https://openalex.org/W3116132922",
    "https://openalex.org/W3159900299",
    "https://openalex.org/W2538358357",
    "https://openalex.org/W2990555152",
    "https://openalex.org/W3177804148",
    "https://openalex.org/W3030374439"
  ],
  "abstract": "Unlike literal expressions, idioms' meanings do not directly follow from their parts, posing a challenge for neural machine translation (NMT). NMT models are often unable to translate idioms accurately and over-generate compositional, literal translations. In this work, we investigate whether the non-compositionality of idioms is reflected in the mechanics of the dominant NMT model, Transformer, by analysing the hidden states and attention patterns for models with English as source language and one of seven European languages as target language.When Transformer emits a non-literal translation - i.e. identifies the expression as idiomatic - the encoder processes idioms more strongly as single lexical units compared to literal expressions. This manifests in idioms' parts being grouped through attention and in reduced interaction between idioms and their context.In the decoder's cross-attention, figurative inputs result in reduced attention on source-side tokens. These results suggest that Transformer's tendency to process idioms as compositional expressions contributes to literal translations of idioms.",
  "full_text": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\nVolume 1: Long Papers, pages 3608 - 3626\nMay 22-27, 2022c⃝2022 Association for Computational Linguistics\nCan Transformer be Too Compositional?\nAnalysing Idiom Processing in Neural Machine Translation\nVerna Dankers1, Christopher G. Lucas1, and Ivan Titov1,2\n1ILCC, University of Edinburgh\n2ILLC, University of Amsterdam\nvernadankers@gmail.com, {clucas2, ititov}@inf.ed.ac.uk\nAbstract\nUnlike literal expressions, idioms’ meanings\ndo not directly follow from their parts, pos-\ning a challenge for neural machine translation\n(NMT). NMT models are often unable to trans-\nlate idioms accurately and over-generate com-\npositional, literal translations. In this work, we\ninvestigate whether the non-compositionality\nof idioms is reﬂected in the mechanics of\nthe dominant NMT model, Transformer, by\nanalysing the hidden states and attention pat-\nterns for models with English as source lan-\nguage and one of seven European languages\nas target language. When Transformer emits\na non-literal translation – i.e. identiﬁes the ex-\npression as idiomatic – the encoder processes\nidioms more strongly as single lexical units\ncompared to literal expressions. This mani-\nfests in idioms’ parts being grouped through\nattention and in reduced interaction between\nidioms and their context. In the decoder’s\ncross-attention, ﬁgurative inputs result in re-\nduced attention on source-side tokens. These\nresults suggest that Transformer’s tendency to\nprocess idioms as compositional expressions\ncontributes to literal translations of idioms.\n1 Introduction\nAn idiom is a group of words of which the ﬁgura-\ntive meaning differs from the literal reading, such\nas “kick the bucket,” which means to die, instead\nof physically kicking a bucket. An idiom’s ﬁgu-\nrative meaning is established by convention and\nis typically non-compositional – i.e. the meaning\ncannot be computed from the meanings of the id-\niom’s parts. Idioms are challenging for the task of\nneural machine translation (NMT) (Barreiro et al.,\n2013; Isabelle et al., 2017; Constant et al., 2017;\nAvramidis et al., 2019). On the one hand, ﬁgures of\nspeech are ubiquitous in natural language (Colson,\n2019). On the other hand, idioms occur much less\nfrequently than their parts, their meanings need\nto be memorised due to the non-compositionality,\ncontext idiom translated\nidiom\n1 2 3\n4\nmore attention for literal\nmore attention for figurative\n</s> translated\ncontext\ncross-attention\nself-attention\nFigure 1: How do attention patterns of ﬁgurative PIEs\nthat are paraphrased by the model compare to atten-\ntion patterns of literal PIEs that are translated word for\nword? We ﬁnd (1) decreased interaction between the\nPIE and its context, (2) increased attention within the\nPIE, (3) decreased cross-attention between the PIE and\nits paraphrase, (4) increased cross-attention from the\nparaphrase to </s>.\nand they require disambiguation before translation.\nAfter all, not all potentially idiomatic expressions\n(PIEs) are ﬁgurative – e.g. consider “When I kicked\nthe bucket, it fell over”. Whether PIEs should re-\nceive a ﬁgurative or literal translation depends on\nthe context. Yet, little is known about neural mecha-\nnisms enabling idiomatic translations and methods\nfor improving them, other than data annotation (Za-\nninello and Birch, 2020). Related work studies\nhow idioms are represented by Transformer-based\nlanguage models (e.g. García et al., 2021a,b), but\nthose models are not required to output a discrete\nrepresentation of the idiom’s meaning, which is a\ncomplicating factor for NMT models.\nIn this work, we analyse idiom processing for\npre-trained NMT Transformer models (Vaswani\net al., 2017) for seven European languages by com-\nparing literal and ﬁgurative occurrences of PIEs.\nThe comparison can help identify mechanics that\nunderlie neural idiom processing to pave the way\nfor methods that improve idiomatic translations.\nLarge-scale analyses of idiom translations suffer\n3608\nfrom a lack of parallel corpora (Fadaee et al., 2018).\nWe, therefore, use a monolingual corpus, heuris-\ntically label Transformer’s translations, and ver-\nify the heuristic works as intended through human\nevaluation, as described in §3. To understand how\nidioms are represented in Transformer, we ﬁrstly\napply interpretability techniques to measure the im-\npact of PIEs on the encoder’s self-attention and the\ncross-attention mechanisms (§4), as well as the en-\ncoder’s hidden representations (§5). Afterwards, in\n§6, we intervene in the models while they process\nidiomatic expressions to show that one can change\nnon-compositional translations into compositional\nones.\nThe results indicate that Transformer typically\ntranslates idioms in a too compositional manner,\nproviding a word-for-word translation. Analyses\nof attention patterns – summarised in Figure 1 –\nand hidden representations point to the encoder\nas the mechanism grouping components of ﬁgura-\ntive PIEs. Increased attention within the PIE is ac-\ncompanied by reduced attention to context. When\ntranslating ﬁgurative PIEs, the decoder relies less\non the encoder’s output than for literal PIEs. These\npatterns are stronger for ﬁgurative PIEs that the\nmodel paraphrases than for sentences that receive\nan overly compositional translation and hold across\nthe seven European languages. Considering that\na recent trend in NLP is to encourage even more\ncompositional processing in NMT (Raunak et al.,\n2019; Chaabouni et al., 2021; Li et al., 2021, i.a.),\nwe recommend caution. It may be beneﬁcial to\nevaluate the effect of compositionality-favouring\ntechniques on non-compositional phenomena like\nidioms to ensure their effect is not detrimental.\n2 Related Work\nThis section summarises work discussing human\nidiom comprehension, interpretability studies for\nNMT, and literature about ﬁgurative language pro-\ncessing in Transformer.\nIdiom comprehension Historically, idioms were\nconsidered non-compositional units (Swinney and\nCutler, 1979). Two main views ( literal ﬁrst and\ndirect access) existed for how humans interpreted\nthem. The former suggests humans attempt a com-\npositional interpretation before considering the ﬁg-\nurative interpretation in case of a contextual dis-\ncrepancy (Bobrow and Bell, 1973; Grice, 1975,\n1989). The latter view suggests one can imme-\ndiately retrieve the non-compositional meaning\n(Gibbs Jr et al., 1994). The more recenthybrid view\nposits that idioms are simultaneously processed as\na whole – primed by a superlemma (Kuiper et al.,\n2007) – and word for word (Caillies and Butcher,\n2007). The processing speed and retrieval of the\nﬁgurative meaning depend on the idiom’s seman-\ntic properties and the context (Cain et al., 2009;\nVulchanova et al., 2019). Examples of semantic\nproperties are the conventionality and decompos-\nability of idioms (Nunberg et al., 1994). We do\nnot expect processes in Transformer to resemble id-\niom processing in humans. Nonetheless, this work\nhelps us determine our focus of study on the role\nof the surrounding context and the extent to which\nidioms’ parts are processed as a whole.\nTranslating PIEs that are used ﬁguratively is not\nalways straightforward. Baker et al. (1992) discuss\nstrategies for human translators: (i) Using an idiom\nfrom the target language of similar meaning and\nform, (ii) using an idiom from the target language\nwith a similar meaning and a different form, (iii)\ncopying the idiom to the translation, (iv) paraphras-\ning the idiom or (v) omitting it. In the absence\nof idioms with similar meanings across languages,\n(iv) is the most common strategy. Our main focus\nis on literal translations ( word-for-word transla-\ntions), and paraphrases.\nInterpreting Transformer Analyses of Trans-\nformer for NMT studied the encoder’s hidden rep-\nresentations and self-attention mechanism (e.g. Ra-\nganato and Tiedemann, 2018; Tang et al., 2019b;\nV oita et al., 2019), the cross-attention (e.g. Tang\net al., 2019a) and the decoder (e.g. Yang et al.,\n2020). The encoder is particularly important for\nthe contextualisation of tokens from the source sen-\ntence; it acts as a feature extractor (Tang et al.,\n2019b). The encoder’s bottom three layers better\nrepresent low-level syntactic features, whereas the\ntop three layers better capture semantic features\n(Raganato and Tiedemann, 2018). As a result, one\nwould expect the representations in higher layers\nto be more representative of idiomaticity.\nIdioms are a speciﬁc kind of ambiguity, and\nwhether a word is ambiguous can accurately be pre-\ndicted from the encoder’s hidden representations,\nas shown by Tang et al. (2019a) for ambiguous\nnouns. Transformer’s cross-attention is not cru-\ncial for disambiguating word senses (Tang et al.,\n2018), but the encoder’s self-attention does reﬂect\nambiguity through more distributed attention for\nambiguous nouns (Tang et al., 2019a).\n3609\nTropes in Transformer Various studies exam-\nine the Transformer-based language model BERT’s\n(Devlin et al., 2019) ability to capture tropes like\nmetonyms (Pedinotti and Lenci, 2020), idioms\n(Kurfalı and Östling, 2020), and multiple types\nof ﬁgurative language (Shwartz and Dagan, 2019).\nKurfalı and Östling (2020) detect idioms based on\nthe dissimilarity of BERT’s representations of a\nPIE and its context, assuming that contextual dis-\ncrepancies indicate ﬁgurative usage. Pedinotti and\nLenci (2020) measure whether BERT detects mean-\ning shift for metonymic expressions but ﬁnd cloze\nprobabilities more indicative than vector similari-\nties. Shwartz and Dagan (2019) ﬁnd that BERT is\nbetter at detecting ﬁgurative meaning shift than at\npredicting implicit meaning – e.g. predicting that\n“a hot argument” does not involve temperature.\nThe most recent work studies properties of\nhidden representations of noun-noun compounds\n(NCs) and verb-noun compounds (VCs): García\net al. (2021b) examine (contextualised) word em-\nbeddings, including BERT, to compare ﬁgurative\nand literal NC types. They investigate the simi-\nlarities between (1) NCs and their synonyms, (2)\nNCs and their components, (3) in-context and out-\nof-context representations, and (4) the impact of\nreplacing one component in the NC. Surprisingly,\nidiomatic NCs are quite similar to their components\nand are less similar to their synonym compared to\nliteral NCs. Moreover, the context of the NC hardly\ncontributes to how indicative its representation is of\nidiomaticity, which was also shown by García et al.\n(2021a), who measured the correlation between to-\nken-level idiomaticity scores and NCs’ similarity\nin- and out-of-context.\nIn search of the idiomatic key of VCs (the part of\nthe input that cues idiomatic usage), Nedumpozhi-\nmana and Kelleher (2021) train a probing classiﬁer\nto distinguish literal usage from ﬁgurative usage.\nThey then compare the impact of masking the PIE\nto masking the context on the classiﬁer’s perfor-\nmance and conclude that the idiomatic key mainly\nlies within the PIE itself, although there is some\ninformation coming from the surrounding context.\n3 Method\nWe use Transformer models (Vaswani et al., 2017)\nwith English as the source language and one of\nseven languages as the target language (Dutch,\nGerman, Swedish, Danish, French, Italian, Span-\nish).1 Transformer contains encoder and decoder\nnetworks with six self-attention layers each and\neight heads per attention mechanism. The mod-\nels are pre-trained by Tiedemann and Thottingal\n(2020) with the Marian-MT framework (Junczys-\nDowmunt et al., 2018) on a collection of corpora\n(OPUS) (Tiedemann and Thottingal, 2020).2 We\nextract hidden states and attention patterns for sen-\ntences with PIEs. The analyses presented are de-\ntailed for Dutch, after which we explain how the\nresults for the other languages compare to Dutch.3\nParallel PIE corpora are rare, exist for a handful\nof languages only, and are limited in size (Fadaee\net al., 2018). Rather than rely on a small paral-\nlel corpus, we use the largest corpus of English\nPIEs to date and annotate the translations heuris-\ntically. This section provides corpus statistics and\ndiscusses the heuristic annotation method.\nMAGPIE corpus The MAGPIE corpus pre-\nsented by Haagsma et al. (2020) contains 1756\nEnglish idioms from the Oxford Dictionary of En-\nglish with 57k occurrences. MAGPIE contains\nidentical PIE matches and morphological and syn-\ntactic variants, through the inclusion of common\nmodiﬁcations of PIEs, such as passivisation (“the\nbeans were spilled”) and word insertions (“spill\nall the beans”).4 We use 37k samples annotated as\nfully ﬁgurative or literal, for 1482 idioms that con-\ntain nouns, numerals or adjectives that are colours\n(which we refer to as keywords). Because idioms\nshow syntactic and morphological variability, we\nfocus mostly on the nouns. Verbs and their trans-\nlation are harder to identify due to the variability.\nMoreover, idiom indexes are also typically organ-\nised based on the nominal constituents, instead of\nthe verbs (Piirainen, 2013). Only the PIE and its\nsentential context are presented to the model. We\ndistinguish between PIEs and their context using\nthe corpus’s word-level annotations.\nHeuristic annotation method The MAGPIE\nsentences are translated by the models with beam\nsearch and a beam size of ﬁve. The translations are\nlabelled heuristically. In the presence of a literal\ntranslation of at least one of the idiom’s keywords,\n1Our ﬁgures refer to these languages using their ISO 639-1\ncodes, that are nl, de, sv, da, fr, it and es, respectively.\n2The models are available via the transformers library\n(Wolf et al., 2020).\n3The data and code are available via themt_idioms github\nrepository.\n4Available via the MAGPIE github repository.\n3610\nCategory nl de sv da fr it es\nFigurative, paraphrase 20 20 24 18 19 20 24\nFigurative, word for word 80 80 76 82 81 80 76\nLiteral, paraphrase 5 6 8 5 7 9 7\nLiteral, word for word 95 94 92 95 93 91 93\nTable 1: Distribution of the heuristically assigned la-\nbels for translations of MAGPIE sentences in percent-\nages, expressed within category (ﬁgurative / literal).\nnl de sv da fr it\nde\nsv\nda\nfr\nit\nes\n 0.66\n0.68\n0.70\n0.72\nmacro F1-score\nnl de sv da fr it\nde\nsv\nda\nfr\nit\nes\n0.2\n0.4\n0.6\ngenetic similarity\nFigure 2: The macro-averaged F1-score of translation\nlabels (paraphrase vs word for word) for ﬁgurative PIEs\nand languages’ genetic similarity visualised (Pearson’s\nr=0.61, p< 0.005).\nthe entire translation is labelled as a word-for-\nword translation, where the literal translations of\nkeywords are extracted from the model and Google\ntranslate. When a literally translated keyword is not\npresent, it is considered a paraphrase.5 Shao et al.\n(2018) previously analysed NMT translations of 50\nChinese idioms using a similar method and man-\nually curated lists of literal translations of idioms’\nwords to detect literal translation errors. Dankers\net al. (2022) use a similar method for 20 English\nidioms, to track when a word-for-word translation\nchanges into a paraphrased one during training for\nan English-Dutch (En-Nl) NMT model.\nTable 1 summarises the distribution of these cat-\negories for all languages, for the subsets of ﬁgu-\nrative and literal examples from MAGPIE. Gen-\nerally, paraphrased translations of ﬁgurative PIEs\nare more appropriate than word-for-word transla-\ntions, whereas literal PIEs can be translated word\nfor word (Baker et al., 1992). The vast major-\nity of literal PIEs indeed result in word-for-word\ntranslations. The subset of ﬁgurative samples re-\nsults in more paraphrases, but ≥ 76% is still a\nword-for-word translation, dependent on the lan-\nguage. Although the statistics are similar across\nlanguages, there are differences in which examples\nare paraphrased. Figure 2 illustrates the agreement\n5The annotation does not evaluate whether paraphrases\nare correct, which requires expert idiom knowledge in both\nlanguages. A paraphrase being provided is a ﬁrst step to\nadequately translating idioms and, at present, the only way to\ndetect how the model approaches the task for large datasets.\nCategory # nl de sv da fr it es\nFig., paraphrase 116 88 84 75 81 78 78 87\nFig., word for word 103 95 92 95 74 96 97 82\nLit., paraphrase 28 54 71 43 82 43 32 50\nLit., word for word 103 98 89 97 89 98 100 94\nTable 2: Survey statistics: the number of sentence pairs\nused (#), and the percentage of labels for which the an-\nnotator and the algorithm agreed per language.\nby computing the F1-score when using the predic-\ntions for ﬁgurative instances of one language as\nthe target, and comparing them to predictions from\nanother language. The agreement positively corre-\nlates with genetic similarity as computed using the\nUriel database (Littell et al., 2017).\nTo assess the quality of the heuristic method, one\n(near) native speaker per target language annotated\n350 samples, where they were instructed to focus\non one PIE keyword in the English sentence. An-\nnotators were asked whether (1) the English word\nwas present in the translation (initially referred to as\n“copy”), (2) whether there was a literal translation\nfor the word, or (3) whether neither of those options\nwere suited, referred to as the “paraphrase”.6 Due\nto the presence of cognates in the “copy” category,\nthat category was merged with the “word for word”\ncategory after the annotation. Table 2 summarises\nthe accuracies obtained. Of particular interest are\nsamples that are ﬁgurative and paraphrased, since\nthey represent the translations that are treated non-\ncompositionally by the model, as well as instances\nthat are literal and translated word for word, since\nthey represent the compositional translations for\nnon-idiomatic PIE occurrences. These categories\nhave annotation accuracies of ≥75% and ≥89%,\nrespectively. During preliminary analyses, an anno-\ntation study was conducted for Dutch by annotators\nfrom the crowd-sourcing platform Proliﬁc. The an-\nnotators and the heuristic method agreed in 83% of\nthe annotated examples, and for 77% of the sam-\nples an average of 4 annotators agreed on the label\nunanimously (see Appendix A for more details).\nSentences containing idioms typically yield\nlower BLEU scores (Fadaee et al., 2018). MAG-\nPIE is a monolingual corpus and does not allow us\nto compute BLEU scores, but we refer the reader\nto Appendix G for an exploratory investigation for\nMAGPIE’s idioms using theEn-Nl training corpus.\n6Annotators were not involved in the research. Except for\nSwedish, annotators were native in the target language. For\nethical considerations and more details, see Appendix A.\n3611\n1 2 3 4 5 6\nlayer\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6attention\nfig-par\nfig\nlit\nlit-wfw\n(a) PIE to PIE\n1 2 3 4 5 6\nlayer\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.150attention (b) PIE to context\n1 2 3 4 5 6\nlayer\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.150attention\n(c) Context to PIE\n0.00\n0.02\n0.04\n0.06attention differencepie-pie\npie-con con-pie\nnl\nde\nsv\nda\nfr\nit\nes (d) Language comparison\nFigure 3: Weight distributions of the encoder’s self-\nattention (a-c), and the mean difference of ﬁg-par and\nlit-wfw for all languages (d). Boxes represent quartiles;\nwhiskers show the distribution, excluding outliers.\n4 Attention\nWe now turn to comparing how literal and ﬁgura-\ntive PIEs are processed by Transformer. Whether a\nPIE is ﬁgurative depends on the context – e.g. com-\npare “in culinary school, I feltat sea” to “the sailors\nwere at sea”. Within Transformer, contextualisa-\ntion of input tokens is achieved through the atten-\ntion mechanisms, which is why they are expected to\ncombine the representations of the idioms’ tokens\nand embed the idiom in its context. This section\ndiscusses the impact of PIEs on the encoder’s self-\nattention and the encoder-decoder cross-attention.\nTo assert that the conclusions drawn in this sec-\ntion are not simply explained by shallow statistics\nof the data used, we recompute the results in Ap-\npendix C for (1) a data subset excluding variations\nof PIEs’ standard surface forms, (2) a data subset\nthat includes PIEs that appear in both ﬁgurative and\nliteral contexts, (3) a data subset that controls for\nthe number of tokens within a PIE. Qualitatively,\nthese results lead to the same ﬁndings.\nAttention within the PIE For the En-Nl Trans-\nformer, Figure 3a visualises the distribution of\nattention weights in the encoder’s self-attention\nmechanism for incoming weights to one noun con-\ntained in the PIE from the remaining PIE tokens.\nThroughout the ﬁgures in the paper, we refer to the\nsubset of sentences that have a ﬁgurative PIE and a\n1 2 3 4 5 6\nlayer\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0attention\n(a) Target to PIE noun\n1 2 3 4 5 6\nlayer\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6attention (b) Target to other PIE tokens\n1 2 3 4 5 6\nlayer\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0attention\n(c) Target to </s>\n0.10\n0.05\n0.00\n0.05\n0.10\n0.15\nattention difference\npie-noun\npie-pie pie-eos (d) Language comparison\nFigure 4: The cross-attention for target-side tokens\naligned to PIE nouns (a-c), and the mean difference be-\ntween ﬁg-par and lit-wfw for all languages (d).\nparaphrased translation as ‘ﬁg-par’. The subset of\nsentences with a literal PIE and a word-for-word\ntranslation are indicated by ‘lit-wfw’. We compare\nthose two subsets, as well as all instances of ﬁg-\nurative PIEs (‘ﬁg’) to all instances of literal PIEs\n(‘lit’) using the labels from the MAGPIE dataset.\nOverall, there is increased attention in ﬁgurative\noccurrences of PIEs compared to literal instances.\nThis difference is ampliﬁed for the subset of ﬁgu-\nrative PIEs yielding paraphrased translations. This\npattern is consistent for all languages, as is dis-\nplayed in Figure 3d that presents the difference\nbetween the mean attention weights of the ﬁgura-\ntive, paraphrased instances, and the mean weights\nof the literal instances translated word for word.7\nIn other words, ﬁgurative PIEs are grouped more\nstrongly than their literal counterparts.\nAttention between PIEs and context To exam-\nine the interaction between a PIE and its context,\nwe obtain the attention weights from tokens within\nthe PIE to nouns in the surrounding context of size\n10 (Figure 3b).8 Similarly, the attention from the\nsurrounding context to PIE nouns is measured (Fig-\nure 3c). There is reduced attention from PIEs to\ncontext for ﬁgurative instances, which mirrors the\neffect observed in Figure 3a: increased attention\n7Appendix D details results per language per layer.\n8Throughout the paper, a context size of 10 to the left and\n10 to the right or smaller is used, as sentence length permits.\n3612\nwithin the PIE is accompanied by reduced atten-\ntion to the context. This pattern is consistent across\nlanguages (Figure 3d). From the context to the\nPIE, the average weight is slightly higher for literal\nPIEs, but the effect size is small, indicating only\na minor impact of ﬁgurativeness on the context’s\nattention weights. This will be further investigated\nin §5.\nCross-attention To analyse the encoder-decoder\ninteraction, we decode translations with beam size\nﬁve, and extract the cross-attention weights for\nthose translations. Afterwards, alignments are com-\nputed for the models’ predictions by, together with\n1M sentences from the OPUS corpus per target\nlanguage, aligning them using the eflomal toolkit\n(Östling et al., 2016). The alignment is used to\nmeasure attention from a token aligned to a PIE’s\nnoun to that noun on the source side.9\nFigure 4a presents the attention distribution for\nthe weights that go from the noun’s translation to\nthat PIE noun on the source side, for the En-Nl\nmodel. There is a stark difference between ﬁgu-\nrative and literal PIEs, through reduced attention\non the source-side noun for ﬁgurative PIEs. This\ndifference is particularly strong for the ﬁgurative\nsentences that are paraphrased during the transla-\ntion: when paraphrasing the model appears to rely\nless on the source-side noun than when translat-\ning word for word. Where does the attention ﬂow,\ninstead? To some extent, to the remaining PIE to-\nkens (Figure 4b). A more pronounced pattern of\nincreased attention on the </s> token is shown in\nFigure 4c. Similar behaviour has been observed by\nClark et al. (2019) for BERT’s[SEP] token, who\nsuggest that this indicates a no-operation. In Trans-\nformer’s cross-attention mechanism, this would\nmean that the decoder collects little information\nfrom the source side. Figure 4d compares the mean\nattention weights of the seven languages for the\nﬁgurative inputs that are paraphrased to the literal\nsamples that are translated word for word, conﬁrm-\ning that these patterns are not speciﬁc to En-Nl\ntranslation.\nCollectively, the results provide the observations\ndepicted in Figure 1. When paraphrasing a ﬁgu-\n9Automated alignments may be less accurate for para-\nphrases, and, therefore, we inspect the ﬁg-par alignments: for\nall languages ≤34% of those sentences has no aligned word\nfor the PIE noun. Those sentences are excluded. We manu-\nally inspect the most frequently aligned words for Dutch, that\ncover 48% of the ﬁg-par subcategory in Ap. B, and are all\naccurate.\nrative PIE, the model groups idioms’ parts more\nstrongly than it would otherwise – i.e. it captures\nthe PIE more as one unit. A lack of grouping all ﬁg-\nurative PIEs could be a cause of too compositional\ntranslations. Increased attention within the PIE is\naccompanied by reduced interaction with context,\nindicating that the PIE is translated in a stand-alone\nmanner, contrary to what is expected, namely that\ncontextualisation can resolve the ﬁgurative versus\nliteral ambiguity. There is less cross-attention on\nthe source-side PIE and more attention on the </s>\ntoken when the model emits the translation of ﬁgu-\nrative (paraphrased) PIEs. This suggests that even\nthough the encoder cues ﬁgurative usage, the de-\ncoder retrieves a PIE’s paraphrase and generates its\ntranslation more as a language model would.\n5 Hidden representations\nWithin Transformer, the encoder’s upper layers\nhave previously been found to encode semantic\ninformation (e.g. Raganato and Tiedemann, 2018).\nPIEs’ hidden states are expected to transform over\nlayers due to contextualisation, and become increas-\ningly more indicative of ﬁgurativeness. This sec-\ntion focuses on the impact of PIEs on the hidden\nstates of Transformer’s encoder. We ﬁrstly discuss\nhow much these hidden states change between lay-\ners. Secondly, we measure the inﬂuence of a token\nby masking it out in the attention and analysing the\ndegree of change in the hidden representations of\nits neighbouring tokens. This analysis is performed\nto consolidate ﬁndings from §4, since the extent to\nwhich attention can explain model behaviour is a\ntopic of debate (Jain and Wallace, 2019; Wiegreffe\nand Pinter, 2019).\n5.1 PIE changes over layers\nTo compare representations from different layers,\nwe apply canonical correlation analysis (CCA)\n(Hotelling, 1936), using an implementation from\nRaghu et al. (2017). Assume matricesA∈RdA×N\nand B ∈RdB×N , that are representations for N\ndata points, drawn from two different sources with\ndimensionalities dA and dB – e.g. different layers\nof one network. CCA linearly transforms these\nsubspaces A′ = WA, B′ = VB such as to max-\nimise the correlations {ρ1,...,ρ min(dA,dB)}of the\ntransformed subspaces. We perform CCA using\n>60k random token vectors for a previously un-\nused subset of the MAGPIE corpus – the subset of\nsentences that did not contain nouns in the PIEs –\n3613\n1-2 2-3 3-4 4-5 5-6\nlayers\n0.75\n0.80\n0.85CCA similarity\n(a) Non-PIE nouns\n1-2 2-3 3-4 4-5 5-6\nlayers\n0.75\n0.80\n0.85CCA similarity\nlit-wfw\nlit\nfig\nfig-par (b) PIE nouns\n1-2 2-3 3-4 4-5 5-6\nlayers\n0.00\n0.02\n0.04\n0.06\n0.08difference in similarity\nnl\nde\nsv\nda\nfr\nit\nes\n(c) Languages comparison for PIE nouns\nFigure 5: CCA similarity for layer land layer l+ 1, for\nPIE and non-PIE nouns. The languages comparison dis-\nplays the difference in similarity between lit-wfw and\nﬁg-par.\nto compute the CCA projection matrices W and V.\nW and V are then used to project new data points\nbefore measuring the data points’ correlation. The\nCCA similarity reported in the graphs is the av-\nerage correlation of projected data points. We do\nnot perform CCA separately per data subset due to\nthe small subset sizes and the impact of vocabulary\nsizes on CCA correlations for small datasets (see\nAppendix E).10\nWe compute the CCA similarity for hidden states\nfrom adjacent layers for PIE and non-PIE nouns.\nFigurative PIEs in layer lare typically less similar\nto their representation in layer l−1 compared to\nliteral instances (shown in Figures 5b and 5c). The\nresults for non-PIE nouns (Figure 5a for the En-Nl\nTransformer) do not differ across data subsets, sug-\ngesting that changes observed for ﬁgurative PIEs\nare indeed due to ﬁgurativeness.\n5.2 Intercepting in attention\nWe now compute similarities of representations for\nthe model in two setups: with and without one\ntoken masked in the attention mechanism, as sug-\ngested by V oita et al. (2019). Masking a token\nmeans that other tokens are forbidden to attend to\nthe chosen one. This can reveal whether the atten-\ntion patterns discussed in §4 are indicative of the\n10Extensions of CCA have been proposed that limit the\nnumber of CCA directions over which the correlation is com-\nputed, to only include directions that explain a large portion\nof the variance (Raghu et al., 2017; Morcos et al., 2018). We\ndo not remove directions such as to avoid removing smaller\nvariance components that could still cue ﬁgurativeness (the\nfocus of our work).\n1 2 3 4 5 6\nlayer\n0.95\n0.96\n0.97\n0.98\n0.99\n1.00CCA similarity\n(a) Inﬂuence PIE on PIE\n1 2 3 4 5 6\nlayer\n0.9875\n0.9900\n0.9925\n0.9950\n0.9975\n1.0000CCA similarity (b) Inﬂuence PIE on context\n1 2 3 4 5 6\nlayer\n0.995\n0.996\n0.997\n0.998\n0.999\n1.000CCA similarity\n(c) Inﬂuence context on PIE\n1 2 3 4 5 6\nlayer\n0.985\n0.990\n0.995\n1.000CCA similarity (d) Control setup\n0.000\n0.005\n0.010\n0.015difference in similaritypie-pie pie-con\ncon-pie con-con\nnl\nde\nsv\nda\nfr\nit\nes\n(e) Languages comparison\nFigure 6: Impact of masking a PIE noun in the atten-\ntion on (a) other PIE tokens, (b) other context tokens.\nImpact of masking a non-PIE noun on (c) PIE tokens\nand (d) other non-PIE tokens. (e) shows the difference\nin similarity between lit-wfw and ﬁg-par.\ninﬂuence tokens have on each other’s hidden rep-\nresentations. The ﬁrst representation is the hidden\nrepresentation from layer lfor a token encoded as\nusual. The second one is the hidden representa-\ntion of layer lwhen applying the ﬁrst l−1 layers\nas usual and masking one token in the lth layer.\nCCA is again performed on separate data, where a\nnon-PIE noun is masked, to provide the projection\nmatrices applied before computing similarities in\nthe remainder of this subsection.\nMasking a PIE token To estimate the inﬂuence\nof PIE nouns, we ﬁrst compute the CCA similar-\nity between two representations of tokens from the\nPIE’s context while masking one PIE noun in the at-\ntention for one of those representations. Similarly,\nwe measure the inﬂuence on other tokens within the\nPIE when masking one PIE noun. Within the PIE,\nthe impact is the largest for ﬁgurative instances\n(see Figure 6a for En-Nl and 6e for averages over\nlayers for all languages). This is in line with the\nattention pattern observed. However, whether the\nimpact is the largest on context tokens from ﬁgu-\nrative or literal instances is dependent on the layer\n3614\n0.6\n0.8\n1.0macro F1\nnl\n de\n sv\n da\ne 1 2 3 4 5 6\nlayers\n0.6\n0.8\n1.0macro F1\nfr\ne 1 2 3 4 5 6\nlayers\nes\ne 1 2 3 4 5 6\nlayers\nit\nfig-par/lit-wfw\nfig/lit\nFigure 7: Macro F1-score for probes predicting PIEs’\nlabels. Error bars show standard deviations over folds.\nFig. Freq.\nnl 36/75 34/75\nde 33/68 33/69\nsv 27/77 27/77\nda 32/77 27/78\nfr 37/77 30/76\nit 39/76 34/77\nes 40/78 30/78\n(a) Success rate / BLEU\n50\n25\n0\n25\n50\nchange (%)\npie-pie\npie-con\ncon-pie (b) Change in attention (nl)\nTable 3: Impact of amnesic probing as (a) the success\nrate per PIE type (%), and the BLEU score of trans-\nlations that changed from a paraphrase to a word-for-\nword translation, and (b) the changes in attention.\n(Figure 6b), suggesting that the slight difference in\nattention from the context to the PIE observed in §4\nneed not represent a difference in impact between\nﬁgurative and literal PIEs.\nMasking a context token Lastly, we measure\nthe inﬂuence of masking a noun in the context of\nthe PIE on PIE tokens and non-PIE tokens. Within\nthe PIE, as shown in Figures 6c and 6e, ﬁgura-\ntive instances are less affected by the masked con-\ntext noun compared to literal occurrences of PIEs.\nAgain, this mirrors the patterns observed for atten-\ntion where there was less attention on the context\nfor ﬁgurative PIEs. When masking a non-PIE noun\nand measuring the impact on non-PIE tokens, one\nwould hardly expect any differences between data\nsubsets, as is conﬁrmed in Figures 6d and 6e.\nIn summary, these analyses conﬁrm most of the\ntrends noted for attention patterns. Intercepting\nin the attention through masking indicated that for\nPIE tokens, there is less interaction with the context.\nHowever, this does not necessarily mean that the\ncontext interacts less with ﬁgurative PIEs compared\nto literal PIEs, even if there was a slight difference\nin attention (see §4). The CCA analyses further-\nmore showed that ﬁgurative PIEs are distinct from\ntypical tokens in how they change over layers.\n6 (Amnesic) probing for ﬁgurativeness\nThe previous analyses compared the hidden states\nfor ﬁgurative and literal PIEs, but do not use these\nlabels, otherwise. We now train logistic regression\nprobing classiﬁers (Conneau et al., 2018) to predict\nthe label from hidden representations. The probes’\ninputs are the hidden states of PIE tokens, and the\nF1-scores are averaged over ﬁve folds. All samples\nfrom one PIE are in the same fold, such that the\nclassiﬁer is evaluated on PIEs that were absent from\nits training data. The results (Figure 7) indicate ﬁg-\nurativeness can be predicted from these encodings,\nwith performance increasing until the top layer for\nall languages. F1-scores for the embeddings al-\nready exceed a random baseline, indicating some\nidioms are recognisable independent of context.\nFinally, we use probing classiﬁers to change\nmodels’ PIE translations through amnesic prob-\ning (Elazar et al., 2021): removing features from\nhidden states with iterative null-space projection\n(INLP) (Ravfogel et al., 2020) and measuring the\ninﬂuence of these interventions. INLP trains k\nclassiﬁers to predict a property from vectors. Af-\nter training probe i, parametrised by Wi, the vec-\ntors are projected onto the nullspace of Wi. The\nprojection matrix of the intersection of all knull\nspaces can then remove features found by these\nclassiﬁers. Using INLP, we train 50 classiﬁers to\ndistinguish ﬁgurative PIEs that will be paraphrased\nfrom those to be translated word for word. Af-\nterwards, we run the previously paraphrased PIE\noccurrences through the model while removing in-\nformation from the PIE’s hidden states using INLP\n– i.e. information that could be captured by linear\nclassiﬁers, which need not be the only features rele-\nvant to idiomatic translations. Per idiom, we record\nthe percentage of translations that are no longer\nparaphrased. We report the scores for idioms from\nfour folds and BLEU scores comparing translations\nthat changed label before and after INLP. A ﬁfth\nfold is used for parameter estimation (Appendix F).\nTable 3 presents the results. When intervening\nin the hidden states for all layers l∈{0,1,2,3,4},\nthe average success rate per PIE ranges from 27%\n(for Swedish) to 40% (for Spanish). The interven-\ntions yield reduced attention within the PIE and\nincreased interaction with the context (see Table 3b\nfor Dutch). Table 3 also provides results for a base-\nline probe predicting whether the half-harmonic\nmean of the zipf-frequency of PIE tokens is below\nor above average. This probe is successful too,\n3615\nDutch\nGerman\nSwedish\nDanish\nFrench\nItalian\nSpanish\nThen, brisk again, ' I 'll bear it in mind. ' \nEntonces, rápido de nuevo, ' Lo tendré en cuenta. ' \nEntonces, anímate de nuevo, 'Lo tendré en mente'.\nThe two went hand in hand until the later nineteenth century. \nI due andarono di pari passo fino al XIX secolo.\nI due sono andati mano nella mano fino al XIX secolo successivo.\n(...) beside a autobank, which was out of order.\n(...) à côté d'une autobanque, ce qui était hors service. \n(...) à côté d'une autobanque, ce qui n'était pas de l'ordre.\n(...) managership is absent across the board in Britain.\n(...) lederskab er fraværende over hele linjen i Storbritannien.\n(...) lederskab er fraværende på tværs af bestyrelsen i Storbritannien.\nVocal communication is out of the question till after the third cup (...) \nVokal kommunikation är uteslutet till efter den tredje koppen (...) \nVokal kommunikation är ute ur frågan tills efter den tredje koppen (...)\nThe trouble is, we don't see eye to eye, or, (...)  \nHet probleem is dat we het niet met elkaar eens zijn... of (...)\nHet probleem is, we zien geen oog tegen oog, of, (...) \n(...) of the Salvation Army has broken new ground at the site.\n(...) der Heilsarmee hat am Standort neue Wege eingeschlagen. \n(...) der Heilsarmee hat am Standort einen neuen Boden eingeschlagen.\nFigure 8: Source sentences and translations before and\nafter INLP. PIEs and word-for-word translations are in\nbold font; paraphrases in italics. Colours indicate atten-\ntion changes with respect to the underlined nouns.\nemphasising how brittle idiomatic translations are:\nwhen removing information from the hidden states,\nthe model reverts to compositional translations.\nFigure 8 provides example translations before\nand after the application of INLP, while indicating\nhow the attention on the underlined noun changes.\nGenerally, the attention on that noun reduces for\ntokens other than itself.\nIn summary, when applying INLP to hidden states,\nthe attention patterns resemble patterns for literal\ntokens more, conﬁrming a causal connection be-\ntween the model paraphrasing ﬁgurative PIEs and\nthe attention. However, amnesic probing cannot\nchange the paraphrases for all idioms; thus, ﬁgura-\ntiveness is not merely linearly encoded in the hid-\nden states. The probing accuracies differed across\nlayers and suggested ﬁgurativeness is more easily\ndetectable in higher layers, which is in line with\nthe changes across layers observed in §5.\n7 Conclusion\nIdioms are challenging for NMT models that often\ngenerate overly compositional idiom translations.\nTo understand why this occurs, we analysed idiom\nprocessing in Transformer, using an English id-\niom corpus and heuristically labelled translations in\nseven target languages. We compared hidden states\nand attention patterns for ﬁgurative and literal PIEs.\nIn the encoder, ﬁgurative PIEs are grouped more\nstrongly as one lexical unit than literal instances\nand interact less with their context. The effect is\nstronger for paraphrased translations, suggesting\nthat capturing idioms as single units and translating\nthem in a stand-alone manner aids idiom process-\ning. This ﬁnding agrees with results from Zaninello\nand Birch (2020), who ascertain that encoding an\nidiom as one word improves translations. It also\nagrees with the INLP application causing more\ncompositional translations whilst changing the at-\ntention. By relying less on the encoder’s output,\nthe decoder determines the meaning of ﬁgurative\nPIEs more independently than for literal ones. To\nimprove idiomatic translations, future work could\nuse these insights to make architectural changes to\nimprove the grouping of idioms as single units by\ntraining speciﬁc attention heads to capture multi-\nword expressions or by penalising overly composi-\ntional translations in the training objective.\nAlthough we learnt about mechanics involved in\nidiomatic translations, the vast majority of transla-\ntions was still word for word, indicating that non-\ncompositional processing does not emerge well\n(enough) in Transformer. Paradoxically, a recent\ntrend is to encourage more compositional process-\ning in NMT (Chaabouni et al., 2021; Li et al., 2021;\nRaunak et al., 2019, i.a.). We recommend caution\nsince this inductive bias may harm idiom transla-\ntions. It may be beneﬁcial to evaluate the effect\nof compositionality-favouring techniques on non-\ncompositional phenomena to ensure their effect is\nnot detrimental.\nAcknowledgements\nWe are grateful to Rico Sennrich for providing\nfeedback on an earlier version of the paper. Many\nthanks to Agostina Calabrese, Matthias Lindemann,\nGautier Dagan, Irene Winther, Ronald Cardenas,\nHelena Fabricius-Vieira and Emelie van de Vreken\nfor data annotation and assistance with queries\nabout their native languages. VD is supported\nby the UKRI Centre for Doctoral Training in Nat-\nural Language Processing, funded by the UKRI\n(grant EP/S022481/1) and the University of Edin-\nburgh, School of Informatics and School of Phi-\nlosophy, Psychology & Language Sciences. IT ac-\nknowledges the support of the European Research\nCouncil (ERC StG BroadSem 678254) and the\n3616\nDutch National Science Foundation (NWO Vidi\n639.022.518).\nReferences\nEleftherios Avramidis, Vivien Macketanz, Ursula\nStrohriegel, and Hans Uszkoreit. 2019. Linguistic\nevaluation of German-English machine translation\nusing a test suite. In Proceedings of the Fourth Con-\nference on Machine Translation (Volume 2: Shared\nTask Papers, Day 1), pages 445–454.\nMona Baker et al. 1992. In Other Words. Routledge.\nAnabela Barreiro, Johanna Monti, Brigitte Orliac, Fer-\nnando Batista, et al. 2013. When multiwords go bad\nin machine translation. In Proceedings of the Work-\nshop on Multi-word Units in Machine Translation\nand Translation Technology, pages 26–33.\nSamuel A Bobrow and Susan M Bell. 1973. On catch-\ning on to idiomatic expressions. Memory & cogni-\ntion, 1(3):343–346.\nStéphanie Caillies and Kirsten Butcher. 2007. Process-\ning of idiomatic expressions: Evidence for a new hy-\nbrid view. Metaphor and Symbol, 22(1):79–108.\nKate Cain, Andrea S Towse, and Rachael S Knight.\n2009. The development of idiom comprehension:\nAn investigation of semantic and contextual process-\ning skills. Journal of experimental child psychology,\n102(3):280–298.\nRahma Chaabouni, Roberto Dessì, and Eugene\nKharitonov. 2021. Can transformers jump around\nright in natural language? Assessing performance\ntransfer from scan. In Proceedings of the Fourth\nBlackboxNLP Workshop on Analyzing and Interpret-\ning Neural Networks for NLP, pages 136–148.\nKevin Clark, Urvashi Khandelwal, Omer Levy, and\nChristopher D Manning. 2019. What does BERT\nlook at? An analysis of BERT’s attention. In Pro-\nceedings of the 2019 ACL Workshop BlackboxNLP:\nAnalyzing and Interpreting Neural Networks for\nNLP, pages 276–286.\nJean-Pierre Colson. 2019. Multi-word units in ma-\nchine translation: why the tip of the iceberg re-\nmains problematic–and a tentative corpus-driven so-\nlution. Computational and Corpus-based Phraseol-\nogy, page 145.\nAlexis Conneau, German Kruszewski, Guillaume Lam-\nple, Loïc Barrault, and Marco Baroni. 2018. What\nyou can cram into a single $&!#* vector: Probing\nsentence embeddings for linguistic properties. In\nProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 2126–2136.\nMathieu Constant, Gül¸ sen Eryi ˘git, Johanna Monti,\nLonneke Van Der Plas, Carlos Ramisch, Michael\nRosner, and Amalia Todirascu. 2017. Multiword ex-\npression processing: A survey. Computational Lin-\nguistics, 43(4):837–892.\nVerna Dankers, Elia Bruni, and Dieuwke Hupkes. 2022.\nThe paradox of the compositionality of natural lan-\nguage: a neural machine translation case study. In\nProceedings of the 60th Annual Meeting of the Asso-\nciation for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186.\nYanai Elazar, Shauli Ravfogel, Alon Jacovi, and Yoav\nGoldberg. 2021. Amnesic probing: Behavioral ex-\nplanation with amnesic counterfactuals. Transac-\ntions of the Association for Computational Linguis-\ntics, 9:160–175.\nMarzieh Fadaee, Arianna Bisazza, and Christof Monz.\n2018. Examining the tip of the iceberg: A data set\nfor idiom translation. In Proceedings of the Eleventh\nInternational Conference on Language Resources\nand Evaluation (LREC 2018).\nMarcos García, Tiago Kramer Vieira, Carolina Scar-\nton, Marco Idiart, and Aline Villavicencio. 2021a.\nAssessing the representations of idiomaticity in vec-\ntor models with a noun compound dataset labeled at\ntype and token levels. In Proceedings of the 59th An-\nnual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Confer-\nence on Natural Language Processing (Volume 1:\nLong Papers), pages 2730–2741.\nMarcos García, Tiago Kramer Vieira, Carolina Scar-\nton, Marco Idiart, and Aline Villavicencio. 2021b.\nProbing for idiomaticity in vector space models. In\nProceedings of the 16th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Main Volume, pages 3551–3564.\nRaymond W Gibbs Jr, Raymond W Gibbs, and\nJr Gibbs. 1994. The poetics of mind: Figurative\nthought, language, and understanding . Cambridge\nUniversity Press.\nH. Paul Grice. 1975. Logic and conversation. Syntax\nand Semantics, 3:41–58.\nH. Paul Grice. 1989. Studies in the Way of Words. Har-\nvard University Press.\nHessel Haagsma, Johan Bos, and Malvina Nissim.\n2020. MAGPIE: A large corpus of potentially id-\niomatic expressions. In Proceedings of The 12th\nLanguage Resources and Evaluation Conference ,\npages 279–287.\n3617\nHarold Hotelling. 1936. Relations between two sets of\nvariates. Biometrika, 28(3/4):321–377.\nPierre Isabelle, Colin Cherry, and George Foster. 2017.\nA challenge set approach to evaluating machine\ntranslation. In Proceedings of the 2017 Conference\non Empirical Methods in Natural Language Process-\ning, pages 2486–2496.\nSarthak Jain and Byron C Wallace. 2019. Attention is\nnot explanation. In Proceedings of the 2019 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, Volume 1 (Long and Short Pa-\npers), pages 3543–3556.\nMarcin Junczys-Dowmunt, Roman Grundkiewicz,\nTomasz Dwojak, Hieu Hoang, Kenneth Heaﬁeld,\nTom Neckermann, Frank Seide, Ulrich Germann, Al-\nham Fikri Aji, Nikolay Bogoychev, et al. 2018. Mar-\nian: Fast neural machine translation in C++. In\nProceedings of ACL 2018, System Demonstrations ,\npages 116–121.\nKoenraad Kuiper, Marie-Elaine Van Egmond, Gerard\nKempen, and Simone Sprenger. 2007. Slipping on\nsuperlemmas: Multi-word lexical items in speech\nproduction. The Mental Lexicon, 2(3):313–357.\nMurathan Kurfalı and Robert Östling. 2020. Disam-\nbiguation of potentially idiomatic expressions with\ncontextual embeddings. In Proceedings of the Joint\nWorkshop on Multiword Expressions and Electronic\nLexicons, pages 85–94.\nYafu Li, Yongjing Yin, Yulong Chen, and Yue Zhang.\n2021. On compositional generalization of neural\nmachine translation. In Proceedings of the 59th An-\nnual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Confer-\nence on Natural Language Processing (Volume 1:\nLong Papers), pages 4767–4780.\nPatrick Littell, David R Mortensen, Ke Lin, Katherine\nKairis, Carlisle Turner, and Lori Levin. 2017. Uriel\nand lang2vec: Representing languages as typologi-\ncal, geographical, and phylogenetic vectors. In Pro-\nceedings of the 15th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Volume 2, Short Papers, pages 8–14.\nAri S Morcos, Maithra Raghu, and Samy Bengio. 2018.\nInsights on representational similarity in neural net-\nworks with canonical correlation. In Proceedings of\nthe 32nd International Conference on Neural Infor-\nmation Processing Systems, pages 5732–5741.\nVasudevan Nedumpozhimana and John Kelleher. 2021.\nFinding BERT’s idiomatic key. In Proceedings of\nthe 17th Workshop on Multiword Expressions (MWE\n2021), pages 57–62.\nGeoffrey Nunberg, Ivan A Sag, and Thomas Wasow.\n1994. Idioms. Language, 70(3):491–538.\nRobert Östling, Jörg Tiedemann, et al. 2016. Efﬁcient\nword alignment with markov chain monte carlo.The\nPrague Bulletin of Mathematical Linguistics.\nPaolo Pedinotti and Alessandro Lenci. 2020. Don’t in-\nvite BERT to drink a bottle: Modeling the interpreta-\ntion of metonymies using BERT and distributional\nrepresentations. In Proceedings of the 28th Inter-\nnational Conference on Computational Linguistics ,\npages 6831–6837.\nElisabeth Piirainen. 2013. Widespread idioms in eu-\nrope and beyond. toward a lexicon of common\nﬁgurative units. Neuphilologische Mitteilungen ,\n13(4):489–.\nAlessandro Raganato and Jörg Tiedemann. 2018. An\nanalysis of encoder representations in transformer-\nbased machine translation. EMNLP 2018, page 287.\nMaithra Raghu, Justin Gilmer, Jason Yosinski, and\nJascha Sohl-Dickstein. 2017. SVCCA: singular vec-\ntor canonical correlation analysis for deep learning\ndynamics and interpretability. In Proceedings of\nthe 31st International Conference on Neural Infor-\nmation Processing Systems, pages 6078–6087.\nVikas Raunak, Vaibhav Kumar, Florian Metze, and\nJaimie Callan. 2019. On compositionality in neural\nmachine translation. In NeurIPS 2019 Context and\nCompositionality in Biological and Artiﬁcial Neural\nSystems Workshop.\nShauli Ravfogel, Yanai Elazar, Hila Gonen, Michael\nTwiton, and Yoav Goldberg. 2020. Null it out:\nGuarding protected attributes by iterative nullspace\nprojection. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 7237–7256.\nYutong Shao, Rico Sennrich, Bonnie Webber, and Fed-\nerico Fancellu. 2018. Evaluating machine transla-\ntion performance on chinese idioms with a black-\nlist method. In Proceedings of the Eleventh Interna-\ntional Conference on Language Resources and Eval-\nuation (LREC 2018).\nVered Shwartz and Ido Dagan. 2019. Still a pain in the\nneck: Evaluating text representations on lexical com-\nposition. Transactions of the Association for Com-\nputational Linguistics, 7:403–419.\nDavid A Swinney and Anne Cutler. 1979. The access\nand processing of idiomatic expressions. Journal\nof verbal learning and verbal behavior , 18(5):523–\n534.\nGongbo Tang, Rico Sennrich, and Joakim Nivre. 2018.\nAn analysis of attention mechanisms: The case of\nword sense disambiguation in neural machine trans-\nlation. In Proceedings of the Third Conference on\nMachine Translation: Research Papers , pages 26–\n35.\n3618\nGongbo Tang, Rico Sennrich, and Joakim Nivre. 2019a.\nEncoders help you disambiguate word senses in\nneural machine translation. In Proceedings of the\n2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 1429–1435.\nGongbo Tang, Rico Sennrich, and Joakim Nivre. 2019b.\nUnderstanding neural machine translation by simpli-\nﬁcation: The case of encoder-free models. In Pro-\nceedings of the International Conference on Recent\nAdvances in Natural Language Processing (RANLP\n2019), pages 1186–1193.\nJörg Tiedemann and Santhosh Thottingal. 2020.\nOPUS-MT–building open translation services for\nthe world. In Proceedings of the 22nd Annual Con-\nference of the European Association for Machine\nTranslation, pages 479–480.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Proceedings of the 31st International\nConference on Neural Information Processing Sys-\ntems, pages 6000–6010.\nElena V oita, Rico Sennrich, and Ivan Titov. 2019. The\nbottom-up evolution of representations in the trans-\nformer: A study with machine translation and lan-\nguage modeling objectives. In Proceedings of the\n2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 4387–4397.\nMila Vulchanova, Evelyn Milburn, Valentin Vulchanov,\nand Giosuè Baggio. 2019. Boon or burden? The role\nof compositional meaning in ﬁgurative language pro-\ncessing and acquisition. Journal of Logic, Language\nand Information, 28(2):359–387.\nSarah Wiegreffe and Yuval Pinter. 2019. Attention is\nnot not explanation. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP), pages 11–20.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language process-\ning. In Proceedings of the 2020 Conference on Em-\npirical Methods in Natural Language Processing:\nSystem Demonstrations, pages 38–45, Online. Asso-\nciation for Computational Linguistics.\nYilin Yang, Longyue Wang, Shuming Shi, Prasad Tade-\npalli, Stefan Lee, and Zhaopeng Tu. 2020. On the\nsub-layer functionalities of transformer decoder. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: Findings,\npages 4799–4811.\nAndrea Zaninello and Alexandra Birch. 2020. Multi-\nword expression aware neural machine translation.\nIn Proceedings of The 12th Language Resources and\nEvaluation Conference, pages 3816–3825.\n3619\nAppendix A Survey details\nA.1 Crowd-sourcing annotations for Dutch\nIn an early phase of the research, the quality of the\nheuristic annotation method was estimated through\na survey conducted using the Qualtrics platform by\nannotators from Proliﬁc. The heuristic annotation\nmethod labelled a translation as ‘word for word’\nif the literal translation of a keyword was present,\nwhere the keyword was elicited from MarianMT,\nand from the translation tool DeepL. These anno-\ntators were native speakers of Dutch, and ﬂuent\nin English. To guard the quality of the data col-\nlection, participants went through a pre-screening\nprocess that consisted of a shorter version of the\nsurvey with three practice questions and seven regu-\nlar questions. Participants were selected for the full\nstudy if they correctly answered practice questions,\nused all three of the labels (paraphrase, word for\nword, copy), and did not choose ‘copy’ if the key-\nword was clearly absent from the translation. The\nmain survey consisted of three parts: (1) An expla-\nnation of what an idiom is, of potential literal and\nﬁgurative usage of PIEs, the meaning of the three la-\nbels, and the format to be used in the study. (2) One\npractice exercise where three potential translations\nof one sentence had to be connected to the correct\nlabel. (3) Lastly, 38 questions were ﬁlled out: 12\ninstances that were ﬁgurative and were paraphrased\nby the model, 4 literal instances paraphrased by the\nmodel, 8 literal instances that were translated word\nfor word, 8 ﬁgurative instances that were translated\nword for word, 6 copies (3 ﬁgurative, 3 literal).\nIf the participant indicated that it was a word-\nby-word translation, the follow-up question would\nbe asked, where the participant indicated the lit-\neral translation of the keyword. We repeated the\ninstruction of what constitutes a word-by-word\ntranslation since participants would often select\nthe (conventionalised) idiomatic translation in the\npre-screening phase – e.g. ‘handbereik’ for ‘ﬁn-\ngertips’, for which a literal translation would be\n‘vingertoppen’.\nTable 4 summarises the survey outcomes. The\nannotators and the heuristic method agreed in 83%\nof the cases. For 77% of the samples, the annota-\ntions agreed on the label unanimously.\nA.2 Collecting annotations for 7 languages\nLater on, the analyses were applied to heuristically\nannotated data for all seven languages. The proce-\ndure to elicit the translations of keywords from Mar-\nMAGPIE Predicted Translations\nParaphrase Word for word* Copy*\n# % agr # % agr # % agr\nFigurative 96 86 84 64 84 77 24 83 58\nLiteral 32 73 59 64 91 80 24 69 88\nTable 4: Survey statistics: the number of sentence pairs\nused (#), the % of labels the algorithm and annotators\nagreed on, and inter-annotator agreement. Agreement\nmeans an average of 4 annotators agreed on the label\nunanimously. *Categories merged in the main paper.\nQuestion\nThe following sentence contains \"at your ﬁngertips\":\n\"Using the latest in audio visual technology, the wonders of\nthese six fascinating ‘worlds’ are at your ﬁngertips.\"\nNow categorise the translation of the red word from\nabove in this sentence:\n\"Met behulp van de nieuwste audio visuele technologie,\nzijn de wonderen van deze zes fascinerende\nwerelden binnen handbereik.\"\n◦paraphrase\n◦word-by-word\n◦copy\nFollow-up question\nIf you did not select ’word for word’, leave blank.\nWhat is the translation of the red keyword in \"at your ﬁngertips\"\nin the sentence below:\n(. . . insert sentence. . . )\n(. . . free text response box. . . )\nTable 5: Format of the questions shown to participants\nvia the Qualtrics platform.\nianMT and an online translation tool were adapted\nto improve the recall of keywords for languages\nother than Dutch. Afterwards, postgraduate stu-\ndents from the local university were invited to an-\nnotate the data in exchange for payment, where one\nannotator annotated all 350 samples for a language.\nTo reduce the cognitive load of the experiment,\nonly sentences with ≤40 tokens were shown to\nthe participants. The annotators were native in the\ntarget language and ﬂuent in English, with the ex-\nception of the Swedish speaker, that was native in\nNorwegian and Finnish, and ﬂuent in Swedish and\nEnglish. The annotators participated in a similar\npre-screening test with language-speciﬁc explana-\ntions and examples, and seven practice questions.\nIf the annotators’ answers differed from what was\nexpected, the instructions were discussed with the\nannotator before they proceeded with the full sur-\nvey, and they ﬁlled out the remainder of the survey\nwithout intermediate help or instructions. Table 5\nshows an example question for Dutch.\nA.3 Ethical considerations\nThe surveys referred to in §3 were both approved\nthrough to the university’s research ethics process,\n3620\nwhere an independent committee assessed the setup\nof the survey, the research’s potential harmful im-\npacts and the compensation for the participants.\nIn collecting data annotations, participants were\nshown data from the MAGPIE corpus, available\nunder the CC-BY-4.0 License. All other informa-\ntion shown to them was either collected from the\ncomputational model, or written up by the authors.\nAny identiﬁable information about the participants\nwas stored separately from the participants’ anno-\ntations, for the purposes of compensation. Partic-\nipants were able to provide informed consent to\ndata collection and anonymised data being used in\nacademic publications. They were given the oppor-\ntunity to withdraw at any time. Participants were\ncompensated above the minimum hourly wage of\nthe country in which they were a resident at the\ntime of participating in the study.\nPIE Dutch paraphrase (literal backtranslation) Aligned tokens\nacross the board over hele linie ( over the whole line) board →linie\nbehind the scenes achter de schermen ( behind the screens) scenes →schermen\nbreak new ground nieuwe weg inslaan ( take a new road) ground →weg\nby heart uit het hoofd ( from the head) heart →hoofd\nby the same token op dezelfde manier ( in the same way) token →manier\ncome to mind in me opkomen ( come up in me) mind →me\ncome of age volwassen worden ( become an adult) age →volwassen\nface to face oog in oog ( eye in eye) face →oog\nfollow suit het voorbeeld volgen van ( follow the example of ) suit →voorbeeld\nfor good measure in goede mate* ( in good measure) measure →mate\nfrom scratch vanaf nul ( from zero) scratch →nul\nfrom the word go vanaf het begin ( from the start) word →begin\nget a move on schiet op ( hurry) move →schiet\nget the picture een completer beeld krijgen ( get a more complete vision) picture →beeld\nget to grips with (aan)pakken ( take on) grips →pakken\ngive someone the creeps kriebels krijgen ( getting tickles) creep →(krie)bel\nin broad daylight op klaarlichte dag ( on a luminous day) day(light) →dag\nin full swing in volle gang ( in full progress) sw(ing) →gang\nin the ﬂesh in levende lijve ( in the living body) ﬂesh →lij(ve)\nin the long run op de lange termijn ( on the long term) run →termijn\nin the short run op de korte termijn ( on the short term) run →termijn\nkeep a low proﬁle zich gedeisd houden ( to lay low) proﬁle →(gede)is(d)\noff the record onofﬁcieel ( unofﬁcial) record →(onofﬁci)eel\non someone’s mind iets aan je hoofd hebben ( have something on your head) mind →hoofd\nonce in a while af en toe ( on and off ) while →toe\nout of the blue uit het niets ( out of nothing) blue →niets\nout of the question uit de boze ( from the bad) question →boze\nset eyes on zien / zag ( see / saw) eyes →zag\nsmall print in de kleine lettertjes ( in the little letters) print →(letter)tjes\ntake a back seat op de achterbank ( on the back bench) seat →bank\ntake stock de balans opmaken ( make up the balance) stock →balans\nto all intents and purposes in alle opzichten ( in all aspects) intent →opzichten\nto boot opstarten ( to start) boot →(op)starten\nto the tune of voor het bedrag van ( for the amount of ) tune →bedrag\nwith a view to met het oog op ( with the eye on) view →oog\nTable 6: PIEs for which the word most commonly aligned to the keyword occurs > 20 times. Together, these\nkeywords determine 48% of all the alignments used to perform the cross-attention analysis for ﬁg-par in the\nEnglish-Dutch model. Subwords shown in brackets are due to the subtokens used in Marian-MT: eflomal aligns\nthe parts outside of the brackets to one another.\n⋆Example of a PIE for which the heuristic annotation missed out on a potential literal translation of ‘measure’.\nAppendix B Aligning PIEs and\nparaphrases\nWhen automatically aligning sentences with PIEs\nto translations that are labelled as a paraphrase\nby the heuristic, how does the automated aligner\n(the eflomal toolkit of Östling et al., 2016) handle\nparaphrases? For many PIEs (≤34% of the ﬁg-par\nsentences for all languages), the paraphrases do not\nhave a word in the translation aligned to the PIE\nkeyword on the source side using eflomal. These\nexamples are excluded. However, for a subset that\nappears more well-known, there are common para-\nphrases that the PIE keyword aligns to. We provide\nexamples for Dutch in Table 6. The examples pro-\nvided in the table together cover 48% of all aligned\nsentences used in the cross-attention analysis for\nthe ﬁg-par category, and all are reasonable align-\nments.\n3621\nAppendix C Attention for data subsets\nThe attention weight distributions in the main paper\nincluded all data. To further investigate whether the\ndifferences in attention patterns observed are due to\nfactors other than ﬁgurativeness, we recompute the\nattention patterns for three additional data subsets.\n1 2 3 4 5 6\nlayer\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6attention\nfig-par\nfig\nlit\nlit-wfw\n(a) PIE-PIE\n1 2 3 4 5 6\nlayer\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.150attention (b) PIE-context\n1 2 3 4 5 6\nlayer\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.150attention\n(c) Context-PIE\n0.00\n0.02\n0.04\n0.06\n0.08attention difference\npie-pie\npie-con con-pie\nnl\nde\nsv\nda\nfr\nit\nes (d) Language comparison\nFigure 9: Encoder self-attention distributions, illustrat-\ning attention within the PIE and the interaction between\nthe PIE and its context, for the identical data subset.\n1 2 3 4 5 6\nlayer\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0attention\n(a) Target - PIE noun\n1 2 3 4 5 6\nlayer\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6attention (b) Target - PIE other\n1 2 3 4 5 6\nlayer\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0attention\n(c) Target - </s>\n0.10\n0.05\n0.00\n0.05\n0.10\n0.15\nattention difference\npie-noun\npie-pie\npie-eos (d) Language comparison\nFigure 10: Cross-attention distributions from the trans-\nlation of one PIE noun on the target side to that noun\non the source side, for the identical data subset.\nPIE identical matches We ﬁrst use a subset that\nonly includes samples for which MAGPIE reports\nan identical match between the PIE and the En-\nglish sentence, that includes 17k samples. This\nsubset excludes sentences with modiﬁcations to the\ntypical surface form of a PIE, such as upper-cased\ntokens or insertions of a token into the PIE (e.g.\n“That gossip of a man spilled all of the beans.”).\nFigure 9 shows the three attention patterns pre-\nviously discussed for the encoder’s self-attention\n– i.e. attention from the PIE to the PIE, attention\nfrom the PIE to the context, and from the context\nto the PIE. Overall, the patterns resemble those\ndiscussed in the main text, apart from Figure 9a,\nwhere ﬁgurative instances do not display consis-\ntently higher attention weights compared to literal\ninstances, although the ﬁg-par subset does.\nThis procedure is repeated for the cross-attention\ndistributions. Figure 10 depicts the three patterns\ndiscussed in the main paper – i.e. from the aligned\ntarget-side tokens to the PIE noun, to another PIE\ntoken, and to </s> – for this data subset, providing\nthe same qualitative ﬁndings.\nIntersection of PIEs The second subset (re-\nferred to as intersection) considered is one that\nonly contains idioms that are among all of the sub-\nsets of ﬁgurative, literal, paraphrased and word for\nword instances, covering 11k examples from the\ndataset. The results for the encoder’s self-attention\n1 2 3 4 5 6\nlayer\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6attention\nfig-par\nfig\nlit\nlit-wfw\n(a) PIE-PIE\n1 2 3 4 5 6\nlayer\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.150attention (b) PIE-context\n1 2 3 4 5 6\nlayer\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.150attention\n(c) Context-PIE\n0.00\n0.02\n0.04\n0.06\n0.08attention difference\npie-pie\npie-con con-pie\nnl\nde\nsv\nda\nfr\nit\nes (d) Language comparison\nFigure 11: Encoder self-attention distributions, show-\ning attention within the PIE and the interaction between\nthe PIE and its context, for the intersection data subset.\n3622\n1 2 3 4 5 6\nlayer\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0attention\n(a) Target - PIE noun\n1 2 3 4 5 6\nlayer\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6attention (b) Target - PIE other\n1 2 3 4 5 6\nlayer\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0attention\n(c) Target - </s>\n0.10\n0.05\n0.00\n0.05\n0.10\n0.15\nattention difference\npie-noun\npie-pie pie-eos (d) Language comparison\nFigure 12: Cross-attention distributions from the trans-\nlation of one PIE noun on the target side to that noun\non the source side, for the intersection data subset.\npatterns are shown in Figure 11. Figure 12 sum-\nmarises the results for the cross-attention mecha-\nnisms. These results lead to the same qualitative\nﬁndings as mentioned in the main paper, and, in\nthe encoder, the PIE to PIE attention patterns for\nﬁgurative and literal PIEs are even more distinct.\nControlling PIE length To investigate the im-\npact of the length of a PIE and the length of its\ncontext on the results, we now report additional\nmeasures over sentences, namely:\n• the average number of MarianMT tokens\nlabelled as being part of the PIE (in MAGPIE\nwords like prepositions and determiners are\nnot counted as part of the PIE, so the annota-\ntion can be discontinuous);\n• the distance between the ﬁrst and the last\ntoken of the PIE (two tokens right next to\neach other have a distance of 1);\n• the relative position of the tokens that are\nannotated as belonging to the PIE, which im-\npacts the potential context size, but could also\nimpact how a PIE ‘behaves’;\n• the average distance of the ﬁrst position of\nthe PIE’s context tokens (PIE - 10) to the last\nposition (PIE + 10) (context length).\nFigure 13 summarises these statistics for the\nMAGPIE PIEs. The last two metrics are very stable\nacross categories, with an average relative position\nfig-par\nfig\nlit\nlit-wfw\n0\n1\n2\n3\n4\n5# PIE tokens\nfig-par\nfig\nlit\nlit-wfw\n0\n1\n2\n3\n4\n5PIE distance\nfig-par\nfig\nlit\nlit-wfw\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0relative PIE position\nfig-par\nfig\nlit\nlit-wfw\n0\n5\n10\n15\n20\n25context length\nFigure 13: Length statistics for the four categories of\nPIEs (ﬁg-par, lit-wfw, ﬁg, lit). Error bars indicate stan-\ndard deviations over sentences.\n1 2 3 4 5 6\nlayer\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6attention\nfig-par\nfig\nlit\nlit-wfw\n(a) PIE-PIE\n1 2 3 4 5 6\nlayer\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.150attention (b) PIE-context\n1 2 3 4 5 6\nlayer\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.150attention\n(c) Context-PIE\n0.00\n0.02\n0.04\n0.06\n0.08attention difference\npie-pie\npie-con con-pie\nnl\nde\nsv\nda\nfr\nit\nes (d) Language comparison\nFigure 14: Encoder self-attention distributions, show-\ning attention within the PIE and the interaction between\nthe PIE and its context, for the length controlled subset.\nof 0.57 for PIEs (0.58 for ﬁgurative, 0.56 for lit-\neral), and context lengths of 17.0 (17.0 for ﬁgura-\ntive, 17.1 for literal). The ﬁrst two metrics indicate\nthat ﬁgurative PIEs are a bit longer than literal PIEs\n(0.69 words), and that the distance between the ﬁrst\nand the last word is slightly larger (0.46 positions).\nTo assert that these differences do not substan-\ntially impact our qualitative ﬁndings, we compute\nthe attention analyses over a data subset that only\nuses sentences where there are three tokens an-\nnotated for the PIE, for which the start and end\nare three positions apart. This covers a subset of\napproximately 7k samples, with small variations\nbetween languages due to slightly different tokeni-\nsation of the English words. Figures 14 and 15\npresent the results for the encoder’s self-attention\nand the encoder-decoder cross-attention analyses,\nrespectively. Qualitatively, our ﬁndings for this\nsubset do not differ from the previous ﬁndings.\n3623\n1 2 3 4 5 6\nlayer\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0attention\n(a) Target - PIE noun\n1 2 3 4 5 6\nlayer\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6attention (b) Target - PIE other\n1 2 3 4 5 6\nlayer\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0attention\n(c) Target - </s>\n0.15\n0.10\n0.05\n0.00\n0.05\n0.10\n0.15\n0.20\nattention difference\npie-noun\npie-pie pie-eos (d) Language comparison\nFigure 15: Cross-attention distributions from the trans-\nlation of one PIE noun on the target side to that noun\non the source side, for the length controlled subset.\nAppendix D Results for 7 languages, per\nlayer\nFigures 16 and 17 present the results per layer, for\nthe (cross-)attention graphs from §4. Figure 18\npresent the results per layer, for the CCA similarity\ngraphs from §5.\n1 2 3 4 5 6\n0.00\n0.05\n0.10\n0.15attention difference\n>0 = more attention for fig-par\n(a) Attention from PIE tokens to PIE noun\n1 2 3 4 5 6\n0.015\n0.010\n0.005\n0.000\n0.005\nattention difference<0 = more attention for lit-wfw\n(b) Attention from PIE tokens to context\n1 2 3 4 5 6\n0.015\n0.010\n0.005\n0.000\n0.005\nattention difference\nnl\nde\nsv\nda\nfr\nit\nes\n(c) Attention from context to PIE\nFigure 16: The differences in attention between ﬁg-par\nand lit-wfw visualised per layer, per language.\n1 2 3 4 5 6\n0.4\n0.3\n0.2\n0.1\n0.0\nattention difference\n<0 = more attention for lit-wfw\n(a) Cross-attention from target PIE noun to source PIE noun\n1 2 3 4 5 6\n0.00\n0.02\n0.04\n0.06\n0.08attention difference\n(b) Cross-attention from target PIE noun to rest source PIE\n1 2 3 4 5 6\n0.0\n0.1\n0.2attention difference\n>0 = more attention for fig-par\nnl\nde\nsv\nda\nfr\nit\nes\n(c) Cross-attention from target PIE noun to </s>\nFigure 17: The differences in cross-attention between\nﬁg-par and lit-wfw visualised per layer, per language.\n1 2 3 4 5 6\n0.000\n0.005\n0.010\n0.015\n0.020\n0.025\n0.030difference in similarity\n>0 = more similar for lit-wfw\n(a) Impact on PIE tokens when masking PIE noun\n1 2 3 4 5 6\n0.003\n0.002\n0.001\n0.000\n0.001\n0.002\n0.003\ndifference in similarity\n(b) Impact on the context when masking PIE noun\n1 2 3 4 5 6\n0.005\n0.004\n0.003\n0.002\n0.001\n0.000\ndifference in similarity<0 = more similar for fig-par\n(c) Impact on the PIE token when masking in the context\n1 2 3 4 5 6\n0.003\n0.002\n0.001\n0.000\n0.001\n0.002\n0.003\ndifference in similarity\nnl\nde\nsv\nda\nfr\nit\nes\n(d) Impact on the context token when masking in the context\nFigure 18: The differences in CCA similarity between\nlit-wfw and ﬁg-par visualised per layer, per language.\nHere, “more similar” means that the impact of masking\nis smaller.\n3624\nAppendix E Two-step CCA\nCCA can be used to compare representations over\ndifferent layers of the same network or different\nnetworks in a way that is invariant to afﬁne trans-\nformations (Raghu et al., 2017). The CCA similar-\nity expresses the extent to which two representa-\ntions contain the same information while account-\ning for transformations in these two views of the\ndata. Nonetheless, the similarity depends on the\ndata used to perform CCA. Even with a dataset\nthat is at least an order of magnitude larger than\nthe number of dimensions in the hidden represen-\ntations, the composition of the dataset impacts the\noutcome. Particularly relevant in the context of\nour work is the vocabulary size that impacts CCA\ncomputations.\nWe illustrate this by measuring how hidden rep-\nresentations change over layers, randomly sam-\npling tokens and considering multiple dataset com-\npositions, varying from 64 occurrences of 80\nunique tokens, to 4 occurrences of 1280 unique\ntokens. Recomputing CCA per subset yields the\nsimilarities shown in Figure 19a. Although the\noverall pattern of lower similarity between lower\nlayers and higher similarity between higher layers\nis present for all subsets, the absolute similarity\nmeasures differ between subsets. In Figure 19b,\nhowever, where the projection matrix is computed\non a separate dataset, subsets show comparable\nsimilarities. The differences between the methods\ndecrease as the number of hidden representations\nused to perform CCA grows.\nPerforming CCA separately per (relatively\nsmall) subset of the MAGPIE corpus could thus re-\nﬂect vocabulary differences rather than systematic\ndifferences due to ﬁgurativeness. We merely want\nto apply CCA to account for differences between\nlayers and differences with and without masking\nattention, and thus apply two-step CCA, computing\nprojection matrices on a separate dataset.\n1-2 2-3 3-4 4-5 5-6\nlayers\n0.65\n0.70\n0.75\n0.80\n0.85CCA\n80 x 64\n160 x 32\n320 x 16\n640 x 8\n1280 x 4\n(a) CCA per subset\n1-2 2-3 3-4 4-5 5-6\nlayers\n0.76\n0.78\n0.80\n0.82\n0.84T wo-step CCA\n80 x 64\n160 x 32\n320 x 16\n640 x 8\n1280 x 4 (b) Two-step CCA\nFigure 19: Illustration of the impact of recomputing\nCCA with data subsets of differently composed vocab-\nularies for a dataset size of 5k.\nAppendix F Amnesic probing\nAmnesic probing (Elazar et al., 2021) evaluates\nthe behavioural inﬂuence of information recovered\nfrom hidden representations H by probes, by re-\nmoving that information from the representation\nand measuring the change in behaviour on the main\ntask. INLP, proposed by Ravfogel et al. (2020),\nis used to remove this information from the rep-\nresentations, by training kclassiﬁers to predict a\nproperty from input vectors. After training probe\ni, parametrised by Wi, the vectors are projected\nonto the nullspace of Wi, using projection matrix\nPN(Wi), such that WiPN(Wi)H = 0. The projec-\ntion matrix of the intersection of all knull spaces\ncan then remove features found by the kclassiﬁers.\nUsing INLP, we train50 classiﬁers to detect ﬁgu-\nrative, paraphrased PIEs from ﬁgurative PIEs trans-\nlated word for word from the hidden state. After-\nwards, we apply the projection matrices while the\nmodel processes previously paraphrased transla-\ntions. We separate the PIEs into ﬁve folds, using\none for parameter estimation. For every fold 3\n5 is\nused to train INLP’s probes,1\n5 is used to measure\nwhether the performance of the kprobes decreases\nand 1\n5 is used to measure the changed percentage.\nDependent on where one intervenes in the model,\namnesic probing may be more or less successful,\nsince not every layer encodes the linguistic prop-\nerty and higher layers could recover information\nremoved from lower layers (Elazar et al., 2021).\nThe parameter estimation performed measures the\nimpact of different combinations of layers as the\naverage success rate per PIE type (success means\nachieving a word-for-word translation). As shown\nin Figure 20, there is quite some variation among\nlanguages, but generally intervening in the lower\nlayers of Transformer is the most successful, and\nincluding the sixth layer is quite detrimental. The\nresults in the main body of the paper are computed\n0-2 1-3 2-4 3-5 4-6 0-3 1-4 2-5 3-6 0-4 1-5 2-6 0-5 1-6 0-6\nlayers affected\n0.1\n0.2\n0.3\n0.4avg. % per PIE\nda\nde\nfr\nsv\nnl\nes\nit\nFigure 20: Impact of the selection of layers affected by\nINLP. Dots represented different languages, the squares\nindicate the mean %.\n3625\nby intervening on the hidden states of PIE tokens\nin l∈{0,1,2,3,4}.\nAppendix G Idioms in OPUS\nTo understand whether the model’s translations re-\nﬂect target translations from its training corpus,\nwe extract up to 500 identical matches per idiom\nfrom OPUS for the En-Nl model. These target\ntranslations are labelled heuristically, resulting in\n54% of paraphrased instances, which is substan-\ntially higher than the percentage of paraphrased\ninstances in the model’s translations. This may be\nthe result of infrequent idioms contained in OPUS,\nfor which the model fails to learn the correct im-\nplicit meaning, even though the corpus does pro-\nvide paraphrases. Table 7 illustrates how the pre-\ndicted translations’ labels relate to the labels of\ntarget translations and provides BLEU scores per\nsubset. Samples with a paraphrased target transla-\ntion score substantially lower compared to those\nwith a word-for-word or copied target translation,\nemphasising the negative impact of idioms on trans-\nlation quality.\nOPUS Predicted Translations\nParaphrase Word for word\n(a) Translation type frequency (%)\nParaphrase 54 49 51\nWord for word 46 7 93\n(b) BLEU scores\nParaphrase 27.2 19.9\nWord for word 25.6 38.2\nTable 7: Distribution of translation labels for idiom oc-\ncurrences in OPUS, along with their BLEU scores.\n3626",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7646634578704834
    },
    {
      "name": "Literal and figurative language",
      "score": 0.7189710140228271
    },
    {
      "name": "Principle of compositionality",
      "score": 0.7165979743003845
    },
    {
      "name": "Transformer",
      "score": 0.7157411575317383
    },
    {
      "name": "Machine translation",
      "score": 0.6650618314743042
    },
    {
      "name": "Literal translation",
      "score": 0.6312005519866943
    },
    {
      "name": "Natural language processing",
      "score": 0.6207296252250671
    },
    {
      "name": "Artificial intelligence",
      "score": 0.548143744468689
    },
    {
      "name": "Literal (mathematical logic)",
      "score": 0.5476025342941284
    },
    {
      "name": "Linguistics",
      "score": 0.4185864329338074
    },
    {
      "name": "Source text",
      "score": 0.25848719477653503
    },
    {
      "name": "Programming language",
      "score": 0.11158502101898193
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ]
}