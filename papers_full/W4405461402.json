{
  "title": "Large language models display human-like social desirability biases in Big Five personality surveys",
  "url": "https://openalex.org/W4405461402",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2999273555",
      "name": "Aadesh Salecha",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A3003402943",
      "name": "Molly E. Ireland",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4287857319",
      "name": "Shashanka Subrahmanya",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2554339368",
      "name": "João Sedoc",
      "affiliations": [
        "New York University"
      ]
    },
    {
      "id": "https://openalex.org/A2147282416",
      "name": "Lyle H. Ungar",
      "affiliations": [
        "University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A2056407401",
      "name": "Johannes C Eichstaedt",
      "affiliations": [
        "Stanford University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4283026156",
    "https://openalex.org/W4321455981",
    "https://openalex.org/W4376117416",
    "https://openalex.org/W3161812535",
    "https://openalex.org/W2089632658",
    "https://openalex.org/W4392028279",
    "https://openalex.org/W4383175795",
    "https://openalex.org/W2075902832",
    "https://openalex.org/W4318919287",
    "https://openalex.org/W4389669106",
    "https://openalex.org/W2018300483",
    "https://openalex.org/W3118229828",
    "https://openalex.org/W3165746404",
    "https://openalex.org/W2024509488"
  ],
  "abstract": "Abstract Large language models (LLMs) are becoming more widely used to simulate human participants and so understanding their biases is important. We developed an experimental framework using Big Five personality surveys and uncovered a previously undetected social desirability bias in a wide range of LLMs. By systematically varying the number of questions LLMs were exposed to, we demonstrate their ability to infer when they are being evaluated. When personality evaluation is inferred, LLMs skew their scores towards the desirable ends of trait dimensions (i.e. increased extraversion, decreased neuroticism, etc.). This bias exists in all tested models, including GPT-4/3.5, Claude 3, Llama 3, and PaLM-2. Bias levels appear to increase in more recent models, with GPT-4’s survey responses changing by 1.20 (human) SD and Llama 3’s by 0.98 SD, which are very large effects. This bias remains after question order randomization and paraphrasing. Reverse coding the questions decreases bias levels but does not eliminate them, suggesting that this effect cannot be attributed to acquiescence bias. Our findings reveal an emergent social desirability bias and suggest constraints on profiling LLMs with psychometric tests and on this use of LLMs as proxies for human participants.",
  "full_text": null,
  "topic": "Extraversion and introversion",
  "concepts": [
    {
      "name": "Extraversion and introversion",
      "score": 0.6924892663955688
    },
    {
      "name": "Psychology",
      "score": 0.597620964050293
    },
    {
      "name": "Neuroticism",
      "score": 0.5914798974990845
    },
    {
      "name": "Personality",
      "score": 0.5875192880630493
    },
    {
      "name": "Social psychology",
      "score": 0.5451088547706604
    },
    {
      "name": "Trait",
      "score": 0.4911753833293915
    },
    {
      "name": "Big Five personality traits",
      "score": 0.41367214918136597
    },
    {
      "name": "Computer science",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    }
  ]
}