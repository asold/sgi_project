{
    "title": "Privacy preserving strategies for electronic health records in the era of large language models",
    "url": "https://openalex.org/W4406465563",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2132490811",
            "name": "Jitendra Jonnagaddala",
            "affiliations": [
                "Shaikh Khalifa Medical City",
                "UNSW Sydney"
            ]
        },
        {
            "id": "https://openalex.org/A4226849657",
            "name": "Zoie Shui-Yee Wong",
            "affiliations": [
                "St. Luke's International University",
                "University of Hong Kong",
                "University of Sydney",
                "UNSW Sydney"
            ]
        },
        {
            "id": "https://openalex.org/A2132490811",
            "name": "Jitendra Jonnagaddala",
            "affiliations": [
                "Shaikh Khalifa Medical City",
                "UNSW Sydney"
            ]
        },
        {
            "id": "https://openalex.org/A4226849657",
            "name": "Zoie Shui-Yee Wong",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4404556367",
        "https://openalex.org/W4389377916",
        "https://openalex.org/W107524893",
        "https://openalex.org/W2898415172",
        "https://openalex.org/W4383346782",
        "https://openalex.org/W4300035993",
        "https://openalex.org/W4392557826",
        "https://openalex.org/W4296687378",
        "https://openalex.org/W4396929025",
        "https://openalex.org/W3204796902",
        "https://openalex.org/W4401820676",
        "https://openalex.org/W4402713323",
        "https://openalex.org/W4402943216",
        "https://openalex.org/W4304190143"
    ],
    "abstract": null,
    "full_text": "npj |digital medicine Comment\nPublished in partnership with Seoul National University Bundang Hospital\nhttps://doi.org/10.1038/s41746-025-01429-0\nPrivacy preserving strategies for electronic\nhealth records in the era of large language\nmodels\nJitendra Jonnagaddala & Zoie Shui-Yee Wong\n Check for updates\nElectronic health records (EHRs) secondary usage\nwith large language models (LLMs) raise privacy\nchallenges. National regulations like GDPR and\nHIPAA offer protection frameworks, but speciﬁc\nstrategies are needed to mitigate risk in generative\nAI. Risks can be reduced by using strategies\nlike privacy-preserving locally deployed LLMs,\nsynthetic data generation, differential privacy, and\ndeidentiﬁcation. Depending on the task, strategies\nshould be employed to increase compliance with\npatient privacy regulatory frameworks.\nThe secondary use of electronic health records (EHRs) involves the utili-\nzation of EHR data for various purposes other than their original intent in\nclinical operations, such as clinical research, health systems and services\nresearch, patient registries, quality improvement, disease surveillance, and\nother areas beyond direct patient care\n1. This secondary use of electronic\nhealth records (EHRs) has signiﬁcantly accelerated in the past decade with\nadvances in artiﬁcial intelligence (AI), especially in large language models\n(LLMs)2. EHRs are increasingly used with LLMs for primary uses, such as\nclinical documentation, generation and summarization, as well as for sec-\nondary uses, such as information extraction, retrieval, identiﬁcation of eli-\ngible patients for research, medical education, and outcome reporting.\nSafeguarding both the structured andunstructured sensitive health infor-\nm a t i o n( S H I )o fp a t i e n t sf r o mE H R si se s s e n t i a l ,p a r t i c u l a r l yw h e nL L M sa r e\nused for secondary uses\n3,4. Most countries across the world have stipulated\nregulatory privacy acts, guidelinesand frameworks to achieve this goal.\nThe Health Insurance Portabilityand Accountability Act (HIPAA)\nfrom the United States of America provides guidelines for preserving\npatients’ SHI5. Similarly, in Australia, the Privacy Act of 1988 acted as a\ncounterpart of the HIPAA by providing guidelines and a framework. The\nGeneral Data Protection Regulation (GDPR) provides a framework of laws\nand regulations for the collection and use of the SHI of individuals living in\nthe European Union\n6.I nJ a p a n ,t h eA c to nt h eP r o t e c t i o no fP e r s o n a l\nInformation (APPI)7 sets a legal framework for protecting individual priv-\nacy and personal information, sharing similarities with the data protection\nprinciples of the GDPR. Serving as one of the early data protection laws in\nAsia, the Personal Data (Privacy) Ordinance from Hong Kong applies to\nmaintain and protect patient privacy in the Hong Kong\n8.M o s to ft h e s e\nregulatory frameworks have several commonalities but also differ in certain\naspects. For example, the deﬁnition of SHI and what constitutes SHI vary.\nAdditionally, most of these regulations do not distinguish between\nstructured and unstructured EHR data. This differentiation is important\nbecause structured EHR data is relatively easy to process compared with\nunstructured EHR data, which requires robust information extraction\nmethods and is often not 100% accurate. This difference in complexity\nbetween structured and unstructured data can impact downstream tasks,\nincluding compliance with privacy regulations.\nThese privacy regulations were developed primarily to provide com-\nprehensive requirements and guidelines for securely storing and handling\nSHI. While some regulations, such asthe GDPR, encompass a wide range of\ndata protection principles beyond health data, they also establish speciﬁc\nframeworks for safeguarding SHI and ensuring that it is appropriately\nredacted before public disclosure. These regulations highlight the impor-\ntance of well-designed statistical analysis to protect and maintain privacy.\nThis involves the use of large sample sizes to ensure that the results of\nresearch are meaningful while minimizing the reidentiﬁcation risk to\nindividuals. Most privacy regulations prohibit data sharing involving fewer\nthan ﬁve individuals to reduce the likelihood of reidentiﬁcation. Even in the\nabsence of direct identiﬁers, an individual can sometimes be recognized\nt h r o u g ht h ec o m b i n a t i o no fd a t ap o i n t ss u c ha sd a t e s ,d i a g n o s e s ,a n d\ntreatments, which can increase the risk of reidentiﬁcation.\nEven when adhering to these guidelines, there are still chances of\nunique reidentiﬁcation and group reidentiﬁcation leading to privacy risks.\nUnique reidentiﬁcation occurs when a record in the dataset matches exactly\nwith an identiﬁed individual, whereas group reidentiﬁcation occurs when\none or a few records in the dataset correspond to a small group of identiﬁed\nindividuals\n9. There are instances where identity recovery algorithms applied\nto deidentiﬁed data may be able to retrieve one-to-one, one-to-few and few-\nto-few identities10.\nPrivacy-preserving strategies\nWe summarize a series of privacy-preserving strategies that can be applied\n(Fig. 1). LLMs are frequently employed by clinicians, researchers and edu-\ncators for various purposes, such as documentation, guideline retrieval and\nsummarization and clinical decision support. Regarding adhering to privacy\nregulations and guidelines, the application of LLMs to both structured and\nunstructured EHR data is still in the early phases of development\n11,12.\nNotably, LLMs are often used to extract structured data from unstructured\ninputs, emphasizing their wide-ranging utility. Different technical approa-\nches can be employed to achieve compliance and preserve privacy,\ndepending on the task for which the LLM is used.\nTo reduce the risk in structured EHR data, differential privacy (DP) can\nbe implemented before feeding the input to LLMs. DP can be deﬁned as the\ninability to distinguish between two output probability distributions\n13.\nSuppose we have two databases of SHI that differ by only one patient. DP\nensures that, even with access to one of the databases, it is not possible to\nidentify the differing patient with certainty. This uncertainty is achieved by\nnpj Digital Medicine|            (2025) 8:34 1\n1234567890():,;\n1234567890():,;\nintroducing calibrated noise into the database query results, often using\nLaplace mechanism. Sophisticated deidentiﬁcation solutions such as poly-\nmorphic encryption can also be employed to deidentify structured SHI\nwhile maintaining its usefulness for analytical purposes, which keeps the\ndata secure and reduces the risk of reidentiﬁcation. Some studies suggest the\nuse of Federated Learning (FL) to increase model performance while\nensuring data privacy\n14. FL is a decentralized approach that enables multiple\norganizations to train AI models collaboratively without sharing their raw\ndata. By leveraging enormous volumes of data from many healthcare set-\ntings and maintaining data localization, this approach mitigates privacy\nconcerns and risks. DP, deidentiﬁcation, and FL are some of the techniques\nthat are frequently applied to structured SHI data, but these techniques can\nalso be applied to unstructured data.\nBoth structured and unstructuredE H Rd a t ao f t e nc a p t u r ea n ds u m -\nmarize SHI over different time points of disease progression, which are\nunique to patients. To reduce risk, stringent deidentiﬁcation standards and\nrobust measures must be adopted. One such example is through the dei-\ndentiﬁcation and surrogation of the SHI. Deidentiﬁcation has received\nmuch attention around the globe, and with improvements in LLM tech-\nniques, the accuracy of correctly identifying and removing personal iden-\ntiﬁers while maintaining the data’s utility for analysis and research has\nsigniﬁcantly increased\n15. Liu, J., et al. 2023 presented a hybrid deidentiﬁ-\ncation pipeline for unstructured pathology reports16,17, which incorporates\nboth rule-based techniques and transformer models. The pipeline proved to\nbe efﬁcient in identifying SHI with an accuracy of 95%. Once the SHI is\nidentiﬁed, the reports can be deidentiﬁed by removing or surrogating the\nidentiﬁers. Additionally, earlier versions of this pipeline have been deployed\nin an Australian hospital3.F u r t h e r m o r e ,t h ed e i d e n t iﬁed SHI can be further\nsurrogated before being input into the LLMs. Surrogation maintains the\nsyntactic and synoptic representations of the data\n18. Surrogate generation\ninvolves generating placeholder data that mimic the statistical properties of\nthe original data without compromising individual privacy. This process of\nreplacement with placeholders allows the deidentiﬁed data, whether\nunstructured or structured, to preserve the integrity of the data’s structure\nand meaning. For example, a name [Mr. John Doe] is identiﬁed and\nanonymized as [Patient Name: (REDACTED)] followed by replacement\nwith a surrogated name [Patient Name: Andy Ray]. However, this may have\nan impact on data utility. The impact depends on the level of granularity\nrequired in the analysis and the type of downstream task. For types of\nanalyses, where identiﬁers are not crucial, the impact is minimal. However,\nfor analyses that focus on speciﬁci d e n t iﬁers such as locations and time\nperiods, surrogation has a great impact on data utility. In such cases, other\ntechniques, such as DP can be employed. As the techniques employed are\nsubject to various performance and methodological limitations, it is\nimportant to carefully balance the trade-offs between maintaining data\nprivacy and utility. Appropriate strategies should be employed based on the\ncontext (Fig.1). While less aggressive methods can preserve data utility, they\nmay also result in an increased risk of reidentiﬁcation.\nStudies have assessed the feasibility of employing lightweight, open,\nand ofﬂine LLM locally in secure environments to overcome some of the\nprivacy concerns associated with using third-party LLM\n19– 21. This strategy\ncan be employed for both structured and unstructured data. Local\ndeployment of LLM might also be computationally limited and resource\nintensive with the increasing number of EHRs captured. To address these\nlimitations, one approach is to uselightweight locally deployed LLM or\ntraditional rule-based and machine learning models to deidentify and\ngenerate surrogates before passing the information to proprietary or third-\nparty LLMs. Another approach is to use synthetic data toﬁne-tune, pretrain\nor assess LLM performance on certain tasks. However, this also introduces\nthe risk of misinformation and hallucinations. It is important to recognize\nthat these approaches apply to both primary and secondary uses of\nEHR data.\nWithout proper security measures, whether the LLM is used in the\ncloud or locally, data breaches are possible, which can have long-term\nconsequences. For example, a recent Australian data breach at MediSecure,\nan Australian prescription delivery service company, occurred in April\n2024, exposing private and health-related information on the dark web\n22.\nConsequently, organizations need to employ several strategies to reduce the\nrisk of reidentiﬁcation in the context of these data leaks, wherein the leaked\ninformation can be used to reidentify patients in other datasets4.\nEmploying these strategies can become complex, especially for patients\nwho interact frequently with the health system. This also urges the identi-\nﬁcation and generation of surrogates without losing temporal information.\nH o w e v e r ,t h e r ei sa l w a y sat r a de-off between risks and beneﬁts and context,\nsuch as sharing data publicly on the internet or through secure research\nenvironments. Depending on the type of SHI, whether structured,\nunstructured, or a combination of both, and the type of LLM employed,\nwhether open or closed, and cloud-based or on-premises deployments, the\nassociated risks might vary from minimal to concerning. To achieve the best\noutcomes, most of these strategies must be combined in the context of\nregulations and organizational policies. In addition, it is also important to\nunderstand the theoretical and practical limitations of various privacy-\npreserving techniques. As such, a context-aware approach that factors in the\nspeciﬁc LLM tasks, the data type being processed, and the computational\ninfrastructure is required to mitigatethe privacy risks associated with LLMs.\nFor example, tasks such as identifying patients of interest for clinical\nresearch involving the secondary use of unstructured EHRs require more\nrobust privacy strategies and appropriate computational infrastructure than\nthe use of structured data for the primary purpose of providing care. Fur-\nthermore, governance structures should include regular quality improve-\nment plans to assess the effectiveness of deidentiﬁcation methods as AI\ntechnology continues to evolve. Although we focused primarily on routinely\ncollected EHR data in both unstructured and structured formats, the stra-\ntegies and techniques discussed here can also be applied to other modalities,\nsuch as imaging and omics data.\nPrivacy regula/g415ons and acts\nOrganiza/g415onal policies\nContext-aware strategies\nDeiden/g415ﬁca/g415on\nFederated \nLearning\nSurrogate \nGenera/g415on\nDiﬀeren/g415al \nPrivacy\nSynthe/g415c Data \nGenera/g415on\nLLM task, data type and computa/g415onal infrastructure \nFig. 1 | Context-aware privacy preserving strategies for secondary usage of EHRs.\nThe ﬁgure summarizes how organizations can manage and address privacy issues\nthrough integrating regulatory compliance, developing policies and context-aware\ntechnical strategies to safeguard sensitive data and maintain privacy when using\nEHRs with LLMs. Strategies such as deidentiﬁcation, surrogate generation, federated\nlearning, and differential privacy need to be applied based on the LLM tasks, data\ntypes, and computational infrastructure.\nnpj |digital medicine Comment\nnpj Digital Medicine|            (2025) 8:34 2\nConclusion\nLLMs are frequently employed by clinicians, researchers, and educators for\nvarious purposes. However, the regulatory frameworks and guidelines for\nmanaging privacy while using structured and unstructured EHR data with\nLLMs are still in the early stages and require timely reforms to address\nevolving data modalities and applications of LLMs. Unique or group rei-\ndentiﬁcation risks are associated with the use of LLMs. From the perspective\nof data custodians and users, identifying and understanding the risks\nassociated with LLMs, followed by employing appropriate strategies and\ngovernance frameworks within organizations, can not only reduce privacy\nrisks but also provide an opportunity to address uncertainties.\nData availability\nNo datasets were generated or analysed during the current study.\nJitendra Jonnagaddala1,2,3 & Zoie Shui-Yee Wong4,5,6,7\n1School of Population Health, UNSW Sydney, Kensington, NSW, Australia.\n2NMC Royal Hospital, Khalifa City, Abu Dhabi, United Arab Emirates.\n3SREDH Consortium, Sydney, NSW, Australia.4Graduate School of Public\nHealth, St. Luke’s International University, Tokyo, Japan.5The Kirby\nInstitute, UNSW Sydney, Kensington, NSW, Australia.6School of Medical\nSciences, The University of Sydney, Sydney, NSW, Australia.7School of\nPublic Health, The University of Hong Kong, Hong Kong, China.\ne-mail: jitendra.jonnagaddala@unsw.edu.au\nReceived: 28 October 2024; Accepted: 2 January 2025;\nReferences\n1. Seymour, T., Frantsvog, D. & Graeber, T. Electronic health records (EHR).Am. J. Health Sci.3,\n201 (2012).\n2. Christian Rose, J. H. C. Learning from the EHR to implement AI in healthcare.npj digital\nmedicine 7, https://doi.org/10.1038/s41746-024-01340-0 (2024).\n3. Liu, J. et al. OpenDeID pipeline for unstructured electronic health record text notes based on\nrules and transformers: deidentiﬁcation algorithm development and validation study.J. Med.\nInternet Res.25, e48145 (2023).\n4. Basil, N. N., Ambe, S., Ekhator, C. & Fonkem, E. Health records database and inherent security\nconcerns: a review of the literature.Cureus 14, e30168 (2022).\n5. America, U. S. o.Health insurance portability and accountability act of 1996. Public Law\n104–191, 1996).\n6. Union, E. General data protection regulation (GDPR), https://gdpr-info.eu (2016).\n7. Japan, G. o. Act on the protection of personal information, Act No. 57 of 2003, https://www.\njapaneselawtranslation.go.jp/en/laws/view/4241/en (2023).\n8. Government, D. o. J. o. t. H. K.Personal Data (Privacy) Ordinance, Chapter 486 of the Laws of\nHong Kong (PDPO), http://www.hklii.org.hk/hk/legis/ord/486/index.html (1994).\n9. Sweeney, L. et al. Re-identiﬁcation risks in HIPAA safe harbor data: a study of data from one\nenvironmental health study.Technol. Sci.2017, 2017082801 (2017).\n10. The Ofﬁce of the Victorian Information Commissioner. The Limitations of De-Identiﬁcation\nProtecting Unit-Record Level Personal Information.https://ovic.vic.gov.au/privacy/resources-\nfororganisations/the-limitations-of-de-identiﬁcation-protecting-unit-record-level-personal-\ninformation/ (2018).\n11. Meskó, B. & Topol, E. J. The imperative for regulatory oversight of large language models (or\ngenerative AI) in healthcare.npj Digit. Med.6, 120 (2023).\n12. Raza, M. M., Venkatesh, K. P. & Kvedar, J. C. Generative AI and large language models in health\ncare: pathways to implementation.npj Digit. Med.7, 62 (2024).\n13. Siqi Zhang, X. L. Differential privacy medical data publishing method based on attribute\ncorrelation. Sci. Rep.https://doi.org/10.1038/s41598-022-19544-3 (2022).\n14. Peng, L. et al. An in-depth evaluation of federated learning on biomedical natural language\nprocessing for information extraction.NPJ Digit. Med.7, 127 (2024).\n15. Jonnagaddala, J., Dai, H. J. & Chen, C. T.Large language models for automatic deidentiﬁcation\nof electronic health record notes. 1 edn, Vol. 2148 (Springer Nature, 2025).\n16. Jonnagaddala, J., Chen, A., Batongbacal, S. & Nekkantti, C. The OpenDeID corpus for patient\nde-identiﬁcation. Sci. Rep.11, 19973 (2021).\n17. Gupta, S., Liu, J., Wong, Z. S. & Jonnagaddala, J. Preliminary evaluation ofﬁne-tuning the\nOpenDeLD deidentiﬁcation pipeline across multi-center corpora.Stud. Health Technol. Inf.\n316, 719– 723 (2024).\n18. Chen, A., Jonnagaddala, J., Nekkantti, C. & Liaw, S. T. Generation of surrogates for de-\nidentiﬁcation of electronic health records.Stud. Health Technol. Inf.264,7 0– 73 (2019).\n19. Tai, I. C. Y. et al. Exploring ofﬂine large language models for clinical information extraction: a\nstudy of renal histopathological reports of lupus nephritis patients.Stud. Health Technol. Inf.\n316, 899– 903 (2024).\n20. Wiest, I. C. et al. Privacy-preserving large language models for structured medical information\nretrieval. npj Digit. Med.7, 257 (2024).\n21. Chua, C. E. et al. Integration of customised LLM for discharge summary generation in real-world\nclinical settings: a pilot study on RUSSELL GPT.Lancet Reg. Health– West. Pac.51, https://doi.\norg/10.1016/j.lanwpc.2024.101211 (2024).\n22. InSight. MediSecure breach: implications for health care services and patients, https://\ninsightplus.mja.com.au/2024/37/medisecure-breach-implications-for-health-care-services-\nand-patients/ (2024).\nAcknowledgements\nJ.J. was funded by the Australian National Health and Medical Research Council (grant GNT1192469).\nJ.J. also acknowledges the funding support received through the Research Technology Services at\nthe University of New South Wales Sydney, Google Cloud Research (award GCP19980904), and\nNVIDIA Academic Hardware grant programs.\nAuthor contributions\nJ.J. and Z.S.Y.W. were responsible for conceptualizing the initial concept for this manuscript. Both\nanalyzed the literature; J.J. was responsible for drafting and revising the manuscript. Z.S.Y.W.\nprovided critical intellectual input and revisions. Both authors approved the manuscript.\nCompeting interests\nJ.J. and Z.S.Y.W. are both Guest Editors of Collection on Natural Language Processing of npj Digital\nMedicine. Z.S.Y.W. is also serving the npj Digital Medicine as an Associate Editor.\nAdditional information\nCorrespondenceand requests for materials should be addressed to Jitendra Jonnagaddala.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’sn o t eSpringer Nature remains neutral with regard to jurisdictional claims in published maps\nand institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons Attribution-NonCommercial-\nNoDerivatives 4.0 International License, which permits any non-commercial use, sharing,\ndistribution and reproduction in any medium or format, as long as you give appropriate credit to the\noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if you\nmodiﬁed the licensed material. You do not have permission under this licence to share adapted\nmaterial derived from this article or parts of it. The images or other third party material in this article\nare included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to\nthe material. If material is not included in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain\npermission directly from the copyright holder. To view a copy of this licence, visithttp://\ncreativecommons.org/licenses/by-nc-nd/4.0/\n.\n© The Author(s) 2025\nnpj |digital medicine Comment\nnpj Digital Medicine|            (2025) 8:34 3"
}