{
    "title": "OLaLa: Ontology Matching with Large Language Models",
    "url": "https://openalex.org/W4388514671",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A4225421027",
            "name": "Hertling, Sven",
            "affiliations": [
                "University of Mannheim"
            ]
        },
        {
            "id": "https://openalex.org/A4222248107",
            "name": "Paulheim, Heiko",
            "affiliations": [
                "University of Mannheim"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4283819412",
        "https://openalex.org/W4280604898",
        "https://openalex.org/W3029729116",
        "https://openalex.org/W4379280444",
        "https://openalex.org/W4225319360",
        "https://openalex.org/W3014705052",
        "https://openalex.org/W3164540570",
        "https://openalex.org/W4385474419",
        "https://openalex.org/W4386043360",
        "https://openalex.org/W4385848430",
        "https://openalex.org/W4379280509",
        "https://openalex.org/W6811009250",
        "https://openalex.org/W3121986036",
        "https://openalex.org/W4226099034",
        "https://openalex.org/W3123375411",
        "https://openalex.org/W2970641574",
        "https://openalex.org/W2615447451"
    ],
    "abstract": "Ontology (and more generally: Knowledge Graph) Matching is a challenging task\\nwhere information in natural language is one of the most important signals to\\nprocess. With the rise of Large Language Models, it is possible to incorporate\\nthis knowledge in a better way into the matching pipeline. A number of\\ndecisions still need to be taken, e.g., how to generate a prompt that is useful\\nto the model, how information in the KG can be formulated in prompts, which\\nLarge Language Model to choose, how to provide existing correspondences to the\\nmodel, how to generate candidates, etc. In this paper, we present a prototype\\nthat explores these questions by applying zero-shot and few-shot prompting with\\nmultiple open Large Language Models to different tasks of the Ontology\\nAlignment Evaluation Initiative (OAEI). We show that with only a handful of\\nexamples and a well-designed prompt, it is possible to achieve results that are\\nen par with supervised matching systems which use a much larger portion of the\\nground truth.\\n",
    "full_text": null
}