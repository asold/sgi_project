{
    "title": "Classification of Fake News by Fine-tuning Deep Bidirectional Transformers based Language Model",
    "url": "https://openalex.org/W3015935667",
    "year": 2018,
    "authors": [
        {
            "id": "https://openalex.org/A1976624019",
            "name": "Akshay Aggarwal",
            "affiliations": [
                "Bharati Vidyapeeth Deemed University"
            ]
        },
        {
            "id": "https://openalex.org/A3037286287",
            "name": "Aniruddha Chauhan",
            "affiliations": [
                "Bharati Vidyapeeth Deemed University"
            ]
        },
        {
            "id": "https://openalex.org/A2399348933",
            "name": "Deepika Kumar",
            "affiliations": [
                "Bharati Vidyapeeth Deemed University"
            ]
        },
        {
            "id": "https://openalex.org/A2482475581",
            "name": "Mamta Mittal",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2187470045",
            "name": "Sharad Verma",
            "affiliations": [
                "Bharati Vidyapeeth Deemed University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6733079832",
        "https://openalex.org/W2163605009",
        "https://openalex.org/W6666761814",
        "https://openalex.org/W2997781171",
        "https://openalex.org/W2998205609",
        "https://openalex.org/W2917942747",
        "https://openalex.org/W2117539524",
        "https://openalex.org/W2149933564",
        "https://openalex.org/W2900945483",
        "https://openalex.org/W6754002923",
        "https://openalex.org/W2790409743",
        "https://openalex.org/W2982026428",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W6671933157",
        "https://openalex.org/W2274328556",
        "https://openalex.org/W1990563855",
        "https://openalex.org/W2036879158",
        "https://openalex.org/W2035896792",
        "https://openalex.org/W6684228523",
        "https://openalex.org/W6736575291",
        "https://openalex.org/W2065290828",
        "https://openalex.org/W2516338333",
        "https://openalex.org/W7020404858",
        "https://openalex.org/W2161283199",
        "https://openalex.org/W115470646",
        "https://openalex.org/W6632973184",
        "https://openalex.org/W2808228212",
        "https://openalex.org/W2759820691",
        "https://openalex.org/W2740560510",
        "https://openalex.org/W2903981179",
        "https://openalex.org/W6732648842",
        "https://openalex.org/W2742144412",
        "https://openalex.org/W2949397667",
        "https://openalex.org/W621249151",
        "https://openalex.org/W1566289585",
        "https://openalex.org/W6648914341",
        "https://openalex.org/W6910681941",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W4300952844",
        "https://openalex.org/W1614298861",
        "https://openalex.org/W2489406233",
        "https://openalex.org/W2163220194",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2962739339",
        "https://openalex.org/W2963961878",
        "https://openalex.org/W4299518610",
        "https://openalex.org/W4293355737",
        "https://openalex.org/W4297782361",
        "https://openalex.org/W1522301498",
        "https://openalex.org/W2891453035",
        "https://openalex.org/W4293926355",
        "https://openalex.org/W2582561810",
        "https://openalex.org/W2086677051",
        "https://openalex.org/W4241214831",
        "https://openalex.org/W2899204128",
        "https://openalex.org/W2295598076",
        "https://openalex.org/W1994616650",
        "https://openalex.org/W2963026768",
        "https://openalex.org/W2577716227",
        "https://openalex.org/W2887280559",
        "https://openalex.org/W2525778437",
        "https://openalex.org/W2084591134",
        "https://openalex.org/W1551104980"
    ],
    "abstract": "With the ever-increasing rate of information dissemination and absorption, “Fake News” has become a real menace. Peoplethese days often fall prey to fake news that is in line with their perception. Checking the authenticity of news articlesmanually is a time-consuming and laborious task, thus, giving rise to the requirement for automated computational tools thatcan provide insights about degree of fake ness for news articles. In this paper, a Natural Language Processing (NLP) basedmechanism is proposed to combat this challenge of classifying news articles as either fake or real. Transfer learning on theBidirectional Encoder Representations from Transformers (BERT) language model has been applied for this task. This paperdemonstrates how even with minimal text pre-processing, the fine-tuned BERT model is robust enough to performsignificantly well on the downstream task of classification of news articles. In addition, LSTM and Gradient Boosted Treemodels have been built to perform the task and comparative results are provided for all three models. Fine-tuned BERTmodel could achieve an accuracy of 97.021% on NewsFN data and is able to outperform the other two models byapproximately eight percent.",
    "full_text": "EAI Endorsed Transactions  \non Scalable Information Systems  Research Article \n1 \nClassification of Fake News by Fine-tuning Deep \nBidirectional Transformers based Language Model \nAkshay Aggarwal1, Aniruddha Chauhan1, Deepika Kumar1*, Mamta Mittal2, Sharad Verma1 \n1Department of Computer Science & Engineering, Bharati Vidyapeeth’s College of Engineering, New Delhi-110063 \n2Department of Computer Science & Engineering, G. B. Government Engineering College, New Delhi-110020 \nAbstract \nWith the ever-increasing rate of information dissemination and absorption, “Fake News” has become a real menace. People \nthese days often fall prey to fake news that is in line with their perception. Checking the authenticity of news articles \nmanually is a time-consuming and laborious task, thus, giving rise to the requirement for automated computational tools that \ncan provide insights about degree of fake  ness for news articles. In this paper, a Natural Language Processing (NLP) based \nmechanism is proposed to combat this challenge of classifying news articles as either  fake or real. Transfer learning on the \nBidirectional Encoder Representations from Transformers (BERT) language model has been applied for this task. This paper \ndemonstrates how even with minimal text pre-processing, the fine -tuned BERT model is robust eno ugh to perform \nsignificantly well on the downstream task of classification of news articles. In addition, LSTM and Gradient Boosted Tree \nmodels have been built to perform the task and comparative results are provided for all three models. Fine -tuned BERT \nmodel could achieve an accuracy of 97.021% on NewsFN data and is able to outperform the other two models by \napproximately eight percent. \nKeywords: Fake news, Transfer learning, Deep learning, Natural language processing. \nReceived on 21 January 2020, accepted on 30 March 2020, published on 09 April 2020\nCopyright © \n2020 Akshay Aggarwal  et al., licensed to EAI. This is an open access article distributed under the terms of \nthe Creative Commons Attribution licence (http://creativecommons.org/licenses/by/3.0/), which permits unlimited use, \ndistribution and reproduction in any medium so long as the original work is properly cited. \ndoi: 10.4108/eai.13-7-2018.163973\n1. Introduction\nThe veracity and trustworthiness of news is a crucial issue \nof the modern world. In last few years, dispersion of “fake \nnews” over the internet has increased manifold, hence \nincreasing the need for methods to combat it. Fake news \ncan be termed as “news art icles that are intentionally and \nverifiably false”. Just to get a hint about how impactful fake \nnews is one can look at, many articles that have \ndemonstrated how impactful fake news was in the 2016 \npresidential elections held in the United States [1]. A \nsituation where people don’t completely trust their news \nsources has been created due to promulgation of fake news, \nas per the Gallup polls [2], only thirty -two percent of \nAmericans trust their news sources to be fully accurate and \nfair. In few cases, even t he reputed newspapers are \nsometimes found unreliable as per a study in the UK [3]. \nTwo major psychological factors that make people \n*Corresponding author: deepika.kumar@bharatividyapeeth.edu\ninherently vulnerable to the fake news are Naïve Realism \nand Confirmation Bias, since people tend to believe the \nnews that suits their narratives or affirm their bias, due to \nthis people often end up believing in fake news. \nFurthermore, recent trends of relying heavily on digital \ninformation sources, like social media have left news \nrecipients more susceptible and vulnerable to  fake news. \nThe quick dissemination of fake news can lead to \ncalamitous impacts on the society as a whole. Therefore, \n“automatic fake news detection” has become an emerging \nresearch topic and is attracting a good deal of attention of \nresearchers, especially in the Natural Language Processing \n(NLP) community. Automatic fake news detection aims in \nassessing and filtering potentially deceptive news from real \nnews. Automatic detection of fake news is a modern, but \ncritical NLP problem as stated in the recent su rvey by \nOshikawa et al. [4]. The conventional solution for this \nEAI Endorsed Transactions on \nScalable Information Systems \n05 2020 - 10 2020 | Volume 7 | Issue 27 | e10\nAkshay Aggarwal et al.\n2 \nproblem is to get the claims corroborated by professionals \nsuch as journalists based on evidence that is available. One \nsuch organization that does the fact checking is PolitiFact \n[5] which ha s three editors to inspect a news byte.\nHowever, with increasing amount of data, this process\nbecomes more tedious, cumbersome requires more man\npower and leads to inflated costs. Fake news detection as\nan autonomous task has been researched in different\nperspectives owing to the increasing development in areas\nof Data Mining, Machine Learning (ML) and NLP.\nEven though Deep Learning (DL), a subset of ML performs\nterrifically well in both Computer Vision (CV) as well as\nNLP domains [6-10], there are certain constraints that need\nto be addressed before utilizing DL techniques them for\nany task. These constraints that need to be taken care of are,\nfirstly, these algorithms need a huge chunk of labelled data\n(comparable to ImageNet dataset [11]) and heavy\ncomputational resources for appropriate training which can\nbe sometimes difficult as well as expensive to acquire.\nSecondly, DL can create the problem of underfitting and\noverfitting which leads to poor results. To overcome these\nconstraints researchers have in troduced an approach\nnotably referred to as “Transfer learning” (in this paper,\nfine-tuning is used as a transfer learning technique) [12 -\n13]. The fundamental rule in this approach is to reuse a\nmodel trained for some task as an initial point for a model\nwhich is to be trained for the target downstream task.\nTransfer learning has already shown exceptional results for\nmost of the CV tasks [14 -15] in the past two -three years\nand in practice nowadays, researchers rarely train a DL\nmodel from scratch. Transfer learning which was earlier\nlimited to CV tasks is now possible to do in the domain on\nNLP also with the introduction of recent language\nrepresentation models such as ELMO [16], ULMFiT [17],\nOpen AI transformer [18] and the most recent state-of-the-\nart, Google’s BERT [19]. Transfer learning has performed\nwell on natural language understanding tasks like that of\nCommon-sense Machine Comprehension (CMC); that\nenables learning of temporal and causal learning [20].\nIn this paper, we propose to fine-tune the 12-layered BERT\nlanguage representation model for downstream task of\nclassification of fake news. BERT is a bidirectional model\nwhich itself is based upon a transformer architecture [2 1].\nIn addition, we train 2 more classification models, one of\nwhich is based on an ML algorithm, gradient boosted trees\nand other is a single -layered RNN (LSTM) model.\nExperimental evaluations of these models demonstrate that\nproposed method of fine -tuning BERT is able to\noutperform other 2 models on the classification task by a\ngood margin.\nThe paper follows the following structure. In Section 2, the\nrelevant work in NLP domain and in the detection of fake\nnews is discussed. Following it, is the Section 3, in which\nan in-depth background for BERT language representation\nmodel and  provide the step -by-step directions for fine -\ntuning the model using GPUs is given, and after which our\nproposed methodology is demonstrated. After the previous\nsection, Section 4 gives the results and comparative\nanalysis with different approaches. Finall y, to conclude,\nSection 5 and 6 have the discussion and final conclusion of \nthis research study highlighting its application and the \nfuture scope.  \n2. Related works\nIn this section, we start by discussing how definition of \n“Fake news” has evolved over time. Then, we discuss \nexisting works and methods that are applicable for the task \nof fake news classification. Different researchers have \napplied significantly different approaches for tackling fake \nnews and to achieve decent progress on combating this \nchallenge, so we study these approaches based on their type \ni.e. whether the method applied is content-based, feedback-\nbased or is based on the social media engagement of users.\nAfter this, we give an overview of available datasets that\nhave been used in the past for this task.\nDisinformation and misinformation which is colloquially\nknown as “Fake News”, isn’t a new phenomenon. It has\nrecently garnered much attention due to 2016 US\npresidential elections, as can be observed by looking at the\nterm on Google Trends [2 2]. Misinformation was present\nbefore 2016 election as well, as is evident by studies\nconducted on misinformation before 2016 which shows\nthat misinformation has wide ranging effect s that range\nfrom financial loss, to politics. One such instance is a 2008\nfalse bankruptcy story about UAL parent company which\nled to 76% drop in stock price [23].\nIn content-based based methods, the fundamental basis is\nthat the textual and linguistic f eatures of a real news will\ndiffer from that of a fake news. There are hand-engineered\nways of extracting these cues as well as more recent DL\nmethods. One of the earliest hand -engineered features-\nbased methods, Scientific Content Analysis (SCAN)\nproposed in 1987 was primarily developed for polygraph\nexaminations and consisted of cues such as grammatical\nerrors, continuity in written paragraphs and provided\ninformation [24]. While the method did seem promising in\nits early days but was later proved ineffect ive [2 5, 2 6].\nSCAN also required experts to rigorously analyse the\ncontent. As, there always has been efforts to decrease\nhuman labour for these tasks, another linguistic -based\nmethod was developed by Fuller et al. [2 7]. Authors\ncreated a comprehensive set  of 31 linguistic cues which\nwere further refined using 3 classifiers to have only 8 cues\nfor deception detection. These cues were based on the\npreviously proposed different cue sets in the linguistic field\n[28 – 30]. One main limitation of this work was t hat the\ncues were largely dependent upon topic or domain of the\ntext and the model was not able to generalize well when\ntested on contents from different domains [3 1]. Relatively\nrecent feature -based methods include analysis -based\nmethods such as punctuati on marks [3 2], regular\nexpressions [33], platform (Twitter, Facebook, Wikipedia,\netc.) specific cues such as like counts, hashtags [34, 35].\nWhile the method of hand -designing the features and cues\nis much interpretable but also has disadvantages such as\nneed of re-drawing based on domain, platform or situation\nEAI Endorsed Transactions on \nScalable Information Systems \n05 2020 - 10 2020 | Volume 7 | Issue 27 | e10\nClassification of Fake News by Fine-tuning Deep Bidirectional Transformers based Language Model \n3 \nof the content, human involvements and lack of \ngeneralization. To improve generalization ability of \ndetection models, researchers have also utilized more \neffective ways of extracting features such as  N-gram [36, \n37]. Term frequently vectors are created using N -grams \nand then these are sent to different classifiers like Support \nVector Machine (SVM). While using N-grams did improve \nthe performance but being a simple approach could not \ncapture all the features in the different writing styles. Some \nresearchers also devised the classification models that \ninstead of being word-based like N-grams, are based on the \nsyntactical part of writing that exploits Part of speech \n(POS) tags or are derived from Probabil istic Context Free \nGrammars (PCFG) [3 8-40]. These approaches lacked \nability to capture clues across long news articles and were \neven weaker as compared to word-based approaches.  \nProcess of feature extraction is now automated with the \nadvent of DL. Deep ne ural networks are able to extract \nsimple as well as complex features that are not intuitive. \nWang et al. used two popular forms of neural networks, one \nis Convolutional Neural Network (CNN) and the other is \nbidirectional LSTMs for embedding the statement text and \nspeaker metadata information into lower dimensions and \nthen fed to classifier for classifying fake news based on the \ncontent [4 1]. They also made use of word embedding \nknown as word2vec f or capturing useful contextual \nproperties [4 2]. Quian et al. proposed a Two -level CNN \nwhich first generates sentence embedding using words and \nthen utilize the sentence embedding to create article \nembedding [43]. Their proposed variant of CNN was able \nto outperform the generic CNN. Variants of CNNs and \nRNNs have occasionally been used over the past decade for \nthe same task [44 - 46]. \nWhile most of the work done on detection of Fake News \nhas been on building supervised models, there are \nunsupervised techniques that have been employed to detect \nthe credibility of a pos t. Yang et al. uses opinions of users \non social media towards authenticity of a story and uses \nBayesian networks to build a probabilistic graphical model \nthat treats truth of news and user credibility as latent \nrandom variables [47]. \nThe underlying basis of feed -back based methods are the \nsecondary information such as user’s comments, news’ \npropagation graph in the social media and other user -\nrelated information. Researchers have tried developing \nhand-engineered features for these methods such as \nnumber of followers, content of tweets, depth of retweets, \ngeographical location etc. [4 8 - 50]. The route of retweets \nor shares of a news articles and how it propagates through \nthe social media web has been extensively analysed by \nresearchers. Ma et al. utilized Jaccard similarity to compute \nsimilarity scores of propagation trees of users [ 51, 5 2]. \nTexts of user’s comment along with article’s text also give \nrise to an informative model for fake news classification as \nit is highly likely that fake n ews articles will have fewer \npositive comments as compared to real news articles [5 3]. \nShu et al. proposes a novel method of detection of fake \nnews that uses TriFN which is a tri relationship embedding \nframework between the users, publishers and news piece s; \nthis auxiliary information improves significantly improves \nupon the baseline models [ 54]. Propagation patterns of \narticles can also be useful features in detection of fake \nnews, as was demonstrated by Monti et al. where geometric \ndeep learning was used for creating a model to detect fake \nnews. Heterogenous data like user profile and activity, \ncontent, news spreading patterns and structure of social \nnetwork is fused together underlying by using algorithms \nthat are a generalization of classical convolution al neural \nnetworks to graphs [55]. \nMethodologies discussed so far have been applied on \nvariety of datasets in the past. There are several novel \ndatasets that have been made available solely for the task \nof fake news detection. These datasets do vary largely with \neach other as some may solely comprise of articles related \nto politics while some may be related to any other particular \ndomain. Additionally, datasets also vary on the kind of data \npresent in them as some may contain very short statements \nwhile oth er can have large articles. In the following \nparagraph, we summarize some of the popular datasets. \nDataset that we use is discussed in detail in the later section. \nLIAR dataset available for detection of fake news has 12.8k \nlabelled short political statements collected over a period \nof 9 years (from 2007 to 2016) from POLITIFACT.COM. \nPrecisely, labels in this dataset are: true, mostly -true, half-\ntrue, barely-true, false and pants-fire. Number of claims per \nclass are roughly equal in size. Another dataset, FEVER, \nshort for Fact Extraction and Verification has  185,445 \nclaims. These claims were created by extracting data from \nWikipedia and then the claims were verified without prior \nknowledge of the sentence s of origin . These claims have \nbeen classified into th ree classes : supported, refuted or \nnotenoughinfo and have also been verified by skilled \nannotators [5 6]. As present form of fake news is mostly \npresent on social media, datasets such as \nBUZZFEEDNEWS contain 2282 samples published using \nFacebook by 9 news agencies one week before the 2016 \nUS elections. Every post or link is checked and verified by \n5 BuzzFeed journalists.  Labels in this dataset are: mostly \ntrue, mixture, mostly false and no factual content [5 7]. A \nsimilar dataset, Some-like-it-hoax dataset consists of \n15,500 Facebook posts and 909,236 users that are \nclassified as either hoax or not hoax  [58]. PHEME dataset \nis a collection of 6425 tweets that are rumours and non-\nrumours and were posted during the time of some breaking \nnews. 60% of samples are non -rumours, 16% are true \nrumours, 10% are false and rest are unverified. Most of the \ncontents in the dataset have been verified by journalists and \nvia crowd-sourcing. The CREDBANK dataset  is a set of \ntweets that were traced over a per iod of around 4 months \nduring 2014 -2015. Along with the tweet’s content , it \nconsists of topics classified as events or non events that are \nannotated with ratings  stating their credibility  [59]. \nFAKENEWSNET [60] is yet another popular database of \nNews Content and gives a better understanding of how fake \nnews is present on the social media. \nEAI Endorsed Transactions on \nScalable Information Systems \n05 2020 - 10 2020 | Volume 7 | Issue 27 | e10\n4 \n3. Methodology\nFake news keeps evolving every day, which brings the \nneed of creating an end -to-end classification model which \nis robust and requires minimal computation and pre -\nprocessing. In order to achieve this we have leveraged the \npower of transfer learning in context of NLP by fine-tuning \nBERT for downstream task of fake news classification, to \nshow how the technique of fine -tuning fares in \naccomplishing the task of classification of fake news its \nperformance has been compared to that of gradient boosted \ntrees and LSTMs. \n3.1. Overview of BERT \nBERT is a language representation model, which was \nintroduced by Google AI. BERT is first of its kind language \nrepresentation that can be utilized to pre -train deep \nbidirectional representations by taking into consideration \nleft and right contexts. \nPrevious work in pre -training representations like in \nOpenAI GPT and ELMo are unidirectional and shallow \nbidirectional respectively, as opposed to BERT which is \ndeeply bidirectional. BERT removes the constraint \nprovided by the unidire ctional approach by using Masked  \nLM (Masked Language Model) as a pre-training objective. \nBERT crossed the threshold of eleven state -of-art NLP \ntasks. Hence, BERT provided us with an approach that can \nyield state-of-art results without using heavily enginee red \nand task -specific architectures.  BERT in its input \nrepresentation uses three embedding layers, they are \ndescribed below. The final input embedding is a \nsummation of the three embeddings. Figure 1 demonstrates \nthe block diagram for BERT-based classification model. \nFigure 1. Block Diagram of BERT for classification. \n• Token Embeddings – In BERT it transforms the words\ninto a fixed 768 -dimension vector representation. [CLS]\nand [SEP] tokens are appended to the start and end of the\ntokenized sentence; they serve as input representations for\nclassification tasks and to sep arate input texts. BERT\ncleverly used WordPiece tokenizer which enables BERT to\nstore only 30522 words and rarely encounter any out -of-\nvocabulary word.\n• Segmentation Embeddings - BERT can perform text\nclassification tasks if given a pair of text input. An example\nof this is to classify if two pieces of text are semantically\nsimilar. So, the text is concatenated and fed to BERT,\nBERT distinguishes between text with the help of Segment\nEmbedding. Segment Embedding layer only has two vector\nrepresentations; first vector (EA) is assigned to tokens of\ninput1 and second vector (EB) is assigned to tokens of\ninput2.\n• Positional Embeddings – Used learned positional\nembeddings were used in BERT; this was done using the\nfunctions that were used to calculate positiona l encodings\nin transformer. Positional Embeddings used here\nunderstands the relative positions instead of just the\nabsolute ones. This is done by adding a sinusoidal function\ndepending on the position of token i in the sequence of\nsentence and j for the position of embedding feature to the\n768-dimensional vector representation of words, which\nyields a slightly different position of the same word in\ndifferent positions.\n(1) \nBeing an attention-based architecture, BERT uses Encoder \nwhich is intro duced in the architecture of Transformer \n(contains Encoder and Decoder). In BERT, N encoders are \nstacked together to give the Encoder output. Different \nencoding block finds different relationships between the \ninput representations and encodes them in its output. \nBERT used a novel approach to use bidirectionality, by \npre-training on “masked language model” and “next \nsentence prediction” instead of pre-training the model on a \nlanguage model. MLM (Masked Language Model), forces \nthe model to predict the masked tokens. 15% of all \nWordPiece tokens are masked, of which 80% of the time \nword is replaced by [MASK] token, 10% of the time it is \nreplaced by a random word and rest of the time the word is \nleft unchanged. The model tries to predict the correct value \nof masked words, based on the context given by words that \naren’t masked in the sequence. Technically, three steps are \nrequired to predict output words. Firstly, on top of an \nencoder layer a classification layer is to be added. \nSecondly, Multiplying the embedding matric by the output \nAkshay Aggarwal et al.\nEAI Endorsed Transactions on \nScalable Information Systems \n05 2020 - 10 2020 | Volume 7 | Issue 27 | e10\nClassification of Fake News by Fine-tuning Deep Bidirectional Transformers based Language Model \n5 \nvectors, transforming them into the dimension of the \nvocabulary. Lastly, Calculating the probability of every \nsingle word in the vocabulary using softmax. \nMLM cannot successfully capture the relationships \nbetween two sentences, which i s important for tasks like \nquestion answering and natural language inference. To \nbetter understand the relationships between two sentences \nBERT authors used next sentence prediction which is \nnothing but a classification task that finds if sentence B \nfollows sentence A or not. 50% of the training examples \nare correct, and rest are chosen at random to generate a \nwrong pair of sentences.  \nThe corpus for pre -training as built entirely from \nBookCorpus (800 million words) [ 61] and English \nWikipedia (2,500 million words). The pre-training samples \nwere generated in batches of two such that the length of \ntwo sentences that were chosen was less than 512 tokens \nand in our case 256 tokens. The training loss was computed \nas the sum o f mean MLM likelihood and mean next \nsentence prediction likelihood.  \n3.2. Dataset \nAt present, there are various datasets available to work \nupon in the domain of fake news classification. Each of the \ndatasets has its advantages as well as disadvantages, as we \ndiscussed in Section 2.  In this paper, the proposed method \nhas been applied on NewsFN Dataset [62]. This dataset has \n6335 items, consisting of the headline and text of the news \narticles on politics from a wide range of news sources that \nare classified as either “Fake” or “Real”. Precisely, 3164 \narticles are labeled as “Fake” and 3171 as “Real”. The ratio \nof the number of “Fake” articles to that of “Real” articles \nis roughly 1:1 hence dataset is well balanced with respect \nto the two classes, and there is no need for oversampling or \nunder sampling. Figure 2  describe the word clouds \ncorresponding to each of the two classes. It illustrates the \nmost frequent words other than the stop  words that are \npresent in the dataset. \n   (a)  (b) \nFigure 2. Wordclouds representing most frequent \nwords other than stopwords in (a) Fake News and \n(b) Real News articles.\nThis dataset  does not comprise of any kind of URLs . \nHowever, our work is primarily concerned with the textual \ncontext rather than external links. Additionally, we \nchecked the authenticity of most of the news articles by \nrandomly picking them from the dataset and compa ring \nthem with the reputed online news sources. \n3.3. Data pre-processing \nBefore passing the data through the classification model, it \nis required to do some pre -processing of the texts so that \nour model’s performance doesn’t get hindered by some \nlevel of noise that is present in the dataset. First, we remove \noutliers from the dataset to decrease overall variance in the \ndata.   \n3.3.1 Removing outliers \nAn outlier is a data point that is at a distant from other data \npoints in a particular dataset. After analysis of the dataset, \nit was found out that the length of articles’ texts  varies \nlargely in terms of number of words. Median text length in \nthe dataset is 597, 1% of the dataset has length < 10 and \n1% has length > 3958. So, in order to remove such high \nvariance in the dataset, only those articles that don’t fall in \neither of the above categories  were kept, resulting in total \nof 6210 items.  Figure 3 shows the distribution of text \nlengths before and a fter removing outliers. Table 1 \nsummarizes the related statistical information about the \ndataset. \n(a) \n(b) \nFigure 3. Distribution of length of article’s texts in \nnumber of words (a) Before removing outliers; (b) \nAfter removing outliers \nEAI Endorsed Transactions on \nScalable Information Systems \n05 2020 - 10 2020 | Volume 7 | Issue 27 | e10\n6 \nTable 1: Statistical information about dataset \nbefore and after removing outliers \n3.3.2. Removing noise from text \nTo increase the value of performance metrics, unimportant \nentities or noises in the texts such as punctuation marks, \nnumerical values, new -line characters were removed. \nRemoval of these entities decreases size of sample space of \npossible feature sets  and hence improves the level of \nperformance. \n3.3.3. Partitioning dataset into training and \ntesting sets \nTo ensure that the classification model doesn’t overfit on \nthe dataset and that testing is done on a batch of data that \nhasn’t been seen by the training model, the dataset was \ndivided in two parts, namely, training and testing sets with \nratio 80:20 i.e. eighty percent of the data is utilized for \ntraining and r est twenty percent of data is utilized for \ntesting. Demographics of these datasets are demonstrated \nin Table 2. The training set will be used by the model to \nminimize error rate i.e. to find patterns in the data. While \ntest set will be the one on which assessment of performance \nof the model is done , and which is not seen by the model \nduring training. \nTable 2: Demographics of Training and Testing sets \nTraining set Testing set \nNo. of articles labeled as \n“Fake” \n2453 620 \nNo. of articles labeled as \n“Real” \n2515 622 \nTotal no. of articles 4968 1242 \nThe main goal of this paper is to test the robustness of the \nproposed method of fine-tuning BERT for classification of \nfake news , so text pre -processing is kept as minimal as \npossible. In the next section, little tweaks  that are to be \nmade in the model and how parameters of this state-of-the-\nart language model can be fine -tuned for our downstream \ntask of fake news classification are demonstrated. \n3.4. Preparing BERT model for binary \nclassification \nIn the past, researchers have demonstrated how pre-trained \nlanguage representations can be applied to improve on \nmany supervised downstream tasks such as  natural \nlanguage inference,  question answering,  etc. The main \nadvantage of this method over training from scratch is that \nthere are only a few parameters that are required to be \ntrained from scratch. Specifically, researchers have devised \ntwo inexpensive strategies for making use of pre -trained \nlanguage representations . First strategy is f eature-based \napproach where  pre-trained representations are used as \nadditional features for the downstream task.  Second \nstrategy is f ine tuning  in which we train the downstream \ntasks by fine -tuning i.e.  tweaking the pre -trained \nparameters. \nFeature-based approaches such as ELMo are effective but \nalso require task -specific architectures, while it is not the \ncase for fine -tuning. Since Google’s BERT is one of the \npresent state-of-the-art and most powerful models which \nhas improved benchmark for several datasets, henceforth, \nwe primarily focus on applying a pre-trained BERT model \nfor binary classification by fine-tuning it. \nGoogle Research has  open-sourced the implementation of \nBERT in TensorFlow and has also released several pre -\ntrained models. At the time of our study, there are 6 pre -\ntrained models that have been released by Google. Table 3 \ngives an overview of these models.  The models primarily \nvary in the total number of parameters and how \ncomputationally expensive they are, BERT -Large is more \ncompute-intensive as opposed to BERT-Base. \nFor our  experiment and considering the amount of \ncomputational power available, the smallest and most \nsimplistic, BERT -Base, uncased model for task of fake \nnews classif ication is used . This model comprises of 12 \nattention layers with a total of 110M parameters. Moreover, \nbefore fine-tuning, all the text is converted to lowercase by \nthe tokenizer which comes along the implementation \nprovided by Google. \nBERT uses WordPiece embedding [63] with a vocabulary \nof 30,000 tokens where split word pieces are denoted with \n“##”. Additionally, it uses learned positional embeddings \nfor transforming text and the maximum supported \nsequence length by the model is 512 tokens. As it can be \nseen from Table 1, median text (sequence) length in our \ncase after removing outliers is 597, also, due to  the \nlimitation of resources and better (lesser) running time, we \nset the sequence length to be 256 tokens for each of the text. \nArticles that have sequence length less than 256 are padded \nBefore removing \noutliers \nAfter removing \noutliers \nNo. of articles \nlabeled as “Fake” \n3164 3073 \nNo. of articles \nlabeled as “Real” \n3171 3137 \nMedian length of \narticles’ text \n597.0 597.0 \nAverage length of \narticles’ text \n776.30 731.49 \nMaximum length \nof articles’ text \n20891 3947 \nMinimum length \nof articles’ text \n0 10 \nAkshay Aggarwal et al.\nEAI Endorsed Transactions on \nScalable Information Systems \n05 2020 - 10 2020 | Volume 7 | Issue 27 | e10\nClassification of Fake News by Fine-tuning Deep Bidirectional Transformers based Language Model \n7 \nwith zeros while those with greater than 256 tokens are \nstripped down to 256. \nTable 3: Variation of BERT models open-sourced by \nGoogle Research \nType No. of \nlayers \n(L) \nNo. of \nhidden \nunits \n(H) \nNo. of \nself-\nattention \nheads (A) \nTotal no. of \nparameters \nBERT-Base, \nUncased \n12 768 12 110M \nBERT-Large, \nUncased \n24 1024 16 340M \nBERT-Base, \nCased \n12 768 12 110M \nBERT-Large, \nCased \n24 1024 16 340M \nBERT-Base, \nMultilingual \ncased \n12 768 12 110M \nBERT-Base, \nChinese \n12 768 12 110M \nAs the BERT model can be used for multiple tasks, for \nspecifying the type of task as classification, the first token \nof every sequence in the training as well as test set is fixed \nas a special classification embedding ([CLS]). The output \nof the transformer i.e. the last hidden state corresponding \nto this special token is then used as a cumulative sequence \nrepresentation for performing classification by the model. \nThis output can be represented as a vector \n  where H \nis the hidden size.  \nNew parameters that are added at the time of fine -tuning \nfor classification are \n , where K is the number \nof classes, here 2 (“Fake” and “Real”). Probabilities for \nthese K labels are computed as: \n(2) \nWhere, \n  are the label probabilities. So, the pre -\ntrained parameters of BERT -Base, uncased model and \nparameters of classification layer \n  are jointly fine-tuned \nfor maximizing the log -probability corresponding to the \ncorrect label that is either “Fake” or “Real”. \nFor training of parameters, Adam optimizer is chosen, \nwhich is also recommended by Google [6 4]. Adam \noptimizer is an effective optimization algorithm which has \nthe ability of computing adaptive learning rates for each of \nthe parameters  and is more specifically a combination of \nRMSprop and traditional stochastic gradient descent with \nmomentum [65, 66]. This was specifically designed to train \ndeep neural networks and update the parameter value as: \n(3) \n(4) \nWhere mt and vt are mean estimate and variance at tth time \nstep of the gradients \n  respectively. \n and \n  are the \ndecay rates. Moments mt and vt are then corrected for bias \nas:  \n(5) \n (6) \nWhere, \n  and \n  are the corrected mt and vt respectively. \nThese are then used to update parameter \n  as: \n (7) \nWhere \n  is the learning rate and \n  is a smoothing term. \n Except learning rate, batch size and number of epochs, \nmost of the hyper -parameters of the model are kept the \nsame as the loaded pre -trained model. During our \nexperimentation, we found out that performance of the \nmodel is best when learning rate \n  is 2e – 5, batch size is 16 \nand number of epochs \n  which implies the number of times \ntraining set is passed through the m odel is kept 4. \nFurthermore, for avoiding overfitting, we use dropout \nregularization with d ropout probability r atio of 0.1. The \noverall methodology is summarized in Figure 4 below. \nFigure 4.  Proposed methodology \n4. Experimental results\nFor performance evaluation of the model, accuracy is \nchosen as the  primary metric for evaluation since the  \ntraining set, as well as the test set, are completely balanced. \nIt took around one hour for fine-tuning the model with \nEAI Endorsed Transactions on \nScalable Information Systems \n05 2020 - 10 2020 | Volume 7 | Issue 27 | e10\n8 \ntraining set along with the evaluation of test set on NVIDIA \nTesla K80 accelerated GPU. Final loss on training set came \nout to be 0.1450 while for the test set, resultant loss value \nis 0.1457 which is nearly the same and hence model is able \nto generalize excellently. Accuracy on the test set is \n97.021% which itself is promising and amongst s tate-of-\nthe-art models for classification of fake news. \nFurthermore, for comparing the performance of fine-tuned \nBERT model with other relatively older approaches, we \ntrained two more classification models from scratch i.e. \nwithout any kind of transfer learning. First, we used a \npopular machine learning technique, gr adient boosting \ndecision trees and implemented it using highly optimized \nXGBoost library  [67]. Briefly, gradient boosting yields a \nprediction model in the form of an ensemble of weak \nprediction models, such as decision trees. To represent \nwords of the text  in numerical form, we used tf-idf which \nstands for the product of term frequency and inverse \ndocument frequency. Tf -idf basically reflects how \nimportant a word is to a document in a corpus. For this \nclassifier, most of the hyperparameters are kept as defa ult \nexcept number of decision trees that are equal to 100 in our \ncase and maximum depth of a particular tree is kept as 6. \nThe s econd classifier for comparison is LSTM (Long \nShort-Term Memory) network which is a special kind of \nRNN. LSTMs are usually the first choice when it comes to \nNLP problems as they have the ability to remember key \ninformation for a longer period as compared to other \nsequence models. Similar to the BERT, LSTM also requires \na fixed sequence length. In our case, we use a sequence length \nof 512 for LSTMs which is much closer to median sequence \nlength. Each of the words in the texts needs to be represented \nin numerical form hence before passing data through LSTM \nlayers, an embedding layer of size 400 is also added whose \nparameters are trained along with LSTM’s parameters. To \navoid overfitting, a dropout layer with dropout ratio 0.5 is \nadded after LSTM layers. Dropout layer is then followed by \nclassification layers. This model is also trained with Adam \noptimizer. Batch size for training this model is 43. Accuracies \nfor all three models on the test set are shown in Table 4. \nValues for other evaluation metrics are compared in Table 5. \nTable 4: Accuracy comparison for three models \nModel Accuracy (in percentage) \nFine-tuned BERT 97.021% \nXGBoost 89.372% \nLSTM 86.231% \nFigure 5 below illustrates the comparison of a number of \narticles that are correctly or incorrectly predicted by the \nthree models that are trained. \n(a)\n(b) \n(c) \nFigure 5. Confusion Matrix showing the \nnumber of articles from Test set that are \npredicted as either “Fake” or “Real” by (a) \nBERT model; (b) XGBoost model and (c) LSTM \nmodel \nWe futher computed Precision, Recall and F1 -Score for  \nevaluation and comparativ e analysis o f the above defined \nclassification models. These metrics are computed as: \nAkshay Aggarwal et al.\nEAI Endorsed Transactions on \nScalable Information Systems \n05 2020 - 10 2020 | Volume 7 | Issue 27 | e10\nClassification of Fake News by Fine-tuning Deep Bidirectional Transformers based Language Model \n9 \n (8) \n (9) \n(10) \nFigure 6 gives the comparison of ROC (Receiver Operating \nCharacteristic) curves for three models which are created \nby plotting the  true positive rate  (TPR) against the  false \npositive rate (FPR) at various threshold settings. Values for \nthe area under the ROC curves (ROC AUC score) are \ncomputed using prediction p robabilities for “Real” class \nand are shown in Table 5. \nTable 5: Comparison of Precision; Recall; F1-\nScore and ROC AUC Score for predictions on \nTest set \nModel Precision Recall F1-Score ROC  \nAUC \nFake Real Fake Real Fake Real Score \nFine-\ntuned \nBERT \n0.98 0.95 0.95 0.98 0.97 0.97 0.99 \nXGBoost 0.87 0.91 0.91 0.87 0.89 0.89 0.96 \nLSTM 0.87 0.85 0.84 0.87 0.86 0.86 0.92 \nFigure 6. ROC Curve Comparison \n5. Discussion\nDetection of Fake News is gaining a lot of traction among \nresearchers because of its complexity, and the requirement \nfor an algorithm that can filter thousands of news articles \nand judge their authenticity in a matter of minutes. Earlier \ntechniques to deal with this problem involved a lot of hand-\nengineering of features, this led to poor generalization of \nthe models which is very important in the case of this task. \nWith the advances made in DL the extraction of features is \nnot something that has to be hand engineered, since, deep \nneural networks can extract non-intuitive complex features \nwhich may not have been possible even with hand -\nengineering of features. This promises a better chance of \ngeneralizability of a model.  \nOne of the most recent advances in th e field of NLP has \nbeen the introduction of transformer architecture and the \nBERT model which when fine -tuned with the addition of \none layer was able to set benchmarks on various NLP tasks \nwithout explicitly being trained for doing those \ntasks.Transfer lea rning is a powerful approach that can \nadapt well to different tasks. In this paper a  framework \nbased on natural language processing (NLP) is proposed to \naddress this task of classifying news articles as either fa ke \nor real using Fine Tuned BERT model. The BERT model \nconsiderably outperforms other approaches even with \nminimal to no engineering of features. The results show us \nthat transfer learning can yield good results in the case of \ndetection of fake news as  well. The fine -tuned BERT \nsystem can achieve an  accuracy of 97.021 per cent on \nNewsFN data and is capable of surpassing the other two \nmodels by approximately eight per cent. \n6. Conclusion and Future Scope\nIn this paper,  a powerful and time efficient  approach is \nproposed for accurately classifying news articles into two \nclasses: Fake and Real. Here, in this research study, we \nutilized the robustness of pre-trained BERT language \nmodel and applied a highly successful approach of transfer \nlearning for converting the model into a classificat ion \nmodel. We also built two more models for comparison and \ncomputed values for various evaluation metrics  to support \nthe performance of the proposed method of classifying fake \nnews. Specifically, on NewsFN dataset the pre -trained \nBERT model is able to classify news articles with accuracy \nof 97.021% which is a significant improvement over other \ntraditional approach. \nFor the future, we recommend researchers to  try the same \napproach on datasets that comprise of much diverse news \narticles. Also, instead of lim iting the number of classes to \nonly two, researchers can include various more nuanced \nclasses. Moreover, the overall performance of this \napproach can  be improved by fine -tuning larger BERT \nmodels, provided the available dataset is large enough and \nthere are enough computational resources to  handle the \nincreased computational complexity.  One of the most \nconcerning factors for this research task is to get a properly \nlabeled dataset, as currently, there is no particular dataset \nthat is diverse enough to build a state-of-the-art mechanism \nfor fake news detection.  \nNeedless to say, there is a long way to go tackle the \nproblem of fake news detection, transfer learning promises \nto be a strong means of progress in the field. In our research \nwe have chosen a  binary dataset that has news labelled as \nfake or real, in reality news isn’t as black and white and \nthere are certain nuances that are associated with different \narticles that aim to spread propaganda or fake news, for \ninstance an article may not be entirely fake, just a part of it \nmay be fake. There is a need of large datasets that should \nbe labelled at sentence or paragraph level, so that a more \nfine-grained level of classification can be achieved.  \nEAI Endorsed Transactions on \nScalable Information Systems \n05 2020 - 10 2020 | Volume 7 | Issue 27 | e10\n10 \nReferences \n[1] Allcott, H., & Gentzkow, M. (2017). Socia l media and fake\nnews in the 2016 election. Journal of economic perspectives ,\n31(2), 211-36.\n[2] Swift, A. (2016). Americans’ trust in mass media sinks to new\nlow. Gallup News, 14(6). Retrieved from\nhttps://news.gallup.com/poll/195542/americans-trust-mass-\nmedia-sinks-new-low.aspx.\n[3] Reilly, R., & Nye, R. (2012). Power, principles and the press.\nRetrieved from http://www. The open road. com/wp -\ncontent/uploads/2012/09/Powerprinciples-and-thepress-Open-\nRoad-and-Populus1. pdf.\n[4] Oshikawa, R., Qian, J., & W ang, W. Y. (2018). A survey on\nnatural language processing for fake news detection. arXiv\npreprint arXiv:1811.00770.\n[5] Fact -checking U.S. politics. PolitiFact. Retrieved from\nhttps://www.politifact.com/.\n[6] Krizhevsky, A., Sutskever, I., & Hinton, G. E.  (2012).\nImagenet classification with deep convolutional neural\nnetworks. In Advances in neural information processing\nsystems (pp. 1097-1105).\n[7] Hochreiter, S., & Schmidhuber, J. (1997). Long short -term\nmemory. Neural computation, 9(8), 1735-1780.\n[8] Khan, M. A., Khan, M. A., Ahmed, F., Mittal, M., Goyal, L.\nM., Hemanth, D. J., & Satapathy, S. C. (2020). Gastrointestinal\ndiseases segmentation and classification based on duo -deep\narchitectures. Pattern Recognition Letters, 131, 193-204.\n[9] Gautam, R., & Sharma, M. (2020). Prevalence and Diagnosis\nof Neurological Disorders Using Different Deep Learning\nTechniques: A Meta -Analysis. Journal of Medical Systems,\n44(2), 49.\n[10] Mittal, M., Goyal, L. M., Kaur, S., Kaur, I., Verma, A., &\nHemanth, D. J. (2019). Deep learning based enhanced tumor\nsegmentation approach for MR brain images. Applied Soft\nComputing, 78, 346-354.\n[11] Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S.,\nMa, S.,& Berg, A. C. (2015). Imagenet large scale visual\nrecognition challenge. International journal of computer vision,\n115(3), 211-252.\n[12] Yosinski, J., Clune, J., Bengio, Y., & Lipson, H. (2014). How\ntransferable are features in deep neural networks?. In Advances\nin neural information processing systems (pp. 3320-3328).\n[13] Bawa, V. S., & Kumar, V. (2019). Emotional sentiment\nanalysis for a group of people based on transfer learning with a\nmulti-modal system. Neural Computing and Applications,\n31(12), 9061-9072.\n[14] Tan, C., Sun, F., Kong, T., Zhang, W., Ya ng, C., & Liu, C.\n(2018). A survey on deep transfer learning. In International\nconference on artificial neural networks (pp. 270 -279).\nSpringer, Cham.\n[15] Ramírez, I., Cuesta-Infante, A., Pantrigo, J. J., Montemayor,\nA. S., Moreno, J. L., Alonso, V.,  & Palombarani, L. (2018).\nConvolutional neural networks for computer vision -based\ndetection and recognition of dumpsters. Neural Computing and\nApplications, 1-9.\n[16] Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark,\nC., Lee, K., & Zettlemoyer, L. (20 18). Deep contextualized\nword representations. arXiv preprint arXiv:1802.05365.\n[17] Howard, J., & Ruder, S. (2018). Universal language model\nfine-tuning for text classification. arXiv preprint\narXiv:1801.06146.\n[18] Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I.\n(2018). Improving language understanding by generative pre -\ntraining. URL https://s3 -us-west-2.amazonaws.com/openai-\nassets/researchcovers/languageunsupervised/language\nunderstanding paper. pdf.\n[19] Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018).\nBert: Pre -training of deep bidirectional transformers for\nlanguage understanding. arXiv preprint arXiv:1810.04805.\n[20] Han, W., Peng, M., Xie, Q., Hu, G., Gao, W., Wang, H., ...\n& Liu, Z. (2019).  DTC: Transfer Learning for Common  sense\nMachine Comprehension. Neurocomputing.\n[21] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,\nL., Gomez, A. N.,& Polosukhin, I. (2017). Attention is all you\nneed. In Advances in neural information processi ng systems\n(pp. 5998-6008).\n[22] Fake news - Explore - Google Trends. Retrieved from\nhttps://trends.google.com/trends/explore?date=2013-12-06\n2018-01-06 &geo=US & q=fake news.\n[23] Castillo, C., Mendoza, M., & Poblete, B. (2011). Information\ncredibility on twitter. In Proceedings of the 20th international\nconference on World wide web (pp. 675-684).\n[24] Sapir, A. (1987). The LSI course on scientific content\nanalysis (SCAN). Phoenix, ZA: Laboratory for Scientific\nInterrogation.\n[25] Bogaard, G., Meijer, E. H ., Vrij, A., & Merckelbach, H.\n(2016). Scientific content analysis (SCAN) cannot distinguish\nbetween truthful and fabricated accounts of a negative event.\nFrontiers in psychology, 7, 243.\n[26] Nahari, G., Vrij, A., & Fisher, R. P. (2012). Does the truth\ncome out in the writing? Scan as a lie detection tool. Law and\nHuman Behavior, 36(1), 68.\n[27] Fuller, C. M., Biros, D. P., & Wilson, R. L. (2009). Decision\nsupport for determining veracity via linguistic -based cues.\nDecision Support Systems, 46(3), 695-703.\n[28] Zhou, L., Burgoon, J. K., Nunamaker, J. F., & Twitchell, D.\n(2004). Automating linguistics -based cues for detecting\ndeception in text -based asynchronous computer -mediated\ncommunications. Group decision and negotiation, 13(1), 81 -\n106.\nAkshay Aggarwal et al.\nEAI Endorsed Transactions on \nScalable Information Systems \n05 2020 - 10 2020 | Volume 7 | Issue 27 | e10\nClassification of Fake News by Fine-tuning Deep Bidirectional Transformers based Language Model \n11 \n[29] Buller, D. B., & Burgoon, J. K. (1996). Interpersonal\ndeception theory. Communication theory, 6(3), 203-242.\n[30] Pennebaker, J. W., Francis, M. E., & Booth, R. J. (2001).\nLinguistic inquiry and word count: LIWC 2001. Mahway:\nLawrence Erlbaum Associates, 71(2001), 2001.\n[31] Ali, M., & Levine, T. (2008). The language of truthful and\ndeceptive denials and confessions. Communication Reports,\n21(2), 82-91.\n[32] Rubin, V. L., Conroy, N., Chen, Y., & Cornwell, S. (2016).\nFake news or truth? using satirical cues  to detect potentially\nmisleading news. In Proceedings of the second workshop on\ncomputational approaches to deception detection (pp. 7-17).\n[33] Zhao, Z., Resnick, P., & Mei, Q. (2015). Enquiring minds:\nEarly detection of rumours in social media from enquiry posts.\nIn Proceedings of the 24th international conference on world\nwide web (pp. 1395-1405).\n[34] Morris, M. R., Counts, S., Roseway, A., Hoff, A., &\nSchwarz, J. (2012). Tweeting is believing? Understanding\nmicroblog credibility perceptions. In Proceedings of the ACM\n2012 conference on computer supported cooperative work (pp.\n441-450).\n[35] Chen, Y., Conroy, N. J., & Rubin, V. L. (2015). Misleading\nonline content: recognizing clickbait as\" false news\". In\nProceedings of the 2015 ACM on workshop on mult imodal\ndeception detection (pp. 15-19).\n[36] Mihalcea, R., & Strapparava, C. (2009). The lie detector:\nExplorations in the automatic recognition of deceptive\nlanguage. In Proceedings of the ACL -IJCNLP 2009\nConference Short Papers (pp. 309 -312). Association  for\nComputational Linguistics.\n[37] Ott, M., Choi, Y., Cardie, C., & Hancock, J. T. (2011).\nFinding deceptive opinion spam by any stretch of the\nimagination. In Proceedings of the 49th annual meeting of the\nassociation for computational linguistics: Human  language\ntechnologies-volume 1  (pp. 309 -319). Association for\nComputational Linguistics.\n[38] Biber, D., Johansson, S., Leech, G., Conrad, S., Finegan, E.,\n& Quirk, R. (1999). Longman grammar of spoken and written\nEnglish (Vol. 2). London: longman.\n[39] Rayson, P., Wilson, A., & Leech, G. (2002). Grammatical\nword class variation within the British National Corpus\nsampler. In New Frontiers of Corpus Research  (pp. 295-306).\nBrill Rodopi.\n[40] Johnson, M. (1998). PCFG models of linguistic tree\nrepresentations. Computational Linguistics, 24(4), 613-632.\n[41] Wang, W. Y. (2017). \" liar, liar pants on fire\": A new\nbenchmark dataset for fake news detection. arXiv preprint\narXiv:1705.00648.\n[42] Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013).\nEfficient estimation of word representations in vector space.\narXiv preprint arXiv:1301.3781.\n[43] Qian, F., Gong, C., Sharma, K., & Liu, Y. (2018). Neural\nUser Response Generator: Fake News Detection with\nCollective User Intelligence. In IJCAI (pp. 3834-3840).\n[44] Rashkin, H., Choi, E., Jang, J. Y., Volkova, S., & Choi, Y.\n(2017). Truth of varying shades: Analyzing language in fake\nnews and political fact -checking. In Proceedings of the 2017\nConference on Empirical Methods in Natural Language\nProcessing (pp. 2931-2937).\n[45] Volkova, S., Shaffer, K., Jang, J. Y., & Hodas, N. (2017).\nSeparating facts from fiction: Linguistic models to classify\nsuspicious and trusted news posts on twitter. In Proceedings of\nthe 55th Annual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers) (pp. 647-653).\n[46] Chopra, S., Jain, S., & Sholar, J. M. (2017). Towards\nautomatic identification of fake news: Headline -article stance\ndetection with LS TM attention models. In Stanford CS224d\nDeep Learning for NLP final project.\n[47] Yang, S., Shu, K., Wang, S., Gu, R., Wu, F., & Liu, H.\n(2019). Unsupervised fake news detection on social media: A \ngenerative approach. In Proceedings of the AAAI Conference\non Artificial Intelligence (Vol. 33, pp. 5644-5651).\n[48] Castillo, C., Mendoza, M., & Poblete, B. (2011). Information\ncredibility on twitter. In Proceedings of the 20th international\nconference on World wide web (pp. 675-684).\n[49] Kwon, S., Cha, M., & Jung, K. (2017). Rumor detection over\nvarying time windows. PloS one, 12(1).\n[50] Yang, F., Liu, Y., Yu, X., & Yang, M. (2012). Automatic\ndetection of rumour on Sina Weibo. In Proceedings of the ACM\nSIGKDD Workshop on Mining Data Semantics (pp. 1-7).\n[51] Ma, J., Gao, W., & Wong, K. F. (2017). Detect rumors in\nmicroblog posts using propagation structure via kernel\nlearning. Association for Computational Linguistics.\n[52] Ma, J., Gao, W., & Wong, K. F. (2018). Rumour detection\non twitter  with tree -structured recursive neural networks.\nAssociation for Computational Linguistics.\n[53] Chen, T., Li, X., Yin, H., & Zhang, J. (2018). Call attention\nto rumours: Deep attention based recurrent neural networks for\nearly rumour detection. In Pacific-Asia Conference on\nKnowledge Discovery and Data Mining  (pp. 40-52). Springer,\nCham.\n[54] Shu, K., Wang, S., & Liu, H. (2019). Beyond news contents:\nThe role of social context for fake news detection. In\nProceedings of the Twelfth ACM International Conference on\nWeb Search and Data Mining (pp. 312-320).\n[55] Monti, F., Frasca, F., Eynard, D., Mannion, D., & Bronstein,\nM. M. (2019). Fake news detection on social media using\ngeometric deep learning. arXiv preprint arXiv:1902.06673.\n[56] Thorne, J., Vlachos, A., Christodoulopoulos, C., & Mittal, A.\n(2018). FEVER: a large -scale dataset for fact extraction and\nverification. arXiv preprint arXiv:1803.05355.\n[57] Silverman, C. (2016). Viral fake election news outperformed\nreal news on Facebook in final month s of the us election.\nEAI Endorsed Transactions on \nScalable Information Systems \n05 2020 - 10 2020 | Volume 7 | Issue 27 | e10\n12 \nBuzzFeed News, 16. Retrieved from \nhttps://www.buzzfeednews.com/article/craigsilverman/viral-\nfake-election-news-outperforme-real-news-onFacebook.    \n[58] Tacchini, E., Ballarin, G., Della Vedova, M. L., Moret, S., &\nde Alfaro, L. (2017). Some like it hoax: Automated fake news\ndetection in social networks. arXiv preprint arXiv:1704.07506.\n[59] Mitra, T., & Gilbert, E. (2015). Credbank: A large -scale\nsocial media corpus with associated credibility annotations. In\nNinth International AAAI Conference on Web and Social\nMedia.\n[60] Shu, K., Mahudeswaran, D., Wang, S., Lee, D., & Liu, H.\n(2018). Fakenewsnet: A data repository with news content,\nsocial context and dynamic information for studying fake news\non social media. arXiv preprint arXiv:1809.01286.\n[61] Zhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun,\nR., Torralba, A., & Fidler, S. (2015). Aligning books and\nmovies: Towards story -like visual explanat ions by watching\nmovies and reading books. In Proceedings of the IEEE\ninternational conference on computer vision (pp. 19-27).\n[62] fake_real_news_dataset · GitHub. Retrieved from\nhttps://github.com/GeorgeMcIntire/fake_real_news_dataset.\n[63] Wu, Y., Schuster, M., Chen, Z., Le, Q. V., Norouzi, M.,\nMacherey, W.,& Klingner, J. (2016). Google's neural machine\ntranslation system: Bridging the gap between human and\nmachine translation. arXiv preprint arXiv:1609.08144.\n[64]Kingma, D. P., & Ba, J. (20 14). Adam: A method for\nstochastic optimization. arXiv preprint arXiv:1412.6980.\n[65]Hinton, G., Srivastava, N., & Swersky, K. (2012). Neural\nnetworks for machine learning lecture 6a overview of mini -\nbatch gradient descent. Cited on, 14(8).\n[66] Robbins, H., & Monro, S. (1951). A stochastic\napproximation method. The annals of mathematical statistics,\n400-407.\n[67] Chen, T., & Guestrin, C. (2016). Xgboost: A scalable tree\nboosting system. In Proceedings of the 22nd acm  sigkdd\ninternational conference on knowledge discovery and data\nmining (pp. 785-794).\nAkshay Aggarwal et al.\nEAI Endorsed Transactions on \nScalable Information Systems \n05 2020 - 10 2020 | Volume 7 | Issue 27 | e10"
}