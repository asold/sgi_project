{
  "title": "Extracting structured data from organic synthesis procedures using a fine-tuned large language model",
  "url": "https://openalex.org/W4401173005",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2752629669",
      "name": "Qianxiang Ai",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2653413344",
      "name": "Fanwang Meng",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2097594861",
      "name": "Jiale Shi",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2733001497",
      "name": "Brenden Pelkie",
      "affiliations": [
        "University of Washington"
      ]
    },
    {
      "id": "https://openalex.org/A2514640655",
      "name": "Connor W Coley",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2752629669",
      "name": "Qianxiang Ai",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2653413344",
      "name": "Fanwang Meng",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2097594861",
      "name": "Jiale Shi",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2733001497",
      "name": "Brenden Pelkie",
      "affiliations": [
        "University of Washington"
      ]
    },
    {
      "id": "https://openalex.org/A2514640655",
      "name": "Connor W Coley",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4383187427",
    "https://openalex.org/W4239934460",
    "https://openalex.org/W2149369282",
    "https://openalex.org/W2610394652",
    "https://openalex.org/W2136794542",
    "https://openalex.org/W2111044246",
    "https://openalex.org/W2176758925",
    "https://openalex.org/W4392519967",
    "https://openalex.org/W2101553882",
    "https://openalex.org/W2769387903",
    "https://openalex.org/W2911871734",
    "https://openalex.org/W2970374239",
    "https://openalex.org/W3168661259",
    "https://openalex.org/W4214535912",
    "https://openalex.org/W4283778430",
    "https://openalex.org/W4224442790",
    "https://openalex.org/W6601728261",
    "https://openalex.org/W1604644367",
    "https://openalex.org/W2798734500",
    "https://openalex.org/W2964167098",
    "https://openalex.org/W3214342214",
    "https://openalex.org/W4297253404",
    "https://openalex.org/W4388608412",
    "https://openalex.org/W4391836235",
    "https://openalex.org/W4386902993",
    "https://openalex.org/W4385571521",
    "https://openalex.org/W4389523690",
    "https://openalex.org/W4389300644",
    "https://openalex.org/W3043647281",
    "https://openalex.org/W3091684735",
    "https://openalex.org/W3209726219",
    "https://openalex.org/W4385671288",
    "https://openalex.org/W2523785361",
    "https://openalex.org/W3200122731",
    "https://openalex.org/W3201869313",
    "https://openalex.org/W2901942917",
    "https://openalex.org/W3143418323",
    "https://openalex.org/W4389996830",
    "https://openalex.org/W4353112191",
    "https://openalex.org/W4382198765",
    "https://openalex.org/W3201277766",
    "https://openalex.org/W4386884238",
    "https://openalex.org/W4327913228",
    "https://openalex.org/W3213485948",
    "https://openalex.org/W4389523661",
    "https://openalex.org/W1607035479",
    "https://openalex.org/W4233907442"
  ],
  "abstract": "An open-source fine-tuned large language model can extract reaction information from organic synthesis procedure text into structured data that follows the Open Reaction Database (ORD) schema.",
  "full_text": "Extracting structured data from organic synthesis\nprocedures using aﬁne-tuned large language\nmodel†\nQianxiang Ai,a Fanwang Meng, a Jiale Shi,a Brenden Pelkie b\nand Connor W. Coley *a\nThe popularity of data-driven approaches and machine learning (ML) techniques in theﬁeld of organic\nchemistry and its various subﬁelds has increased the value of structured reaction data. Most data in\nchemistry is represented by unstructured text, and despite the vastness of the organic chemistry\nliterature (papers, patents), manual conversion from unstructured text to structured data remains\na largely manual endeavor. Software tools for this task would facilitate downstream applications such as\nreaction prediction and condition recommendation. In this study, weﬁne-tune a large language model\n(LLM) to extract reaction information from organic synthesis procedure text into structured data\nfollowing the Open Reaction Database (ORD) schema, a comprehensive data structure designed for\norganic reactions. The ﬁne-tuned model produces syntactically correct ORD records with an average\naccuracy of 91.25% for ORD “messages” (e.g., full compound, workups, or condition deﬁnitions) and\n92.25% for individual dataﬁelds (e.g., compound identiﬁers, mass quantities), with the ability to recognize\ncompound-referencing tokens and to infer reaction roles. We investigate its failure modes and evaluate\nperformance on speciﬁc subtasks such as reaction role classiﬁcation.\n1 Introduction\nData-driven methods are now routinely employed in the physical\nsciences. A trend toward the use of supervised machine learning\n(ML) techniques has increased the need for structured data,i.e.,\ndata represented using a standardized data schema. In most\nscientic communities, however, data is stored and communi-\ncated predominantlyvia unstructured documents and prose, with\nonly a few exceptions.\n1 Synthetic organic chemistry is not one of\nthose exceptions. Reaction procedures and details are commonly\nrecorded as free text in journal publications, patents, or electronic\nlab notebooks (ELNs). Manual information extraction and cura-\ntion are still widely used to construct structured datasets from\nunstructured texts.\n2,3 An automated method to extract structured\nreaction data from unstructured texts would accelerate eﬀorts to\nuse historical reaction data for data-driven discovery.\nAs an information extraction task, structured data extraction\nfrom text can be considered as a combination of named entity\nrecognition (NER) and relation extraction (RE) between named\nentities. Challenges in chemical NER include the pervasive usage\nof abbreviations and aliases, deviations from standard\nnomenclature, and the ambiguous boundaries between which\na chemical entity is dened (e.g., when multiple words describe\nas i n g l es p e c i e s ) .\n4,5 A variety of methods have been applied for\nchemical NER tasks. Rule-based or dictionary-based methods,\nsuch as LeadMine\n6 and ChemicalTagger,7 have been used to\nannotate reaction procedure texts or in the text parsing pipeline for\nconstructing synthesis datasets such as SureCHEMBL,\n8 Pistachio,9\nand ZeoSyn.10 While these algorithms are usually computationally\neﬃcient, the scope of rules and dictionary items limits their\ngeneralizability to new datasets.Various statistical model-based\nNER algorithms have also been proposed, oen as a sequence\nlabeling problem where the tokensin a sentence are assigned most\nlikely tags based on token features. A popular strategy is the use of\nconditional randomelds\n11 in combination with expert-selected\nfeatures12 or contextualized word embeddings from neural\nnetworks (recurrent networks,13–15 or transformers16–19).\nTraditionally, RE is formulated as a downstream task to NER\nand is solved as an ensemble of classication problems for entity\npairs.20,21 More recent eﬀorts aim to solve NER and RE simulta-\nneously by building end-to-end models.22–25 This trend has per-\nsisted as pretrained large language models (LLMs) have become\nmore accessible. LLMs have been used for NER/RE tasks in\nbiomedicine,\n26 materials,27 and clinical trials,28 showing promise\nas tools for structured data extraction. For example, Dagdelen\net al. developed a training pipeline for GPT-3 to extract infor-\nmation from scientic texts about crystalline materials as struc-\ntured JSON29 and Walkeret al.present an iterative scheme tone-\naDepartment of Chemical Engineering, Massachusetts Institute of Technology,\nCambridge, MA, USA. E-mail: ccoley@mit.edu\nbDepartment of Chemical Engineering, University of Washington, Seattle, WA, USA\n† Electronic supplementary information (ESI) available. See DOI:\nhttps://doi.org/10.1039/d4dd00091a\nCite this:Digital Discovery,2 0 2 4 ,3,\n1822\nReceived 6th April 2024\nAccepted 30th July 2024\nDOI: 10.1039/d4dd00091a\nrsc.li/digitaldiscovery\n1822 | Digital Discovery,2 0 2 4 ,3,1 8 2 2–1831 © 2024 The Author(s). Published by the Royal Society of Chemistry\nDigital\nDiscovery\nPAPER\nOpen Access Article. Published on 31 July 2024. Downloaded on 11/5/2025 2:28:00 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nView Journal\n | View Issue\ntune LLMs for extracting structured data of gold nanorods\nsynthesis.30 Recent studies by Zhonget al. explored ne-tuned\nLLMs for reaction data extraction from literature in PDF\nformat.\n31,32 The output of these models provides a reasonable\ncoverage of reaction information, with the exception of quantity\ninformation. Pretrained LLMs can also be used for this task\ndirectly without ne-tuning. For example, a recent preprint by\nPatiny and Godin explores extracting analytical experiment\nresults from literature solely through prompt engineering.\n33\nWhile this method can extract structured data by including in-\nprompt data schema, it relies on closed-source LLMs and\nperforms poorly when numerical values are involved.\nOne important use case for extracting structured reaction data\nis the production of procedural instructions to be used for repro-\nducing experiments. For example, Vaucher et al. developed\na transformer-based model to translate sentences of experiment\nprocedures into action sequences.\n34 While these action sequences\ncontain detailed information for execution, their evaluations focus\nmore on the type of action than the parameters or objects of that\naction. SynthReader,\n35 a rule-based translator developed by Mehr\net al.,35 converts natural language procedures tocDL, a data\nschema designed for chemical operations. Such a rule-based\nmethod, despite being computationally eﬃcient, has to be\nexpanded/modied to adapt to a di ﬀerent distribution, e.g.,\na change in writing style. Va rious submissions to Chem-\ninformatics Elsevier Melbourne University (ChEMU) evaluation\nlab\n36–38 also aim to solve the NER/RE tasks including reaction/\nworkup steps. Since these campaigns aim at evaluating indi-\nvidual NER/RE tasks, they do not constitute an end-to-end solution\nfor structured data extraction into a specic output data schema.\nIn this study, we ne-tune an open-source large language\nmodel to extract structured reaction information from\nunstructured text from US patents (Fig. 1). To structure the\ndesired outputs, we adopt the Open Reaction Database (ORD)\ndata format, a comprehensive data schema tailored to organic\nreactions.\n40 The 100 000-reaction dataset we use forne-tuning\nis part of a collection originally published by Lowe in Chemical\nMarkup Language (CML) format,\n39 so the ne-tuned model\nessentially pursues the same goal as Lowe's expert natural\nlanguage processing pipeline, albeit using a di ﬀerent data\nschema. Extracted records cover information on reactants,\nproducts, conditions, and workup steps. We demonstrate that\nthe ne-tuned model produces syntactically correct ORD\nrecords from the USPTO with an average accuracy of 91.25% for\nchemical messages (compounds, workups, conditions) and\n92.25% for individual dataelds. We also investigate its failure\nmodes and evaluate performance on reaction role classication.\nWe note that a preliminary version of this study was previously\ndisclosed as part of a Perspective article on opportunities for\nLLMs in chemistry.\n42\n2 Methods\n2.1 Introduction to the Open Reaction Database (ORD)\nschema\nA reaction record in the ORD is structured as a Reaction\nmessage using Google's Protocol Bu ﬀers, which can be\nfaithfully converted to and from JSON format without loss of\ninformation. For a specic Reaction, we focus on four chemi-\ncally important elds: inputs, conditions, workups, and\noutcomes, each of which is also a message or a list of messages\ndened in ORD schema. An example reaction record is shown in\nFig. 2 with representativeelds populated. There are more than\n600 elds dened in ORD schema, some of which are size-\nmutable, and an ORD record typically includes many nested\nmessages. There are also strict rules on types and values\nadmitted by data elds. For example, the typeeld of Reac-\ntionWorkup is an enumeld that only accepts specic strings,\nand assigning out-of-vocabulary strings to thiseld leads to\na syntactically invalid ORD record. The full denition of the\nReaction message used in this study is available on GitHub.\n44\n2.2 Dataset preparation from patents and the ORD\nReaction records from the United States Patent and Trademark\nOﬃce (USPTO) were collected from the ORD, sharded across\n489 datasets. The link to a complete list of dataset IDs can be\nfound in the ESI.† These records were originally published by\nLowe in Chemical Markup Language (CML) format\n39 and were\nimported into the ORD using a custom CML-to-ORD translation\nscript.\n45 A reaction record is admitted to our dataset if it satises\nthe following conditions:\n/C15 Each of its ReactionInput messages has non-empty values\nfor its componentseld. This usually means this reaction input\nis not the crude product of another reaction and that the\nchemical information of this reaction's inputs are present in\nreaction procedure text.\nFig. 1 Overview of this study's approach to structured reaction data\nextraction from text. A 100k reaction subset of the United States Patent\nand Trademark Oﬃce (USPTO) reaction data39 as represented in the\nOpen Reaction Database (ORD)40 is used to ﬁne-tune and evaluate\nLLaMa-2-7B. An example of the structured ORD record is included in\nSection 2.1. The data pipeline (top left) is detailed in Section 2.2. The\nﬁne-tuning procedure is described in Section 2.3. The llama with a cap\nwas generated using Craiyon AI.41\n© 2024 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 4 ,3,1 8 2 2–1831 | 1823\nPaper Digital Discovery\nOpen Access Article. Published on 31 July 2024. Downloaded on 11/5/2025 2:28:00 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\n/C15 The reaction includes an associated procedure text,i.e., the\nnotes.procedure_details eld of this reaction is a paragraph\ndescribing the reaction.\nReaction records satisfying these criteria were exported to\nJSON and deduplicated using OpenAI's data preparation tools\n(openai tools ne_tunes.prepare_data) to produce 1 339 260\nunique records. The use of OpenAI's data preparation tools is\nfree and was used here solely for convenient prompt dedupli-\ncation. The procedure text and structured JSON are combined\nusing a prompt template (see ESI†) modied from Stanford\nAlpaca.\n46 A sequence length limit of 2048 tokens based on\nLLaMA tokenizer, is imposed due to memory considerations in\nne-tuning the language models. This sequence limit reduces\nthe number of records to 1 300 613 (97.1%) of 1 339 260. The\ncumulative distribution function of sequence lengths is shown\nin Fig. S1.† A subset of 100K records, hereinaer referred to as\nUSPTO-ORD-100K, is randomly selected from the 1 300 613\nrecords. Unless otherwise specied, a random 8 : 1 : 1 train :\nvalidation : test split is applied to USPTO-ORD-100K to train/\nevaluate models throughout this study. This data pipeline is\nschematically shown in Fig. 1.\nThe information in a structured ORD record is not guaranteed\nto be a proper subset of its free text description, as some infor-\nmation in the structured ORD record is derived from elsewhere,\nand in this work denoted“implicit information”. For example,\nthe reaction roles of compounds are rarely stated in a reaction's\ntext description. As another example, the text description may\nindicate altration step (mapping to a ReactionWorkup of type\nFILTRATION in its ORD record) but does not include“lter” or\n“ltration” explicitly, e.g., “passing through celite”. We consider\nthis kind of implicit information learnable and therefore do not\nexclude them from ORD records. On the other hand, some\nimplicit information is considered unlearnable and thus\nexcluded from the ORD records. Specically,\nFig. 2 (Top) The original text description of a reaction procedure and (bottom) example messages within the structured ORD reaction record.43\n1824 | Digital Discovery,2 0 2 4 ,3,1 8 2 2–1831 © 2024 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 31 July 2024. Downloaded on 11/5/2025 2:28:00 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\n/C15 Unspecied outcome: if the name of a product is present in\nthe ORD record and is not explicitly stated in the reaction text,\nthis name is removed from the ORD record. This could happen\nwhen the product name is dened only in the title of the cor-\nresponding patent and not mentioned explicitly in the proce-\ndure text. This can also happen for reactants when they are\nreferred to by compound identiers or generic names.\n/C15 Calculated yield: if the yield value of a product is present in\nthe ORD record and its integer value is not explicitly stated in\nthe reaction text, this value is removed from the ORD record.\nThis can occur when the calculated yield is diﬀerent from the\nyield reported in the procedure text.\n2.3 LLaMA ne-tuning procedure\nLLaMA is a collection of decoder-only modelsrst released in\nFebruary 2023 by Meta AI,\n47 with an updated version LLaMA-2\n(released in July 2023).48 LLaMA models are convenient foun-\ndational models for scientic communities because they are\npre-trained using publicly available data only, have parameter\nsizes ranging from 7 billion to 70 billion, and are distributed\nwith both model weights and training code under an open-\nsource license. We select LLaMA-2-7B in this study forne-\ntuning due to memory considerations. We note the pretrain-\nnetune paradigm is not exclusive to LLaMA nor the decoder-\nonly models, and other large language models are also\namenable to this task. Further performance improvements are\nlikely possible by adopting a diﬀerent pretrained model.\nTo avoid tuning the entire 7 billion parameters in LLaMA-2-\n7B, we adopt LLaMA-Adapter in ourne-tuning procedure.\n49\nLLaMA-Adapter achieves parameter-eﬃcient ne-tuning using\nlearnable adaption prompts: for each of the topmostL trans-\nformer layers, a learnable prompt of lengthK is prepended to\nthe (embedded) word tokens. This procedure reduces the total\nnumber of trainable parameters toK × L × C, where C is the\ntoken embedding dimensions, set to 4096 by default in LLaMA.\nThroughout this study,K = 10 and L = 30, giving 1.2 million\ntrainable parameters that cant in a GPU of 24 GB memory in\nhalf precision.\nThe train and validation datasets from the aforementioned\nrandom split are used forne-tuning LLaMA-2-7B. The valida-\ntion set is used to monitor the training process and to deter-\nmine the number of training epochs with early stopping. Fine-\ntuning LLaMA-2-7B for 15 epochs with an initial learning rate\nof 7 × 10\n−5 was completed in approximately 70 hours using 2\nNVIDIA RTX 4090 GPUs. In contrast, preparing the ORD data-\nsets (in .pb.gz format) to obtain USPTO-ORD-100K took\napproximately 4 hours using our scripts with a 16-core 4.70 GHz\nCPU (Intel® i7-1260P). The average inference speed was roughly\n37 token per second as estimated over 100 generations on one\nRTX 4090 GPU with batch size set to 1. This model is referred to\nas “the ne-tuned model” throughout this study. The hyper-\nparameters forne-tuning were not optimized.\n2.4 Evaluation protocol and metrics\nText descriptions of reaction records from the test set of USPTO-\nORD-100K are passed to thene-tuned LLaMA-2-7B to generate\nstructured data as text completions for model evaluation.\nBecause a Reaction message consists of nested sub-messages\n(or “objects” in JSON terminology), such as Compound and\nReactionWorkup, we can dene evaluation tasks based on the\ncomparison between the ground truth and LLM-inferred Reac-\ntion at the message level: Evaluation Metric 1. For a given\nmessage type, how many messages of this message type are\naccurately extracted or erroneously added, removed, or altered?\nFig. 3 shows an example of Evaluation Metric 1 when\ncomparing two ReactionInput messages given the message type\nof Compound messages. To distinguish the three failure modes,\nwe rst dene a distance function for the given message type\nbased on DeepDistance,\n50 an edit distance similar to Lev-\nenshtein distance designed for nested objects. When\ncomparing two lists of messages (the shorter list is padded with\nempty messages such that two lists are of equal sizes), a bijec-\ntive mapping between messages from two lists is found by\nminimizing the distance sum of all pairs, which is then used to\nidentify the aforementioned failure modes.\nSince a message always has a tree structure, we can also\ndene evaluation tasks at the leaf level, where a leaf corre-\nsponds to an unstructured, literaleld: Evaluation Metric 2. For\na given message type, how many leafelds of messages of this\nmessage type are accurately extracted or erroneously added,\nremoved, or altered?\nWe note that Evaluation Metric 1 is de ned at a lower\ngranularity and is more stringent than Evaluation Metric 2, as\nsummarized in Table 1. For example, in the case shown in\nFig. 3, an entire compound message (blue) is marked as altered,\nwhile only two leaf elds (underscored) are considered as\n“Alteration” (value), and “Addition” (reaction_role), respec-\ntively. Assigning “Addition” and “Removal” to leaf elds also\ndepends on the assignment at the message level, for example,\nwhen a message is assigned“Removal”, all of its leafelds are\nassigned “Removal”.\nIt could be reasonable to use a numerical error measure to\nevaluate eld-level extraction. This is because for certain\ndownstream tasks, such as reaction condition recommenda-\ntion, one could argue that mis-extracted elds containing\noating point numbers will have a less deleterious eﬀect on\nperformance if they are close to the true value. However, we\nprefer the strict evaluation of exact-match accuracy for the\ninformation extraction task used here as sometimes missing or\nmisplacing a number can happen more frequently than\nextracting a wrong number. This is reected in an analysis on\nextracting reaction temperature values (ESI Section S7†).\n3 Results and discussion\n3.1 Quantitative model evaluation\nThe ne-tuned LLaMA-2-7B model is evaluated against the test\nset from the random 8 : 1 : 1 train–validation–test split of\nUSPTO-ORD-100K. Out of the 10K model outputs (completions),\nonly 42 (0.4%) of them are invalid JSON records, and 59 (0.6%)\nof them are invalid ORD records. Note the former is a suﬃcient\ncondition for the latter. All of the 42 syntactically JSON invalid\ncompletions can be “repaired” by heuristic string operations,\n© 2024 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 4 ,3,1 8 2 2–1831 | 1825\nPaper Digital Discovery\nOpen Access Article. Published on 31 July 2024. Downloaded on 11/5/2025 2:28:00 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nsuch as adding missing quotes or commas, using jsonrepair.51\nAer repairing, 9963 (99.6%) valid ORD records are collected.\nThese results indicate that thene-tuned model successfully\nlearns the syntax of the ORD's structured data schema during\ntraining.\nTable 2 summarizes the evaluation results at the message\nlevel (Evaluation Metric 1). The ne-tuned model is able to\nextract compound information for ReactionInput entries reli-\nably with an accuracy of 85.6%. Compared with missing\ncompound information in ReactionInput (5.0%, failure mode\n“Removal”), it is relatively rare (2.3%) for the model to include\nexcess compounds (failure mode“Addition”), and almost all of\nthe excess compounds come from misplacement (e.g., a Pro-\nductCompound is placed in ReactionInput) instead of\nhallucination.\nErrors in extracting ProductCompound entries are more\nfrequent, as indicated by a lower accuracy of 71.3%. Upon\ninspection, we noticed the errors mainly originate from implicit\ninformation: some elds of a ProductCompound message are\nnot explicitly stated in the text description and are instead\nderived or inferred. One example is the“calculated” reaction\nyield, in contrast to the “reported” reaction yield which the\nmodel can capture successfully (Table S2†). To alleviate this\neﬀect, we also report the accuracy using a more lenient routine\nfor identifying equivalent ProductCompound messages that\nconsiders two ProductCompound messages identical if all of\ntheir identiers and amount elds are identical. Theseelds\noen capture all important chemical information about reac-\ntion outcomes. Aer applying this less strict equivalence de-\nnition, the accuracy for extracting ProductCompound messages\nincreases from 71.3% to 87.1%, indicating that the model is\ncapable of chemical entity/relation extraction even if it struggles\nwith implicit calculation of yields. This routine also results in\nan increased accuracy (91.5%) for Compound messages in\nReactionInput by excluding errors in reaction role classication\n(vide infra).\nHigh accuracies of 95.7% and 90.7% are measured for\nReactionConditions and ReactionWorkup, respectively. Since\nthe ORD schema denes ReactionConditions as one single\nmessage rather than a list of messages, no “Addition” or\n“Removal” of this type of message is applicable.\nTo further understand how thene-tuned model performs in\nextracting di ﬀerent types of chemical information, the\ncompletions are examined withner granularity at the leaf level\n(Evaluation Metric 2), as shown in Table 3. The ne-tuned\nmodel shows excellent recognition capability for chemical\nentities such as compound identiers (accuracy 93.5%) and\namounts (95.2%), and it can infer reaction roles that are usually\nnot explicitly stated in procedure texts (Section 3.3). Errors at\nFig. 3 An example of Evaluation Metric 1 for when comparing two lists of Compound messages, where the ground truth denotes the already\nstructured JSON from the test set of USPTO-ORD-100K. Three failure modes at the Compound message level,“Addition”, “Removal”, and\n“Alteration” are colored green, yellow, and blue, respectively. Underscoredﬁelds denote failures at the leafﬁelds level (Evaluation Metric 2,vide\ninfra). Data shown is for illustration purposes only.\nTable 1 Comparison between Evaluation Metric 1 and 2\nMetric\nSpecict oa\nmessage type\nSpecict oa\neld type What is being counted? Granularity\n1 Yes No Added/removed/altered messages Low\n2 Yes Yes Added/removed/altered leaf elds High\n1826 | Digital Discovery,2 0 2 4 ,3,1 8 2 2–1831 © 2024 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 31 July 2024. Downloaded on 11/5/2025 2:28:00 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nthe eld-level mainly come from implicit information in Pro-\nductCompound messages, such as calculated yields (Table S1†).\nAs an alternate approach and point of comparison, we\nexplored extracting structured data with pretrained LLMs\ndirectly using the chain-of-thought prompting method,\n52 a few-\nshot training method by engineering the prompts such that\nthey mimic the thought processes of a human when solving\na complicated task. This method is easier to deploy compared to\nthe ne-tuning methods; however, it could only produce\nsyntactically correct ORD data in 408 out of 500 cases aer\nrepairing with accuracies of 61.2% and 31.3% for Compound\nand ProductCompound, respectively, indicating that chain-of-\nthought prompting without ne-tuning is likely insuﬃcient\nfor this task. This prompting method is also limited by human-\ncraed instructions and the context window of the model, and,\nconsidering there are more than 600 diﬀerent elds dened in\nORD schema, preparing examples and steps to extract a full\nReaction record seems impractical. Enabling JSON mode\nthrough OpenAI API in this process does not improve the model\nperformance (Table S4†). Details of our implementation and\nevaluation can be found in ESI.†\n3.2 Comparison to previous studies\nAs a smart chemical NER tool, thene-tuned model learned to\nrecognize cross-referencing tokens and to ignore unwanted\nchemical entities. This is reected in the comparison (Table 4)\nbetween thene-tuned model and ChemDataExtractor (version\n2.1.0),\n53,54 a toolkit for extracting chemical information mainly\nfrom scientic literature. Specically, the comparison is made\nfor the task of compound name recognition, which evaluates\nthe list of compounds (entities) extracted from a reaction. This\nlist is directly available both from the output of ChemDataEx-\ntractor and from the ORD-formatted structured data from the\nne-tuned model. While ChemDataExtractor is capable of\nrecognizing many chemical entities, it frequently fails to iden-\ntify referencing tokens, such as “desired product ” or\n“compound 322” (the “Removal” column). It also captures\nexcess chemical entities, such as“1H” from NMR reports (“the\n“Addition” column). These errors are at least partially attribut-\nable to the distribution shi in how procedures are described in\nour source text paragraphs. We also compare ourned-tuned\nmodel with a NER model based on a pre-trained BERT model,\nMatSciBERT.\n55 This NER model is trained and evaluated using\nthe same USPTO-ORD-100K dataset and is marginally better\nthan thene-tuned LLaMA model. Considering the signicantly\nlower training cost of the BERT model compared tone-tuning\nthe LLaMa model (∼10×), the former may be preferable for pure\nNER tasks.\nWe further test thene-tuned model on uniproduct reactions\nfrom the ChemRxnExtractor\n16 dataset, a set of 123 records with\nTable 2 Evaluation results at the message level (Evaluation Metric 1) for structured records extracted using theﬁne-tuned LLaMA-2-7B model.\nFor each record in the test set of USPTO-ORD-100K, an ORD-formatted JSON record is extracted from the unstructured text and evaluated\nagainst the ground truth using Evaluation Metric 1. The“Path” column denotes the root path of the corresponding messages in a reaction\nmessage. * These values were calculated using a more lenient routine detailed in the main text\nMessage type Path Accurate Removal Addition Alteration Total\nCompound Inputs 38 470 (85.6%) 2242 (5.0%) 1015 (2.3%) 4242 (9.4%) 44 954\n41 138* (91.5%) 1574 * (3.5%)\nProductCompound Outcomes 7450 (71.3%) 345 (3.3%) 58 (0.6%) 2656 (25.4%) 10 451\n9105* (87.1%) 1001 * (9.6%)\nReactionConditions Conditions 9524 (95.7%) N/A N/A 433 (4.4%) 9957\nReactionWorkup Workups 44 165 (90.7%) 1713 (3.5%) 1719 (3.5%) 2807 (5.8%) 48 685\nTable 3 Evaluation results at the leafﬁeld level (Evaluation Metric 2) for structured records extracted using theﬁne-tuned LLaMA-7B model. For\neach record in the test set of USPTO-ORD-100K, an ORD-formatted JSON record is extracted from the unstructured text and evaluated against\nthe ground truth using Evaluation Metric 2.* These ﬁelds do not belong to any of theﬁve ﬁeld types (identiﬁers, amount, reaction role, condition,\nworkup). In this dataset, all of them are leafﬁelds of ProductCompound, including texture, isolated_color, and yield-related measurements\nMessage type Field type Accurate Removal Addition Alteration Total\nProductCompound & Compound Identi ers 100 958 (93.5%) 5490 (5.1%) 2590 (2.4%) 1566 (1.5%) 108 014\nAmount 74 209 (95.2%) 3434 (4.4%) 2182 (2.8%) 300 (0.4%) 77 943\nReaction role 48 262 (89.3%) 2797 (5.2%) 1264 (2.3%) 2978 (5.5%) 54 037\nReactionConditions Condition 26 782 (98.3%) 298 (1.1%) 391 (1.4%) 176 (0.7%) 27 256\nReactionWorkup Workup 178 733 (94.0%) 8360 (4.4%) 10 189 (5.4%) 3156 (1.7%) 190 249\nOther* 31 794 (84.80%) 5261 (14.0%) 2240 (6.0%) 439 (1.2%) 37 494\nTable 4 Compound name recognition results of the ﬁne-tuned\nmodel, ChemDataExtractor, and the MatSciBert model from the test\nset of USPTO-ORD-100K. In this task, a set of compound names\n(entities) is extracted from the unstructured text and is then evaluated\nagainst the ground truth\nModel Accurate Removal Addition Alteration Total\nFine-tuned 94.9% 4.1% 2.2% 1.0% 78 408\nChemDataExtractor 76.1% 16.0% 22.7% 8.0%\nMatSciBert 96.6% 2.2% 2.4% 1.2%\n© 2024 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 4 ,3,1 8 2 2–1831 | 1827\nPaper Digital Discovery\nOpen Access Article. Published on 31 July 2024. Downloaded on 11/5/2025 2:28:00 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nlabeled tokens for compound names. All records from this\ndataset were collected from individual literature passages. These\npassages can be considered an out-of-distribution challenge to\nour ne-tuned model: they tend to be dened by general chem-\nical transformations (e.g., “oxidation of A gave B” or “cyclization\nof A aﬀorded B”) instead of specic actions in synthesis proce-\ndures, chemical amount information is rarely present, and\nnamed entities in these passages are frequently represented by\nexternally referencing tokens. As expected, thene-tuned model\nperforms poorly on this dataset, with an accuracy of 62.6% and\na tendency to include unwanted tokens (Table S1 †). Such\na tendency oen results from prioritizing chemical entities above\nreferencing tokens. For example, in “by heating tryptophan\nmethyl ester (9) at 140 °C for 3 h” the token “9” is the correct\ntoken to extract, while the ne-tuned model only recognizes\n“tryptophan methyl ester” which is a chemical entity in a more\ngeneral sense. These results suggest the ChemRxnExtractor\ndataset di ﬀers signi cantly from USPTO-ORD-100K, which\njusties ne-tuning the base LLaMA-2-7B model for the Chem-\nRxnExtractor dataset. Unfortunately, the small size of the\nChemRxnExtractor dataset makes it insuﬃcient for ne-tuning\nand subsequent evaluation (ESI Section S2†).\n3.3 Reaction role classication\nReaction role assignments that distinguish reactants, reagents,\ncatalysts, and solvents are sometimes used in downstream tasks\nsuch as reaction condition recommendation.\n56–58 The reaction\nrole of a compound is context-dependent,e.g., a chemical can\nserve as a solvent or a reactant in diﬀerent reactions, and not\nexplicitly stated in procedure text, so this is also not a pure\ninformation extraction task. However, since this implicit\ninformation is included in ne-tuning, the ne-tuned model\nlearns the conventions about role assignment in a generalizable\nway, and the inferred assignment is directly available in the\nreaction_role eld. Since each Compound message is allowed to\nhave only one reaction_role, the reaction role assignment is\na standard classication problem. While the ORD data schema\nhas more than 10 types of reaction roles de ned to cover\na variety of situations, in this dataset only three are used for\ninput compounds (CATALYST, REACTANT, SOLVENT). The\nprediction of one of these three labels for each compound\ndenes the reaction role classi cation problem (and corre-\nsponding denitions of accuracy) discussed in this section We\nexclude ProductCompound messages in this section because\nthey always have a reaction_role of PRODUCT in this dataset.\nWe also evaluate a popularity baseline that makes classication\ndecisions based on the role frequency of compounds in the\ntraining dataset; roles are uniformly randomly assigned in the\ncase of ties or unseen compounds.\nFig. 4A shows the confusion matrix of reaction role assign-\nment from the ne-tuned model for all compounds in Reac-\ntionInput from the test dataset. The classi cation accuracy\ndecreases from REACTANT to SOLVENT to CATALYST, with\na tendency to mislabel SOLVENT or CATALYST as REACTANT,\nas expected based on class populations. Compared to extracting\ncompounds of other roles (2.6% for REACTANT, 1.4% for\nSOLVENT), the model failed more frequently (4.2%) when\nextracting catalysts. Fig. 4B shows the results from the popu-\nlarity baseline with similar accuracies for SOLVENT and\nCATALYST, and lower accuracy for REACTANT compared to the\nne-tuned model. A macro-average F1 score of 86.1% is calcu-\nlated for the ne-tuned model, while the popularity baseline\ngives 63.5%. For compounds whose reaction role in the dataset\nvaries from reaction to reaction, the diﬀerence between thene-\ntuned model (Fig. 4C) and the popularity baseline (Fig. 4D)\nbecomes more pronounced: the former exhibits better perfor-\nmance for both REACTANT and CATALYST. These results\nsuggest through ne-tuning the model learned to make role\nclassications based on reaction context.\n4 Conclusion\nWe have demonstrated the application of ane-tuned LLaMA\nmodel for the extraction of structured reaction information\nFig. 4 Confusion matrices of reaction role classi ﬁcation for the\ncompounds in the test dataset using (A) theﬁne-tuned model and (B)\nthe popularity baseline. The results for compounds whose role in the\ndataset varies from reaction to reaction are shown for (C) theﬁne-\ntuned model and (D) the baseline model. Percentage values were\nnormalized using the number of true instances. In addition to three\nreaction role classes, prediction results can also be labeled as\n“MISSING”– when the corresponding compound is absent in the\nextracted ORD record, and“ERROR”– when the name of the extracted\ncompound is incorrect. Note that because the reaction role classiﬁ-\ncation depends on correct extraction of compound names, theﬁrst\ntwo rows of Fig. 4A and B share identical values. The same applies to\nthe ﬁrst two rows of Fig. 4C and D.\n1828\n| Digital Discovery,2 0 2 4 ,3,1 8 2 2–1831 © 2024 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 31 July 2024. Downloaded on 11/5/2025 2:28:00 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nfrom unstructured reaction texts from the USPTO. Thene-\ntuned model can consistently (99.6%) produce JSON records\ncomplying with the highly structured ORD data schema. The\nne-tuned model exhibits average accuracies of 91.3% for\nmessage level, and 92.3% foreld-level extractions. The ne-\ntuned model can also infer reaction roles that are not explic-\nitly stated in texts, modestly beating the popularity baseline for\nrole classication. While the model may not be accurate enough\nto be directly used in dataset preparation, it may greatly accel-\nerate information extraction compared to manual extraction,\nand simplify the job of human curators, especially for detailed,\nnested data schemas.\nAs reaction data can include additional non-textual\nelements, such as reaction schemes and tables for reporting\nconditions/yields, multi-modality models will be needed to fully\norganize unstructured data. For reaction schemes, recent\ndevelopments in theeld of optical chemical structure recog-\nnition have enabled open-source tools to accurately capture\nchemical entities from raster images. Notable examples include\nMolScribe\n59 and RxnScribe 60 developed by Barzilay and\ncoworkers, as well as ReactionDataExtractor61,62 by Wilary and\nCole. Table parsing/extraction tools have also been developed\nfor chemistry literature, such as the table parsing module in\nChemDataExtractor\n54 and OpticalTable-SQA, 63 a ne-tuned\nquestion-answering language model for table extraction. As\nmultimodal foundation models become increasingly available\nin elds beyond chemistry, it will be worth exploring their\nsuitability for reaction data extraction.\nThe obvious use of thene-tuned model is to support reac-\ntion data import to ORD with proper expert validation of the\nLLM-generated output. For example, as a postprocessing tool to\nconvert unstructured ELN reports to structured data, or\na reviewing/proofreading tool to expose as structured data what\nwould otherwise be unsearchable, such as the procedure details\nburied in supplementary materials of a journal article. Tools\npresented in this study should contribute to answering the call\nfor standardization in reaction informatics.\n1,64 As aligning\nreaction text with molecular representation has been demon-\nstrated to be helpful in prediction tasks, the tool developed in\nthis study could also serve as an auxiliary to inform reaction\npredictive models.\n65\nData availability\nThe source code for data processing, thene-tuning and eval-\nuation scripts, and allne-tuning/evaluation datasets used in\nthis study can be found at https://github.com/qai222/\nLLM_organic_synthesis. The ne-tuned model is available at\nhttps://doi.org/10.6084/m9.gshare.25485973.\nAuthor contributions\nQianxiang Ai: conceptualization, data curation, formal analysis,\ninvestigation, methodology, soware, writing – original dra\npreparation. Fanwang Meng: data curation, formal analysis.\nJiale Shi: conceptualization, methodology, soware. Brenden\nPelkie: data curation, formal analysis. Connor W. Coley: fund-\ning acquisition, supervision, writing– review & editing.\nConﬂicts of interest\nThere are no conicts of interest to declare.\nAcknowledgements\nResearch reported in this publication was supported by the\nNational Institutes of Health under award number\nU18TR004149 and by the U.S. National Science Foundation\nthrough the UW Molecular Engineering Materials Center\n(MEM-C), a Materials Research Science and Engineering Center\n(DMR-2308979). The content is solely the responsibility of the\nauthors and does not necessarily represent the oﬃcial views of\nthe National Institutes of Health or the National Science\nFoundation. The authors thank Dr Ben Blaiszik for seed fund-\ning. The authors also thank Zhengkai Tu, Dr Hassan Harb, Dr\nJacob No. Sanders, Dr Stefan Bringuier, and Marcus Schwarting\nfor helpful discussions.\nNotes and references\n1 R. Mercado, S. M. Kearnes and C. W. Coley,J. Chem. Inf.\nModel., 2023,63, 4253–4265.\n2 S. W. Gabrielson,J. Med. Libr. Assoc., 2018,106, 588–590.\n3 A. J. Lawson, J. Swienty-Busch, T. G´eoui and D. Evans, inThe\nFuture of the History of Chemical Information, American\nChemical Society, ACS Symposium Series, 2014, vol. 1164,\npp. 127–148.\n4 M. Krallinger, O. Rabal, F. Leitner, M. Vazquez, D. Salgado,\nZ. Lu, R. Leaman, Y. Lu, D. Ji, D. M. Lowe, R. A. Sayle,\nR. T. Batista-Navarro, R. Rak, T. Huber, T. Rockt ¨aschel,\nS. Matos, D. Campos, B. Tang, H. Xu, T. Munkhdalai,\nK. H. Ryu, S. Ramanan, S. Nathan, S. ˇZitnik, M. Bajec,\nL. Weber, M. Irmer, S. A. Akhondi, J. A. Kors, S. Xu, X. An,\nU. K. Sikdar, A. Ekbal, M. Yoshioka, T. M. Dieb, M. Choi,\nK. Verspoor, M. Khabsa, C. L. Giles, H. Liu,\nK. E. Ravikumar, A. Lamurias, F. M. Couto, H.-J. Dai,\nR. T.-H. Tsai, C. Ata, T. Can, A. Usi´e, R. Alves, I. Segura-\nBedmar, P. Mart ´ınez, J. Oyarzabal and A. Valencia, J.\nCheminf., 2015,7, S2.\n5 M. Krallinger, O. Rabal, A. Lourenço, J. Oyarzabal and\nA. Valencia,Chem. Rev., 2017,117, 7673–7761.\n6 D. M. Lowe and R. A. Sayle,J. Cheminf., 2015,7, S5.\n7 L. Hawizy, D. M. Jessop, N. Adams and P. Murray-Rust,J.\nCheminf., 2011,3, 17.\n8 G. Papadatos, M. Davies, N. Dedman, J. Chambers,\nA. Gaulton, J. Siddle, R. Koks, S. A. Irvine, J. Pettersson,\nN. Goncharoﬀ, A. Hersey and J. P. Overington,Nucleic Acids\nRes., 2016,44, D1220–D1228.\n9 NextMove So warejPistachio, https://\nwww.nextmovesoware.com/pistachio.html.\n10 E. Pan, S. Kwon, Z. Jensen, M. Xie, R. G´omez-Bombarelli,\nM. Moliner, Y. Rom´an-Leshkov and E. Olivetti, ACS Cent.\nSci., 2024, 729–743.\n© 2024 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 4 ,3,1 8 2 2–1831 | 1829\nPaper Digital Discovery\nOpen Access Article. Published on 31 July 2024. Downloaded on 11/5/2025 2:28:00 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\n11 J. Laﬀerty, A. McCallum, F. Pereira,et al., Icml, 2001, 3.\n12 T. Rockt¨aschel, M. Weidlich and U. Leser, Bioinformatics,\n2012, 28, 1633–1640.\n13 L. Luo, Z. Yang, P. Yang, Y. Zhang, L. Wang, H. Lin and\nJ. Wang,Bioinformatics, 2018,34, 1381–1388.\n14 W. Hemati and A. Mehler,J. Cheminf., 2019,11,3 .\n15 Z. Zhai, D. Q. Nguyen, S. Akhondi, C. Thorne,\nC. Druckenbrodt, T. Cohn, M. Gregory and K. Verspoor,\nProceedings of the 18th BioNLP Workshop and Shared Task,\nFlorence, Italy, 2019, pp. 328–338.\n16 J. Guo, A. S. Ibanez-Lopez, H. Gao, V. Quach, C. W. Coley,\nK. F. Jensen and R. Barzilay,J. Chem. Inf. Model., 2022, 62,\n2035–2045.\n17 T. Isazawa and J. M. Cole,J. Chem. Inf. Model., 2022, 62,\n1207–1213.\n18 T. Almeida, R. Antunes, J. F. Silva, J. R. Almeida and S. Matos,\nDatabase, 2022,2022, baac047.\n19 A. Trewartha, N. Walker, H. Huo, S. Lee, K. Cruse,\nJ. Dagdelen, A. Dunn, K. A. Persson, G. Ceder and A. Jain,\nPatterns, 2022,3, 100488.\n20 R. Hoﬀmann, C. Zhang, X. Ling, L. Zettlemoyer and\nD. S. Weld, Proceedings of the 49th Annual Meeting of the\nAssociation for Computational Linguistics: Human Language\nTechnologies, Portland, Oregon, USA, 2011, pp. 541–550.\n21 S. Riedel, L. Yao and A. McCallum,Machine Learning and\nKnowledge Discovery in Databases, Berlin, Heidelberg, 2010,\npp. 148–163.\n22 X. Zeng, D. Zeng, S. He, K. Liu and J. Zhao,Proceedings of the\n56th Annual Meeting of the Association for Computational\nLinguistics, volume 1: Long Papers , Melbourne, Australia,\n2018, pp. 506–514.\n23 M. Miwa and M. Bansal, End-to-End Relation Extraction\nusing LSTMs on Sequences and Tree Structures, in\nProceedings of the 54th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) ,\nAssociation for Computational Linguistics, Berlin,\nGermany, 2016, pp. 1105–1116, DOI:10.18653/v1/P16-1105.\n24 P.-L. Huguet Cabot and R. Navigli,Findings of the Association\nfor Computational Linguistics: EMNLP 2021 , Punta Cana,\nDominican Republic, 2021, pp. 2370\n–2381.\n25 M. Eberts and A. Ulges,Proceedings of the 16th Conference of\nthe European Chapter of the Association for Computational\nLinguistics: Main Volume, 2021, pp. 3650–3660.\n26 R. Luo, L. Sun, Y. Xia, T. Qin, S. Zhang, H. Poon and T.-Y. Liu,\nBriengs Bioinf., 2022,23, bbac409.\n27 M. Ansari and S. M. Moosavi, Agent-based Learning of\nMaterials Datasets from Scientic Literature, arXiv, 2023,\npreprint, arXiv:2312.11690 [cs], http://arxiv.org/abs/\n2312.11690.\n28 S. Datta, K. Lee, H. Paek, F. J. Manion, N. Ofoegbu, J. Du,\nY. Li, L.-C. Huang, J. Wang, B. Lin, H. Xu and X. Wang,J.\nAm. Med. Inform. Assoc., 2024,31, 375–385.\n29 J. Dagdelen, A. Dunn, S. Lee, N. Walker, A. S. Rosen,\nG. Ceder, K. A. Persson and A. Jain,Nat. Commun., 2024,\n15, 1418.\n30 N. Walker, S. Lee, J. Dagdelen, K. Cruse, S. Gleason, A. Dunn,\nG. Ceder, A. Paul Alivisatos, K. A. Persson and A. Jain,Digital\nDiscovery, 2023,2, 1768–1782.\n31 M. Zhong, S. Ouyang, M. Jiang, V. Hu, Y. Jiao, X. Wang and\nJ. Han, Findings of the Association for Computational\nLinguistics: ACL 2023, Toronto, Canada, 2023, pp. 12120–\n12130.\n32 M. Zhong, S. Ouyang, Y. Jiao, P. Kargupta, L. Luo, Y. Shen,\nB. Zhou, X. Zhong, X. Liu, H. Li, J. Xiao, M. Jiang, V. Hu,\nX. Wang, H. Ji, M. Burke, H. Zhao and J. Han,Proceedings\nof the 2023 Conference on Empirical Methods in Natural\nLanguage Processing: System Demonstrations , Singapore,\n2023, pp. 389–402.\n33 L. Patiny and G. Godin, Automatic extraction of FAIR data\nfrom publications using LLM, ChemRxiv, 2023, preprint,\nDOI: 10.26434/chemrxiv-2023-05v1b-v2.\n34 A. C. Vaucher, F. Zipoli, J. Geluykens, V. H. Nair, P. Schwaller\nand T. Laino,Nat. Commun., 2020,11, 3601.\n35 S. H. M. Mehr, M. Craven, A. I. Leonov, G. Keenan and\nL. Cronin,Science, 2020,370, 101–108.\n36 J. He, D. Q. Nguyen, S. A. Akhondi, C. Druckenbrodt,\nC. Thorne, R. Hoessel, Z. Afzal, Z. Zhai, B. Fang and\nH. Yoshikawa,Proceedings of the CLEF 2020 conference, 2020.\n37 Y. Li, B. Fang, J. He, H. Yoshikawa, S. A. Akhondi,\nC. Druckenbrodt, C. Thorne, Z. Afzal, Z. Zhai and\nT. Baldwin,CLEF (Working Notes), 2021, 693–709.\n38 Y. Li, B. Fang, J. He, H. Yoshikawa, S. A. Akhondi,\nC. Druckenbrodt, C. Thorne, Z. Afzal, Z. Zhai and\nK. Machi,CLEF (Working Notes)\n, 2022, pp. 758–781.\n39 D. Lowe, Chemical reactions from US patents (1976-\nSep2016), 2017, https://gshare.com/articles/dataset/\nChemical_reactions_from_US_patents_1976-Sep2016_/\n5104873.\n40 S. M. Kearnes, M. R. Maser, M. Wleklinski, A. Kast,\nA. G. Doyle, S. D. Dreher, J. M. Hawkins, K. F. Jensen and\nC. W. Coley,J. Am. Chem. Soc., 2021,143, 18820–18826.\n41 Craiyon, A llama with a square academic cap, https://\nwww.craiyon.com/.\n42 K. M. Jablonka, Q. Ai, A. Al-Feghali, S. Badhwar,\nJ. D. Bocarsly, A. M. Bran, S. Bringuier, L. C. Brinson,\nK. Choudhary, D. Circi, S. Cox, W. A. d. Jong, M. L. Evans,\nN. Gastellu, J. Genzling, M. V. Gil, A. K. Gupta, Z. Hong,\nA. Imran, S. Kruschwitz, A. Labarre, J. L´ala, T. Liu, S. Ma,\nS. Majumdar, G. W. Merz, N. Moitessier, E. Moubarak,\nB. Mouriño, B. Pelkie, M. Pieler, M. C. Ramos, B. Rankovi´c,\nS. G. Rodriques, J. N. Sanders, P. Schwaller, M. Schwarting,\nJ. Shi, B. Smit, B. E. Smith, J. V. Herck, C. Völker, L. Ward,\nS. Warren, B. Weiser, S. Zhang, X. Zhang, G. A. Zia,\nA. Scourtas, K. J. Schmidt, I. Foster, A. D. White and\nB. Blaiszik,Digital Discovery, 2023,2, 1233–1250.\n43 R. Hammond Jr, Apparatus detachably attachable toshing\npoles for holding and dispensing semi-liquids, 1993,https://\npatents.google.com/patent/US5242088A/en?\noq=US07985863B2A.\n44 Open Reaction Database, ord-schema, https://github.com/\nopen-reaction-database/ord-schema/blob/\n1830 | Digital Discovery,2 0 2 4 ,3,1 8 2 2–1831 © 2024 The Author(s). Published by the Royal Society of Chemistry\nDigital Discovery Paper\nOpen Access Article. Published on 31 July 2024. Downloaded on 11/5/2025 2:28:00 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online\nec1ac7965e79e0165ecc3549af7ee8a31c2725a0/proto/\nreaction.proto.\n45 S. Kearnes, CML to ORD parser,https://github.com/open-\nreaction-database/ord-schema/blob/\n81ﬀ0943538364722c4ca82d66b24c4361644b56/ord_schema/\nscripts/parse_uspto.py.\n46 R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin,\nP. Liang and T. B. Hashimoto, Stanford Alpaca: An\nInstruction-following LLaMA model, Publication Title:\nGitHub repository, 2023, https://github.com/tatsu-lab/\nstanford_alpaca.\n47 H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,\nT. Lacroix, B. Rozi `ere, N. Goyal, E. Hambro, F. Azhar,\nA. Rodriguez, A. Joulin, E. Grave and G. Lample, LLaMA:\nOpen and Eﬃcient Foundation Language Models, arXiv,\n2023, preprint, arXiv:2302.13971 [cs], http://arxiv.org/abs/\n2302.13971.\n48 H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi,\nY. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale,\nD. Bikel, L. Blecher, C. C. Ferrer, M. Chen, G. Cucurull,\nD. Esiobu, J. Fernandes, J. Fu, W. Fu, B. Fuller, C. Gao,\nV. Goswami, N. Goyal, A. Hartshorn, S. Hosseini, R. Hou,\nH. Inan, M. Kardas, V. Kerkez, M. Khabsa, I. Kloumann,\nA. Korenev, P. S. Koura, M.-A. Lachaux, T. Lavril, J. Lee,\nD. Liskovich, Y. Lu, Y. Mao, X. Martinet, T. Mihaylov,\nP. Mishra, I. Molybog, Y. Nie, A. Poulton, J. Reizenstein,\nR. Rungta, K. Saladi, A. Schelten, R. Silva, E. M. Smith,\nR. Subramanian, X. E. Tan, B. Tang, R. Taylor, A. Williams,\nJ. X. Kuan, P. Xu, Z. Yan, I. Zarov, Y. Zhang, A. Fan,\nM. Kambadur, S. Narang, A. Rodriguez, R. Stojnic,\nS. Edunov and T. Scialom, Llama 2: Open Foundation and\nFine-Tuned Chat Models, arXiv, 2023, preprint,\narXiv:2307.09288 [cs],http://arxiv.org/abs/2307.09288.\n49 R. Zhang, J. Han, C. Liu, P. Gao, A. Zhou, X. Hu, S. Yan, P. Lu,\nH. Li and Y. Qiao, LLaMA-Adapter: Eﬃcient Fine-tuning of\nLanguage Models with Zero-init Attention, arXiv, 2023,\npreprint, arXiv:2303.16199 [cs], http://arxiv.org/abs/\n2303.16199.\n50 S. Dehpour, seperman/deepdiﬀ, 2024, https://github.com/\nseperman/deepdiﬀ, original-date: 2014-09-26T03:21:47Z.\n51 J. d. Jong, josdejong/jsonrepair, 2024, https://github.com/\njosdejong/jsonrepair, original-date: 2020-11-02T16:05:02Z.\n52 J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia,\nE. Chi, Q. Le and D. Zhou, Chain-of-Thought Prompting\nElicits Reasoning in Large Language Models,arXiv, 2023,\npreprint, arXiv:2201.11903 [cs], http://arxiv.org/abs/\n2201.11903.\n53 M. C. Swain and J. M. Cole,J. Chem. Inf. Model., 2016, 56,\n1894–1904.\n54 J. Mavraˇci´c, C. J. Court, T. Isazawa, S. R. Elliott and\nJ. M. Cole,J. Chem. Inf. Model., 2021,61, 4280–4289.\n55 T. Gupta, M. Zaki, N. A. Krishnan and Mausam,npj Comput.\nMater., 2022,8, 102.\n56 H. Gao, T. J. Struble, C. W. Coley, Y. Wang, W. H. Green and\nK. F. Jensen,ACS Cent. Sci., 2018,4, 1465–\n1476.\n57 A. M. ˙Zura´nski, J. I. Martinez Alvarado, B. J. Shields and\nA. G. Doyle,Acc. Chem. Res., 2021,54, 1856–1865.\n58 V. Voinarovska, M. Kabeshov, D. Dudenko, S. Genheden and\nI. V. Tetko,J. Chem. Inf. Model., 2024,64,4 2–56.\n59 Y. Qian, J. Guo, Z. Tu, Z. Li, C. W. Coley and R. Barzilay,J.\nChem. Inf. Model., 2023,63, 1925–1934.\n60 Y. Qian, J. Guo, Z. Tu, C. W. Coley and R. Barzilay,J. Chem.\nInf. Model., 2023,63, 4030–4041.\n61 D. M. Wilary and J. M. Cole,J. Chem. Inf. Model., 2021, 61,\n4962–4974.\n62 D. M. Wilary and J. M. Cole,J. Chem. Inf. Model., 2023, 63,\n6053–6067.\n63 J. Zhao, S. Huang and J. M. Cole,J. Chem. Inf. Model., 2023,\n63, 1961–1981.\n64 P. Baldi,J. Chem. Inf. Model., 2022,62, 2011–2014.\n65 Y. Qian, Z. Li, Z. Tu, C. Coley and R. Barzilay,Proceedings of\nthe 2023 Conference on Empirical Methods in Natural Language\nProcessing, Singapore, 2023, pp. 12731–12745.\n© 2024 The Author(s). Published by the Royal Society of Chemistry Digital Discovery,2 0 2 4 ,3,1 8 2 2–1831 | 1831\nPaper Digital Discovery\nOpen Access Article. Published on 31 July 2024. Downloaded on 11/5/2025 2:28:00 PM. \n This article is licensed under a \nCreative Commons Attribution 3.0 Unported Licence.\nView Article Online",
  "topic": "Schema (genetic algorithms)",
  "concepts": [
    {
      "name": "Schema (genetic algorithms)",
      "score": 0.7362972497940063
    },
    {
      "name": "Computer science",
      "score": 0.6996718049049377
    },
    {
      "name": "Natural language processing",
      "score": 0.5172824859619141
    },
    {
      "name": "Open source",
      "score": 0.49838852882385254
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4149266183376312
    },
    {
      "name": "Information retrieval",
      "score": 0.37070339918136597
    },
    {
      "name": "Programming language",
      "score": 0.33023810386657715
    },
    {
      "name": "Database",
      "score": 0.3287743926048279
    },
    {
      "name": "Software",
      "score": 0.07857587933540344
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I63966007",
      "name": "Massachusetts Institute of Technology",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I201448701",
      "name": "University of Washington",
      "country": "US"
    }
  ],
  "cited_by": 17
}