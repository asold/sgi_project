{
    "title": "Artificial Intelligence in Academic Translation: A Comparative Study of Large Language Models and Google Translate",
    "url": "https://openalex.org/W4394814366",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2258697334",
            "name": "Mohammed Mohsen",
            "affiliations": [
                "Najran University"
            ]
        },
        {
            "id": "https://openalex.org/A2258697334",
            "name": "Mohammed Mohsen",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2553176868",
        "https://openalex.org/W4389437528",
        "https://openalex.org/W4382775625",
        "https://openalex.org/W2154238592",
        "https://openalex.org/W4386249236",
        "https://openalex.org/W6730267373",
        "https://openalex.org/W2163423754",
        "https://openalex.org/W2014247439",
        "https://openalex.org/W3144451117",
        "https://openalex.org/W4230831858",
        "https://openalex.org/W4365516555",
        "https://openalex.org/W4360620450",
        "https://openalex.org/W4385448543",
        "https://openalex.org/W2146161677",
        "https://openalex.org/W1991599773",
        "https://openalex.org/W4365512576",
        "https://openalex.org/W4391958362",
        "https://openalex.org/W2594229957",
        "https://openalex.org/W4387782591",
        "https://openalex.org/W4210276879",
        "https://openalex.org/W2251526099",
        "https://openalex.org/W4385191065",
        "https://openalex.org/W2251187191",
        "https://openalex.org/W3016364508",
        "https://openalex.org/W2888442053"
    ],
    "abstract": "Purpose. The advent of Large Language Model (LLM), a generative artificial intelligence (AI) model, in November 2022 has had a profound impact on various domains, including the field of translation studies. This motivated this study to conduct a rigorous evaluation of the effectiveness and precision of machine translation, represented by Google Translate (GT), in comparison to Large Language Models (LLMs), specifically ChatGPT 3.5 and 4, when translating academic abstracts bidirectionally between English and Arabic. Methods. Employing a mixed-design approach, this study utilizes a corpus comprising 20 abstracts sourced from peer-reviewed journals indexed in the Clarivate Web of Science, specifically the Journal of Arabic Literature and Al-Istihlal Journal. The abstracts are equally divided to represent both English-Arabic and Arabic-English translation directionality. The study’s design is rooted in a comprehensive evaluation rubric adapted from Hurtado Albir and Taylor (2015), focusing on semantic integrity, syntactic coherence, and technical adequacy. Three independent raters carried out assessments of the translation outputs generated by both GT and LLM models. Results. Results from quantitative and qualitative analyses indicated that LLM tools significantly outperformed MT outputs in both Arabic and English translation directions. Additionally, ChatGPT 4 demonstrated a significant advantage over ChatGPT 3.5 in Arabic-English translation, while no statistically significant difference was observed in the English-Arabic translation directionality. Qualitative analysis findings indicated that AI tools exhibited the capacity to comprehend contextual nuances, recognize city names, and adapt to the target language's style. Conversely, GT displayed limitations in handling specific contextual aspects and often provided literal translations for certain terms.",
    "full_text": "Psycholinguistics (2024), 35 (2), 134–156\n134 psycholing-journal.com\nISSN  2309-1797 (print) / 2415-3397 (online) \nhttps://doi.org/10.31470/2309-1797-2024-35-2-134-156 UDC 81’23\nArtificial Intelligence in Academic Translation: \nA Comparative Study of Large Language \nModels and Google Translate *\nШтучний інтелект в академічному перекладі: \nПорівняльне дослідження великих \nмовних моделей та Google Translate **\nMohammed Ali Mohsen\nPh.D. in Linguistics,\nProfessor of Applied linguistics\nМохаммед Алі Мохсен\nдоктор філософії в галузі\nлінгвістики, професор у галузі \nприкладної лінгвістики\nE-mail: mmohsen1976@gmail.com\nmamohsen@nu.edu.sa\nhttps://orcid.org/0000-0003-3169-102X\nNajran University \n(Saudi Arabia)\n King Abdulaziz Street, \nNajran, Kingdom of  Saudi Arabia, \n66251\nУніверситет Наджран \n(Саудівська Аравія)\n вул. Короля Абдулазиза, \nНаджран, Саудівська Аравія, \n66251\nOriginal manuscript received December 15, 2023\nRevised manuscript accepted March 18, 2024\n* **\n* This research received grant no. (15/2023) from the Arab Observatory for Translation \n(an affiliate of ALECSO), which is supported by the Literature, Publishing & Translation \nCommission in Saudi Arabia.\n** Це дослідження отримало грант № (15/2023) від Арабської обсерваторії перекладу \n(філії ALECSO), яку підтримує Комісія з питань літератури, видавничої справи та \nперекладу Саудівської Аравії.\nArtificial Intelligence in Academic Translation...\n135\n© Mohsen, M.\nABSTRACTS\nPurpose. The advent of Large Language Model (LLM), a generative artificial \nintelligence (AI) model, in November 2022 has had a profound impact on various \ndomains, including the field of translation studies. This motivated this study \nto conduct a rigorous evaluation of the effectiveness and precision of machine \ntranslation, represented by Google Translate (GT), in comparison to Large Language \nModels (LLMs), specifically ChatGPT 3.5 and 4, when translating academic abstracts \nbidirectionally between English and Arabic.\nMethods. Employing a mixed-design approach, this study utilizes a corpus \ncomprising 20 abstracts sourced from peer-reviewed journals indexed in the Clarivate \nWeb of Science, specifically the Journal of Arabic Literature and Al-Istihlal Journal. \nThe abstracts are equally divided to represent both English-Arabic and Arabic-\nEnglish translation directionality. The study’s design is rooted in a comprehensive \nevaluation rubric adapted from Hurtado Albir and Taylor (2015), focusing on \nsemantic integrity, syntactic coherence, and technical adequacy. Three independent \nraters carried out assessments of the translation outputs generated by both GT \nand LLM models.\nResults. Results from quantitative and qualitative analyses indicated that LLM tools \nsignificantly outperformed MT outputs in both Arabic and English translation directions. \nAdditionally, ChatGPT 4 demonstrated a significant advantage over ChatGPT 3.5 in \nArabic-English translation, while no statistically significant difference was observed \nin the English-Arabic translation directionality. Qualitative analysis findings indicated \nthat AI tools exhibited the capacity to comprehend contextual nuances, recognize city \nnames, and adapt to the target language’s style. Conversely, GT displayed limitations \nin handling specific contextual aspects and often provided literal translations for \ncertain terms.\nKey words: ChatGPT, Machine Translation, Google Translate, articles’ abstract.\nIntroduction\nThe rapid advancement of technology has had a profound impact \non various aspects of human life, including the field of translation \nstudies. For many years, researchers, as highlighted by Quah (2006), \nhave been striving to automate the translation process, aiming to \nconvert text from a source language (SL) to a target language (TL). \nHowever, this endeavor has been challenged by the complexity of \nhuman language, which includes nuances and idiomatic expressions \nunique to each language. These challenges have led to doubts regarding \nthe effectiveness of machine translation (MT). In fact, historical \nrecords, such as the PAALC report from the 1960s, cautioned against \nШтучний інтелект в академічному перекладі...\n136\n©  Мохсен, М.\nthe use of MT due to its limitations in accurately conveying intended \nmeanings. The emergence of Statistical Machine Translation (SMT) in \nthe late 1980s rekindled optimism in the field, suggesting that while MT \nmight not achieve perfect accuracy, it could still serve as a useful tool \nrequiring human intervention for quality assurance. The landscape of \nMT underwent a transformative change with the introduction of Neural \nMachine Translation (NMT) by Google in 2016. Utilizing advanced \nnatural language processing techniques, NMT significantly enhanced the \nquality of translated text. This paradigm shift led to a transition from \na Computer-Assisted Translation (CAT) model to a Machine-Assisted \nHuman Translation (MAHT) model, positioning technology as the \nprincipal agent in the translation process (Mohsen et al., 2023). In recent \nyears, the advent of Large Language Model (LLM), particularly the \nGenerative Pre-trained Transformer (ChatGPT) developed by OpenAI, \nhas further revolutionized the field (Baidoo-Anu & Ansah, 2023; \nLyu et al., 2023). Initially designed as a conversational interface, \nChatGPT has demonstrated a wide array of functionalities beyond \ndialogic interactions, including translation capabilities (Hendy et al., \n2023). The launch of the new AI tool has motivated the researchers to \ninvestigate its efficacy in terms of translating academic genre. Given \nthe potentials of AI and Google translate to automate translating texts \nand the variability across type of language and text genre, the current \nstudy aims to evaluate their efficacy in aiding the English to Arabic \ntranslation process. By identifying their strengths and limitations, \nthis study offers valuable insights to translators on optimizing their \nworkflow. Furthermore, pinpointing areas for improvement in AI and \nMT will not only enhance their utility but also contribute to the broader \ndiscourse in translation studies. This investigation thus serves a dual \npurpose: facilitating immediate practical applications and informing \nfuture technological advancements in the field. Therefore, the current \nstudy aims to address the following research question:\nRQ 1. How do the translational outputs of ChatGPT and Google \nTranslate compare in terms of good quality translated \noutputs when translating academic abstracts between Arabic \nand English?\nArtificial Intelligence in Academic Translation...\n137\n© Mohsen, M.\nLiterature Review\nAI Affordances and Limitations\nOver the past several decades, Artificial Intelligence (AI) has \nundergone transformative developments, culminating in sophisticated \nalgorithms that address intricate problems and streamline human \nendeavors (Hossain, 2023). A salient manifestation of this progress \nlies in the realm of MT, which utilizes advanced computational \nmodels to transcribe textual or auditory content from one language to \nanother (Sennrich et al., 2017; Vaswani et al., 2018). This sector has \nparticularly benefited from the infusion of deep learning paradigms \n(Goodfellow et al., 2016). Fundamentally, AI architectural design \nis anchored in the seminal Transformer model by (Vaswani et al., \n2018), a blueprint that has been pivotal in shaping contemporary MT \ntechnologies. This is exemplified by Google's Transformer-based Neural \nMachine Translation system (GNMT), which attests to the model's \nscalability and efficiency (Wu et al., 2018). In its operational schema, \nChatGPT adopts a comprehensive data-driven methodology, assimilating \na diverse corpus spanning numerous linguistic styles and thematic \ndomains (Malik et al., 2023). While this renders ChatGPT a versatile \ninstrument for translation endeavors, it is imperative to acknowledge \nthat ChatGPT lacks adequacy in providing a good text outputs for \nlow-sources languages and sometimes generate subtle word-level \nhallucinations (Hendy et al., 2023). This issue motivates the researcher \nto investigate how different MT tools treated Arabic academic texts, \nbeing a low-sourced language (Islam et al., 2021) to English, and in \nreturn, how English texts would be translated into Arabic.\nMT systems like Google Translate, which has been thoroughly \ninvestigated in translation studies literature, have demonstrated efficacy \nin real-time text-based interactions and broad language coverage \n(Jiao et al., 2023). Recent research indicates that chatbot language \nmodels like ChatGPT offer unique affordances that warrant further \ninvestigation. Specifically, ChatGPT has shown competitive performance \nin translating high-resource European languages, albeit with limitations \nin low-resource languages (Jiao et al., 2023). Beyond mere translation, \nchatbots have been found to enhance user experience in various industries \nsuch as travel, tourism, and hospitality (Bulchand-Gidumal et al.). \nThey operate through a multi-step process involving natural language \nШтучний інтелект в академічному перекладі...\n138\n©  Мохсен, М.\nunderstanding, automatic response generation, and fluent language \nconstruction, offering the potential for more nuanced and context-aware \ntranslations (Suta et al., 2020). Additionally, chatbots have demonstrated \ncost and time efficiency in translational medicine (Abashev et al., 2017) \nand have even outperformed teacher counseling services in educational \nsettings (Wu et al., 2020). These unique affordances suggest that chatbot \nlanguage models could complement or even enhance existing MT \ntechnologies, making them a subject of significant academic interest.\nWhile MT and AI can help human translators to speed up \nthe translation process, it is critical to acknowledge that MT is not \nasolution for addressing the multifaceted nature of natural language. \nThe complexity of human language, which is influenced by factors such \nas text genre, contextual nuance, and the speaker or writer’s intent, poses \nconsiderable challenges for the accurate rendering of meaning through \nMT alone (Valdeón, 2023). As such, it is often imperative to involve \nhuman expertise in various MT contexts. Human intervention becomes \nindispensable for tasks like disambiguation, interpretation of idiomatic \nexpressions, and ensuring cultural sensitivity, among other complex \nlinguistic and semantic aspects that MT systems might not fully grasp \n(Hutchins, 2005). This underlines the necessity for a hybrid model that \nsynergizes both machine and human capabilities to achieve higher levels \nof accuracy and contextual relevance. Therefore, it is crucial to not \noverstate the capabilities of MT and to recognize the continuing need \nfor human expertise in ensuring the fidelity and nuanced understanding \nof translated text.\nLiterary Text and Translation\nThe literary genre is known for evoking emotion rather than \nproviding information, which requires additional reading and listening \nto be fully comprehensible (Jones, 2019). Some authors leave the \ninterpretation of their texts up to the readers, allowing them to understand \nit in their own way. This can result in multiple meanings and make \ntranslation a daunting task (Ponzio, 2007). Unlike technical translation, \nliterary translation is challenging because of the multiple meanings the \ntext contains and the various intentions that the narrators, novelists, and \npoets want to convey. As a result, it was previously believed that this \ngenre could only be handled by human translators and that any attempt \nto automate literary translation with MT would be futile. However, the \nArtificial Intelligence in Academic Translation...\n139\n© Mohsen, M.\ndevelopment of NMT has brought hope that machine can assist human \ntranslators in dealing with literary texts, although their reliability is not \nyet perfect (Sanz-Valdivieso & López-Arroyo, 2023). Literary translation \npresents unique difficulties that make it harder to automate compared \nto technical translations. According to Toral and Way (2015), literary \ntexts often require more liberal or metaphorical translations, which can \nconfuse alignment algorithms (V oigt & Jurafsky, 2012). Additionally, the \nbroader range of topics and richer vocabulary found in the literary texts \nleads to texts that are less predictable for machine translation systems \n(Toral & Way, 2015). Other factors like preserving rhyme, rhythm, \nmeter and other literary constraints, especially in poetry translation \n(Genzel et al., 2010), as well as managing dense discourse features like \nreferential cohesion (V oigt & Jurafsky, 2012) further complicate the \nprocess. In the present study, the author seeks to investigate the efficacy \nof translating abstracts of literary academic texts employing two distinct \napproaches: LLMs, exemplified by ChatGPT, and MT, exemplified \nby GT. The primary objective is to assess the effectiveness of these \nmethods and to gauge their ability to approximate the translation quality \nachieved by human translators.\nRelated Works\nWith the introduction of SMT and NMT, various attempts have \nbeen made to investigate the effectiveness and accuracy of MT in \ntranslating texts, as well as its potential to assist or even replace human \ntranslators. The nature of the text is crucial in determining whether MT \ncan be a suitable tool for human translators, as some texts are easier \nto translate while others pose more challenges. The main question here \nis whether MT can successfully translate literary texts in different or \nrelated languages, which remains a challenge for researchers.\nIn an effort to address this question, Toral and Way (2015) \nconducted a study exploring the use of SMT for literary translation \nbetween two related languages: Spanish and Catalan. Their aim was to \nassess the translatability of literary texts and evaluate the feasibility of \nusing SMT for translating novels. The authors utilized corpus analysis \nto compare the domain specificity and translation freedom of literary \nparallel texts with other domains. The findings revealed that while \ntranslating novels posed more constraints compared to news texts, it was \nless restrictive than translating technical texts. To translate a novel, the \nШтучний інтелект в академічному перекладі...\n140\n©  Мохсен, М.\nauthors adapted an ES-CA SMT system and utilized in-domain novels \nfor tuning, language modelling, and translation modelling. As a result, \nthe adapted SMT system showed an improvement of +9.38% Bilingual \nEvaluation Understudy (BLU) over a strong baseline. Further analysis \nshowed that nearly 20% of the sentences had matches at the sentence \nlevel with the human translation, with an additional 10% requiring only \nsmall edits (within 5 edits). A manual evaluation indicated that over \n60% of the MT output was rated as good as or even better than the \nprofessional translation. Toral and Way (2015) concludes that while \nSMT can assist in literary translation for related languages, challenges \nat the discourse level still need to be addressed.\nAs the launch of ChatGPT was in November 2022, there is \na dearth of research studies investigating the efficacy of such tool on \nimprovement of translation studies. Several works appeared online as \npre-prints that are yet published due to the long peer review process. \nTwo preprints are related to the use of ChatGPT to the field of translation \nstudies in low-sourced languages context: Arabic and Bengali. The first \nattempt was conducted by Ghosh and Caliskan (2023) who examined \ngender bias in ChatGPT when translating between English and Bengali, \na widely spoken yet understudied language that uses gender-neutral \npronouns. Through prompts about occupations and actions, the authors \nfind ChatGPT exhibits strong implicit gender biases, associating certain \noccupations like doctor with ‘he’ and nurse with 'she'. It also associates \ncertain actions like cooking with ‘she’. ChatGPT fails to translate \nthe English gender-neutral pronoun ‘they’ properly into Bengali. The \nbiases persist even when gender information is explicitly provided \nin the prompt. Similar issues occur when translating from five other \ngender-neutral languages into English. The authors situate the biases as \nstemming from the training data and socio-technical factors privileging \nhigh-resource languages like English. They argue the biases can \nperpetuate harmful gender stereotypes and erase non-binary identities. \nThe authors call for a human-centered approach to designing translation \ntools that meaningfully involves speakers of diverse languages.\nThe second attempt was carried out by Khoshafah (2023) who \nevaluates the accuracy of ChatGPT for Arabic-English translation by \ncomparing its outputs to professional human translations across various \ntext genres like historical, literary, media, legal, and scientific. The \nresults show ChatGPT can provide accurate translations for simple \nArtificial Intelligence in Academic Translation...\n141\n© Mohsen, M.\ncontent but struggles with complex texts requiring domain knowledge \nor cultural nuance. Though generally conveying the right meaning, \nChatGPT's translations lack the precision of human translations for legal \ndocuments, medical reports, scientific studies, and literary works. The \nauthor concludes that ChatGPT is a valuable tool for basic cross-cultural \ncommunication, but limitations remain compared to human translation. \nThey offer recommendations for using ChatGPT as a translator, \nemphasizing the need for caution with technical, culturally specific, or \nhighly sensitive content, and combining it with professional translation/\nproofreading where accuracy is critical.\nWhile the previous attempts have made progress in advancing \nthe field by exploring how LLM tools can be used for translating \nlow-sourced languages like Arabic and Bengali, it is crucial to \nthoroughly investigate this in comparison to the dominant MT tool, GT. \nOur focus is to examine abstracts of academic literary texts due to their \nsuccinct yet information-rich composition and to analyze how different \ntools handle various language pair directions, such as Arabic-English \nand English-Arabic.\nMethodology\nSituated within a mixed-methods research paradigm, the \ncurrent study was explicitly designed to scrutinize the translation of \nacademic abstracts between the English and Arabic. Given the inherent \ncomplexities and specialized lexicon endemic to scholarly discourse, \nthe investigation aims to rigorously assess the fidelity and accuracy of \ntranslations produced by GT and ChatGPT. The empirical corpus for \nthis inquiry encompasses a total of 20 research article abstracts, equally \npartitioned between the translational directions of English-Arabic \nand Arabic-English. These abstracts are elicited from two scholarly \npeer-reviewed journals in Arabic literature discourse, namely, Journal \nof Arabic Literature and Al-Istihlal Journal.  Four issues were the \nrationale for selecting these specific journals as the corpus source. \nFirstly, the two journals’ main scope is to publish research examining \nArabic literary works, ensuring the originality of the SL texts and close \napproximation to the areas being investigated. Secondly, the two journals \nare distinguished for their international scope and adopting rigorous \npeer-review process, thereby enhancing scholarly credibility. Lastly, their \nШтучний інтелект в академічному перекладі...\n142\n©  Мохсен, М.\nindexing in the Clarivate Web of Science Core Collection serves as an \nadditional endorsement of the academic rigor embedded in its published \nmaterial. Fourth, the abstracts are available in the Web of Science and \ncould be downloaded to an excel sheet that to be easily scrutinized.\nData Extraction\nThe titles of the journals were inputted into the Web of Science \ndatabase to retrieve abstracts of research papers pertaining to literary \nworks associated with the Arabic language. Our focus was limited to \njournals dedicated exclusively to the examination of Arabic literature. \nAmong these journals, we specifically chose the Journal of Arabic \nLiterature, published by Brill, which features scholarly articles in \nEnglish. Additionally, we selected the Al-Istihlal journal, which publishes \narticles in Arabic, accompanied by abstracts available in both Arabic \nand English. These texts are generally dense with discipline-specific \nterminology and employ a high degree of academic formality, which \ncan serve as a reliable benchmark for assessment and might pose \na challenge for both tools. Comprehensive records, including the article \ntitles, authors, publication sources, and abstracts, were extracted and \ndownloaded in the form of an Excel spreadsheet. Regardless of their \npublication dates or the topics covered, I randomly selected 10 abstracts \nfor further analysis and examination.\nAbstracts Translation\nIn order to streamline the translation process for the selected \nabstracts, I implemented the GPT for Excel Word tool, integrating \nChat GPT 3.5-turbo for efficient automated translation. Within Excel, \nwe employed the function “GPT_translate (source text, ‘target text’)” \nto facilitate bidirectional translation between Arabic and English for \nthe two files at hand. Moreover, I leveraged Google Sheets to harness \nthe functionalities associated with GT, utilizing the specific function \n“GOOGLE_translate (source language, target language)”. Concerning \nthe use of ChatGPT 4, the abstracts were placed in the search bar \none by one using the following prompt (Please translate the following \nabstract to English/Arabic) as to keep giving the ChatGPT 4 the \ntranslation outputs. The resulting translations, including those generated \nby the LLM, and those from GT were subsequently transcribed into the \ncorresponding Excel sheets. This approach enabled us to consolidate \nArtificial Intelligence in Academic Translation...\n143\n© Mohsen, M.\nand juxtapose the translated versions alongside the original content for \ncomprehensive analysis and comparison.\nRubric and Evaluation\nTo evaluate the outputs performed by LLM and GT, the translated \ntexts were scrutinized to evaluative rubric formulated by (Hurtado Albir & \nTaylor, 2015), which emphasizes key dimensions such as adequacy of \nthe SL meaning, syntactic coherence, technical adequacy, and correct \nuse of vocabulary. Three main categories were the focus of the rubric, \nnamely, expression of the meaning of the original text (40%), which \ncontains three subcategories; the same information, the same clarity, \nand the same register. The second category entitles “Composition in the \ntarget language (40%), encompassing four subcategories, Conventions \nof written language (correct orthography and typography, V ocabulary \n(appropriateness and richness, Morphosyntax (good use of verb tenses \nand modes, prepositions, etc.), Cohesion (good use of connectors and \nreferential elements), and Coherence (ideas well organized and clearly \npresented). Details are presented in the screenshot (Appendix A). All \nthese categories were placed near the texts and scores were shown for \nraters for the purpose of assessment. Three raters were recruited to \nassess the outputs of the translated texts against the rubric. Those raters \nhave been working as instructors of translation courses, one is an Arabic \nnative speaker who is working as an assistant professor of English \nliterature, another one is MA holder of translation studies working as \na lecturer of translation studies, and a third one is an MA holder of \napplied linguistics and an expert in language assessment. To avoid hallo \neffect, texts were made anonymous in terms of the translation tools and \ninstead they were coded as evaluation 1, evaluation  2, and evaluation 3 \n(referring to GT, ChatGPt 3.5, and ChatGPT  4 respectively). The raters \nevaluated each translated abstracts based on the established rubric, and \ntheir scores were combined and averaged to run statistical analysis in \nSPSS software to identify the performance scores attributable to each \ntool. Subsequently, a qualitative examination of the types of errors \nand inadequacies are conducted, offering insights into the respective \nstrengths and limitations of ChatGPT 3.5, 4 and GT.\nData Analysis\nThis study sought to evaluate the accuracy of translations \nproduced by three different methods: GT, ChatGPT 3.5 and ChatGPT  4. \nШтучний інтелект в академічному перекладі...\n144\n©  Мохсен, М.\nThe analysis involved both descriptive data that calculate the means \nand standard deviation for all types of translated texts. Additionally, \ninferential statistical procedures were run to find out the comparisons \nbetween every type of translation. To run the data set of the current \nstudy, normal distribution of the data was run using A Shapiro-Wilk \ntest considering that the study sample was small. Consequently, \na non-parametric Kruskal-Wallis test was conducted to determine the \nperformance of three scenarios investigated in the study against the \naccuracy of the translation outputs. The scores were averaged based \non the raters’ evaluation and placed in the SPSS file. I use Paython to \nhighlight matching words that appear in every translation tool for the \ntwo genres and calculated the rate of matching words among the tools \nin general and between the two AI tools in specific (See supplementary \nmaterials B and C).\nResults\nQuantitative Analysis\nEnglish-Arabic Text Directionality\nThe initial analysis provided for the translation scores, as presented \nin Table 1. ChatGPT 4 (GPT4) recorded the highest average score \n(Med = 9.35, SD = 0.84), followed by ChatGPT 3.5 (GPT3.5) (M = 8.9, \nSD = 0.54), and GT had the lowest average score (Med = 4.75, \nSD = 0.43). This suggests a preliminary indication of the superiority of \nChatGPT 4 in translation accuracy.\nTable 1\nDescriptive and Inferential Statistics for the English Abstracts Translated \ninto Arabic\nTranslation tool Median Mean rank SE H Df P r(effect size)\nGoogle Translate 4.75 5.50 .26 21.14 2 .000 0.92\nChatGPT 3.5 8.9 16.00 .17\nChatGPT 4 9.35 25.00 .13\nTable 1 shows that there was a trajectory improvement from \nGT to ChatGPT 3.5 to ChatGPT 4. To see if the scores across tools \nwere statistically significant, a post-hoc comparison was run and \nsummarized in Table 2.\nArtificial Intelligence in Academic Translation...\n145\n© Mohsen, M.\nTable 2\nA Post-hoc Comparison of Scores of Translation Tools for English-Arabic \nDirectionality\nSample 1-Sample 2 Test \nStatistic\nStd. \nError\nStd. Test \nStatistic Sig. Effect size (r)\nChatGPT3.5-GT 10.5 3.9 2.66 .023* .84\nChatGPT4-GT 19.5 3.9 4.95 .000* .86\nChatGPT3.5-ChatGPT 4 9.0 3.9 2.28 .067 -\nFurther analysis using Kruscal Wallis with Bonferroni correction \nfor pairwise comparisons indicated significant differences between \neach pair of translation methods (see Table 2). Results showed that \nboth LLM translation tools significantly outperformed GT, H (2)=21.1, \np<.05, r= 92. Specifically, ChatGPT 3.5 statistically outscored English \ntexts translated into Arabic, as indicated by Mann-Whiteney Test \nU(N=10)= .000, z=3.72, p<.05, r=.84. Similarly, ChatGPT 4 scored \nsignificantly better that GT, U(N=10)= .000, z=3.72 p<.05, r=.86. \nHowever, there was no significant difference that was reported between \nthe scores of texts translated by ChatGPT 3.5 or ChatGPT 4.\nEnglish-Arabic Directionality\nAnother descriptive and inferential statistics were run to calculate \nthe median scores of the Arabic literary texts translated to English and to \nsee if translation tools outperform each other. Table 3 summarizes that.\nTable 3\nDescriptive and Inferential Statistics for the English Abstracts Translated \ninto English\nTranslation tool Median Mean Rank SE H Df P r(effect size)\nGoogle Translate 4.52 5.50 3.93 21.4 2 .000 0.95\nChatGPT 3.5 8.24 17.90 3.93\nChatGPT 4 9.67 23.10 3.93\nA non-parametric test, Kruskal Wallis was utilized to run the \nstatistical analysis across the texts scores. The difference between the \nmedian along with the mean ranks were significant, H(2)=24.6, p<.05, \nr=.95. Post hoc comparisons were conducted using Mann-Whitney \nTests with a Bonferroni adjusted alpha correction. The difference \nШтучний інтелект в академічному перекладі...\n146\n©  Мохсен, М.\nbetween Google Translate and ChatGPT 3.5 was statistically significant \n(U (N=10) = .00, z = 3.71, p = .000, r=84). Concerning the comparison \nbetween the performance of GT versus ChatGPT 4, results from the \nMann-Whitney Test showed significant differences, U(N=10)= .000, \nz=3.79, r=90. Likewise, results indicated a superiority of ChatGPT 4 \nperformance over ChatGPT 3.5 ( U=10), .000, z = 3.78, p = .000, r=.75). \nAgain, a post-hoc analysis was performed to see statistical significance \nover the three translation tools for Arabic-English directionality.\nTable 4\nA post-hoc Comparison of Scores of Translation Tools for Arabic-English \nDirectionality\nSample 1-Sample 2 Test \nStatistic\nStd. \nError\nStd. Test \nStatistic Sig. Effect size (r)\nChatGPT3.5-GT 12.9 3.9 3.15 .000* .84\nChatGPT4-GT 17.6 3.9 4.47 . 000* .90\nChatGPT3.5-ChatGPT 4 5.20 3.9 1.32 .002* .75\nThe results from Table 4 underscore significant differences in the \nquality of translations provided by Google Translate, ChatGPT 3.5, and \nChatGPT 4. The advanced AI models, particularly ChatGPT 4, exhibited \na notable superiority in translation accuracy over traditional machine \ntranslation tools like Google Translate. These findings not only highlight \nthe rapid advancements in AI-driven language translation but also \nemphasize the increasing effectiveness of these models in producing \ntranslations that are closer to human-level quality .\nQualitative Analysis\nTo enhance the findings from qualitative analysis, I analysed one \nabstract from each genre to find out how translation ran over every \ntranslation tool against accuracy and readability of the translation outputs \nin the target language. Given the constraints of word counts of this \narticle, I will critically examine one example from both directionalities.\nEnglish-Arabic Directionality (Example Abstract 1)\nThe abstract under scrutiny delves into the thematic realm of \nAlgerian Arabic poems known as “Buqalah,” which encapsulate \nconnotative insights into the resistance of Algerian women during the \nArtificial Intelligence in Academic Translation...\n147\n© Mohsen, M.\nFrench colonization era. In the comparative analysis of translation \noutputs across three different scenarios, a congruence of merely 22% \nwas observed, with a notably higher alignment of 40% between the two \nLLMs (refer to Appendix B for an in-depth analysis).\nA noteworthy observation is that Google Translate (GT) exhibited \nlimitations in its translational capacity, particularly in the context of \ngeographic nomenclature. Titles corresponding to city names such as \nBuqalah, Blida, Cherchell, Tlemcen, Constantine, and Algiers  were left \nuntranslated, retaining their original form in the source language (SL). \nIn stark contrast, both ChatGPT 3.5 and 4 adeptly identified and \naccurately translated these names as Algerian city titles. Furthermore, \nGT demonstrated a deficiency in converting the grammatical functions \nof certain terms. For instance, the word “morality” (a noun in English) \nwas erroneously rendered into an Arabic adjectival form شفويةby GT, \nand similarly mistranslated as شفهيةby ChatGPT 3.0. ChatGPT 4, \nhowever, adeptly translated it into the noun شفاهيةwhich aligns more \ncoherently with its usage in the Arabic academic genre.\nLiteral translations in GT were also evident, as seen in the \ntranslation of “oral literature” to الأدب الفموي an idiosyncratic rendition, \nwhereas the LLM tools offered more contextually accurate translations. \nAdditionally, a masculine bias was observed in the outputs of GT and \nChatGPT 3.5 in instances requiring a feminine pronoun, specifically in \nthe phrase “يرتبط الطقوس This gender-specific inaccuracy was notably \nabsent in the translations provided by ChatGPT 4.\nThe translation of the term “divinatory” varied across the \nplatforms, being rendered as إلهية, تنبؤand تنجيمin GT, ChatGPT 3.5, and \nChatGPT 4, respectively. Notably, ChatGPT 4's translation encapsulates \nthe contextual essence of the term more effectively, highlighting its \nadvanced comprehension and translational capabilities.\nArabic-English Directionality (Example Abstract 6)\nThe abstract in question examines a Syrian novel, which explores \nthe theme of alienation among the Syrian populace. A significant \ndistinction was observed in the treatment of the novel's title by different \ntranslation tools. GT and ChatGPT 3.5 resorted to a mere transliteration \nof the title, whereas ChatGPT 4 demonstrated a superior capability by \naccurately translating the title into English.\nIn the realm of lexical translations, GT's approach occasionally \ndeviated from conveying the intended meanings. For instance, the Arabic \nШтучний інтелект в академічному перекладі...\n148\n©  Мохсен, М.\nword “تحدثتwas translated by GT as “spoke”, which diverges from \nthe contextually appropriate meaning. In contrast, ChatGPT 3.5 and \n4 adeptly translated it as “address” and “discuss”, respectively, thus \npreserving the intended nuance. Similarly, the literal translation of “تأتي ”\nas “come” by GT was identified as inadequate, a shortcoming that was \neffectively rectified in the translations provided by the LLM tools.\nA notable discrepancy was also observed in the translation of the \nphrase “السرد الروائيGT rendered it as “narrative narration”, an awkward \nand redundant expression due to the repetition of similar words with \nonly a slight grammatical variation. ChatGPT 3.5 and 4, however, \nproficiently translated it to “narrative structure”, thereby eliminating \nthe redundancy and enhancing coherence. An additional aspect where \nGT’s limitations were apparent pertains to sentence structuring. GT \ntended to adhere to the syntactic rules of the source language (SL), \noften opting for comma separation over full stops, resulting in lengthy, \nrun-on sentences. This sharply contrasted with the translations generated \nby the LLM tools, which respected the syntactic norms of the target \nlanguage (TL), resulting in more segmented and coherent sentence \nstructures. Specifically, ChatGPT 3.5 produced an abstract comprising \nfive sentences, while ChatGPT 4 generated an abstract of six sentences.\nThe analysis of identical word matches across the three translation \ntools yielded a matching rate of 28%, while a substantially higher rate \nof 74% was observed between the AI tools. This disparity underscores \nthe enhanced accuracy and consistency of AI-based translation tools \ncompared to conventional tools like GT. Further details and analyses \ncan be found in Appendix C.\nDiscussion\nThe primary objective of the present study was to evaluate the \nproficiency of conventional translation (CT) tools and advanced artificial \nintelligence (AI) translation tools in addressing the inherent challenges \nof translating academic abstracts from literary studies. The study aimed \nto ascertain the extent to which these tools could accurately identify \nand overcome the unique difficulties posed by such texts and measure \nthe closeness of their translation outputs to human translation standards. \nThe results revealed a notable deficiency in GT, a representative of \nCT tools, particularly in its ability to comprehend contextual words \nArtificial Intelligence in Academic Translation...\n149\n© Mohsen, M.\nand nuances within academic abstracts that encompass literary styles. \nThis inadequacy was observed in translations involving both SL to \nTL and vice versa, leading to outputs that were often unreadable and \nlacked coherence. A  significant shortcoming of GT was its inability to \naccurately identify and translate many words in the TL, often resorting \nto mere transliteration. This limitation was especially pronounced in \ncases involving the titles of cities or locations, where GT failed to \ncapture the intended meaning.\nFurthermore, the study’s findings partially resonate with the \nobservations made by Toral and Way (2015). Their research highlighted \nthat MT tools generally exhibit poor performance in translating \nliterary texts, attributed primarily to the complex nature of literary \ngenres and the inherent differences between language systems. This \nstudy corroborates their findings, particularly in the context of GT \nstruggling with translations from Arabic to English. GT’s translations \nwere often constrained by the rules and stylistic elements of the SL, \nresulting in excessively long sentences or, in some cases, entire \nabstracts being condensed into a single sentence. This issue exemplifies \nGT's limitations in adapting to the structural and stylistic differences \nbetween the SL and TL. In contrast, LLM tools demonstrated superior \nperformance in translating outputs, producing nearly coherent sentences \nwhile accurately preserving the intended meanings of the SL and \nensuring readability in the TL. This can be attributed to the inherent \ncapabilities of LLMs to comprehend the contextual nuances embedded \nwithin the SL texts and effectively convey the meaning into the \ntarget texts. The exceptional performance exhibited by LLM models \ncan be attributed to extensive training aimed at enhancing translation \noutputs and overcoming the challenges encountered by LLMs. These \nconcerted efforts have contributed significantly to refining the translation \ncapabilities and improving the overall quality of LLM-based translations \n(Lyu et al., 2023).\nOur findings indicate that all of the LLM tools showcased \na significant advantage over the translation outputs generated by GT \nfor both Arabic and English academic abstracts. Notably, inaccuracies \nwere observed in the translation outputs of GT and ChatGPT 3.5 \npertaining to the feminine pronoun. Additionally, ChatGPT 3.5 exhibited \nshortcomings in recognizing the neutral pronoun “they”, which can be \nattributed to the limited availability of training data for low-resourced \nШтучний інтелект в академічному перекладі...\n150\n©  Мохсен, М.\nlanguages like Arabic. These limitations resulted in certain inaccuracies \nin the translation outputs and occasional instances of hallucination. \nArabic, similar to Bangali, has been identified as a low-resourced \nlanguage in previous studies, which may explain the difficulties faced \nby ChatGPT  3.5 in accurately identifying pronouns. However, our \nresearch highlights that ChatGPT 4 demonstrates remarkable competence \nin recognizing pronouns and subject antecedents for both Arabic \nand English translations, overcoming the aforementioned challenges \npresented by its predecessor (ChatGPT 3.5), as well as GT. The findings \nof our study align with those of Sanz-Valdivieso and López-Arroyo \n(2023) providing further support for their observations. They reported \nthat ChatGPT 3.5 generated fewer significant errors compared to GT \nwhen translating vocabulary related to olive oil and wine. These results \nreinforce the notion that ChatGPT 3.5 exhibits improved accuracy \nand proficiency in handling domain-specific terminology within \nthis particular context. This is also in line with Khoshafa’s (2023)  it \nbecomes evident that while ChatGPT 3.5 has shown improvements in \ncertain areas, it is not without its limitations. The study by Khoshafa \npoints out that, despite advancements, ChatGPT 3.5 still encounters \ndifficulties in fully comprehending complex texts and accurately \nidentifying terminologies that have cross-cultural implications. This \nsuggests that while ChatGPT3.5 has made strides in domain-specific \ntranslation, challenges remain in its ability to consistently understand \nand translate texts that involve intricate conceptual nuances or that \nbridge diverse cultural contexts.\nIn the comparative assessment of LLMs, specifically ChatGPT  3.5 \nand ChatGPT 4, a discernible superiority in performance was noted for \nChatGPT 4 in the context of translating Arabic texts into English. This \nheightened efficacy can be attributed to a multitude of factors, central \nto which is the ability of ChatGPT 4 to preserve the intended meaning, \nmaintain readability, and adhere to the academic style of the TL. This \nobservation is congruent with the research conducted by Son and Kim \n(2023), which highlighted that translations from non-English languages \nto English by ChatGPT 4 were more proficient compared to other \nMT tools such as GT and Microsoft Translator. Further supporting \nthis conclusion are the findings of Lyu et al. (2023), who noted that \ntranslations performed by ChatGPT 3.5 for low-resourced languages \noccasionally resulted in 'hallucinations' or significant inaccuracies. \nArtificial Intelligence in Academic Translation...\n151\n© Mohsen, M.\nThis phenomenon underscores the challenges inherent in translating \nlanguages with limited resources and representation in global linguistic \ndatabases. In contrast, ChatGPT 4’s enhanced performance can be largely \nascribed to the continuous evolution and improvements in AI technology \naimed at simulating human-like translation capabilities. As elucidated by \nRay (2023), key advancements contributing to this progression include \na more nuanced understanding of context, the reduction of biases, \nand refined fine-tuning capabilities. The non-identical nature of the \noutputs from both ChatGPT 3.5 and ChatGPT 4, especially in terms \nof matching rates (as detailed in the supplementary materials), further \nillustrates the evolutionary leap from the former to the latter. The high \nevaluation scores assigned by raters to ChatGPT 4’s translations attest \nto its remarkable ability to closely mirror human translation. This \nis particularly evident in its proficiency at capturing the contextual \nmeanings of the SL text and effectively navigating the complexities of \nliterary translation.\nConclusion and Limitations\nThe study presented herein focuses on assessing the accuracy \nand effectiveness of three translation tools – GT, which utilizes NTM, \nand two LLMs, ChatGPT 3.5 and 4 – in translating academic abstracts \nwithin the literary genre. Our findings reveal a significant disparity in \nperformance among these tools. GT’s outputs were generally inaccurate, \noften failing to grasp contextual phrases, resulting in unreadable \ntexts, and heavily influenced by the style of the SL. Conversely, the \nLLMs, represented by ChatGPT 3.5 and 4, demonstrated remarkable \naptitude in processing literary texts, adhering closely to the academic \nwriting conventions of the target language (TL), and significantly \noutperforming GT.\nSeveral factors underpin ChatGPT 4’s superior performance. These \ninclude its extensive training dataset and advanced algorithms, which \nare fine-tuned to understand diverse genres and handle low-resourced \nlanguages effectively. Additionally, ChatGPT 4 integrates updates \nthat refine its ability to mitigate biases and errors, particularly in \nunderrepresented languages like Arabic. The implications of our \nfindings could be particularly valuable for translator training, offering \nШтучний інтелект в академічному перекладі...\n152\n©  Мохсен, М.\ninsights into how the efficiency of various translation modes can be \nleveraged to augment the human translation process. It is important, \nhowever, to recognize that despite the advancements of LLM tools, \nhuman intervention remains crucial to refine the outputs and ensure they \naccurately convey the intended meaning of the SL.\nThe study, however, is not devoid of limitations. Firstly, the \nanalysis was based on a sample of only 10 abstracts for each language \ndirectionality. This limitation was due to the challenges in assigning \nvoluntary raters to evaluate longer texts across three different tools. \nFuture research might benefit from a larger sample size to yield more \nreliable and generalizable findings. Secondly, the study’s focus on \nliterary academic abstracts may not fully encapsulate the capabilities \nof these tools in other genres, which also warrant examination. Lastly, \nthe study's scope was restricted to a select few translation tools. For \na more comprehensive understanding of the capabilities of MT and \nLLMs, future studies should consider incorporating a broader array of \ntranslation tools to evaluate their efficacy in producing high-quality \ntranslation outputs.\nADHERENCE TO ETHICAL STANDARDS\nEthic declarations.  The study does not involve human participants or animals. \nTherefore, no IRB application was required.\nData Availability. The data supporting the findings of this study are available \nwithin the manuscript. Raw datasets generated during the current study are available \nfrom the corresponding author, Dr. Mohammed Ali Mohsen, upon reasonable request.\nFunding. This research received grant no. (15/2023) from the Arab Observatory \nfor Translation (an affiliate of ALECSO), which is supported by the Literature, \nPublishing & Translation Commission in Saudi Arabia.\nConflicts of Interest.  The authors declares no conflict of interest.\nConsent for Publication. All authors commented on previous versions of the \nmanuscript. All authors have read and approved the final version of the manuscript.\nOpen Access. This article is licensed under a Creative Commons Attribution 4.0 \nInternational License.\nReferences\nAbashev, A., Grigoryev, R., Grigorian, K., & Boyko, V . (2017). Programming Tools \nfor Messenger-Based Chatbot System Organization: Implication for Outpatient \nArtificial Intelligence in Academic Translation...\n153\n© Mohsen, M.\nand Translational Medicines. BioNanoScience, 7 (2), 403–407. https://doi.\norg/10.1007/s12668-016-0376-9\nBaidoo-Anu, D., & Ansah, L.O. (2023). Education in the era of generative artificial \nintelligence (AI): Understanding the potential benefits of ChatGPT in promoting \nteaching and learning. Journal of AI, 7 (1), 52–62. https://doi.org/10.61969/\njai.1337500\nBulchand-Gidumal, J., William Secin, E., O’Connor, P., & Buhalis, D. (2023). \nArtificial intelligence’s impact on hospitality and tourism marketing: exploring \nkey themes and addressing challenges. Current Issues in Tourism. https://doi.org/\n10.1080/13683500.2023.2229480\nGenzel, D., Uszkoreit, J., & Och, F. (2010). “Poetic” statistical machine translation: \nrhyme and meter. In Hang Li, & Lluís Màrquez (Eds.), Proceedings of the \n2010 Conference on Empirical Methods in Natural Language Processing  \n(Massachusetts, USA, 9–11 October 2010) (pp. 158–166). Cambridge, MA. \nAssociation for Computational Linguistics.\nGhosh, S., & Caliskan, A. (2023). ChatGPT Perpetuates Gender Bias in Machine \nTranslation and Ignores Non-Gendered Pronouns: Findings across Bengali and \nFive other Low-Resource Languages. arXiv preprint arXiv:2305.10510 . https://\ndoi.org/10.1145/3600211.3604672\nGoodfellow, I., Bengio, Y ., & Courville, A. (2016). Deep learning. MIT press.\nHendy, A., Abdelrehim, M., Sharaf, A., Raunak, V ., Gabr, M., Matsushita, H., \nKim, Y .J., Afify, M., & Awadalla, H.H. (2023). How good are gpt models \nat machine translation? A comprehensive evaluation. arXiv preprint \narXiv:2302.09210.\nHossain, K.A. (2023). Analysis of Present and Future Use of Artificial Intelligence \n(AI) in Line of Fourth Industrial Revolution (4IR). Scientific Research Journal, \nXI(VIII), 1–50. http://dx.doi.org/10.31364/SCIRJ/v11.i8.2023.P0823954\nHurtado Albir, A., & Taylor, P. (2015). The acquisition of translation competence. \nCompetences, tasks, and assessment in translator training. Meta, 60 (2), 256–280. \nhttps://doi.org/10.7202/1032857ar\nHutchins, J. (2005). Example-based machine translation: a review and commentary. \nMachine Translation, 19 (3), 197–211. https://doi.org/10.1007/s10590-006-9003-9\nIslam, M.A., Anik, M.S.H., & Islam, A.B.M.A.A. (2021). Towards achieving a delicate \nblending between rule-based translator and neural machine translator. Neural \nComputing and Applications, 33 (18), 12141–12167. https://doi.org/10.1007/\ns00521-021-05895-x\nJiao, W., Wang, W., Huang, J.-t., Wang, X., & Tu, Z. (2023). Is ChatGPT a good \ntranslator? A preliminary study. arXiv preprint arXiv:2301.08745.\nJones, F.R. (2019). Literary translation . Routledge encyclopedia of translation studies. \nhttps://doi.org/10.4324/9781315678627-63\nKhoshafah, F. (2023). ChatGPT for Arabic-English translation: Evaluating the accuracy, \n13 April 2023, PREPRINT (Version 1) available at Research Square. https://doi.\norg/10.21203/rs.3.rs-2814154/v1\nLyu, C., Xu, J., & Wang, L. (2023). New trends in machine translation using large \nlanguage models: Case examples with chatgpt. arXiv preprint arXiv:2305.01181.\nMalik, T., Dwivedi, Y ., Kshetri, N., Hughes, L., Slade, E.L., Jeyaraj, A., Kar, A.K., \nBaabdullah, A.M., Koohang, A., & Raghavan, V . (2023). “So what if ChatGPT \nwrote it?” Multidisciplinary perspectives on opportunities, challenges and \nimplications of generative conversational AI for research, practice and policy. \nШтучний інтелект в академічному перекладі...\n154\n©  Мохсен, М.\nInternational Journal of Information Management, 71 , 102642. https://doi.\norg/10.1016/j.ijinfomgt.2023.102642\nMohsen, M.A., Althebi, S., & Albahooth, M. (2023). A scientometric study of three \ndecades of machine translation research: Trending issues, hotspot research, and \ncocitation analysis. Cogent Arts & Humanities, 10 (1). https://doi.org/10.1080/233\n11983.2023.2242620\nPonzio, A. (2007). Translation and the literary text. TTR, 20 (2), 89–119. https://doi.\norg/10.7202/018823ar\nQuah, C.K. (2006). Translation and technology . Springer. https://doi.\norg/10.1057/9780230287105\nRay, P.P. (2023). ChatGPT: A comprehensive review on background, applications, \nkey challenges, bias, ethics, limitations and future scope. Internet of Things and \nCyber-Physical Systems, 3,  121–154. https://doi.org/https://doi.org/10.1016/j.\niotcps.2023.04.003\nSanz-Valdivieso, L., & López-Arroyo, B. (2023). Google Translate vs. ChatGPT: Can \nnon-language professionals trust them for specialized translation? Proceedings of \nthe International Conference HiT-IT 2023 (Naples, Italy, 7–9 July 2023)  (pp. 97–\n107). https://doi.org/10.26615/issn.2683-0078.2023_008\nSennrich, R., Firat, O., Cho, K., Birch, A., Haddow, B., Hitschler, J., Junczys-\nDowmunt, M., Läubli, S., Barone, A.V .M., & Mokry, J. (2017). Nematus: \na toolkit for neural machine translation. arXiv preprint arXiv:1703.04357 .\nSon, J., & Kim, B. (2023). Translation Performance from the User’s Perspective of \nLarge Language Models and Neural Machine Translation Systems. Information, \n14(10), 574. https://doi.org/10.3390/info14100574\nSuta, P., Lan, X., Wu, B., Mongkolnam, P., & Chan, J.H. (2020). An overview of \nmachine learning in chatbots. International Journal of Mechanical Engineering \nand Robotics Research, 9 (4), 502–510. https://doi.org/10.18178/ijmerr.9.4.502-510\nToral, A., & Way, A. (2015). Translating literary text between related languages using \nSMT. In Proceedings of the Fourth Workshop on Computational Linguistics \nfor Literature pages (Denver, Colorado, USA, June 4, 2015)  (pp. 123–132). \nAssociation for Computational Linguistics. https://doi.org/10.3115/v1/W15-0714\nValdeón, R.A. (2023). Automated translation and pragmatic force: A discussion from \nthe perspective of intercultural pragmatics. Babel, 69(4), 447–464. https://doi.org/\nhttps://doi.org/10.1075/babel.00328.val\nVaswani, A., Bengio, S., Brevdo, E., Chollet, F., Gomez, A.N., Gouws, S., Jones, L., \nKaiser, Ł., Kalchbrenner, N., & Parmar, N. (2018). Tensor2tensor for neural \nmachine translation. arXiv preprint arXiv:1803.07416 .\nV oigt, R., & Jurafsky, D. (2012). Towards a literary machine translation: The role \nof referential cohesion. David Elson, Anna Kazantseva, Rada Mihalcea, \nStan Szpakowicz (Eds.), Proceedings of the NAACL-HLT 2012 Workshop on \nComputational Linguistics for Literature (Montreal, Canada, June 8, 2012) \n(pp. 18–25). Association for Computational Linguistics.\nWu, E.H.-K., Lin, C.-H., Ou, Y .-Y ., Liu, C.-Z., Wang, W.-K., & Chao, C.-Y . (2020). \nAdvantages and constraints of a hybrid model K-12 E-Learning assistant chatbot. \nIeee Access, 8 , 77788-77801. https://doi.org/10.1109/ACCESS.2020.2988252\nWu, L., Tian, F., Qin, T., Lai, J., & Liu, T.-Y . (2018). A study of reinforcement \nlearning for neural machine translation. arXiv preprint arXiv:1808.08866.\nArtificial Intelligence in Academic Translation...\n155\n© Mohsen, M.\nAppendix A\nScreenshot of the Evaluation Sheets\nAppendix B\nTranslation Comparison Table with Match Rates (Updated Data)\nhttps://nejranuniversity-my.sharepoint.com/:u:/g/personal/mamohsen_nu_\nedu_sa/Eb6Cig9mnUlHo2xLjPACBqsB79vthdWvtTV3eGRlj5KaXw?e=v\nN752m\nAppendix C\nTranslation Comparison Table with Match Rates\nhttps://nejranuniversity-my.sharepoint.com/:u:/g/personal/mamohsen_nu_\nedu_sa/ERDoHtPwcYlHmEcuhCBFk_8BpkN89goT8PLbb5IDURvN8Q?\ne=6IV1uf\nШтучний інтелект в академічному перекладі...\n156\n©  Мохсен, М.\nАНОТАЦІЯ\nМета. Поява в листопаді 2022 року генеративної моделі штучного інтелекту \n(ШІ) Large Language Model (LLM) справила глибокий вплив на різні сфери, \nзокрема й на перекладознавство. Це спонукало нас провести ретельну оцінку \nефективності й точності машинного перекладу, представленого Google \nTranslate (GT), у порівнянні з великими мовними моделями (LLM), зокрема \nChatGPT 3.5 і 4, при двосторонньому перекладі академічних рефератів з \nанглійської та арабської мов.\nМетоди. Застосовуючи змішаний підхід, у цьому дослідженні використано \nкорпус, що складається з 20 рефератів, взятих з рецензованих журналів, \nіндексованих у Clarivate Web of Science, зокрема, Journal of Arabic Literature \nта Al-Istihlal Journal. Анотації розділені порівну, щоб представити як англо-\nарабський, так і арабсько-англійський напрямки перекладу. Дизайн дослідження \nґрунтується на комплексній шкалі оцінювання, адаптованій з Hurtado Albir and \nTaylor (2015), з акцентом на семантичну цілісність, синтаксичну зв’язність \nі технічну адекватність. Троє незалежних експертів оцінювали результати \nперекладу, отримані за моделями GT і LLM.\nРезультати. Результати кількісного та якісного аналізу показали, що \nінструменти LLM значно перевершують результати перекладу за допомогою \nМТ як в арабському, так і в англійському напрямках. Крім того, ChatGPT 4 \nпродемонстрував значну перевагу над ChatGPT 3.5 в арабсько-англійському \nперекладі, тоді як в англо-арабському напрямку перекладу статистично \nзначущої різниці не спостерігалося. Результати якісного аналізу показали, що \nінструменти ШІ здатні розуміти контекстуальні нюанси, розпізнавати назви \nміст і адаптуватися до стилю цільової мови. І навпаки, ГТ демонстрував \nобмеження в роботі з конкретними контекстуальними аспектами і часто \nнадавав дослівний переклад певних термінів.\nКлючові слова: ChatGPT, машинний переклад, Google Translate, анотація статті.\n"
}