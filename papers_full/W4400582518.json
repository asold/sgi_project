{
  "title": "Can Large Language Models Transform Natural Language Intent into Formal Method Postconditions?",
  "url": "https://openalex.org/W4400582518",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3000437246",
      "name": "Madeline Endres",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2796307633",
      "name": "Sarah Fakhoury",
      "affiliations": [
        "Seattle University",
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2152902633",
      "name": "Saikat Chakraborty",
      "affiliations": [
        "Microsoft (United States)",
        "Seattle University"
      ]
    },
    {
      "id": "https://openalex.org/A2178011691",
      "name": "Shuvendu K. Lahiri",
      "affiliations": [
        "Seattle University",
        "Microsoft (United States)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2133068784",
    "https://openalex.org/W2879105418",
    "https://openalex.org/W2088094671",
    "https://openalex.org/W2139555094",
    "https://openalex.org/W2036086780",
    "https://openalex.org/W1511110335",
    "https://openalex.org/W4284690374",
    "https://openalex.org/W2103318645",
    "https://openalex.org/W4398239232",
    "https://openalex.org/W1971650562",
    "https://openalex.org/W2185676247",
    "https://openalex.org/W2471601946",
    "https://openalex.org/W2968771148",
    "https://openalex.org/W2135841285",
    "https://openalex.org/W2156723666",
    "https://openalex.org/W2130427425",
    "https://openalex.org/W2118111397",
    "https://openalex.org/W4384304865",
    "https://openalex.org/W4285204876",
    "https://openalex.org/W3160282589",
    "https://openalex.org/W1589211450",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W3149821397",
    "https://openalex.org/W3089816368",
    "https://openalex.org/W2311603331",
    "https://openalex.org/W2126775986",
    "https://openalex.org/W4240226860",
    "https://openalex.org/W2152874840",
    "https://openalex.org/W2170196926",
    "https://openalex.org/W2118655104",
    "https://openalex.org/W4287668913",
    "https://openalex.org/W3086938529",
    "https://openalex.org/W6838461927",
    "https://openalex.org/W3032926390",
    "https://openalex.org/W2109612250",
    "https://openalex.org/W2617604339",
    "https://openalex.org/W4283026156",
    "https://openalex.org/W2561675875",
    "https://openalex.org/W2747329762"
  ],
  "abstract": "Informal natural language that describes code functionality, such as code comments or function documentation, may contain substantial information about a program’s intent. However, there is typically no guarantee that a program’s implementation and natural language documentation are aligned. In the case of a conflict, leveraging information in code-adjacent natural language has the potential to enhance fault localization, debugging, and code trustworthiness. In practice, however, this information is often underutilized due to the inherent ambiguity of natural language, which makes natural language intent challenging to check programmatically. The “emergent abilities” of Large Language Models (LLMs) have the potential to facilitate the translation of natural language intent to programmatically checkable assertions. However, it is unclear if LLMs can correctly translate informal natural language specifications into formal specifications that match programmer intent. Additionally, it is unclear if such translation could be useful in practice. In this paper, we describe nl2postcondition, the problem of leveraging LLMs for transforming informal natural language to formal method postconditions, expressed as program assertions. We introduce and validate metrics to measure and compare different nl2postcondition approaches, using the correctness and discriminative power of generated postconditions. We then use qualitative and quantitative methods to assess the quality of nl2postcondition postconditions, finding that they are generally correct and able to discriminate incorrect code. Finally, we find that via LLMs has the potential to be helpful in practice; generated postconditions were able to catch 64 real-world historical bugs from Defects4J.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8444329500198364
    },
    {
      "name": "Programming language",
      "score": 0.6352946758270264
    },
    {
      "name": "Natural language",
      "score": 0.6288350820541382
    },
    {
      "name": "Correctness",
      "score": 0.5547380447387695
    },
    {
      "name": "Documentation",
      "score": 0.47830989956855774
    },
    {
      "name": "Object language",
      "score": 0.4610298275947571
    },
    {
      "name": "Specification language",
      "score": 0.4494013786315918
    },
    {
      "name": "Natural language programming",
      "score": 0.4200356602668762
    },
    {
      "name": "Natural language processing",
      "score": 0.38150104880332947
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3471122980117798
    },
    {
      "name": "Universal Networking Language",
      "score": 0.2383919060230255
    },
    {
      "name": "Comprehension approach",
      "score": 0.11902472376823425
    }
  ]
}