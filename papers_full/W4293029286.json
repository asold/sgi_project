{
  "title": "Training Vision Transformers in Federated Learning with Limited Edge-Device Resources",
  "url": "https://openalex.org/W4293029286",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A1990088120",
      "name": "Jiang Tao",
      "affiliations": [
        "Tianjin University"
      ]
    },
    {
      "id": "https://openalex.org/A2135624771",
      "name": "Zhen Gao",
      "affiliations": [
        "Tianjin University"
      ]
    },
    {
      "id": "https://openalex.org/A259644255",
      "name": "Zhaohui Guo",
      "affiliations": [
        "Tianjin University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6778883912",
    "https://openalex.org/W3040573126",
    "https://openalex.org/W3164573547",
    "https://openalex.org/W3206144059",
    "https://openalex.org/W2541884796",
    "https://openalex.org/W2995022099",
    "https://openalex.org/W2963209930",
    "https://openalex.org/W2903470619",
    "https://openalex.org/W3094163844",
    "https://openalex.org/W3116489684",
    "https://openalex.org/W2970454332",
    "https://openalex.org/W6797790494",
    "https://openalex.org/W2963091558",
    "https://openalex.org/W3044211235",
    "https://openalex.org/W2990614164",
    "https://openalex.org/W2535838896",
    "https://openalex.org/W3128339117",
    "https://openalex.org/W2978110818",
    "https://openalex.org/W6773976177"
  ],
  "abstract": "Vision transformers (ViTs) demonstrate exceptional performance in numerous computer vision tasks owing to their self-attention modules. Despite improved network performance, transformers frequently require significant computational resources. The increasing need for data privacy has encouraged the development of federated learning (FL). Traditional FL places a computing burden on edge devices. However, ViTs cannot be directly applied through FL on resource-constrained edge devices. To utilize the powerful ViT structure, we reformulated FL as a federated knowledge distillation training algorithm called FedVKD. FedVKD uses an alternating minimization strategy to train small convolutional neural networks on edge nodes and periodically transfers their knowledge to a large server-side transformer encoder via knowledge distillation. FedVKD affords the benefits of reduced edge-computing load and improved performance for vision tasks, while preserving FedGKT-like asynchronous training. We used four datasets and their non-IID variations to test the proposed FedVKD. When utilizing a larger dataset, FedVKD achieved higher accuracy than FedGKT and FedAvg.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7460960149765015
    },
    {
      "name": "Transformer",
      "score": 0.7266666293144226
    },
    {
      "name": "Edge device",
      "score": 0.7091532945632935
    },
    {
      "name": "Encoder",
      "score": 0.6220365762710571
    },
    {
      "name": "Edge computing",
      "score": 0.5869587659835815
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5003795623779297
    },
    {
      "name": "Deep learning",
      "score": 0.48493459820747375
    },
    {
      "name": "Convolutional neural network",
      "score": 0.47209495306015015
    },
    {
      "name": "Minification",
      "score": 0.4525226950645447
    },
    {
      "name": "Training set",
      "score": 0.4373036324977875
    },
    {
      "name": "Asynchronous learning",
      "score": 0.43451496958732605
    },
    {
      "name": "Asynchronous communication",
      "score": 0.4272286891937256
    },
    {
      "name": "Machine learning",
      "score": 0.4170178174972534
    },
    {
      "name": "Computer engineering",
      "score": 0.41131800413131714
    },
    {
      "name": "Enhanced Data Rates for GSM Evolution",
      "score": 0.4000885784626007
    },
    {
      "name": "Real-time computing",
      "score": 0.3346486985683441
    },
    {
      "name": "Computer network",
      "score": 0.15273669362068176
    },
    {
      "name": "Engineering",
      "score": 0.14224305748939514
    },
    {
      "name": "Voltage",
      "score": 0.09962502121925354
    },
    {
      "name": "Electrical engineering",
      "score": 0.08997714519500732
    },
    {
      "name": "Operating system",
      "score": 0.08865600824356079
    },
    {
      "name": "Cooperative learning",
      "score": 0.0
    },
    {
      "name": "Cloud computing",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Teaching method",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Synchronous learning",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I162868743",
      "name": "Tianjin University",
      "country": "CN"
    }
  ]
}