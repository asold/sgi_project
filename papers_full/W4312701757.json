{
    "title": "Self-Supervised RGB-NIR Fusion Video Vision Transformer Framework for rPPG Estimation",
    "url": "https://openalex.org/W4312701757",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2113190571",
            "name": "So-Yeon Park",
            "affiliations": [
                "Sookmyung Women's University"
            ]
        },
        {
            "id": "https://openalex.org/A2310616265",
            "name": "Bo Kyeong Kim",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4286392470",
            "name": "Suh-Yeon Dong",
            "affiliations": [
                "Sookmyung Women's University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2016778993",
        "https://openalex.org/W2122098299",
        "https://openalex.org/W6840952533",
        "https://openalex.org/W6774314701",
        "https://openalex.org/W6807118051",
        "https://openalex.org/W3204093119",
        "https://openalex.org/W3109219900",
        "https://openalex.org/W6755677326",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W6655867299",
        "https://openalex.org/W3195233483",
        "https://openalex.org/W2970238056",
        "https://openalex.org/W2898940198",
        "https://openalex.org/W2971200605",
        "https://openalex.org/W3015003552",
        "https://openalex.org/W3131296864",
        "https://openalex.org/W6796707148",
        "https://openalex.org/W4312358294",
        "https://openalex.org/W6753412334",
        "https://openalex.org/W2963495494",
        "https://openalex.org/W2903521046",
        "https://openalex.org/W2902449706",
        "https://openalex.org/W2982196965",
        "https://openalex.org/W2292374408",
        "https://openalex.org/W6767419198",
        "https://openalex.org/W3036674548",
        "https://openalex.org/W2963433879",
        "https://openalex.org/W2002282659",
        "https://openalex.org/W2970821245",
        "https://openalex.org/W2027310320",
        "https://openalex.org/W2782530141",
        "https://openalex.org/W1986618684",
        "https://openalex.org/W3035524453",
        "https://openalex.org/W4226043703",
        "https://openalex.org/W6743555153",
        "https://openalex.org/W2963524571",
        "https://openalex.org/W2970231061",
        "https://openalex.org/W3172595589",
        "https://openalex.org/W4221155627",
        "https://openalex.org/W3020225364",
        "https://openalex.org/W2903559293",
        "https://openalex.org/W3172863135",
        "https://openalex.org/W2164598857",
        "https://openalex.org/W2958501326",
        "https://openalex.org/W3208893812",
        "https://openalex.org/W4214612132",
        "https://openalex.org/W4288358601",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2884585870",
        "https://openalex.org/W2896102525",
        "https://openalex.org/W3100063341",
        "https://openalex.org/W4287236261",
        "https://openalex.org/W3005680577",
        "https://openalex.org/W4206847144",
        "https://openalex.org/W2963307811",
        "https://openalex.org/W2022351629"
    ],
    "abstract": "Remote photoplethysmography (rPPG) is a technology that can estimate non-contact heart rate (HR) using facial videos. Estimating rPPG signals requires low cost, and thus, it is widely used for non-contact health monitoring. Recent HR estimation studies based on rPPG heavily rely on the supervised feature learning on normal RGB videos. However, the RGB-only methods are significantly affected by head movements and various illumination conditions, and it is difficult to obtain large-scale labeled data for rPPG in order to determine the performance of supervised learning methods. To address these problems, we present the first of its kind self-supervised transformer-based fusion learning framework for rPPG estimation. In our study, we propose an end-to-end Fusion Video Vision Transformer (Fusion ViViT) network that can extract long-range local and global spatiotemporal features from videos and convert them into video sequences to enhance the rPPG representation. In addition, the self-attention of the transformer integrates the spatiotemporal representations of complementary RGB and near-infrared (NIR), which, in turn, enable robust HR estimation even under complex conditions. We use contrastive learning as a self-supervised learning scheme. We evaluate our framework on public datasets containing both RGB, NIR videos and physiological signals. The result of near-instant HR (approximately 6 s) estimation on the large-scale rPPG dataset with various scenarios, was 14.86 of RMSE, which was competitive with the state-of-the-art accuracy of average HR (approximately 30 s). Furthermore, transfer learning results on the driving rPPG dataset showed a stable HR estimation performance with 16.94 of RMSE, demonstrating that our framework can be utilized in the real world.",
    "full_text": null
}