{
  "title": "Spatiotemporal model based on transformer for bias correction and temporal downscaling of forecasts",
  "url": "https://openalex.org/W4310039988",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A1811607940",
      "name": "Li Xiang",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2223223105",
      "name": "Jiping Guan",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2023736280",
      "name": "Jie Xiang",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2106312615",
      "name": "Li-Feng Zhang",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2997482752",
      "name": "Fuhan Zhang",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A1811607940",
      "name": "Li Xiang",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2223223105",
      "name": "Jiping Guan",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2023736280",
      "name": "Jie Xiang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2106312615",
      "name": "Li-Feng Zhang",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2997482752",
      "name": "Fuhan Zhang",
      "affiliations": [
        "China XD Group (China)",
        "National University of Defense Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1789155650",
    "https://openalex.org/W3081373097",
    "https://openalex.org/W3011863222",
    "https://openalex.org/W6810026097",
    "https://openalex.org/W1523222099",
    "https://openalex.org/W2026058014",
    "https://openalex.org/W4213019189",
    "https://openalex.org/W3171394698",
    "https://openalex.org/W2944725125",
    "https://openalex.org/W3025949386",
    "https://openalex.org/W6770461272",
    "https://openalex.org/W2904349382",
    "https://openalex.org/W2173251738",
    "https://openalex.org/W2795061970",
    "https://openalex.org/W2273673107",
    "https://openalex.org/W2981548405",
    "https://openalex.org/W586005332",
    "https://openalex.org/W6773340818",
    "https://openalex.org/W3011739652",
    "https://openalex.org/W2969752514",
    "https://openalex.org/W6792155083",
    "https://openalex.org/W6797737728",
    "https://openalex.org/W1961597561",
    "https://openalex.org/W2045577896",
    "https://openalex.org/W7000894120",
    "https://openalex.org/W2993613894",
    "https://openalex.org/W6639824700",
    "https://openalex.org/W6739112683",
    "https://openalex.org/W2059342705",
    "https://openalex.org/W4249395738",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W6797358519",
    "https://openalex.org/W3005197680",
    "https://openalex.org/W4220765537",
    "https://openalex.org/W3096052669",
    "https://openalex.org/W2915610351",
    "https://openalex.org/W3134265440",
    "https://openalex.org/W3177318507",
    "https://openalex.org/W3154407200",
    "https://openalex.org/W2171859864",
    "https://openalex.org/W2990944018",
    "https://openalex.org/W1686810756",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3174786912",
    "https://openalex.org/W3138516171",
    "https://openalex.org/W3003844914",
    "https://openalex.org/W1901129140",
    "https://openalex.org/W2625614184",
    "https://openalex.org/W4312560592",
    "https://openalex.org/W3111283122",
    "https://openalex.org/W2798122215",
    "https://openalex.org/W4312434878",
    "https://openalex.org/W2950151243",
    "https://openalex.org/W3006683367"
  ],
  "abstract": "Numerical weather prediction (NWP) provides the future state of the atmosphere and is a major tool for weather forecasting. However, NWP has inevitable errors and requires bias correction to obtain more accurate forecasts. NWP is based on discrete numerical calculations, which inevitably result in a loss in resolution, and downscaling provides important support for obtaining detailed weather forecasts. In this paper, based on the spatio-temporal modeling approach, the Spatio-Temporal Transformer U-Net (ST-UNet) is constructed based on the U-net framework using the swin transformer and convolution to perform bias correction and temporal downscaling. The encoder part extracts features from the multi-time forecasts, and the decoder part uses the features from the encoder part and the constructed query vector for feature reconstruction. Besides, the query builder block generates different query vectors to accomplish different tasks. Multi-time bias correction was conducted for the 2-m temperature and the 10-m wind component. The results showed that the deep learning model significantly outperformed the anomaly numerical correction with observations, and ST-UNet also outperformed the U-Net model for single-time bias correction and the 3-dimensional U-Net (3D-UNet) model for multi-time bias correction. Forecasts from ST-UNet obtained the smallest root mean square error and the largest accuracy and correlation coefficient on both the 2-m temperature and 10-m wind component experiments. Meanwhile, temporal downscaling was performed to obtain hourly forecasts based on ST-UNet, which increased the temporal resolution and reduced the root mean square error by 0.78 compared to the original forecasts. Therefore, our proposed model can be applied to both bias correction and temporal downscaling tasks and achieve good accuracy.",
  "full_text": "Spatiotemporal model based on\ntransformer for bias correction\nand temporal downscaling of\nforecasts\nLi Xiang1† , Jiping Guan1† , Jie Xiang1*, Lifeng Zhang1 and\nFuhan Zhang2\n1College of Meteorology and Oceanology, National University of Defense Technology, Changsha,\nChina, 2Xi’an Satellite Control Center, Xi’an, China\nNumerical weather prediction (NWP) provides the future state of the\natmosphere and is a major tool for weather forecasting. However, NWP has\ninevitable errors and requires bias correction to obtain more accurate forecasts.\nNWP is based on discrete numerical calculations, which inevitably result in a loss\nin resolution, and downscaling provides important support for obtaining\ndetailed weather forecasts. In this paper, based on the spatio-temporal\nmodeling approach, the Spatio-Temporal Transformer U-Net (ST-UNet) is\nconstructed based on the U-net framework using the swin transformer and\nconvolution to perform bias correction and temporal downscaling. The\nencoder part extracts features from the multi-time forecasts, and the\ndecoder part uses the features from the encoder part and the constructed\nquery vector for feature reconstruction. Besides, the query builder block\ngenerates different query vectors to accomplish different tasks. Multi-time\nbias correction was conducted for the 2-m temperature and the 10-m wind\ncomponent. The results showed that the deep learning model signiﬁcantly\noutperformed the anomaly numerical correction with observations, and ST-\nUNet also outperformed the U-Net model for single-time bias correction and\nthe 3-dimensional U-Net (3D-UNet) model for multi-time bias correction.\nForecasts from ST-UNet obtained the smallest root mean square error and\nthe largest accuracy and correlation coefﬁcient on both the 2-m temperature\nand 10-m wind component experiments. Meanwhile, temporal downscaling\nwas performed to obtain hourly forecasts based on ST-UNet, which increased\nthe temporal resolution and reduced the root mean square error by\n0.78 compared to the original forecasts. Therefore, our proposed model can\nbe applied to both bias correction and temporal downscaling tasks and achieve\ngood accuracy.\nKEYWORDS\nspatiotemporal modeling, bias correction, temporal downscaling, weather\nforecasting, swin transformer\nOPEN ACCESS\nEDITED BY\nZengyun Hu,\nChinese Academy of Sciences (CAS),\nChina\nREVIEWED BY\nYuanjian Yang,\nNanjing University of Information\nScience and Technology, China\nJunqiang Yao,\nChina Meteorological Administration,\nChina\n*CORRESPONDENCE\nJie Xiang,\nxiangjie@nudt.edu.cn\n†These authors have contributed equally\nto this work\nSPECIALTY SECTION\nThis article was submitted to\nAtmosphere and Climate,\na section of the journal\nFrontiers in Environmental Science\nRECEIVED 08 September 2022\nACCEPTED 01 November 2022\nPUBLISHED 25 November 2022\nCITATION\nXiang L, Guan J, Xiang J, Zhang L and\nZhang F (2022), Spatiotemporal model\nbased on transformer for bias correction\nand temporal downscaling of forecasts.\nFront. Environ. Sci. 10:1039764.\ndoi: 10.3389/fenvs.2022.1039764\nCOPYRIGHT\n© 2022 Xiang, Guan, Xiang, Zhang and\nZhang. This is an open-access article\ndistributed under the terms of the\nCreative Commons Attribution License\n(CC BY). The use, distribution or\nreproduction in other forums is\npermitted, provided the original\nauthor(s) and the copyright owner(s) are\ncredited and that the original\npublication in this journal is cited, in\naccordance with accepted academic\npractice. No use, distribution or\nreproduction is permitted which does\nnot comply with these terms.\nFrontiers inEnvironmental Science frontiersin.org01\nTYPE Original Research\nPUBLISHED 25 November 2022\nDOI 10.3389/fenvs.2022.1039764\n1 Introduction\nWeather changes have a great impact on human life and\nproduction, and accurately learning about the future state of the\nweather is signiﬁcant. Weather forecasting, as a method of\npredicting the future state of the atmosphere, has always been\na fundamental issue and a research hotspot in the ﬁeld of\natmospheric science ( Bauer et al., 2015 ). Nowadays,\noperational weather forecasting is based on NWP models,\nwhich use powerful computers to perform numerical\ncalculations to solve the hydrodynamic and thermodynamic\nequations describing the evolution of weather, thus predicting\nthe future state of atmospheric motion and weather phenomena\n(Bauer et al., 2015 ; Krishnamupti and Bounoua, 2018 ).\nAttributed to the development of computer technology\n(Shuman, 1989; Lapillonne et al., 2016 ), model technology\n(Kalnay et al., 1996) and observational tools (Schulze, 2007;\nLeuenberger et al., 2020), NWP has made great progress in\nthe last few decades.\nHowever, NWP still suffers from unavoidable errors and a\ndeﬁciency in model resolution. The NWP model cannot\naccurately describe sub-grid processes, while the numerical\ncalculation process is approximated and the initial ﬁeld is\ninaccurate. As a result, there are errors in the NWP, which\nare divided into initialﬁeld errors and model errors (Privé and\nErrico, 2013). Data assimilation can be used to obtain a more\nrealistic state of the atmosphere by fusing satellite, radar, and\nother observations, thus providing an accurate initialﬁeld (Ghil\nand Malanotte-Rizzoli, 1991). Ensemble forecasts, which make\nuse of forecasts from different conditions to compensate for the\nmodel’s lack of description of physical processes and the\nuncertainty of other factors, have been used in practical\napplications (Zhu, 2005; Qiao et al., 2020). However, many\nindustries such as agriculture and transportation require\naccurate weather forecasts, so NWP forecasts need further\ncorrections. Meanwhile, due to the limitation of\ncomputational and storage resources, NWP forecasts are\nlimited in spatial and temporal resolutions, which makes it\ndifﬁcult to provide ﬁner spatial and temporal forecast results.\nTo address this issue, downscaling methods have been developed.\nFor bias correction, many methods have been proposed,\nincluding model output statistics (MOS) (Glahn and Lowry,\n1972), anomaly numerical correction with Observations\n(ANO) (Peng et al., 2013), Bayesian model averaging (BMA)\n(Sloughter et al., 2010), the Kalman ﬁlter (Yang, 2019), and\nmodel output machine learning (MOML) (Li et al., 2019). MOS\nuses multivariate linear equations to establish the relationship\nbetween observations and forecasts, which relies on a large\namount of data. Based on the theory that atmospheric states\ncan be divided into climate-averaged and perturbed states (Qian,\n2012), ANO overlays the difference between the climate-\naveraged state of the observations and the climate-averaged\nstate of the model to correct the model bias. However, during\nsudden weather changes, ANO is dif ﬁcult to revise model\noutputs. BMA obtains the best forecasts by constructing\nprobability density functions (PDFs), so it is strongly\ndependent on the accuracy of the PDFs. For MOML, a variety\nof machine learning algorithms such as the support vector\nmachine and the random forest can be used to establish the\nrelationship between multiple forecast elements and correction\nelements to realize bias correction (Cho et al., 2020), where the\nchoice of forecast elements is important for MOML. The deep\nlearning model can also be used for bias correction, which is\ndescribed in the next paragraph. For downscaling problems,\ncurrent research focuses on spatial downscaling,\ni.e., converting large-scale low-resolution model outputs into\nhigh-resolution data. Traditional downscaling methods include\nstatistical downscaling and dynamical downscaling, which use\nstatistical relationships and nested models, respectively.\nHowever, temporal downscaling is also important. A\nstochastic weather generator is applied to seasonal\nprecipitation and temperature forecasts, which extends\ngeneralized linear modeling approach to stochastic weather\ngenerator and introduces the aggregated climate statistics as\ncovariates (Kim et al., 2016). At present, less research studies\nin this ﬁeld have applied deep learning methods.\nWith the rise of deep learning techniques, they have been\nwidely used and have achieved great success in many ﬁelds,\nincluding atmospheric science (Wang et al., 2021). Deep learning\nhas been applied to areas such as image classiﬁcation and image\nsegmentation, where the data is generally gridded and spatial\nfeature extraction has greatly improved the capability of the\nmodels. In contrast, methods such as MOS, BMA, and MOML\nestablish regression relationships for a single point, so deep\nlearning has an advantage in extracting spatial features from\nforecast data. Meanwhile, deep learning models can be migrated\nto a wide range of tasks, and their parameters can be adjusted\nthrough training to achieve superior results. This also allows deep\nlearning to accomplish many tasks in theﬁeld of atmospheric\nscience, such as prediction, inversion, and bias correction.\nHowever, deep learning frameworks lack interpretability and\nare like black boxes. Therefore, constructing appropriate models\nfor different tasks and adding physical meaning to the models is\nthe direction of deep learning development. To realize\nprecipitation nowcasting, models derived from the encoder-\ndecoder framework are adopted to generate nowcasting by\nfusing radar data and satellite data (Shi et al., 2017; Zhang\net al., 2021). To invert the meteorological elements such as\nprecipitation, Wu et al. (2020a); Xue et al. (2021)constructed\nmodels based on the convolutional neural network (CNN) or\nrecurrent neural network to achieve precipitation estimation by\nusing satellite bright temperature data, topographic elevation\ndata, and meteorological station data. Combining the\ndiscontinuity of precipitation and the ill-posed property of\ndownscaling, a novel deep learning model was constructed by\nusing the super-resolution reconstruction technique in deep\nFrontiers inEnvironmental Science frontiersin.org02\nXiang et al. 10.3389/fenvs.2022.1039764\nlearning to realize precipitation downscaling (Xiang et al., 2022).\nFor bias correction, the UNet was used to conduct bias correction\nby combining multiple forecast elements of the model output\n(Chen et al., 2020; Han et al., 2021), which indicates that deep\nlearning models can signiﬁcantly reduce the error of the forecast\ndata. Therefore, for bias correction and temporal downscaling,\nthis paper attempts to propose a model based on deep learning\nmethod to complete the above tasks, and achieves better results\nthan the previous methods.\nIn this study, the spatio-temporal transformer U-net (ST-UNet)\nis proposed based on spatio-temporal modeling to perform bias\ncorrection and temporal downscaling tasks. The shifted window\n(swin) transformer is a hierarchical structure based on the\ntransformer, and it divides images into non-overlapping\nwindows and shifted windows. The self-attention mechanism is\napplied to each of the non-overlapping windows and shifted\nwindows to obtain global features. The traditional U-net model\nis also a hierarchical u-shaped structure based on CNN. This paper\nreplaces CNN with the swin transformer to facilitate the local\nfeature extraction of CNN. The bias correction and downscaling\ntasks are transformed into the image translation problem in deep\nlearning, and the spatio-temporal information of forecasts is fully\nexploited. For meteorological elements, the atmospheric state at a\ngiven point and a given time is not only related to the surrounding\natmosphere but also the atmospheric state before and after. That is,\nthe atmosphere has a spatio-temporal evolution, so mining spatio-\ntemporal features is conducive to bias correction, which is also an\nimportant basis for temporal downscaling. Based on spatio-\ntemporal modeling, this paper uses multi-time forecasts as input\nwhile processing the spatio-temporal information. The encoder part\nprocesses the input to obtain different levels of features. The query\nbuilder block generates differentquery vectors for bias correction\nand downscaling tasks. The decoder uses the query vector and the\nfeatures from the encoder to complete the feature reconstruction\nand generate the multi-time output. Finally, the capability of our\nproposed model for each of the two tasks was veriﬁed by bias\ncorrection on 2-m temperature and 10-m u component of wind and\ntemporal downscaling on 2-m temperature.\n2 Data description\nIn this study, bias correction and temporal downscaling are\napplied to the forecast data to obtain more accurate and detailed\nforecasts. The operational GlobalForecast System forecast (GFS)\ndata provided by the National Centers for Environmental Prediction\nis used in this study (National Centers for Environmental Prediction,\nNational Weather Service, NOAA, U.S. Department of Commerce,\n2015). GFS is 0.25° ×0 . 2 5° gridded data that includes a wide range of\nmeteorological elements in the air and on the surface. The data has\nforecast time steps at a 3-h interval from 0 to 240 h and a 12-h\ninterval from 240 to 384 h. The model forecast is performed at 00,\n06, 12, and 18 UTC daily. As an alternative to ERA-Interim, ERA-5\nis theﬁfth generation of the European Center for Medium-Range\nWeather Forecasts Reanalysis (ERA), which provides hourly\nestimates of atmospheric, terrestrial, and oceanic climate variables\n(Hersbach, 2016). ERA-5 uses advanced modeling and data\nassimilation systems to integrate historical observations and\nsatellite data into global estimates, which can provide a more\nrealistic state of the atmosphere (He et al., 2019; Hersbach et al.,\n2020). Thus, ERA-5 is as used the true data in this study. The ERA-5\ndata has the same spatial resolution as the GFS forecasts, but its\ntemporal resolution is 1 h, so it provides a more detailed view of the\natmospheric state.\nOur research areas are 105\n°– 120°E and 20°– 40°N, which cover\nthe central and eastern regions of China and have many different\ngeographic features and weather conditions. The speciﬁcd o m a i n\nand geographic features are illustrated in Figure 1.F o rb i a s\ncorrection and temporal downscaling tasks, the multi-time data\nof GFS forecast is taken as input, and the ERA-5 data at the same\nmoment provides the true atmospheric state as the output target.\nThe GFS forecast data for the period from 15 January 2015 to\n30 September 2020 is used in this study. For each forecast sample,\nthe dataset is constructed by using the ERA-5 data corresponding\nto the forecast time as the true value. Meanwhile, to maintain the\nstability of the training process and to speed up the convergence,\nthe raw data is normalized by using zero-mean normalization.\nThe data from 15 January 2015 to 28 February 2019 is used as the\ntraining set, the data from 1 March 2019 to 31 August 2019 is\nused as the validation set, and the data from 1 September 2019 to\n30 September 2020 is used as the test set. There are more than\n8,000 samples in total. The ratio of training, validation, and test\nset is approximately 7:1:2.\n3 Methods\nTraditional bias correction methods make individual\ncorrections to the forecast data at a given time. They cannot\ntake full advantage of the temporal correlation of the forecast\ndata and cost a lot of resources for repeated modeling (Han et al.,\n2021). Also, the elements of the atmosphere (e.g., temperature,\nhumidity, windﬁeld, etc.) are correlated in time. Therefore, it is\nmore effective to perform bias correction on adjacent multi-time\nforecasts at a particular moment in time. Meanwhile, a multi-\ntime bias correction model can be constructed, which uses multi-\ntime forecasts as input to complete the bias correction of multi-\ntime forecasts. Speciﬁcally, given the forecast resultP at the issue\ntime t\n0 from the GFS, 3 days of forecasts are selected at an interval\nof 6 h, which is denoted asP′:\nP′ /equals Pt\nn,w×h{}\nt/equals t0+1,t0+2,...,t0+T\nn/equals 1,2,...,N w/equals 1,2,...,W h/equals 1,2,...,H (1)\nwhere T denotes the length of the forecast time series,N denotes\nthe number of meteorological elements, andW × H denotes the\ngrid size of the forecast.\nFrontiers inEnvironmental Science frontiersin.org03\nXiang et al. 10.3389/fenvs.2022.1039764\nThe ERA-5 data at the time corresponding to forecast dataP′\nis selected as the true value and denoted as G. For the bias\ncorrection or temporal downscaling task, the mapping\nrelationship F between P′ and G need to be determined.\nConsidering that the true state Gt0 at the issue time t0 is\nrelated to the forecast data P, it is also used as the input.\nThus, for the bias correction task, we have the following equation:\nPpre /equals FP ′,G t() (2)\nwhere F denotes the mapping relationship for bias correction,\nand Ppre denotes the corrected forecast data.\nThe elements of the atmosphere are closely related and they\nevolve simultaneously in space and time. Also, temperature,\nrelative humidity, and wind speed are closely related to each\nother (including the temporal and spatial distribution and error\ncharacteristics) in terms of the equation constraints of the NWP\nmodel and the dynamic, thermal, and micro-physical\ncharacteristics of the atmosphere. Therefore, other\nmeteorological elements are introduced into the input. In this\npaper, 2-m temperature, 2-m relative humidity, and 10-m wind\nare used as inputs. Therefore, we have the following equation:\nP\npre /equals FP n′,G t() (3)\nwhere Pn′ represents the forecast data of n meteorological\nelements, including 2-m temperature, 2-m relative humidity,\nand 10-m wind.\nIn addition to the bias correction task, temporal downscaling\nis also performed, i.e., low-resolution forecast data are used in the\ntime dimension to obtain high-resolution forecasts. Meanwhile,\nthe same inputs are used, but forecasts are selected for 1 day at an\ninterval of 3 h. Besides, hourly ERA-5 data in the same time range\nare used as true values. Then, by adapting the bias correction\nmodel, temporal downscaling results can be obtained. The whole\nprocess is described as follows:\nP\npre′ /equals F′ Pn′,G t() (4)\nwhere F′ represents the mapping relationship for temporal\ndownscaling, and Ppre′ denotes the forecast data after temporal\ndownscaling.\nIn the following, the swin transformer and the speci ﬁc\nframework of our proposed model will be introduced. Our\nmodel consists of three parts: the encoder, the decoder, and\nthe query builder. The encoder uses the swin transformer for\nfeature extraction and convolution for downsampling, and the\nabove process is implemented in multiple layers. The query\nbuilder uses the features of the last layer in the encoder to\ngenerate the query vector. At different layers, the decoder\ncombines the encoder’s feature processed by 3D convolution\nand the query vector to realize upsampling, and theﬁnal output is\ngenerated from the reconstructed features. By modifying the\nquery builder, error correction and temporal downscaling can be\naccomplished. It is worth noting that different query vectors are\nconstructed for different tasks, and the overall framework is\nshared.\n3.1 Swin transformer\nFor gridded data such as images, CNN is applied for data\nprocessing ( Khan et al., 2018 ). Because of its local and\ntranslation-invariant properties, the convolution operation is\nused in extracting spatial features from gridded data, and\nmany network structures have been derived from CNN\n(Simonyan and Zisserman, 2014 ; Ronneberger et al., 2015 ).\nFIGURE 1\nThe study area. The colored bar represents the elevation of the terrain.\nFrontiers inEnvironmental Science frontiersin.org04\nXiang et al. 10.3389/fenvs.2022.1039764\nHowever, the receptive ﬁeld of spatial extraction of CNN is\nlimited. With the outstanding performance of the transformer in\nnatural language processing, the transformer is gradually applied\nto computer vision for processing image data (Han et al., 2022).\nThe core operation of the transformer is scaled dot-product\nattention (Vaswani et al., 2017). Given a queryQ ∈ Rn×dq and a\nset of key-value pairsK ∈ Rn×dq , V ∈ Rn×dv , scaled dot-product\nattention calculates the attention score as:\nAttention Q, K, V() /equals softmax QKT\n/radicaltpext/radicaltpext\ndk\n√ V() (5)\nwhere softmax is the softmax function, and 1/radicaltpext/radicaltpext\ndk\n√ is the scaling\nfactor.\nTo address the high computational consumption of the\nattention mechanism, many new versions have been proposed,\nsuch as informer, lite transformer, swin transformer (Wu et al.,\n2020b; Zhou et al., 2021a; Liu et al., 2021). The swin transformer\nuses a hierarchical structure and applies an attention mechanism\nto non-overlapping windows and shifted windows (Liu et al.,\n2021). It is an excellent transformer designed for computer vision\napplications and is used in our model to process spatio-temporal\ninformation from gridded forecasts.\n3.2 Model\nBased on the swin transformer and convolution, a spatio-\ntemporal model is constructed in this study to perform the bias\ncorrection task and the temporal downscaling task, as shown in\nFigure 2 . The spatio-temporal model based on the swin\ntransformer has been designed and applied to video super-\nresolution tasks and action recognition tasks ( Geng et al.,\n2022; Liu et al., 2022). The entire framework consists of an\nencoder, a decoder, and a query builder. The encoder extracts\nfeature from the input, while the decoder used reconstructed\nfeatures to generate the output. For the encoder and decoder, a\nseries of swin transformers and convolution layers (including\nconvolution and deconvolution) are used respectively. The swin\ntransformer is used for feature extraction and reconstruction,\nwhile convolution and deconvolution are used for upsampling\nFIGURE 2\nThe overall structure of our proposes model.\nFrontiers inEnvironmental Science frontiersin.org05\nXiang et al. 10.3389/fenvs.2022.1039764\nand downsampling, respectively. Features from different layers of\nthe encoder are processed with 3-dimensional convolution and\nthen used in the decoder. The query builder generates different\ninitial queries and applies them to the decoder.\n3.2.1 Encoder\nFirstly, the feature extraction block performs feature\nextraction on the input. The block consists of two-\ndimensional convolutions and normalization layers that map\nthe input into higher dimensions. Then, the high-dimensional\nfeatures are processed by a series of swin transformer encoder\nblocks, while each swin transformer encoder block is connected\nto a downsampling block consisting of a convolution (except\nfor the last swin transforme r). The downsampling block\ndecreases the size of features by a factor of two, so different\nlayers acquire information at different scales. The above is\nexpressed as follows:\nXk /equals Tswin Ek−1() ,k /equals 1, 2, 3, 4\nEk /equals Cdown Xk() ,k /equals 1, 2, 3\nEk /equals Xk,k /equals 4\n⎧⎪⎨\n⎪⎩ (6)\nwhere Tswin denotes the swin transformer encoder block,Cdown\ndenotes the downsampling block,Xk denotes the output of the\nswin transformer encoder block, andEk denotes the output of\neach layer in the encoder.\nAs shown inFigure 3, the swin transformer encoder block\nconsists of window-based multi-layer self-attention (W-MSA)\nand shifted window-based multi-layer self-attention (SW-\nMSA). The inputs are passed through a LayerNorm (LN)\nlayer, the W-MSA, the LN, and a multi-layer perception\n(MLP) layer. The W-MSA lacks connections across\nwindows, which limits its modeling power. Then, a shifted\nwindow partitioning approach called SW-MSA is proposed to\nintroduce cross-window connections. The subsequent\noperations are consistent except for the change in the self-\nattention block.\n3.2.2 Query builder block\nThe output feature of each swin transformer encoder block\nhas time steps of the same length, which is the same as the input.\nOnly the size of the features is gradually reduced. The feature of\nthe last blockE\nn is formulated as follows:\nEn /equals En,3,E n,6,E n,9, ... ,E n,3*T() (7)\nwhere T represents the total length of the time steps ofEn, which\nremains the same as that of the input’s forecast time series.\nTo make the model suitable for different tasks, a query\nbuilder block is constructed. For the bias correction task,En is\ndirectly used as the initial query vector; for the time downscaling\ntask, En is used to generate an initial query vector with a time\nseries length consistent with the downscaling target. Thus, the\nfollowing equation can be derived:\nQ /equals\nEn,t t /equals 3k\n2\n3En,t + 1\n3En,t+3 t /equals 3k + 1\n1\n3En,t + 2\n3En,t+3 t /equals 3k + 2\n⎧⎪⎪⎪\n⎪\n⎪\n⎪\n⎨\n⎪⎪\n⎪\n⎪\n⎪\n⎪\n⎩\n(8)\nwhere Q is the initial query vector. The above formula represents\nthe initial query vector for temporal downscaling.\n3.2.3 Decoder\nIn the decoder, multiple swin transformer decoder blocks\nand upsampling blocks are used. In each layer of the decoder, the\nswin transformer decoder block generates output features by the\nquery vector acting on a dictionary of key-value pairs. Each swin\ntransformer decoder block has two inputs: a feature from the\nencoder at the same layer, and a query vector. For the encoder’s\nfeatures, 3-dimensional convolution is used to exploit the local\nFIGURE 3\nThe structure of the swin transformer encoder block.\nFIGURE 4\nThe structure of the swin transformer decoder block.\nFrontiers inEnvironmental Science frontiersin.org06\nXiang et al. 10.3389/fenvs.2022.1039764\nfeature extraction capability of convolution ( Kopuklu et al.,\n2019). Unlike the 2-dimensional convolution, the 3-\ndimensional convolution can act on multiple dimensions in\ntime and space to generate key-value pairs. The query vector\nis generated by the query builder block in theﬁrst layer and the\noutput of the previous layer. Subsequently, the output of the swin\ntransformer decoder block is upsampled by an upsampling block\nconsisting of deconvolution. The whole process is shown below:\nDk /equals Cup Tswin C3d Xk() ,Q()() ,k /equals 4\nDk /equals Cup Tswin C3d Xk() ,D k+1()() ,k /equals 2, 3\nDk /equals Tswin C3d Xk() ,D k+1() ,k /equals 1\n⎧⎪⎨\n⎪⎩ (9)\nwhere Tswin denotes the swin transformer decoder block, Cup\ndenotes the upsampling block,C3d denotes the 3D convolution,\nand Xk denotes the output of the swin transformer encoder block.\nThe structure of the swin transformer decoder block is shown\nin Figure 4. The query vector isﬁrst passed through W-MSA.\nThen, the output feature from the encoder is used as a dictionary\nof key-value pairs, which passes through the window-based\nmulti-layer cross-attention (W-MCA) with the query vector.\nThe query vector acts on the dictionary of key-value pairs\nfrom the encoder to generate the features for the target task\nin W-MCA. The same operation is performed by SW-MSA and\nshifted window-based multi-layer cross-attention (SW-MCA).\nFinally, the feature from theﬁnal layer of the swin transformer\ndecoder block is passed through the reconstruction block to\ngenerate the output. The reconstruction block consists of a series\nof residual blocks.\n4 Experiment\n4.1 Train details\nThe Adam optimizer with β1 = 0.9 and β2 = 0.999 is\nemployed for training. The initial learning rate is set to 1 ×\ne−4. Also, the learning rate exponential decay scheme is adopted\nto improve the stability of the training process, with the decay\nexponent parameter set to 0.98. The batch size is set to 8, and the\nloss function is set to the MSE loss function. Each model is\ntrained for about 50 epochs. All models are implemented with\nPyTorch.\n4.2 Baseline methods\nAnomaly numerical correction with observations (ANO) is a\ntraditional bias correction model that decomposes observations\nand model forecasts into climate mean state and disturbance\nstate. The speciﬁc correction process of ANO is described as\nfollows. The coordinate of a grid point is denoted as (i, j), and the\nclimate mean state of forecastspi,j and the climate mean state of\nobservations yi,j are represented as:\npi,j /equals 1\nN ∑\nN\nk/equals 1\npi,j (10)\nyi,j /equals 1\nN ∑\nN\nk/equals 1\nyi,j (11)\nTherefore, the corrected result is\npi,j′ /equals pi,j − pi,j − yi,j() (12)\nwhere pi,j′ is the corrected result,pi,j represents the forecast result\nfor grid point (i, j), yi,j represents the observation data for grid\npoint (i, j), and N represents the total number of samples. The\nforecasts are corrected for each forecast time separately. For more\ndetails of ANO, refer to (Peng et al., 2013).\nThe single-time correction model U-Net and the multi-time\ncorrection model 3D-UNet are taken for comparison to\ninvestigate the effectiveness of our proposed model against the\nclassical deep learning-based bias correction model. The U-Net\nmodel is developed based on the encoder-decoder framework\nwith two-dimensional convolution as the basic operation. It is\ncommonly used in a variety of applications, such as image\nTABLE 1 The parameters and training time of different models in bias correction and temporal downscaling tasks.\nTask Model Parameters (millions) Training time (hours)\nBias correction U-Net 8.03 0.8\n3D-UNet 9.19 2\nST-UNet 2.14 6.3\nTemporal downscaling 3D-UNet 9.17 1.7\nST-UNet 1.21 8.5\nTABLE 2 The overall performance of multi-time bias correction for the\n2-m temperature on the test set.\nModel MAE RMSE CC Acc (%) DISO\nGFS 2.1063 2.7255 0.8972 0.5676 1.4824\nANO 2.0151 2.6028 0.9155 0.5845 1.4167\n3D-UNet 1.1129 1.4775 0.9573 0.8422 0.7744\nST-UNet 1.0065 1.3361 0.9649 0.8757 0.6967\nFrontiers inEnvironmental Science frontiersin.org07\nXiang et al. 10.3389/fenvs.2022.1039764\nsegmentation and image recognition (Ronneberger et al., 2015).\nAlso, it has been used in bias correction, but only for single-time\nerror revisions (Han et al., 2021). The 3D-UNet model replaces\ntwo-dimensional convolution with three-dimensional\nconvolution, and it is also developed based on the encoder-\ndecoder framework. It can handle temporal information, so it can\nbe applied to multi-time bias correction (Chen et al., 2020). In the\nexperiment, a version of 3D-UNet with an attention module is\nused as a baseline method (Oktay et al., 2018). For temporal\ndownscaling, a video super-resolution model using 3-\ndimensional convolution and U-Net architecture is used as a\nbaseline method (Kalluri et al., 2020), which models the temporal\ndynamics between the input frames to complete video frame\ninterpolation. It can be used in temporal downscaling and we still\nname it as 3D-UNet. The parameters and training time of\ndifferent models in detail is showed inTable 1.\n4.3 Evaluation indicators\nTo evaluate the effectiveness of different methods for bias\ncorrection and temporal downscaling, mean absolute error\n(MAE), root mean square error (RMSE), correlation\ncoefﬁcient (CC), and accuracy (Acc) are employed as\nevaluation indicators. RMSE is a general metric for evaluating\nregression problems, and MAE can also be used to evaluate the\nerror between the corrected and true values. CC characterizes the\ncorrelation degree between the corrected and true values, and\nAcc represents the accuracy of the corrected results. For the\ncorrected or downscaled resultP\npre, the corresponding true value\nis denoted asPtrue. MAE and RMSE are calculated as:\nRMSE /equals\n/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext /radicaltpext\n1\nN ∑\nN\n1\n1\nT Pn\npre − Pn\ntrue()\n2\n√\n(13)\nMAE /equals 1\nN ∑\nN\n1\n1\nT|Pn\npre − Pn\ntrue| (14)\nCC /equals\nCov Ppre, Ptrue()/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext\nVar Ppre() Var Ptrue()\n√ (15)\nwhere Ppre represents the forecast result vector,Ptrue represents\nthe true value vector,N represents the total number of samples,\nand T represents the total length of forecast time.\nAccuracy is a metric that is often used for classiﬁcation tasks.\nFor regression tasks, the evaluation can be transformed into a\nbinary classiﬁcation problem by setting a threshold. If the\nthreshold is set to σ, positive samples |Ppre − Ptrue| < σ are\ndenoted asNP, and negative samples |Ppre − Ptrue|≥ σ are denoted\nas NG. Then the accuracy is expressed as:\nAcc /equals NP\nNG + NP\n× 100% (16)\nFor various meteorological elements, the threshold σ has\ndifferent values. According to (Chen et al., 2020), σ is set to 2°Ct o\nTABLE 3 The performance of bias correction for 2-m temperature of\n24 h forecast on the test set.\nModel MAE RMSE CC Acc (%) DISO\nGFS 2.0603 2.6625 0.9048 0.5757 1.4796\nANO 1.9678 2.5383 0.922 0.5937 1.4115\nUNet 1.4022 1.9529 0.9509 0.7672 1.0285\n3D-UNet 1.0306 1.3664 0.9631 0.8673 0.7297\nST-UNet 0.9219 1.2178 0.9706 0.9020 0.6480\nFIGURE 5\nThe RMSE of bias correction on the 2-m temperature for different forecast times on the test set.\nFrontiers inEnvironmental Science frontiersin.org08\nXiang et al. 10.3389/fenvs.2022.1039764\nevaluate the post-processing methods of temperature forecasting.\nAccordingly, σ is set to 2 in our experiments of 2-m temperature.\nAnd σ is set to 1.5 in experiments for 10-m u component of wind.\nIt often happens that MAE, RMSE, CC, and Acc exhibit\ninconsistency in the experiments. For example, the value of\nRMSE decreases a lot, but the increase in Acc is not very\nsigniﬁcant. Here, a comprehensive statistic metric, DISO (the\ndistance between indices of simulation and observation) is\nextended to evaluate the overall performance of different\nmethods. If the statistical metrics for n chosen are (s1, s2, ... ,\nsn) and the corresponding metrics between the truth data and\nitself are (s1\n0,s 2\n0\n, ... ,s n\n0), then DISO is calculated as (Hu et al.,\n2019; Zhou et al., 2021b):\nDISOi /equals\n/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext /radicaltpext\ns1\ni − s1\n0()\n2\n+ s2\ni − s2\n0()\n2\n+ /+ sn\ni − sn\n0()\n2\n√\n(17)\nIn this study, DISO, which is composed of four widely used\nstatistical metrics: MAE, RMSE, CC, and Acc. In order to eliminate\nthe inﬂuence of dimension, MAE and RMSE are normalized as\nNormalized MAE (NMAE) and Normalized RMSE (NRMSE) by\ndividing the maximum of MAE and RMSE respectively:\nDISO\ni /equals\n/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext\nNMAEi − NMAE0() 2 + NRMSEi − NRMSE0() 2\n+ CCi − CC0() 2 + Acci − Acc0() 2\n√\n(18)\nIf the result perfectly performs the best, the best statistical metrics are:\nNMAE=0 ,NRMSE=0 ,CC =1 ,Acc= 1, then DISO can be expressed:\nDISOi /equals\n/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext\nNMAEi() 2 + NRMSEi() 2 + CCi − 1() 2 + Acci − 1() 2\n√\n(19)\nNow, the value of DISO expressed by the statistical metrics\nbetween the forecast and the truth are used to evaluate the\nperformance of different methods. A larger value of DISO\nindicates that the method has a poorer performance.\n5 Result\nOur proposed model can perform both bias correction and\ntemporal downscaling tasks, so it is evaluated in terms of the two\ntasks mentioned above on test set.\nFIGURE 6\nThe RMSE spatial distributions of bias correction for 2-m temperature on the test set over study area.\nFrontiers inEnvironmental Science frontiersin.org09\nXiang et al. 10.3389/fenvs.2022.1039764\n5.1 Bias correction\n5.1.1 2-m temperature\nTable 2presents the overall effectiveness of different methods\nfor the multi-time bias correction on 2 m temperature, while\nTable 3presents the effectiveness of the bias correction on the 2-\nm temperature at the forecast time of 24 h. For the multi-time\nbias correction task, all methods show some improvement on the\noriginal GFS forecast data. Among them, the bias correction\nmethods based on deep learning perform better than ANO.\nCompared with the 3D-UNet model based on convolution,\nour proposed model is based on the swin transformer. By\nutilizing the long-range information capture capability of the\ntransformer structure, our proposed model achieves the best\nresults. Meanwhile, the traditional U-Net model (Han et al.,\n2021) is taken to perform the bias correction of 24 h forecast to\nexplore the effectiveness of the multi-time spatio-temporal\ncorrection method. It can be seen that the results based on\nspatio-temporal correction are signiﬁcantly better than those\nof single-time correction, that is, 3D-UNet and ST-UNet are\nbetter than UNet. ST-UNet and 3D-UNet utilize not only the\nspatial distribution of the forecast data but also the temporal\ncorrelation of the forecast data, so they achieve better results,\nindicating that the spatio-temporal modeling approach has a\nFIGURE 7\nThe distributions of 2-m temperature on the forecast time of 24, 48, and 72 h, including GFS, ERA-5, and corrected results from ANO, 3D-UNet,\nand ST-UNet.\nTABLE 4 The overall performance of multi-time bias correction for the\n10-m u component of wind on the test set.\nModel MAE RMSE CC Acc (%) DISO\nGFS 1.0176 1.4244 0.7819 0.7805 1.4477\nANO 0.9893 1.3936 0.7820 0.7915 1.4118\n3D-UNet 0.6651 0.9353 0.8548 0.9073 0.9424\nST-UNet 0.6300 0.8763 0.8744 0.9225 0.8852\nTABLE 5 The performance of bias correction for the 10-m u\ncomponent of wind at the forecast time of 24 h on the test set.\nModel MAE RMSE CC Acc (%) DISO\nGFS 0.9805 1.3662 0.8011 0.7926 1.4431\nANO 0.9542 1.3374 0.8012 0.8030 1.4084\nUNet 0.6302 0.8760 0.8776 0.9218 0.9194\n3D-UNet 0.6186 0.8628 0.8776 0.9238 0.9042\nST-UNet 0.5825 0.8025 0.8954 0.9388 0.8442\nFrontiers inEnvironmental Science frontiersin.org10\nXiang et al. 10.3389/fenvs.2022.1039764\nFIGURE 8\nThe RMSE of bias correction on the 10-m u component of wind for different forecast times on the test set.\nFIGURE 9\nThe RMSE spatial distribution of bias correction for the 10-m u component of wind on the test set over the study area.\nFrontiers inEnvironmental Science frontiersin.org11\nXiang et al. 10.3389/fenvs.2022.1039764\nbetter effect on bias correction. Besides, the ST-UNet based on\nthe swin transformer obtains the best results for bias correction.\nTo further demonstrate the multi-time bias correction of\ndifferent methods,Figure 5presents the RMSE of the corrected\nresults for different forecast times. It can be seen that the RMSE\nof the forecasts increases with the forecast time, and the RMSE of\nGFS forecasts is always the highest. The ANO method provides\nsome bias correction to the forecasts, but the results are still not\nsatisfactory. Deep learning-based methods obtain good results.\nFor our proposed ST-UNet, the RMSE is always the lowest, but\nthe increase in RMSE with forecast time is also minimal,\nindicating that our model outperforms the CNN-based 3D-\nUNet model.\nTo further investigate the effectiveness of different models,\nthe RMSE spatial distribution of the bias correction results is\nplotted. Figure 6 shows the spatial distribution of RMSE for\ndifferent methods, where (a), (b), (c), and (d) show the RMSE\ndistributions in the same color range for different methods, and\n(e) and (f) show the RMSE distributions in the reduced color\nrange for (c) and (d). From (a), (b), (c), and (d), it can be seen that\nthe RMSE of ANO is reduced compared to that of the original\nGFS data, and the RMSE of the deep learning-based bias\ncorrection method is signiﬁcantly reduced. This indicates the\neffectiveness of our spatio-temporal and multiple data fusion\nmethod and the obvious advantage of the deep learning model\nfor bias correction. From (e) and (f), it can be observed that our\nproposed ST-UNet model outperforms the 3D-UNet model, as\nshown by the signiﬁcant reduction of RMSE in the large value\nregions, especially in the central and northern parts of the\nstudy area.\nAn example of bias correction is presented inFigure 7. Here,\nthe results for the three forecast times of 24, 48, and 72 h are\nconsidered. It can be seen from the results that the ANO method\nonly makes a simple correction to the original GFS, and the result\nis still quite different from the ERA-5 data. The 3D-UNet model\nand the ST-UNet model greatly improve the GFS data, and the\nresults have similarities to the ERA-5 data in terms of spatial\ndistribution. The ST-UNet model can obtain better results at the\nextremes and mutations than 3D-UNet, that is, and the spatial\ndistribution of the data is more consistent with that of the ERA-\n5 data.\n5.1.2 10-m U component of wind\nExperiments are also conducted on the 10-m u component of\nwind. Table 4presents the overall effect of different methods on\nmulti-time bias correction on the 10-m u component of wind.\nThe results are similar to that of the 2-m temperature bias\ncorrection. Speciﬁcally, ANO has some improvements for GFS\nforecast data, and the method based on deep learning can greatly\nimprove the GFS forecast data. Our proposed STUNet model\nperforms the best with the smallest RMSE, MAE, and largest CC\nand Acc.Table 5shows the effect of bias correction at the forecast\ntime of 24 h. The methods based on spatio-temporal modeling\nstill achieve better correction results than ANO. Meanwhile,\nFigure 8 shows the RMSE of the corrected results for different\nforecast times. Similar to the 2-m temperature bias correction,\nTABLE 6 The performance of temporal downscaling for 2-m\ntemperature on the test set.\nModel MAE RMSE CC Acc (%) DISO\nGFS 1.4482 1.8910 0.9313 0.7355 1.4403\n3D-UNet 0.9362 1.244 0.9726 0.8994 0.9282\nST-UNet 0.8422 1.1126 0.9744 0.9235 0.8312\nFIGURE 10\nThe RMSE of temporal downscaling on 2-m temperature for differents forecast times on the test set.\nFrontiers inEnvironmental Science frontiersin.org12\nXiang et al. 10.3389/fenvs.2022.1039764\nour proposed ST-UNet model always achieves the smallest RMSE\nas the forecast time increases.\nFigure 9 presents the RMSE spatial distribution of bias\ncorrection, where (a), (b), (c), and (d) show the RMSE\ndistributions in the same color range for different methods,\nand (e) and (f) show the RMSE distributions in the reduced\ncolor range for (c) and (d). 3D-UNet and ST-UNet largely reduce\nthe RMSE across the study area, and the value of RMSE is much\nsmaller than that of ANO. It can be seen from (e) and (f) that ST-\nUNet further reduces the RMSE in the region of extreme values,\nespecially in the north of the study area.\n5.2 Temporal downscaling\nDue to the discretization of numerical calculations, forecast\ndata products have resolution limitations. The temporal\nresolution of GFS forecast data is 3 h, and the GFS forecast\ndata is downscaled. Using the ST-UNet model, the temporal\nresolution of the GFS forecast data is increased to 1 h. The whole\ntemporal downscaling process improves the temporal resolution\nof forecast data. Meanwhile, since the same ground truth and\nmodel framework are used for bias correction, the whole\ndownscaling process is accompanied by bias correction, so\nmore accurate forecast data are also obtained. Therefore, the\ntemporal downscaling process helps to obtain more detailed and\nprecise forecast data.\nA temporal downscaling experiment is conducted by using\nforecasts with a forecast time of 3 h– 24 h at an interval of 3 h as\ninput and the 2-m temperature of ERA-5 at an interval of 1 h as\nthe true value. Similar to the bias correction, 2-m temperature, 2-\nm relative humidity, and 10-m wind are used as multi-element\ninputs, and the forecasts at an interval of 3 h would yield 2-m\ntemperature results at an interval of 1 h.Table 6presents the 2-m\ntemperature temporal downscaling results. The RMSE of the GFS\ndata is large, the RMSE of the downscaling results is signiﬁcantly\nreduced, and the CC and Acc of the downscaling results are\nsigniﬁcantly increased. Figure 10 shows the RMSE of GFS and\ndownscaling results over forecast time. It can be seen that our\nmodel still obtains a small RMSE for the downscaling results as\nthe forecast time increases. Most importantly, for the missing\nforecast time, the RMSE of the downscaling results obtained by\nthe ST-UNet model is still small and does not show abrupt\nincreases, indicating that the proposed model is stable.\nFigure 11 presents the results of a temporal downscaling\nexample. The row“GFS” shows the forecast data of 18 h, 21 h, and\n24 h; the rows of“ST-UNet” and “ERA-5” show the downscaling\nresults and reanalysis data of 18– 24 h, respectively. For the three\nforecast times of 18, 21, and 24 h, ST-UNet has a certain bias\ncorrection effect on the original GFS data; especially in the south of\nthe study area, where the correction effect is obvious, and the area\nwith large values is corrected. For other temporal downscaling\nresults obtained by ST-UNet, they are consistent with the\nERA5 data in the overall spatial distribution.\nFIGURE 11\nThe distributions of 2-m temperature on the forecast time of 15– 24 h, including GFS, ERA-5, and downscaling results obtained by ST-UNet.\nFrontiers inEnvironmental Science frontiersin.org13\nXiang et al. 10.3389/fenvs.2022.1039764\n6 Conclusion\nIn this paper, a deep learning model called ST-UNet is proposed\nbased on spatio-temporal modeling to accomplish both bias\ncorrection and temporal downscaling. With the swin transformer\nas the main module and CNN as a supplement (Kopuklu et al., 2019;\nLiu et al., 2021), the ST-UNet model is constructed based on the\nframework of U-net. The encoder performs feature extraction and\ndownsampling on the input, and the decoder applies the query vector\nto the features of the decoder to generate the output. To accomplish\nboth the bias correction and downscali n gt a s k s ,aq u e r yb u i l d e rb l o c k\nis proposed to generate the initial query vector. The main highlights\nof our work are as follows. Firstly, a spatio-temporal modeling\napproach that exploits both the spatial distribution and temporal\ncorrelation of forecast data is used, which performs better than\nsingle-time bias correction for the bias correction task; secondly,\nwhile previous work used CNNs for meteorological grid data, this\npaper uses the swin transformer, which exploits a self-attention\nmechanism to extract global features, thus achieving better results\nthan 3D-UNet; thirdly, both the bias correction and temporal\ndownscaling tasks are performed based on the ST-UNet model.\nTo verify the bias correction capability of our proposed\nmodel, multi-time bias correction of the 2-m temperature and\nthe 10-m u component of wind is performed, and multiple types\nof multi-time forecasts are used as input. In the experiments, the\ndeep learning model performs signiﬁcantly better than ANO in\nbias correction, with a signiﬁcant reduction in RMSE and a\nsigniﬁcant increase in CC and Acc. By analyzing the spatial\ndistribution of RMSE, the deep learning approach can reduce\nRMSE signiﬁcantly over the study range, while our proposed\nmodel obtains the smallest RMSE, especially in the regions with\nextreme values. To validate the temporal downscaling effect of\nour proposed model, temporal downscaling of 3-h forecasts is\nperformed to obtain 1-h forecasts. In the 2-m temperature\nexperiment, forecasts with errors much smaller than the\noriginal GFS are obtained, which indicates that the temporal\ndownscaling process helps to obtain more detailed forecasts and\ncorrect the forecasts to obtain more accurate results.\nIn summary, our proposed model can perform both bias\ncorrection and spatial downscaling tasks to obtain more accurate\nand detailed forecast data. This process is based on spatio-\ntemporal modeling and combines both the swin transformer\nmodule and the U-Net framework. Our proposed model can be\napplied to a wide range of model outputs and this will be the\nfocus of our future research.\nData availability statement\nThe original contributions presented in the study are\nincluded in the article/Supplementary Material, further\ninquiries can be directed to the corresponding author.\nAuthor contributions\nLX and JG contributed to the conception and design of the\nstudy. LX organized the database. LX and JX performed the\nstatistical analysis. LX wrote theﬁrst draft of the manuscript. LX,\nLZ, and FZ wrote sections of the manuscript. All authors\ncontributed to the manuscript revision, and they read and\napproved the submitted version.\nFunding\nThis work was supported by the National Natural Science\nFoundation of China (Grant No. 41975066).\nAcknowledgments\nWe thank the reviewers for their comments, which helped us\nimprove the manuscript.\nConﬂict of interest\nThe authors declare that the research was conducted\nin the absence of any commercial or ﬁnancial\nrelationships that could be construed as a potential conﬂict\nof interest.\nPublisher’s note\nAll claims expressed in this article are solely those of the\nauthors and do not necessarily represent those of their afﬁliated\norganizations, or those of the publisher, the editors and the\nreviewers. Any product that may be evaluated in this article, or\nclaim that may be made by its manufacturer, is not guaranteed or\nendorsed by the publisher.\nFrontiers inEnvironmental Science frontiersin.org14\nXiang et al. 10.3389/fenvs.2022.1039764\nReferences\nBauer, P., Thorpe, A., and Brunet, G. (2015). The quiet revolution of numerical\nweather prediction. Nature 525, 47– 55. doi:10.1038/nature14956\nChen, K., Wang, P., Yang, X., Zhang, N., and Wang, D. (2020). A model output\ndeep learning method for grid temperature forecasts in tianjin area.Appl. Sci.10,\n5808. doi:10.3390/app10175808\nCho, D., Yoo, C., Im, J., and Cha, D.-H. (2020). Comparative assessment of\nvarious machine learning-based bias correction methods for numerical weather\nprediction model forecasts of extreme air temperatures in urban areas.Earth Space\nSci. 7, e2019EA000740. doi:10.1029/2019ea000740\nGeng, Z., Liang, L., Ding, T., and Zharkov, I. (2022).“Rstt: Real-time spatial\ntemporal transformer for space-time video super-resolution,” in Proceedings of the\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\n17441– 17451.\nGhil, M., and Malanotte-Rizzoli, P. (1991). Data assimilation in meteorology and\noceanography. Adv. Geophys. 33, 141– 266.\nGlahn, H. R., and Lowry, D. A. (1972). The use of model output statistics (mos) in\nobjective weather forecasting. J. Appl. Meteor. 11, 1203– 1211. doi:10.1175/1520-\n0450(1972)011<1203:tuomos>2.0.co;2\nHan, K., Wang, Y., Chen, H., Chen, X., Guo, J., Liu, Z., et al. (2022). A survey on\nvision transformer. IEEE Trans. pattern analysis Mach. Intell.\nHan, L., Chen, M., Chen, K., Chen, H., Zhang, Y., Lu, B., et al. (2021). A deep\nlearning method for bias correction of ecmwf 24– 240 h forecasts.Adv. Atmos. Sci.\n38, 1444– 1459. doi:10.1007/s00376-021-0215-y\nHe, D., Zhou, Z., Kang, Z., and Liu, L. (2019). Numerical studies on forecast error\ncorrection of grapes model with variational approach.Adv. Meteorology2019, 1– 13.\ndoi:10.1155/2019/2856289\nHersbach, H., Bell, B., Berrisford, P., Hirahara, S., Horányi, A., Muñoz-Sabater, J.,\net al. (2020). The era5 global reanalysis.Q. J. R. Meteorol. Soc.146, 1999– 2049.\ndoi:10.1002/qj.3803\nHersbach, H. (2016). “The era5 atmospheric reanalysis,” in AGU fall meeting\nabstracts.\nHu, Z., Chen, X., Zhou, Q., Chen, D., and Li, J. (2019). Diso: A rethink of Taylor\ndiagram. Int. J. Climatol.39, 2825– 2832. doi:10.1002/joc.5972\nKalluri, T., Pathak, D., Chandraker, M., and Tran, D. (2020).Flavr: Flow-agnostic\nvideo representations for fast frame interpolation[arXiv preprint arXiv:2012.08512].\nKalnay, E., Kanamitsu, M., Kistler, R., Collins, W., Deaven, D., Gandin, L., et al.\n(1996). The ncep/ncar 40-year reanalysis project. Bull. Am. Meteorol. Soc. 77,\n437– 471. doi:10.1175/1520-0477(1996)077<0437:tnyrp>2.0.co;2\nKhan, S., Rahmani, H., Shah, S. A. A., and Bennamoun, M. (2018). A guide to\nconvolutional neural networks for computer vision.Synthesis Lect. Comput. Vis.8,\n1– 207. doi:10.2200/s00822ed1v01y201712cov015\nKim, Y., Rajagopalan, B., and Lee, G. (2016). Temporal statistical downscaling of\nprecipitation and temperature forecasts using a stochastic weather generator.Adv.\nAtmos. Sci. 33, 175– 183. doi:10.1007/s00376-015-5115-6\nKopuklu, O., Kose, N., Gunduz, A., and Rigoll, G. (2019).“Resource efﬁcient 3d\nconvolutional neural networks,” in Proceedings of the IEEE/CVF International\nConference on Computer Vision Workshops.\nKrishnamupti, T., and Bounoua, L. (2018).An introduction to numerical weather\nprediction techniques. Florida, United States: CRC Press.\nLapillonne, X., Fuhrer, O., Spörri, P., Osuna, C., Walser, A., Arteaga, A., et al.\n(2016). “Operational numerical weather prediction on a gpu-accelerated cluster\nsupercomputer,” in EGU General Assembly Conference Abstracts.\nLeuenberger, D., Haefele, A., Omanovic, N., Fengler, M., Martucci, G., Calpini, B.,\net al. (2020). Improving high-impact numerical weather prediction with lidar and\ndrone observations.Bull. Am. Meteorological Soc.101, E1036– E1051. doi:10.1175/\nbams-d-19-0119.1\nLi, H., Yu, C., Xia, J., Wang, Y., Zhu, J., and Zhang, P. (2019). A model output\nmachine learning method for grid temperature forecasts in the beijing area.Adv.\nAtmos. Sci. 36, 1156– 1170. doi:10.1007/s00376-019-9023-z\nLiu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., et al. (2021). “Swin\ntransformer: Hierarchical vision transformer using shifted windows, ” in\nProceedings of the IEEE/CVF International Conference on Computer Vision,\n10012– 10022.\nLiu, Z., Ning, J., Cao, Y., Wei, Y., Zhang, Z., Lin, S., et al. (2022).“Video swin\ntransformer,” in Proceedings of the IEEE/CVF Conference on Computer Vision\nand Pattern Recognition, 3202– 3211.\nNational Centers for Environmental Prediction, National Weather Service,\nNOAA, U.S. Department of Commerce (2015). Ncep gfs 0.25 degree global\nforecast grids historical archive.\nOktay, O., Schlemper, J., Folgoc, L. L., Lee, M., Heinrich, M., Misawa, K., et al.\n(2018). Attention u-net: Learning where to look for the pancreas.\nPeng, X., Che, Y., and Chang, J. (2013). A novel approach to improve\nnumerical weather prediction skills by using anomaly integration and\nhistorical data. J. Geophys. Res. Atmos. 118, 8814 – 8826. doi:10.1002/jgrd.\n50682\nPrivé, N. C., and Errico, R. M. (2013). The role of model and initial condition\nerror in numerical weather forecasting investigated with an observing system\nsimulation experiment. Tellus A Dyn. Meteorology Oceanogr.65, 21740. doi:10.\n3402/tellusa.v65i0.21740\nQian, W.-H. (2012). How to improve the skills of weather and climate\npredictions? Chin. J. Geophys.55, 1532– 1540.\nQiao, S., Zou, M., Cheung, H. N., Zhou, W., Li, Q., Feng, G., et al. (2020).\nPredictability of the wintertime 500 hpa geopotential height over ural-siberia in the\nncep climate forecast system.Clim. Dyn.54, 1591– 1606. doi:10.1007/s00382-019-\n05074-8\nRonneberger, O., Fischer, P., and Brox, T. (2015). “U-net: Convolutional\nnetworks for biomedical image segmentation,\n” in International Conference on\nMedical image computing and computer-assisted intervention, 234– 241.\nSchulze, G. (2007). Atmospheric observations and numerical weather prediction:\nSaeon review. South Afr. J. Sci.103, 318– 323.\nShi, X., Gao, Z., Lausen, L., Wang, H., Yeung, D.-Y., Wong, W.-k., et al. (2017).\nDeep learning for precipitation nowcasting: A benchmark and a new model.Adv.\nneural Inf. Process. Syst.30.\nShuman, F. G. (1989). History of numerical weather prediction at the national\nmeteorological center.Weather Forecast.4, 286– 296. doi:10.1175/1520-0434(1989)\n004<0286:honwpa>2.0.co;2\nSimonyan, K., and Zisserman, A. (2014).Very deep convolutional networks for\nlarge-scale image recognition.\nSloughter, J. M., Gneiting, T., and Raftery, A. E. (2010). Probabilistic wind speed\nforecasting using ensembles and bayesian model averaging.J. Am. Stat. Assoc.105,\n25– 35. doi:10.1198/jasa.2009.ap08615\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., et al.\n(2017). Attention is all you need.Adv. neural Inf. Process. Syst.30.\nW a n g ,R . ,W a n g ,D . ,Q i ,J . ,W u ,J . ,L i a n g ,S . ,a n dH u a n g ,Z .( 2 0 2 1 ) .“Research\nsituation and development trends of deep learning application in\nmeteorology, ” in International Conference on Arti ﬁcial Intelligence and\nSecurity, 451 – 462.\nWu, H., Yang, Q., Liu, J., and Wang, G. (2020a). A spatiotemporal deep fusion\nmodel for merging satellite and gauge precipitation in China.J. Hydrology 584,\n124664. doi:10.1016/j.jhydrol.2020.124664\nWu, Z., Liu, Z., Lin, J., Lin, Y., and Han, S. (2020b).Lite transformer with long-\nshort range attention.\nXiang, L., Xiang, J., Guan, J., Zhang, F., Zhao, Y., and Zhang, L. (2022). A novel\nreference-based and gradient-guided deep learning model for daily precipitation\ndownscaling. Atmosphere 13, 511. doi:10.3390/atmos13040511\nXue, M., Hang, R., Liu, Q., Yuan, X.-T., and Lu, X. (2021). Cnn-based near-real-\ntime precipitation estimation from fengyun-2 satellite over xinjiang, China.Atmos.\nRes. 250, 105337. doi:10.1016/j.atmosres.2020.105337\nYang, D. (2019). On post-processing day-ahead nwp forecasts using kalman\nﬁltering. Sol. Energy 182, 179– 181. doi:10.1016/j.solener.2019.02.044\nZhang, F., Wang, X., Guan, J., Wu, M., and Guo, L. (2021). Rn-Net: A deep\nlearning approach to 0– 2 hour rainfall nowcasting based on radar and automatic\nweather station data.Sensors 21, 1981. doi:10.3390/s21061981\nZhou, H., Zhang, S., Peng, J., Zhang, S., Li, J., Xiong, H., et al. (2021a).\nInformer: Beyond ef ﬁcient transformer for long sequence time-series\nforecasting. Proc. AAAI Conf. Artif. Intell. 35, 11106 – 11115. doi:10.1609/\naaai.v35i12.17325\nZhou, Q., Chen, D., Hu, Z., and Chen, X. (2021b). Decompositions of Taylor\ndiagram and diso performance criteria.Int. J. Climatol.41, 5726– 5732. doi:10.1002/\njoc.7149\nZhu, Y. (2005). Ensemble forecast: A new approach to uncertainty and\npredictability. Adv. Atmos. Sci.22, 781– 788. doi:10.1007/bf02918678\nFrontiers inEnvironmental Science frontiersin.org15\nXiang et al. 10.3389/fenvs.2022.1039764",
  "topic": "Downscaling",
  "concepts": [
    {
      "name": "Downscaling",
      "score": 0.8949811458587646
    },
    {
      "name": "Mean squared error",
      "score": 0.6279997825622559
    },
    {
      "name": "Numerical weather prediction",
      "score": 0.5981595516204834
    },
    {
      "name": "Computer science",
      "score": 0.5249695181846619
    },
    {
      "name": "Transformer",
      "score": 0.464322030544281
    },
    {
      "name": "Temporal resolution",
      "score": 0.4585866630077362
    },
    {
      "name": "Meteorology",
      "score": 0.37061482667922974
    },
    {
      "name": "Algorithm",
      "score": 0.3600982427597046
    },
    {
      "name": "Mathematics",
      "score": 0.3148443102836609
    },
    {
      "name": "Statistics",
      "score": 0.25810205936431885
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Precipitation",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I170215575",
      "name": "National University of Defense Technology",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210141776",
      "name": "China XD Group (China)",
      "country": "CN"
    }
  ],
  "cited_by": 12
}