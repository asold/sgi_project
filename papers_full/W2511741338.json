{
  "title": "Numerically Grounded Language Models for Semantic Error Correction",
  "url": "https://openalex.org/W2511741338",
  "year": 2016,
  "authors": [
    {
      "id": "https://openalex.org/A5015056626",
      "name": "Georgios Spithourakis",
      "affiliations": [
        "National Technical University of Athens"
      ]
    },
    {
      "id": "https://openalex.org/A5018976680",
      "name": "Isabelle Augenstein",
      "affiliations": [
        "University College London"
      ]
    },
    {
      "id": "https://openalex.org/A5101404695",
      "name": "Sebastian Riedel",
      "affiliations": [
        "University College London"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2252122141",
    "https://openalex.org/W2130359236",
    "https://openalex.org/W2250742840",
    "https://openalex.org/W224572144",
    "https://openalex.org/W2494752089",
    "https://openalex.org/W2112184938",
    "https://openalex.org/W1605960500",
    "https://openalex.org/W2084531783",
    "https://openalex.org/W2251885125",
    "https://openalex.org/W6908809",
    "https://openalex.org/W2167025863",
    "https://openalex.org/W2149557440",
    "https://openalex.org/W2126618487",
    "https://openalex.org/W806995027",
    "https://openalex.org/W2137115322",
    "https://openalex.org/W166374374",
    "https://openalex.org/W2026645695",
    "https://openalex.org/W2473539527"
  ],
  "abstract": "Semantic error detection and correction is an important task for applications such as fact checking, speech-to-text or grammatical error correction. Current approaches generally focus on relatively shallow semantics and do not account for numeric quantities. Our approach uses language models grounded in numbers within the text. Such groundings are easily achieved for recurrent neural language model architectures, which can be further conditioned on incomplete background knowledge bases. Our evaluation on clinical reports shows that numerical grounding improves perplexity by 33% and F1 for semantic error correction by 5 points when compared to ungrounded approaches. Conditioning on a knowledge base yields further improvements.",
  "full_text": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 987–992,\nAustin, Texas, November 1-5, 2016.c⃝2016 Association for Computational Linguistics\nNumerically Grounded Language Models for Semantic Error Correction\nGeorgios P. Spithourakisand Isabelle Augenstein and Sebastian Riedel\nDepartment of Computer Science\nUniversity College London\n{g.spithourakis, i.augenstein, s.riedel}@cs.ucl.ac.uk\nAbstract\nSemantic error detection and correction is an\nimportant task for applications such as fact\nchecking, speech-to-text or grammatical er-\nror correction. Current approaches gener-\nally focus on relatively shallow semantics and\ndo not account for numeric quantities. Our\napproach uses language models grounded in\nnumbers within the text. Such groundings\nare easily achieved for recurrent neural lan-\nguage model architectures, which can be fur-\nther conditioned on incomplete background\nknowledge bases. Our evaluation on clinical\nreports shows that numerical grounding im-\nproves perplexity by 33% and F1 for semantic\nerror correction by 5 points when compared\nto ungrounded approaches. Conditioning on a\nknowledge base yields further improvements.\n1 Introduction\nIn many real world scenarios it is important to de-\ntect and potentially correct semantic errors and in-\nconsistencies in text. For example, when clinicians\ncompose reports, some statements in the text may\nbe inconsistent with measurements taken from the\npatient (Bowman, 2013). Error rates in clinical\ndata range from 2.3% to 26.9% (Goldberg et al.,\n2008) and many of them are number-based errors\n(Arts et al., 2002). Likewise, a blog writer may\nmake statistical claims that contradict facts recorded\nin databases (Munger, 2008). Numerical concepts\nconstitute 29% of contradictions in Wikipedia and\nGoogleNews (De Marneffe et al., 2008) and 8.8%\nof contradictory pairs in entailment datasets (Dagan\net al., 2006).\nFigure 1: Semantic error correction using language models.\n“EF” is a clinical term and stands for “ejection fraction”.\nThese inconsistencies may stem from oversight,\nlack of reporting guidelines or negligence. In fact\nthey may not even be errors at all, but point to inter-\nesting outliers or to errors in a reference database. In\nall cases, it is important to spot and possibly correct\nsuch inconsistencies. This task is known as semantic\nerror correction (SEC) (Dahlmeier and Ng, 2011).\nIn this paper, we propose a SEC approach to sup-\nport clinicians with writing patient reports. A SEC\nsystem reads a patient’s structured background in-\nformation from a knowledge base ( KB) and their\nclinical report. Then it recommends improvements\nto the text of the report for semantic consistency. An\nexample of an inconsistency is shown in Figure 1.\n987\nThe SEC system has been trained on a dataset of\nrecords and learnt that the phrases “non dilated” and\n“severely dilated” correspond to high and low val-\nues for “EF” (abbreviation for “ejection fraction”, a\nclinical measurement), respectively. If the system\nis then presented with the phrase “non dilated” in\nthe context of a low value, it will detect a seman-\ntic inconsistency and correct the text to “severely di-\nlated”.\nOur contributions are: 1) a straightforward ex-\ntension to recurrent neural network (RNN) language\nmodels for grounding them in numbers available in\nthe text; 2) a simple method for modelling text con-\nditioned on an incomplete KB by lexicalising it; 3)\nour evaluation on a semantic error correction task\nfor clinical records shows that our method achieves\nF1 improvements of 5 and 6 percentage points with\ngrounding and KB conditioning, respectively, over\nan ungrounded approach (F1 of 49%).\n2 Methodology\nOur approach to semantic error correction (Figure 1)\nstarts with training a language model (LM), which\ncan be grounded in numeric quantities mentioned in-\nline with text (Subsection 2.1) and/or conditioned\non a potentially incomplete KB (Subsection 2.2).\nGiven a document for semantic checking, a hypoth-\nesis generator proposes corrections, which are then\nscored using the trained language model (Subsec-\ntion 2.3). A ﬁnal decision step involves accepting\nthe best scoring hypothesis.\n2.1 Numerically grounded language modelling\nLet {w1, ..., wT }denote a document, where wt is\nthe one-hot representation of the t-th token and V\nis the vocabulary size. A neural LM uses a ma-\ntrix, Ein ∈ RD×V , to derive word embeddings,\new\nt = Einwt. A hidden state from the previous time\nstep, ht−1, and the current word embedding, ew\nt , are\nsequentially fed to an RNN’s recurrence function to\nproduce the current hidden state,ht ∈RD. The con-\nditional probability of the next word is estimated as\nsoftmax(Eoutht), where Eout ∈RV ×D is an output\nembeddings matrix.\nWe propose concatenating a representation,en\nt , of\nthe numeric value of wt to the inputs of the RNN’s\nrecurrence function at each time step. Through this\nFigure 2:A language model that is numerically grounded and\nconditioned on a lexicalised KB. Examples of data in rounded\nrectangles.\nnumeric representation, the model can generalise\nto out-of-vocabulary numbers. A straightforward\nrepresentation is deﬁning en\nt = ﬂoat( wt), where\nﬂoat(.) is a numeric conversion function that returns\na ﬂoating point number constructed from the string\nof its input. If conversion fails, it returns zero.\nThe proposed mechanism for numerical ground-\ning is shown in Figure 2. Now the probability of\neach next word depends on numbers that have ap-\npeared earlier in the text. We treat numbers as a\nseparate modality that happens to share the same\nmedium as natural language (text), but can convey\nexact measurements of properties of the real world.\nAt training time, the numeric representations medi-\nate to ground the language model in the real world.\n2.2 Conditioning on incomplete KBs\nThe proposed extension can also be used in con-\nditional language modelling of documents given a\nknowledge base. Consider a set of KB tuples accom-\npanying each document and describing its attributes\nin the form < attribute, value >, where attributes\nare deﬁned by a KB schema. We can lexicalise the\nKB by converting its tuples into textual statements\nof the form ” attribute : value”. An example of\nhow we lexicalise the KB is shown in Figure 2. The\ngenerated tokens can then be interpreted for their\nword embeddings and numeric representations. This\n988\ntrain dev test\n#documents 11,158 1,625 3,220\n#tokens/\ndoc\nall 204.9 204.4 202.2\nwords 95.7% 95.7% 95.7%\nnumeric 4.3% 4.3% 4.3%\n#unique\ntokens\nall 18,916 6,572 9,515\nwords 47.8% 58.25% 54.1%\nnumeric 52.24% 41.9% 45.81%\nOOV\nrate\nall 5.0% 5.1% 5.2%\nwords 3.4% 3.5% 3.5%\nnumeric 40.4% 40.8% 41.8%\nTable 1:Statistics for clinical dataset. Counts for non-numeric\n(words) and numeric tokens reported as percentage of counts for\nall tokens. Out-of-vocabulary (OOV) rates are for vocabulary of\n1000 most frequent words in the train data.\napproach can incorporate KB tuples ﬂexibly, even\nwhen values of some attributes are missing.\n2.3 Semantic error correction\nA statistical model chooses the most likely correc-\ntion from a set of possible correction choices. If the\nmodel scores a corrected hypothesis higher than the\noriginal document, the correction is accepted.\nA hypothesis generator function , G, takes the\noriginal document, H0, as input and generates a\nset of candidate corrected documents G(H0) =\n{H1, ..., HM }. A simple hypothesis generator uses\nconfusion sets of semantically related words to pro-\nduce all possible substitutions.\nA scorer model, s, assigns a score s(Hi) ∈ R\nto a hypothesis Hi. The scorer is based on a likeli-\nhood ratio test between the original document (null\nhypothesis, H0) and each candidate correction (al-\nternative hypotheses, Hi), i.e. s(Hi) = p(Hi)\np(H0) . The\nassigned score represents how much more probable\na correction is than the original document.\nThe probability of observing a document, p(Hi),\ncan be estimated using language models, or\ngrounded and conditional variants thereof.\n3 Data\nOur dataset comprises 16,003 clinical records from\nthe London Chest Hospital (Table 1). Each patient\nrecord consists of a text report and accompanying\nstructured KB tuples. The latter describe 20 possible\nnumeric attributes (age, gender, etc.), which are also\ndescription confusion set\nintensiﬁers (adv): non, mildly, severely\nintensiﬁers (adj): mild, moderate, severe\nunits: cm, mm, ml, kg, bpm\nviability: viable, non-viable\nquartiles: 25, 50, 75, 100\ninequalities: <, >\nTable 2:Confusion sets.\npartly contained in the report. On average,7.7 tuples\nare completed per record. Numeric tokens constitute\nonly a small proportion of each sentence (4.3%), but\naccount for a large part of the unique tokens vocab-\nulary (>40%) and suffer from high OOV rates.\nTo evaluate SEC, we generate a “corrupted”\ndataset of semantic errors from the test part of the\n“trusted” dataset (Table 1, last column). We manu-\nally build confusion sets (Table 2) by searching the\ndevelopment set for words related to numeric quanti-\nties and grouping them if they appear in similar con-\ntexts. Then, for each document in the trusted test\nset we generate an erroneous document by sampling\na substitution from the confusion sets. Documents\nwith no possible substitution are excluded. The re-\nsulting “corrupted” dataset is balanced, containing\n2,926 correct and 2,926 incorrect documents.\n4 Results and discussion\nOur base LM is a single-layer long short-term mem-\nory network (LSTM, Hochreiter and Schmidhuber\n(1997) with all latent dimensions (internal matrices,\ninput and output embeddings) set to D = 50 . We\nextend this baseline to a conditional variant by con-\nditioning on the lexicalised KB (see Section 2.2).\nWe also derive a numerically grounded model by\nconcatenating the numerical representation of each\ntoken to the inputs of the base LM model (see Sec-\ntion 2.1). Finally, we consider a model that is both\ngrounded and conditional (g-conditional).\nThe vocabulary contains the V = 1000 most fre-\nquent tokens in the training set. Out-of-vocabulary\ntokens are substituted with <num unk>, if nu-\nmeric, and <unk>, otherwise. We extract the\nnumerical representations before masking, so that\nthe grounded models can generalise to out-of-\nvocabulary numbers. Models are trained to min-\nimise token cross-entropy, with 20 epochs of back-\n989\nmodel tokens PP APP\nbase LM\nall 14.96 22.11\nwords 13.93 17.94\nnumeric 72.38 2289.47\nconditional\nall 14.52 21.47\nwords 13.49 17.38\nnumeric 74.48 2355.77\ngrounded\nall 9.91 14.66\nwords 9.28 11.96\nnumeric 42.67 1349.59\ng-conditional\nall 9.39 13.88\nwords 8.80 11.33\nnumeric 39.84 1260.28\nTable 3:Language modelling evaluation results on the test set.\nWe report perplexity (PP) and adjusted perplexity (APP). Best\nresults in bold.\npropagation and adaptive mini-batch gradient de-\nscent (AdaDelta) (Zeiler, 2012).\nFor SEC, we use an oracle hypothesis generator\nthat has access to the groundtruth confusion sets (Ta-\nble 2). We estimate the scorer (Section 2.3) using the\ntrained base, conditional, grounded or g-conditional\nLMs. As additional baselines we consider a scorer\nthat assigns random scores from a uniform distribu-\ntion and always (never) scorers that assign the low-\nest (highest) score to the original document and uni-\nformly random scores to the corrections.\n4.1 Experiment 1: Numerically grounded LM\nWe report perplexity and adjusted perplexity (Ue-\nberla, 1994) of our LMs on the test set for all tokens\nand token classes (Table 3). Adjusted perplexity is\nnot sensitive to OOV-rates and thus allows for mean-\ningful comparisons across token classes. Perplexi-\nties are high for numeric tokens because they form a\nlarge proportion of the vocabulary. The grounded\nand g-conditional models achieved a 33.3% and\n36.9% improvement in perplexity, respectively, over\nthe base LM model. Conditioning without ground-\ning yields only slight improvements, because most\nof the numerical values from the lexicalised KB are\nout-of-vocabulary.\nThe qualitative example in Figure 3 demonstrates\nhow numeric values inﬂuence the probability of to-\nkens given their history. We select a document from\nthe development set and substitute its numeric val-\nFigure 3:Qualitative example. Template document and docu-\nment probabilities for<WORD>={‘non’, ‘mildly’, ‘severely’}\nand varying numbers. Probabilities are renormalised over the\nset of possible choices.\nues as we vary EF (the rest are set by solving\na known system of equations). The selected ex-\nact values were unseen in the training data. We\ncalculate the probabilities for observing the docu-\nment with different word choices {“non”, “mildly”,\n“severely”}under the grounded LM and ﬁnd that\n“non dilated” is associated with higher EF values.\nThis shows that it has captured semantic dependen-\ncies on numbers.\n4.2 Experiment 2: Semantic error correction\nWe evaluate SEC systems on the corrupted dataset\n(Section 3) for detection and correction.\nFor detection, we report precision, recall and F1\nscores in Table 4. Our g-conditional model achieves\nthe best results, a total F1 improvement of 2 points\nover the base LM model and 7 points over the best\nbaseline. The conditional model without ground-\ning performs slightly worse in the F1 metric than\nthe base LM . Note that with more hypotheses the\nrandom baseline behaves more similarly to always.\nOur hypothesis generator generated on average 12\nhypotheses per document. The results of never are\nzero as it fails to detect any error.\nFor correction, we report mean average precision\n(MAP) in addition to the same metrics as for detec-\ntion (Table 5). The former measures the position\nof the ranking of the correct hypothesis. The al-\nways (never) baseline ranks the correct hypothesis\nat the top (bottom). Again, the g-conditional model\n990\nmodel P R F1\nrandom 50.27 90.29 64.58\nalways 50.00 100.0 66.67\nnever 0.0 0.0 0.0\nbase LM 57.51 94.05 71.38\nconditional 56.86 94.43 70.98\ngrounded 58.87 94.70 72.61\ng-conditional 60.48 95.25 73.98\nTable 4:Error detection results on the test set. We report preci-\nsion (P), recall (R) and F1. Best results in bold.\nyields the best results, achieving an improvement of\n6 points in F1 and 5 points in MAP over the base\nLM model and an improvement of 47 points in F1\nand 9 points in MAP over the best baseline. The\nconditional model without grounding has the worst\nperformance among the LM-based models.\n5 Related Work\nGrounded language models represent the relation-\nship between words and the non-linguistic con-\ntext they refer to. Previous work grounds lan-\nguage on vision (Bruni et al., 2014; Socher et al.,\n2014; Silberer and Lapata, 2014), audio (Kiela and\nClark, 2015), video (Fleischman and Roy, 2008),\ncolour (McMahan and Stone, 2015), and olfactory\nperception (Kiela et al., 2015). However, no pre-\nvious approach has explored in-line numbers as a\nsource of grounding.\nOur language modelling approach to SEC is in-\nspired by LM approaches to grammatical error de-\ntection (GEC) (Ng et al., 2013; Felice et al., 2014).\nThey similarly derive confusion sets of semantically\nrelated words, substitute the target words with al-\nternatives and score them with an LM. Existing se-\nmantic error correction approaches aim at correct-\ning word error choices (Dahlmeier and Ng, 2011),\ncollocation errors (Kochmar, 2016), and semantic\nanomalies in adjective-noun combinations (Vecchi\net al., 2011). So far, SEC approaches focus on\nshort distance semantic agreement, whereas our ap-\nproach can detect errors which require to resolve\nlong-range dependencies. Work on GEC and SEC\nshows that language models are useful for error cor-\nrection, however they neither ground in numeric\nquantities nor incorporate background KBs.\nmodel MAP P R F1\nrandom 27.75 5.73 10.29 7.36\nalways 20.39 6.13 12.26 8.18\nnever 60.06 0.0 0.0 0.0\nbase LM 64.37 39.54 64.66 49.07\nconditional 62.76 37.46 62.20 46.76\ngrounded 68.21 44.25 71.19 54.58\ng-conditional 69.14 45.36 71.43 55.48\nTable 5:Error correction results on the test set. We report mean\naverage precision (MAP), precision (P), recall (R) and F1. Best\nresults in bold.\n6 Conclusion\nIn this paper, we proposed a simple technique to\nmodel language in relation to numbers it refers to,\nas well as conditionally on incomplete knowledge\nbases. We found that the proposed techniques lead to\nperformance improvements in the tasks of language\nmodelling, and semantic error detection and correc-\ntion. Numerically grounded models make it possible\nto capture semantic dependencies of content words\non numbers.\nIn future work, we will plan to apply numeri-\ncally grounded models to other tasks, such as nu-\nmeric error correction. We will explore alternative\nways for deriving the numeric representations, such\nas accounting for verbal descriptions of numbers.\nFor SEC, a trainable hypothesis generator can po-\ntentially improve the coverage of the system.\nAcknowledgments\nThe authors would like to thank the anonymous\nreviewers for their insightful comments. We also\nthank Steffen Petersen for providing the dataset and\nadvising us on the clinical aspects of this work.\nThis research was supported by the Farr Institute\nof Health Informatics Research, an Allen Distin-\nguished Investigator award and Elsevier.\nReferences\nDanielle GT Arts, Nicolette F De Keizer, and Gert-Jan\nScheffer. 2002. Deﬁning and improving data quality\nin medical registries: a literature review, case study,\nand generic framework. Journal of the American Med-\nical Informatics Association, 9(6):600–611.\n991\nSue Bowman. 2013. Impact of Electronic Health\nRecord Systems on Information Integrity: Quality and\nSafety Implications. Perspectives in Health Informa-\ntion Management, page 1.\nElia Bruni, Nam-Khanh Tran, and Marco Baroni. 2014.\nMultimodal distributional semantics. J. Artif. Intell.\nRes.(JAIR), 49(1-47).\nIdo Dagan, Oren Glickman, and Bernardo Magnini.\n2006. The pascal recognising textual entailment\nchallenge. In Machine learning challenges. evaluat-\ning predictive uncertainty, visual object classiﬁcation,\nand recognising tectual entailment , pages 177–190.\nSpringer.\nDaniel Dahlmeier and Hwee Tou Ng. 2011. Correcting\nSemantic Collocation Errors with L1-induced Para-\nphrases. In Proceedings of EMNLP, pages 107–117.\nMarie-Catherine De Marneffe, Anna N Rafferty, and\nChristopher D Manning. 2008. Finding Contradic-\ntions in Text. In ACL, volume 8, pages 1039–1047.\nMariano Felice, Zheng Yuan, Øistein E Andersen, He-\nlen Yannakoudakis, and Ekaterina Kochmar. 2014.\nGrammatical error correction using hybrid systems\nand type ﬁltering. In CoNLL Shared Task, pages 15–\n24.\nMichael Fleischman and Deb Roy. 2008. Grounded Lan-\nguage Modeling for Automatic Speech Recognition of\nSports Video. In Proceedings of ACL, pages 121–129.\nSaveli Goldberg, Andrzej Niemierko, and Alexander\nTurchin. 2008. Analysis of data errors in clinical re-\nsearch databases. In AMIA. Citeseer.\nSepp Hochreiter and J ¨urgen Schmidhuber. 1997. Long\nshort-term memory. Neural computation, 9(8):1735–\n1780.\nDouwe Kiela and Stephen Clark. 2015. Multi- and\nCross-Modal Semantics Beyond Vision: Grounding\nin Auditory Perception. In Proceedings of EMNLP ,\npages 2461–2470.\nDouwe Kiela, Luana Bulat, and Stephen Clark. 2015.\nGrounding Semantics in Olfactory Perception. In Pro-\nceedings of ACL, pages 231–236.\nEkaterina Kochmar. 2016. Error Detection in Content\nWord Combinations. Ph.D. thesis, University of Cam-\nbridge, Computer Laboratory.\nBrian McMahan and Matthew Stone. 2015. A bayesian\nmodel of grounded color semantics. Transactions of\nthe Association for Computational Linguistics, 3:103–\n115.\nMichael C Munger. 2008. Blogging and political infor-\nmation: truth or truthiness? Public Choice , 134(1-\n2):125–138.\nHwee Tou Ng, Siew Mei Wu, Yuanbin Wu, Christian\nHadiwinoto, and Joel Tetreault. 2013. The CoNLL-\n2013 Shared Task on Grammatical Error Correction.\nIn Hwee Tou Ng, Joel Tetreault, Siew Mei Wu, Yuan-\nbin Wu, and Christian Hadiwinoto, editors, Proceed-\nings of the CoNLL: Shared Task, pages 1–12.\nCarina Silberer and Mirella Lapata. 2014. Learn-\ning Grounded Meaning Representations with Autoen-\ncoders. In Proceedings of ACL, pages 721–732.\nRichard Socher, Andrej Karpathy, Quoc V . Le, Christo-\npher D. Manning, and Andrew Y . Ng. 2014.\nGrounded Compositional Semantics for Finding and\nDescribing Images with Sentences. TACL, 2:207–218.\nJoerg Ueberla. 1994. Analysing a simple language\nmodel·some general conclusions for language mod-\nels for speech recognition. Computer Speech & Lan-\nguage, 8(2):153–176.\nEva Maria Vecchi, Marco Baroni, and Roberto Zampar-\nelli. 2011. (Linear) Maps of the Impossible: Captur-\ning semantic anomalies in distributional space. InPro-\nceedings of the Workshop on Distributional Semantics\nand Compositionality, pages 1–9.\nMatthew D. Zeiler. 2012. ADADELTA: An Adaptive\nLearning Rate Method. CoRR, abs/1212.5701.\n992",
  "topic": "Perplexity",
  "concepts": [
    {
      "name": "Perplexity",
      "score": 0.9455100297927856
    },
    {
      "name": "Computer science",
      "score": 0.7589632868766785
    },
    {
      "name": "Natural language processing",
      "score": 0.6729257702827454
    },
    {
      "name": "Artificial intelligence",
      "score": 0.611139714717865
    },
    {
      "name": "Language model",
      "score": 0.6010809540748596
    },
    {
      "name": "Semantics (computer science)",
      "score": 0.5935558676719666
    },
    {
      "name": "Error detection and correction",
      "score": 0.578707218170166
    },
    {
      "name": "Focus (optics)",
      "score": 0.5243913531303406
    },
    {
      "name": "Task (project management)",
      "score": 0.5227066278457642
    },
    {
      "name": "Algorithm",
      "score": 0.21997401118278503
    },
    {
      "name": "Programming language",
      "score": 0.16981583833694458
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Optics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I174458059",
      "name": "National Technical University of Athens",
      "country": "GR"
    },
    {
      "id": "https://openalex.org/I45129253",
      "name": "University College London",
      "country": "GB"
    }
  ]
}