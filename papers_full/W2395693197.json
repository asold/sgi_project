{
  "title": "Emoticon Smoothed Language Models for Twitter Sentiment Analysis",
  "url": "https://openalex.org/W2395693197",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2328232551",
      "name": "Kun-Lin Liu",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A4202857191",
      "name": "Wu-Jun Li",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2162841773",
      "name": "Minyi Guo",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2328232551",
      "name": "Kun-Lin Liu",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A4202857191",
      "name": "Wu-Jun Li",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    },
    {
      "id": "https://openalex.org/A2162841773",
      "name": "Minyi Guo",
      "affiliations": [
        "Shanghai Jiao Tong University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2124156373",
    "https://openalex.org/W2112251034",
    "https://openalex.org/W6836791981",
    "https://openalex.org/W2113125055",
    "https://openalex.org/W93018862",
    "https://openalex.org/W2198817044",
    "https://openalex.org/W6677771139",
    "https://openalex.org/W6631834165",
    "https://openalex.org/W6674691379",
    "https://openalex.org/W2951278869",
    "https://openalex.org/W2093390569",
    "https://openalex.org/W2143570397",
    "https://openalex.org/W1972594981",
    "https://openalex.org/W1532325895",
    "https://openalex.org/W2021891520",
    "https://openalex.org/W2166706824",
    "https://openalex.org/W2171645516",
    "https://openalex.org/W2059503205",
    "https://openalex.org/W2097726431",
    "https://openalex.org/W2029181554",
    "https://openalex.org/W2119759918",
    "https://openalex.org/W2267835966",
    "https://openalex.org/W4206765718",
    "https://openalex.org/W4213009331",
    "https://openalex.org/W4255173720",
    "https://openalex.org/W142212369"
  ],
  "abstract": "Twitter sentiment analysis (TSA) has become a hot research topic in recent years. The goal of this task is to discover the attitude or opinion of the tweets, which is typically formulated as a machine learning based text classification problem. Some methods use manually labeled data to train fully supervised models, while others use some noisy labels, such as emoticons and hashtags, for model training. In general, we can only get a limited number of training data for the fully supervised models because it is very labor-intensive and time-consuming to manually label the tweets. As for the models with noisy labels, it is hard for them to achieve satisfactory performance due to the noise in the labels although it is easy to get a large amount of data for training. Hence, the best strategy is to utilize both manually labeled data and noisy labeled data for training. However, how to seamlessly integrate these two different kinds of data into the same learning framework is still a challenge. In this paper, we present a novel model, called emoticon smoothed language model (ESLAM), to handle this challenge. The basic idea is to train a language model based on the manually labeled data, and then use the noisy emoticon data for smoothing. Experiments on real data sets demonstrate that ESLAM can effectively integrate both kinds of data to outperform those methods using only one of them.",
  "full_text": "Emoticon Smoothed Language Models\nfor Twitter Sentiment Analysis\nKun-Lin Liu, Wu-Jun Li, Minyi Guo\nShanghai Key Laboratory of Scalable Computing and Systems\nDepartment of Computer Science and Engineering, Shanghai Jiao Tong University, China\nliukunlin@sjtu.edu.cn, {liwujun,guo-my}@cs.sjtu.edu.cn\nAbstract\nTwitter sentiment analysis (TSA) has become a hot research\ntopic in recent years. The goal of this task is to discover\nthe attitude or opinion of the tweets, which is typically\nformulated as a machine learning based text classiﬁcation\nproblem. Some methods use manually labeled data to\ntrain fully supervised models, while others use some noisy\nlabels, such as emoticons and hashtags, for model training.\nIn general, we can only get a limited number of training\ndata for the fully supervised models because it is very\nlabor-intensive and time-consuming to manually label the\ntweets. As for the models with noisy labels, it is hard for\nthem to achieve satisfactory performance due to the noise\nin the labels although it is easy to get a large amount of\ndata for training. Hence, the best strategy is to utilize both\nmanually labeled data and noisy labeled data for training.\nHowever, how to seamlessly integrate these two different\nkinds of data into the same learning framework is still a\nchallenge. In this paper, we present a novel model, called\ne\nmoticon smoothed language model (ESLAM), to handle\nthis challenge. The basic idea is to train a language model\nbased on the manually labeled data, and then use the noisy\nemoticon data for smoothing. Experiments on real data sets\ndemonstrate that ESLAM can effectively integrate both kinds\nof data to outperform those methods using only one of them.\nIntroduction\nSentiment analysis (SA) (Pang and Lee 2007) (also known\nas opinion mining) is mainly about discovering “what others\nthink” from data such as product reviews and news articles.\nOn one hand, consumers can seek advices about a product\nto make informed decisions in the consuming process. On\nthe other hand, vendors are paying more and more atten-\ntion to online opinions about their products and services.\nHence, SA has attracted increasing attention from many re-\nsearch communities such as machine learning, data mining,\nand natural language processing. The sentiment of a docu-\nment or sentence can be positive, negative or neutral. Hence,\nSA is actually a three-way classiﬁcation problem. In prac-\ntice, most methods adopt a two-step strategy for SA (Pang\nand Lee 2007). In the subjectivity classiﬁcation step, the tar-\nget is classiﬁed to be subjective or neutral (objective), and\nin the polarity classiﬁcation step, the subjective targets are\nCopyright c⃝ 2012, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\nfurther classiﬁed as positive or negative. Hence, two clas-\nsiﬁers are trained for the whole SA process, one is called\nsubjectivity classiﬁer, and the other is called polarity classi-\nﬁer. Since (Pang, Lee, and Vaithyanathan 2002) formulated\nSA as a machine learning based text classiﬁcation problem,\nmore and more machine learning methods have been pro-\nposed for SA (Pang and Lee 2007).\nTwitter is a popular online micro-blogging service\nlaunched in 2006. Users on Twitter write tweets up to 140\ncharacters to tell others about what they are doing and think-\ning. According to the some sources 1, until 2011, there have\nbeen over 300 million users on Twitter and 300 million new\ntweets are generated every day. Because almost all tweets\nare public, these rich data offer new opportunities for do-\ning research on data mining and natural language process-\ning(Liu et al. 2011a; 2011b; 2011c; Jiang et al. 2011).\nOne way to perform Twitter sentiment analysis (TSA) is\nto directly exploit traditional SA methods (Pang and Lee\n2007). However, tweets are quite different from other text\nforms like product reviews and news articles. Firstly, tweets\nare often short and ambiguous because of the limitation of\ncharacters. Secondly, there’re more misspelled words, slang,\nmodal particles and acronyms on Twitter because of its ca-\nsual form. Thirdly, a huge amount of unlabeled or noisy la-\nbeled data can be easily downloaded through Twitter API.\nTherefore, many novel SA methods have been specially de-\nveloped for TSA. These methods can be mainly divided into\ntwo categories: fully supervised methods and distantly su-\npervised methods2.\nThe fully supervised methods try to learn the classi-\nﬁers from manually labeled data. (Jansen et al. 2009) uses\nthe multinomial Bayes model to perform automatic TSA.\n(Bermingham and Smeaton 2010) compares support vector\nmachine (SVM) and multinomial naive Bayes (MNB) for\nboth blog and microblog SA, and ﬁnds that SVM outper-\nforms MNB on blogs with long text but MNB outperforms\nSVM on microblogs with short text. One problem with the\nfully supervised methods is that it is very labor-intensive and\ntime-consuming to manually label the data and hence the\ntraining data sets for most methods are often too small to\n1http://en.wikipedia.org/wiki/Twitter\n2We use the terminology ‘distant’ as that from (Go, Bhayani,\nand Huang 2009).\nProceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence\n1678\nguarantee a good performance.\nMore recent works have focused on distantly supervised\nmethods which learn the classiﬁers from data with noisy la-\nbels such as emoticons and hashtags. The distant supervi-\nsion method (Go, Bhayani, and Huang 2009) uses the emoti-\ncons like “:)” and “:(” as noisy labels for polarity classiﬁca-\ntion. The basic assumption is that a tweet containing “:)”\nis most likely to have a positive emotion and that contain-\ning “:(” is assumed to be negative. Experiments show that\nthese emoticons do contain some discriminative informa-\ntion for SA. Hashtags (e.g., #sucks) or Smileys are used in\n(Davidov, Tsur, and Rappoport 2010) to identify sentiment\ntypes. (Barbosa and Feng 2010) uses the noisy data collected\nfrom some Twitter sentiment detection web sites, such as the\nTwitter Sentiment3. (Kouloumpis, Wilson, and Moore 2011)\ninvestigates both hashtags and emoticons and ﬁnds that com-\nbining both of them can get better performance than using\nonly hashtags. The advantage of these distantly supervised\nmethods is that the labor-intensive manual annotation can\nbe avoided and a large amount of training data can be easily\nbuilt, either from Twitter API or existing web sites. How-\never, due to the noise in the labels, the accuracy of these\nmethods is not satisfactory.\nConsidering the shortcomings of the fully supervised and\ndistantly supervised methods, we argue that the best strat-\negy is to utilize both manually labeled data and noisy la-\nbeled data for training. However, how to seamlessly inte-\ngrate these two different kinds of data into the same learn-\ning framework is still a challenge. In this paper, we propose\na novel model, called e\nmoticon smoothed language model\n(ESLAM), to handle this challenge. The main contributions\nof ESLAM are outlined as follows:\n• ESLAM uses the noisy emoticon data to smooth the lan-\nguage model trained from manually labeled data. Hence,\nESLAM seamlessly integrate both manually labeled data\nand noisy labeled data into a probabilistic framework. The\nlarge amount of noisy emoticon data gives ESLAM have\nthe power to deal with misspelled words, slang, modal\nparticles, acronyms, and the unforseen test words, which\ncannot be easily handled by fully supervised methods.\n• Besides the polarity classiﬁcation, ESLAM can also be\nused for subjectivity classiﬁcation which cannot be han-\ndled by most existing distantly supervised methods.\n• Rather than crawling a large amount of noisy data to lo-\ncal disks which is a typical choice by existing distantly\nsupervised methods, we propose an efﬁcient and conve-\nnient way to directly estimate the word probabilities from\nTwitter API without downloading any tweet. This is very\npromising because it is very expensive in terms of time\nand storage to download and process large amount of\ntweets.\n• Experiments on real data sets demonstrate that ESLAM\ncan effectively integrate both manually labeled data and\nnoisy labeled data to outperform those methods using\nonly one of them.\n3http://twittersentiment.appspot.com/\nRelated Work\nSA (Pang and Lee 2007) has a long history in natural lan-\nguage processing. Before (Pang, Lee, and Vaithyanathan\n2002), almost all methods are partially knowledge-based.\n(Pang, Lee, and Vaithyanathan 2002) shows that machine\nlearning techniques, such as naive Bayes, maximum entropy\nclassiﬁers, and SVM can outperform the knowledge-based\nbaselines on movie reviews. After that, the machine learn-\ning based methods have become the mainstream for SA.\nEarlier works on TSA follow the methods of traditional\nSA on normal text forms like movie reviews. These methods\nare mainly fully supervised (Jansen et al. 2009; Bermingham\nand Smeaton 2010) which have been introduced in the Intro-\nduction section. Most recent works include target-dependent\nSA based on SVM (Jiang et al. 2011), user-level SA based\non social networks (Tan et al. 2011), sentiment stream anal-\nysis based on association rules (Silva et al. 2011), and real-\ntime SA (Guerra et al. 2011).\nRecently, more and more distantly supervised methods\nare proposed. (Go, Bhayani, and Huang 2009)’s training\ndata consist of tweets with emoticons like “:)” and “:(” and\nthey use these emoticons as noisy labels. (Davidov, Tsur,\nand Rappoport 2010) uses 50 Twitter tags and 15 smileys\nas noisy labels to identify and classify diverse sentiment\ntypes of tweets. Other methods with noisy labels (Barbosa\nand Feng 2010; Kouloumpis, Wilson, and Moore 2011) are\nalso proposed. All these methods cannot handle subjectiv-\nity classiﬁcation well. Furthermore, these methods need to\ncrawl all the data and store them in the local disks. This is\nvery inefﬁcient when millions or even billions of tweets are\nused because request rate for crawling tweets is limited by\nTwitter server.\nAlthough a lot of TSA methods have been proposed, few\nof them can effectively integrate both manually labeled data\nand noisy labeled data into the same framework, which mo-\ntivates our ESLAM work in this paper.\nOur Approach\nIn this section, ﬁrst we present how to adapt language mod-\nels (Manning, Raghavan, and Schutze 2009) for SA. Then\nwe propose a very effective and efﬁcient way to learn the\nemoticon model from Twitter API. Finally, we will intro-\nduce the strategy to seamlessly integrate both manually la-\nbeled data and emoticon data into a probabilistic framework\nwhich is our ESLAM method.\nLanguage Models for SA\nLanguage models (LM) can be either probabilistic or non-\nprobabilistic. In this paper, we refer to probabilistic lan-\nguage models which are widely used in information retrieval\nand natural language processing (Ponte and Croft 1998;\nZhai and Lafferty 2004; Manning, Raghavan, and Schutze\n2009). A LM assign a probability to a sequence of words. In\ninformation retrieval, ﬁrst we estimate a LM for each doc-\nument, then we can compute a likelihood measuring how\nlikely a query is generated by each document LM and rank\nthe documents with respect to the likelihoods.\n1679\nTSA is actually a classiﬁcation problem. To adapt LM for\nTSA, we concatenate all the tweets from the same class to\nform one synthetic document. Hence, for the polarity clas-\nsiﬁcation problem, one document is constructed from posi-\ntive training tweets, and the other document is constructed\nfrom negative training tweets. Then we learn two LMs, one\nfor positive class and the other for negative class. The LM\nlearning procedure for subjectivity classiﬁcation is similar.\nDuring the test phase, we treat each test tweet as a query,\nand then we can use the likelihoods to rank the classes. The\nclass with the highest likelihood will be chosen as the label\nof the test tweet.\nWe use c1 and c2 to denote the two language models. In\npolarity classiﬁcation, c1 is the language model for positive\ntweets and c2 is for negative tweets. In subjectivity classiﬁ-\ncation, c1 is for subjective class and c2 is for objective (neu-\ntral) class. In order to classify a tweet tto c1 or c2, we need\nto estimate the tweet likelihoods computed by P(t|c1) and\nP(t|c2). By using the common unigram assumption, we get:\nP(t|c) =\nn∏\ni=1\nP(wi|c),\nwhere nis the number of words in tweet tand P(wi|c) is a\nmultinomial distribution estimated from the LM of class c.\nThis probability simulates the generative process of the test\ntweet. Firstly, the ﬁrst word (w1) is generated by following\na multinomial distribution P(wi|c). After that, the second\nword is generated independently of the previous word by\nfollowing the same distribution. This process continues until\nall the words in this tweet have been generated.\nOne commonly used method to estimate the distributions\nis maximum likelihood estimate (MLE), which computes\nthe probability as follows:\nPa(wi|c) =Ni,c\nNc\n,\nwhere Ni,c is the number of times word wi appearing in\ntraining data of class cand Nc is the total number of words\nin training data of class c.\nIn general, the vocabulary is determined by the training\nset. To classify tweets in test set, it is very common to en-\ncounter words that do not appear in training set especially\nwhen there are not enough training data or the words are\nnot well-formed. In these cases, smoothing (Zhai and Laf-\nferty 2004) plays a very important role in language mod-\nels because it can avoid assigning zero probability to un-\nseen words. Furthermore, smoothing can make the model\nmore accurate and robust. Representative smoothing meth-\nods include Dirichlet smoothing and Jelinek-Mercer (JM)\nsmoothing (Zhai and Lafferty 2004). Although the original\nJM smoothing method is used to linear interpolation of the\nMLE model with the collection model (Zhai and Lafferty\n2004), we use JM smoothing method to linearly interpolate\nthe MLE model with the emoticon model in this paper.\nEmoticon Model\nFrom the emoticon data, we can also build the LMs for dif-\nferent classes. We propose a very effective and efﬁcient way\nto estimate the emoticon LM Pu(wi|c) from Twitter Search\nAPI. Twitter Search API 4 is a dedicated API for running\nsearches against the real-time index of recent tweets. Its in-\ndex includes tweets between 6-9 days. Given a query which\nconsists of one or several words, the API returns up to 1500\nrelevant tweets and their posting time.\nPolarity Classiﬁcation To get Pu(wi|c1), the probabil-\nity of wi in positive class, we make an assumption that all\ntweets containing “:)” are positive. We build a query “wi :)”\nand input it to the Search API. Then it returns tweets con-\ntaining both wi and “:)” with their posting time. After sum-\nmarization, we get the number of tweets nwi and the time\nrange of these tweets twi. Then we build another query “:)”\nand get the number of returned tweetsnsand the time range\nts. Some estimations 5 show that a tweet contains 15 words\non average.\nAssume that the tweets on Twitter are uniformly dis-\ntributed with respect to time. Similar to the rule of getting\nPa(wi|c), we can estimate Pu(wi|c1) with the following\nrule:\nPu(wi|c1) =\nnwi\ntwi\nns\nts ×15 = nwi ×ts\n15 ×twi ×ns.\nThe term nwi\ntwi\nis roughly the number of times word wi ap-\npearing in class c per unit time, and the term ns\nts ×15 is\nroughly the total number of words in class cper unit time.\nLet Fu = ∑|V |\nj=1 Pu(wj|c) be the normalization factor\nwhere |V|is the size of vocabulary containing both seen and\nunseen words. Then each estimatedPu(wi|c) should be nor-\nmalized to make them sum up to one:\nPu(wi|c) :=Pu(wi|c)/Fu = Pu(wi|c)\n∑|V |\nj=1 Pu(wj|c)\n=\nnwi×ts\n15×twi×ns\n∑|V |\nj=1\nnwj ×ts\n15×twj ×ns\n=\nnwi\ntwi\n∑|V |\nj=1\nnwj\ntwj\n.\nWe can ﬁnd that there is no need to get tsand ns, because\nPu(wi|c) can be determined only by nwi and twi.\nFor the LM of negative class, we assume that the negative\ntweets are those containing “:(”. The estimate procedure for\nPu(wi|c2) is similar to that for Pu(wi|c1). The only differ-\nence is that the query should be changed to “wi :(”.\nSubjectivity Classiﬁcation For subjectivity classiﬁcation,\nthe two classes are subjective and objective. The assump-\ntion for subjective tweets is that tweets with “:)” or “:(” are\nassumed to carry subjectivity of the users. So we build the\nquery “wi:) OR :(” for the subjective class.\nAs for the objective LM, getting Pu(wi|c2), the probabil-\nity of wi in objective class, is much more challenging than\nthat in subjective class. To the best of our knowledge, no\ngeneral assumption for objective tweets has been reported by\nresearchers. We tried the strategy which treats tweets with-\nout emoticons as objective but the experiments showed that\n4https://dev.twitter.com/docs/using-search\n5http://blog.oup.com/2009/06/oxford-twitter/\n1680\nthe results were not satisfactory, which implies that this as-\nsumption is unreasonable. (Kouloumpis, Wilson, and Moore\n2011) tries to use some hashtags like “#jobs” as indicators\nfor objective tweets. However, this assumption is not gen-\neral enough because the number of tweets containing spe-\nciﬁc hashtags is limited and these tweets’ sentiment may be\nbiased to certain topics like “jobs”.\nHere we present a novel assumption for objective tweets\nthat tweets containing an objective url link is assumed to be\nobjective. Based on our observation, we ﬁnd that urls linking\nto the picture sites (e.g., twitpic.com) or video sites (e.g.,\nyoutube.com) are often subjective and other urls like those\nlinking to news articles are usually objective. Hence, if a\nurl link doesn’t represent pictures or videos, we call it an\nobjective url link. Based on the above assumption, we build\nthe query “wifilter : links” 6 to get the statistics about the\nobjective class.\nESLAM\nAfter we have estimated the Pa(wi|c) from manually la-\nbeled data and Pu(wi|c) from the noisy emoticon data,\nwe can integrate them into the same probabilistic frame-\nwork Pco(wi|c). Before combining Pa(wi|c) and Pu(wi|c),\nthere’s another important step: smoothing Pu(wi|c). Be-\ncause Pu(wi|c) is estimated from noisy emoticon data, it can\nbe biased. We adopt Dirichlet smoothing (Zhai and Lafferty\n2004) to smooth Pu(wi|c).\nBy following the JM smoothing principle (Zhai and Laf-\nferty 2004), our ESLAM model Pco(wi|c) can be computed\nas follows:\nPco(wi|c) =αPa(wi|c) + (1−α)Pu(wi|c), (1)\nwhere α ∈[0,1] is the combination parameter controlling\nthe contribution of each component.\nExperiments\nData Set\nThe publicly available Sanders Corpus 7 is used for evalu-\nation. It consists of 5513 manually labeled tweets. These\ntweets were collected with respect to one of the four dif-\nferent topics (Apple, Google, Microsoft, and Twitter). After\nremoving the non-English and spam tweets, we have 3727\ntweets left. The detailed information of the corpus is shown\nin Table 1. As for the noisy emoticon data, theoretically we\nuse all the data existing in Twitter by sampling with its API.\nTable 1: Corpus Statistics\nCorpus # Positive # Negative # Neutral # Total\nSanders 570 654 2503 3727\nWe adopt the following strategies to preprocess the data:\n• Username. Twitter usernames which start with @ are re-\nplaced with “twitterusername”.\n6ﬁlter:links means returning tweets containing urls.\n7http://www.sananalytics.com/lab/twitter-sentiment/\n• Digits. All Digits in tweets are replaced with “twitter-\ndigit”.\n• Links. All urls in tweets are replaced with “twitterurl”.\n• Stopwords. Stopwords like “the” and “to” are removed.\n• Lower case and Stemming. All words are changed to their\nlower cases and stemmed to terms.\n• Retweets and Duplicates. Retweets and duplicate tweets\nare removed to avoid giving extra weight to these tweets\nin training data.\nEvaluation Scheme and Metrics\nAfter removing the retweets or duplicates and setting the\nclasses to be balanced, we randomly choose 956 tweets for\npolarity classiﬁcation, including 478 positive tweets and 478\nnegative ones. For the subjectivity classiﬁcation, we also set\nthe classes to be balanced and randomly choose 1948 tweets\nfor evaluation, including 974 subjective tweets and 974 ob-\njective (neutral) ones.\nThe evaluation schemes for both polarity and subjectivity\nclassiﬁcation are similar. Assume the total number of man-\nually labeled tweets, including both training and test data,\nis X. Each time we randomly sample the same amount of\ntweets (say Y) for both classes (e.g., positive and negative)\nfor training, and use the rest X −2Y tweets for test. This\nrandom selection and testing is carried out 10 rounds inde-\npendently for each unique training set size, and the average\nperformance is reported. We perform experiments with dif-\nferent sizes of training set, i.e., Y is set to different values,\nsuch as 32, 64, and 128.\nAs in (Go, Bhayani, and Huang 2009) and (Kouloumpis,\nWilson, and Moore 2011), we adopt accuracy and F-score\nas our evaluation metrics. Accuracy is a measure of what\npercentage of test data are correctly predicted, and F-score\nis computed by combining precision and recall.\nEffect of Emoticons\nWe compare our ESLAM method to the fully supervised\nlanguage model (LM) to verify whether the smoothing with\nemoticons is useful or not. Please note that the fully super-\nvised LM uses only the manually labeled data for training\nwhile ESLAM integrates both manually labeled data and the\nemoticon data for training. Figure 1 and Figure 2 respec-\ntively illustrate the accuracy and F-score of the two methods\nwith different number of manually labeled training data, i.e.,\n2Y = 32,64,128,256,512,768.\nFrom Figure 1 and Figure 2, we can see that as the num-\nber of manually labeled data increases, the performance of\nboth methods will also increase, which is reasonable because\nthe manually labeled data contain strong discriminative in-\nformation. Under all the evaluation settings, ESLAM con-\nsistently outperforms the fully supervised LM, in particular\nfor the settings with small number of manually labeled data.\nThis implies that the noisy emoticon data do have some use-\nful information and our ESLAM can effectively exploit it to\nachieve good performance.\nFigure 3 and Figure 4 demonstrate the accuracy and F-\nscore of the two methods on subjectivity classiﬁcation with\n1681\nFigure 1: Effect of emoticons on accuracy of polarity classiﬁca-\ntion.\nFigure 2: Effect of emoticons on F-score of polarity classiﬁcation.\ndifferent number of manually labeled training data, respec-\ntively. The results are similar to those for polarity classi-\nﬁcation which once again veriﬁes the effectiveness of our\nESLAM to utilize the noisy emoticon data. The good per-\nformance of ESLAM also veriﬁes that our url link based\nmethod is effective to ﬁnd objective tweets, which is a big\nchallenge for most existing distantly supervised methods.\nFigure 3: Effect of emoticons on accuracy of subjectivity classiﬁ-\ncation.\nEffect of Manually Labeled Data\nWe compare our ESLAM method to the distantly supervised\nLM to verify whether the manually labeled data can provide\nextra useful information for classiﬁcation. Please note that\nthe distantly supervised LM uses only the noisy emoticon\ndata for training, while ESLAM integrates both manually\nlabeled data and the emoticon data for training.\nFigure 5 and Figure 6 illustrate the accuracy and F-score\nof the two methods on polarity classiﬁcation with different\nnumber of manually labeled training data, respectively. The\nFigure 4: Effect of emoticons on F-score of subjectivity classiﬁ-\ncation.\nblue line corresponds to the performance of distantly super-\nvised LM, which also corresponds to the case of zero manu-\nally labeled data. The red line is the results of ESLAM. We\ncan ﬁnd that ESLAM achieves better performance than the\ndistantly supervised LM. With the increase of manually la-\nbeled data, the performance gap between them will become\nlarger and larger. This veriﬁes our claim that it is not enough\nto use only the data of noisy labels for training.\nFigure 5: Effect of manually labeled data on accuracy of polarity\nclassiﬁcation.\nFigure 6: Effect of manually labeled data on F-score of polarity\nclassiﬁcation.\nFigure 7 and Figure 8 illustrate the accuracy and F-score\nof the two methods on subjectivity classiﬁcation with differ-\nent number of manually labeled training data, respectively.\nThe results are similar to those for polarity classiﬁcation.\nSensitivity to Parameters\nThe parameter α in (1) plays a critical role to control the\ncontribution between the manually labeled information and\nnoisy labeled information. To show the effect of this param-\neter in detail, we try different values for polarity classiﬁca-\n1682\nFigure 7: Effect of manually labeled data on accuracy of subjec-\ntivity classiﬁcation.\nFigure 8: Effect of manually labeled data on F-score of subjectiv-\nity classiﬁcation.\ntion. Figure 9 and Figure 10 show the accuracy of ESLAM\nwith 128 and 512 labeled training tweets, respectively.\nThe case α= 0means only noisy emoticon data are used\nand α = 1 is the fully supervised case. The results in the\nFigures clearly show that the best strategy is to integrate both\nmanually labeled data and noisy data into training. We also\nnotice that with 512 labeled training data ESLAM achieves\nits best performance with relatively bigger α than the case\nof 128 labeled data, which is obviously reasonable. Further-\nmore, we ﬁnd that ESLAM is not sensitive to the small vari-\nations in the value of parameterαbecause the range for αto\nachieve the better performance is large.\nFigure 9: Effect of the smoothing parameter α with 128 labeled\ntraining tweets.\nConclusion\nExisting methods use either manually labeled data or noisy\nlabeled data for Twitter sentiment analysis, but few of them\nutilize both of them for training. In this paper, we propose\na novel model, called emoticon smoothed language model\n(ESLAM), to seamlessly integrate these two kinds of data\nFigure 10: Effect of the smoothing parameter α with 512 labeled\ntraining tweets.\ninto the same probabilistic framework. Experiments on real\ndata sets show that our ESLAM method can effectively inte-\ngrate both kinds of data to outperform those methods using\nonly one of them.\nOur ESLAM method is general enough to integrate other\nkinds of noisy labels for model training, which will be pur-\nsued in our future work.\nAcknowledgments\nThis work is supported by the NSFC (No. 61100125) and the 863\nProgram of China (No. 2011AA01A202, No. 2012AA011003).\nReferences\nBarbosa, L., and Feng, J. 2010. Robust sentiment detection\non twitter from biased and noisy data. In COLING, 36–44.\nBermingham, A., and Smeaton, A. F. 2010. Classifying\nsentiment in microblogs: is brevity an advantage? In CIKM,\n1833–1836.\nDavidov, D.; Tsur, O.; and Rappoport, A. 2010. Enhanced\nsentiment learning using twitter hashtags and smileys. In\nCOLING, 241–249.\nGo, A.; Bhayani, R.; and Huang, L. 2009. Twitter sentiment\nclassiﬁcation using distant supervision. Technical report\n.\nGuerra, P. H. C.; Veloso, A.; Jr., W. M.; and Almeida, V .\n2011. From bias to opinion: a transfer-learning approach to\nreal-time sentiment analysis. In KDD, 150–158.\nJansen, B. J.; Zhang, M.; Sobel, K.; and Chowdury, A. 2009.\nTwitter power: Tweets as electronic word of mouth. JASIST\n60(11):2169–2188.\nJiang, L.; Yu, M.; Zhou, M.; Liu, X.; and Zhao, T. 2011.\nTarget-dependent twitter sentiment classiﬁcation. In ACL,\n151–160.\nKouloumpis, E.; Wilson, T.; and Moore, J. 2011. Twit-\nter sentiment analysis: The good the bad and the omg! In\nICWSM, 538–541.\nLiu, X.; Li, K.; Zhou, M.; and Xiong, Z. 2011a. Collective\nsemantic role labeling for tweets with clustering. In IJCAI,\n1832–1837.\nLiu, X.; Li, K.; Zhou, M.; and Xiong, Z. 2011b. Enhanc-\ning semantic role labeling for tweets using self-training. In\nAAAI.\nLiu, X.; Zhang, S.; Wei, F.; and Zhou, M. 2011c. Recogniz-\ning named entities in tweets. In ACL, 359–367.\n1683\nManning, C. D.; Raghavan, P.; and Schutze, H. 2009.An In-\ntroduction to Information Retrieval. Cambridge University\nPress.\nPang, B., and Lee, L. 2007. Opinion mining and sentiment\nanalysis. Foundations and Trends in Information Retrieval\n2(1-2):1–135.\nPang, B.; Lee, L.; and Vaithyanathan, S. 2002. Thumbs up?\nsentiment classiﬁcation using machine learning techniques.\nIn EMNLP, 79–86.\nPonte, J. M., and Croft, W. B. 1998. A language modeling\napproach to information retrieval. In SIGIR, 275–281.\nSilva, I. S.; Gomide, J.; Veloso, A.; Jr., W. M.; and Fer-\nreira, R. 2011. Effective sentiment stream analysis with\nself-augmenting training and demand-driven projection. In\nSIGIR, 475–484.\nTan, C.; Lee, L.; Tang, J.; Jiang, L.; Zhou, M.; and Li, P.\n2011. User-level sentiment analysis incorporating social net-\nworks. In KDD, 1397–1405.\nZhai, C., and Lafferty, J. D. 2004. A study of smooth-\ning methods for language models applied to information re-\ntrieval. ACM Trans. Inf. Syst. 22(2):179–214.\n1684",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8394355773925781
    },
    {
      "name": "Noisy data",
      "score": 0.6707679033279419
    },
    {
      "name": "Smoothing",
      "score": 0.6340920329093933
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6283485889434814
    },
    {
      "name": "Labeled data",
      "score": 0.6097894906997681
    },
    {
      "name": "Sentiment analysis",
      "score": 0.5888524055480957
    },
    {
      "name": "Language model",
      "score": 0.5839271545410156
    },
    {
      "name": "Task (project management)",
      "score": 0.5781307220458984
    },
    {
      "name": "Machine learning",
      "score": 0.571101188659668
    },
    {
      "name": "Noise (video)",
      "score": 0.4922882616519928
    },
    {
      "name": "Training set",
      "score": 0.45709294080734253
    },
    {
      "name": "Social media",
      "score": 0.42982080578804016
    },
    {
      "name": "Synthetic data",
      "score": 0.42633187770843506
    },
    {
      "name": "Supervised learning",
      "score": 0.42007142305374146
    },
    {
      "name": "Natural language processing",
      "score": 0.36329782009124756
    },
    {
      "name": "Image (mathematics)",
      "score": 0.07632660865783691
    },
    {
      "name": "Artificial neural network",
      "score": 0.0714726448059082
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "World Wide Web",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Computer vision",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I183067930",
      "name": "Shanghai Jiao Tong University",
      "country": "CN"
    }
  ]
}