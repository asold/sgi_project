{
    "title": "Response Generated by Large Language Models Depends on the Structure of the Prompt",
    "url": "https://openalex.org/W4393165047",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2411372681",
            "name": "Pradosh Kumar Sarangi",
            "affiliations": [
                "All India Institute of Medical Sciences, Deoghar"
            ]
        },
        {
            "id": "https://openalex.org/A2556512418",
            "name": "Himel Mondal",
            "affiliations": [
                "All India Institute of Medical Sciences, Deoghar"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4390431026",
        "https://openalex.org/W4386867830",
        "https://openalex.org/W4379598302",
        "https://openalex.org/W4390233942"
    ],
    "abstract": "Letter to: Assessing the Capability of ChatGPT, Google Bard, and Microsoft Bing in Solving Radiology Case VignettesIndian J Radiol Imaging eFirstDOI: 10.1055/s-0043-1777746",
    "full_text": "Response Generated by Large Language Models\nDepends on the Structure of the Prompt\nPradosh Kumar Sarangi1 Himel Mondal2\n1 Department of Radiodiagnosis, All India Institute of Medical\nSciences, Deoghar, Jharkhand, India\n2 Department of Physiology, All India Institute of Medical Sciences,\nDeoghar, Jharkhand, India\nIndian J Radiol Imaging 2024;34:574– 575.\nAddress for correspondence Himel Mondal, MBBS, MD, Department\nof Physiology, All India Institute of Medical Sciences, Deoghar 814152,\nJharkhand, India (e-mail: himelmkcg@gmail.com).We appreciate the opportunity to respond to the letter\nwritten in response to our published article titled“Assessing\nthe capability of ChatGPT, Google Bard, and Microsoft Bing in\nsolving radiology case vignettes.”1 We thank the authors for\ntheir interest in our work and thoughtful questions.\nThe use of large language models (LLMs) like ChatGPT,\nGoogle Bard, Microsoft Bing, etc., in radiology is indeed a\nburgeoning ﬁeld, and we are pleased that our study has\nsparked further discussion. We would like to address the\nraised concerns and provide additional information to en-\nhance the clarity of our methodology.\nThe authors asked us about the input prompts. We used\nthe Fellowship of the Royal College of Radiologists Part 2A\npattern questions directly as prompts. There was no preﬁx( e .\ng., role deﬁnition) or sufﬁx (e.g., customizing response for\nreader) attached to the prompt.\n►Fig. 1 present such a\nquestion used as a prompt in ChatGPT (GPT3.5; free version).\nWe appreciate the authors’ acknowledgment of the po-\ntential inﬂuence of prompt engineering on the performance\nof LLMs. Indeed, the intricacies of prompt design can change\nthe response drastically. We summarized top ten tips\nin ►Table 1 about designing prompts for better output\nFig. 1 Example of a prompt we used for getting response from ChatGPT3.5.\narticle published online\nMarch 25, 2024\nDOI https://doi.org/\n10.1055/s-0044-1782165.\nISSN 0971-3026.\n© 2024. Indian Radiological Association. All rights reserved.\nThis is an open access article published by Thieme under the terms of the\nCreative Commons Attribution-NonDeri vative-NonCommercial-License,\npermitting copying and reproduction so long as the original work is given\nappropriate credit. Contents may not be used for commercial purposes, or\nadapted, remixed, transformed or built upon. (https://creativecommons.org/\nlicenses/by-nc-nd/4.0/)\nThieme Medical and Scientiﬁc Publishers Pvt. Ltd., A-12, 2nd Floor,\nSector 2, Noida-201301 UP, India\nLetter to the Editor\nTHIEME\n574\nArticle published online: 2024-03-25\nfrom the LLM. There are several websites that help training\nprompt engineering.2,3\nThe authors raise a valid question about any training we\nused for the chatbots. We conﬁrm that the chatbots, includ-\ning ChatGPT, Google Bard, and Microsoft Bing, were not\ntrained by us. Instead, we utilized pretrained models from\nthe respective platforms to ensure a fair evaluation of their\nout-of-the-box diagnostic capabilities. However, studies\nhave reported that ﬁne-tuned GPT 3.5 and GPT 4 models\nhave shown better responses.\n4\nWe hope that these clariﬁcations address the concerns\nraised by the authors. Thank you for providing this platform\nfor academic discourse.\nFunding\nNone.\nConﬂict of Interest\nNone declared.\nReferences\n1 Sarangi PK, Narayan RK, Mohakud S, Vats A, Sahani D, Mondal H.\nAssessing the capability of ChatGPT, Google Bard, and Microsoft\nBing in solving radiology case vignettes. Indian J Radiol Imaging\n2024;34(02):276– 282\n2 Meskó B. Prompt engineering as an important emerging skill for\nmedical professionals: tutorial. J Med Internet Res 2023;25:\ne50638\n3 Giray L. Prompt engineering with ChatGPT: a guide for academic\nwriters. Ann Biomed Eng 2023;51(12):2629– 2633\n4 Gamble JL, Ferguson D, Yuen J, Sheikh A. Limitations of GPT-\n3.5 and GPT-4 in applying Fleischner Society Guidelines\nto incidental lung nodules. Can Assoc Radiol J 2024;75(02):\n412– 416\nTable 1 Ten tips for using prompts for using large language models (LLMs)\nTip Brief\n1. Clearly deﬁne the objective Clearly state the purpose of your inquiry or the type of information you are\nseeking\n2. Ask to play a role You can ask it to play a particular role also. For example, you can provide a prompt\nlike “act like an academic writer”\n3. Provide context and relevant\ninformation\nInclude background details that can help the model better understand your\nrequest. The more details are given to it, more speciﬁcw o u l db et h er e s p o n s e\n4. Use speciﬁc language Incorporate precise and clear language to guide the model in generating\nresponses. Although LLMs’ comprehension is high, sometimes the models may\ngenerate undesired text due to ambiguity in input language\n5. Experiment with formatting and\nstructure\nExplore different ways to structure your prompt for improved clarity and\nspeciﬁcity\n6. Provide example An example of what answer you want helps the model to prepare better response\n7. Divide task in smaller segments Putting a complex task would make the response complex. Hence, large task can\nbe divided to smaller fragments for a better output\n8. Ask for references Medical literature needs reference. Hence, the LLM may ask to write with\nreference\n9. Chain of thoughts A simple calculation can be mistaken by LLM. Hence, always ask to do a stepwise\ncalculation or generate content step by step\n10. Specify text volume The length of text, sentence structure, and readability can be de ﬁned. For\nexample, one can prompt to“generate content for a 6th standard student”\nNote: A guide is also available from https://platform.openai.com/docs/guides/prompt-engineering/six-strategies-for-getting-better-resu lts.\nIndian Journal of Radiology and Imaging Vol. 34 No. 3/2024 © 2024. Indian Radiological Association. All rights reserved.\nLetter to the Editor 575\n"
}