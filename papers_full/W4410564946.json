{
  "title": "Empirical Guidelines for Deploying LLMs onto Resource-constrained Edge Devices",
  "url": "https://openalex.org/W4410564946",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2623290222",
      "name": "Ruiyang Qin",
      "affiliations": [
        "Villanova University"
      ]
    },
    {
      "id": "https://openalex.org/A2900393613",
      "name": "Dancheng Liu",
      "affiliations": [
        "University at Buffalo, State University of New York"
      ]
    },
    {
      "id": "https://openalex.org/A2330390030",
      "name": "Chenhui Xu",
      "affiliations": [
        "University at Buffalo, State University of New York"
      ]
    },
    {
      "id": "https://openalex.org/A2986280855",
      "name": "Zheyu Yan",
      "affiliations": [
        "University of Notre Dame"
      ]
    },
    {
      "id": "https://openalex.org/A3197525403",
      "name": "Zhaoxuan Tan",
      "affiliations": [
        "University of Notre Dame"
      ]
    },
    {
      "id": "https://openalex.org/A2911401464",
      "name": "Zhenge Jia",
      "affiliations": [
        "University of Notre Dame"
      ]
    },
    {
      "id": "https://openalex.org/A4289828482",
      "name": "Amir Nassereldine",
      "affiliations": [
        "University at Buffalo, State University of New York"
      ]
    },
    {
      "id": "https://openalex.org/A2121185196",
      "name": "Jiajie Li",
      "affiliations": [
        "University at Buffalo, State University of New York"
      ]
    },
    {
      "id": "https://openalex.org/A2098004101",
      "name": "Meng Jiang",
      "affiliations": [
        "University of Notre Dame"
      ]
    },
    {
      "id": "https://openalex.org/A2160800653",
      "name": "Ahmed Abbasi",
      "affiliations": [
        "University of Notre Dame"
      ]
    },
    {
      "id": "https://openalex.org/A2187349416",
      "name": "Jinjun Xiong",
      "affiliations": [
        "University at Buffalo, State University of New York"
      ]
    },
    {
      "id": "https://openalex.org/A2112093511",
      "name": "Yiyu Shi",
      "affiliations": [
        "University of Notre Dame"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3037021823",
    "https://openalex.org/W4404058379",
    "https://openalex.org/W4391136507",
    "https://openalex.org/W4393147129",
    "https://openalex.org/W3044853528",
    "https://openalex.org/W4210783934",
    "https://openalex.org/W4322766882",
    "https://openalex.org/W4372348475",
    "https://openalex.org/W6851896007",
    "https://openalex.org/W3043669475",
    "https://openalex.org/W4366549000",
    "https://openalex.org/W4385571011",
    "https://openalex.org/W4401043244",
    "https://openalex.org/W4407298138",
    "https://openalex.org/W4205991051",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W4406650295",
    "https://openalex.org/W6838539104",
    "https://openalex.org/W4280534475",
    "https://openalex.org/W4388623217",
    "https://openalex.org/W6852962002",
    "https://openalex.org/W6853349582",
    "https://openalex.org/W4401547146",
    "https://openalex.org/W4392126167",
    "https://openalex.org/W4393160423",
    "https://openalex.org/W4393168993",
    "https://openalex.org/W4393146966",
    "https://openalex.org/W4386273009",
    "https://openalex.org/W4392271030",
    "https://openalex.org/W4393299232",
    "https://openalex.org/W4404782847",
    "https://openalex.org/W4283766928"
  ],
  "abstract": "The scaling laws have become the de facto guidelines for designing large language models (LLMs), but they were studied under the assumption of unlimited computing resources for both training and inference. As LLMs are increasingly used as personalized intelligent assistants, their customization (i.e., learning through fine-tuning) and deployment onto resource-constrained edge devices will become more and more prevalent. An urgent but open question is how a resource-constrained computing environment would affect the design choices for a personalized LLM. We study this problem empirically in this work. In particular, we consider the tradeoffs among a number of key design factors and their intertwined impacts on learning efficiency and accuracy. The factors include the learning methods for LLM customization, the amount of personalized data used for learning customization, the types and sizes of LLMs, the compression methods of LLMs, the amount of time afforded to learn, and the difficulty levels of the target use cases. Through extensive experimentation and benchmarking, we draw a number of surprisingly insightful guidelines for deploying LLMs onto resource-constrained devices. For example, an optimal choice between parameter learning and RAG may vary depending on the difficulty of the downstream task, the longer fine-tuning time does not necessarily help the model, and a compressed LLM may be a better choice than an uncompressed LLM to learn from limited personalized data.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8238295912742615
    },
    {
      "name": "Enhanced Data Rates for GSM Evolution",
      "score": 0.5677643418312073
    },
    {
      "name": "Resource (disambiguation)",
      "score": 0.5018234252929688
    },
    {
      "name": "Telecommunications",
      "score": 0.2702655792236328
    },
    {
      "name": "Computer network",
      "score": 0.20769530534744263
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I7863295",
      "name": "Villanova University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I63190737",
      "name": "University at Buffalo, State University of New York",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I107639228",
      "name": "University of Notre Dame",
      "country": "US"
    }
  ],
  "cited_by": 6
}