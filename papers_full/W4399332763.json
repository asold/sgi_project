{
    "title": "Helpful or Harmful? Exploring the Efficacy of Large Language Models for Online Grooming Prevention",
    "url": "https://openalex.org/W4399332763",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2598876456",
            "name": "Ellie Prosser",
            "affiliations": [
                "University of Bristol"
            ]
        },
        {
            "id": "https://openalex.org/A2111189288",
            "name": "Matthew Edwards",
            "affiliations": [
                "University of Bristol"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4387801427",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W4366249120",
        "https://openalex.org/W3200209840",
        "https://openalex.org/W4323037544",
        "https://openalex.org/W2484944616",
        "https://openalex.org/W4225165463",
        "https://openalex.org/W3185341429",
        "https://openalex.org/W3199400376",
        "https://openalex.org/W1967022892",
        "https://openalex.org/W4386867830",
        "https://openalex.org/W4382246105",
        "https://openalex.org/W2113109652",
        "https://openalex.org/W4210403989",
        "https://openalex.org/W3011574394",
        "https://openalex.org/W2136583886",
        "https://openalex.org/W2529427724",
        "https://openalex.org/W4225095645",
        "https://openalex.org/W2588759517",
        "https://openalex.org/W4385570036",
        "https://openalex.org/W4366548330",
        "https://openalex.org/W3088409176"
    ],
    "abstract": "Powerful generative Large Language Models (LLMs) are becoming popular tools amongst the general public as question-answering systems, and are being utilised by vulnerable groups such as children. With children increasingly interacting with these tools, it is imperative for researchers to scrutinise the safety of LLMs, especially for applications that could lead to serious outcomes, such as online child safety queries. In this paper, the efficacy of LLMs for online grooming prevention is explored both for identifying and avoiding grooming through advice generation, and the impact of prompt design on model performance is investigated by varying the provided context and prompt specificity. In results reflecting over 6,000 LLM interactions, we find that no models were clearly appropriate for online grooming prevention, with an observed lack of consistency in behaviours, and potential for harmful answer generation, especially from open-source models. We outline where and how models fall short, providing suggestions for improvement, and identify prompt designs that heavily altered model performance in troubling ways, with findings that can be used to inform best practice usage guides.",
    "full_text": null
}